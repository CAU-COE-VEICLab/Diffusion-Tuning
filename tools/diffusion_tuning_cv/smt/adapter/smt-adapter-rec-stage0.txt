[2024-08-01 08:52:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 366): INFO Full config saved to pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/config.json
[2024-08-01 08:52:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/convnext-b/convnext_base_22k_224.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_convnext_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 27
    - 3
    DIMS:
    - 128
    - 256
    - 512
    - 1024
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: part0
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_conv_b_step_corss0
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 0.0001
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 0.8
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.0e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 1.0e-08

[2024-08-01 08:52:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/diffusion_finetune/convnext/adapter_convnext/diffusion_ft_adapter_convnext_base_224_22kto1k_step_crosslayer_process0.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/convnext-b/convnext_base_22k_224.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/diffusion-ft", "tag": "diffusion_ft_adapter_conv_b_step_corss0", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-08-01 08:52:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 108): INFO Creating model:adapter_convnext_diffusion_finetune/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0
[2024-08-01 08:52:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 110): INFO Adapter_ConvNeXt_Diffusion_Finetune(
  (uma): UMA(filter_strategy1=18, filter_strategy2=6,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): Identity()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (12): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (13): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (14): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (15): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (16): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (17): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (18): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (19): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (20): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (21): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (22): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (23): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (24): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (25): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (26): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (memory_downsampling): ModuleList()
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-08-01 08:52:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 113): INFO number of params: 4005032
[2024-08-01 08:52:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 150): INFO no checkpoint found in pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0, ignoring auto resume
[2024-08-01 08:52:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/convnext-b/convnext_base_22k_224.pth for fine-tuning......
[2024-08-01 08:52:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 112): INFO loading ImageNet-22K weight to ImageNet-1K ......
[2024-08-01 08:52:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['stages.0.0.adapter.down.weight', 'stages.0.0.adapter.down.bias', 'stages.0.0.adapter.up.weight', 'stages.0.0.adapter.up.bias', 'stages.0.1.adapter.down.weight', 'stages.0.1.adapter.down.bias', 'stages.0.1.adapter.up.weight', 'stages.0.1.adapter.up.bias', 'stages.0.2.adapter.down.weight', 'stages.0.2.adapter.down.bias', 'stages.0.2.adapter.up.weight', 'stages.0.2.adapter.up.bias', 'stages.1.0.adapter.down.weight', 'stages.1.0.adapter.down.bias', 'stages.1.0.adapter.up.weight', 'stages.1.0.adapter.up.bias', 'stages.1.1.adapter.down.weight', 'stages.1.1.adapter.down.bias', 'stages.1.1.adapter.up.weight', 'stages.1.1.adapter.up.bias', 'stages.1.2.adapter.down.weight', 'stages.1.2.adapter.down.bias', 'stages.1.2.adapter.up.weight', 'stages.1.2.adapter.up.bias', 'stages.2.0.adapter.down.weight', 'stages.2.0.adapter.down.bias', 'stages.2.0.adapter.up.weight', 'stages.2.0.adapter.up.bias', 'stages.2.1.adapter.down.weight', 'stages.2.1.adapter.down.bias', 'stages.2.1.adapter.up.weight', 'stages.2.1.adapter.up.bias', 'stages.2.2.adapter.down.weight', 'stages.2.2.adapter.down.bias', 'stages.2.2.adapter.up.weight', 'stages.2.2.adapter.up.bias', 'stages.2.3.adapter.down.weight', 'stages.2.3.adapter.down.bias', 'stages.2.3.adapter.up.weight', 'stages.2.3.adapter.up.bias', 'stages.2.4.adapter.down.weight', 'stages.2.4.adapter.down.bias', 'stages.2.4.adapter.up.weight', 'stages.2.4.adapter.up.bias', 'stages.2.5.adapter.down.weight', 'stages.2.5.adapter.down.bias', 'stages.2.5.adapter.up.weight', 'stages.2.5.adapter.up.bias', 'stages.2.6.adapter.down.weight', 'stages.2.6.adapter.down.bias', 'stages.2.6.adapter.up.weight', 'stages.2.6.adapter.up.bias', 'stages.2.7.adapter.down.weight', 'stages.2.7.adapter.down.bias', 'stages.2.7.adapter.up.weight', 'stages.2.7.adapter.up.bias', 'stages.2.8.adapter.down.weight', 'stages.2.8.adapter.down.bias', 'stages.2.8.adapter.up.weight', 'stages.2.8.adapter.up.bias', 'stages.2.9.adapter.down.weight', 'stages.2.9.adapter.down.bias', 'stages.2.9.adapter.up.weight', 'stages.2.9.adapter.up.bias', 'stages.2.10.adapter.down.weight', 'stages.2.10.adapter.down.bias', 'stages.2.10.adapter.up.weight', 'stages.2.10.adapter.up.bias', 'stages.2.11.adapter.down.weight', 'stages.2.11.adapter.down.bias', 'stages.2.11.adapter.up.weight', 'stages.2.11.adapter.up.bias', 'stages.2.12.adapter.down.weight', 'stages.2.12.adapter.down.bias', 'stages.2.12.adapter.up.weight', 'stages.2.12.adapter.up.bias', 'stages.2.13.adapter.down.weight', 'stages.2.13.adapter.down.bias', 'stages.2.13.adapter.up.weight', 'stages.2.13.adapter.up.bias', 'stages.2.14.adapter.down.weight', 'stages.2.14.adapter.down.bias', 'stages.2.14.adapter.up.weight', 'stages.2.14.adapter.up.bias', 'stages.2.15.adapter.down.weight', 'stages.2.15.adapter.down.bias', 'stages.2.15.adapter.up.weight', 'stages.2.15.adapter.up.bias', 'stages.2.16.adapter.down.weight', 'stages.2.16.adapter.down.bias', 'stages.2.16.adapter.up.weight', 'stages.2.16.adapter.up.bias', 'stages.2.17.adapter.down.weight', 'stages.2.17.adapter.down.bias', 'stages.2.17.adapter.up.weight', 'stages.2.17.adapter.up.bias', 'stages.2.18.adapter.down.weight', 'stages.2.18.adapter.down.bias', 'stages.2.18.adapter.up.weight', 'stages.2.18.adapter.up.bias', 'stages.2.19.adapter.down.weight', 'stages.2.19.adapter.down.bias', 'stages.2.19.adapter.up.weight', 'stages.2.19.adapter.up.bias', 'stages.2.20.adapter.down.weight', 'stages.2.20.adapter.down.bias', 'stages.2.20.adapter.up.weight', 'stages.2.20.adapter.up.bias', 'stages.2.21.adapter.down.weight', 'stages.2.21.adapter.down.bias', 'stages.2.21.adapter.up.weight', 'stages.2.21.adapter.up.bias', 'stages.2.22.adapter.down.weight', 'stages.2.22.adapter.down.bias', 'stages.2.22.adapter.up.weight', 'stages.2.22.adapter.up.bias', 'stages.2.23.adapter.down.weight', 'stages.2.23.adapter.down.bias', 'stages.2.23.adapter.up.weight', 'stages.2.23.adapter.up.bias', 'stages.2.24.adapter.down.weight', 'stages.2.24.adapter.down.bias', 'stages.2.24.adapter.up.weight', 'stages.2.24.adapter.up.bias', 'stages.2.25.adapter.down.weight', 'stages.2.25.adapter.down.bias', 'stages.2.25.adapter.up.weight', 'stages.2.25.adapter.up.bias', 'stages.2.26.adapter.down.weight', 'stages.2.26.adapter.down.bias', 'stages.2.26.adapter.up.weight', 'stages.2.26.adapter.up.bias', 'stages.3.0.adapter.down.weight', 'stages.3.0.adapter.down.bias', 'stages.3.0.adapter.up.weight', 'stages.3.0.adapter.up.bias', 'stages.3.1.adapter.down.weight', 'stages.3.1.adapter.down.bias', 'stages.3.1.adapter.up.weight', 'stages.3.1.adapter.up.bias', 'stages.3.2.adapter.down.weight', 'stages.3.2.adapter.down.bias', 'stages.3.2.adapter.up.weight', 'stages.3.2.adapter.up.bias'], unexpected_keys=[])
[2024-08-01 08:52:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/convnext-b/convnext_base_22k_224.pth'
[2024-08-01 08:53:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 63.841 (63.841)	Loss 0.3735 (0.3735)	Acc@1 91.016 (91.016)	Acc@5 98.828 (98.828)	Mem 3069MB
[2024-08-01 08:54:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 65.006 Acc@5 77.592
[2024-08-01 08:54:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 162): INFO Accuracy of the network on the 50000 test images: 65.0%
[2024-08-01 08:54:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 168): INFO Start training
[2024-08-01 08:55:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][0/2502]	eta 20:55:43 lr 0.000100	 wd 0.0000	time 30.1131 (30.1131)	loss 1.6934 (1.6934)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 7655MB
[2024-08-01 08:55:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:19:47 lr 0.000100	 wd 0.0000	time 0.1879 (0.4945)	loss 1.3779 (1.5385)	grad_norm 0.4102 (nan)	loss_scale 32768.0000 (33092.4356)	mem 7655MB
[2024-08-01 08:56:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:17:16 lr 0.000100	 wd 0.0000	time 0.3460 (0.4505)	loss 1.1924 (1.4927)	grad_norm 0.3942 (nan)	loss_scale 32768.0000 (32931.0249)	mem 7655MB
[2024-08-01 08:56:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:14:04 lr 0.000100	 wd 0.0000	time 0.1908 (0.3837)	loss 1.6553 (1.4611)	grad_norm 0.4261 (nan)	loss_scale 32768.0000 (32876.8638)	mem 7655MB
[2024-08-01 08:56:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:11:49 lr 0.000100	 wd 0.0000	time 0.1743 (0.3374)	loss 1.5244 (1.4254)	grad_norm 0.4333 (nan)	loss_scale 32768.0000 (32849.7157)	mem 7655MB
[2024-08-01 08:57:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:10:21 lr 0.000100	 wd 0.0000	time 0.2268 (0.3105)	loss 1.2100 (1.3965)	grad_norm 0.4434 (nan)	loss_scale 32768.0000 (32833.4052)	mem 7655MB
[2024-08-01 08:57:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:30 lr 0.000100	 wd 0.0000	time 0.2024 (0.2998)	loss 1.2871 (1.3647)	grad_norm 0.4568 (nan)	loss_scale 32768.0000 (32822.5225)	mem 7655MB
[2024-08-01 08:58:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:34 lr 0.000100	 wd 0.0000	time 0.2023 (0.2854)	loss 1.1211 (1.3318)	grad_norm 0.4981 (nan)	loss_scale 32768.0000 (32814.7447)	mem 7655MB
[2024-08-01 08:58:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:48 lr 0.000100	 wd 0.0000	time 0.1956 (0.2751)	loss 1.0684 (1.3050)	grad_norm 0.4705 (nan)	loss_scale 32768.0000 (32808.9089)	mem 7655MB
[2024-08-01 08:58:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:06 lr 0.000100	 wd 0.0000	time 0.1906 (0.2664)	loss 1.2285 (1.2795)	grad_norm 0.4978 (nan)	loss_scale 32768.0000 (32804.3685)	mem 7655MB
[2024-08-01 08:59:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:06:42 lr 0.000100	 wd 0.0000	time 0.4020 (0.2680)	loss 0.9849 (1.2574)	grad_norm 0.4985 (nan)	loss_scale 32768.0000 (32800.7353)	mem 7655MB
[2024-08-01 08:59:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:23 lr 0.000100	 wd 0.0000	time 0.1851 (0.2733)	loss 1.0674 (1.2385)	grad_norm 0.5090 (nan)	loss_scale 32768.0000 (32797.7620)	mem 7655MB
[2024-08-01 09:00:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:47 lr 0.000100	 wd 0.0000	time 0.1997 (0.2669)	loss 0.9497 (1.2218)	grad_norm 0.4641 (nan)	loss_scale 32768.0000 (32795.2839)	mem 7655MB
[2024-08-01 09:00:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:14 lr 0.000100	 wd 0.0000	time 0.1775 (0.2613)	loss 1.0205 (1.2079)	grad_norm 0.4898 (nan)	loss_scale 32768.0000 (32793.1868)	mem 7655MB
[2024-08-01 09:00:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:44 lr 0.000100	 wd 0.0000	time 0.2878 (0.2583)	loss 0.9834 (1.1941)	grad_norm 0.4982 (nan)	loss_scale 32768.0000 (32791.3890)	mem 7655MB
[2024-08-01 09:01:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:17 lr 0.000100	 wd 0.0000	time 0.1525 (0.2567)	loss 1.0605 (1.1825)	grad_norm 0.4826 (nan)	loss_scale 32768.0000 (32789.8308)	mem 7655MB
[2024-08-01 09:01:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:48 lr 0.000100	 wd 0.0000	time 0.1667 (0.2533)	loss 1.1504 (1.1723)	grad_norm 0.4652 (nan)	loss_scale 32768.0000 (32788.4672)	mem 7655MB
[2024-08-01 09:01:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:20 lr 0.000100	 wd 0.0000	time 0.2078 (0.2501)	loss 0.9644 (1.1624)	grad_norm 0.4432 (nan)	loss_scale 32768.0000 (32787.2640)	mem 7655MB
[2024-08-01 09:02:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:02:53 lr 0.000100	 wd 0.0000	time 0.2038 (0.2475)	loss 0.9351 (1.1532)	grad_norm 0.4749 (nan)	loss_scale 32768.0000 (32786.1943)	mem 7655MB
[2024-08-01 09:02:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:29 lr 0.000100	 wd 0.0000	time 0.2036 (0.2485)	loss 1.1504 (1.1450)	grad_norm 0.4475 (nan)	loss_scale 32768.0000 (32785.2372)	mem 7655MB
[2024-08-01 09:02:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:03 lr 0.000100	 wd 0.0000	time 0.1984 (0.2466)	loss 1.0352 (1.1377)	grad_norm 0.4628 (nan)	loss_scale 32768.0000 (32784.3758)	mem 7655MB
[2024-08-01 09:03:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:38 lr 0.000100	 wd 0.0000	time 0.1809 (0.2444)	loss 1.0049 (1.1309)	grad_norm 0.4400 (nan)	loss_scale 32768.0000 (32783.5964)	mem 7655MB
[2024-08-01 09:03:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:13 lr 0.000100	 wd 0.0000	time 0.1960 (0.2424)	loss 1.0557 (1.1238)	grad_norm 0.4406 (nan)	loss_scale 32768.0000 (32782.8878)	mem 7655MB
[2024-08-01 09:03:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:48 lr 0.000100	 wd 0.0000	time 0.2000 (0.2414)	loss 1.1084 (1.1174)	grad_norm 0.4538 (nan)	loss_scale 32768.0000 (32782.2408)	mem 7655MB
[2024-08-01 09:04:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:24 lr 0.000100	 wd 0.0000	time 0.3040 (0.2415)	loss 1.1562 (1.1119)	grad_norm 0.4248 (nan)	loss_scale 32768.0000 (32781.6476)	mem 7655MB
[2024-08-01 09:04:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000100	 wd 0.0000	time 0.1539 (0.2391)	loss 0.9648 (1.1063)	grad_norm 0.4214 (nan)	loss_scale 32768.0000 (32781.1020)	mem 7655MB
[2024-08-01 09:04:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 0 training takes 0:10:02
[2024-08-01 09:04:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_0.pth saving......
[2024-08-01 09:04:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_0.pth saved !!!
[2024-08-01 09:05:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 65.281 (65.281)	Loss 0.3936 (0.3936)	Acc@1 91.211 (91.211)	Acc@5 98.633 (98.633)	Mem 7655MB
[2024-08-01 09:06:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 83.192 Acc@5 96.852
[2024-08-01 09:06:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.2%
[2024-08-01 09:06:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 83.19%
[2024-08-01 09:06:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saving......
[2024-08-01 09:06:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saved !!!
[2024-08-01 09:06:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][0/2502]	eta 11:16:33 lr 0.000100	 wd 0.0000	time 16.2245 (16.2245)	loss 0.8257 (0.8257)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:06:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:14:37 lr 0.000100	 wd 0.0000	time 0.2179 (0.3653)	loss 0.8862 (0.9611)	grad_norm 0.4267 (0.4251)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:07:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:13:56 lr 0.000100	 wd 0.0000	time 0.2458 (0.3636)	loss 0.8608 (0.9664)	grad_norm 0.4159 (0.4243)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:07:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:41 lr 0.000100	 wd 0.0000	time 0.1888 (0.3185)	loss 1.0107 (0.9665)	grad_norm 0.4239 (0.4233)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:08:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:10:04 lr 0.000100	 wd 0.0000	time 0.2038 (0.2877)	loss 0.9453 (0.9675)	grad_norm 0.4316 (0.4226)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:08:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:08:56 lr 0.000100	 wd 0.0000	time 0.1638 (0.2682)	loss 0.8530 (0.9634)	grad_norm 0.4154 (0.4213)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:08:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:08:26 lr 0.000100	 wd 0.0000	time 0.4024 (0.2663)	loss 0.9912 (0.9638)	grad_norm 0.4169 (0.4201)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:09:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:01 lr 0.000100	 wd 0.0000	time 0.2015 (0.2670)	loss 0.8555 (0.9622)	grad_norm 0.4176 (0.4190)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:09:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:19 lr 0.000100	 wd 0.0000	time 0.1756 (0.2582)	loss 1.0908 (0.9635)	grad_norm 0.4086 (0.4180)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:09:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:06:42 lr 0.000099	 wd 0.0000	time 0.1856 (0.2511)	loss 0.9014 (0.9622)	grad_norm 0.4103 (0.4166)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:10:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:12 lr 0.000099	 wd 0.0000	time 0.3179 (0.2479)	loss 0.9771 (0.9615)	grad_norm 0.4088 (0.4156)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:10:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:05:55 lr 0.000099	 wd 0.0000	time 0.1781 (0.2538)	loss 1.0771 (0.9618)	grad_norm 0.4062 (0.4144)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:11:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:24 lr 0.000099	 wd 0.0000	time 0.1703 (0.2490)	loss 0.9966 (0.9613)	grad_norm 0.4159 (0.4135)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:11:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:04:54 lr 0.000099	 wd 0.0000	time 0.1939 (0.2449)	loss 0.9404 (0.9614)	grad_norm 0.3999 (0.4126)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:11:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:26 lr 0.000099	 wd 0.0000	time 0.1957 (0.2419)	loss 0.9658 (0.9608)	grad_norm 0.4038 (0.4116)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:12:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:02 lr 0.000099	 wd 0.0000	time 0.1811 (0.2420)	loss 0.9668 (0.9612)	grad_norm 0.3917 (0.4106)	loss_scale 65536.0000 (32811.6616)	mem 7655MB
[2024-08-01 09:12:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:36 lr 0.000099	 wd 0.0000	time 0.1904 (0.2399)	loss 0.8594 (0.9604)	grad_norm 0.3706 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7655MB
[2024-08-01 09:12:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:10 lr 0.000099	 wd 0.0000	time 0.1960 (0.2376)	loss 0.8311 (0.9599)	grad_norm 0.3975 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7655MB
[2024-08-01 09:13:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:45 lr 0.000099	 wd 0.0000	time 0.1835 (0.2354)	loss 1.0605 (0.9596)	grad_norm 0.3834 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7655MB
[2024-08-01 09:13:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:21 lr 0.000099	 wd 0.0000	time 0.2089 (0.2345)	loss 0.9912 (0.9593)	grad_norm 0.3902 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7655MB
[2024-08-01 09:14:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:01:57 lr 0.000099	 wd 0.0000	time 0.2141 (0.2349)	loss 0.8423 (0.9589)	grad_norm 0.3892 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7655MB
[2024-08-01 09:14:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:33 lr 0.000099	 wd 0.0000	time 0.1724 (0.2334)	loss 0.8950 (0.9584)	grad_norm 0.4008 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7655MB
[2024-08-01 09:14:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:10 lr 0.000099	 wd 0.0000	time 0.1938 (0.2319)	loss 0.8188 (0.9570)	grad_norm 0.3672 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7655MB
[2024-08-01 09:15:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:46 lr 0.000099	 wd 0.0000	time 0.1696 (0.2307)	loss 0.9956 (0.9573)	grad_norm 0.3877 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7655MB
[2024-08-01 09:15:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:23 lr 0.000099	 wd 0.0000	time 0.1857 (0.2305)	loss 0.9448 (0.9568)	grad_norm 0.3871 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7655MB
[2024-08-01 09:15:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000099	 wd 0.0000	time 0.1556 (0.2288)	loss 0.9600 (0.9568)	grad_norm 0.3891 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7655MB
[2024-08-01 09:15:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 1 training takes 0:09:37
[2024-08-01 09:16:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 26.692 (26.692)	Loss 0.3892 (0.3892)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 09:16:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 83.982 Acc@5 97.170
[2024-08-01 09:16:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-08-01 09:16:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 83.98%
[2024-08-01 09:16:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saving......
[2024-08-01 09:16:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saved !!!
[2024-08-01 09:16:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][0/2502]	eta 20:35:11 lr 0.000099	 wd 0.0000	time 29.6207 (29.6207)	loss 0.8315 (0.8315)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:17:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:20:34 lr 0.000099	 wd 0.0000	time 0.1950 (0.5140)	loss 1.0439 (0.9450)	grad_norm 0.3832 (0.3757)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:17:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:13:34 lr 0.000099	 wd 0.0000	time 0.1863 (0.3540)	loss 1.0498 (0.9413)	grad_norm 0.3837 (0.3768)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:17:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:11:02 lr 0.000099	 wd 0.0000	time 0.1965 (0.3010)	loss 0.8677 (0.9360)	grad_norm 0.3772 (0.3765)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:18:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:09:50 lr 0.000099	 wd 0.0000	time 0.2953 (0.2810)	loss 1.0391 (0.9373)	grad_norm 0.3634 (0.3768)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:18:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:09:50 lr 0.000099	 wd 0.0000	time 0.1648 (0.2950)	loss 0.9653 (0.9429)	grad_norm 0.3870 (0.3764)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:19:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:49 lr 0.000099	 wd 0.0000	time 0.1866 (0.2783)	loss 0.8643 (0.9431)	grad_norm 0.3801 (0.3760)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:19:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:08:00 lr 0.000099	 wd 0.0000	time 0.1651 (0.2665)	loss 0.9517 (0.9427)	grad_norm 0.3732 (0.3755)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:19:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:20 lr 0.000099	 wd 0.0000	time 0.2198 (0.2586)	loss 0.8457 (0.9405)	grad_norm 0.3703 (0.3749)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:20:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:07:07 lr 0.000098	 wd 0.0000	time 0.1750 (0.2670)	loss 0.9741 (0.9402)	grad_norm 0.3837 (0.3746)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:20:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:30 lr 0.000098	 wd 0.0000	time 0.1794 (0.2601)	loss 0.8696 (0.9389)	grad_norm 0.3726 (0.3740)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:21:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:56 lr 0.000098	 wd 0.0000	time 0.1683 (0.2544)	loss 0.9697 (0.9384)	grad_norm 0.3757 (0.3736)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:21:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:25 lr 0.000098	 wd 0.0000	time 0.1989 (0.2497)	loss 1.1035 (0.9384)	grad_norm 0.3767 (0.3731)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:21:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:05:03 lr 0.000098	 wd 0.0000	time 0.1981 (0.2522)	loss 0.9717 (0.9390)	grad_norm 0.3828 (0.3726)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:22:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:33 lr 0.000098	 wd 0.0000	time 0.1868 (0.2481)	loss 1.0186 (0.9390)	grad_norm 0.3554 (0.3719)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:22:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:05 lr 0.000098	 wd 0.0000	time 0.1884 (0.2451)	loss 1.0928 (0.9392)	grad_norm 0.3657 (0.3714)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:22:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:38 lr 0.000098	 wd 0.0000	time 0.1923 (0.2421)	loss 0.9731 (0.9385)	grad_norm 0.3673 (0.3711)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:23:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:12 lr 0.000098	 wd 0.0000	time 0.2123 (0.2405)	loss 0.9297 (0.9389)	grad_norm 0.3646 (0.3706)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:23:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:48 lr 0.000098	 wd 0.0000	time 0.1741 (0.2402)	loss 0.9146 (0.9387)	grad_norm 0.3405 (0.3702)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:24:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:23 lr 0.000098	 wd 0.0000	time 0.1687 (0.2383)	loss 0.8276 (0.9390)	grad_norm 0.3565 (0.3699)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:24:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:01:58 lr 0.000098	 wd 0.0000	time 0.1687 (0.2365)	loss 0.9146 (0.9387)	grad_norm 0.3471 (0.3694)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:24:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:34 lr 0.000098	 wd 0.0000	time 0.2162 (0.2349)	loss 0.9814 (0.9392)	grad_norm 0.3669 (0.3690)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:25:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:11 lr 0.000098	 wd 0.0000	time 0.1703 (0.2351)	loss 0.9028 (0.9387)	grad_norm 0.3567 (0.3685)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:25:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:47 lr 0.000098	 wd 0.0000	time 0.1805 (0.2343)	loss 0.8750 (0.9383)	grad_norm 0.3740 (0.3680)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:25:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:23 lr 0.000098	 wd 0.0000	time 0.1671 (0.2329)	loss 0.8950 (0.9383)	grad_norm 0.3571 (0.3676)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:26:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000098	 wd 0.0000	time 0.1581 (0.2307)	loss 0.9219 (0.9375)	grad_norm 0.3642 (0.3672)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:26:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 2 training takes 0:09:41
[2024-08-01 09:26:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 40.500 (40.500)	Loss 0.3828 (0.3828)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 09:27:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 84.234 Acc@5 97.354
[2024-08-01 09:27:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-08-01 09:27:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 84.23%
[2024-08-01 09:27:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saving......
[2024-08-01 09:27:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saved !!!
[2024-08-01 09:27:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][0/2502]	eta 10:18:50 lr 0.000098	 wd 0.0000	time 14.8402 (14.8402)	loss 0.7676 (0.7676)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:27:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:13:46 lr 0.000098	 wd 0.0000	time 0.1803 (0.3443)	loss 1.0537 (0.9280)	grad_norm 0.3773 (0.3583)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:28:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:10:32 lr 0.000097	 wd 0.0000	time 0.2250 (0.2748)	loss 1.0830 (0.9241)	grad_norm 0.3681 (0.3568)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:28:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:11:15 lr 0.000097	 wd 0.0000	time 0.2009 (0.3066)	loss 1.0781 (0.9255)	grad_norm 0.3498 (0.3563)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:28:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:09:46 lr 0.000097	 wd 0.0000	time 0.1821 (0.2791)	loss 1.0283 (0.9255)	grad_norm 0.3378 (0.3551)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:29:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:08:44 lr 0.000097	 wd 0.0000	time 0.1894 (0.2620)	loss 0.9639 (0.9266)	grad_norm nan (nan)	loss_scale 32768.0000 (32898.8104)	mem 7655MB
[2024-08-01 09:29:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:08:01 lr 0.000097	 wd 0.0000	time 0.1886 (0.2529)	loss 0.8716 (0.9271)	grad_norm 0.3788 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7655MB
[2024-08-01 09:30:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:08:01 lr 0.000097	 wd 0.0000	time 0.1710 (0.2674)	loss 0.9775 (0.9280)	grad_norm 0.3541 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7655MB
[2024-08-01 09:30:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:20 lr 0.000097	 wd 0.0000	time 0.1979 (0.2585)	loss 0.9141 (0.9267)	grad_norm 0.3673 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7655MB
[2024-08-01 09:30:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:06:43 lr 0.000097	 wd 0.0000	time 0.1957 (0.2517)	loss 0.9731 (0.9269)	grad_norm 0.3490 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7655MB
[2024-08-01 09:31:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:10 lr 0.000097	 wd 0.0000	time 0.2488 (0.2468)	loss 1.0879 (0.9286)	grad_norm 0.3755 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7655MB
[2024-08-01 09:31:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:05:52 lr 0.000097	 wd 0.0000	time 0.1980 (0.2511)	loss 0.8330 (0.9276)	grad_norm 0.3660 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7655MB
[2024-08-01 09:32:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:21 lr 0.000097	 wd 0.0000	time 0.1840 (0.2466)	loss 0.9932 (0.9268)	grad_norm 0.3414 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7655MB
[2024-08-01 09:32:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:04:51 lr 0.000097	 wd 0.0000	time 0.1692 (0.2429)	loss 1.0352 (0.9277)	grad_norm 0.3296 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7655MB
[2024-08-01 09:32:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:24 lr 0.000097	 wd 0.0000	time 0.2159 (0.2397)	loss 0.8984 (0.9274)	grad_norm 0.3334 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7655MB
[2024-08-01 09:33:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:03:58 lr 0.000097	 wd 0.0000	time 0.2182 (0.2382)	loss 0.8433 (0.9283)	grad_norm 0.3297 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7655MB
[2024-08-01 09:33:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:34 lr 0.000096	 wd 0.0000	time 0.2030 (0.2373)	loss 0.8882 (0.9274)	grad_norm 0.3565 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7655MB
[2024-08-01 09:33:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:08 lr 0.000096	 wd 0.0000	time 0.1865 (0.2351)	loss 0.9541 (0.9272)	grad_norm 0.3440 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7655MB
[2024-08-01 09:34:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:43 lr 0.000096	 wd 0.0000	time 0.1849 (0.2331)	loss 0.9404 (0.9271)	grad_norm 0.3306 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7655MB
[2024-08-01 09:34:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:19 lr 0.000096	 wd 0.0000	time 0.1845 (0.2315)	loss 0.9463 (0.9265)	grad_norm 0.3465 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7655MB
[2024-08-01 09:34:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:01:56 lr 0.000096	 wd 0.0000	time 0.2671 (0.2315)	loss 0.8853 (0.9269)	grad_norm 0.3431 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7655MB
[2024-08-01 09:35:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:32 lr 0.000096	 wd 0.0000	time 0.2082 (0.2307)	loss 0.7368 (0.9262)	grad_norm 0.3523 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7655MB
[2024-08-01 09:35:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:09 lr 0.000096	 wd 0.0000	time 0.1832 (0.2294)	loss 0.8472 (0.9257)	grad_norm 0.3458 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7655MB
[2024-08-01 09:35:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:46 lr 0.000096	 wd 0.0000	time 0.2035 (0.2279)	loss 1.0039 (0.9259)	grad_norm 0.3404 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7655MB
[2024-08-01 09:36:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:23 lr 0.000096	 wd 0.0000	time 0.2153 (0.2273)	loss 0.8491 (0.9257)	grad_norm 0.3351 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7655MB
[2024-08-01 09:36:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000096	 wd 0.0000	time 0.1552 (0.2261)	loss 0.8359 (0.9261)	grad_norm 0.3548 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7655MB
[2024-08-01 09:36:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 3 training takes 0:09:32
[2024-08-01 09:36:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 21.929 (21.929)	Loss 0.3862 (0.3862)	Acc@1 91.016 (91.016)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 09:37:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 84.468 Acc@5 97.384
[2024-08-01 09:37:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.5%
[2024-08-01 09:37:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 84.47%
[2024-08-01 09:37:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saving......
[2024-08-01 09:37:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saved !!!
[2024-08-01 09:37:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][0/2502]	eta 10:56:10 lr 0.000096	 wd 0.0000	time 15.7355 (15.7355)	loss 0.9336 (0.9336)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:37:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:18:30 lr 0.000096	 wd 0.0000	time 0.1979 (0.4624)	loss 0.8115 (0.9260)	grad_norm 0.3434 (0.3424)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:38:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:12:51 lr 0.000096	 wd 0.0000	time 0.1858 (0.3350)	loss 0.9287 (0.9246)	grad_norm 0.3206 (0.3421)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:38:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:10:32 lr 0.000095	 wd 0.0000	time 0.1983 (0.2873)	loss 0.9126 (0.9241)	grad_norm 0.3498 (0.3423)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:38:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:09:15 lr 0.000095	 wd 0.0000	time 0.1715 (0.2641)	loss 0.8882 (0.9192)	grad_norm 0.3286 (0.3424)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:39:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:08:31 lr 0.000095	 wd 0.0000	time 0.3462 (0.2557)	loss 0.9639 (0.9209)	grad_norm 0.3331 (0.3423)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:39:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:08:35 lr 0.000095	 wd 0.0000	time 0.1866 (0.2711)	loss 0.8745 (0.9232)	grad_norm 0.3585 (0.3423)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:40:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:07:49 lr 0.000095	 wd 0.0000	time 0.1776 (0.2604)	loss 1.0371 (0.9196)	grad_norm 0.3321 (0.3418)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:40:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:09 lr 0.000095	 wd 0.0000	time 0.1965 (0.2525)	loss 0.8789 (0.9198)	grad_norm 0.3556 (0.3416)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:40:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:06:36 lr 0.000095	 wd 0.0000	time 0.2172 (0.2478)	loss 0.8818 (0.9210)	grad_norm 0.3457 (0.3414)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:41:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:19 lr 0.000095	 wd 0.0000	time 0.1795 (0.2526)	loss 0.9253 (0.9207)	grad_norm 0.3433 (0.3414)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:41:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:05:46 lr 0.000095	 wd 0.0000	time 0.1851 (0.2474)	loss 1.0117 (0.9221)	grad_norm 0.3494 (0.3415)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:42:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:16 lr 0.000095	 wd 0.0000	time 0.2080 (0.2431)	loss 0.7666 (0.9219)	grad_norm 0.3293 (0.3412)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:42:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:04:48 lr 0.000095	 wd 0.0000	time 0.2286 (0.2398)	loss 0.8823 (0.9211)	grad_norm 0.3359 (0.3409)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:42:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:32 lr 0.000094	 wd 0.0000	time 0.1762 (0.2468)	loss 0.8901 (0.9205)	grad_norm 0.3377 (0.3409)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:43:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:04 lr 0.000094	 wd 0.0000	time 0.2034 (0.2435)	loss 0.7832 (0.9205)	grad_norm 0.3361 (0.3408)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:43:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:37 lr 0.000094	 wd 0.0000	time 0.2208 (0.2406)	loss 0.8579 (0.9202)	grad_norm 0.3315 (0.3406)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:43:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:10 lr 0.000094	 wd 0.0000	time 0.1934 (0.2380)	loss 1.1094 (0.9198)	grad_norm 0.3404 (0.3404)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:44:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:46 lr 0.000094	 wd 0.0000	time 0.1881 (0.2368)	loss 0.9458 (0.9202)	grad_norm 0.3332 (0.3402)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:44:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:22 lr 0.000094	 wd 0.0000	time 0.2465 (0.2370)	loss 0.9419 (0.9201)	grad_norm 0.3290 (0.3400)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:45:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:01:58 lr 0.000094	 wd 0.0000	time 0.2144 (0.2353)	loss 0.7812 (0.9196)	grad_norm nan (nan)	loss_scale 32768.0000 (32800.7516)	mem 7655MB
[2024-08-01 09:45:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:33 lr 0.000094	 wd 0.0000	time 0.1985 (0.2335)	loss 0.8384 (0.9204)	grad_norm 0.3516 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7655MB
[2024-08-01 09:45:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:10 lr 0.000094	 wd 0.0000	time 0.2383 (0.2324)	loss 1.0029 (0.9198)	grad_norm 0.3040 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7655MB
[2024-08-01 09:46:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:47 lr 0.000094	 wd 0.0000	time 0.1799 (0.2328)	loss 0.8838 (0.9200)	grad_norm 0.3332 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7655MB
[2024-08-01 09:46:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:23 lr 0.000093	 wd 0.0000	time 0.2019 (0.2318)	loss 0.8589 (0.9201)	grad_norm 0.3112 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7655MB
[2024-08-01 09:46:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000093	 wd 0.0000	time 0.1568 (0.2297)	loss 0.7817 (0.9200)	grad_norm 0.3345 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7655MB
[2024-08-01 09:46:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 4 training takes 0:09:38
[2024-08-01 09:47:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 28.874 (28.874)	Loss 0.3723 (0.3723)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 09:47:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 84.710 Acc@5 97.426
[2024-08-01 09:47:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-08-01 09:47:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 84.71%
[2024-08-01 09:47:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saving......
[2024-08-01 09:47:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saved !!!
[2024-08-01 09:48:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][0/2502]	eta 12:29:47 lr 0.000093	 wd 0.0000	time 17.9806 (17.9806)	loss 0.9067 (0.9067)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:48:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:15:07 lr 0.000093	 wd 0.0000	time 0.1767 (0.3779)	loss 0.9595 (0.9092)	grad_norm 0.3446 (0.3347)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:48:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:10:59 lr 0.000093	 wd 0.0000	time 0.1720 (0.2863)	loss 0.8496 (0.9118)	grad_norm 0.3434 (0.3359)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:49:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:21 lr 0.000093	 wd 0.0000	time 0.3713 (0.2821)	loss 1.0645 (0.9105)	grad_norm 0.3295 (0.3350)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:49:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:10:05 lr 0.000093	 wd 0.0000	time 0.2313 (0.2880)	loss 0.9897 (0.9097)	grad_norm 0.3394 (0.3352)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:50:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:08:59 lr 0.000093	 wd 0.0000	time 0.1869 (0.2696)	loss 0.8862 (0.9100)	grad_norm 0.3491 (0.3350)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:50:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:07 lr 0.000093	 wd 0.0000	time 0.1827 (0.2565)	loss 0.9019 (0.9129)	grad_norm 0.3373 (0.3347)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:50:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:31 lr 0.000093	 wd 0.0000	time 0.2563 (0.2508)	loss 0.8125 (0.9121)	grad_norm 0.3498 (0.3346)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:51:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:07 lr 0.000093	 wd 0.0000	time 0.1781 (0.2510)	loss 0.8647 (0.9119)	grad_norm 0.3417 (0.3347)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:51:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:32 lr 0.000092	 wd 0.0000	time 0.1832 (0.2450)	loss 0.9385 (0.9123)	grad_norm 0.3302 (0.3346)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:51:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:01 lr 0.000092	 wd 0.0000	time 0.1881 (0.2405)	loss 0.9478 (0.9139)	grad_norm 0.3275 (0.3345)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:52:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:32 lr 0.000092	 wd 0.0000	time 0.1872 (0.2369)	loss 0.8604 (0.9151)	grad_norm 0.3324 (0.3345)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:52:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:16 lr 0.000092	 wd 0.0000	time 0.1817 (0.2431)	loss 0.9243 (0.9157)	grad_norm 0.3251 (0.3346)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:52:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:47 lr 0.000092	 wd 0.0000	time 0.2064 (0.2393)	loss 1.0146 (0.9151)	grad_norm 0.3423 (0.3343)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:53:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:20 lr 0.000092	 wd 0.0000	time 0.1872 (0.2363)	loss 0.8926 (0.9142)	grad_norm 0.3416 (0.3342)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:53:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:03:54 lr 0.000092	 wd 0.0000	time 0.1871 (0.2337)	loss 0.8813 (0.9148)	grad_norm 0.3273 (0.3341)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:53:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:29 lr 0.000092	 wd 0.0000	time 0.1943 (0.2326)	loss 0.8154 (0.9152)	grad_norm 0.3437 (0.3340)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:54:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:06 lr 0.000092	 wd 0.0000	time 0.1805 (0.2325)	loss 0.8940 (0.9156)	grad_norm 0.3222 (0.3340)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:54:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:42 lr 0.000091	 wd 0.0000	time 0.2214 (0.2308)	loss 0.9219 (0.9149)	grad_norm 0.3301 (0.3340)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:55:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:17 lr 0.000091	 wd 0.0000	time 0.1950 (0.2292)	loss 0.8809 (0.9146)	grad_norm 0.3276 (0.3340)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:55:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:01:54 lr 0.000091	 wd 0.0000	time 0.2599 (0.2280)	loss 1.0010 (0.9152)	grad_norm 0.3358 (0.3340)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:55:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:31 lr 0.000091	 wd 0.0000	time 0.1723 (0.2283)	loss 0.9966 (0.9146)	grad_norm 0.3470 (0.3339)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:56:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:08 lr 0.000091	 wd 0.0000	time 0.1895 (0.2279)	loss 1.0186 (0.9146)	grad_norm 0.3368 (0.3337)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:56:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:45 lr 0.000091	 wd 0.0000	time 0.1869 (0.2268)	loss 0.7876 (0.9144)	grad_norm 0.3543 (0.3337)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:56:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:23 lr 0.000091	 wd 0.0000	time 0.1806 (0.2255)	loss 0.8223 (0.9139)	grad_norm 0.3408 (0.3336)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:57:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000091	 wd 0.0000	time 0.1556 (0.2238)	loss 0.8071 (0.9133)	grad_norm 0.3299 (0.3335)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:57:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 5 training takes 0:09:24
[2024-08-01 09:57:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 39.341 (39.341)	Loss 0.3711 (0.3711)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 09:58:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 84.808 Acc@5 97.508
[2024-08-01 09:58:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-08-01 09:58:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 84.81%
[2024-08-01 09:58:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saving......
[2024-08-01 09:58:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saved !!!
[2024-08-01 09:58:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][0/2502]	eta 11:05:08 lr 0.000091	 wd 0.0000	time 15.9506 (15.9506)	loss 0.9551 (0.9551)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:58:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:14:37 lr 0.000090	 wd 0.0000	time 0.3281 (0.3655)	loss 0.8721 (0.9201)	grad_norm 0.3461 (0.3302)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:59:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:13:16 lr 0.000090	 wd 0.0000	time 0.1957 (0.3460)	loss 0.8193 (0.9124)	grad_norm 0.3297 (0.3305)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:59:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:10:50 lr 0.000090	 wd 0.0000	time 0.1795 (0.2955)	loss 0.9497 (0.9139)	grad_norm 0.3275 (0.3305)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 09:59:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:09:27 lr 0.000090	 wd 0.0000	time 0.1779 (0.2700)	loss 0.9019 (0.9127)	grad_norm 0.3198 (0.3310)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:00:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:08:31 lr 0.000090	 wd 0.0000	time 0.2118 (0.2555)	loss 0.9648 (0.9128)	grad_norm 0.3210 (0.3310)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:00:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:08:28 lr 0.000090	 wd 0.0000	time 0.1920 (0.2672)	loss 0.8926 (0.9124)	grad_norm 0.3420 (0.3312)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:01:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:07:42 lr 0.000090	 wd 0.0000	time 0.1735 (0.2568)	loss 1.0039 (0.9124)	grad_norm 0.3347 (0.3313)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:01:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:04 lr 0.000090	 wd 0.0000	time 0.1930 (0.2494)	loss 0.7451 (0.9124)	grad_norm 0.3301 (0.3310)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:01:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:06:29 lr 0.000089	 wd 0.0000	time 0.1932 (0.2429)	loss 0.8955 (0.9120)	grad_norm 0.3149 (0.3308)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:02:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:01 lr 0.000089	 wd 0.0000	time 0.2267 (0.2407)	loss 0.8711 (0.9129)	grad_norm 0.3266 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7655MB
[2024-08-01 10:02:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:35 lr 0.000089	 wd 0.0000	time 0.1862 (0.2395)	loss 0.8281 (0.9114)	grad_norm 0.3276 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7655MB
[2024-08-01 10:02:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:07 lr 0.000089	 wd 0.0000	time 0.1777 (0.2361)	loss 0.8657 (0.9114)	grad_norm 0.3300 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7655MB
[2024-08-01 10:03:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:04:40 lr 0.000089	 wd 0.0000	time 0.1526 (0.2333)	loss 0.7812 (0.9108)	grad_norm 0.3243 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7655MB
[2024-08-01 10:03:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:14 lr 0.000089	 wd 0.0000	time 0.1920 (0.2311)	loss 0.9331 (0.9103)	grad_norm 0.3274 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7655MB
[2024-08-01 10:03:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:03:51 lr 0.000089	 wd 0.0000	time 0.1777 (0.2308)	loss 0.8140 (0.9103)	grad_norm 0.3293 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7655MB
[2024-08-01 10:04:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:26 lr 0.000089	 wd 0.0000	time 0.1949 (0.2294)	loss 0.8174 (0.9097)	grad_norm 0.3172 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7655MB
[2024-08-01 10:04:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:02 lr 0.000088	 wd 0.0000	time 0.2032 (0.2276)	loss 0.8794 (0.9083)	grad_norm 0.3134 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7655MB
[2024-08-01 10:04:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:38 lr 0.000088	 wd 0.0000	time 0.1989 (0.2259)	loss 0.8496 (0.9082)	grad_norm 0.3239 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7655MB
[2024-08-01 10:05:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:15 lr 0.000088	 wd 0.0000	time 0.1971 (0.2251)	loss 0.9038 (0.9086)	grad_norm 0.3263 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7655MB
[2024-08-01 10:05:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:01:53 lr 0.000088	 wd 0.0000	time 0.1844 (0.2259)	loss 0.9546 (0.9092)	grad_norm 0.3330 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7655MB
[2024-08-01 10:05:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:30 lr 0.000088	 wd 0.0000	time 0.1866 (0.2250)	loss 0.8184 (0.9091)	grad_norm 0.3279 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7655MB
[2024-08-01 10:06:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:07 lr 0.000088	 wd 0.0000	time 0.1787 (0.2238)	loss 0.9224 (0.9084)	grad_norm 0.3280 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7655MB
[2024-08-01 10:06:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:45 lr 0.000088	 wd 0.0000	time 0.1772 (0.2228)	loss 0.8462 (0.9082)	grad_norm 0.3283 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7655MB
[2024-08-01 10:06:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:22 lr 0.000087	 wd 0.0000	time 1.7354 (0.2232)	loss 0.9189 (0.9088)	grad_norm 0.3159 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7655MB
[2024-08-01 10:07:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000087	 wd 0.0000	time 0.1584 (0.2216)	loss 0.8237 (0.9094)	grad_norm 0.3339 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7655MB
[2024-08-01 10:07:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 6 training takes 0:09:19
[2024-08-01 10:07:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 18.371 (18.371)	Loss 0.3704 (0.3704)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 10:07:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 84.822 Acc@5 97.482
[2024-08-01 10:07:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-08-01 10:07:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 84.82%
[2024-08-01 10:07:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saving......
[2024-08-01 10:07:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saved !!!
[2024-08-01 10:08:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][0/2502]	eta 12:58:14 lr 0.000087	 wd 0.0000	time 18.6630 (18.6630)	loss 0.9155 (0.9155)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:08:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:18:48 lr 0.000087	 wd 0.0000	time 0.1749 (0.4699)	loss 0.9775 (0.9073)	grad_norm 0.3192 (0.3278)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:09:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:12:47 lr 0.000087	 wd 0.0000	time 0.1974 (0.3332)	loss 0.9033 (0.9043)	grad_norm 0.3196 (0.3292)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:09:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:10:31 lr 0.000087	 wd 0.0000	time 0.1881 (0.2868)	loss 0.8677 (0.9015)	grad_norm 0.3311 (0.3288)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:09:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:09:13 lr 0.000087	 wd 0.0000	time 0.1830 (0.2634)	loss 0.8979 (0.9065)	grad_norm 0.3507 (0.3293)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:10:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:08:26 lr 0.000087	 wd 0.0000	time 0.2144 (0.2528)	loss 0.7896 (0.9042)	grad_norm 0.3071 (0.3290)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:10:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:08 lr 0.000086	 wd 0.0000	time 0.1571 (0.2566)	loss 1.0371 (0.9064)	grad_norm 0.3133 (0.3289)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:10:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:07:26 lr 0.000086	 wd 0.0000	time 0.2073 (0.2479)	loss 0.8159 (0.9058)	grad_norm 0.3059 (0.3288)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:11:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:06:51 lr 0.000086	 wd 0.0000	time 0.1717 (0.2418)	loss 0.8433 (0.9045)	grad_norm 0.3160 (0.3289)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:11:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:06:19 lr 0.000086	 wd 0.0000	time 0.1931 (0.2372)	loss 0.8770 (0.9055)	grad_norm 0.3258 (0.3289)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:12:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:13 lr 0.000086	 wd 0.0000	time 0.2500 (0.2489)	loss 0.7827 (0.9054)	grad_norm 0.3396 (0.3287)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:12:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:42 lr 0.000086	 wd 0.0000	time 0.1552 (0.2441)	loss 0.8013 (0.9047)	grad_norm 0.3286 (0.3286)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:12:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:12 lr 0.000086	 wd 0.0000	time 0.2143 (0.2402)	loss 0.9375 (0.9040)	grad_norm 0.3299 (0.3285)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:13:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:04:44 lr 0.000085	 wd 0.0000	time 0.2002 (0.2366)	loss 0.9517 (0.9035)	grad_norm 0.3161 (0.3285)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:13:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:19 lr 0.000085	 wd 0.0000	time 0.2453 (0.2354)	loss 0.7905 (0.9039)	grad_norm 0.3303 (0.3286)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:13:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:03:55 lr 0.000085	 wd 0.0000	time 0.1949 (0.2347)	loss 0.8604 (0.9036)	grad_norm 0.3319 (0.3285)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:14:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:29 lr 0.000085	 wd 0.0000	time 0.1972 (0.2324)	loss 0.9146 (0.9033)	grad_norm 0.3304 (0.3284)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:14:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:04 lr 0.000085	 wd 0.0000	time 0.1714 (0.2305)	loss 1.0254 (0.9029)	grad_norm 0.3111 (0.3283)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:14:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:40 lr 0.000085	 wd 0.0000	time 0.2059 (0.2291)	loss 0.8687 (0.9030)	grad_norm 0.3263 (0.3282)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:15:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:18 lr 0.000085	 wd 0.0000	time 0.2008 (0.2299)	loss 0.9429 (0.9030)	grad_norm 0.3229 (0.3282)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:15:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:01:54 lr 0.000084	 wd 0.0000	time 0.1727 (0.2290)	loss 0.8550 (0.9024)	grad_norm 0.3346 (0.3281)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:15:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:31 lr 0.000084	 wd 0.0000	time 0.2109 (0.2276)	loss 1.0518 (0.9035)	grad_norm 0.3363 (0.3282)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:16:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:08 lr 0.000084	 wd 0.0000	time 0.2213 (0.2261)	loss 0.7192 (0.9027)	grad_norm 0.3490 (0.3282)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:16:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:45 lr 0.000084	 wd 0.0000	time 0.2345 (0.2256)	loss 0.9883 (0.9027)	grad_norm 0.3273 (0.3282)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:16:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:23 lr 0.000084	 wd 0.0000	time 0.1883 (0.2259)	loss 0.9849 (0.9030)	grad_norm 0.3329 (0.3282)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:17:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000084	 wd 0.0000	time 0.1556 (0.2240)	loss 0.9033 (0.9034)	grad_norm 0.3436 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7655MB
[2024-08-01 10:17:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 7 training takes 0:09:24
[2024-08-01 10:17:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 19.132 (19.132)	Loss 0.3638 (0.3638)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 10:17:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 84.788 Acc@5 97.520
[2024-08-01 10:17:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-08-01 10:17:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 84.82%
[2024-08-01 10:18:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][0/2502]	eta 22:30:20 lr 0.000084	 wd 0.0000	time 32.3821 (32.3821)	loss 0.8291 (0.8291)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:18:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:20:58 lr 0.000083	 wd 0.0000	time 0.1902 (0.5241)	loss 0.8604 (0.9068)	grad_norm 0.3181 (0.3297)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:19:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:13:45 lr 0.000083	 wd 0.0000	time 0.1901 (0.3588)	loss 0.8813 (0.9054)	grad_norm 0.3212 (0.3286)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:19:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:11:07 lr 0.000083	 wd 0.0000	time 0.1750 (0.3030)	loss 0.8701 (0.9013)	grad_norm 0.3423 (0.3276)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:19:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:09:59 lr 0.000083	 wd 0.0000	time 0.2931 (0.2854)	loss 1.0381 (0.9026)	grad_norm 0.3253 (0.3273)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:20:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:09:27 lr 0.000083	 wd 0.0000	time 0.1956 (0.2836)	loss 0.8354 (0.9037)	grad_norm 0.3269 (0.3272)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:20:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:30 lr 0.000083	 wd 0.0000	time 0.1720 (0.2685)	loss 0.8770 (0.9035)	grad_norm 0.3382 (0.3269)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:20:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:44 lr 0.000083	 wd 0.0000	time 0.1805 (0.2576)	loss 0.8896 (0.9028)	grad_norm 0.3388 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:21:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:07 lr 0.000082	 wd 0.0000	time 0.2022 (0.2509)	loss 0.7754 (0.9025)	grad_norm 0.3308 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:21:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:51 lr 0.000082	 wd 0.0000	time 0.1840 (0.2566)	loss 1.0518 (0.9037)	grad_norm 0.3235 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:22:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:16 lr 0.000082	 wd 0.0000	time 0.1749 (0.2504)	loss 1.0664 (0.9041)	grad_norm 0.3227 (0.3269)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:22:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:44 lr 0.000082	 wd 0.0000	time 0.2124 (0.2454)	loss 0.9858 (0.9038)	grad_norm 0.3356 (0.3269)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:22:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:14 lr 0.000082	 wd 0.0000	time 0.2026 (0.2413)	loss 0.8384 (0.9034)	grad_norm 0.3210 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:23:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:59 lr 0.000082	 wd 0.0000	time 0.1894 (0.2496)	loss 0.8398 (0.9035)	grad_norm 0.3275 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:23:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:31 lr 0.000081	 wd 0.0000	time 0.1751 (0.2463)	loss 0.8428 (0.9032)	grad_norm 0.3204 (0.3269)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:23:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:04:03 lr 0.000081	 wd 0.0000	time 0.1874 (0.2429)	loss 0.8730 (0.9029)	grad_norm 0.3402 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:24:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:36 lr 0.000081	 wd 0.0000	time 0.1941 (0.2399)	loss 1.0059 (0.9023)	grad_norm 0.3182 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:24:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:11 lr 0.000081	 wd 0.0000	time 0.1912 (0.2384)	loss 0.8652 (0.9030)	grad_norm 0.3125 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:24:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:47 lr 0.000081	 wd 0.0000	time 0.1795 (0.2380)	loss 0.9053 (0.9032)	grad_norm 0.3363 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:25:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:22 lr 0.000081	 wd 0.0000	time 0.1733 (0.2361)	loss 0.7993 (0.9027)	grad_norm 0.3089 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:25:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:57 lr 0.000080	 wd 0.0000	time 0.1762 (0.2343)	loss 0.8462 (0.9029)	grad_norm 0.3519 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:25:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:33 lr 0.000080	 wd 0.0000	time 0.2076 (0.2327)	loss 0.9116 (0.9031)	grad_norm 0.3287 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:26:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:10 lr 0.000080	 wd 0.0000	time 0.1885 (0.2325)	loss 0.8589 (0.9026)	grad_norm 0.3288 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:26:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:46 lr 0.000080	 wd 0.0000	time 0.2172 (0.2315)	loss 0.9805 (0.9024)	grad_norm 0.3189 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:27:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:23 lr 0.000080	 wd 0.0000	time 0.2228 (0.2302)	loss 0.9614 (0.9023)	grad_norm 0.3348 (0.3271)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:27:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000080	 wd 0.0000	time 0.1533 (0.2280)	loss 0.9482 (0.9023)	grad_norm 0.3266 (0.3271)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:27:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 8 training takes 0:09:34
[2024-08-01 10:28:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 37.364 (37.364)	Loss 0.3677 (0.3677)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 10:28:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 84.948 Acc@5 97.546
[2024-08-01 10:28:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-08-01 10:28:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 84.95%
[2024-08-01 10:28:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saving......
[2024-08-01 10:28:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saved !!!
[2024-08-01 10:28:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][0/2502]	eta 10:45:34 lr 0.000080	 wd 0.0000	time 15.4816 (15.4816)	loss 0.8921 (0.8921)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:28:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:13:58 lr 0.000079	 wd 0.0000	time 0.1840 (0.3491)	loss 0.9863 (0.8969)	grad_norm 0.3328 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:29:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:10:31 lr 0.000079	 wd 0.0000	time 0.2124 (0.2742)	loss 0.7725 (0.8945)	grad_norm 0.3188 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:29:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:22 lr 0.000079	 wd 0.0000	time 0.1947 (0.2826)	loss 0.9697 (0.8968)	grad_norm 0.3087 (0.3274)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:30:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:07 lr 0.000079	 wd 0.0000	time 0.1645 (0.2606)	loss 0.9038 (0.8961)	grad_norm 0.3127 (0.3272)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:30:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:08:15 lr 0.000079	 wd 0.0000	time 0.1833 (0.2476)	loss 0.6885 (0.9007)	grad_norm 0.3302 (0.3274)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:30:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:07:34 lr 0.000079	 wd 0.0000	time 0.1813 (0.2388)	loss 0.7339 (0.8983)	grad_norm 0.3384 (0.3269)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:31:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:17 lr 0.000078	 wd 0.0000	time 0.4634 (0.2429)	loss 0.9556 (0.8991)	grad_norm 0.3304 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:31:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:00 lr 0.000078	 wd 0.0000	time 0.1813 (0.2474)	loss 0.9199 (0.9002)	grad_norm 0.3053 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:31:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:27 lr 0.000078	 wd 0.0000	time 0.1942 (0.2417)	loss 1.0498 (0.9008)	grad_norm 0.3264 (0.3267)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:32:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:05:55 lr 0.000078	 wd 0.0000	time 0.1717 (0.2368)	loss 0.9771 (0.9011)	grad_norm 0.3316 (0.3266)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:32:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:30 lr 0.000078	 wd 0.0000	time 0.2714 (0.2357)	loss 0.8315 (0.9010)	grad_norm 0.3419 (0.3265)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:33:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:16 lr 0.000078	 wd 0.0000	time 0.1678 (0.2433)	loss 0.9771 (0.9007)	grad_norm 0.3312 (0.3264)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:33:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:47 lr 0.000077	 wd 0.0000	time 0.2119 (0.2396)	loss 0.9468 (0.9009)	grad_norm 0.3164 (0.3263)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:33:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:20 lr 0.000077	 wd 0.0000	time 0.2068 (0.2361)	loss 0.9307 (0.9012)	grad_norm 0.3119 (0.3263)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:34:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:03:54 lr 0.000077	 wd 0.0000	time 0.2135 (0.2340)	loss 0.9819 (0.9014)	grad_norm 0.3386 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7655MB
[2024-08-01 10:34:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:31 lr 0.000077	 wd 0.0000	time 0.1954 (0.2340)	loss 0.9097 (0.9010)	grad_norm 0.3153 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7655MB
[2024-08-01 10:34:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:06 lr 0.000077	 wd 0.0000	time 0.2214 (0.2321)	loss 0.8481 (0.9017)	grad_norm 0.3094 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7655MB
[2024-08-01 10:35:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:41 lr 0.000077	 wd 0.0000	time 0.2008 (0.2304)	loss 0.7461 (0.9013)	grad_norm 0.3337 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7655MB
[2024-08-01 10:35:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:17 lr 0.000076	 wd 0.0000	time 0.2039 (0.2286)	loss 0.9414 (0.9013)	grad_norm 0.3214 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7655MB
[2024-08-01 10:35:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:01:54 lr 0.000076	 wd 0.0000	time 0.1886 (0.2283)	loss 0.9204 (0.9021)	grad_norm 0.3187 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7655MB
[2024-08-01 10:36:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:32 lr 0.000076	 wd 0.0000	time 0.1959 (0.2289)	loss 1.0537 (0.9025)	grad_norm 0.3163 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7655MB
[2024-08-01 10:36:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:08 lr 0.000076	 wd 0.0000	time 0.2188 (0.2277)	loss 0.9155 (0.9028)	grad_norm 0.3240 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7655MB
[2024-08-01 10:36:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:45 lr 0.000076	 wd 0.0000	time 0.2080 (0.2264)	loss 0.8862 (0.9023)	grad_norm 0.3492 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7655MB
[2024-08-01 10:37:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:22 lr 0.000075	 wd 0.0000	time 0.2044 (0.2255)	loss 0.8379 (0.9023)	grad_norm 0.3313 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7655MB
[2024-08-01 10:37:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000075	 wd 0.0000	time 0.1594 (0.2238)	loss 0.8667 (0.9023)	grad_norm 0.3134 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7655MB
[2024-08-01 10:37:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 9 training takes 0:09:29
[2024-08-01 10:38:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 24.052 (24.052)	Loss 0.3640 (0.3640)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 10:38:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 84.900 Acc@5 97.538
[2024-08-01 10:38:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-08-01 10:38:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 84.95%
[2024-08-01 10:38:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][0/2502]	eta 11:03:20 lr 0.000075	 wd 0.0000	time 15.9076 (15.9076)	loss 1.0596 (1.0596)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:39:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:14:55 lr 0.000075	 wd 0.0000	time 0.2247 (0.3727)	loss 0.7417 (0.9136)	grad_norm 0.3293 (0.3271)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:39:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:12:20 lr 0.000075	 wd 0.0000	time 0.1918 (0.3217)	loss 0.9805 (0.9057)	grad_norm 0.3381 (0.3267)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:39:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:15 lr 0.000075	 wd 0.0000	time 0.1970 (0.2793)	loss 0.8848 (0.9015)	grad_norm 0.3134 (0.3265)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:40:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:02 lr 0.000075	 wd 0.0000	time 0.1765 (0.2581)	loss 0.9214 (0.8994)	grad_norm 0.3353 (0.3266)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:40:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:08:10 lr 0.000074	 wd 0.0000	time 0.1890 (0.2451)	loss 0.7803 (0.9005)	grad_norm 0.3389 (0.3269)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:40:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:01 lr 0.000074	 wd 0.0000	time 0.1952 (0.2534)	loss 0.9512 (0.8994)	grad_norm 0.3217 (0.3266)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:41:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:24 lr 0.000074	 wd 0.0000	time 0.1952 (0.2464)	loss 0.8271 (0.8981)	grad_norm 0.3155 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:41:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:06:48 lr 0.000074	 wd 0.0000	time 0.1742 (0.2401)	loss 0.8838 (0.8985)	grad_norm 0.3246 (0.3272)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:41:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:16 lr 0.000074	 wd 0.0000	time 0.1728 (0.2352)	loss 0.8662 (0.8990)	grad_norm 0.3232 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:42:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:05:52 lr 0.000073	 wd 0.0000	time 0.2978 (0.2346)	loss 0.8403 (0.8991)	grad_norm 0.3238 (0.3271)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:42:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:36 lr 0.000073	 wd 0.0000	time 0.1964 (0.2397)	loss 0.8052 (0.8991)	grad_norm 0.3195 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:43:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:07 lr 0.000073	 wd 0.0000	time 0.1629 (0.2358)	loss 1.0186 (0.8989)	grad_norm 0.3210 (0.3271)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:43:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:39 lr 0.000073	 wd 0.0000	time 0.1809 (0.2327)	loss 0.8809 (0.8988)	grad_norm 0.3302 (0.3272)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:43:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:14 lr 0.000073	 wd 0.0000	time 0.2181 (0.2306)	loss 0.8042 (0.8987)	grad_norm 0.3493 (0.3271)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:44:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:03:50 lr 0.000073	 wd 0.0000	time 0.1709 (0.2304)	loss 0.8618 (0.8984)	grad_norm 0.3318 (0.3269)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:44:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:26 lr 0.000072	 wd 0.0000	time 0.1785 (0.2288)	loss 0.7817 (0.8986)	grad_norm 0.3130 (0.3269)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:44:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:02 lr 0.000072	 wd 0.0000	time 0.1857 (0.2271)	loss 0.8770 (0.8989)	grad_norm 0.3168 (0.3269)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:45:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:38 lr 0.000072	 wd 0.0000	time 0.1542 (0.2254)	loss 0.9712 (0.8988)	grad_norm 0.3387 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:45:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:15 lr 0.000072	 wd 0.0000	time 0.1871 (0.2247)	loss 0.9707 (0.8987)	grad_norm 0.3310 (0.3269)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:45:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:53 lr 0.000072	 wd 0.0000	time 0.1879 (0.2252)	loss 0.8936 (0.8991)	grad_norm 0.3318 (0.3271)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:46:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:30 lr 0.000071	 wd 0.0000	time 0.1769 (0.2241)	loss 0.8760 (0.8991)	grad_norm 0.3398 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:46:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:07 lr 0.000071	 wd 0.0000	time 0.1886 (0.2230)	loss 0.8735 (0.8996)	grad_norm 0.3182 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:46:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:44 lr 0.000071	 wd 0.0000	time 0.2339 (0.2220)	loss 0.9604 (0.8990)	grad_norm 0.3208 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:47:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:22 lr 0.000071	 wd 0.0000	time 0.2021 (0.2217)	loss 0.9038 (0.8996)	grad_norm 0.3212 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:47:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000071	 wd 0.0000	time 0.1536 (0.2206)	loss 0.9971 (0.8989)	grad_norm 0.3268 (0.3271)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:47:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 10 training takes 0:09:17
[2024-08-01 10:47:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 18.920 (18.920)	Loss 0.3684 (0.3684)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 10:48:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 84.960 Acc@5 97.552
[2024-08-01 10:48:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-08-01 10:48:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 84.96%
[2024-08-01 10:48:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saving......
[2024-08-01 10:48:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saved !!!
[2024-08-01 10:48:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][0/2502]	eta 10:39:31 lr 0.000071	 wd 0.0000	time 15.3363 (15.3363)	loss 0.8208 (0.8208)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:48:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:16:38 lr 0.000070	 wd 0.0000	time 1.0246 (0.4158)	loss 0.9180 (0.8925)	grad_norm 0.3225 (0.3274)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:49:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:11:44 lr 0.000070	 wd 0.0000	time 0.2023 (0.3063)	loss 0.9116 (0.8952)	grad_norm 0.3356 (0.3271)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:49:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:09:52 lr 0.000070	 wd 0.0000	time 0.1713 (0.2691)	loss 1.0166 (0.8961)	grad_norm 0.3311 (0.3274)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:49:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:08:46 lr 0.000070	 wd 0.0000	time 0.1781 (0.2503)	loss 0.9609 (0.8944)	grad_norm 0.3371 (0.3274)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:50:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:08:02 lr 0.000070	 wd 0.0000	time 0.2012 (0.2408)	loss 0.7983 (0.8934)	grad_norm 0.3195 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7655MB
[2024-08-01 10:50:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:00 lr 0.000069	 wd 0.0000	time 0.1958 (0.2527)	loss 1.0889 (0.8918)	grad_norm 0.3272 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7655MB
[2024-08-01 10:51:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:07:20 lr 0.000069	 wd 0.0000	time 0.2103 (0.2447)	loss 0.8809 (0.8944)	grad_norm 0.3331 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7655MB
[2024-08-01 10:51:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:06:46 lr 0.000069	 wd 0.0000	time 0.1834 (0.2386)	loss 0.9199 (0.8953)	grad_norm 0.3256 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7655MB
[2024-08-01 10:51:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:06:14 lr 0.000069	 wd 0.0000	time 0.2371 (0.2339)	loss 1.0283 (0.8958)	grad_norm 0.3424 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7655MB
[2024-08-01 10:52:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:04 lr 0.000069	 wd 0.0000	time 0.2223 (0.2424)	loss 0.8501 (0.8972)	grad_norm 0.3270 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7655MB
[2024-08-01 10:52:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:34 lr 0.000069	 wd 0.0000	time 0.1944 (0.2385)	loss 0.8188 (0.8975)	grad_norm 0.3224 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7655MB
[2024-08-01 10:52:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:05 lr 0.000068	 wd 0.0000	time 0.1787 (0.2350)	loss 0.9512 (0.8978)	grad_norm 0.3315 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7655MB
[2024-08-01 10:53:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:04:38 lr 0.000068	 wd 0.0000	time 0.1723 (0.2318)	loss 0.7593 (0.8981)	grad_norm 0.3198 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7655MB
[2024-08-01 10:53:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:15 lr 0.000068	 wd 0.0000	time 0.2797 (0.2315)	loss 0.8613 (0.8986)	grad_norm 0.3434 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7655MB
[2024-08-01 10:54:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:03:52 lr 0.000068	 wd 0.0000	time 0.2603 (0.2317)	loss 0.9692 (0.8981)	grad_norm 0.3390 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7655MB
[2024-08-01 10:54:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:27 lr 0.000068	 wd 0.0000	time 0.1659 (0.2296)	loss 0.9258 (0.8982)	grad_norm 0.3510 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7655MB
[2024-08-01 10:54:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:02 lr 0.000067	 wd 0.0000	time 0.2074 (0.2277)	loss 0.7939 (0.8983)	grad_norm 0.3323 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7655MB
[2024-08-01 10:55:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:38 lr 0.000067	 wd 0.0000	time 0.1808 (0.2260)	loss 1.1299 (0.8991)	grad_norm 0.3224 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7655MB
[2024-08-01 10:55:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:16 lr 0.000067	 wd 0.0000	time 1.3753 (0.2262)	loss 0.7949 (0.8996)	grad_norm 0.3167 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7655MB
[2024-08-01 10:55:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:01:53 lr 0.000067	 wd 0.0000	time 0.2031 (0.2258)	loss 0.9170 (0.8992)	grad_norm 0.3245 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7655MB
[2024-08-01 10:56:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:30 lr 0.000067	 wd 0.0000	time 0.1810 (0.2244)	loss 0.8657 (0.8988)	grad_norm 0.3415 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7655MB
[2024-08-01 10:56:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:07 lr 0.000066	 wd 0.0000	time 0.1936 (0.2233)	loss 0.9268 (0.8988)	grad_norm 0.3347 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7655MB
[2024-08-01 10:56:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:44 lr 0.000066	 wd 0.0000	time 0.2293 (0.2227)	loss 0.8799 (0.8988)	grad_norm 0.3260 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7655MB
[2024-08-01 10:57:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:22 lr 0.000066	 wd 0.0000	time 0.1675 (0.2230)	loss 0.8896 (0.8990)	grad_norm 0.3305 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7655MB
[2024-08-01 10:57:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000066	 wd 0.0000	time 0.1598 (0.2213)	loss 1.0918 (0.8982)	grad_norm 0.3320 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7655MB
[2024-08-01 10:57:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 11 training takes 0:09:18
[2024-08-01 10:57:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 19.429 (19.429)	Loss 0.3655 (0.3655)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 10:58:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 84.996 Acc@5 97.546
[2024-08-01 10:58:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-08-01 10:58:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.00%
[2024-08-01 10:58:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saving......
[2024-08-01 10:58:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saved !!!
[2024-08-01 10:58:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][0/2502]	eta 18:23:52 lr 0.000066	 wd 0.0000	time 26.4718 (26.4718)	loss 0.9438 (0.9438)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:58:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:19:27 lr 0.000066	 wd 0.0000	time 0.1725 (0.4859)	loss 0.8491 (0.8848)	grad_norm 0.3374 (0.3290)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:59:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:13:04 lr 0.000065	 wd 0.0000	time 0.1900 (0.3406)	loss 0.8755 (0.8912)	grad_norm 0.3269 (0.3280)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:59:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:42 lr 0.000065	 wd 0.0000	time 0.1796 (0.2919)	loss 0.9321 (0.9013)	grad_norm 0.3453 (0.3280)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 10:59:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:24 lr 0.000065	 wd 0.0000	time 0.1889 (0.2683)	loss 0.8706 (0.9028)	grad_norm 0.3231 (0.3280)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:00:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:09:28 lr 0.000065	 wd 0.0000	time 0.2445 (0.2840)	loss 0.7798 (0.9015)	grad_norm 0.3263 (0.3278)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:00:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:08:32 lr 0.000065	 wd 0.0000	time 0.1916 (0.2697)	loss 0.7979 (0.9017)	grad_norm 0.3305 (0.3282)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:01:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:47 lr 0.000064	 wd 0.0000	time 0.2032 (0.2592)	loss 0.8472 (0.9014)	grad_norm 0.3198 (0.3279)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:01:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:07:06 lr 0.000064	 wd 0.0000	time 0.2491 (0.2509)	loss 0.9316 (0.9003)	grad_norm 0.3162 (0.3279)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:01:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:48 lr 0.000064	 wd 0.0000	time 0.2001 (0.2551)	loss 0.8291 (0.8995)	grad_norm 0.3339 (0.3283)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:02:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:14 lr 0.000064	 wd 0.0000	time 0.1897 (0.2495)	loss 0.9414 (0.8996)	grad_norm 0.3236 (0.3283)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:02:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:42 lr 0.000064	 wd 0.0000	time 0.1924 (0.2444)	loss 0.7573 (0.8994)	grad_norm 0.3157 (0.3282)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:02:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:13 lr 0.000063	 wd 0.0000	time 0.1768 (0.2404)	loss 0.9126 (0.8985)	grad_norm 0.3403 (0.3282)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:03:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:46 lr 0.000063	 wd 0.0000	time 0.2034 (0.2382)	loss 0.7905 (0.8986)	grad_norm 0.3406 (0.3280)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:03:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:21 lr 0.000063	 wd 0.0000	time 0.1933 (0.2371)	loss 0.9507 (0.8986)	grad_norm 0.3307 (0.3280)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:03:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:03:55 lr 0.000063	 wd 0.0000	time 0.1805 (0.2347)	loss 0.8667 (0.8995)	grad_norm 0.3298 (0.3281)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:04:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:29 lr 0.000063	 wd 0.0000	time 0.2165 (0.2324)	loss 0.8853 (0.8989)	grad_norm 0.3211 (0.3281)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:04:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:04 lr 0.000062	 wd 0.0000	time 0.1861 (0.2303)	loss 0.8618 (0.8988)	grad_norm 0.3265 (0.3282)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:04:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:41 lr 0.000062	 wd 0.0000	time 0.2055 (0.2294)	loss 0.8096 (0.8990)	grad_norm 0.3379 (0.3285)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:05:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:18 lr 0.000062	 wd 0.0000	time 0.1754 (0.2300)	loss 0.8511 (0.8986)	grad_norm 0.3240 (0.3285)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:05:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:01:54 lr 0.000062	 wd 0.0000	time 0.1738 (0.2286)	loss 0.8398 (0.8989)	grad_norm 0.3291 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7655MB
[2024-08-01 11:06:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:31 lr 0.000062	 wd 0.0000	time 0.1763 (0.2272)	loss 0.8550 (0.8992)	grad_norm 0.3295 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7655MB
[2024-08-01 11:06:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:08 lr 0.000061	 wd 0.0000	time 0.1817 (0.2261)	loss 0.9146 (0.8993)	grad_norm 0.3371 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7655MB
[2024-08-01 11:06:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:45 lr 0.000061	 wd 0.0000	time 0.1901 (0.2262)	loss 0.8926 (0.8989)	grad_norm 0.3087 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7655MB
[2024-08-01 11:07:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:23 lr 0.000061	 wd 0.0000	time 0.1942 (0.2255)	loss 0.8862 (0.8981)	grad_norm 0.3296 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7655MB
[2024-08-01 11:07:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000061	 wd 0.0000	time 0.1624 (0.2237)	loss 0.9199 (0.8980)	grad_norm 0.3345 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7655MB
[2024-08-01 11:07:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 12 training takes 0:09:23
[2024-08-01 11:07:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 18.897 (18.897)	Loss 0.3616 (0.3616)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 11:07:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 85.004 Acc@5 97.574
[2024-08-01 11:07:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-08-01 11:07:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.00%
[2024-08-01 11:07:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saving......
[2024-08-01 11:07:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saved !!!
[2024-08-01 11:08:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][0/2502]	eta 1 day, 0:21:13 lr 0.000061	 wd 0.0000	time 35.0414 (35.0414)	loss 0.8457 (0.8457)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:08:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:21:36 lr 0.000061	 wd 0.0000	time 0.1680 (0.5396)	loss 0.8013 (0.8865)	grad_norm 0.3253 (0.3264)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:09:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:14:05 lr 0.000060	 wd 0.0000	time 0.1829 (0.3674)	loss 0.8135 (0.8955)	grad_norm 0.3401 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:09:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:11:25 lr 0.000060	 wd 0.0000	time 0.2167 (0.3112)	loss 0.7979 (0.8895)	grad_norm 0.3342 (0.3272)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:10:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:11:17 lr 0.000060	 wd 0.0000	time 0.2221 (0.3223)	loss 0.7822 (0.8906)	grad_norm 0.3305 (0.3278)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:10:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:09:57 lr 0.000060	 wd 0.0000	time 0.1872 (0.2983)	loss 0.8442 (0.8911)	grad_norm 0.3260 (0.3283)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:10:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:54 lr 0.000060	 wd 0.0000	time 0.1842 (0.2811)	loss 0.8120 (0.8922)	grad_norm 0.3270 (0.3288)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:11:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:08:04 lr 0.000059	 wd 0.0000	time 0.1924 (0.2690)	loss 1.0156 (0.8926)	grad_norm 0.3526 (0.3288)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:11:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:33 lr 0.000059	 wd 0.0000	time 0.2408 (0.2662)	loss 0.9409 (0.8925)	grad_norm 0.3336 (0.3288)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:11:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:06:54 lr 0.000059	 wd 0.0000	time 0.2042 (0.2590)	loss 0.9517 (0.8934)	grad_norm 0.3279 (0.3292)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:12:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:19 lr 0.000059	 wd 0.0000	time 0.1698 (0.2529)	loss 0.9966 (0.8943)	grad_norm 0.3394 (0.3294)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:12:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:47 lr 0.000059	 wd 0.0000	time 0.1926 (0.2477)	loss 0.8716 (0.8938)	grad_norm 0.3281 (0.3292)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:12:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:17 lr 0.000058	 wd 0.0000	time 0.2050 (0.2442)	loss 0.9873 (0.8941)	grad_norm 0.3392 (0.3292)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:13:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:04:53 lr 0.000058	 wd 0.0000	time 0.1842 (0.2441)	loss 0.8999 (0.8946)	grad_norm 0.3386 (0.3293)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:13:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:25 lr 0.000058	 wd 0.0000	time 0.2495 (0.2411)	loss 1.0732 (0.8943)	grad_norm 0.3158 (0.3294)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:13:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:03:58 lr 0.000058	 wd 0.0000	time 0.2093 (0.2382)	loss 0.9141 (0.8945)	grad_norm 0.3401 (0.3295)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:14:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:32 lr 0.000058	 wd 0.0000	time 0.1884 (0.2355)	loss 0.8438 (0.8949)	grad_norm 0.3226 (0.3296)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:14:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:07 lr 0.000057	 wd 0.0000	time 0.2098 (0.2344)	loss 0.8433 (0.8949)	grad_norm 0.3205 (0.3296)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:15:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:44 lr 0.000057	 wd 0.0000	time 0.2303 (0.2340)	loss 0.8662 (0.8949)	grad_norm 0.3387 (0.3297)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:15:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:19 lr 0.000057	 wd 0.0000	time 0.1907 (0.2321)	loss 0.8164 (0.8937)	grad_norm 0.3435 (0.3297)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:15:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:55 lr 0.000057	 wd 0.0000	time 0.1897 (0.2305)	loss 0.8667 (0.8943)	grad_norm 0.3210 (0.3299)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:16:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:32 lr 0.000057	 wd 0.0000	time 0.2331 (0.2292)	loss 0.8970 (0.8950)	grad_norm 0.3056 (0.3298)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:16:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:09 lr 0.000056	 wd 0.0000	time 0.3655 (0.2286)	loss 0.9736 (0.8950)	grad_norm 0.3434 (0.3298)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:16:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:46 lr 0.000056	 wd 0.0000	time 0.1959 (0.2284)	loss 0.8237 (0.8946)	grad_norm 0.3296 (0.3299)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:17:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:23 lr 0.000056	 wd 0.0000	time 0.1942 (0.2271)	loss 0.8965 (0.8950)	grad_norm 0.3130 (0.3299)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:17:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000056	 wd 0.0000	time 0.1558 (0.2251)	loss 0.8286 (0.8950)	grad_norm 0.3210 (0.3298)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:17:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 13 training takes 0:09:27
[2024-08-01 11:18:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 37.920 (37.920)	Loss 0.3616 (0.3616)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 11:18:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 85.028 Acc@5 97.594
[2024-08-01 11:18:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-08-01 11:18:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.03%
[2024-08-01 11:18:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saving......
[2024-08-01 11:18:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saved !!!
[2024-08-01 11:18:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][0/2502]	eta 11:00:09 lr 0.000056	 wd 0.0000	time 15.8311 (15.8311)	loss 0.9937 (0.9937)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:18:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:14:22 lr 0.000055	 wd 0.0000	time 0.1995 (0.3591)	loss 0.8687 (0.8916)	grad_norm 0.3288 (0.3301)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:19:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:10:46 lr 0.000055	 wd 0.0000	time 0.2543 (0.2808)	loss 0.8516 (0.8935)	grad_norm 0.3223 (0.3299)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:19:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:11:04 lr 0.000055	 wd 0.0000	time 0.2304 (0.3018)	loss 1.1387 (0.8956)	grad_norm 0.3228 (0.3296)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:20:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:09:38 lr 0.000055	 wd 0.0000	time 0.1973 (0.2753)	loss 1.1201 (0.8944)	grad_norm 0.3260 (0.3302)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:20:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:08:38 lr 0.000055	 wd 0.0000	time 0.1808 (0.2588)	loss 0.9424 (0.8940)	grad_norm 0.3125 (0.3299)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:20:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:07:51 lr 0.000054	 wd 0.0000	time 0.2189 (0.2476)	loss 0.8633 (0.8945)	grad_norm 0.3524 (0.3303)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:21:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:44 lr 0.000054	 wd 0.0000	time 0.2007 (0.2579)	loss 0.8169 (0.8936)	grad_norm 0.3281 (0.3307)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:21:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:05 lr 0.000054	 wd 0.0000	time 0.2189 (0.2503)	loss 0.7993 (0.8938)	grad_norm 0.3245 (0.3307)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:21:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:31 lr 0.000054	 wd 0.0000	time 0.1760 (0.2442)	loss 0.8828 (0.8935)	grad_norm 0.3474 (0.3307)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:22:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:05:59 lr 0.000054	 wd 0.0000	time 0.1893 (0.2392)	loss 0.9302 (0.8928)	grad_norm 0.3527 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7655MB
[2024-08-01 11:22:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:33 lr 0.000053	 wd 0.0000	time 0.2124 (0.2376)	loss 0.8408 (0.8925)	grad_norm 0.3140 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7655MB
[2024-08-01 11:23:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:07 lr 0.000053	 wd 0.0000	time 0.1892 (0.2364)	loss 0.8887 (0.8924)	grad_norm 0.3401 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7655MB
[2024-08-01 11:23:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:04:40 lr 0.000053	 wd 0.0000	time 0.1773 (0.2335)	loss 1.1016 (0.8921)	grad_norm 0.3398 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7655MB
[2024-08-01 11:23:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:14 lr 0.000053	 wd 0.0000	time 0.1714 (0.2309)	loss 0.9111 (0.8923)	grad_norm 0.3150 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7655MB
[2024-08-01 11:24:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:03:49 lr 0.000053	 wd 0.0000	time 0.1963 (0.2288)	loss 0.8726 (0.8926)	grad_norm 0.3352 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7655MB
[2024-08-01 11:24:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:25 lr 0.000052	 wd 0.0000	time 0.1895 (0.2278)	loss 0.8677 (0.8922)	grad_norm 0.3371 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7655MB
[2024-08-01 11:24:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:02 lr 0.000052	 wd 0.0000	time 0.2160 (0.2280)	loss 1.0664 (0.8927)	grad_norm 0.3526 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7655MB
[2024-08-01 11:25:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:38 lr 0.000052	 wd 0.0000	time 0.1984 (0.2264)	loss 0.7036 (0.8929)	grad_norm 0.3267 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7655MB
[2024-08-01 11:25:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:15 lr 0.000052	 wd 0.0000	time 0.1812 (0.2249)	loss 0.8428 (0.8926)	grad_norm 0.3300 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7655MB
[2024-08-01 11:25:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:01:52 lr 0.000052	 wd 0.0000	time 0.1897 (0.2240)	loss 0.8052 (0.8924)	grad_norm 0.3329 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7655MB
[2024-08-01 11:26:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:30 lr 0.000051	 wd 0.0000	time 0.3688 (0.2246)	loss 0.9336 (0.8924)	grad_norm 0.3260 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7655MB
[2024-08-01 11:26:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:07 lr 0.000051	 wd 0.0000	time 0.1886 (0.2237)	loss 0.8936 (0.8931)	grad_norm 0.3251 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7655MB
[2024-08-01 11:26:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:44 lr 0.000051	 wd 0.0000	time 0.1756 (0.2226)	loss 0.8594 (0.8928)	grad_norm 0.3354 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7655MB
[2024-08-01 11:27:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:22 lr 0.000051	 wd 0.0000	time 0.1747 (0.2215)	loss 0.9927 (0.8934)	grad_norm 0.3335 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7655MB
[2024-08-01 11:27:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000051	 wd 0.0000	time 0.1560 (0.2199)	loss 0.8901 (0.8936)	grad_norm 0.3345 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7655MB
[2024-08-01 11:27:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 14 training takes 0:09:14
[2024-08-01 11:28:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 37.887 (37.887)	Loss 0.3589 (0.3589)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 11:28:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 85.044 Acc@5 97.586
[2024-08-01 11:28:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-08-01 11:28:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.04%
[2024-08-01 11:28:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saving......
[2024-08-01 11:28:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saved !!!
[2024-08-01 11:28:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][0/2502]	eta 10:34:01 lr 0.000051	 wd 0.0000	time 15.2046 (15.2046)	loss 0.8091 (0.8091)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:29:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:14:21 lr 0.000050	 wd 0.0000	time 0.1934 (0.3586)	loss 0.9897 (0.9013)	grad_norm 0.3339 (0.3307)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:29:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:12:21 lr 0.000050	 wd 0.0000	time 0.1965 (0.3221)	loss 1.0117 (0.8958)	grad_norm 0.3320 (0.3324)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:29:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:10:14 lr 0.000050	 wd 0.0000	time 0.1713 (0.2792)	loss 0.9463 (0.8933)	grad_norm 0.3286 (0.3326)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:30:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:09:02 lr 0.000050	 wd 0.0000	time 0.1551 (0.2580)	loss 1.0205 (0.8946)	grad_norm 0.3397 (0.3328)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:30:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:08:09 lr 0.000049	 wd 0.0000	time 0.1834 (0.2445)	loss 0.7930 (0.8967)	grad_norm 0.3398 (0.3330)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:30:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:07:42 lr 0.000049	 wd 0.0000	time 0.3208 (0.2434)	loss 0.8447 (0.8961)	grad_norm 0.3415 (0.3327)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:31:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:19 lr 0.000049	 wd 0.0000	time 0.1813 (0.2442)	loss 0.8286 (0.8933)	grad_norm 0.3351 (0.3329)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:31:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:06:44 lr 0.000049	 wd 0.0000	time 0.1803 (0.2380)	loss 1.0312 (0.8937)	grad_norm 0.3381 (0.3329)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:31:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:13 lr 0.000049	 wd 0.0000	time 0.1982 (0.2333)	loss 0.8110 (0.8938)	grad_norm 0.3422 (0.3332)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:32:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:05:46 lr 0.000048	 wd 0.0000	time 0.2162 (0.2309)	loss 0.9302 (0.8935)	grad_norm 0.3245 (0.3333)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:32:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:24 lr 0.000048	 wd 0.0000	time 0.2018 (0.2312)	loss 0.9258 (0.8913)	grad_norm 0.3536 (0.3329)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:33:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:04:58 lr 0.000048	 wd 0.0000	time 0.1933 (0.2290)	loss 0.8208 (0.8922)	grad_norm 0.3229 (0.3328)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:33:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:04:32 lr 0.000048	 wd 0.0000	time 0.1742 (0.2265)	loss 0.9233 (0.8917)	grad_norm 0.3272 (0.3330)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:33:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:07 lr 0.000048	 wd 0.0000	time 0.1859 (0.2243)	loss 0.8174 (0.8921)	grad_norm 0.3360 (0.3331)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:34:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:03:44 lr 0.000047	 wd 0.0000	time 0.2473 (0.2238)	loss 0.9473 (0.8915)	grad_norm 0.3249 (0.3333)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:34:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:22 lr 0.000047	 wd 0.0000	time 0.1796 (0.2241)	loss 0.9546 (0.8916)	grad_norm 0.3339 (0.3334)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:34:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:02:58 lr 0.000047	 wd 0.0000	time 0.1853 (0.2226)	loss 0.8164 (0.8919)	grad_norm 0.3237 (0.3335)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:35:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:35 lr 0.000047	 wd 0.0000	time 0.1715 (0.2213)	loss 1.0449 (0.8924)	grad_norm 0.3580 (0.3334)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:35:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:12 lr 0.000047	 wd 0.0000	time 0.2154 (0.2203)	loss 0.9771 (0.8919)	grad_norm 0.3417 (0.3335)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:35:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:01:51 lr 0.000046	 wd 0.0000	time 0.1686 (0.2213)	loss 1.0498 (0.8927)	grad_norm 0.3615 (0.3335)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:36:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:28 lr 0.000046	 wd 0.0000	time 0.1801 (0.2208)	loss 0.8472 (0.8926)	grad_norm 0.3243 (0.3334)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:36:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:06 lr 0.000046	 wd 0.0000	time 0.1806 (0.2199)	loss 0.9126 (0.8929)	grad_norm 0.3271 (0.3333)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:36:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:44 lr 0.000046	 wd 0.0000	time 0.1902 (0.2189)	loss 0.9268 (0.8929)	grad_norm 0.3510 (0.3334)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:37:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:22 lr 0.000046	 wd 0.0000	time 0.2173 (0.2185)	loss 0.9292 (0.8929)	grad_norm 0.3352 (0.3335)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:37:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000045	 wd 0.0000	time 0.1566 (0.2170)	loss 1.1133 (0.8932)	grad_norm 0.3328 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7655MB
[2024-08-01 11:37:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 15 training takes 0:09:12
[2024-08-01 11:37:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_15.pth saving......
[2024-08-01 11:37:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_15.pth saved !!!
[2024-08-01 11:37:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 19.059 (19.059)	Loss 0.3630 (0.3630)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 11:38:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 85.066 Acc@5 97.592
[2024-08-01 11:38:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-08-01 11:38:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.07%
[2024-08-01 11:38:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saving......
[2024-08-01 11:38:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saved !!!
[2024-08-01 11:38:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][0/2502]	eta 11:28:45 lr 0.000045	 wd 0.0000	time 16.5168 (16.5168)	loss 0.7368 (0.7368)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:38:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:16:24 lr 0.000045	 wd 0.0000	time 0.3774 (0.4097)	loss 1.0117 (0.9041)	grad_norm 0.3418 (0.3353)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:39:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:12:42 lr 0.000045	 wd 0.0000	time 0.1832 (0.3313)	loss 0.9131 (0.8927)	grad_norm 0.3403 (0.3343)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:39:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:10:27 lr 0.000045	 wd 0.0000	time 0.1608 (0.2851)	loss 0.9331 (0.8941)	grad_norm 0.3267 (0.3333)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:39:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:09:12 lr 0.000045	 wd 0.0000	time 0.1754 (0.2627)	loss 0.9263 (0.8937)	grad_norm 0.3371 (0.3336)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:40:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:08:21 lr 0.000044	 wd 0.0000	time 0.2177 (0.2507)	loss 0.9912 (0.8936)	grad_norm 0.3275 (0.3337)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:40:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:16 lr 0.000044	 wd 0.0000	time 0.1633 (0.2610)	loss 0.9351 (0.8936)	grad_norm 0.3295 (0.3339)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:41:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:33 lr 0.000044	 wd 0.0000	time 0.1903 (0.2518)	loss 0.9224 (0.8939)	grad_norm 0.3297 (0.3337)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:41:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:06:57 lr 0.000044	 wd 0.0000	time 0.1731 (0.2452)	loss 0.9023 (0.8931)	grad_norm 0.3316 (0.3338)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:41:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:24 lr 0.000043	 wd 0.0000	time 0.1971 (0.2400)	loss 0.8066 (0.8946)	grad_norm 0.3419 (0.3341)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:42:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:05:58 lr 0.000043	 wd 0.0000	time 0.1821 (0.2385)	loss 0.8813 (0.8949)	grad_norm 0.3381 (0.3344)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:42:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:31 lr 0.000043	 wd 0.0000	time 0.1904 (0.2368)	loss 0.9897 (0.8952)	grad_norm 0.3481 (0.3346)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:42:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:04 lr 0.000043	 wd 0.0000	time 0.1746 (0.2335)	loss 0.9204 (0.8947)	grad_norm 0.3384 (0.3345)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:43:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:04:37 lr 0.000043	 wd 0.0000	time 0.1902 (0.2308)	loss 0.9917 (0.8941)	grad_norm 0.3371 (0.3345)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:43:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:12 lr 0.000042	 wd 0.0000	time 0.2146 (0.2287)	loss 0.8154 (0.8935)	grad_norm 0.3237 (0.3345)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:43:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:03:49 lr 0.000042	 wd 0.0000	time 0.1969 (0.2291)	loss 0.8262 (0.8930)	grad_norm 0.3146 (0.3345)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:44:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:25 lr 0.000042	 wd 0.0000	time 0.1754 (0.2277)	loss 0.7988 (0.8928)	grad_norm 0.3346 (0.3344)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:44:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:01 lr 0.000042	 wd 0.0000	time 0.1838 (0.2260)	loss 0.8853 (0.8925)	grad_norm 0.3366 (0.3347)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:44:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:37 lr 0.000042	 wd 0.0000	time 0.1791 (0.2244)	loss 1.0449 (0.8927)	grad_norm 0.3196 (0.3347)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:45:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:14 lr 0.000041	 wd 0.0000	time 0.1838 (0.2238)	loss 1.0195 (0.8917)	grad_norm 0.3305 (0.3346)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:45:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:01:52 lr 0.000041	 wd 0.0000	time 0.3804 (0.2246)	loss 0.8574 (0.8914)	grad_norm 0.3327 (0.3346)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:46:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:29 lr 0.000041	 wd 0.0000	time 0.2085 (0.2235)	loss 0.6880 (0.8910)	grad_norm 0.3349 (0.3347)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:46:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:07 lr 0.000041	 wd 0.0000	time 0.1721 (0.2222)	loss 0.7969 (0.8910)	grad_norm 0.3386 (0.3348)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:46:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:44 lr 0.000041	 wd 0.0000	time 0.1940 (0.2213)	loss 0.6978 (0.8904)	grad_norm 0.3492 (0.3347)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:47:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:22 lr 0.000040	 wd 0.0000	time 0.1740 (0.2209)	loss 0.7847 (0.8903)	grad_norm 0.3380 (0.3346)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:47:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1593 (0.2200)	loss 0.8452 (0.8899)	grad_norm 0.3671 (0.3347)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:47:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 16 training takes 0:09:16
[2024-08-01 11:47:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 19.184 (19.184)	Loss 0.3604 (0.3604)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 11:48:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 85.056 Acc@5 97.584
[2024-08-01 11:48:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-08-01 11:48:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.07%
[2024-08-01 11:48:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][0/2502]	eta 13:07:18 lr 0.000040	 wd 0.0000	time 18.8802 (18.8802)	loss 0.7695 (0.7695)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:48:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:18:56 lr 0.000040	 wd 0.0000	time 0.1850 (0.4733)	loss 0.9951 (0.8900)	grad_norm 0.3257 (0.3346)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:49:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:12:54 lr 0.000040	 wd 0.0000	time 0.1916 (0.3364)	loss 0.8862 (0.8947)	grad_norm 0.3139 (0.3354)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:49:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:35 lr 0.000040	 wd 0.0000	time 0.1932 (0.2888)	loss 0.8984 (0.8906)	grad_norm 0.3531 (0.3357)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:49:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:09:16 lr 0.000039	 wd 0.0000	time 0.1677 (0.2646)	loss 0.9443 (0.8892)	grad_norm 0.3250 (0.3358)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:50:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:08:50 lr 0.000039	 wd 0.0000	time 0.7966 (0.2652)	loss 0.7666 (0.8873)	grad_norm 0.3559 (0.3358)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:50:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:20 lr 0.000039	 wd 0.0000	time 0.1896 (0.2633)	loss 0.8218 (0.8888)	grad_norm 0.3503 (0.3360)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:51:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:36 lr 0.000039	 wd 0.0000	time 0.1910 (0.2535)	loss 0.9185 (0.8880)	grad_norm 0.3380 (0.3360)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:51:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:06:58 lr 0.000039	 wd 0.0000	time 0.1834 (0.2457)	loss 0.8018 (0.8883)	grad_norm 0.3286 (0.3360)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:51:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:28 lr 0.000038	 wd 0.0000	time 0.2051 (0.2422)	loss 1.0000 (0.8885)	grad_norm 0.3278 (0.3357)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:52:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:03 lr 0.000038	 wd 0.0000	time 0.2034 (0.2419)	loss 0.9292 (0.8885)	grad_norm 0.3379 (0.3359)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:52:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:33 lr 0.000038	 wd 0.0000	time 0.1815 (0.2379)	loss 0.7393 (0.8897)	grad_norm 0.3373 (0.3361)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:52:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:05 lr 0.000038	 wd 0.0000	time 0.1802 (0.2345)	loss 0.7842 (0.8911)	grad_norm 0.3493 (0.3363)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:53:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:04:38 lr 0.000038	 wd 0.0000	time 0.1742 (0.2314)	loss 0.9077 (0.8902)	grad_norm 0.3235 (0.3363)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:53:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:13 lr 0.000037	 wd 0.0000	time 0.2050 (0.2303)	loss 0.9185 (0.8911)	grad_norm 0.3179 (0.3363)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:53:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:03:50 lr 0.000037	 wd 0.0000	time 0.2130 (0.2304)	loss 0.8862 (0.8910)	grad_norm 0.3348 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7655MB
[2024-08-01 11:54:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:26 lr 0.000037	 wd 0.0000	time 0.1555 (0.2284)	loss 1.0430 (0.8907)	grad_norm 0.3478 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7655MB
[2024-08-01 11:54:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:01 lr 0.000037	 wd 0.0000	time 0.2093 (0.2267)	loss 1.0508 (0.8909)	grad_norm 0.3362 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7655MB
[2024-08-01 11:54:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:38 lr 0.000037	 wd 0.0000	time 0.1891 (0.2251)	loss 0.7969 (0.8923)	grad_norm 0.3444 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7655MB
[2024-08-01 11:55:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:15 lr 0.000036	 wd 0.0000	time 0.2419 (0.2256)	loss 0.7700 (0.8927)	grad_norm 0.3296 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7655MB
[2024-08-01 11:55:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:01:52 lr 0.000036	 wd 0.0000	time 0.1895 (0.2250)	loss 0.8154 (0.8922)	grad_norm 0.3327 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7655MB
[2024-08-01 11:55:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:29 lr 0.000036	 wd 0.0000	time 0.1733 (0.2238)	loss 0.8247 (0.8916)	grad_norm 0.3297 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7655MB
[2024-08-01 11:56:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:07 lr 0.000036	 wd 0.0000	time 0.1687 (0.2226)	loss 0.9663 (0.8915)	grad_norm 0.3343 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7655MB
[2024-08-01 11:56:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:44 lr 0.000036	 wd 0.0000	time 0.1955 (0.2219)	loss 0.9248 (0.8911)	grad_norm 0.3314 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7655MB
[2024-08-01 11:56:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:22 lr 0.000035	 wd 0.0000	time 0.1852 (0.2222)	loss 0.8374 (0.8914)	grad_norm 0.3353 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7655MB
[2024-08-01 11:57:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1533 (0.2205)	loss 0.9287 (0.8917)	grad_norm 0.3338 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7655MB
[2024-08-01 11:57:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 17 training takes 0:09:17
[2024-08-01 11:57:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 22.553 (22.553)	Loss 0.3586 (0.3586)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 11:57:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 85.128 Acc@5 97.614
[2024-08-01 11:57:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-08-01 11:57:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.13%
[2024-08-01 11:57:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saving......
[2024-08-01 11:57:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saved !!!
[2024-08-01 11:58:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][0/2502]	eta 23:36:07 lr 0.000035	 wd 0.0000	time 33.9600 (33.9600)	loss 0.9102 (0.9102)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:58:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:21:14 lr 0.000035	 wd 0.0000	time 0.1641 (0.5305)	loss 1.0078 (0.8944)	grad_norm 0.3406 (0.3378)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:59:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:13:54 lr 0.000035	 wd 0.0000	time 0.1932 (0.3627)	loss 0.8408 (0.8894)	grad_norm 0.3495 (0.3375)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:59:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:11:12 lr 0.000035	 wd 0.0000	time 0.1861 (0.3053)	loss 0.9346 (0.8932)	grad_norm 0.3369 (0.3383)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 11:59:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:10:04 lr 0.000034	 wd 0.0000	time 0.2333 (0.2877)	loss 0.7969 (0.8949)	grad_norm 0.3457 (0.3380)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:00:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:09:12 lr 0.000034	 wd 0.0000	time 0.1780 (0.2758)	loss 0.7114 (0.8947)	grad_norm 0.3362 (0.3373)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:00:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:08:18 lr 0.000034	 wd 0.0000	time 0.1551 (0.2621)	loss 0.9546 (0.8908)	grad_norm 0.3481 (0.3375)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:00:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:07:35 lr 0.000034	 wd 0.0000	time 0.2037 (0.2526)	loss 0.9629 (0.8880)	grad_norm 0.3207 (0.3372)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:01:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:06:58 lr 0.000034	 wd 0.0000	time 0.2056 (0.2461)	loss 1.0850 (0.8863)	grad_norm 0.3243 (0.3371)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:01:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:06:34 lr 0.000033	 wd 0.0000	time 0.1775 (0.2465)	loss 0.9639 (0.8867)	grad_norm 0.3483 (0.3372)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:02:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:03 lr 0.000033	 wd 0.0000	time 0.1911 (0.2417)	loss 0.8550 (0.8876)	grad_norm 0.3402 (0.3373)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:02:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:33 lr 0.000033	 wd 0.0000	time 0.1874 (0.2377)	loss 0.8008 (0.8889)	grad_norm 0.3296 (0.3374)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:02:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:05 lr 0.000033	 wd 0.0000	time 0.1921 (0.2344)	loss 0.8984 (0.8884)	grad_norm 0.3327 (0.3375)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:03:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:04:40 lr 0.000033	 wd 0.0000	time 0.2980 (0.2331)	loss 0.8989 (0.8898)	grad_norm 0.3340 (0.3377)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:03:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:16 lr 0.000032	 wd 0.0000	time 0.2333 (0.2326)	loss 1.0146 (0.8892)	grad_norm 0.3417 (0.3378)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:03:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:03:50 lr 0.000032	 wd 0.0000	time 0.1924 (0.2304)	loss 0.8774 (0.8902)	grad_norm 0.3416 (0.3377)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:04:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:25 lr 0.000032	 wd 0.0000	time 0.1952 (0.2284)	loss 0.8750 (0.8894)	grad_norm 0.3388 (0.3378)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:04:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:01 lr 0.000032	 wd 0.0000	time 0.1921 (0.2264)	loss 0.9814 (0.8896)	grad_norm 0.3450 (0.3378)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:04:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:38 lr 0.000032	 wd 0.0000	time 0.1678 (0.2255)	loss 0.8320 (0.8895)	grad_norm 0.3531 (0.3379)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:05:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:16 lr 0.000032	 wd 0.0000	time 0.2409 (0.2261)	loss 0.8374 (0.8891)	grad_norm 0.3413 (0.3380)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:05:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:01:52 lr 0.000031	 wd 0.0000	time 0.2168 (0.2249)	loss 0.8887 (0.8898)	grad_norm 0.3226 (0.3381)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:05:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:29 lr 0.000031	 wd 0.0000	time 0.1959 (0.2238)	loss 0.7520 (0.8899)	grad_norm 0.3458 (0.3381)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:06:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:07 lr 0.000031	 wd 0.0000	time 0.2071 (0.2228)	loss 0.9097 (0.8898)	grad_norm 0.3325 (0.3382)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:06:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:45 lr 0.000031	 wd 0.0000	time 0.3709 (0.2231)	loss 0.7622 (0.8901)	grad_norm 0.3237 (0.3382)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:06:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:22 lr 0.000031	 wd 0.0000	time 0.2011 (0.2225)	loss 0.8789 (0.8902)	grad_norm 0.3441 (0.3384)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:07:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000030	 wd 0.0000	time 0.1596 (0.2207)	loss 0.8716 (0.8902)	grad_norm 0.3434 (0.3384)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:07:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 18 training takes 0:09:20
[2024-08-01 12:07:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 19.276 (19.276)	Loss 0.3579 (0.3579)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 12:07:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 85.072 Acc@5 97.598
[2024-08-01 12:07:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-08-01 12:07:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.13%
[2024-08-01 12:08:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][0/2502]	eta 23:54:40 lr 0.000030	 wd 0.0000	time 34.4046 (34.4046)	loss 0.8691 (0.8691)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:08:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:21:50 lr 0.000030	 wd 0.0000	time 0.1767 (0.5455)	loss 1.0273 (0.8808)	grad_norm 0.3370 (0.3377)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:09:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:14:09 lr 0.000030	 wd 0.0000	time 0.1931 (0.3690)	loss 0.7041 (0.8784)	grad_norm 0.3566 (0.3384)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:09:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:12:47 lr 0.000030	 wd 0.0000	time 0.5418 (0.3485)	loss 0.9888 (0.8837)	grad_norm 0.3408 (0.3383)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:10:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:11:04 lr 0.000030	 wd 0.0000	time 0.1617 (0.3163)	loss 0.8403 (0.8863)	grad_norm 0.3200 (0.3382)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:10:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:09:44 lr 0.000029	 wd 0.0000	time 0.1900 (0.2920)	loss 0.9526 (0.8865)	grad_norm 0.3374 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7655MB
[2024-08-01 12:10:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:43 lr 0.000029	 wd 0.0000	time 0.1940 (0.2754)	loss 0.7656 (0.8880)	grad_norm 0.3310 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7655MB
[2024-08-01 12:11:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:08:01 lr 0.000029	 wd 0.0000	time 0.2196 (0.2669)	loss 1.0127 (0.8892)	grad_norm 0.3291 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7655MB
[2024-08-01 12:11:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:07:42 lr 0.000029	 wd 0.0000	time 0.2062 (0.2716)	loss 0.8628 (0.8905)	grad_norm 0.3502 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7655MB
[2024-08-01 12:11:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:07:01 lr 0.000029	 wd 0.0000	time 0.1855 (0.2632)	loss 0.8652 (0.8902)	grad_norm 0.3368 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7655MB
[2024-08-01 12:12:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:25 lr 0.000028	 wd 0.0000	time 0.1737 (0.2567)	loss 0.9609 (0.8909)	grad_norm 0.3356 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7655MB
[2024-08-01 12:12:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:53 lr 0.000028	 wd 0.0000	time 0.2019 (0.2520)	loss 0.8232 (0.8903)	grad_norm 0.3441 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7655MB
[2024-08-01 12:13:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:35 lr 0.000028	 wd 0.0000	time 0.1799 (0.2577)	loss 0.8706 (0.8906)	grad_norm 0.3426 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7655MB
[2024-08-01 12:13:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:05:04 lr 0.000028	 wd 0.0000	time 0.1979 (0.2529)	loss 0.8335 (0.8910)	grad_norm 0.3367 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7655MB
[2024-08-01 12:13:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:34 lr 0.000028	 wd 0.0000	time 0.1691 (0.2487)	loss 0.8325 (0.8906)	grad_norm 0.3351 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7655MB
[2024-08-01 12:14:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:04:05 lr 0.000028	 wd 0.0000	time 0.1762 (0.2453)	loss 0.8901 (0.8910)	grad_norm 0.3234 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7655MB
[2024-08-01 12:14:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:40 lr 0.000027	 wd 0.0000	time 0.2278 (0.2440)	loss 0.8882 (0.8915)	grad_norm 0.3555 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7655MB
[2024-08-01 12:14:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:14 lr 0.000027	 wd 0.0000	time 0.1955 (0.2430)	loss 0.9927 (0.8915)	grad_norm 0.3349 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7655MB
[2024-08-01 12:15:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:48 lr 0.000027	 wd 0.0000	time 0.1992 (0.2407)	loss 0.8208 (0.8918)	grad_norm 0.3332 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7655MB
[2024-08-01 12:15:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:23 lr 0.000027	 wd 0.0000	time 0.1613 (0.2385)	loss 0.8560 (0.8919)	grad_norm 0.3371 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7655MB
[2024-08-01 12:15:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:59 lr 0.000027	 wd 0.0000	time 0.2208 (0.2374)	loss 0.9600 (0.8917)	grad_norm 0.3426 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7655MB
[2024-08-01 12:16:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:35 lr 0.000026	 wd 0.0000	time 0.1624 (0.2375)	loss 0.9912 (0.8914)	grad_norm 0.3365 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7655MB
[2024-08-01 12:16:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:11 lr 0.000026	 wd 0.0000	time 0.2165 (0.2363)	loss 0.8862 (0.8907)	grad_norm 0.3774 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7655MB
[2024-08-01 12:16:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:47 lr 0.000026	 wd 0.0000	time 0.1804 (0.2347)	loss 0.9229 (0.8903)	grad_norm 0.3392 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7655MB
[2024-08-01 12:17:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:23 lr 0.000026	 wd 0.0000	time 0.2097 (0.2332)	loss 0.9785 (0.8902)	grad_norm 0.3534 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7655MB
[2024-08-01 12:17:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1520 (0.2312)	loss 0.7100 (0.8902)	grad_norm 0.3452 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7655MB
[2024-08-01 12:17:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 19 training takes 0:09:46
[2024-08-01 12:18:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 30.067 (30.067)	Loss 0.3604 (0.3604)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 12:18:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 85.078 Acc@5 97.606
[2024-08-01 12:18:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-08-01 12:18:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.13%
[2024-08-01 12:18:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][0/2502]	eta 11:06:42 lr 0.000026	 wd 0.0000	time 15.9882 (15.9882)	loss 0.8550 (0.8550)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:19:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:15:43 lr 0.000026	 wd 0.0000	time 0.2827 (0.3928)	loss 1.0166 (0.8945)	grad_norm 0.3379 (0.3423)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:19:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:12:40 lr 0.000025	 wd 0.0000	time 0.1687 (0.3302)	loss 0.9585 (0.8853)	grad_norm 0.3402 (0.3418)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:19:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:10:26 lr 0.000025	 wd 0.0000	time 0.1757 (0.2844)	loss 0.7622 (0.8814)	grad_norm 0.3511 (0.3416)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:20:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:09:11 lr 0.000025	 wd 0.0000	time 0.1900 (0.2622)	loss 0.8726 (0.8818)	grad_norm 0.3449 (0.3412)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:20:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:08:19 lr 0.000025	 wd 0.0000	time 0.2834 (0.2495)	loss 0.8677 (0.8813)	grad_norm 0.3289 (0.3418)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:21:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:08:17 lr 0.000025	 wd 0.0000	time 0.1682 (0.2615)	loss 0.8022 (0.8817)	grad_norm 0.3425 (0.3414)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:21:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:34 lr 0.000025	 wd 0.0000	time 0.1939 (0.2520)	loss 0.7930 (0.8822)	grad_norm 0.3283 (0.3416)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:21:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:06:56 lr 0.000024	 wd 0.0000	time 0.1780 (0.2448)	loss 1.0078 (0.8827)	grad_norm 0.3288 (0.3416)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:22:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:23 lr 0.000024	 wd 0.0000	time 0.2137 (0.2392)	loss 0.7559 (0.8827)	grad_norm 0.3248 (0.3416)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:22:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:09 lr 0.000024	 wd 0.0000	time 0.2112 (0.2458)	loss 0.8203 (0.8824)	grad_norm 0.3342 (0.3413)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:22:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:38 lr 0.000024	 wd 0.0000	time 0.1939 (0.2416)	loss 0.8110 (0.8826)	grad_norm 0.3338 (0.3413)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:23:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:09 lr 0.000024	 wd 0.0000	time 0.1646 (0.2377)	loss 0.7402 (0.8821)	grad_norm 0.3309 (0.3414)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:23:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:04:41 lr 0.000023	 wd 0.0000	time 0.1814 (0.2345)	loss 0.8979 (0.8821)	grad_norm 0.3408 (0.3411)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:24:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:17 lr 0.000023	 wd 0.0000	time 0.3319 (0.2334)	loss 0.9312 (0.8826)	grad_norm 0.3476 (0.3412)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:24:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:03:53 lr 0.000023	 wd 0.0000	time 0.1988 (0.2333)	loss 0.9570 (0.8822)	grad_norm 0.3479 (0.3411)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:24:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:28 lr 0.000023	 wd 0.0000	time 0.1810 (0.2313)	loss 0.9331 (0.8816)	grad_norm 0.3500 (0.3412)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:25:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:03 lr 0.000023	 wd 0.0000	time 0.1759 (0.2292)	loss 0.9775 (0.8817)	grad_norm 0.3390 (0.3411)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:25:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:39 lr 0.000023	 wd 0.0000	time 0.1977 (0.2275)	loss 0.8135 (0.8825)	grad_norm 0.3427 (0.3411)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:25:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:16 lr 0.000022	 wd 0.0000	time 0.1856 (0.2268)	loss 1.0068 (0.8831)	grad_norm 0.3514 (0.3412)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:26:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:01:54 lr 0.000022	 wd 0.0000	time 0.1746 (0.2274)	loss 0.9165 (0.8830)	grad_norm 0.3326 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7655MB
[2024-08-01 12:26:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:30 lr 0.000022	 wd 0.0000	time 0.1899 (0.2261)	loss 0.9297 (0.8835)	grad_norm 0.3480 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7655MB
[2024-08-01 12:26:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:07 lr 0.000022	 wd 0.0000	time 0.1999 (0.2249)	loss 0.8999 (0.8840)	grad_norm 0.3464 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7655MB
[2024-08-01 12:27:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:45 lr 0.000022	 wd 0.0000	time 0.2050 (0.2240)	loss 0.8164 (0.8848)	grad_norm 0.3592 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7655MB
[2024-08-01 12:27:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:22 lr 0.000022	 wd 0.0000	time 0.1770 (0.2244)	loss 0.8521 (0.8850)	grad_norm 0.3436 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7655MB
[2024-08-01 12:27:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1520 (0.2226)	loss 0.7939 (0.8849)	grad_norm 0.3264 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7655MB
[2024-08-01 12:28:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 20 training takes 0:09:27
[2024-08-01 12:28:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 18.864 (18.864)	Loss 0.3586 (0.3586)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 12:28:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 85.150 Acc@5 97.610
[2024-08-01 12:28:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 12:28:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.15%
[2024-08-01 12:28:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saving......
[2024-08-01 12:28:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saved !!!
[2024-08-01 12:29:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][0/2502]	eta 1 day, 1:40:19 lr 0.000021	 wd 0.0000	time 36.9382 (36.9382)	loss 0.9248 (0.9248)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:29:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:22:20 lr 0.000021	 wd 0.0000	time 0.1701 (0.5583)	loss 0.9126 (0.8969)	grad_norm 0.3344 (0.3415)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:29:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:14:27 lr 0.000021	 wd 0.0000	time 0.2011 (0.3767)	loss 0.9297 (0.8900)	grad_norm 0.3312 (0.3413)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:30:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:11:35 lr 0.000021	 wd 0.0000	time 0.2141 (0.3157)	loss 0.9243 (0.8877)	grad_norm 0.3398 (0.3418)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:30:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:11:18 lr 0.000021	 wd 0.0000	time 0.2168 (0.3226)	loss 1.0000 (0.8879)	grad_norm 0.3368 (0.3416)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:31:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:09:57 lr 0.000021	 wd 0.0000	time 0.1979 (0.2985)	loss 0.8267 (0.8882)	grad_norm 0.3359 (0.3419)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:31:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:54 lr 0.000020	 wd 0.0000	time 0.1833 (0.2809)	loss 0.8906 (0.8872)	grad_norm 0.3441 (0.3423)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:31:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:08:03 lr 0.000020	 wd 0.0000	time 0.2040 (0.2681)	loss 1.0049 (0.8874)	grad_norm 0.3532 (0.3422)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:32:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:27 lr 0.000020	 wd 0.0000	time 0.2531 (0.2627)	loss 0.9199 (0.8875)	grad_norm 0.3587 (0.3422)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:32:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:54 lr 0.000020	 wd 0.0000	time 0.2068 (0.2587)	loss 0.8423 (0.8886)	grad_norm 0.3326 (0.3420)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:32:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:19 lr 0.000020	 wd 0.0000	time 0.1652 (0.2525)	loss 0.8481 (0.8880)	grad_norm 0.3206 (0.3420)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:33:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:05:46 lr 0.000020	 wd 0.0000	time 0.1700 (0.2475)	loss 0.9048 (0.8884)	grad_norm 0.3366 (0.3421)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:33:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:17 lr 0.000019	 wd 0.0000	time 0.1934 (0.2436)	loss 0.8560 (0.8897)	grad_norm 0.3419 (0.3421)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:33:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:52 lr 0.000019	 wd 0.0000	time 0.1561 (0.2432)	loss 0.9668 (0.8892)	grad_norm 0.3300 (0.3420)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:34:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:25 lr 0.000019	 wd 0.0000	time 0.2099 (0.2405)	loss 0.9033 (0.8892)	grad_norm 0.3354 (0.3419)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:34:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:03:58 lr 0.000019	 wd 0.0000	time 0.1834 (0.2377)	loss 0.9136 (0.8889)	grad_norm 0.3338 (0.3418)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:34:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:32 lr 0.000019	 wd 0.0000	time 0.1908 (0.2351)	loss 0.9170 (0.8882)	grad_norm 0.3540 (0.3419)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:35:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:07 lr 0.000019	 wd 0.0000	time 0.1838 (0.2332)	loss 0.8833 (0.8888)	grad_norm 0.3401 (0.3420)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:35:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:43 lr 0.000018	 wd 0.0000	time 0.1808 (0.2332)	loss 0.8970 (0.8887)	grad_norm 0.3448 (0.3421)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:35:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:19 lr 0.000018	 wd 0.0000	time 0.1952 (0.2319)	loss 0.9077 (0.8888)	grad_norm 0.3412 (0.3422)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:36:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:55 lr 0.000018	 wd 0.0000	time 0.1823 (0.2302)	loss 0.7598 (0.8886)	grad_norm 0.3487 (0.3423)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:36:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:31 lr 0.000018	 wd 0.0000	time 0.1938 (0.2287)	loss 0.7671 (0.8881)	grad_norm 0.3282 (0.3424)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:37:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:08 lr 0.000018	 wd 0.0000	time 0.2282 (0.2280)	loss 0.7944 (0.8874)	grad_norm 0.3449 (0.3424)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:37:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:46 lr 0.000018	 wd 0.0000	time 0.2270 (0.2283)	loss 0.9424 (0.8874)	grad_norm 0.3409 (0.3424)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:37:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:23 lr 0.000018	 wd 0.0000	time 0.2028 (0.2272)	loss 0.8740 (0.8874)	grad_norm 0.3377 (0.3426)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:38:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000017	 wd 0.0000	time 0.1588 (0.2252)	loss 0.9111 (0.8876)	grad_norm 0.3182 (0.3425)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:38:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 21 training takes 0:09:31
[2024-08-01 12:38:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 29.782 (29.782)	Loss 0.3567 (0.3567)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 12:39:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 85.172 Acc@5 97.604
[2024-08-01 12:39:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 12:39:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.17%
[2024-08-01 12:39:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saving......
[2024-08-01 12:39:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth saved !!!
[2024-08-01 12:39:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][0/2502]	eta 11:03:37 lr 0.000017	 wd 0.0000	time 15.9141 (15.9141)	loss 0.8540 (0.8540)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:39:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:14:02 lr 0.000017	 wd 0.0000	time 0.1761 (0.3508)	loss 0.9263 (0.8914)	grad_norm 0.3478 (0.3438)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:40:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:10:36 lr 0.000017	 wd 0.0000	time 0.1893 (0.2764)	loss 0.8003 (0.8872)	grad_norm 0.3320 (0.3429)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:40:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:10:23 lr 0.000017	 wd 0.0000	time 0.2057 (0.2832)	loss 0.8789 (0.8866)	grad_norm 0.3380 (0.3432)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:40:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:09:09 lr 0.000017	 wd 0.0000	time 0.1761 (0.2613)	loss 0.8179 (0.8916)	grad_norm 0.3381 (0.3435)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:41:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:08:15 lr 0.000017	 wd 0.0000	time 0.1888 (0.2474)	loss 0.7080 (0.8896)	grad_norm 0.3314 (0.3432)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:41:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:07:33 lr 0.000016	 wd 0.0000	time 0.1712 (0.2384)	loss 0.9395 (0.8907)	grad_norm 0.3242 (0.3433)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:41:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:10 lr 0.000016	 wd 0.0000	time 0.3851 (0.2392)	loss 0.9888 (0.8892)	grad_norm 0.3346 (0.3437)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:42:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:06:51 lr 0.000016	 wd 0.0000	time 0.1830 (0.2416)	loss 0.8931 (0.8892)	grad_norm 0.3396 (0.3436)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:42:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:18 lr 0.000016	 wd 0.0000	time 0.1899 (0.2366)	loss 0.8472 (0.8893)	grad_norm 0.3307 (0.3438)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:42:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:05:49 lr 0.000016	 wd 0.0000	time 0.1933 (0.2324)	loss 0.9121 (0.8889)	grad_norm 0.3289 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7655MB
[2024-08-01 12:43:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:22 lr 0.000016	 wd 0.0000	time 0.2104 (0.2303)	loss 0.7866 (0.8875)	grad_norm 0.3291 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7655MB
[2024-08-01 12:43:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:04:59 lr 0.000016	 wd 0.0000	time 0.2459 (0.2300)	loss 0.8574 (0.8878)	grad_norm 0.3421 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7655MB
[2024-08-01 12:44:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:04:34 lr 0.000015	 wd 0.0000	time 0.1933 (0.2280)	loss 0.8843 (0.8865)	grad_norm 0.3396 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7655MB
[2024-08-01 12:44:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:08 lr 0.000015	 wd 0.0000	time 0.2105 (0.2258)	loss 0.8828 (0.8864)	grad_norm 0.3403 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7655MB
[2024-08-01 12:44:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:03:44 lr 0.000015	 wd 0.0000	time 0.1752 (0.2238)	loss 0.6948 (0.8864)	grad_norm 0.3374 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7655MB
[2024-08-01 12:45:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:21 lr 0.000015	 wd 0.0000	time 0.2102 (0.2230)	loss 0.8511 (0.8867)	grad_norm 0.3472 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7655MB
[2024-08-01 12:45:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:02:59 lr 0.000015	 wd 0.0000	time 0.2034 (0.2236)	loss 0.9033 (0.8862)	grad_norm 0.3462 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7655MB
[2024-08-01 12:45:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:35 lr 0.000015	 wd 0.0000	time 0.1692 (0.2222)	loss 0.9521 (0.8861)	grad_norm 0.3389 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7655MB
[2024-08-01 12:46:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:13 lr 0.000015	 wd 0.0000	time 0.1851 (0.2210)	loss 0.9009 (0.8867)	grad_norm 0.3396 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7655MB
[2024-08-01 12:46:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:50 lr 0.000014	 wd 0.0000	time 0.2214 (0.2200)	loss 0.9731 (0.8864)	grad_norm 0.3188 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7655MB
[2024-08-01 12:46:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:28 lr 0.000014	 wd 0.0000	time 0.1694 (0.2207)	loss 0.8364 (0.8868)	grad_norm 0.3408 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7655MB
[2024-08-01 12:47:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:06 lr 0.000014	 wd 0.0000	time 0.1679 (0.2205)	loss 0.6909 (0.8867)	grad_norm 0.3417 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7655MB
[2024-08-01 12:47:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:44 lr 0.000014	 wd 0.0000	time 0.2197 (0.2196)	loss 0.9512 (0.8866)	grad_norm 0.3447 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7655MB
[2024-08-01 12:47:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:22 lr 0.000014	 wd 0.0000	time 0.1841 (0.2187)	loss 0.7695 (0.8868)	grad_norm 0.3460 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7655MB
[2024-08-01 12:48:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1579 (0.2171)	loss 0.8467 (0.8863)	grad_norm 0.3560 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7655MB
[2024-08-01 12:48:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 22 training takes 0:09:10
[2024-08-01 12:48:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 38.121 (38.121)	Loss 0.3569 (0.3569)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 12:49:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 85.140 Acc@5 97.616
[2024-08-01 12:49:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-08-01 12:49:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.17%
[2024-08-01 12:49:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][0/2502]	eta 10:49:16 lr 0.000014	 wd 0.0000	time 15.5703 (15.5703)	loss 0.7808 (0.7808)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:49:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:15:27 lr 0.000014	 wd 0.0000	time 0.2302 (0.3859)	loss 0.8809 (0.8848)	grad_norm 0.3425 (0.3453)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:50:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:12:13 lr 0.000013	 wd 0.0000	time 0.2169 (0.3185)	loss 0.9385 (0.8816)	grad_norm 0.3658 (0.3443)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:50:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:10:09 lr 0.000013	 wd 0.0000	time 0.1814 (0.2767)	loss 0.7793 (0.8800)	grad_norm 0.3363 (0.3443)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:50:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:08:58 lr 0.000013	 wd 0.0000	time 0.1726 (0.2560)	loss 1.0010 (0.8818)	grad_norm 0.3421 (0.3449)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:51:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:08:08 lr 0.000013	 wd 0.0000	time 0.1948 (0.2438)	loss 0.9038 (0.8859)	grad_norm 0.3330 (0.3450)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:51:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:08:01 lr 0.000013	 wd 0.0000	time 0.1970 (0.2532)	loss 0.9033 (0.8872)	grad_norm 0.3470 (0.3451)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:52:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:22 lr 0.000013	 wd 0.0000	time 0.2076 (0.2453)	loss 0.9648 (0.8878)	grad_norm 0.3306 (0.3447)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:52:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:06:46 lr 0.000013	 wd 0.0000	time 0.1919 (0.2389)	loss 0.9927 (0.8874)	grad_norm 0.3467 (0.3445)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:52:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:06:14 lr 0.000012	 wd 0.0000	time 0.1844 (0.2337)	loss 1.1230 (0.8859)	grad_norm 0.3489 (0.3445)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:53:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:05:49 lr 0.000012	 wd 0.0000	time 0.2955 (0.2325)	loss 0.7500 (0.8863)	grad_norm 0.3443 (0.3445)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:53:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:28 lr 0.000012	 wd 0.0000	time 0.1779 (0.2342)	loss 0.7310 (0.8854)	grad_norm 0.3523 (0.3446)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:53:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:00 lr 0.000012	 wd 0.0000	time 0.1846 (0.2311)	loss 0.9468 (0.8857)	grad_norm 0.3294 (0.3446)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:54:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:04:34 lr 0.000012	 wd 0.0000	time 0.1853 (0.2285)	loss 0.9556 (0.8859)	grad_norm 0.3606 (0.3448)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:54:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:09 lr 0.000012	 wd 0.0000	time 0.2100 (0.2265)	loss 0.9595 (0.8863)	grad_norm 0.3472 (0.3448)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:54:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:03:47 lr 0.000012	 wd 0.0000	time 0.1800 (0.2271)	loss 0.7798 (0.8871)	grad_norm 0.3495 (0.3449)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:55:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:23 lr 0.000012	 wd 0.0000	time 0.1742 (0.2257)	loss 0.9082 (0.8871)	grad_norm 0.3334 (0.3450)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:55:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:02:59 lr 0.000011	 wd 0.0000	time 0.2048 (0.2240)	loss 0.7959 (0.8869)	grad_norm 0.3445 (0.3451)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:55:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:36 lr 0.000011	 wd 0.0000	time 0.1727 (0.2225)	loss 0.9116 (0.8871)	grad_norm 0.3365 (0.3451)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:56:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:13 lr 0.000011	 wd 0.0000	time 0.2065 (0.2216)	loss 0.8027 (0.8866)	grad_norm 0.3400 (0.3450)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:56:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:01:51 lr 0.000011	 wd 0.0000	time 0.1667 (0.2225)	loss 0.9927 (0.8865)	grad_norm 0.3390 (0.3450)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:56:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:29 lr 0.000011	 wd 0.0000	time 0.1910 (0.2216)	loss 1.0225 (0.8865)	grad_norm 0.3179 (0.3449)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:57:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:06 lr 0.000011	 wd 0.0000	time 0.1909 (0.2206)	loss 0.9697 (0.8860)	grad_norm 0.3563 (0.3448)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:57:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:44 lr 0.000011	 wd 0.0000	time 0.1824 (0.2196)	loss 0.8662 (0.8862)	grad_norm 0.3437 (0.3448)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:57:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:22 lr 0.000011	 wd 0.0000	time 0.1965 (0.2193)	loss 0.9043 (0.8863)	grad_norm 0.3399 (0.3448)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 12:58:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1580 (0.2183)	loss 0.8159 (0.8861)	grad_norm 0.3503 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7655MB
[2024-08-01 12:58:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 23 training takes 0:09:18
[2024-08-01 12:58:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 20.493 (20.493)	Loss 0.3572 (0.3572)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 12:59:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 85.170 Acc@5 97.610
[2024-08-01 12:59:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 12:59:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.17%
[2024-08-01 12:59:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][0/2502]	eta 1 day, 0:35:19 lr 0.000010	 wd 0.0000	time 35.3794 (35.3794)	loss 0.8872 (0.8872)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:00:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:22:23 lr 0.000010	 wd 0.0000	time 0.1723 (0.5594)	loss 0.9966 (0.8822)	grad_norm 0.3273 (0.3457)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:00:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:14:27 lr 0.000010	 wd 0.0000	time 0.1891 (0.3767)	loss 0.9072 (0.8842)	grad_norm 0.3513 (0.3450)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:00:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:11:33 lr 0.000010	 wd 0.0000	time 0.1981 (0.3151)	loss 0.8159 (0.8869)	grad_norm 0.3695 (0.3451)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:01:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:10:22 lr 0.000010	 wd 0.0000	time 0.3806 (0.2963)	loss 0.7437 (0.8882)	grad_norm 0.3399 (0.3452)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:01:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:10:05 lr 0.000010	 wd 0.0000	time 0.1750 (0.3026)	loss 0.8984 (0.8901)	grad_norm 0.3882 (0.3454)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:02:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:09:01 lr 0.000010	 wd 0.0000	time 0.1917 (0.2849)	loss 0.9004 (0.8877)	grad_norm 0.3284 (0.3459)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:02:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:08:09 lr 0.000010	 wd 0.0000	time 0.1521 (0.2716)	loss 0.8481 (0.8869)	grad_norm 0.3368 (0.3455)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:02:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:07:29 lr 0.000010	 wd 0.0000	time 0.2237 (0.2642)	loss 0.8086 (0.8862)	grad_norm 0.3524 (0.3453)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:03:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:06:55 lr 0.000009	 wd 0.0000	time 0.1820 (0.2592)	loss 0.9541 (0.8869)	grad_norm 0.3468 (0.3452)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:03:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:20 lr 0.000009	 wd 0.0000	time 0.1838 (0.2534)	loss 0.8198 (0.8878)	grad_norm 0.3495 (0.3452)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:03:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:05:48 lr 0.000009	 wd 0.0000	time 0.1885 (0.2485)	loss 0.8306 (0.8876)	grad_norm 0.3420 (0.3456)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:04:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:17 lr 0.000009	 wd 0.0000	time 0.1804 (0.2441)	loss 0.8418 (0.8872)	grad_norm 0.3199 (0.3456)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:04:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:04:51 lr 0.000009	 wd 0.0000	time 0.1871 (0.2426)	loss 0.7456 (0.8858)	grad_norm 0.3485 (0.3455)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:04:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:25 lr 0.000009	 wd 0.0000	time 0.1749 (0.2414)	loss 0.7954 (0.8861)	grad_norm 0.3370 (0.3456)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:05:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:03:58 lr 0.000009	 wd 0.0000	time 0.1809 (0.2385)	loss 0.8418 (0.8861)	grad_norm 0.3401 (0.3455)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:05:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:32 lr 0.000009	 wd 0.0000	time 0.1748 (0.2358)	loss 0.8975 (0.8861)	grad_norm 0.3373 (0.3456)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:05:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:07 lr 0.000008	 wd 0.0000	time 0.1880 (0.2336)	loss 0.9839 (0.8865)	grad_norm 0.3475 (0.3456)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:06:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:43 lr 0.000008	 wd 0.0000	time 0.1655 (0.2336)	loss 0.7944 (0.8868)	grad_norm 0.3360 (0.3455)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:06:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:19 lr 0.000008	 wd 0.0000	time 0.1970 (0.2321)	loss 0.7456 (0.8865)	grad_norm 0.3309 (0.3456)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:06:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:01:55 lr 0.000008	 wd 0.0000	time 0.1920 (0.2305)	loss 0.7217 (0.8864)	grad_norm 0.3453 (0.3457)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:07:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:32 lr 0.000008	 wd 0.0000	time 0.1987 (0.2290)	loss 0.9868 (0.8861)	grad_norm 0.3553 (0.3457)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:07:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:08 lr 0.000008	 wd 0.0000	time 0.2084 (0.2279)	loss 0.8779 (0.8860)	grad_norm 0.3420 (0.3457)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:07:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:46 lr 0.000008	 wd 0.0000	time 0.1930 (0.2279)	loss 0.9316 (0.8862)	grad_norm 0.3285 (0.3456)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:08:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:23 lr 0.000008	 wd 0.0000	time 0.1975 (0.2270)	loss 1.0713 (0.8860)	grad_norm 0.3397 (0.3456)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:08:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1539 (0.2250)	loss 0.9976 (0.8858)	grad_norm 0.3368 (0.3456)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:08:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 24 training takes 0:09:31
[2024-08-01 13:09:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 31.581 (31.581)	Loss 0.3577 (0.3577)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 13:09:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 85.162 Acc@5 97.612
[2024-08-01 13:09:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 13:09:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.17%
[2024-08-01 13:09:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][0/2502]	eta 11:32:27 lr 0.000008	 wd 0.0000	time 16.6057 (16.6057)	loss 0.8867 (0.8867)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:10:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:14:32 lr 0.000008	 wd 0.0000	time 0.2020 (0.3630)	loss 0.8418 (0.8995)	grad_norm 0.3339 (0.3475)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:10:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:10:45 lr 0.000007	 wd 0.0000	time 0.1909 (0.2804)	loss 0.8242 (0.8964)	grad_norm 0.3467 (0.3466)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:11:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:11:01 lr 0.000007	 wd 0.0000	time 0.2227 (0.3005)	loss 0.9009 (0.8890)	grad_norm 0.3453 (0.3466)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:11:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:09:40 lr 0.000007	 wd 0.0000	time 0.1827 (0.2761)	loss 0.7471 (0.8901)	grad_norm 0.3480 (0.3468)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:11:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:08:38 lr 0.000007	 wd 0.0000	time 0.2154 (0.2591)	loss 0.8774 (0.8895)	grad_norm 0.3296 (0.3465)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:12:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:07:51 lr 0.000007	 wd 0.0000	time 0.1787 (0.2478)	loss 0.7471 (0.8890)	grad_norm 0.3555 (0.3464)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:12:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:07:21 lr 0.000007	 wd 0.0000	time 0.2077 (0.2450)	loss 0.8472 (0.8881)	grad_norm 0.3483 (0.3464)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:12:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:06:51 lr 0.000007	 wd 0.0000	time 0.1733 (0.2419)	loss 0.9976 (0.8876)	grad_norm 0.3473 (0.3463)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:13:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:06:19 lr 0.000007	 wd 0.0000	time 0.1746 (0.2368)	loss 0.7329 (0.8874)	grad_norm 0.3426 (0.3462)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:13:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:05:49 lr 0.000007	 wd 0.0000	time 0.2021 (0.2330)	loss 0.9468 (0.8880)	grad_norm 0.3660 (0.3465)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:13:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:22 lr 0.000007	 wd 0.0000	time 0.2061 (0.2302)	loss 1.0234 (0.8874)	grad_norm 0.3469 (0.3465)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:14:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:01 lr 0.000006	 wd 0.0000	time 0.1583 (0.2313)	loss 1.0107 (0.8883)	grad_norm 0.3492 (0.3463)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:14:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:04:35 lr 0.000006	 wd 0.0000	time 0.1930 (0.2291)	loss 0.8926 (0.8872)	grad_norm 0.3296 (0.3463)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:14:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:10 lr 0.000006	 wd 0.0000	time 0.1841 (0.2269)	loss 0.9492 (0.8869)	grad_norm 0.3331 (0.3462)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:15:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:03:45 lr 0.000006	 wd 0.0000	time 0.1882 (0.2248)	loss 0.9839 (0.8878)	grad_norm 0.3401 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7655MB
[2024-08-01 13:15:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:21 lr 0.000006	 wd 0.0000	time 0.2106 (0.2238)	loss 0.7612 (0.8873)	grad_norm 0.3352 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7655MB
[2024-08-01 13:16:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:00 lr 0.000006	 wd 0.0000	time 0.2436 (0.2245)	loss 0.8213 (0.8881)	grad_norm 0.3376 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7655MB
[2024-08-01 13:16:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:36 lr 0.000006	 wd 0.0000	time 0.1817 (0.2233)	loss 0.9219 (0.8876)	grad_norm 0.3260 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7655MB
[2024-08-01 13:16:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:13 lr 0.000006	 wd 0.0000	time 0.1868 (0.2221)	loss 1.0049 (0.8876)	grad_norm 0.3403 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7655MB
[2024-08-01 13:17:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:01:50 lr 0.000006	 wd 0.0000	time 0.2088 (0.2208)	loss 1.0420 (0.8876)	grad_norm 0.3417 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7655MB
[2024-08-01 13:17:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:28 lr 0.000006	 wd 0.0000	time 0.2035 (0.2203)	loss 0.9058 (0.8870)	grad_norm 0.3362 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7655MB
[2024-08-01 13:17:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:06 lr 0.000006	 wd 0.0000	time 0.1919 (0.2212)	loss 0.8438 (0.8867)	grad_norm 0.3234 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7655MB
[2024-08-01 13:18:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:44 lr 0.000005	 wd 0.0000	time 0.1878 (0.2202)	loss 0.7944 (0.8865)	grad_norm 0.3420 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7655MB
[2024-08-01 13:18:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:22 lr 0.000005	 wd 0.0000	time 0.1743 (0.2193)	loss 0.8330 (0.8865)	grad_norm 0.3310 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7655MB
[2024-08-01 13:18:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000005	 wd 0.0000	time 0.1602 (0.2177)	loss 0.8975 (0.8869)	grad_norm 0.3490 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7655MB
[2024-08-01 13:18:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 25 training takes 0:09:12
[2024-08-01 13:19:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 40.768 (40.768)	Loss 0.3579 (0.3579)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 13:19:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 85.128 Acc@5 97.618
[2024-08-01 13:19:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-08-01 13:19:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.17%
[2024-08-01 13:20:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][0/2502]	eta 11:41:47 lr 0.000005	 wd 0.0000	time 16.8295 (16.8295)	loss 1.0303 (1.0303)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:20:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:16:56 lr 0.000005	 wd 0.0000	time 0.3299 (0.4233)	loss 0.7930 (0.8955)	grad_norm 0.3386 (0.3502)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:21:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:13:08 lr 0.000005	 wd 0.0000	time 0.1718 (0.3426)	loss 0.8706 (0.8919)	grad_norm 0.3551 (0.3486)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:21:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:10:44 lr 0.000005	 wd 0.0000	time 0.1646 (0.2928)	loss 0.8892 (0.8929)	grad_norm 0.3608 (0.3482)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:21:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:09:22 lr 0.000005	 wd 0.0000	time 0.1719 (0.2677)	loss 0.9077 (0.8902)	grad_norm 0.3478 (0.3475)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:21:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:08:29 lr 0.000005	 wd 0.0000	time 0.1962 (0.2543)	loss 0.8223 (0.8882)	grad_norm 0.3262 (0.3471)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:22:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:08:20 lr 0.000005	 wd 0.0000	time 0.2093 (0.2631)	loss 0.8662 (0.8890)	grad_norm 0.3441 (0.3472)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:22:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:36 lr 0.000005	 wd 0.0000	time 0.1777 (0.2535)	loss 0.8311 (0.8869)	grad_norm 0.3357 (0.3469)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:23:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:06:58 lr 0.000005	 wd 0.0000	time 0.1846 (0.2461)	loss 0.8711 (0.8880)	grad_norm 0.3573 (0.3468)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:23:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:06:25 lr 0.000005	 wd 0.0000	time 0.2274 (0.2409)	loss 0.7925 (0.8864)	grad_norm 0.3505 (0.3470)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:23:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:00 lr 0.000004	 wd 0.0000	time 0.1957 (0.2398)	loss 0.9438 (0.8868)	grad_norm 0.3359 (0.3470)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:24:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:34 lr 0.000004	 wd 0.0000	time 0.2115 (0.2386)	loss 0.9775 (0.8877)	grad_norm 0.3361 (0.3469)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:24:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:06 lr 0.000004	 wd 0.0000	time 0.1769 (0.2351)	loss 0.9033 (0.8874)	grad_norm 0.3423 (0.3469)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:24:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:04:38 lr 0.000004	 wd 0.0000	time 0.1914 (0.2321)	loss 0.7646 (0.8877)	grad_norm 0.3396 (0.3469)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:25:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:13 lr 0.000004	 wd 0.0000	time 0.2061 (0.2303)	loss 0.9878 (0.8874)	grad_norm 0.3426 (0.3470)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:25:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:03:51 lr 0.000004	 wd 0.0000	time 0.1971 (0.2306)	loss 0.8667 (0.8877)	grad_norm 0.3402 (0.3470)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:25:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:26 lr 0.000004	 wd 0.0000	time 0.2372 (0.2288)	loss 0.7388 (0.8866)	grad_norm 0.3211 (0.3470)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:26:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:02 lr 0.000004	 wd 0.0000	time 0.1859 (0.2270)	loss 0.8564 (0.8874)	grad_norm 0.3336 (0.3469)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:26:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:38 lr 0.000004	 wd 0.0000	time 0.2018 (0.2253)	loss 0.9380 (0.8879)	grad_norm 0.3418 (0.3469)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:26:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:15 lr 0.000004	 wd 0.0000	time 0.1918 (0.2246)	loss 0.8843 (0.8873)	grad_norm 0.3407 (0.3468)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:27:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:01:53 lr 0.000004	 wd 0.0000	time 0.1731 (0.2255)	loss 0.9517 (0.8872)	grad_norm 0.3492 (0.3468)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:27:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:30 lr 0.000004	 wd 0.0000	time 0.1710 (0.2244)	loss 0.8916 (0.8875)	grad_norm 0.3540 (0.3469)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:28:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:07 lr 0.000004	 wd 0.0000	time 0.1929 (0.2232)	loss 0.9458 (0.8875)	grad_norm 0.3487 (0.3468)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:28:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:44 lr 0.000004	 wd 0.0000	time 0.2077 (0.2223)	loss 0.8535 (0.8871)	grad_norm 0.3541 (0.3468)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:28:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:22 lr 0.000003	 wd 0.0000	time 0.1830 (0.2226)	loss 0.8857 (0.8875)	grad_norm 0.3546 (0.3469)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:29:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1637 (0.2210)	loss 0.9409 (0.8876)	grad_norm 0.3446 (0.3469)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:29:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 26 training takes 0:09:23
[2024-08-01 13:29:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 22.514 (22.514)	Loss 0.3572 (0.3572)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 13:29:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 85.146 Acc@5 97.618
[2024-08-01 13:29:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-08-01 13:29:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.17%
[2024-08-01 13:30:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][0/2502]	eta 21:04:02 lr 0.000003	 wd 0.0000	time 30.3127 (30.3127)	loss 0.9448 (0.9448)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:30:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:20:40 lr 0.000003	 wd 0.0000	time 0.2010 (0.5164)	loss 0.8901 (0.8928)	grad_norm 0.3441 (0.3465)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:31:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:13:38 lr 0.000003	 wd 0.0000	time 0.1964 (0.3556)	loss 0.7319 (0.8867)	grad_norm 0.3563 (0.3465)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:31:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:11:03 lr 0.000003	 wd 0.0000	time 0.1720 (0.3014)	loss 0.9043 (0.8869)	grad_norm 0.3593 (0.3470)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:31:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:09:47 lr 0.000003	 wd 0.0000	time 0.2624 (0.2796)	loss 0.8262 (0.8862)	grad_norm 0.3417 (0.3472)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:32:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:09:18 lr 0.000003	 wd 0.0000	time 0.1755 (0.2789)	loss 0.7446 (0.8854)	grad_norm 0.3741 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7655MB
[2024-08-01 13:32:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:23 lr 0.000003	 wd 0.0000	time 0.1660 (0.2646)	loss 0.8237 (0.8876)	grad_norm 0.3555 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7655MB
[2024-08-01 13:32:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:38 lr 0.000003	 wd 0.0000	time 0.1828 (0.2543)	loss 0.8320 (0.8873)	grad_norm 0.3622 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7655MB
[2024-08-01 13:33:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:00 lr 0.000003	 wd 0.0000	time 0.2116 (0.2472)	loss 0.9043 (0.8866)	grad_norm 0.3397 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7655MB
[2024-08-01 13:33:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:51 lr 0.000003	 wd 0.0000	time 0.2238 (0.2569)	loss 0.7476 (0.8862)	grad_norm 0.3358 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7655MB
[2024-08-01 13:34:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:16 lr 0.000003	 wd 0.0000	time 0.1939 (0.2510)	loss 0.8931 (0.8857)	grad_norm 0.3358 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7655MB
[2024-08-01 13:34:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:44 lr 0.000003	 wd 0.0000	time 0.1784 (0.2459)	loss 0.7769 (0.8856)	grad_norm 0.3525 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7655MB
[2024-08-01 13:34:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:14 lr 0.000003	 wd 0.0000	time 0.1948 (0.2414)	loss 0.8994 (0.8846)	grad_norm 0.3427 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7655MB
[2024-08-01 13:35:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:50 lr 0.000003	 wd 0.0000	time 0.3440 (0.2420)	loss 0.8643 (0.8847)	grad_norm 0.3510 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7655MB
[2024-08-01 13:35:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:28 lr 0.000003	 wd 0.0000	time 0.1786 (0.2440)	loss 0.8047 (0.8846)	grad_norm 0.3465 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7655MB
[2024-08-01 13:35:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:04:01 lr 0.000003	 wd 0.0000	time 0.1731 (0.2408)	loss 0.9951 (0.8847)	grad_norm 0.3408 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7655MB
[2024-08-01 13:36:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:34 lr 0.000003	 wd 0.0000	time 0.1707 (0.2380)	loss 0.8896 (0.8847)	grad_norm 0.3412 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7655MB
[2024-08-01 13:36:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:09 lr 0.000002	 wd 0.0000	time 0.2031 (0.2362)	loss 0.8911 (0.8848)	grad_norm 0.3476 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7655MB
[2024-08-01 13:36:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:45 lr 0.000002	 wd 0.0000	time 0.2136 (0.2358)	loss 0.7759 (0.8852)	grad_norm 0.3457 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7655MB
[2024-08-01 13:37:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:20 lr 0.000002	 wd 0.0000	time 0.1749 (0.2341)	loss 0.8179 (0.8854)	grad_norm 0.3408 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7655MB
[2024-08-01 13:37:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:56 lr 0.000002	 wd 0.0000	time 0.1848 (0.2324)	loss 0.7598 (0.8851)	grad_norm 0.3279 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7655MB
[2024-08-01 13:37:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:32 lr 0.000002	 wd 0.0000	time 0.1780 (0.2307)	loss 1.0293 (0.8861)	grad_norm 0.3618 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7655MB
[2024-08-01 13:38:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:09 lr 0.000002	 wd 0.0000	time 0.1858 (0.2299)	loss 0.7437 (0.8856)	grad_norm 0.3436 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7655MB
[2024-08-01 13:38:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:46 lr 0.000002	 wd 0.0000	time 0.2196 (0.2303)	loss 0.8403 (0.8860)	grad_norm 0.3475 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7655MB
[2024-08-01 13:39:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:23 lr 0.000002	 wd 0.0000	time 0.1629 (0.2290)	loss 0.9062 (0.8856)	grad_norm 0.3560 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7655MB
[2024-08-01 13:39:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1538 (0.2270)	loss 0.8647 (0.8858)	grad_norm 0.3402 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7655MB
[2024-08-01 13:39:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 27 training takes 0:09:37
[2024-08-01 13:40:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 41.368 (41.368)	Loss 0.3574 (0.3574)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 13:40:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 85.168 Acc@5 97.616
[2024-08-01 13:40:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 13:40:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.17%
[2024-08-01 13:40:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][0/2502]	eta 11:18:22 lr 0.000002	 wd 0.0000	time 16.2679 (16.2679)	loss 0.8574 (0.8574)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:41:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:14:18 lr 0.000002	 wd 0.0000	time 0.1771 (0.3573)	loss 0.8867 (0.8808)	grad_norm 0.3612 (0.3478)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:41:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:11:11 lr 0.000002	 wd 0.0000	time 0.2660 (0.2918)	loss 0.8521 (0.8873)	grad_norm 0.3478 (0.3473)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:41:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:10:31 lr 0.000002	 wd 0.0000	time 0.1689 (0.2869)	loss 0.9819 (0.8887)	grad_norm 0.3474 (0.3472)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:42:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:09:14 lr 0.000002	 wd 0.0000	time 0.1994 (0.2637)	loss 0.7944 (0.8840)	grad_norm 0.3445 (0.3474)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:42:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:08:19 lr 0.000002	 wd 0.0000	time 0.1991 (0.2496)	loss 0.8706 (0.8862)	grad_norm 0.3446 (0.3477)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:42:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:07:37 lr 0.000002	 wd 0.0000	time 0.2001 (0.2407)	loss 0.9297 (0.8876)	grad_norm 0.3459 (0.3472)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:43:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:16 lr 0.000002	 wd 0.0000	time 0.1634 (0.2422)	loss 0.8589 (0.8867)	grad_norm 0.3431 (0.3472)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:43:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:06:43 lr 0.000002	 wd 0.0000	time 0.1983 (0.2369)	loss 0.8486 (0.8877)	grad_norm 0.3413 (0.3473)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:43:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:12 lr 0.000002	 wd 0.0000	time 0.1921 (0.2325)	loss 0.8452 (0.8875)	grad_norm 0.3500 (0.3473)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:44:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:05:43 lr 0.000002	 wd 0.0000	time 0.1811 (0.2289)	loss 0.8613 (0.8874)	grad_norm 0.3321 (0.3473)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:44:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:19 lr 0.000002	 wd 0.0000	time 0.2220 (0.2276)	loss 0.8311 (0.8858)	grad_norm 0.3504 (0.3472)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:45:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:04:56 lr 0.000002	 wd 0.0000	time 0.1559 (0.2276)	loss 0.8833 (0.8859)	grad_norm 0.3539 (0.3474)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:45:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:04:31 lr 0.000002	 wd 0.0000	time 0.1795 (0.2256)	loss 0.9741 (0.8863)	grad_norm 0.3566 (0.3474)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:45:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:06 lr 0.000002	 wd 0.0000	time 0.1825 (0.2238)	loss 0.8057 (0.8856)	grad_norm 0.3536 (0.3473)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:46:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:03:42 lr 0.000002	 wd 0.0000	time 0.1713 (0.2219)	loss 0.7983 (0.8857)	grad_norm 0.3619 (0.3474)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:46:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:19 lr 0.000002	 wd 0.0000	time 0.2063 (0.2215)	loss 1.0244 (0.8860)	grad_norm 0.3577 (0.3473)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:46:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:02:58 lr 0.000001	 wd 0.0000	time 0.1861 (0.2221)	loss 0.9253 (0.8860)	grad_norm 0.3629 (0.3473)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:47:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:34 lr 0.000001	 wd 0.0000	time 0.1969 (0.2207)	loss 0.7734 (0.8856)	grad_norm 0.3638 (0.3474)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:47:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:12 lr 0.000001	 wd 0.0000	time 0.2165 (0.2195)	loss 0.8818 (0.8865)	grad_norm 0.3430 (0.3476)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:47:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:01:49 lr 0.000001	 wd 0.0000	time 0.2109 (0.2186)	loss 0.8037 (0.8856)	grad_norm 0.3414 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7655MB
[2024-08-01 13:48:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:28 lr 0.000001	 wd 0.0000	time 0.1954 (0.2195)	loss 0.8545 (0.8854)	grad_norm 0.3649 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7655MB
[2024-08-01 13:48:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:06 lr 0.000001	 wd 0.0000	time 0.2112 (0.2191)	loss 0.9072 (0.8849)	grad_norm 0.3548 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7655MB
[2024-08-01 13:48:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:44 lr 0.000001	 wd 0.0000	time 0.1777 (0.2181)	loss 0.8149 (0.8847)	grad_norm 0.3401 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7655MB
[2024-08-01 13:49:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:22 lr 0.000001	 wd 0.0000	time 0.1895 (0.2172)	loss 0.9819 (0.8843)	grad_norm 0.3482 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7655MB
[2024-08-01 13:49:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1604 (0.2157)	loss 0.8613 (0.8844)	grad_norm 0.3333 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7655MB
[2024-08-01 13:49:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 28 training takes 0:09:05
[2024-08-01 13:50:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 35.100 (35.100)	Loss 0.3574 (0.3574)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 13:50:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 85.156 Acc@5 97.612
[2024-08-01 13:50:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 13:50:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.17%
[2024-08-01 13:50:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][0/2502]	eta 10:56:00 lr 0.000001	 wd 0.0000	time 15.7316 (15.7316)	loss 0.9639 (0.9639)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:51:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:14:52 lr 0.000001	 wd 0.0000	time 0.2289 (0.3715)	loss 0.8662 (0.8948)	grad_norm 0.3545 (0.3487)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:51:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:11:38 lr 0.000001	 wd 0.0000	time 0.1817 (0.3035)	loss 0.9077 (0.8948)	grad_norm 0.3630 (0.3481)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:51:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:09:49 lr 0.000001	 wd 0.0000	time 0.1646 (0.2676)	loss 0.8481 (0.8944)	grad_norm 0.3469 (0.3471)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:52:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:08:44 lr 0.000001	 wd 0.0000	time 0.1918 (0.2495)	loss 0.8657 (0.8936)	grad_norm 0.3432 (0.3471)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:52:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:07:56 lr 0.000001	 wd 0.0000	time 0.1819 (0.2379)	loss 0.8354 (0.8931)	grad_norm 0.3572 (0.3479)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:53:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:01 lr 0.000001	 wd 0.0000	time 0.2232 (0.2530)	loss 0.7524 (0.8919)	grad_norm 0.3576 (0.3473)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:53:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:23 lr 0.000001	 wd 0.0000	time 0.1968 (0.2463)	loss 0.8613 (0.8909)	grad_norm 0.3351 (0.3475)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:53:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:06:48 lr 0.000001	 wd 0.0000	time 0.1938 (0.2399)	loss 0.8301 (0.8913)	grad_norm 0.3306 (0.3474)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:54:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:06:15 lr 0.000001	 wd 0.0000	time 0.1612 (0.2347)	loss 0.8740 (0.8913)	grad_norm 0.3574 (0.3476)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:54:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:05:49 lr 0.000001	 wd 0.0000	time 0.2079 (0.2325)	loss 0.8286 (0.8917)	grad_norm 0.3598 (0.3475)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:54:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:31 lr 0.000001	 wd 0.0000	time 0.1761 (0.2363)	loss 1.0039 (0.8913)	grad_norm 0.3333 (0.3475)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:55:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:03 lr 0.000001	 wd 0.0000	time 0.1982 (0.2329)	loss 0.7642 (0.8899)	grad_norm 0.3531 (0.3477)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:55:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:04:36 lr 0.000001	 wd 0.0000	time 0.1745 (0.2302)	loss 0.9033 (0.8898)	grad_norm 0.3554 (0.3478)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:55:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:11 lr 0.000001	 wd 0.0000	time 0.1983 (0.2280)	loss 0.9766 (0.8896)	grad_norm 0.3610 (0.3477)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:56:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:03:49 lr 0.000001	 wd 0.0000	time 0.1860 (0.2287)	loss 0.8164 (0.8882)	grad_norm 0.3501 (0.3478)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:56:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:24 lr 0.000001	 wd 0.0000	time 0.1888 (0.2272)	loss 0.9072 (0.8876)	grad_norm 0.3525 (0.3478)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:56:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:00 lr 0.000001	 wd 0.0000	time 0.1976 (0.2254)	loss 0.9243 (0.8865)	grad_norm 0.3575 (0.3477)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:57:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:37 lr 0.000001	 wd 0.0000	time 0.1776 (0.2238)	loss 0.7764 (0.8858)	grad_norm 0.3333 (0.3476)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:57:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:14 lr 0.000001	 wd 0.0000	time 0.1975 (0.2229)	loss 0.7334 (0.8859)	grad_norm 0.3527 (0.3476)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:57:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:01:52 lr 0.000001	 wd 0.0000	time 0.1620 (0.2238)	loss 0.8555 (0.8862)	grad_norm 0.3573 (0.3476)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:58:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:29 lr 0.000001	 wd 0.0000	time 0.1681 (0.2228)	loss 0.8188 (0.8864)	grad_norm 0.3321 (0.3475)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:58:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:06 lr 0.000001	 wd 0.0000	time 0.1970 (0.2218)	loss 0.7822 (0.8858)	grad_norm 0.3429 (0.3476)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:58:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:44 lr 0.000001	 wd 0.0000	time 0.1984 (0.2208)	loss 0.7217 (0.8861)	grad_norm 0.3656 (0.3476)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:59:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:22 lr 0.000001	 wd 0.0000	time 0.1898 (0.2205)	loss 0.7847 (0.8861)	grad_norm 0.3630 (0.3477)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:59:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1584 (0.2196)	loss 0.9570 (0.8858)	grad_norm 0.3529 (0.3477)	loss_scale 32768.0000 (32768.0000)	mem 7655MB
[2024-08-01 13:59:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 249): INFO EPOCH 29 training takes 0:09:21
[2024-08-01 13:59:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_29.pth saving......
[2024-08-01 13:59:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_29.pth saved !!!
[2024-08-01 14:00:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 289): INFO Test: [0/98]	Time 17.620 (17.620)	Loss 0.3579 (0.3579)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 7655MB
[2024-08-01 14:00:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 296): INFO  * Acc@1 85.164 Acc@5 97.610
[2024-08-01 14:00:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 14:00:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 182): INFO Max accuracy: 85.17%
[2024-08-01 14:00:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0] (main.py 189): INFO Training time 5:05:45
