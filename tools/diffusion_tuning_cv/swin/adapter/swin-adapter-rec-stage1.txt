[2024-07-13 23:09:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/config.json
[2024-07-13 23:09:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_swin_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 9
    - 3
    DIMS:
    - 96
    - 192
    - 384
    - 768
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: false
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: stage2
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_swin_b_22kto1k_step_stag2
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 4.0e-05
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.0e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 4.0e-08
  WEIGHT_DECAY: 1.0e-08

[2024-07-13 23:09:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/swin/diffusion_ft_adapter_swin_base_patch4_window7_224_22kto1k_step_stage_process2.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_adapter_swin_b_22kto1k_step_stag2", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-13 23:10:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 108): INFO Creating model:adapter_swin_diffusion_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2
[2024-07-13 23:10:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 110): INFO Adapter_SwinTransformer_Diffusion_Finetune(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (uma): UMA(filter_strategy1=23, filter_strategy2=7,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-13 23:10:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 113): INFO number of params: 3397864
[2024-07-13 23:10:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 116): INFO number of GFLOPs: 15.438473216
[2024-07-13 23:10:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 150): INFO no checkpoint found in pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2, ignoring auto resume
[2024-07-13 23:10:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth for fine-tuning......
[2024-07-13 23:10:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])
[2024-07-13 23:10:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth'
[2024-07-13 23:11:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 68.850 (68.850)	Loss 0.4150 (0.4150)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 1484MB
[2024-07-13 23:11:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 83.798 Acc@5 97.154
[2024-07-13 23:11:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 162): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 23:11:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 168): INFO Start training
[2024-07-13 23:11:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][0/2502]	eta 14:10:04 lr 0.000000	 wd 0.0000	time 20.3855 (20.3855)	loss 1.6337 (1.6337)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 5242MB
[2024-07-13 23:12:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:20:11 lr 0.000000	 wd 0.0000	time 0.4159 (0.5043)	loss 1.4163 (1.4183)	grad_norm 0.4040 (0.4148)	loss_scale 65536.0000 (65536.0000)	mem 5279MB
[2024-07-13 23:12:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:15:16 lr 0.000001	 wd 0.0000	time 0.2253 (0.3979)	loss 1.4519 (1.4025)	grad_norm 0.4173 (nan)	loss_scale 32768.0000 (56406.6070)	mem 5279MB
[2024-07-13 23:13:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:12 lr 0.000001	 wd 0.0000	time 0.1728 (0.3326)	loss 1.4540 (1.3826)	grad_norm 0.4131 (nan)	loss_scale 32768.0000 (48553.2492)	mem 5279MB
[2024-07-13 23:13:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:29 lr 0.000001	 wd 0.0000	time 0.1915 (0.2996)	loss 1.8521 (1.3854)	grad_norm 0.4121 (nan)	loss_scale 32768.0000 (44616.7781)	mem 5279MB
[2024-07-13 23:13:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:09:55 lr 0.000002	 wd 0.0000	time 0.4156 (0.2973)	loss 1.5100 (1.3844)	grad_norm 0.4167 (nan)	loss_scale 32768.0000 (42251.7525)	mem 5279MB
[2024-07-13 23:14:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:18 lr 0.000002	 wd 0.0000	time 0.2097 (0.2935)	loss 1.1910 (1.3844)	grad_norm 0.4063 (nan)	loss_scale 32768.0000 (40673.7571)	mem 5279MB
[2024-07-13 23:14:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:26 lr 0.000002	 wd 0.0000	time 0.2072 (0.2812)	loss 1.4368 (1.3804)	grad_norm 0.3921 (nan)	loss_scale 32768.0000 (39545.9743)	mem 5279MB
[2024-07-13 23:15:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:41 lr 0.000003	 wd 0.0000	time 0.1977 (0.2711)	loss 1.5433 (1.3811)	grad_norm 0.4069 (nan)	loss_scale 32768.0000 (38699.7853)	mem 5279MB
[2024-07-13 23:15:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:09 lr 0.000003	 wd 0.0000	time 0.3392 (0.2679)	loss 1.5706 (1.3761)	grad_norm 0.4300 (nan)	loss_scale 16384.0000 (37386.7969)	mem 5279MB
[2024-07-13 23:15:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:06:43 lr 0.000003	 wd 0.0000	time 0.1974 (0.2683)	loss 1.3609 (1.3758)	grad_norm 0.4554 (nan)	loss_scale 16384.0000 (35288.6154)	mem 5279MB
[2024-07-13 23:16:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:08 lr 0.000004	 wd 0.0000	time 0.2167 (0.2627)	loss 1.5315 (1.3764)	grad_norm 0.3825 (nan)	loss_scale 16384.0000 (33571.5749)	mem 5279MB
[2024-07-13 23:16:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:35 lr 0.000004	 wd 0.0000	time 0.1935 (0.2580)	loss 1.4908 (1.3787)	grad_norm 0.3953 (nan)	loss_scale 16384.0000 (32140.4696)	mem 5279MB
[2024-07-13 23:17:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:06 lr 0.000004	 wd 0.0000	time 0.1873 (0.2547)	loss 1.4571 (1.3807)	grad_norm 0.4305 (nan)	loss_scale 16384.0000 (30929.3651)	mem 5279MB
[2024-07-13 23:17:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:44 lr 0.000005	 wd 0.0000	time 0.1832 (0.2584)	loss 1.5683 (1.3817)	grad_norm 0.4061 (nan)	loss_scale 16384.0000 (29891.1520)	mem 5279MB
[2024-07-13 23:17:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:15 lr 0.000005	 wd 0.0000	time 0.1856 (0.2546)	loss 1.4888 (1.3816)	grad_norm 0.4155 (nan)	loss_scale 16384.0000 (28991.2751)	mem 5279MB
[2024-07-13 23:18:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:46 lr 0.000005	 wd 0.0000	time 0.1841 (0.2516)	loss 1.6088 (1.3822)	grad_norm 0.4137 (nan)	loss_scale 16384.0000 (28203.8126)	mem 5279MB
[2024-07-13 23:18:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:19 lr 0.000005	 wd 0.0000	time 0.2469 (0.2492)	loss 1.5114 (1.3812)	grad_norm 0.4150 (nan)	loss_scale 8192.0000 (27412.6185)	mem 5279MB
[2024-07-13 23:19:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:02:55 lr 0.000006	 wd 0.0000	time 0.2879 (0.2498)	loss 1.2352 (1.3818)	grad_norm 0.4093 (nan)	loss_scale 8192.0000 (26345.3992)	mem 5279MB
[2024-07-13 23:19:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:29 lr 0.000006	 wd 0.0000	time 0.2040 (0.2481)	loss 1.6521 (1.3812)	grad_norm 0.4028 (nan)	loss_scale 8192.0000 (25390.4598)	mem 5279MB
[2024-07-13 23:19:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:03 lr 0.000006	 wd 0.0000	time 0.2121 (0.2460)	loss 1.4964 (1.3792)	grad_norm 0.3928 (nan)	loss_scale 8192.0000 (24530.9665)	mem 5279MB
[2024-07-13 23:20:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:38 lr 0.000007	 wd 0.0000	time 0.2231 (0.2441)	loss 1.3837 (1.3797)	grad_norm 0.4094 (nan)	loss_scale 8192.0000 (23753.2908)	mem 5279MB
[2024-07-13 23:20:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:13 lr 0.000007	 wd 0.0000	time 1.8291 (0.2440)	loss 1.6311 (1.3804)	grad_norm 0.3980 (nan)	loss_scale 8192.0000 (23046.2808)	mem 5279MB
[2024-07-13 23:20:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:49 lr 0.000007	 wd 0.0000	time 0.2419 (0.2429)	loss 1.5383 (1.3791)	grad_norm 0.4152 (nan)	loss_scale 8192.0000 (22400.7232)	mem 5279MB
[2024-07-13 23:21:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:24 lr 0.000008	 wd 0.0000	time 0.2321 (0.2413)	loss 1.4179 (1.3792)	grad_norm 0.3961 (nan)	loss_scale 8192.0000 (21808.9396)	mem 5279MB
[2024-07-13 23:21:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1697 (0.2388)	loss 1.6494 (1.3793)	grad_norm 0.3889 (nan)	loss_scale 8192.0000 (21264.4798)	mem 5279MB
[2024-07-13 23:21:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 0 training takes 0:10:01
[2024-07-13 23:21:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_0.pth saving......
[2024-07-13 23:21:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_0.pth saved !!!
[2024-07-13 23:22:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 62.458 (62.458)	Loss 0.4128 (0.4128)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 5279MB
[2024-07-13 23:22:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 83.862 Acc@5 97.174
[2024-07-13 23:22:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-13 23:22:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 83.86%
[2024-07-13 23:22:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth saving......
[2024-07-13 23:22:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth saved !!!
[2024-07-13 23:23:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][0/2502]	eta 10:21:23 lr 0.000008	 wd 0.0000	time 14.9014 (14.9014)	loss 1.2263 (1.2263)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:23:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:15:36 lr 0.000008	 wd 0.0000	time 0.3742 (0.3901)	loss 1.1639 (1.4165)	grad_norm 0.4145 (0.4297)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:24:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:14:04 lr 0.000009	 wd 0.0000	time 0.1800 (0.3667)	loss 1.3748 (1.4164)	grad_norm 0.4578 (0.4240)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:24:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:23 lr 0.000009	 wd 0.0000	time 0.1844 (0.3102)	loss 1.7005 (1.3953)	grad_norm 0.4107 (0.4218)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:24:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:09:52 lr 0.000009	 wd 0.0000	time 0.1974 (0.2820)	loss 0.9861 (1.3844)	grad_norm 0.3894 (0.4200)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:25:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:09:00 lr 0.000010	 wd 0.0000	time 0.3682 (0.2702)	loss 1.5296 (1.3830)	grad_norm 0.3944 (0.4189)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:25:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:09:05 lr 0.000010	 wd 0.0000	time 0.1750 (0.2871)	loss 1.4408 (1.3825)	grad_norm 0.4371 (0.4188)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:26:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:16 lr 0.000010	 wd 0.0000	time 0.1917 (0.2753)	loss 1.6540 (1.3813)	grad_norm 0.4100 (0.4188)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:26:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:32 lr 0.000011	 wd 0.0000	time 0.1830 (0.2659)	loss 1.5802 (1.3850)	grad_norm 0.3901 (0.4179)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:26:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:06:57 lr 0.000011	 wd 0.0000	time 0.2194 (0.2603)	loss 1.5953 (1.3821)	grad_norm 0.4053 (0.4181)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:27:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:27 lr 0.000011	 wd 0.0000	time 0.1853 (0.2580)	loss 1.6890 (1.3808)	grad_norm 0.4301 (0.4180)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:27:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:05:55 lr 0.000012	 wd 0.0000	time 0.1810 (0.2533)	loss 1.0816 (1.3798)	grad_norm 0.4659 (0.4175)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:27:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:24 lr 0.000012	 wd 0.0000	time 0.1655 (0.2493)	loss 1.3758 (1.3825)	grad_norm 0.3955 (0.4171)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:28:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:04:55 lr 0.000012	 wd 0.0000	time 0.2065 (0.2459)	loss 1.5725 (1.3859)	grad_norm 0.4132 (0.4202)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:28:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:31 lr 0.000012	 wd 0.0000	time 0.1744 (0.2463)	loss 1.4499 (1.3839)	grad_norm 0.4142 (0.4195)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:28:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:04 lr 0.000013	 wd 0.0000	time 0.1823 (0.2442)	loss 0.9783 (1.3821)	grad_norm 0.4164 (0.4189)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:29:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:38 lr 0.000013	 wd 0.0000	time 0.2073 (0.2419)	loss 0.9314 (1.3807)	grad_norm 0.4065 (0.4182)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:29:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:12 lr 0.000013	 wd 0.0000	time 0.2240 (0.2398)	loss 1.3575 (1.3800)	grad_norm 0.4219 (0.4200)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:29:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:47 lr 0.000014	 wd 0.0000	time 0.2162 (0.2386)	loss 1.4573 (1.3801)	grad_norm 0.3786 (0.4201)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:30:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:24 lr 0.000014	 wd 0.0000	time 0.1626 (0.2393)	loss 1.4765 (1.3811)	grad_norm 0.4171 (0.4198)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:30:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:01:59 lr 0.000014	 wd 0.0000	time 0.1830 (0.2376)	loss 1.3406 (1.3803)	grad_norm 0.3887 (0.4197)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:31:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:34 lr 0.000015	 wd 0.0000	time 0.2010 (0.2362)	loss 1.4052 (1.3813)	grad_norm 0.3952 (0.4198)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:31:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:10 lr 0.000015	 wd 0.0000	time 0.2210 (0.2351)	loss 1.2212 (1.3825)	grad_norm 0.4196 (0.4199)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:31:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:47 lr 0.000015	 wd 0.0000	time 0.2250 (0.2351)	loss 1.6315 (1.3830)	grad_norm 0.4043 (0.4198)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:32:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:23 lr 0.000016	 wd 0.0000	time 0.1991 (0.2343)	loss 1.4795 (1.3810)	grad_norm 0.4371 (0.4197)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:32:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1493 (0.2320)	loss 1.0998 (1.3823)	grad_norm 0.4120 (0.4203)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:32:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 1 training takes 0:09:44
[2024-07-13 23:33:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 26.916 (26.916)	Loss 0.4104 (0.4104)	Acc@1 92.773 (92.773)	Acc@5 98.438 (98.438)	Mem 5279MB
[2024-07-13 23:33:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 83.970 Acc@5 97.206
[2024-07-13 23:33:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-13 23:33:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 83.97%
[2024-07-13 23:33:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth saving......
[2024-07-13 23:33:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth saved !!!
[2024-07-13 23:33:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][0/2502]	eta 19:21:45 lr 0.000016	 wd 0.0000	time 27.8598 (27.8598)	loss 1.6457 (1.6457)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:34:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:18:58 lr 0.000016	 wd 0.0000	time 0.2126 (0.4738)	loss 1.4368 (1.3524)	grad_norm 0.4048 (0.4142)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:34:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:12:59 lr 0.000017	 wd 0.0000	time 0.1987 (0.3384)	loss 1.4484 (1.3732)	grad_norm 0.3665 (0.4159)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:34:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:10:59 lr 0.000017	 wd 0.0000	time 0.2898 (0.2995)	loss 1.3028 (1.3844)	grad_norm 0.4163 (0.4191)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:35:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:10:36 lr 0.000017	 wd 0.0000	time 0.1533 (0.3029)	loss 1.5538 (1.3822)	grad_norm 0.4357 (0.4186)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:35:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:09:24 lr 0.000018	 wd 0.0000	time 0.1847 (0.2819)	loss 1.5602 (1.3806)	grad_norm 0.4014 (0.4191)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:35:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:29 lr 0.000018	 wd 0.0000	time 0.1880 (0.2681)	loss 1.2758 (1.3751)	grad_norm 0.3957 (0.4192)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:36:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:07:49 lr 0.000018	 wd 0.0000	time 0.2077 (0.2604)	loss 1.2697 (1.3773)	grad_norm 0.4276 (0.4195)	loss_scale 16384.0000 (8472.4679)	mem 5279MB
[2024-07-13 23:36:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:20 lr 0.000019	 wd 0.0000	time 0.2033 (0.2587)	loss 1.4592 (1.3754)	grad_norm 0.3836 (nan)	loss_scale 8192.0000 (9378.3571)	mem 5279MB
[2024-07-13 23:37:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:45 lr 0.000019	 wd 0.0000	time 0.1751 (0.2532)	loss 1.5520 (1.3799)	grad_norm 0.4382 (nan)	loss_scale 8192.0000 (9246.6859)	mem 5279MB
[2024-07-13 23:37:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:13 lr 0.000019	 wd 0.0000	time 0.1910 (0.2486)	loss 1.4622 (1.3809)	grad_norm 0.4005 (nan)	loss_scale 8192.0000 (9141.3227)	mem 5279MB
[2024-07-13 23:37:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:42 lr 0.000020	 wd 0.0000	time 0.1791 (0.2444)	loss 1.1860 (1.3804)	grad_norm 0.4035 (nan)	loss_scale 8192.0000 (9055.0990)	mem 5279MB
[2024-07-13 23:38:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:18 lr 0.000020	 wd 0.0000	time 0.2637 (0.2443)	loss 1.2716 (1.3794)	grad_norm 0.4019 (nan)	loss_scale 8192.0000 (8983.2340)	mem 5279MB
[2024-07-13 23:38:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:04:53 lr 0.000020	 wd 0.0000	time 0.1971 (0.2441)	loss 1.7224 (1.3821)	grad_norm 0.4240 (nan)	loss_scale 8192.0000 (8922.4166)	mem 5279MB
[2024-07-13 23:38:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:25 lr 0.000020	 wd 0.0000	time 0.2143 (0.2412)	loss 1.4480 (1.3821)	grad_norm 0.4257 (nan)	loss_scale 8192.0000 (8870.2812)	mem 5279MB
[2024-07-13 23:39:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:03:59 lr 0.000021	 wd 0.0000	time 0.1762 (0.2386)	loss 1.5028 (1.3801)	grad_norm 0.3847 (nan)	loss_scale 8192.0000 (8825.0926)	mem 5279MB
[2024-07-13 23:39:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:33 lr 0.000021	 wd 0.0000	time 0.2218 (0.2370)	loss 1.2971 (1.3803)	grad_norm 0.4528 (nan)	loss_scale 8192.0000 (8785.5490)	mem 5279MB
[2024-07-13 23:40:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:10 lr 0.000021	 wd 0.0000	time 0.1775 (0.2375)	loss 1.4519 (1.3800)	grad_norm 0.4660 (nan)	loss_scale 8192.0000 (8750.6549)	mem 5279MB
[2024-07-13 23:40:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:45 lr 0.000022	 wd 0.0000	time 0.1866 (0.2360)	loss 1.3555 (1.3800)	grad_norm 0.4958 (nan)	loss_scale 8192.0000 (8719.6358)	mem 5279MB
[2024-07-13 23:40:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:21 lr 0.000022	 wd 0.0000	time 0.2238 (0.2345)	loss 1.0722 (1.3785)	grad_norm 0.3951 (nan)	loss_scale 8192.0000 (8691.8801)	mem 5279MB
[2024-07-13 23:41:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:01:56 lr 0.000022	 wd 0.0000	time 0.1937 (0.2329)	loss 1.1234 (1.3766)	grad_norm 0.3861 (nan)	loss_scale 8192.0000 (8666.8986)	mem 5279MB
[2024-07-13 23:41:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:33 lr 0.000023	 wd 0.0000	time 0.2632 (0.2325)	loss 1.4523 (1.3768)	grad_norm 0.4137 (nan)	loss_scale 8192.0000 (8644.2951)	mem 5279MB
[2024-07-13 23:41:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:10 lr 0.000023	 wd 0.0000	time 0.1866 (0.2325)	loss 1.5243 (1.3769)	grad_norm 0.4706 (nan)	loss_scale 8192.0000 (8623.7456)	mem 5279MB
[2024-07-13 23:42:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:46 lr 0.000023	 wd 0.0000	time 0.2194 (0.2313)	loss 1.5928 (1.3769)	grad_norm 0.4025 (nan)	loss_scale 8192.0000 (8604.9822)	mem 5279MB
[2024-07-13 23:42:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:23 lr 0.000024	 wd 0.0000	time 0.2504 (0.2302)	loss 1.4396 (1.3758)	grad_norm 0.5802 (nan)	loss_scale 8192.0000 (8587.7818)	mem 5279MB
[2024-07-13 23:42:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1568 (0.2279)	loss 1.4483 (1.3757)	grad_norm 0.3803 (nan)	loss_scale 8192.0000 (8571.9568)	mem 5279MB
[2024-07-13 23:42:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 2 training takes 0:09:34
[2024-07-13 23:43:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 41.817 (41.817)	Loss 0.4075 (0.4075)	Acc@1 92.969 (92.969)	Acc@5 98.438 (98.438)	Mem 5279MB
[2024-07-13 23:43:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 83.974 Acc@5 97.184
[2024-07-13 23:43:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-13 23:43:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 83.97%
[2024-07-13 23:43:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth saving......
[2024-07-13 23:43:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth saved !!!
[2024-07-13 23:44:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][0/2502]	eta 11:07:55 lr 0.000024	 wd 0.0000	time 16.0175 (16.0175)	loss 1.0857 (1.0857)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:44:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:15:35 lr 0.000024	 wd 0.0000	time 0.2738 (0.3895)	loss 1.6784 (1.3608)	grad_norm 0.4547 (0.4107)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:45:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:13:48 lr 0.000025	 wd 0.0000	time 0.1721 (0.3600)	loss 1.4957 (1.3730)	grad_norm 0.3933 (0.4121)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:45:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:11:12 lr 0.000025	 wd 0.0000	time 0.2116 (0.3056)	loss 1.4035 (1.3617)	grad_norm 0.3839 (0.4160)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:45:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:09:46 lr 0.000025	 wd 0.0000	time 0.2312 (0.2792)	loss 1.5451 (1.3684)	grad_norm 0.4599 (0.4161)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:46:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:08:49 lr 0.000026	 wd 0.0000	time 0.2332 (0.2646)	loss 1.4106 (1.3656)	grad_norm 0.4170 (0.4139)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:46:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:08:18 lr 0.000026	 wd 0.0000	time 0.2152 (0.2621)	loss 1.4691 (1.3652)	grad_norm 0.4130 (0.4139)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:46:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:07:37 lr 0.000026	 wd 0.0000	time 0.1879 (0.2541)	loss 1.5118 (1.3672)	grad_norm 0.4240 (0.4142)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:47:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:01 lr 0.000027	 wd 0.0000	time 0.1896 (0.2477)	loss 1.1337 (1.3677)	grad_norm 0.3937 (0.4148)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:47:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:06:28 lr 0.000027	 wd 0.0000	time 0.2356 (0.2422)	loss 1.3532 (1.3693)	grad_norm 0.3982 (0.4158)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:47:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:01 lr 0.000027	 wd 0.0000	time 0.2755 (0.2408)	loss 1.6103 (1.3727)	grad_norm 0.3967 (0.4152)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:48:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:05:37 lr 0.000028	 wd 0.0000	time 0.1893 (0.2409)	loss 1.4078 (1.3751)	grad_norm 0.4054 (0.4150)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:48:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:09 lr 0.000028	 wd 0.0000	time 0.1814 (0.2376)	loss 1.3185 (1.3739)	grad_norm 0.3621 (0.4151)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:48:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:04:42 lr 0.000028	 wd 0.0000	time 0.1601 (0.2348)	loss 1.2285 (1.3767)	grad_norm 0.3922 (0.4147)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:49:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:16 lr 0.000028	 wd 0.0000	time 0.1886 (0.2330)	loss 1.2328 (1.3774)	grad_norm 0.4210 (0.4158)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:49:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:03:53 lr 0.000029	 wd 0.0000	time 0.1934 (0.2335)	loss 1.3825 (1.3777)	grad_norm 0.4108 (0.4151)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:49:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:29 lr 0.000029	 wd 0.0000	time 0.1713 (0.2321)	loss 1.4312 (1.3765)	grad_norm 0.4050 (0.4152)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:50:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:04 lr 0.000029	 wd 0.0000	time 0.2223 (0.2306)	loss 1.0816 (1.3755)	grad_norm 0.3838 (0.4154)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:50:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:40 lr 0.000030	 wd 0.0000	time 0.1863 (0.2290)	loss 1.6390 (1.3771)	grad_norm 0.4198 (0.4154)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:51:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:17 lr 0.000030	 wd 0.0000	time 0.2198 (0.2287)	loss 1.5319 (1.3767)	grad_norm 0.4099 (0.4154)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:51:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:01:55 lr 0.000030	 wd 0.0000	time 0.2035 (0.2293)	loss 1.1542 (1.3774)	grad_norm 0.4018 (0.4154)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:51:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:31 lr 0.000031	 wd 0.0000	time 0.1876 (0.2280)	loss 1.2280 (1.3758)	grad_norm 0.3915 (0.4152)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:52:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:08 lr 0.000031	 wd 0.0000	time 0.2093 (0.2270)	loss 1.3777 (1.3769)	grad_norm 0.4935 (0.4152)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-13 23:52:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:45 lr 0.000031	 wd 0.0000	time 0.2708 (0.2263)	loss 1.5576 (1.3775)	grad_norm 0.3986 (0.4158)	loss_scale 16384.0000 (8227.6019)	mem 5279MB
[2024-07-13 23:52:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:23 lr 0.000032	 wd 0.0000	time 0.2343 (0.2266)	loss 1.0000 (1.3767)	grad_norm 0.3946 (0.4154)	loss_scale 16384.0000 (8567.3103)	mem 5279MB
[2024-07-13 23:53:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000032	 wd 0.0000	time 0.1342 (0.2247)	loss 1.5548 (1.3771)	grad_norm 0.4050 (0.4154)	loss_scale 16384.0000 (8879.8529)	mem 5279MB
[2024-07-13 23:53:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 3 training takes 0:09:27
[2024-07-13 23:53:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 24.250 (24.250)	Loss 0.4109 (0.4109)	Acc@1 92.773 (92.773)	Acc@5 98.438 (98.438)	Mem 5279MB
[2024-07-13 23:53:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 83.936 Acc@5 97.224
[2024-07-13 23:53:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-13 23:53:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 83.97%
[2024-07-13 23:54:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][0/2502]	eta 1 day, 0:27:42 lr 0.000032	 wd 0.0000	time 35.1967 (35.1967)	loss 1.4507 (1.4507)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-13 23:54:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:22:31 lr 0.000032	 wd 0.0000	time 0.1810 (0.5627)	loss 1.1629 (1.3881)	grad_norm 0.4450 (0.4166)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-13 23:55:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:14:35 lr 0.000033	 wd 0.0000	time 0.1810 (0.3802)	loss 1.1406 (1.3897)	grad_norm 0.4098 (nan)	loss_scale 8192.0000 (15324.3383)	mem 5279MB
[2024-07-13 23:55:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:11:42 lr 0.000033	 wd 0.0000	time 0.2055 (0.3191)	loss 1.1203 (1.3893)	grad_norm 0.4419 (nan)	loss_scale 8192.0000 (12954.7907)	mem 5279MB
[2024-07-13 23:55:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:10:29 lr 0.000033	 wd 0.0000	time 0.3516 (0.2993)	loss 1.5890 (1.3848)	grad_norm 0.3764 (nan)	loss_scale 8192.0000 (11767.0623)	mem 5279MB
[2024-07-13 23:56:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:10:08 lr 0.000034	 wd 0.0000	time 0.1708 (0.3041)	loss 1.3532 (1.3779)	grad_norm 0.5178 (nan)	loss_scale 8192.0000 (11053.4770)	mem 5279MB
[2024-07-13 23:56:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:09:05 lr 0.000034	 wd 0.0000	time 0.2069 (0.2870)	loss 1.4875 (1.3738)	grad_norm 0.4066 (nan)	loss_scale 8192.0000 (10577.3577)	mem 5279MB
[2024-07-13 23:57:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:08:13 lr 0.000034	 wd 0.0000	time 0.1824 (0.2738)	loss 1.2887 (1.3738)	grad_norm 0.4067 (nan)	loss_scale 8192.0000 (10237.0785)	mem 5279MB
[2024-07-13 23:57:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:34 lr 0.000035	 wd 0.0000	time 0.2109 (0.2673)	loss 1.4821 (1.3731)	grad_norm 0.5330 (nan)	loss_scale 8192.0000 (9981.7628)	mem 5279MB
[2024-07-13 23:57:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:07:11 lr 0.000035	 wd 0.0000	time 0.1797 (0.2694)	loss 1.4793 (1.3742)	grad_norm 0.3895 (nan)	loss_scale 8192.0000 (9783.1210)	mem 5279MB
[2024-07-13 23:58:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:33 lr 0.000035	 wd 0.0000	time 0.1945 (0.2623)	loss 1.5328 (1.3749)	grad_norm 0.3771 (nan)	loss_scale 8192.0000 (9624.1678)	mem 5279MB
[2024-07-13 23:58:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:06:00 lr 0.000036	 wd 0.0000	time 0.1998 (0.2568)	loss 1.5295 (1.3756)	grad_norm 0.4039 (nan)	loss_scale 8192.0000 (9494.0890)	mem 5279MB
[2024-07-13 23:58:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:29 lr 0.000036	 wd 0.0000	time 0.2187 (0.2528)	loss 1.0870 (1.3741)	grad_norm 0.4241 (nan)	loss_scale 8192.0000 (9385.6719)	mem 5279MB
[2024-07-13 23:59:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:05:03 lr 0.000036	 wd 0.0000	time 0.1780 (0.2528)	loss 1.5972 (1.3734)	grad_norm 0.4341 (nan)	loss_scale 8192.0000 (9293.9216)	mem 5279MB
[2024-07-13 23:59:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:35 lr 0.000036	 wd 0.0000	time 0.1962 (0.2496)	loss 1.5143 (1.3735)	grad_norm 0.4152 (nan)	loss_scale 8192.0000 (9215.2691)	mem 5279MB
[2024-07-14 00:00:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:07 lr 0.000037	 wd 0.0000	time 0.1722 (0.2466)	loss 1.2701 (1.3760)	grad_norm 0.3846 (nan)	loss_scale 8192.0000 (9147.0966)	mem 5279MB
[2024-07-14 00:00:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:39 lr 0.000037	 wd 0.0000	time 0.1770 (0.2437)	loss 1.0681 (1.3756)	grad_norm 0.3966 (nan)	loss_scale 8192.0000 (9087.4403)	mem 5279MB
[2024-07-14 00:00:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:14 lr 0.000037	 wd 0.0000	time 0.1872 (0.2425)	loss 1.5662 (1.3749)	grad_norm 0.4350 (nan)	loss_scale 8192.0000 (9034.7984)	mem 5279MB
[2024-07-14 00:01:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:50 lr 0.000038	 wd 0.0000	time 0.1886 (0.2424)	loss 1.3859 (1.3748)	grad_norm 0.3891 (nan)	loss_scale 8192.0000 (8988.0022)	mem 5279MB
[2024-07-14 00:01:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:24 lr 0.000038	 wd 0.0000	time 0.2072 (0.2406)	loss 1.6572 (1.3746)	grad_norm 0.3958 (nan)	loss_scale 8192.0000 (8946.1294)	mem 5279MB
[2024-07-14 00:01:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:01:59 lr 0.000038	 wd 0.0000	time 0.1913 (0.2388)	loss 1.4654 (1.3739)	grad_norm 0.3992 (nan)	loss_scale 8192.0000 (8908.4418)	mem 5279MB
[2024-07-14 00:02:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:35 lr 0.000039	 wd 0.0000	time 0.2038 (0.2376)	loss 1.4380 (1.3743)	grad_norm 0.4121 (nan)	loss_scale 8192.0000 (8874.3417)	mem 5279MB
[2024-07-14 00:02:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:11 lr 0.000039	 wd 0.0000	time 0.2055 (0.2374)	loss 0.9835 (1.3720)	grad_norm 0.3780 (nan)	loss_scale 8192.0000 (8843.3403)	mem 5279MB
[2024-07-14 00:02:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:47 lr 0.000039	 wd 0.0000	time 0.1836 (0.2364)	loss 1.3237 (1.3722)	grad_norm 0.3928 (nan)	loss_scale 8192.0000 (8815.0335)	mem 5279MB
[2024-07-14 00:03:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:23 lr 0.000040	 wd 0.0000	time 0.1797 (0.2352)	loss 1.5795 (1.3721)	grad_norm 0.3873 (nan)	loss_scale 8192.0000 (8789.0845)	mem 5279MB
[2024-07-14 00:03:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1543 (0.2329)	loss 0.9309 (1.3719)	grad_norm 0.3861 (nan)	loss_scale 8192.0000 (8765.2107)	mem 5279MB
[2024-07-14 00:03:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 4 training takes 0:09:47
[2024-07-14 00:04:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 40.752 (40.752)	Loss 0.4092 (0.4092)	Acc@1 92.773 (92.773)	Acc@5 98.438 (98.438)	Mem 5279MB
[2024-07-14 00:04:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 83.964 Acc@5 97.234
[2024-07-14 00:04:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-14 00:04:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 83.97%
[2024-07-14 00:04:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][0/2502]	eta 12:07:21 lr 0.000040	 wd 0.0000	time 17.4427 (17.4427)	loss 1.6203 (1.6203)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 00:05:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:14:39 lr 0.000040	 wd 0.0000	time 0.1694 (0.3660)	loss 1.2806 (1.3904)	grad_norm 0.4492 (0.4283)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 00:05:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:13:15 lr 0.000040	 wd 0.0000	time 0.2207 (0.3456)	loss 1.4797 (1.3944)	grad_norm 0.4016 (0.4284)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 00:06:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:11:11 lr 0.000040	 wd 0.0000	time 0.1906 (0.3050)	loss 1.6321 (1.3843)	grad_norm 0.4133 (0.4233)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 00:06:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:43 lr 0.000040	 wd 0.0000	time 0.1922 (0.2777)	loss 0.9897 (1.3860)	grad_norm 0.4214 (0.4200)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 00:06:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:08:43 lr 0.000040	 wd 0.0000	time 0.2064 (0.2613)	loss 1.5323 (1.3815)	grad_norm 0.3955 (0.4182)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 00:07:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:12 lr 0.000040	 wd 0.0000	time 0.4577 (0.2592)	loss 1.4317 (1.3824)	grad_norm 0.3799 (0.4172)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 00:07:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:58 lr 0.000040	 wd 0.0000	time 0.1943 (0.2655)	loss 1.4710 (1.3800)	grad_norm 0.4396 (0.4177)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 00:07:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:18 lr 0.000040	 wd 0.0000	time 0.2159 (0.2574)	loss 0.9361 (1.3740)	grad_norm 0.4911 (0.4185)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 00:08:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:41 lr 0.000040	 wd 0.0000	time 0.1816 (0.2508)	loss 0.9132 (1.3733)	grad_norm 0.4034 (0.4180)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 00:08:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:11 lr 0.000040	 wd 0.0000	time 0.2568 (0.2476)	loss 1.5215 (1.3764)	grad_norm 0.3966 (0.4186)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 00:09:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:52 lr 0.000040	 wd 0.0000	time 0.2152 (0.2516)	loss 1.5604 (1.3723)	grad_norm 0.4009 (0.4187)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 00:09:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:22 lr 0.000040	 wd 0.0000	time 0.1946 (0.2475)	loss 1.5562 (1.3703)	grad_norm 0.3891 (0.4179)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 00:09:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:53 lr 0.000040	 wd 0.0000	time 0.1796 (0.2441)	loss 1.5030 (1.3707)	grad_norm 0.4202 (0.4180)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 00:10:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:26 lr 0.000040	 wd 0.0000	time 0.1982 (0.2419)	loss 1.5335 (1.3703)	grad_norm 0.3920 (0.4177)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 00:10:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:04:02 lr 0.000040	 wd 0.0000	time 0.2000 (0.2423)	loss 1.3949 (1.3703)	grad_norm 0.4107 (0.4179)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 00:10:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:37 lr 0.000040	 wd 0.0000	time 0.1705 (0.2408)	loss 1.4466 (1.3723)	grad_norm 0.4404 (0.4173)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 00:11:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:11 lr 0.000040	 wd 0.0000	time 0.1826 (0.2386)	loss 1.3635 (1.3719)	grad_norm 0.3775 (0.4172)	loss_scale 16384.0000 (8326.8477)	mem 5279MB
[2024-07-14 00:11:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:46 lr 0.000040	 wd 0.0000	time 0.1735 (0.2367)	loss 0.9930 (1.3712)	grad_norm 0.3840 (0.4169)	loss_scale 16384.0000 (8774.2188)	mem 5279MB
[2024-07-14 00:12:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:22 lr 0.000040	 wd 0.0000	time 0.2587 (0.2360)	loss 1.4826 (1.3733)	grad_norm 0.4102 (0.4164)	loss_scale 16384.0000 (9174.5229)	mem 5279MB
[2024-07-14 00:12:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:01:58 lr 0.000040	 wd 0.0000	time 0.1918 (0.2364)	loss 1.5422 (1.3742)	grad_norm 0.4001 (0.4166)	loss_scale 16384.0000 (9534.8166)	mem 5279MB
[2024-07-14 00:12:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:34 lr 0.000040	 wd 0.0000	time 0.1800 (0.2349)	loss 1.5290 (1.3747)	grad_norm 0.3933 (0.4163)	loss_scale 16384.0000 (9860.8129)	mem 5279MB
[2024-07-14 00:13:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:10 lr 0.000040	 wd 0.0000	time 0.1721 (0.2335)	loss 1.2469 (1.3726)	grad_norm 0.4362 (0.4164)	loss_scale 16384.0000 (10157.1867)	mem 5279MB
[2024-07-14 00:13:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:46 lr 0.000040	 wd 0.0000	time 0.2053 (0.2325)	loss 0.8998 (1.3717)	grad_norm 0.3805 (0.4162)	loss_scale 16384.0000 (10427.8001)	mem 5279MB
[2024-07-14 00:13:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:23 lr 0.000040	 wd 0.0000	time 0.1675 (0.2329)	loss 1.5169 (1.3719)	grad_norm 0.4255 (0.4162)	loss_scale 16384.0000 (10675.8717)	mem 5279MB
[2024-07-14 00:14:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1551 (0.2307)	loss 1.5260 (1.3717)	grad_norm 0.3925 (0.4166)	loss_scale 16384.0000 (10904.1056)	mem 5279MB
[2024-07-14 00:14:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 5 training takes 0:09:41
[2024-07-14 00:14:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 22.723 (22.723)	Loss 0.4089 (0.4089)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 5279MB
[2024-07-14 00:14:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 83.986 Acc@5 97.222
[2024-07-14 00:14:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-14 00:14:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 83.99%
[2024-07-14 00:14:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth saving......
[2024-07-14 00:14:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth saved !!!
[2024-07-14 00:15:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][0/2502]	eta 22:25:28 lr 0.000040	 wd 0.0000	time 32.2655 (32.2655)	loss 1.5737 (1.5737)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 00:15:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:21:22 lr 0.000040	 wd 0.0000	time 0.1741 (0.5340)	loss 1.2258 (1.3421)	grad_norm 0.4036 (0.4146)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 00:16:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:14:05 lr 0.000040	 wd 0.0000	time 0.1839 (0.3671)	loss 1.6072 (1.3644)	grad_norm 0.4007 (0.4146)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 00:16:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:11:25 lr 0.000040	 wd 0.0000	time 0.1782 (0.3111)	loss 1.4673 (1.3745)	grad_norm 0.4463 (0.4167)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 00:16:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:10:26 lr 0.000040	 wd 0.0000	time 0.3928 (0.2983)	loss 1.3712 (1.3680)	grad_norm 0.4933 (0.4163)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 00:17:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:10:18 lr 0.000040	 wd 0.0000	time 0.2058 (0.3090)	loss 1.3684 (1.3625)	grad_norm 0.3929 (0.4159)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 00:17:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:09:13 lr 0.000040	 wd 0.0000	time 0.1796 (0.2911)	loss 1.6018 (1.3666)	grad_norm 0.3979 (0.4184)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 00:18:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:08:20 lr 0.000040	 wd 0.0000	time 0.1821 (0.2779)	loss 1.4186 (1.3689)	grad_norm 0.4201 (0.4189)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 00:18:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:46 lr 0.000040	 wd 0.0000	time 0.3284 (0.2743)	loss 1.0123 (1.3679)	grad_norm 0.4404 (0.4182)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 00:19:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:07:25 lr 0.000040	 wd 0.0000	time 0.1973 (0.2778)	loss 1.6582 (1.3719)	grad_norm 0.3702 (0.4190)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 00:19:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:45 lr 0.000040	 wd 0.0000	time 0.2169 (0.2700)	loss 1.3210 (1.3674)	grad_norm 0.3976 (0.4185)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 00:19:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:06:09 lr 0.000040	 wd 0.0000	time 0.2092 (0.2634)	loss 1.2124 (1.3666)	grad_norm 0.4277 (0.4187)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 00:20:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:39 lr 0.000040	 wd 0.0000	time 0.2727 (0.2610)	loss 1.0731 (1.3682)	grad_norm 0.4118 (0.4184)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 00:20:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:05:16 lr 0.000040	 wd 0.0000	time 0.1833 (0.2631)	loss 1.4098 (1.3673)	grad_norm 0.4078 (0.4180)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 00:20:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:44 lr 0.000040	 wd 0.0000	time 0.2299 (0.2586)	loss 1.6613 (1.3659)	grad_norm 0.4135 (0.4178)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 00:21:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:15 lr 0.000040	 wd 0.0000	time 0.1814 (0.2549)	loss 1.4719 (1.3674)	grad_norm 0.3918 (0.4169)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 00:21:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:47 lr 0.000040	 wd 0.0000	time 0.2058 (0.2523)	loss 1.5578 (1.3661)	grad_norm 0.4095 (nan)	loss_scale 8192.0000 (16240.7295)	mem 5279MB
[2024-07-14 00:21:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:22 lr 0.000040	 wd 0.0000	time 0.1770 (0.2519)	loss 1.5089 (1.3653)	grad_norm 0.3787 (nan)	loss_scale 8192.0000 (15767.5532)	mem 5279MB
[2024-07-14 00:22:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:55 lr 0.000040	 wd 0.0000	time 0.2285 (0.2496)	loss 1.1678 (1.3650)	grad_norm 0.4315 (nan)	loss_scale 4096.0000 (15337.8257)	mem 5279MB
[2024-07-14 00:22:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:28 lr 0.000040	 wd 0.0000	time 0.1870 (0.2473)	loss 1.2864 (1.3645)	grad_norm 0.4014 (nan)	loss_scale 4096.0000 (14746.4619)	mem 5279MB
[2024-07-14 00:23:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:02:03 lr 0.000039	 wd 0.0000	time 0.1983 (0.2452)	loss 0.9985 (1.3644)	grad_norm 0.4125 (nan)	loss_scale 4096.0000 (14214.2049)	mem 5279MB
[2024-07-14 00:23:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:38 lr 0.000039	 wd 0.0000	time 0.2155 (0.2443)	loss 1.5623 (1.3640)	grad_norm 0.5029 (nan)	loss_scale 4096.0000 (13732.6149)	mem 5279MB
[2024-07-14 00:23:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:13 lr 0.000039	 wd 0.0000	time 0.2021 (0.2440)	loss 1.2601 (1.3645)	grad_norm 0.3955 (nan)	loss_scale 4096.0000 (13294.7860)	mem 5279MB
[2024-07-14 00:24:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:48 lr 0.000039	 wd 0.0000	time 0.1923 (0.2424)	loss 1.4642 (1.3652)	grad_norm 0.4840 (nan)	loss_scale 4096.0000 (12895.0126)	mem 5279MB
[2024-07-14 00:24:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:24 lr 0.000039	 wd 0.0000	time 0.1613 (0.2408)	loss 1.2068 (1.3644)	grad_norm 0.3764 (nan)	loss_scale 4096.0000 (12528.5398)	mem 5279MB
[2024-07-14 00:24:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1562 (0.2383)	loss 1.0359 (1.3651)	grad_norm 0.4425 (nan)	loss_scale 4096.0000 (12191.3731)	mem 5279MB
[2024-07-14 00:24:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 6 training takes 0:10:00
[2024-07-14 00:25:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 44.117 (44.117)	Loss 0.4109 (0.4109)	Acc@1 92.969 (92.969)	Acc@5 98.438 (98.438)	Mem 5279MB
[2024-07-14 00:25:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 83.954 Acc@5 97.250
[2024-07-14 00:25:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-14 00:25:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 83.99%
[2024-07-14 00:26:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][0/2502]	eta 11:48:33 lr 0.000039	 wd 0.0000	time 16.9919 (16.9919)	loss 1.6091 (1.6091)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:26:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:16:23 lr 0.000039	 wd 0.0000	time 0.4482 (0.4096)	loss 1.2391 (1.3901)	grad_norm 0.4126 (0.4065)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:26:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:13:21 lr 0.000039	 wd 0.0000	time 0.2075 (0.3483)	loss 1.4661 (1.3647)	grad_norm 0.4514 (0.4176)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:27:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:10:57 lr 0.000039	 wd 0.0000	time 0.2013 (0.2985)	loss 1.3220 (1.3622)	grad_norm 0.4185 (0.4160)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:27:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:09:36 lr 0.000039	 wd 0.0000	time 0.1778 (0.2743)	loss 1.3512 (1.3640)	grad_norm 0.4132 (0.4148)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:27:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:08:44 lr 0.000039	 wd 0.0000	time 0.2415 (0.2621)	loss 1.4404 (1.3596)	grad_norm 0.3945 (0.4156)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:28:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:40 lr 0.000039	 wd 0.0000	time 0.2035 (0.2739)	loss 1.3419 (1.3634)	grad_norm 0.3932 (0.4166)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:28:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:07:54 lr 0.000039	 wd 0.0000	time 0.1994 (0.2636)	loss 1.4847 (1.3672)	grad_norm 0.4012 (0.4172)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:29:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:07:14 lr 0.000039	 wd 0.0000	time 0.1870 (0.2553)	loss 0.8953 (1.3696)	grad_norm 0.4463 (0.4179)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:29:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:06:41 lr 0.000039	 wd 0.0000	time 0.2369 (0.2507)	loss 1.0959 (1.3713)	grad_norm 0.3969 (0.4186)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:30:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:35 lr 0.000039	 wd 0.0000	time 0.1954 (0.2632)	loss 1.1821 (1.3672)	grad_norm 0.4053 (0.4190)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:30:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:06:01 lr 0.000039	 wd 0.0000	time 0.2027 (0.2575)	loss 1.2455 (1.3656)	grad_norm 0.3888 (0.4193)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:30:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:29 lr 0.000039	 wd 0.0000	time 0.1962 (0.2528)	loss 1.4209 (1.3643)	grad_norm 0.4772 (0.4198)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:31:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:05:00 lr 0.000039	 wd 0.0000	time 0.2114 (0.2498)	loss 1.4805 (1.3643)	grad_norm 0.3823 (0.4195)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:31:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:34 lr 0.000039	 wd 0.0000	time 0.2838 (0.2489)	loss 1.4029 (1.3651)	grad_norm 0.3843 (0.4187)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:31:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:06 lr 0.000039	 wd 0.0000	time 0.1979 (0.2461)	loss 1.6503 (1.3644)	grad_norm 0.4359 (0.4194)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:32:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:39 lr 0.000039	 wd 0.0000	time 0.2202 (0.2437)	loss 1.5384 (1.3662)	grad_norm 0.4100 (0.4188)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:32:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:13 lr 0.000039	 wd 0.0000	time 0.1854 (0.2411)	loss 1.5755 (1.3666)	grad_norm 0.4638 (0.4188)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:33:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:48 lr 0.000039	 wd 0.0000	time 0.2456 (0.2402)	loss 1.1293 (1.3662)	grad_norm 0.4404 (0.4188)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:33:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:24 lr 0.000039	 wd 0.0000	time 0.2133 (0.2402)	loss 1.3072 (1.3656)	grad_norm 0.4724 (0.4184)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:33:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:01:59 lr 0.000039	 wd 0.0000	time 0.2042 (0.2385)	loss 1.4372 (1.3667)	grad_norm 0.3886 (0.4185)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:34:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:35 lr 0.000039	 wd 0.0000	time 0.1880 (0.2369)	loss 1.5072 (1.3677)	grad_norm 0.4479 (0.4185)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:34:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:11 lr 0.000039	 wd 0.0000	time 0.2149 (0.2357)	loss 1.1194 (1.3658)	grad_norm 0.3938 (0.4182)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:34:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:47 lr 0.000039	 wd 0.0000	time 0.2216 (0.2359)	loss 1.5821 (1.3663)	grad_norm 0.4018 (0.4180)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:35:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:23 lr 0.000039	 wd 0.0000	time 0.1738 (0.2346)	loss 1.4736 (1.3658)	grad_norm 0.4029 (0.4190)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:35:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1444 (0.2322)	loss 1.2847 (1.3660)	grad_norm 0.4141 (0.4193)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:35:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 7 training takes 0:09:45
[2024-07-14 00:35:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 23.366 (23.366)	Loss 0.4158 (0.4158)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 5279MB
[2024-07-14 00:36:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.012 Acc@5 97.230
[2024-07-14 00:36:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-14 00:36:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.01%
[2024-07-14 00:36:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth saving......
[2024-07-14 00:36:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth saved !!!
[2024-07-14 00:36:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][0/2502]	eta 16:30:19 lr 0.000039	 wd 0.0000	time 23.7487 (23.7487)	loss 1.4357 (1.4357)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:36:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:17:28 lr 0.000039	 wd 0.0000	time 0.1861 (0.4367)	loss 1.4619 (1.4033)	grad_norm 0.4150 (0.4175)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:37:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:12:14 lr 0.000039	 wd 0.0000	time 0.1631 (0.3190)	loss 1.5437 (1.3786)	grad_norm 0.4266 (0.4189)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:37:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:10:25 lr 0.000038	 wd 0.0000	time 0.2031 (0.2843)	loss 1.3605 (1.3761)	grad_norm 0.4045 (0.4176)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:38:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:10:19 lr 0.000038	 wd 0.0000	time 0.2462 (0.2946)	loss 1.6357 (1.3720)	grad_norm 0.4236 (0.4170)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:38:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:09:12 lr 0.000038	 wd 0.0000	time 0.1808 (0.2759)	loss 1.4473 (1.3749)	grad_norm 0.4026 (0.4197)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:38:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:19 lr 0.000038	 wd 0.0000	time 0.1757 (0.2627)	loss 1.5317 (1.3793)	grad_norm 0.3980 (0.4223)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:39:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:38 lr 0.000038	 wd 0.0000	time 0.2626 (0.2547)	loss 1.6517 (1.3775)	grad_norm 0.4219 (0.4230)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:39:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:27 lr 0.000038	 wd 0.0000	time 0.2266 (0.2629)	loss 1.4842 (1.3751)	grad_norm 0.3950 (0.4221)	loss_scale 8192.0000 (4136.9089)	mem 5279MB
[2024-07-14 00:40:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:50 lr 0.000038	 wd 0.0000	time 0.2236 (0.2561)	loss 1.6567 (1.3751)	grad_norm 0.3945 (0.4208)	loss_scale 8192.0000 (4586.9745)	mem 5279MB
[2024-07-14 00:40:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:16 lr 0.000038	 wd 0.0000	time 0.2258 (0.2507)	loss 1.5012 (1.3713)	grad_norm 0.4041 (0.4199)	loss_scale 8192.0000 (4947.1169)	mem 5279MB
[2024-07-14 00:40:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:45 lr 0.000038	 wd 0.0000	time 0.2332 (0.2464)	loss 1.3457 (1.3683)	grad_norm 0.4050 (0.4197)	loss_scale 8192.0000 (5241.8383)	mem 5279MB
[2024-07-14 00:41:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:22 lr 0.000038	 wd 0.0000	time 0.1849 (0.2474)	loss 1.4592 (1.3685)	grad_norm 0.6066 (0.4197)	loss_scale 8192.0000 (5487.4804)	mem 5279MB
[2024-07-14 00:41:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:53 lr 0.000038	 wd 0.0000	time 0.1765 (0.2443)	loss 1.1817 (1.3671)	grad_norm 0.4210 (0.4186)	loss_scale 8192.0000 (5695.3605)	mem 5279MB
[2024-07-14 00:41:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:26 lr 0.000038	 wd 0.0000	time 0.1987 (0.2415)	loss 0.9615 (1.3688)	grad_norm 0.4213 (nan)	loss_scale 4096.0000 (5797.5503)	mem 5279MB
[2024-07-14 00:42:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:03:59 lr 0.000038	 wd 0.0000	time 0.1601 (0.2387)	loss 0.8380 (1.3666)	grad_norm 0.4754 (nan)	loss_scale 4096.0000 (5684.1892)	mem 5279MB
[2024-07-14 00:42:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:33 lr 0.000038	 wd 0.0000	time 0.2051 (0.2372)	loss 1.2301 (1.3638)	grad_norm 0.3940 (nan)	loss_scale 4096.0000 (5584.9894)	mem 5279MB
[2024-07-14 00:42:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:10 lr 0.000038	 wd 0.0000	time 0.1724 (0.2374)	loss 1.1813 (1.3656)	grad_norm 0.3983 (nan)	loss_scale 4096.0000 (5497.4533)	mem 5279MB
[2024-07-14 00:43:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:45 lr 0.000038	 wd 0.0000	time 0.2279 (0.2358)	loss 1.5369 (1.3667)	grad_norm 0.3890 (nan)	loss_scale 4096.0000 (5419.6380)	mem 5279MB
[2024-07-14 00:43:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:21 lr 0.000038	 wd 0.0000	time 0.1804 (0.2343)	loss 1.3117 (1.3659)	grad_norm 0.3990 (nan)	loss_scale 4096.0000 (5350.0095)	mem 5279MB
[2024-07-14 00:43:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:56 lr 0.000038	 wd 0.0000	time 0.2035 (0.2329)	loss 1.6842 (1.3679)	grad_norm 0.4154 (nan)	loss_scale 4096.0000 (5287.3403)	mem 5279MB
[2024-07-14 00:44:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:33 lr 0.000038	 wd 0.0000	time 0.2419 (0.2324)	loss 1.4057 (1.3669)	grad_norm 0.4081 (nan)	loss_scale 4096.0000 (5230.6368)	mem 5279MB
[2024-07-14 00:44:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:10 lr 0.000038	 wd 0.0000	time 0.1968 (0.2327)	loss 1.5734 (1.3655)	grad_norm 0.4195 (nan)	loss_scale 4096.0000 (5179.0859)	mem 5279MB
[2024-07-14 00:45:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:46 lr 0.000038	 wd 0.0000	time 0.1856 (0.2315)	loss 1.4956 (1.3662)	grad_norm 0.4560 (nan)	loss_scale 4096.0000 (5132.0156)	mem 5279MB
[2024-07-14 00:45:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:23 lr 0.000038	 wd 0.0000	time 0.1911 (0.2303)	loss 1.3202 (1.3678)	grad_norm 0.4170 (nan)	loss_scale 4096.0000 (5088.8663)	mem 5279MB
[2024-07-14 00:45:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000038	 wd 0.0000	time 0.1522 (0.2281)	loss 1.7603 (1.3692)	grad_norm 0.3853 (nan)	loss_scale 4096.0000 (5049.1675)	mem 5279MB
[2024-07-14 00:45:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 8 training takes 0:09:35
[2024-07-14 00:46:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 38.692 (38.692)	Loss 0.4163 (0.4163)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 5279MB
[2024-07-14 00:46:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.006 Acc@5 97.254
[2024-07-14 00:46:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-14 00:46:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.01%
[2024-07-14 00:46:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][0/2502]	eta 11:19:07 lr 0.000038	 wd 0.0000	time 16.2860 (16.2860)	loss 1.3716 (1.3716)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:47:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:14:55 lr 0.000038	 wd 0.0000	time 0.2388 (0.3730)	loss 1.2365 (1.3333)	grad_norm 0.3995 (0.4170)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:47:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:13:16 lr 0.000037	 wd 0.0000	time 0.2110 (0.3459)	loss 1.4897 (1.3462)	grad_norm 0.4360 (0.4174)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:48:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:56 lr 0.000037	 wd 0.0000	time 0.1737 (0.2980)	loss 1.4461 (1.3580)	grad_norm 0.4075 (0.4185)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:48:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:32 lr 0.000037	 wd 0.0000	time 0.1959 (0.2725)	loss 1.5828 (1.3530)	grad_norm 0.3853 (0.4215)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:48:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:08:35 lr 0.000037	 wd 0.0000	time 0.2041 (0.2577)	loss 1.3906 (1.3597)	grad_norm 0.4077 (0.4211)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:49:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:29 lr 0.000037	 wd 0.0000	time 0.2557 (0.2681)	loss 1.5203 (1.3542)	grad_norm 0.3858 (0.4198)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:49:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:49 lr 0.000037	 wd 0.0000	time 0.1942 (0.2605)	loss 1.5390 (1.3557)	grad_norm 0.3943 (0.4180)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:50:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:10 lr 0.000037	 wd 0.0000	time 0.2013 (0.2528)	loss 1.3922 (1.3586)	grad_norm 0.4110 (0.4177)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:50:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:35 lr 0.000037	 wd 0.0000	time 0.1727 (0.2467)	loss 1.5993 (1.3558)	grad_norm 0.4017 (0.4172)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:50:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:07 lr 0.000037	 wd 0.0000	time 0.2301 (0.2446)	loss 1.4694 (1.3585)	grad_norm 0.4147 (0.4170)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:51:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:40 lr 0.000037	 wd 0.0000	time 0.2117 (0.2429)	loss 1.4009 (1.3616)	grad_norm 0.3919 (0.4165)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:51:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:11 lr 0.000037	 wd 0.0000	time 0.1843 (0.2394)	loss 1.5500 (1.3627)	grad_norm 0.3864 (0.4165)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:51:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:44 lr 0.000037	 wd 0.0000	time 0.1864 (0.2365)	loss 0.9656 (1.3607)	grad_norm 0.3998 (0.4165)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:52:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:18 lr 0.000037	 wd 0.0000	time 0.2074 (0.2342)	loss 1.3453 (1.3621)	grad_norm 0.3851 (0.4180)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:52:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:03:54 lr 0.000037	 wd 0.0000	time 0.2103 (0.2340)	loss 1.4719 (1.3640)	grad_norm 0.4127 (0.4177)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:52:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:29 lr 0.000037	 wd 0.0000	time 0.1772 (0.2325)	loss 0.9248 (1.3631)	grad_norm 0.3846 (0.4178)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:53:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:05 lr 0.000037	 wd 0.0000	time 0.1911 (0.2308)	loss 1.1129 (1.3643)	grad_norm 0.3928 (0.4177)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:53:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:40 lr 0.000037	 wd 0.0000	time 0.2026 (0.2292)	loss 1.5384 (1.3647)	grad_norm 0.4259 (0.4179)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:53:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:17 lr 0.000037	 wd 0.0000	time 0.1964 (0.2286)	loss 1.3306 (1.3634)	grad_norm 0.4310 (0.4179)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:54:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:01:54 lr 0.000037	 wd 0.0000	time 0.1621 (0.2290)	loss 1.4852 (1.3636)	grad_norm 0.3792 (0.4181)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:54:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:31 lr 0.000036	 wd 0.0000	time 0.2203 (0.2279)	loss 1.0753 (1.3637)	grad_norm 0.4159 (0.4180)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:54:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:08 lr 0.000036	 wd 0.0000	time 0.2051 (0.2267)	loss 1.4927 (1.3647)	grad_norm 0.4126 (0.4182)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:55:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:45 lr 0.000036	 wd 0.0000	time 0.1808 (0.2259)	loss 1.4264 (1.3654)	grad_norm 0.4009 (0.4179)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:55:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:23 lr 0.000036	 wd 0.0000	time 0.1963 (0.2261)	loss 1.2745 (1.3651)	grad_norm 0.4174 (0.4179)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:56:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000036	 wd 0.0000	time 0.1524 (0.2242)	loss 1.1345 (1.3662)	grad_norm 0.3910 (0.4180)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:56:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 9 training takes 0:09:26
[2024-07-14 00:56:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 22.427 (22.427)	Loss 0.4099 (0.4099)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 00:56:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 83.998 Acc@5 97.248
[2024-07-14 00:56:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-14 00:56:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.01%
[2024-07-14 00:56:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][0/2502]	eta 13:12:47 lr 0.000036	 wd 0.0000	time 19.0118 (19.0118)	loss 1.3016 (1.3016)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:57:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:18:25 lr 0.000036	 wd 0.0000	time 0.1933 (0.4602)	loss 1.3457 (1.3468)	grad_norm 0.4141 (0.4090)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:57:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:12:40 lr 0.000036	 wd 0.0000	time 0.2029 (0.3303)	loss 1.2993 (1.3675)	grad_norm 0.3898 (0.4120)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:58:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:32 lr 0.000036	 wd 0.0000	time 0.1773 (0.2873)	loss 0.8836 (1.3650)	grad_norm 0.4230 (0.4157)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 00:58:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:17 lr 0.000036	 wd 0.0000	time 0.2112 (0.2650)	loss 1.5325 (1.3680)	grad_norm 0.4305 (0.4146)	loss_scale 8192.0000 (4402.4339)	mem 5279MB
[2024-07-14 00:58:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:08:47 lr 0.000036	 wd 0.0000	time 0.4329 (0.2635)	loss 1.4156 (1.3639)	grad_norm 0.3916 (0.4144)	loss_scale 8192.0000 (5158.8343)	mem 5279MB
[2024-07-14 00:59:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:16 lr 0.000036	 wd 0.0000	time 0.1704 (0.2609)	loss 1.5210 (1.3641)	grad_norm 0.4476 (0.4136)	loss_scale 8192.0000 (5663.5208)	mem 5279MB
[2024-07-14 00:59:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:34 lr 0.000036	 wd 0.0000	time 0.1853 (0.2521)	loss 1.4981 (1.3602)	grad_norm 0.3940 (0.4138)	loss_scale 8192.0000 (6024.2168)	mem 5279MB
[2024-07-14 00:59:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:06:58 lr 0.000036	 wd 0.0000	time 0.1870 (0.2459)	loss 1.2492 (1.3595)	grad_norm 0.3956 (0.4141)	loss_scale 8192.0000 (6294.8514)	mem 5279MB
[2024-07-14 01:00:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:29 lr 0.000036	 wd 0.0000	time 0.2000 (0.2432)	loss 1.5337 (1.3596)	grad_norm 0.4415 (0.4147)	loss_scale 8192.0000 (6505.4118)	mem 5279MB
[2024-07-14 01:00:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:05 lr 0.000036	 wd 0.0000	time 0.2284 (0.2436)	loss 1.4948 (1.3581)	grad_norm 0.4118 (0.4148)	loss_scale 8192.0000 (6673.9021)	mem 5279MB
[2024-07-14 01:01:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:36 lr 0.000036	 wd 0.0000	time 0.2041 (0.2399)	loss 1.3111 (1.3557)	grad_norm 0.3894 (0.4146)	loss_scale 8192.0000 (6811.7856)	mem 5279MB
[2024-07-14 01:01:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:08 lr 0.000035	 wd 0.0000	time 0.1922 (0.2368)	loss 1.3484 (1.3563)	grad_norm 0.4230 (0.4150)	loss_scale 8192.0000 (6926.7077)	mem 5279MB
[2024-07-14 01:01:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:41 lr 0.000035	 wd 0.0000	time 0.1770 (0.2343)	loss 1.5783 (1.3589)	grad_norm 0.4070 (0.4150)	loss_scale 8192.0000 (7023.9631)	mem 5279MB
[2024-07-14 01:02:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:18 lr 0.000035	 wd 0.0000	time 0.2297 (0.2350)	loss 1.3561 (1.3594)	grad_norm 0.4461 (0.4149)	loss_scale 8192.0000 (7107.3348)	mem 5279MB
[2024-07-14 01:02:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:03:53 lr 0.000035	 wd 0.0000	time 0.1799 (0.2333)	loss 1.2609 (1.3593)	grad_norm 0.3774 (0.4147)	loss_scale 8192.0000 (7179.5976)	mem 5279MB
[2024-07-14 01:02:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:28 lr 0.000035	 wd 0.0000	time 0.1774 (0.2315)	loss 1.2369 (1.3607)	grad_norm 0.4200 (0.4146)	loss_scale 8192.0000 (7242.8332)	mem 5279MB
[2024-07-14 01:03:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:04 lr 0.000035	 wd 0.0000	time 0.2043 (0.2298)	loss 1.3137 (1.3617)	grad_norm 0.4063 (0.4146)	loss_scale 8192.0000 (7298.6337)	mem 5279MB
[2024-07-14 01:03:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:40 lr 0.000035	 wd 0.0000	time 0.1912 (0.2291)	loss 1.4136 (1.3623)	grad_norm 0.4571 (0.4146)	loss_scale 8192.0000 (7348.2376)	mem 5279MB
[2024-07-14 01:03:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:18 lr 0.000035	 wd 0.0000	time 0.2618 (0.2296)	loss 1.5178 (1.3638)	grad_norm 0.4129 (0.4149)	loss_scale 8192.0000 (7392.6228)	mem 5279MB
[2024-07-14 01:04:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:54 lr 0.000035	 wd 0.0000	time 0.2115 (0.2284)	loss 1.2572 (1.3648)	grad_norm 0.4257 (0.4154)	loss_scale 8192.0000 (7432.5717)	mem 5279MB
[2024-07-14 01:04:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:31 lr 0.000035	 wd 0.0000	time 0.2199 (0.2273)	loss 1.5680 (1.3666)	grad_norm 0.4228 (0.4153)	loss_scale 8192.0000 (7468.7178)	mem 5279MB
[2024-07-14 01:04:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:08 lr 0.000035	 wd 0.0000	time 0.1911 (0.2263)	loss 0.9657 (1.3664)	grad_norm 0.4107 (0.4173)	loss_scale 8192.0000 (7501.5793)	mem 5279MB
[2024-07-14 01:05:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:45 lr 0.000035	 wd 0.0000	time 0.1371 (0.2261)	loss 1.4936 (1.3660)	grad_norm 0.4408 (0.4171)	loss_scale 8192.0000 (7531.5845)	mem 5279MB
[2024-07-14 01:05:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:23 lr 0.000035	 wd 0.0000	time 0.1740 (0.2259)	loss 1.5208 (1.3659)	grad_norm 0.3943 (0.4173)	loss_scale 8192.0000 (7559.0904)	mem 5279MB
[2024-07-14 01:06:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1536 (0.2239)	loss 1.3441 (1.3649)	grad_norm 0.4098 (0.4174)	loss_scale 8192.0000 (7584.3966)	mem 5279MB
[2024-07-14 01:06:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 10 training takes 0:09:24
[2024-07-14 01:06:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 19.532 (19.532)	Loss 0.4153 (0.4153)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 01:06:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 83.958 Acc@5 97.246
[2024-07-14 01:06:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-14 01:06:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.01%
[2024-07-14 01:07:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][0/2502]	eta 1 day, 2:37:52 lr 0.000035	 wd 0.0000	time 38.3182 (38.3182)	loss 1.5112 (1.5112)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:07:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:23:18 lr 0.000035	 wd 0.0000	time 0.1965 (0.5824)	loss 1.4016 (1.3558)	grad_norm 0.4476 (0.4232)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:07:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:14:59 lr 0.000034	 wd 0.0000	time 0.1745 (0.3906)	loss 1.4793 (1.3601)	grad_norm 0.4018 (0.4342)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:08:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:12:09 lr 0.000034	 wd 0.0000	time 0.2181 (0.3314)	loss 1.3365 (1.3624)	grad_norm 0.4181 (0.4308)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:08:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:11:51 lr 0.000034	 wd 0.0000	time 0.1775 (0.3386)	loss 1.5449 (1.3624)	grad_norm 0.4105 (0.4297)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:09:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:10:22 lr 0.000034	 wd 0.0000	time 0.1888 (0.3108)	loss 1.3804 (1.3592)	grad_norm 0.3738 (0.4255)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:09:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:09:15 lr 0.000034	 wd 0.0000	time 0.2015 (0.2922)	loss 1.4868 (1.3569)	grad_norm 0.4180 (0.4265)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:09:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:08:24 lr 0.000034	 wd 0.0000	time 0.2271 (0.2802)	loss 1.4796 (1.3574)	grad_norm 0.4147 (0.4261)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:10:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:08:08 lr 0.000034	 wd 0.0000	time 0.2197 (0.2872)	loss 1.6168 (1.3599)	grad_norm 0.4279 (0.4258)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:10:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:07:24 lr 0.000034	 wd 0.0000	time 0.1722 (0.2775)	loss 1.5227 (1.3599)	grad_norm 0.4119 (0.4250)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:11:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:45 lr 0.000034	 wd 0.0000	time 0.1859 (0.2696)	loss 1.4623 (1.3619)	grad_norm 0.4353 (0.4251)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:11:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:06:10 lr 0.000034	 wd 0.0000	time 0.2602 (0.2639)	loss 1.5608 (1.3633)	grad_norm 0.4481 (0.4255)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:11:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:42 lr 0.000034	 wd 0.0000	time 0.1899 (0.2631)	loss 1.6906 (1.3631)	grad_norm 0.4217 (0.4253)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:12:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:05:10 lr 0.000034	 wd 0.0000	time 0.1813 (0.2586)	loss 0.9094 (1.3621)	grad_norm 0.4038 (0.4256)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:12:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:40 lr 0.000034	 wd 0.0000	time 0.1989 (0.2546)	loss 0.8811 (1.3617)	grad_norm 0.3785 (0.4252)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:12:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:04:11 lr 0.000034	 wd 0.0000	time 0.2071 (0.2509)	loss 1.4396 (1.3609)	grad_norm 0.3812 (0.4240)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:13:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:44 lr 0.000034	 wd 0.0000	time 0.2349 (0.2490)	loss 1.2618 (1.3619)	grad_norm 0.4318 (0.4239)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:13:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:19 lr 0.000033	 wd 0.0000	time 0.2379 (0.2483)	loss 1.4738 (1.3611)	grad_norm 0.3929 (0.4248)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:13:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:52 lr 0.000033	 wd 0.0000	time 0.1954 (0.2460)	loss 1.2968 (1.3628)	grad_norm 0.3985 (0.4244)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:14:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:26 lr 0.000033	 wd 0.0000	time 0.1930 (0.2439)	loss 1.5016 (1.3630)	grad_norm 0.4084 (0.4239)	loss_scale 16384.0000 (8329.8979)	mem 5279MB
[2024-07-14 01:14:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:02:01 lr 0.000033	 wd 0.0000	time 0.2104 (0.2420)	loss 1.1153 (1.3624)	grad_norm 0.3944 (0.4235)	loss_scale 16384.0000 (8732.4018)	mem 5279MB
[2024-07-14 01:15:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:37 lr 0.000033	 wd 0.0000	time 0.1934 (0.2418)	loss 1.5700 (1.3622)	grad_norm 0.4365 (0.4236)	loss_scale 16384.0000 (9096.5902)	mem 5279MB
[2024-07-14 01:15:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:12 lr 0.000033	 wd 0.0000	time 0.1811 (0.2406)	loss 1.2807 (1.3631)	grad_norm 0.4074 (0.4239)	loss_scale 16384.0000 (9427.6856)	mem 5279MB
[2024-07-14 01:15:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:48 lr 0.000033	 wd 0.0000	time 0.1850 (0.2390)	loss 1.5436 (1.3629)	grad_norm 0.4058 (0.4235)	loss_scale 16384.0000 (9730.0026)	mem 5279MB
[2024-07-14 01:16:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:24 lr 0.000033	 wd 0.0000	time 0.1944 (0.2374)	loss 1.2673 (1.3621)	grad_norm 0.4353 (0.4235)	loss_scale 16384.0000 (10007.1370)	mem 5279MB
[2024-07-14 01:16:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000033	 wd 0.0000	time 0.1492 (0.2351)	loss 1.4007 (1.3617)	grad_norm 0.4084 (0.4232)	loss_scale 16384.0000 (10262.1096)	mem 5279MB
[2024-07-14 01:16:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 11 training takes 0:09:52
[2024-07-14 01:17:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 38.283 (38.283)	Loss 0.4136 (0.4136)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 5279MB
[2024-07-14 01:17:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.100 Acc@5 97.278
[2024-07-14 01:17:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 01:17:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.10%
[2024-07-14 01:17:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth saving......
[2024-07-14 01:17:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth saved !!!
[2024-07-14 01:17:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][0/2502]	eta 10:51:10 lr 0.000033	 wd 0.0000	time 15.6157 (15.6157)	loss 1.6237 (1.6237)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 01:17:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:14:48 lr 0.000033	 wd 0.0000	time 0.2597 (0.3699)	loss 1.5020 (1.3669)	grad_norm 0.4052 (0.4206)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 01:18:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:13:10 lr 0.000033	 wd 0.0000	time 0.1720 (0.3434)	loss 0.9891 (1.3730)	grad_norm 0.4544 (0.4260)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 01:18:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:49 lr 0.000033	 wd 0.0000	time 0.1915 (0.2950)	loss 1.2960 (1.3732)	grad_norm 0.4490 (0.4219)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 01:19:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:29 lr 0.000033	 wd 0.0000	time 0.1732 (0.2710)	loss 1.2334 (1.3657)	grad_norm 0.3965 (0.4206)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 01:19:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:08:35 lr 0.000032	 wd 0.0000	time 0.2414 (0.2573)	loss 1.0138 (1.3664)	grad_norm 0.4240 (nan)	loss_scale 8192.0000 (16187.7844)	mem 5279MB
[2024-07-14 01:20:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:08:37 lr 0.000032	 wd 0.0000	time 0.2022 (0.2719)	loss 1.3581 (1.3637)	grad_norm 0.4191 (nan)	loss_scale 8192.0000 (14857.3710)	mem 5279MB
[2024-07-14 01:20:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:51 lr 0.000032	 wd 0.0000	time 0.2049 (0.2618)	loss 1.4624 (1.3615)	grad_norm 0.4239 (nan)	loss_scale 8192.0000 (13906.5335)	mem 5279MB
[2024-07-14 01:20:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:07:12 lr 0.000032	 wd 0.0000	time 0.1896 (0.2543)	loss 1.4608 (1.3695)	grad_norm 0.4070 (nan)	loss_scale 8192.0000 (13193.1086)	mem 5279MB
[2024-07-14 01:21:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:38 lr 0.000032	 wd 0.0000	time 0.2143 (0.2487)	loss 1.0474 (1.3698)	grad_norm 0.4059 (nan)	loss_scale 8192.0000 (12638.0466)	mem 5279MB
[2024-07-14 01:21:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:12 lr 0.000032	 wd 0.0000	time 0.2309 (0.2477)	loss 1.6549 (1.3675)	grad_norm 0.4098 (nan)	loss_scale 8192.0000 (12193.8861)	mem 5279MB
[2024-07-14 01:21:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:43 lr 0.000032	 wd 0.0000	time 0.1807 (0.2448)	loss 1.4764 (1.3714)	grad_norm 0.4041 (nan)	loss_scale 8192.0000 (11830.4087)	mem 5279MB
[2024-07-14 01:22:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:14 lr 0.000032	 wd 0.0000	time 0.1915 (0.2412)	loss 1.5130 (1.3705)	grad_norm 0.4231 (nan)	loss_scale 8192.0000 (11527.4604)	mem 5279MB
[2024-07-14 01:22:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:45 lr 0.000032	 wd 0.0000	time 0.1870 (0.2379)	loss 1.4575 (1.3709)	grad_norm 0.4030 (nan)	loss_scale 8192.0000 (11271.0838)	mem 5279MB
[2024-07-14 01:22:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:20 lr 0.000032	 wd 0.0000	time 0.2337 (0.2363)	loss 1.5997 (1.3708)	grad_norm 0.4246 (nan)	loss_scale 8192.0000 (11051.3062)	mem 5279MB
[2024-07-14 01:23:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:03:56 lr 0.000032	 wd 0.0000	time 0.3739 (0.2358)	loss 1.4270 (1.3715)	grad_norm 0.4001 (nan)	loss_scale 8192.0000 (10860.8128)	mem 5279MB
[2024-07-14 01:23:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:30 lr 0.000032	 wd 0.0000	time 0.1779 (0.2338)	loss 1.4217 (1.3703)	grad_norm 0.5020 (nan)	loss_scale 8192.0000 (10694.1162)	mem 5279MB
[2024-07-14 01:23:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:06 lr 0.000031	 wd 0.0000	time 0.1656 (0.2320)	loss 1.5637 (1.3714)	grad_norm 0.4302 (nan)	loss_scale 8192.0000 (10547.0194)	mem 5279MB
[2024-07-14 01:24:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:41 lr 0.000031	 wd 0.0000	time 0.1712 (0.2304)	loss 1.2804 (1.3721)	grad_norm 0.4177 (nan)	loss_scale 8192.0000 (10416.2576)	mem 5279MB
[2024-07-14 01:24:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:18 lr 0.000031	 wd 0.0000	time 0.1985 (0.2300)	loss 1.4269 (1.3717)	grad_norm 0.4527 (nan)	loss_scale 8192.0000 (10299.2530)	mem 5279MB
[2024-07-14 01:25:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:01:55 lr 0.000031	 wd 0.0000	time 0.1743 (0.2305)	loss 1.4159 (1.3707)	grad_norm 0.3863 (nan)	loss_scale 8192.0000 (10193.9430)	mem 5279MB
[2024-07-14 01:25:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:32 lr 0.000031	 wd 0.0000	time 0.2314 (0.2294)	loss 1.4459 (1.3719)	grad_norm 0.4181 (nan)	loss_scale 8192.0000 (10098.6578)	mem 5279MB
[2024-07-14 01:25:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:08 lr 0.000031	 wd 0.0000	time 0.2010 (0.2281)	loss 1.5709 (1.3734)	grad_norm 0.4374 (nan)	loss_scale 8192.0000 (10012.0309)	mem 5279MB
[2024-07-14 01:26:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:45 lr 0.000031	 wd 0.0000	time 0.1965 (0.2275)	loss 1.4397 (1.3734)	grad_norm 0.4289 (nan)	loss_scale 8192.0000 (9932.9335)	mem 5279MB
[2024-07-14 01:26:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:23 lr 0.000031	 wd 0.0000	time 0.1855 (0.2278)	loss 1.4989 (1.3731)	grad_norm 0.4434 (nan)	loss_scale 8192.0000 (9860.4248)	mem 5279MB
[2024-07-14 01:26:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000031	 wd 0.0000	time 0.1421 (0.2258)	loss 1.1208 (1.3719)	grad_norm 0.4308 (nan)	loss_scale 8192.0000 (9793.7145)	mem 5279MB
[2024-07-14 01:26:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 12 training takes 0:09:29
[2024-07-14 01:27:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 21.011 (21.011)	Loss 0.4143 (0.4143)	Acc@1 92.773 (92.773)	Acc@5 98.438 (98.438)	Mem 5279MB
[2024-07-14 01:27:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.054 Acc@5 97.274
[2024-07-14 01:27:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 01:27:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.10%
[2024-07-14 01:27:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][0/2502]	eta 23:37:29 lr 0.000031	 wd 0.0000	time 33.9926 (33.9926)	loss 1.3692 (1.3692)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:28:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:21:41 lr 0.000031	 wd 0.0000	time 0.1773 (0.5420)	loss 1.4109 (1.3583)	grad_norm 0.4161 (0.4200)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:28:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:14:12 lr 0.000031	 wd 0.0000	time 0.1876 (0.3702)	loss 1.6884 (1.3605)	grad_norm 0.4404 (0.4180)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:28:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:11:30 lr 0.000031	 wd 0.0000	time 0.1877 (0.3136)	loss 1.4476 (1.3690)	grad_norm 0.3926 (0.4159)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:29:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:10:12 lr 0.000030	 wd 0.0000	time 0.3663 (0.2912)	loss 1.3401 (1.3676)	grad_norm 0.4152 (0.4149)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:29:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:10:03 lr 0.000030	 wd 0.0000	time 0.2030 (0.3015)	loss 1.5303 (1.3621)	grad_norm 0.5040 (0.4158)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:30:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:09:01 lr 0.000030	 wd 0.0000	time 0.1870 (0.2845)	loss 1.5328 (1.3681)	grad_norm 0.3974 (0.4159)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:30:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:08:10 lr 0.000030	 wd 0.0000	time 0.1796 (0.2721)	loss 1.4355 (1.3634)	grad_norm 0.4212 (0.4169)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:30:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:34 lr 0.000030	 wd 0.0000	time 0.4390 (0.2672)	loss 1.5454 (1.3672)	grad_norm 0.3822 (0.4165)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:31:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:07:15 lr 0.000030	 wd 0.0000	time 0.1857 (0.2719)	loss 1.5334 (1.3642)	grad_norm 0.4387 (0.4169)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:31:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:37 lr 0.000030	 wd 0.0000	time 0.1842 (0.2647)	loss 1.6095 (1.3697)	grad_norm 0.3850 (0.4175)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:32:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:06:03 lr 0.000030	 wd 0.0000	time 0.1970 (0.2590)	loss 1.3956 (1.3713)	grad_norm 0.4624 (0.4176)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:32:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:32 lr 0.000030	 wd 0.0000	time 0.2082 (0.2553)	loss 1.5678 (1.3675)	grad_norm 0.4044 (0.4177)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:32:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:05:05 lr 0.000030	 wd 0.0000	time 0.2544 (0.2539)	loss 1.4284 (1.3663)	grad_norm 0.3891 (0.4194)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:33:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:35 lr 0.000030	 wd 0.0000	time 0.1993 (0.2503)	loss 1.6549 (1.3668)	grad_norm 0.4121 (0.4190)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:33:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:04:07 lr 0.000030	 wd 0.0000	time 0.2321 (0.2472)	loss 1.6332 (1.3656)	grad_norm 0.4088 (0.4191)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:33:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:40 lr 0.000029	 wd 0.0000	time 0.2120 (0.2442)	loss 1.5779 (1.3652)	grad_norm 0.4117 (0.4194)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:34:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:14 lr 0.000029	 wd 0.0000	time 0.2024 (0.2426)	loss 0.8701 (1.3628)	grad_norm 0.4198 (nan)	loss_scale 4096.0000 (8129.3921)	mem 5279MB
[2024-07-14 01:34:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:50 lr 0.000029	 wd 0.0000	time 0.1855 (0.2429)	loss 1.4326 (1.3645)	grad_norm 0.4436 (nan)	loss_scale 4096.0000 (7905.4392)	mem 5279MB
[2024-07-14 01:35:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:25 lr 0.000029	 wd 0.0000	time 0.2110 (0.2410)	loss 1.2230 (1.3649)	grad_norm 0.4033 (nan)	loss_scale 4096.0000 (7705.0479)	mem 5279MB
[2024-07-14 01:35:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:59 lr 0.000029	 wd 0.0000	time 0.1751 (0.2390)	loss 1.4371 (1.3660)	grad_norm 0.4006 (nan)	loss_scale 4096.0000 (7524.6857)	mem 5279MB
[2024-07-14 01:35:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:35 lr 0.000029	 wd 0.0000	time 0.1958 (0.2377)	loss 1.1113 (1.3657)	grad_norm 0.4125 (nan)	loss_scale 4096.0000 (7361.4926)	mem 5279MB
[2024-07-14 01:36:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:11 lr 0.000029	 wd 0.0000	time 0.1854 (0.2374)	loss 1.5418 (1.3672)	grad_norm 0.4157 (nan)	loss_scale 4096.0000 (7213.1286)	mem 5279MB
[2024-07-14 01:36:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:47 lr 0.000029	 wd 0.0000	time 0.2005 (0.2361)	loss 1.3095 (1.3666)	grad_norm 0.4299 (nan)	loss_scale 4096.0000 (7077.6601)	mem 5279MB
[2024-07-14 01:36:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:23 lr 0.000029	 wd 0.0000	time 0.2086 (0.2347)	loss 1.6880 (1.3678)	grad_norm 0.4040 (nan)	loss_scale 4096.0000 (6953.4761)	mem 5279MB
[2024-07-14 01:37:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000029	 wd 0.0000	time 0.1498 (0.2320)	loss 1.5332 (1.3672)	grad_norm 0.4108 (nan)	loss_scale 4096.0000 (6839.2227)	mem 5279MB
[2024-07-14 01:37:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 13 training takes 0:09:44
[2024-07-14 01:37:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 40.813 (40.813)	Loss 0.4116 (0.4116)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 01:38:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.040 Acc@5 97.306
[2024-07-14 01:38:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-14 01:38:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.10%
[2024-07-14 01:38:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][0/2502]	eta 11:56:36 lr 0.000029	 wd 0.0000	time 17.1847 (17.1847)	loss 1.4890 (1.4890)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:38:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:14:40 lr 0.000029	 wd 0.0000	time 0.1948 (0.3666)	loss 1.5431 (1.3773)	grad_norm 0.3993 (0.4127)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:39:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:11:54 lr 0.000028	 wd 0.0000	time 0.3300 (0.3102)	loss 1.3034 (1.3962)	grad_norm 0.3811 (0.4183)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:39:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:10:32 lr 0.000028	 wd 0.0000	time 0.1955 (0.2873)	loss 1.0157 (1.3843)	grad_norm 0.3933 (0.4172)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:39:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:09:16 lr 0.000028	 wd 0.0000	time 0.1907 (0.2645)	loss 1.2095 (1.3693)	grad_norm 0.4148 (0.4197)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:40:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:08:23 lr 0.000028	 wd 0.0000	time 0.1915 (0.2515)	loss 1.2886 (1.3720)	grad_norm 0.4238 (0.4207)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:40:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:07:44 lr 0.000028	 wd 0.0000	time 0.2077 (0.2442)	loss 1.6690 (1.3775)	grad_norm 0.4447 (0.4203)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:40:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:34 lr 0.000028	 wd 0.0000	time 0.1810 (0.2521)	loss 1.4393 (1.3734)	grad_norm 0.4093 (0.4198)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:41:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:06:57 lr 0.000028	 wd 0.0000	time 0.1808 (0.2455)	loss 1.3815 (1.3697)	grad_norm 0.5946 (0.4214)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:41:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:25 lr 0.000028	 wd 0.0000	time 0.1485 (0.2406)	loss 1.4418 (1.3659)	grad_norm 0.4416 (0.4212)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:42:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:05:55 lr 0.000028	 wd 0.0000	time 0.2036 (0.2368)	loss 1.3299 (1.3642)	grad_norm 0.4031 (0.4206)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:42:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:30 lr 0.000028	 wd 0.0000	time 0.2348 (0.2359)	loss 1.4896 (1.3619)	grad_norm 0.3780 (0.4209)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:42:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:06 lr 0.000028	 wd 0.0000	time 0.2049 (0.2352)	loss 1.4107 (1.3620)	grad_norm 0.3993 (0.4212)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:43:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:04:39 lr 0.000027	 wd 0.0000	time 0.2002 (0.2328)	loss 1.1775 (1.3622)	grad_norm 0.4214 (0.4209)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:43:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:13 lr 0.000027	 wd 0.0000	time 0.1997 (0.2304)	loss 1.6624 (1.3612)	grad_norm 0.4217 (0.4208)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:43:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:03:49 lr 0.000027	 wd 0.0000	time 0.2382 (0.2291)	loss 1.3689 (1.3620)	grad_norm 0.3953 (0.4208)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:44:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:26 lr 0.000027	 wd 0.0000	time 0.3584 (0.2295)	loss 1.3186 (1.3619)	grad_norm 0.4653 (0.4208)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:44:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:02 lr 0.000027	 wd 0.0000	time 0.2001 (0.2281)	loss 1.2048 (1.3612)	grad_norm 0.4661 (0.4207)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:44:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:39 lr 0.000027	 wd 0.0000	time 0.1995 (0.2270)	loss 1.3198 (1.3611)	grad_norm 0.4142 (0.4211)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:45:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:15 lr 0.000027	 wd 0.0000	time 0.2430 (0.2256)	loss 1.5518 (1.3612)	grad_norm 0.4321 (0.4210)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:45:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:01:53 lr 0.000027	 wd 0.0000	time 0.2178 (0.2254)	loss 1.0716 (1.3631)	grad_norm 0.4042 (0.4212)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:45:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:30 lr 0.000027	 wd 0.0000	time 0.1677 (0.2254)	loss 1.5709 (1.3628)	grad_norm 2.0522 (0.4228)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:46:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:07 lr 0.000027	 wd 0.0000	time 0.2068 (0.2244)	loss 1.2130 (1.3630)	grad_norm 0.4704 (0.4233)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:46:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:45 lr 0.000027	 wd 0.0000	time 0.2156 (0.2235)	loss 1.3967 (1.3639)	grad_norm 0.5818 (0.4236)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:46:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:22 lr 0.000026	 wd 0.0000	time 0.1911 (0.2230)	loss 1.1407 (1.3649)	grad_norm 0.4398 (0.4247)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:47:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1404 (0.2215)	loss 1.2470 (1.3640)	grad_norm 0.4289 (0.4243)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:47:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 14 training takes 0:09:20
[2024-07-14 01:47:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 23.215 (23.215)	Loss 0.4114 (0.4114)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 01:47:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.006 Acc@5 97.258
[2024-07-14 01:47:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-14 01:47:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.10%
[2024-07-14 01:48:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][0/2502]	eta 10:53:09 lr 0.000026	 wd 0.0000	time 15.6632 (15.6632)	loss 1.4605 (1.4605)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:48:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:15:24 lr 0.000026	 wd 0.0000	time 0.2778 (0.3848)	loss 1.0174 (1.3511)	grad_norm 0.4036 (0.4162)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:49:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:13:00 lr 0.000026	 wd 0.0000	time 0.1861 (0.3391)	loss 1.4514 (1.3659)	grad_norm 0.4124 (0.4302)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:49:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:10:45 lr 0.000026	 wd 0.0000	time 0.1771 (0.2931)	loss 1.3974 (1.3529)	grad_norm 0.3825 (0.4242)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:49:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:09:26 lr 0.000026	 wd 0.0000	time 0.1670 (0.2697)	loss 1.4031 (1.3564)	grad_norm 0.4282 (0.4218)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:50:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:08:31 lr 0.000026	 wd 0.0000	time 0.2176 (0.2557)	loss 0.8738 (1.3541)	grad_norm 0.4012 (0.4219)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:50:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:08:27 lr 0.000026	 wd 0.0000	time 0.2166 (0.2668)	loss 0.8433 (1.3576)	grad_norm 0.4257 (0.4220)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 01:50:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:43 lr 0.000026	 wd 0.0000	time 0.1852 (0.2574)	loss 1.1101 (1.3602)	grad_norm 0.4659 (0.4220)	loss_scale 8192.0000 (4271.2924)	mem 5279MB
[2024-07-14 01:51:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:07:05 lr 0.000026	 wd 0.0000	time 0.2240 (0.2501)	loss 1.4113 (1.3606)	grad_norm 0.4362 (0.4216)	loss_scale 8192.0000 (4760.7690)	mem 5279MB
[2024-07-14 01:51:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:31 lr 0.000025	 wd 0.0000	time 0.2309 (0.2447)	loss 1.2314 (1.3614)	grad_norm 0.4004 (0.4236)	loss_scale 8192.0000 (5141.5938)	mem 5279MB
[2024-07-14 01:52:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:06:09 lr 0.000025	 wd 0.0000	time 1.9306 (0.2457)	loss 1.4392 (1.3630)	grad_norm 0.3891 (0.4230)	loss_scale 8192.0000 (5446.3297)	mem 5279MB
[2024-07-14 01:52:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:40 lr 0.000025	 wd 0.0000	time 0.1799 (0.2427)	loss 1.2476 (1.3601)	grad_norm 0.3945 (0.4225)	loss_scale 8192.0000 (5695.7094)	mem 5279MB
[2024-07-14 01:52:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:11 lr 0.000025	 wd 0.0000	time 0.2089 (0.2394)	loss 1.4031 (1.3608)	grad_norm 0.4073 (0.4222)	loss_scale 8192.0000 (5903.5604)	mem 5279MB
[2024-07-14 01:53:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:04:44 lr 0.000025	 wd 0.0000	time 0.2107 (0.2366)	loss 1.3778 (1.3591)	grad_norm 0.4256 (0.4221)	loss_scale 8192.0000 (6079.4589)	mem 5279MB
[2024-07-14 01:53:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:18 lr 0.000025	 wd 0.0000	time 0.1949 (0.2346)	loss 1.4530 (1.3594)	grad_norm 0.4084 (0.4219)	loss_scale 8192.0000 (6230.2470)	mem 5279MB
[2024-07-14 01:53:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:03:55 lr 0.000025	 wd 0.0000	time 0.2034 (0.2346)	loss 1.5782 (1.3591)	grad_norm 0.4117 (0.4223)	loss_scale 8192.0000 (6360.9434)	mem 5279MB
[2024-07-14 01:54:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:30 lr 0.000025	 wd 0.0000	time 0.1624 (0.2330)	loss 1.2881 (1.3614)	grad_norm 0.4092 (0.4234)	loss_scale 8192.0000 (6475.3129)	mem 5279MB
[2024-07-14 01:54:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:05 lr 0.000025	 wd 0.0000	time 0.1620 (0.2311)	loss 1.4314 (1.3605)	grad_norm 0.4165 (0.4235)	loss_scale 8192.0000 (6576.2352)	mem 5279MB
[2024-07-14 01:54:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:41 lr 0.000025	 wd 0.0000	time 0.2035 (0.2296)	loss 1.0819 (1.3602)	grad_norm 0.4247 (0.4232)	loss_scale 8192.0000 (6665.9500)	mem 5279MB
[2024-07-14 01:55:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:17 lr 0.000024	 wd 0.0000	time 0.2105 (0.2292)	loss 1.6052 (1.3607)	grad_norm 0.4035 (0.4245)	loss_scale 8192.0000 (6746.2262)	mem 5279MB
[2024-07-14 01:55:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:01:55 lr 0.000024	 wd 0.0000	time 0.1678 (0.2297)	loss 1.8459 (1.3629)	grad_norm 0.4347 (0.4242)	loss_scale 8192.0000 (6818.4788)	mem 5279MB
[2024-07-14 01:55:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:31 lr 0.000024	 wd 0.0000	time 0.1901 (0.2284)	loss 1.5145 (1.3637)	grad_norm 0.4410 (0.4239)	loss_scale 8192.0000 (6883.8534)	mem 5279MB
[2024-07-14 01:56:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:08 lr 0.000024	 wd 0.0000	time 0.1712 (0.2272)	loss 1.0765 (1.3649)	grad_norm 0.3756 (0.4237)	loss_scale 8192.0000 (6943.2876)	mem 5279MB
[2024-07-14 01:56:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:45 lr 0.000024	 wd 0.0000	time 0.2445 (0.2266)	loss 1.5874 (1.3650)	grad_norm 0.4055 (0.4235)	loss_scale 8192.0000 (6997.5558)	mem 5279MB
[2024-07-14 01:57:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:23 lr 0.000024	 wd 0.0000	time 0.1797 (0.2267)	loss 1.0754 (1.3638)	grad_norm 0.4650 (0.4236)	loss_scale 8192.0000 (7047.3036)	mem 5279MB
[2024-07-14 01:57:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1320 (0.2247)	loss 1.2176 (1.3639)	grad_norm 0.3885 (0.4233)	loss_scale 8192.0000 (7093.0732)	mem 5279MB
[2024-07-14 01:57:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 15 training takes 0:09:26
[2024-07-14 01:57:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_15.pth saving......
[2024-07-14 01:57:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_15.pth saved !!!
[2024-07-14 01:57:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 20.455 (20.455)	Loss 0.4133 (0.4133)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 01:58:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.022 Acc@5 97.276
[2024-07-14 01:58:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-14 01:58:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.10%
[2024-07-14 01:58:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][0/2502]	eta 21:38:23 lr 0.000024	 wd 0.0000	time 31.1363 (31.1363)	loss 1.2747 (1.2747)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:58:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:21:09 lr 0.000024	 wd 0.0000	time 0.2055 (0.5286)	loss 1.4767 (1.3576)	grad_norm 0.4320 (0.4194)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:59:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:13:57 lr 0.000024	 wd 0.0000	time 0.1863 (0.3640)	loss 1.3196 (1.3670)	grad_norm 0.4363 (0.4210)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:59:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:11:19 lr 0.000024	 wd 0.0000	time 0.1905 (0.3088)	loss 1.3695 (1.3789)	grad_norm 0.3919 (0.4190)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 01:59:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:10:15 lr 0.000024	 wd 0.0000	time 0.5229 (0.2926)	loss 1.2734 (1.3729)	grad_norm 0.4224 (0.4205)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:00:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:09:57 lr 0.000023	 wd 0.0000	time 0.1877 (0.2983)	loss 1.2619 (1.3832)	grad_norm 0.3960 (0.4214)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:00:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:55 lr 0.000023	 wd 0.0000	time 0.1890 (0.2816)	loss 1.0426 (1.3755)	grad_norm 0.4618 (0.4221)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:01:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:08:05 lr 0.000023	 wd 0.0000	time 0.1789 (0.2696)	loss 1.3316 (1.3773)	grad_norm 0.4092 (0.4219)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:01:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:07:28 lr 0.000023	 wd 0.0000	time 0.2329 (0.2632)	loss 1.3964 (1.3717)	grad_norm 0.3915 (0.4213)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:01:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:07:05 lr 0.000023	 wd 0.0000	time 0.1906 (0.2656)	loss 1.5606 (1.3695)	grad_norm 0.4070 (0.4226)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:02:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:06:29 lr 0.000023	 wd 0.0000	time 0.2133 (0.2590)	loss 1.5681 (1.3697)	grad_norm 0.4006 (0.4233)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:02:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:55 lr 0.000023	 wd 0.0000	time 0.1817 (0.2537)	loss 1.3333 (1.3708)	grad_norm 0.4356 (0.4244)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:02:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:24 lr 0.000023	 wd 0.0000	time 0.2292 (0.2496)	loss 1.4249 (1.3720)	grad_norm 0.4177 (0.4238)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:03:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:04:59 lr 0.000023	 wd 0.0000	time 0.1671 (0.2492)	loss 1.0961 (1.3725)	grad_norm 0.4028 (0.4235)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:03:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:30 lr 0.000023	 wd 0.0000	time 0.2000 (0.2459)	loss 1.2028 (1.3698)	grad_norm 0.4002 (0.4245)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:04:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:04:03 lr 0.000022	 wd 0.0000	time 0.2218 (0.2429)	loss 1.3984 (1.3667)	grad_norm 0.6233 (0.4248)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:04:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:36 lr 0.000022	 wd 0.0000	time 0.2135 (0.2402)	loss 1.3849 (1.3671)	grad_norm 0.4336 (0.4245)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:04:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:11 lr 0.000022	 wd 0.0000	time 0.2086 (0.2388)	loss 1.1079 (1.3651)	grad_norm 0.5574 (0.4260)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:05:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:48 lr 0.000022	 wd 0.0000	time 0.2096 (0.2393)	loss 1.2516 (1.3634)	grad_norm 0.4342 (0.4261)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:05:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:23 lr 0.000022	 wd 0.0000	time 0.1925 (0.2377)	loss 1.1920 (1.3622)	grad_norm 0.3942 (0.4261)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:05:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:01:58 lr 0.000022	 wd 0.0000	time 0.2116 (0.2360)	loss 1.4793 (1.3625)	grad_norm 0.4184 (0.4262)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:06:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:34 lr 0.000022	 wd 0.0000	time 0.1881 (0.2345)	loss 1.3550 (1.3620)	grad_norm 0.4293 (0.4261)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:06:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:10 lr 0.000022	 wd 0.0000	time 0.1942 (0.2339)	loss 1.4728 (1.3626)	grad_norm 0.3979 (0.4258)	loss_scale 16384.0000 (8311.1022)	mem 5279MB
[2024-07-14 02:06:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:47 lr 0.000022	 wd 0.0000	time 0.1967 (0.2331)	loss 1.2321 (1.3627)	grad_norm 0.4052 (0.4257)	loss_scale 16384.0000 (8661.9452)	mem 5279MB
[2024-07-14 02:07:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:23 lr 0.000022	 wd 0.0000	time 0.2193 (0.2319)	loss 1.5488 (1.3629)	grad_norm 0.4152 (0.4253)	loss_scale 16384.0000 (8983.5635)	mem 5279MB
[2024-07-14 02:07:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1555 (0.2296)	loss 1.3870 (1.3628)	grad_norm 0.4566 (0.4253)	loss_scale 16384.0000 (9279.4626)	mem 5279MB
[2024-07-14 02:07:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 16 training takes 0:09:38
[2024-07-14 02:08:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 39.335 (39.335)	Loss 0.4131 (0.4131)	Acc@1 92.969 (92.969)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 02:08:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.068 Acc@5 97.274
[2024-07-14 02:08:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 02:08:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.10%
[2024-07-14 02:08:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][0/2502]	eta 11:45:04 lr 0.000021	 wd 0.0000	time 16.9081 (16.9081)	loss 1.4539 (1.4539)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:09:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:14:31 lr 0.000021	 wd 0.0000	time 0.1939 (0.3630)	loss 1.5655 (1.3364)	grad_norm 0.4136 (0.4173)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:09:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:10:58 lr 0.000021	 wd 0.0000	time 0.2090 (0.2861)	loss 1.5897 (1.3521)	grad_norm 0.4367 (0.4192)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:10:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:11:02 lr 0.000021	 wd 0.0000	time 0.2195 (0.3008)	loss 1.3353 (1.3484)	grad_norm 0.4323 (0.4211)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:10:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:09:37 lr 0.000021	 wd 0.0000	time 0.1648 (0.2747)	loss 1.1373 (1.3426)	grad_norm 0.4008 (0.4243)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:10:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:08:39 lr 0.000021	 wd 0.0000	time 0.1759 (0.2595)	loss 1.3754 (1.3426)	grad_norm 0.4124 (0.4247)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:11:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:07:55 lr 0.000021	 wd 0.0000	time 0.1943 (0.2499)	loss 1.1853 (1.3495)	grad_norm 0.4294 (0.4247)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:11:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:43 lr 0.000021	 wd 0.0000	time 0.2401 (0.2569)	loss 1.3442 (1.3554)	grad_norm 0.3958 (0.4243)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:11:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:07:05 lr 0.000021	 wd 0.0000	time 0.2065 (0.2503)	loss 1.3683 (1.3592)	grad_norm 0.4095 (0.4260)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:12:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:31 lr 0.000021	 wd 0.0000	time 0.1941 (0.2444)	loss 1.5957 (1.3607)	grad_norm 0.4280 (0.4262)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:12:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:00 lr 0.000020	 wd 0.0000	time 0.1863 (0.2401)	loss 1.5374 (1.3592)	grad_norm 0.4264 (0.4253)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:12:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:35 lr 0.000020	 wd 0.0000	time 0.2341 (0.2390)	loss 1.1162 (1.3597)	grad_norm 0.4205 (0.4246)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:13:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:10 lr 0.000020	 wd 0.0000	time 0.2014 (0.2385)	loss 1.6011 (1.3615)	grad_norm 0.9230 (0.4246)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:13:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:04:43 lr 0.000020	 wd 0.0000	time 0.1861 (0.2360)	loss 1.1761 (1.3615)	grad_norm 0.6260 (0.4245)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:13:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:17 lr 0.000020	 wd 0.0000	time 0.1811 (0.2336)	loss 1.4896 (1.3623)	grad_norm 0.4265 (0.4243)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:14:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:03:52 lr 0.000020	 wd 0.0000	time 0.2403 (0.2317)	loss 1.3912 (1.3631)	grad_norm 0.4256 (0.4244)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:14:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:29 lr 0.000020	 wd 0.0000	time 0.2093 (0.2326)	loss 1.5562 (1.3644)	grad_norm 0.4155 (0.4246)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:15:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:05 lr 0.000020	 wd 0.0000	time 0.2068 (0.2313)	loss 1.5715 (1.3663)	grad_norm 0.4134 (0.4247)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:15:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:41 lr 0.000020	 wd 0.0000	time 0.1805 (0.2298)	loss 1.3128 (1.3671)	grad_norm 0.4384 (0.4248)	loss_scale 16384.0000 (16384.0000)	mem 5279MB
[2024-07-14 02:15:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:17 lr 0.000020	 wd 0.0000	time 0.2033 (0.2285)	loss 1.1556 (1.3679)	grad_norm 0.4648 (nan)	loss_scale 8192.0000 (16246.1021)	mem 5279MB
[2024-07-14 02:16:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:01:54 lr 0.000019	 wd 0.0000	time 0.2203 (0.2281)	loss 1.5650 (1.3658)	grad_norm 0.4452 (nan)	loss_scale 8192.0000 (15843.5982)	mem 5279MB
[2024-07-14 02:16:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:31 lr 0.000019	 wd 0.0000	time 0.2172 (0.2286)	loss 1.4367 (1.3656)	grad_norm 0.4018 (nan)	loss_scale 8192.0000 (15479.4098)	mem 5279MB
[2024-07-14 02:16:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:08 lr 0.000019	 wd 0.0000	time 0.1610 (0.2275)	loss 1.3411 (1.3667)	grad_norm 0.3908 (nan)	loss_scale 8192.0000 (15148.3144)	mem 5279MB
[2024-07-14 02:17:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:45 lr 0.000019	 wd 0.0000	time 0.1753 (0.2265)	loss 1.4777 (1.3661)	grad_norm 0.4282 (nan)	loss_scale 8192.0000 (14845.9974)	mem 5279MB
[2024-07-14 02:17:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:23 lr 0.000019	 wd 0.0000	time 0.2139 (0.2257)	loss 1.4713 (1.3647)	grad_norm 0.4058 (nan)	loss_scale 8192.0000 (14568.8630)	mem 5279MB
[2024-07-14 02:17:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000019	 wd 0.0000	time 0.1669 (0.2241)	loss 1.5030 (1.3652)	grad_norm 0.4075 (nan)	loss_scale 8192.0000 (14313.8904)	mem 5279MB
[2024-07-14 02:18:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 17 training takes 0:09:30
[2024-07-14 02:18:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 27.522 (27.522)	Loss 0.4124 (0.4124)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 02:18:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.092 Acc@5 97.282
[2024-07-14 02:18:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 02:18:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.10%
[2024-07-14 02:18:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][0/2502]	eta 11:23:52 lr 0.000019	 wd 0.0000	time 16.4000 (16.4000)	loss 1.6005 (1.6005)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:19:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:16:16 lr 0.000019	 wd 0.0000	time 0.2781 (0.4067)	loss 1.5700 (1.4053)	grad_norm 0.4350 (0.4277)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:19:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:12:42 lr 0.000019	 wd 0.0000	time 0.2013 (0.3313)	loss 1.4831 (1.3859)	grad_norm 0.4030 (0.4240)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:20:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:10:30 lr 0.000019	 wd 0.0000	time 0.1865 (0.2865)	loss 1.7261 (1.3851)	grad_norm 0.4071 (0.4247)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:20:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:09:15 lr 0.000019	 wd 0.0000	time 0.2024 (0.2645)	loss 1.4464 (1.3781)	grad_norm 0.4162 (0.4246)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:20:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:08:26 lr 0.000018	 wd 0.0000	time 0.2670 (0.2530)	loss 1.3127 (1.3676)	grad_norm 0.4225 (0.4257)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:21:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:08:24 lr 0.000018	 wd 0.0000	time 0.1840 (0.2654)	loss 1.6399 (1.3684)	grad_norm 0.3773 (0.4242)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:21:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:07:41 lr 0.000018	 wd 0.0000	time 0.1952 (0.2562)	loss 1.4332 (1.3688)	grad_norm 0.4051 (0.4234)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:22:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:03 lr 0.000018	 wd 0.0000	time 0.1754 (0.2491)	loss 1.0959 (1.3664)	grad_norm 0.4171 (0.4232)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:22:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:06:30 lr 0.000018	 wd 0.0000	time 0.2036 (0.2438)	loss 1.1806 (1.3625)	grad_norm 0.4945 (0.4229)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:22:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:15 lr 0.000018	 wd 0.0000	time 0.2027 (0.2501)	loss 1.0375 (1.3659)	grad_norm 0.4297 (0.4261)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:23:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:44 lr 0.000018	 wd 0.0000	time 0.1756 (0.2458)	loss 1.2631 (1.3654)	grad_norm 0.3925 (0.4258)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:23:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:15 lr 0.000018	 wd 0.0000	time 0.2005 (0.2420)	loss 1.6575 (1.3657)	grad_norm 0.4212 (0.4263)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:23:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:04:46 lr 0.000018	 wd 0.0000	time 0.2240 (0.2388)	loss 1.4146 (1.3663)	grad_norm 0.4900 (0.4271)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:24:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:22 lr 0.000018	 wd 0.0000	time 0.2279 (0.2379)	loss 1.2258 (1.3661)	grad_norm 0.4077 (0.4268)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:24:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:03:57 lr 0.000017	 wd 0.0000	time 0.1901 (0.2373)	loss 1.5958 (1.3652)	grad_norm 0.4082 (0.4264)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:24:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:32 lr 0.000017	 wd 0.0000	time 0.1966 (0.2352)	loss 1.4846 (1.3646)	grad_norm 0.4311 (0.4273)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:25:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:07 lr 0.000017	 wd 0.0000	time 0.2047 (0.2333)	loss 1.4746 (1.3648)	grad_norm 0.4137 (0.4273)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:25:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:42 lr 0.000017	 wd 0.0000	time 0.2547 (0.2321)	loss 1.3347 (1.3656)	grad_norm 0.4142 (0.4270)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:26:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:20 lr 0.000017	 wd 0.0000	time 0.2473 (0.2326)	loss 1.4747 (1.3649)	grad_norm 0.4169 (0.4267)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:26:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:01:56 lr 0.000017	 wd 0.0000	time 0.2019 (0.2315)	loss 1.3842 (1.3670)	grad_norm 0.4832 (0.4267)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:26:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:32 lr 0.000017	 wd 0.0000	time 0.2007 (0.2302)	loss 1.4454 (1.3663)	grad_norm 0.4483 (0.4264)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:27:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:09 lr 0.000017	 wd 0.0000	time 0.2062 (0.2290)	loss 1.3483 (1.3663)	grad_norm 0.3837 (0.4261)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:27:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:46 lr 0.000017	 wd 0.0000	time 0.2341 (0.2287)	loss 1.4994 (1.3666)	grad_norm 0.3951 (0.4261)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:27:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:23 lr 0.000017	 wd 0.0000	time 0.2407 (0.2289)	loss 1.5247 (1.3679)	grad_norm 0.4181 (0.4264)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:28:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1454 (0.2267)	loss 1.4953 (1.3674)	grad_norm 0.3964 (0.4271)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:28:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 18 training takes 0:09:33
[2024-07-14 02:28:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 18.574 (18.574)	Loss 0.4138 (0.4138)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 02:28:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.064 Acc@5 97.246
[2024-07-14 02:28:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 02:28:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.10%
[2024-07-14 02:29:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][0/2502]	eta 1 day, 0:57:46 lr 0.000016	 wd 0.0000	time 35.9179 (35.9179)	loss 1.4313 (1.4313)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:29:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:22:08 lr 0.000016	 wd 0.0000	time 0.1940 (0.5533)	loss 1.1022 (1.3793)	grad_norm 0.4222 (0.4223)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:30:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:14:24 lr 0.000016	 wd 0.0000	time 0.1677 (0.3756)	loss 1.4523 (1.3727)	grad_norm 0.4330 (0.4310)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:30:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:11:38 lr 0.000016	 wd 0.0000	time 0.1891 (0.3174)	loss 1.3058 (1.3853)	grad_norm 0.4099 (0.4309)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:30:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:10:47 lr 0.000016	 wd 0.0000	time 0.2164 (0.3081)	loss 1.5039 (1.3847)	grad_norm 0.4002 (0.4303)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:31:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:09:33 lr 0.000016	 wd 0.0000	time 0.2088 (0.2863)	loss 1.5207 (1.3798)	grad_norm 0.4333 (0.4294)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:31:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:38 lr 0.000016	 wd 0.0000	time 0.1974 (0.2729)	loss 1.4858 (1.3747)	grad_norm 0.4104 (0.4284)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:31:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:07:53 lr 0.000016	 wd 0.0000	time 0.1837 (0.2625)	loss 1.6565 (1.3767)	grad_norm 0.4267 (0.4275)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:32:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:07:23 lr 0.000016	 wd 0.0000	time 0.3479 (0.2603)	loss 1.3600 (1.3754)	grad_norm 0.4103 (0.4268)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:32:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:07:00 lr 0.000016	 wd 0.0000	time 0.1957 (0.2626)	loss 1.2403 (1.3750)	grad_norm 0.3914 (0.4269)	loss_scale 16384.0000 (8519.3163)	mem 5279MB
[2024-07-14 02:33:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:25 lr 0.000016	 wd 0.0000	time 0.1960 (0.2563)	loss 1.5840 (1.3758)	grad_norm 0.4599 (0.4275)	loss_scale 16384.0000 (9304.9990)	mem 5279MB
[2024-07-14 02:33:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:52 lr 0.000015	 wd 0.0000	time 0.1771 (0.2511)	loss 0.9248 (1.3744)	grad_norm 0.4055 (0.4269)	loss_scale 16384.0000 (9947.9600)	mem 5279MB
[2024-07-14 02:33:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:22 lr 0.000015	 wd 0.0000	time 0.2991 (0.2480)	loss 1.1186 (1.3727)	grad_norm 0.4306 (0.4266)	loss_scale 16384.0000 (10483.8501)	mem 5279MB
[2024-07-14 02:34:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:04:57 lr 0.000015	 wd 0.0000	time 0.1784 (0.2479)	loss 1.5919 (1.3732)	grad_norm 0.4236 (0.4261)	loss_scale 16384.0000 (10937.3590)	mem 5279MB
[2024-07-14 02:34:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:29 lr 0.000015	 wd 0.0000	time 0.1848 (0.2448)	loss 1.4607 (1.3741)	grad_norm 0.4122 (0.4263)	loss_scale 16384.0000 (11326.1271)	mem 5279MB
[2024-07-14 02:34:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:04:02 lr 0.000015	 wd 0.0000	time 0.1968 (0.2420)	loss 1.2156 (1.3739)	grad_norm 0.3954 (0.4272)	loss_scale 16384.0000 (11663.0939)	mem 5279MB
[2024-07-14 02:35:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:35 lr 0.000015	 wd 0.0000	time 0.1968 (0.2394)	loss 1.3039 (1.3741)	grad_norm 0.4190 (0.4271)	loss_scale 16384.0000 (11957.9663)	mem 5279MB
[2024-07-14 02:35:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:11 lr 0.000015	 wd 0.0000	time 0.2053 (0.2384)	loss 1.4053 (1.3749)	grad_norm 0.4038 (0.4267)	loss_scale 16384.0000 (12218.1681)	mem 5279MB
[2024-07-14 02:35:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:47 lr 0.000015	 wd 0.0000	time 0.1976 (0.2386)	loss 1.3435 (1.3745)	grad_norm 0.4750 (0.4265)	loss_scale 16384.0000 (12449.4747)	mem 5279MB
[2024-07-14 02:36:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:22 lr 0.000015	 wd 0.0000	time 0.2043 (0.2368)	loss 1.4157 (1.3748)	grad_norm 0.3845 (0.4262)	loss_scale 16384.0000 (12656.4461)	mem 5279MB
[2024-07-14 02:36:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:58 lr 0.000015	 wd 0.0000	time 0.1912 (0.2352)	loss 1.0638 (1.3743)	grad_norm 0.4612 (nan)	loss_scale 8192.0000 (12498.8386)	mem 5279MB
[2024-07-14 02:37:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:34 lr 0.000014	 wd 0.0000	time 0.2041 (0.2342)	loss 1.1847 (1.3732)	grad_norm 0.4055 (nan)	loss_scale 8192.0000 (12293.8486)	mem 5279MB
[2024-07-14 02:37:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:10 lr 0.000014	 wd 0.0000	time 0.1982 (0.2342)	loss 1.4828 (1.3711)	grad_norm 0.4388 (nan)	loss_scale 8192.0000 (12107.4857)	mem 5279MB
[2024-07-14 02:37:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:47 lr 0.000014	 wd 0.0000	time 0.2347 (0.2331)	loss 1.4108 (1.3707)	grad_norm 0.4247 (nan)	loss_scale 8192.0000 (11937.3212)	mem 5279MB
[2024-07-14 02:38:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:23 lr 0.000014	 wd 0.0000	time 0.1745 (0.2319)	loss 1.5558 (1.3721)	grad_norm 0.4104 (nan)	loss_scale 8192.0000 (11781.3311)	mem 5279MB
[2024-07-14 02:38:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1650 (0.2296)	loss 1.2337 (1.3720)	grad_norm 0.4230 (nan)	loss_scale 8192.0000 (11637.8153)	mem 5279MB
[2024-07-14 02:38:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 19 training takes 0:09:42
[2024-07-14 02:39:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 43.152 (43.152)	Loss 0.4146 (0.4146)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 02:39:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.076 Acc@5 97.286
[2024-07-14 02:39:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 02:39:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.10%
[2024-07-14 02:39:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][0/2502]	eta 10:57:31 lr 0.000014	 wd 0.0000	time 15.7681 (15.7681)	loss 0.9924 (0.9924)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:40:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:14:48 lr 0.000014	 wd 0.0000	time 0.2699 (0.3697)	loss 1.5888 (1.3685)	grad_norm 0.4055 (0.4228)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:40:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:13:09 lr 0.000014	 wd 0.0000	time 0.1742 (0.3431)	loss 1.4314 (1.3696)	grad_norm 0.4306 (0.4192)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:40:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:10:50 lr 0.000014	 wd 0.0000	time 0.2095 (0.2953)	loss 1.4759 (1.3659)	grad_norm 0.4194 (0.4204)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:41:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:09:30 lr 0.000014	 wd 0.0000	time 0.1952 (0.2714)	loss 1.4174 (1.3752)	grad_norm 0.4503 (0.4204)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:41:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:08:32 lr 0.000014	 wd 0.0000	time 0.2001 (0.2559)	loss 1.5487 (1.3771)	grad_norm 0.4116 (0.4238)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:42:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:08:17 lr 0.000014	 wd 0.0000	time 0.1512 (0.2613)	loss 1.3338 (1.3735)	grad_norm 0.4107 (0.4234)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:42:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:36 lr 0.000013	 wd 0.0000	time 0.1986 (0.2535)	loss 1.4802 (1.3757)	grad_norm 0.4230 (0.4235)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:42:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:07:00 lr 0.000013	 wd 0.0000	time 0.1871 (0.2468)	loss 1.2613 (1.3727)	grad_norm 0.4393 (0.4239)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:43:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:27 lr 0.000013	 wd 0.0000	time 0.1870 (0.2417)	loss 1.6023 (1.3754)	grad_norm 0.4049 (0.4250)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:43:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:00 lr 0.000013	 wd 0.0000	time 0.2495 (0.2399)	loss 1.2967 (1.3743)	grad_norm 0.4000 (0.4240)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:43:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:42 lr 0.000013	 wd 0.0000	time 0.2163 (0.2444)	loss 1.3565 (1.3720)	grad_norm 0.4151 (0.4246)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:44:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:13 lr 0.000013	 wd 0.0000	time 0.1871 (0.2406)	loss 1.4268 (1.3689)	grad_norm 0.4100 (0.4250)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:44:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:04:45 lr 0.000013	 wd 0.0000	time 0.1930 (0.2376)	loss 1.3299 (1.3676)	grad_norm 0.4112 (0.4249)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:45:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:19 lr 0.000013	 wd 0.0000	time 0.2199 (0.2356)	loss 1.4011 (1.3695)	grad_norm 0.4326 (0.4251)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:45:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:03:56 lr 0.000013	 wd 0.0000	time 0.1862 (0.2360)	loss 1.4421 (1.3700)	grad_norm 0.4340 (0.4269)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:45:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:31 lr 0.000013	 wd 0.0000	time 0.2140 (0.2344)	loss 1.6860 (1.3703)	grad_norm 0.4285 (0.4285)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:46:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:06 lr 0.000012	 wd 0.0000	time 0.2032 (0.2327)	loss 1.5329 (1.3696)	grad_norm 0.3944 (0.4286)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:46:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:42 lr 0.000012	 wd 0.0000	time 0.1986 (0.2309)	loss 1.3096 (1.3688)	grad_norm 0.4124 (0.4288)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:46:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:18 lr 0.000012	 wd 0.0000	time 0.2148 (0.2305)	loss 1.5354 (1.3708)	grad_norm 0.3910 (0.4290)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:47:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:01:55 lr 0.000012	 wd 0.0000	time 0.1917 (0.2305)	loss 1.5091 (1.3703)	grad_norm 0.4138 (0.4288)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 02:47:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:32 lr 0.000012	 wd 0.0000	time 0.2009 (0.2294)	loss 1.3178 (1.3709)	grad_norm 0.3962 (nan)	loss_scale 4096.0000 (8125.7154)	mem 5279MB
[2024-07-14 02:47:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:08 lr 0.000012	 wd 0.0000	time 0.1981 (0.2282)	loss 1.2760 (1.3725)	grad_norm 0.4310 (nan)	loss_scale 4096.0000 (7942.6297)	mem 5279MB
[2024-07-14 02:48:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:45 lr 0.000012	 wd 0.0000	time 0.2083 (0.2272)	loss 1.4057 (1.3725)	grad_norm 0.4168 (nan)	loss_scale 4096.0000 (7775.4576)	mem 5279MB
[2024-07-14 02:48:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:23 lr 0.000012	 wd 0.0000	time 0.2034 (0.2279)	loss 1.3604 (1.3728)	grad_norm 0.3896 (nan)	loss_scale 4096.0000 (7622.2107)	mem 5279MB
[2024-07-14 02:48:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000012	 wd 0.0000	time 0.1410 (0.2258)	loss 1.6244 (1.3735)	grad_norm 0.4146 (nan)	loss_scale 4096.0000 (7481.2187)	mem 5279MB
[2024-07-14 02:49:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 20 training takes 0:09:34
[2024-07-14 02:49:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 19.142 (19.142)	Loss 0.4148 (0.4148)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 02:49:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.114 Acc@5 97.268
[2024-07-14 02:49:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 02:49:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.11%
[2024-07-14 02:49:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth saving......
[2024-07-14 02:49:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth saved !!!
[2024-07-14 02:50:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][0/2502]	eta 22:29:10 lr 0.000012	 wd 0.0000	time 32.3541 (32.3541)	loss 1.5772 (1.5772)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:50:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:21:02 lr 0.000012	 wd 0.0000	time 0.1958 (0.5257)	loss 1.4773 (1.3934)	grad_norm 0.4084 (0.4316)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:50:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:13:53 lr 0.000012	 wd 0.0000	time 0.1681 (0.3619)	loss 0.9027 (1.3740)	grad_norm 0.4270 (0.4226)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:51:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:11:15 lr 0.000012	 wd 0.0000	time 0.1621 (0.3068)	loss 1.3959 (1.3666)	grad_norm 0.4516 (0.4217)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:51:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:10:06 lr 0.000011	 wd 0.0000	time 0.2392 (0.2887)	loss 1.4543 (1.3677)	grad_norm 0.4866 (0.4226)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:52:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:09:28 lr 0.000011	 wd 0.0000	time 0.1734 (0.2840)	loss 1.3610 (1.3670)	grad_norm 0.4253 (0.4227)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:52:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:32 lr 0.000011	 wd 0.0000	time 0.1892 (0.2694)	loss 1.2071 (1.3675)	grad_norm 0.4352 (0.4230)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:52:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:07:48 lr 0.000011	 wd 0.0000	time 0.2006 (0.2598)	loss 1.2995 (1.3621)	grad_norm 0.4097 (0.4227)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:53:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:12 lr 0.000011	 wd 0.0000	time 0.2128 (0.2541)	loss 1.2148 (1.3616)	grad_norm 0.3975 (0.4234)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:53:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:47 lr 0.000011	 wd 0.0000	time 0.1837 (0.2543)	loss 1.5379 (1.3625)	grad_norm 0.4069 (0.4234)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:53:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:14 lr 0.000011	 wd 0.0000	time 0.2352 (0.2492)	loss 1.0559 (1.3616)	grad_norm 0.4158 (0.4234)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:54:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:05:43 lr 0.000011	 wd 0.0000	time 0.1689 (0.2451)	loss 1.4731 (1.3616)	grad_norm 0.4082 (0.4243)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:54:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:14 lr 0.000011	 wd 0.0000	time 0.2146 (0.2413)	loss 1.3439 (1.3627)	grad_norm 0.4033 (0.4237)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:54:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:48 lr 0.000011	 wd 0.0000	time 0.1853 (0.2404)	loss 1.5169 (1.3629)	grad_norm 0.4020 (0.4233)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:55:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:24 lr 0.000011	 wd 0.0000	time 0.1977 (0.2398)	loss 1.4377 (1.3634)	grad_norm 0.4485 (0.4239)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:55:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:03:57 lr 0.000010	 wd 0.0000	time 0.1788 (0.2373)	loss 1.6415 (1.3631)	grad_norm 0.4086 (0.4238)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:56:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:31 lr 0.000010	 wd 0.0000	time 0.1843 (0.2350)	loss 1.2257 (1.3625)	grad_norm 0.4633 (0.4243)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:56:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:07 lr 0.000010	 wd 0.0000	time 0.1996 (0.2336)	loss 1.4895 (1.3626)	grad_norm 0.4342 (0.4243)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:56:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:44 lr 0.000010	 wd 0.0000	time 0.1919 (0.2346)	loss 1.0208 (1.3631)	grad_norm 0.4333 (0.4240)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:57:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:20 lr 0.000010	 wd 0.0000	time 0.1969 (0.2335)	loss 1.0052 (1.3618)	grad_norm 0.4450 (0.4239)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:57:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:56 lr 0.000010	 wd 0.0000	time 0.1934 (0.2320)	loss 1.4075 (1.3613)	grad_norm 0.4086 (0.4240)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:57:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:32 lr 0.000010	 wd 0.0000	time 0.2128 (0.2306)	loss 1.1856 (1.3616)	grad_norm 0.4200 (0.4239)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:58:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:09 lr 0.000010	 wd 0.0000	time 0.2000 (0.2300)	loss 1.5708 (1.3595)	grad_norm 0.3961 (0.4239)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:58:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:46 lr 0.000010	 wd 0.0000	time 0.1884 (0.2301)	loss 1.5728 (1.3593)	grad_norm 0.4196 (0.4239)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:58:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:23 lr 0.000010	 wd 0.0000	time 0.1847 (0.2289)	loss 1.3888 (1.3606)	grad_norm 0.4235 (0.4240)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:59:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1392 (0.2268)	loss 1.3355 (1.3602)	grad_norm 0.4385 (0.4245)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 02:59:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 21 training takes 0:09:35
[2024-07-14 02:59:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 40.646 (40.646)	Loss 0.4131 (0.4131)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 03:00:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.058 Acc@5 97.268
[2024-07-14 03:00:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 03:00:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.11%
[2024-07-14 03:00:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][0/2502]	eta 11:22:41 lr 0.000010	 wd 0.0000	time 16.3715 (16.3715)	loss 1.3257 (1.3257)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:00:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:14:23 lr 0.000010	 wd 0.0000	time 0.1794 (0.3595)	loss 1.2835 (1.3717)	grad_norm 0.3885 (0.4282)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:01:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:11:11 lr 0.000009	 wd 0.0000	time 0.2862 (0.2916)	loss 1.1816 (1.3681)	grad_norm 0.3872 (0.4227)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:01:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:10:34 lr 0.000009	 wd 0.0000	time 0.1903 (0.2880)	loss 1.5222 (1.3720)	grad_norm 0.4166 (0.4234)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:02:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:09:18 lr 0.000009	 wd 0.0000	time 0.2011 (0.2656)	loss 1.4366 (1.3760)	grad_norm 0.4374 (0.4255)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:02:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:08:24 lr 0.000009	 wd 0.0000	time 0.1843 (0.2519)	loss 0.9051 (1.3752)	grad_norm 0.4176 (0.4277)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:02:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:07:45 lr 0.000009	 wd 0.0000	time 0.2257 (0.2450)	loss 1.3691 (1.3783)	grad_norm 0.4524 (0.4269)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:03:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:21 lr 0.000009	 wd 0.0000	time 0.2024 (0.2449)	loss 0.9080 (1.3738)	grad_norm 0.4164 (0.4277)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:03:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:06:48 lr 0.000009	 wd 0.0000	time 0.1912 (0.2400)	loss 1.3796 (1.3696)	grad_norm 0.4051 (0.4272)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:03:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:17 lr 0.000009	 wd 0.0000	time 0.2017 (0.2359)	loss 1.3605 (1.3686)	grad_norm 0.4192 (0.4297)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:04:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:05:48 lr 0.000009	 wd 0.0000	time 0.2123 (0.2322)	loss 1.5521 (1.3707)	grad_norm 0.4314 (0.4322)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:04:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:23 lr 0.000009	 wd 0.0000	time 0.2560 (0.2311)	loss 1.4081 (1.3683)	grad_norm 0.4318 (0.4316)	loss_scale 8192.0000 (4237.3697)	mem 5279MB
[2024-07-14 03:04:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:00 lr 0.000009	 wd 0.0000	time 0.2223 (0.2310)	loss 1.3465 (1.3670)	grad_norm 0.4363 (0.4314)	loss_scale 8192.0000 (4566.6478)	mem 5279MB
[2024-07-14 03:05:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:04:34 lr 0.000009	 wd 0.0000	time 0.1929 (0.2287)	loss 0.9460 (1.3675)	grad_norm 0.4132 (0.4311)	loss_scale 8192.0000 (4845.3067)	mem 5279MB
[2024-07-14 03:05:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:09 lr 0.000008	 wd 0.0000	time 0.1724 (0.2267)	loss 1.5662 (1.3695)	grad_norm 0.4403 (0.4315)	loss_scale 8192.0000 (5084.1856)	mem 5279MB
[2024-07-14 03:05:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:03:45 lr 0.000008	 wd 0.0000	time 0.2518 (0.2251)	loss 1.3296 (1.3701)	grad_norm 0.4182 (0.4315)	loss_scale 8192.0000 (5291.2352)	mem 5279MB
[2024-07-14 03:06:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:24 lr 0.000008	 wd 0.0000	time 0.1400 (0.2263)	loss 1.5524 (1.3704)	grad_norm 0.4279 (0.4313)	loss_scale 8192.0000 (5472.4197)	mem 5279MB
[2024-07-14 03:06:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:00 lr 0.000008	 wd 0.0000	time 0.2093 (0.2253)	loss 1.3162 (1.3700)	grad_norm 0.4201 (0.4308)	loss_scale 8192.0000 (5632.3010)	mem 5279MB
[2024-07-14 03:07:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:37 lr 0.000008	 wd 0.0000	time 0.2013 (0.2241)	loss 1.5882 (1.3694)	grad_norm 0.4241 (0.4303)	loss_scale 8192.0000 (5774.4275)	mem 5279MB
[2024-07-14 03:07:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:14 lr 0.000008	 wd 0.0000	time 0.2125 (0.2230)	loss 1.5519 (1.3689)	grad_norm 0.4385 (0.4307)	loss_scale 8192.0000 (5901.6013)	mem 5279MB
[2024-07-14 03:07:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:51 lr 0.000008	 wd 0.0000	time 0.2422 (0.2228)	loss 1.5175 (1.3680)	grad_norm 0.3879 (0.4304)	loss_scale 8192.0000 (6016.0640)	mem 5279MB
[2024-07-14 03:08:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:29 lr 0.000008	 wd 0.0000	time 0.1926 (0.2236)	loss 1.4381 (1.3685)	grad_norm 0.4302 (0.4306)	loss_scale 8192.0000 (6119.6307)	mem 5279MB
[2024-07-14 03:08:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:07 lr 0.000008	 wd 0.0000	time 0.2037 (0.2229)	loss 1.4388 (1.3667)	grad_norm 0.4192 (0.4300)	loss_scale 8192.0000 (6213.7865)	mem 5279MB
[2024-07-14 03:08:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:44 lr 0.000008	 wd 0.0000	time 0.2057 (0.2220)	loss 1.5068 (1.3668)	grad_norm 0.4338 (0.4295)	loss_scale 8192.0000 (6299.7584)	mem 5279MB
[2024-07-14 03:09:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:22 lr 0.000008	 wd 0.0000	time 0.1855 (0.2213)	loss 1.2171 (1.3662)	grad_norm 0.4047 (0.4292)	loss_scale 8192.0000 (6378.5689)	mem 5279MB
[2024-07-14 03:09:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1519 (0.2199)	loss 0.9978 (1.3653)	grad_norm 0.4208 (0.4291)	loss_scale 8192.0000 (6451.0772)	mem 5279MB
[2024-07-14 03:09:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 22 training takes 0:09:22
[2024-07-14 03:10:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 28.482 (28.482)	Loss 0.4133 (0.4133)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 03:10:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.104 Acc@5 97.276
[2024-07-14 03:10:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 03:10:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.11%
[2024-07-14 03:10:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][0/2502]	eta 10:48:22 lr 0.000008	 wd 0.0000	time 15.5487 (15.5487)	loss 1.1690 (1.1690)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:11:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:17:43 lr 0.000008	 wd 0.0000	time 0.1524 (0.4427)	loss 1.5841 (1.4018)	grad_norm 0.4028 (nan)	loss_scale 4096.0000 (4542.0990)	mem 5279MB
[2024-07-14 03:11:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:12:24 lr 0.000007	 wd 0.0000	time 0.1661 (0.3235)	loss 1.5574 (1.3810)	grad_norm 0.4293 (nan)	loss_scale 4096.0000 (4320.1592)	mem 5279MB
[2024-07-14 03:11:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:10:21 lr 0.000007	 wd 0.0000	time 0.1854 (0.2824)	loss 1.5275 (1.3743)	grad_norm 0.4202 (nan)	loss_scale 4096.0000 (4245.6877)	mem 5279MB
[2024-07-14 03:12:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:09:07 lr 0.000007	 wd 0.0000	time 0.1878 (0.2607)	loss 1.5333 (1.3660)	grad_norm 0.4029 (nan)	loss_scale 4096.0000 (4208.3591)	mem 5279MB
[2024-07-14 03:12:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:08:23 lr 0.000007	 wd 0.0000	time 0.2190 (0.2516)	loss 1.6845 (1.3710)	grad_norm 0.4338 (nan)	loss_scale 4096.0000 (4185.9321)	mem 5279MB
[2024-07-14 03:13:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:08:24 lr 0.000007	 wd 0.0000	time 0.1727 (0.2655)	loss 1.1414 (1.3709)	grad_norm 0.4342 (nan)	loss_scale 4096.0000 (4170.9684)	mem 5279MB
[2024-07-14 03:13:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:41 lr 0.000007	 wd 0.0000	time 0.2124 (0.2561)	loss 1.4214 (1.3683)	grad_norm 0.4063 (nan)	loss_scale 4096.0000 (4160.2739)	mem 5279MB
[2024-07-14 03:13:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:07:03 lr 0.000007	 wd 0.0000	time 0.1786 (0.2488)	loss 1.6914 (1.3671)	grad_norm 0.4250 (nan)	loss_scale 4096.0000 (4152.2497)	mem 5279MB
[2024-07-14 03:14:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:06:32 lr 0.000007	 wd 0.0000	time 0.2470 (0.2448)	loss 1.7153 (1.3636)	grad_norm 0.4636 (nan)	loss_scale 4096.0000 (4146.0067)	mem 5279MB
[2024-07-14 03:14:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:06 lr 0.000007	 wd 0.0000	time 0.1989 (0.2438)	loss 1.1475 (1.3616)	grad_norm 0.5922 (nan)	loss_scale 4096.0000 (4141.0110)	mem 5279MB
[2024-07-14 03:14:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:37 lr 0.000007	 wd 0.0000	time 0.1800 (0.2404)	loss 0.8906 (1.3572)	grad_norm 0.4317 (nan)	loss_scale 4096.0000 (4136.9228)	mem 5279MB
[2024-07-14 03:15:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:09 lr 0.000007	 wd 0.0000	time 0.2003 (0.2375)	loss 1.5645 (1.3590)	grad_norm 0.4184 (nan)	loss_scale 4096.0000 (4133.5154)	mem 5279MB
[2024-07-14 03:15:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:04:41 lr 0.000007	 wd 0.0000	time 0.1884 (0.2345)	loss 1.4534 (1.3605)	grad_norm 0.4044 (nan)	loss_scale 4096.0000 (4130.6318)	mem 5279MB
[2024-07-14 03:15:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:17 lr 0.000007	 wd 0.0000	time 0.2036 (0.2338)	loss 1.5911 (1.3605)	grad_norm 0.4389 (nan)	loss_scale 4096.0000 (4128.1599)	mem 5279MB
[2024-07-14 03:16:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:03:54 lr 0.000006	 wd 0.0000	time 0.1549 (0.2340)	loss 1.2853 (1.3627)	grad_norm 0.4397 (nan)	loss_scale 4096.0000 (4126.0173)	mem 5279MB
[2024-07-14 03:16:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:29 lr 0.000006	 wd 0.0000	time 0.2193 (0.2320)	loss 1.1722 (1.3620)	grad_norm 0.4204 (nan)	loss_scale 4096.0000 (4124.1424)	mem 5279MB
[2024-07-14 03:16:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:04 lr 0.000006	 wd 0.0000	time 0.1790 (0.2303)	loss 1.3292 (1.3623)	grad_norm 0.4305 (nan)	loss_scale 4096.0000 (4122.4879)	mem 5279MB
[2024-07-14 03:17:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:40 lr 0.000006	 wd 0.0000	time 0.2195 (0.2292)	loss 1.4438 (1.3617)	grad_norm 0.4324 (nan)	loss_scale 4096.0000 (4121.0172)	mem 5279MB
[2024-07-14 03:17:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:18 lr 0.000006	 wd 0.0000	time 0.2347 (0.2299)	loss 1.2439 (1.3644)	grad_norm 0.4426 (nan)	loss_scale 4096.0000 (4119.7012)	mem 5279MB
[2024-07-14 03:18:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:01:55 lr 0.000006	 wd 0.0000	time 0.1767 (0.2291)	loss 1.4604 (1.3632)	grad_norm 0.4132 (nan)	loss_scale 4096.0000 (4118.5167)	mem 5279MB
[2024-07-14 03:18:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:31 lr 0.000006	 wd 0.0000	time 0.1793 (0.2280)	loss 1.7010 (1.3637)	grad_norm 0.4177 (nan)	loss_scale 4096.0000 (4117.4450)	mem 5279MB
[2024-07-14 03:18:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:08 lr 0.000006	 wd 0.0000	time 0.2168 (0.2269)	loss 1.4832 (1.3615)	grad_norm 0.4251 (nan)	loss_scale 4096.0000 (4116.4707)	mem 5279MB
[2024-07-14 03:19:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:45 lr 0.000006	 wd 0.0000	time 0.1910 (0.2266)	loss 1.6035 (1.3616)	grad_norm 0.4315 (nan)	loss_scale 4096.0000 (4115.5811)	mem 5279MB
[2024-07-14 03:19:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:23 lr 0.000006	 wd 0.0000	time 0.1825 (0.2267)	loss 1.5542 (1.3622)	grad_norm 0.4128 (nan)	loss_scale 4096.0000 (4114.7655)	mem 5279MB
[2024-07-14 03:19:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000006	 wd 0.0000	time 0.1661 (0.2246)	loss 1.4427 (1.3629)	grad_norm 0.4174 (nan)	loss_scale 4096.0000 (4114.0152)	mem 5279MB
[2024-07-14 03:19:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 23 training takes 0:09:30
[2024-07-14 03:20:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 19.543 (19.543)	Loss 0.4126 (0.4126)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 03:20:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.096 Acc@5 97.276
[2024-07-14 03:20:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 03:20:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.11%
[2024-07-14 03:21:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][0/2502]	eta 1 day, 2:28:07 lr 0.000006	 wd 0.0000	time 38.0844 (38.0844)	loss 1.5914 (1.5914)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:21:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:23:01 lr 0.000006	 wd 0.0000	time 0.1899 (0.5750)	loss 1.1458 (1.4024)	grad_norm 0.4366 (0.4386)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:21:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:14:46 lr 0.000006	 wd 0.0000	time 0.1930 (0.3852)	loss 1.4259 (1.3842)	grad_norm 0.4254 (0.4322)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:22:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:12:21 lr 0.000006	 wd 0.0000	time 0.3770 (0.3368)	loss 1.6392 (1.3774)	grad_norm 0.4323 (0.4369)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:22:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:11:54 lr 0.000005	 wd 0.0000	time 0.1831 (0.3401)	loss 1.4142 (1.3740)	grad_norm 0.4324 (0.4353)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:23:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:10:25 lr 0.000005	 wd 0.0000	time 0.1906 (0.3125)	loss 1.6773 (1.3754)	grad_norm 0.4196 (0.4367)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:23:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:09:17 lr 0.000005	 wd 0.0000	time 0.1803 (0.2932)	loss 1.4128 (1.3724)	grad_norm 0.4154 (0.4352)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:23:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:08:30 lr 0.000005	 wd 0.0000	time 0.2166 (0.2835)	loss 1.3503 (1.3734)	grad_norm 0.4860 (0.4346)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:24:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:08:06 lr 0.000005	 wd 0.0000	time 0.2048 (0.2859)	loss 1.4256 (1.3745)	grad_norm 0.4170 (0.4357)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:24:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:07:22 lr 0.000005	 wd 0.0000	time 0.2104 (0.2762)	loss 1.5624 (1.3714)	grad_norm 0.4403 (0.4347)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:25:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:43 lr 0.000005	 wd 0.0000	time 0.2163 (0.2688)	loss 1.2191 (1.3717)	grad_norm 0.4369 (0.4366)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:25:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:06:10 lr 0.000005	 wd 0.0000	time 0.2364 (0.2639)	loss 1.5063 (1.3706)	grad_norm 0.5227 (0.4362)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:25:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:40 lr 0.000005	 wd 0.0000	time 0.1862 (0.2617)	loss 1.2543 (1.3688)	grad_norm 0.4172 (0.4359)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:26:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:05:09 lr 0.000005	 wd 0.0000	time 0.1979 (0.2575)	loss 1.4022 (1.3681)	grad_norm 0.4481 (0.4353)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:26:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:39 lr 0.000005	 wd 0.0000	time 0.2070 (0.2536)	loss 1.3519 (1.3665)	grad_norm 0.4298 (0.4345)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:26:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:10 lr 0.000005	 wd 0.0000	time 0.1840 (0.2500)	loss 0.9879 (1.3650)	grad_norm 0.4197 (0.4340)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 03:27:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:43 lr 0.000005	 wd 0.0000	time 0.2251 (0.2483)	loss 1.5264 (1.3647)	grad_norm 0.4237 (0.4337)	loss_scale 8192.0000 (4331.3729)	mem 5279MB
[2024-07-14 03:27:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:18 lr 0.000005	 wd 0.0000	time 0.1799 (0.2471)	loss 1.7025 (1.3659)	grad_norm 0.4161 (0.4330)	loss_scale 8192.0000 (4558.3351)	mem 5279MB
[2024-07-14 03:27:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:51 lr 0.000005	 wd 0.0000	time 0.1932 (0.2446)	loss 1.1406 (1.3637)	grad_norm 0.4060 (0.4323)	loss_scale 8192.0000 (4760.0933)	mem 5279MB
[2024-07-14 03:28:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:25 lr 0.000005	 wd 0.0000	time 0.1899 (0.2424)	loss 1.4258 (1.3648)	grad_norm 0.4124 (0.4329)	loss_scale 8192.0000 (4940.6249)	mem 5279MB
[2024-07-14 03:28:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:02:00 lr 0.000004	 wd 0.0000	time 0.1864 (0.2409)	loss 1.3936 (1.3654)	grad_norm 0.4257 (0.4330)	loss_scale 8192.0000 (5103.1124)	mem 5279MB
[2024-07-14 03:29:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:36 lr 0.000004	 wd 0.0000	time 0.1938 (0.2411)	loss 1.5442 (1.3645)	grad_norm 0.4304 (0.4341)	loss_scale 8192.0000 (5250.1323)	mem 5279MB
[2024-07-14 03:29:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:12 lr 0.000004	 wd 0.0000	time 0.1920 (0.2398)	loss 1.4181 (1.3644)	grad_norm 0.4106 (0.4340)	loss_scale 8192.0000 (5383.7928)	mem 5279MB
[2024-07-14 03:29:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:48 lr 0.000004	 wd 0.0000	time 0.1861 (0.2383)	loss 1.7499 (1.3640)	grad_norm 0.4354 (0.4337)	loss_scale 8192.0000 (5505.8357)	mem 5279MB
[2024-07-14 03:30:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:24 lr 0.000004	 wd 0.0000	time 0.2170 (0.2366)	loss 1.5020 (1.3639)	grad_norm 0.3936 (0.4336)	loss_scale 8192.0000 (5617.7126)	mem 5279MB
[2024-07-14 03:30:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000004	 wd 0.0000	time 0.1507 (0.2343)	loss 1.2634 (1.3641)	grad_norm 0.4344 (0.4333)	loss_scale 8192.0000 (5720.6429)	mem 5279MB
[2024-07-14 03:30:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 24 training takes 0:09:53
[2024-07-14 03:31:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 36.091 (36.091)	Loss 0.4133 (0.4133)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 03:31:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.102 Acc@5 97.266
[2024-07-14 03:31:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 03:31:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.11%
[2024-07-14 03:31:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][0/2502]	eta 10:57:17 lr 0.000004	 wd 0.0000	time 15.7625 (15.7625)	loss 1.2503 (1.2503)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:32:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:16:37 lr 0.000004	 wd 0.0000	time 0.3007 (0.4153)	loss 1.3977 (1.3327)	grad_norm 0.4186 (0.4282)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:32:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:12:27 lr 0.000004	 wd 0.0000	time 0.1807 (0.3247)	loss 1.4942 (1.3606)	grad_norm 0.3874 (0.4257)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:32:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:10:22 lr 0.000004	 wd 0.0000	time 0.2221 (0.2826)	loss 1.1223 (1.3507)	grad_norm 0.3897 (0.4250)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:33:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:09:10 lr 0.000004	 wd 0.0000	time 0.2060 (0.2620)	loss 1.2488 (1.3656)	grad_norm 0.4158 (0.4261)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:33:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:08:22 lr 0.000004	 wd 0.0000	time 0.1990 (0.2512)	loss 1.5670 (1.3656)	grad_norm 0.4027 (0.4265)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:33:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:11 lr 0.000004	 wd 0.0000	time 0.1733 (0.2583)	loss 1.1619 (1.3670)	grad_norm 0.3954 (0.4264)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:34:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:07:30 lr 0.000004	 wd 0.0000	time 0.1598 (0.2498)	loss 1.2546 (1.3674)	grad_norm 0.4162 (0.4261)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:34:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:06:54 lr 0.000004	 wd 0.0000	time 0.1697 (0.2438)	loss 1.0082 (1.3675)	grad_norm 0.4914 (0.4279)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:34:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:06:23 lr 0.000004	 wd 0.0000	time 0.2421 (0.2394)	loss 1.5169 (1.3694)	grad_norm 0.4056 (0.4283)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:35:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:00 lr 0.000004	 wd 0.0000	time 0.1436 (0.2400)	loss 1.2242 (1.3698)	grad_norm 0.4282 (0.4284)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:35:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:33 lr 0.000004	 wd 0.0000	time 0.2576 (0.2375)	loss 1.2872 (1.3678)	grad_norm 0.4598 (0.4279)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:36:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:05 lr 0.000004	 wd 0.0000	time 0.2148 (0.2346)	loss 1.3548 (1.3702)	grad_norm 0.4260 (0.4277)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:36:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:04:38 lr 0.000003	 wd 0.0000	time 0.2089 (0.2320)	loss 1.4861 (1.3718)	grad_norm 0.4295 (0.4287)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:36:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:14 lr 0.000003	 wd 0.0000	time 0.1940 (0.2306)	loss 1.1250 (1.3713)	grad_norm 0.4027 (0.4307)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:37:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:03:51 lr 0.000003	 wd 0.0000	time 0.2303 (0.2307)	loss 1.2444 (1.3714)	grad_norm 0.4086 (0.4305)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:37:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:26 lr 0.000003	 wd 0.0000	time 0.1666 (0.2293)	loss 1.5053 (1.3707)	grad_norm 0.4161 (0.4301)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:37:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:02 lr 0.000003	 wd 0.0000	time 0.1822 (0.2277)	loss 1.3951 (1.3701)	grad_norm 0.4153 (0.4300)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:38:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:38 lr 0.000003	 wd 0.0000	time 0.1898 (0.2264)	loss 1.5664 (1.3699)	grad_norm 0.4317 (0.4303)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:38:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:16 lr 0.000003	 wd 0.0000	time 0.2797 (0.2264)	loss 1.9436 (1.3697)	grad_norm 0.5038 (0.4301)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:38:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:01:53 lr 0.000003	 wd 0.0000	time 0.2057 (0.2268)	loss 1.2776 (1.3690)	grad_norm 0.4074 (0.4293)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:39:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:30 lr 0.000003	 wd 0.0000	time 0.2277 (0.2258)	loss 0.8872 (1.3690)	grad_norm 0.4484 (0.4293)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:39:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:07 lr 0.000003	 wd 0.0000	time 0.1915 (0.2248)	loss 1.4479 (1.3677)	grad_norm 0.4161 (0.4292)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:39:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:45 lr 0.000003	 wd 0.0000	time 0.2184 (0.2242)	loss 1.2121 (1.3664)	grad_norm 0.3765 (0.4288)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:40:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:22 lr 0.000003	 wd 0.0000	time 0.1834 (0.2245)	loss 1.3969 (1.3679)	grad_norm 0.4440 (0.4289)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:40:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1583 (0.2225)	loss 1.4916 (1.3680)	grad_norm 0.4302 (0.4291)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:40:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 25 training takes 0:09:24
[2024-07-14 03:41:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 22.406 (22.406)	Loss 0.4133 (0.4133)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 03:41:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.120 Acc@5 97.270
[2024-07-14 03:41:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 03:41:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-14 03:41:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth saving......
[2024-07-14 03:41:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth saved !!!
[2024-07-14 03:42:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][0/2502]	eta 1 day, 0:47:33 lr 0.000003	 wd 0.0000	time 35.6727 (35.6727)	loss 1.3334 (1.3334)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:42:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:22:03 lr 0.000003	 wd 0.0000	time 0.1850 (0.5511)	loss 1.5247 (1.3611)	grad_norm 0.3944 (0.4329)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:42:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:14:23 lr 0.000003	 wd 0.0000	time 0.1671 (0.3750)	loss 1.4832 (1.3817)	grad_norm 0.4179 (0.4316)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:43:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:11:41 lr 0.000003	 wd 0.0000	time 0.2435 (0.3184)	loss 1.4873 (1.3731)	grad_norm 0.4393 (0.4330)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:43:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:11:16 lr 0.000003	 wd 0.0000	time 0.1901 (0.3218)	loss 1.6424 (1.3750)	grad_norm 0.4049 (0.4332)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:43:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:09:55 lr 0.000003	 wd 0.0000	time 0.1966 (0.2973)	loss 1.6361 (1.3814)	grad_norm 0.4425 (0.4339)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:44:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:08:53 lr 0.000003	 wd 0.0000	time 0.2228 (0.2806)	loss 1.4023 (1.3765)	grad_norm 0.4544 (0.4334)	loss_scale 16384.0000 (9500.5391)	mem 5279MB
[2024-07-14 03:44:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:08:04 lr 0.000003	 wd 0.0000	time 0.2113 (0.2688)	loss 1.5399 (1.3723)	grad_norm 0.4077 (0.4329)	loss_scale 16384.0000 (10482.4879)	mem 5279MB
[2024-07-14 03:45:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:07:49 lr 0.000002	 wd 0.0000	time 0.1863 (0.2757)	loss 1.6049 (1.3709)	grad_norm 0.4354 (0.4320)	loss_scale 16384.0000 (11219.2559)	mem 5279MB
[2024-07-14 03:45:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:07:08 lr 0.000002	 wd 0.0000	time 0.1895 (0.2675)	loss 1.3865 (1.3709)	grad_norm 0.4226 (nan)	loss_scale 8192.0000 (11428.7947)	mem 5279MB
[2024-07-14 03:45:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:31 lr 0.000002	 wd 0.0000	time 0.2121 (0.2608)	loss 1.4289 (1.3714)	grad_norm 0.4195 (nan)	loss_scale 8192.0000 (11105.4386)	mem 5279MB
[2024-07-14 03:46:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:57 lr 0.000002	 wd 0.0000	time 0.1854 (0.2552)	loss 1.5944 (1.3729)	grad_norm 0.4063 (nan)	loss_scale 8192.0000 (10840.8211)	mem 5279MB
[2024-07-14 03:46:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:33 lr 0.000002	 wd 0.0000	time 0.2978 (0.2561)	loss 1.0838 (1.3733)	grad_norm 0.4972 (nan)	loss_scale 8192.0000 (10620.2698)	mem 5279MB
[2024-07-14 03:47:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:05:07 lr 0.000002	 wd 0.0000	time 0.1886 (0.2556)	loss 0.9590 (1.3715)	grad_norm 0.4301 (nan)	loss_scale 8192.0000 (10433.6234)	mem 5279MB
[2024-07-14 03:47:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:37 lr 0.000002	 wd 0.0000	time 0.2063 (0.2517)	loss 1.5950 (1.3709)	grad_norm 0.4149 (nan)	loss_scale 8192.0000 (10273.6217)	mem 5279MB
[2024-07-14 03:47:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:04:08 lr 0.000002	 wd 0.0000	time 0.1657 (0.2483)	loss 1.4019 (1.3697)	grad_norm 0.4351 (nan)	loss_scale 8192.0000 (10134.9394)	mem 5279MB
[2024-07-14 03:48:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:41 lr 0.000002	 wd 0.0000	time 0.2254 (0.2461)	loss 1.4592 (1.3686)	grad_norm 0.4228 (nan)	loss_scale 8192.0000 (10013.5815)	mem 5279MB
[2024-07-14 03:48:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:17 lr 0.000002	 wd 0.0000	time 0.1743 (0.2459)	loss 1.2785 (1.3697)	grad_norm 0.8055 (nan)	loss_scale 8192.0000 (9906.4927)	mem 5279MB
[2024-07-14 03:48:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:51 lr 0.000002	 wd 0.0000	time 0.2580 (0.2438)	loss 1.5401 (1.3725)	grad_norm 0.4158 (nan)	loss_scale 8192.0000 (9811.2959)	mem 5279MB
[2024-07-14 03:49:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:25 lr 0.000002	 wd 0.0000	time 0.2163 (0.2417)	loss 0.9826 (1.3711)	grad_norm 0.4062 (nan)	loss_scale 8192.0000 (9726.1147)	mem 5279MB
[2024-07-14 03:49:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:02:00 lr 0.000002	 wd 0.0000	time 0.2373 (0.2398)	loss 0.9199 (1.3701)	grad_norm 0.4736 (nan)	loss_scale 8192.0000 (9649.4473)	mem 5279MB
[2024-07-14 03:49:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:36 lr 0.000002	 wd 0.0000	time 0.4359 (0.2393)	loss 1.1262 (1.3690)	grad_norm 0.4104 (nan)	loss_scale 8192.0000 (9580.0781)	mem 5279MB
[2024-07-14 03:50:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:12 lr 0.000002	 wd 0.0000	time 0.2165 (0.2391)	loss 0.9729 (1.3688)	grad_norm 0.4301 (nan)	loss_scale 8192.0000 (9517.0123)	mem 5279MB
[2024-07-14 03:50:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:47 lr 0.000002	 wd 0.0000	time 0.1980 (0.2376)	loss 1.2025 (1.3676)	grad_norm 0.4326 (nan)	loss_scale 8192.0000 (9459.4281)	mem 5279MB
[2024-07-14 03:50:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:24 lr 0.000002	 wd 0.0000	time 0.1694 (0.2361)	loss 1.1234 (1.3677)	grad_norm 0.4469 (nan)	loss_scale 8192.0000 (9406.6406)	mem 5279MB
[2024-07-14 03:51:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1452 (0.2337)	loss 0.9511 (1.3659)	grad_norm 0.4509 (nan)	loss_scale 8192.0000 (9358.0744)	mem 5279MB
[2024-07-14 03:51:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 26 training takes 0:09:53
[2024-07-14 03:52:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 38.711 (38.711)	Loss 0.4141 (0.4141)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 03:52:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.100 Acc@5 97.282
[2024-07-14 03:52:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 03:52:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-14 03:52:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][0/2502]	eta 11:23:56 lr 0.000002	 wd 0.0000	time 16.4014 (16.4014)	loss 0.9440 (0.9440)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:52:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:16:02 lr 0.000002	 wd 0.0000	time 0.3366 (0.4006)	loss 1.4961 (1.3732)	grad_norm 0.4204 (0.4277)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:53:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:12:47 lr 0.000002	 wd 0.0000	time 0.2095 (0.3332)	loss 1.5795 (1.3680)	grad_norm 0.4330 (0.4444)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:53:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:10:33 lr 0.000002	 wd 0.0000	time 0.1775 (0.2878)	loss 1.3638 (1.3681)	grad_norm 0.4090 (0.4388)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:54:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:09:18 lr 0.000002	 wd 0.0000	time 0.2031 (0.2658)	loss 1.4510 (1.3657)	grad_norm 0.4115 (0.4380)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:54:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:08:28 lr 0.000002	 wd 0.0000	time 0.2073 (0.2538)	loss 0.9803 (1.3615)	grad_norm 0.6184 (0.4369)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:54:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:07:58 lr 0.000002	 wd 0.0000	time 0.1919 (0.2518)	loss 1.2778 (1.3646)	grad_norm 0.4122 (0.4348)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:55:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:21 lr 0.000002	 wd 0.0000	time 0.1746 (0.2453)	loss 1.4870 (1.3705)	grad_norm 0.5326 (0.4354)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:55:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:06:47 lr 0.000002	 wd 0.0000	time 0.2164 (0.2393)	loss 1.5365 (1.3738)	grad_norm 0.4147 (0.4340)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:55:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:16 lr 0.000001	 wd 0.0000	time 0.1980 (0.2348)	loss 1.2884 (1.3786)	grad_norm 0.3941 (0.4336)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:56:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:05:51 lr 0.000001	 wd 0.0000	time 0.2165 (0.2340)	loss 1.4379 (1.3767)	grad_norm 0.4113 (0.4329)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:56:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:27 lr 0.000001	 wd 0.0000	time 0.1982 (0.2334)	loss 1.5242 (1.3766)	grad_norm 0.3996 (0.4327)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:56:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:00 lr 0.000001	 wd 0.0000	time 0.1732 (0.2308)	loss 1.4970 (1.3765)	grad_norm 0.4389 (0.4319)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:57:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:34 lr 0.000001	 wd 0.0000	time 0.1776 (0.2285)	loss 1.4895 (1.3737)	grad_norm 0.4104 (0.4311)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:57:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:09 lr 0.000001	 wd 0.0000	time 0.1709 (0.2268)	loss 1.2774 (1.3742)	grad_norm 0.4180 (0.4311)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:58:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:03:48 lr 0.000001	 wd 0.0000	time 0.1757 (0.2276)	loss 1.5517 (1.3738)	grad_norm 0.4259 (0.4312)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:58:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:24 lr 0.000001	 wd 0.0000	time 0.1828 (0.2269)	loss 1.5622 (1.3718)	grad_norm 0.4334 (0.4328)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:58:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:00 lr 0.000001	 wd 0.0000	time 0.1935 (0.2256)	loss 1.3965 (1.3696)	grad_norm 0.4234 (0.4325)	loss_scale 8192.0000 (8192.0000)	mem 5279MB
[2024-07-14 03:59:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:37 lr 0.000001	 wd 0.0000	time 0.1952 (0.2242)	loss 1.5233 (1.3701)	grad_norm 0.4131 (nan)	loss_scale 4096.0000 (8169.2571)	mem 5279MB
[2024-07-14 03:59:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:14 lr 0.000001	 wd 0.0000	time 0.2391 (0.2239)	loss 1.0818 (1.3716)	grad_norm 0.4325 (nan)	loss_scale 4096.0000 (7954.9879)	mem 5279MB
[2024-07-14 03:59:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:52 lr 0.000001	 wd 0.0000	time 0.2036 (0.2247)	loss 1.0594 (1.3705)	grad_norm 0.4372 (nan)	loss_scale 4096.0000 (7762.1349)	mem 5279MB
[2024-07-14 04:00:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:30 lr 0.000001	 wd 0.0000	time 0.2031 (0.2239)	loss 1.7210 (1.3697)	grad_norm 0.4163 (nan)	loss_scale 4096.0000 (7587.6402)	mem 5279MB
[2024-07-14 04:00:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:07 lr 0.000001	 wd 0.0000	time 0.2218 (0.2230)	loss 1.0967 (1.3705)	grad_norm 0.4255 (nan)	loss_scale 4096.0000 (7429.0014)	mem 5279MB
[2024-07-14 04:00:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:44 lr 0.000001	 wd 0.0000	time 0.1909 (0.2222)	loss 1.4574 (1.3705)	grad_norm 0.3995 (nan)	loss_scale 4096.0000 (7284.1512)	mem 5279MB
[2024-07-14 04:01:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:22 lr 0.000001	 wd 0.0000	time 0.1648 (0.2228)	loss 1.3790 (1.3702)	grad_norm 0.4682 (nan)	loss_scale 4096.0000 (7151.3669)	mem 5279MB
[2024-07-14 04:01:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1484 (0.2210)	loss 1.5131 (1.3685)	grad_norm 0.3911 (nan)	loss_scale 4096.0000 (7029.2011)	mem 5279MB
[2024-07-14 04:01:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 27 training takes 0:09:22
[2024-07-14 04:02:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 19.262 (19.262)	Loss 0.4141 (0.4141)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 04:02:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.106 Acc@5 97.278
[2024-07-14 04:02:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 04:02:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-14 04:02:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][0/2502]	eta 22:32:36 lr 0.000001	 wd 0.0000	time 32.4366 (32.4366)	loss 1.3063 (1.3063)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:03:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:21:29 lr 0.000001	 wd 0.0000	time 0.1907 (0.5369)	loss 1.0697 (1.3493)	grad_norm 0.4186 (0.4203)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:03:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:14:06 lr 0.000001	 wd 0.0000	time 0.1932 (0.3679)	loss 1.0720 (1.3530)	grad_norm 0.4266 (0.4338)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:03:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:11:23 lr 0.000001	 wd 0.0000	time 0.1962 (0.3105)	loss 1.6372 (1.3634)	grad_norm 0.4126 (0.4295)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:04:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:10:07 lr 0.000001	 wd 0.0000	time 0.2123 (0.2892)	loss 1.3949 (1.3678)	grad_norm 0.4336 (0.4337)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:04:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:09:10 lr 0.000001	 wd 0.0000	time 0.1948 (0.2748)	loss 1.5758 (1.3698)	grad_norm 0.4553 (0.4329)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:04:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:20 lr 0.000001	 wd 0.0000	time 0.1887 (0.2630)	loss 1.3998 (1.3697)	grad_norm 0.4198 (0.4316)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:05:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:38 lr 0.000001	 wd 0.0000	time 0.2006 (0.2545)	loss 1.0245 (1.3716)	grad_norm 0.4068 (0.4304)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:05:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:01 lr 0.000001	 wd 0.0000	time 0.2050 (0.2474)	loss 1.6180 (1.3688)	grad_norm 0.4185 (0.4298)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:05:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:33 lr 0.000001	 wd 0.0000	time 0.1876 (0.2457)	loss 1.5393 (1.3693)	grad_norm 0.5132 (0.4308)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:06:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:05 lr 0.000001	 wd 0.0000	time 0.1858 (0.2437)	loss 1.5636 (1.3720)	grad_norm 0.4268 (0.4307)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:06:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:36 lr 0.000001	 wd 0.0000	time 0.2103 (0.2399)	loss 0.9502 (1.3685)	grad_norm 0.4329 (0.4307)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:07:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:08 lr 0.000001	 wd 0.0000	time 0.2237 (0.2366)	loss 1.2193 (1.3687)	grad_norm 0.4278 (0.4305)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:07:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:04:41 lr 0.000001	 wd 0.0000	time 0.2248 (0.2346)	loss 1.5725 (1.3655)	grad_norm 0.4766 (0.4331)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:07:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:18 lr 0.000001	 wd 0.0000	time 0.3139 (0.2349)	loss 0.9320 (1.3666)	grad_norm 0.4146 (0.4325)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:08:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:03:53 lr 0.000001	 wd 0.0000	time 0.1911 (0.2331)	loss 1.4944 (1.3652)	grad_norm 0.4148 (0.4322)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:08:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:28 lr 0.000001	 wd 0.0000	time 0.1926 (0.2311)	loss 1.1879 (1.3647)	grad_norm 0.4322 (0.4345)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:08:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:03 lr 0.000001	 wd 0.0000	time 0.1833 (0.2292)	loss 1.4317 (1.3662)	grad_norm 0.4342 (0.4357)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:09:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:40 lr 0.000001	 wd 0.0000	time 0.2264 (0.2287)	loss 1.3860 (1.3659)	grad_norm 0.4383 (0.4357)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:09:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:17 lr 0.000001	 wd 0.0000	time 0.1824 (0.2289)	loss 1.5468 (1.3648)	grad_norm 0.4534 (0.4360)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:09:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:01:54 lr 0.000001	 wd 0.0000	time 0.1997 (0.2276)	loss 0.8808 (1.3647)	grad_norm 0.5330 (0.4359)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:10:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:31 lr 0.000001	 wd 0.0000	time 0.2078 (0.2266)	loss 1.0983 (1.3650)	grad_norm 0.4142 (0.4353)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:10:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:08 lr 0.000001	 wd 0.0000	time 0.2340 (0.2259)	loss 1.5338 (1.3638)	grad_norm 0.4152 (0.4348)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:10:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:45 lr 0.000001	 wd 0.0000	time 0.2000 (0.2264)	loss 1.1003 (1.3639)	grad_norm 0.4171 (0.4344)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:11:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:23 lr 0.000001	 wd 0.0000	time 0.1708 (0.2259)	loss 1.5744 (1.3624)	grad_norm 0.4113 (0.4341)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:11:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1431 (0.2238)	loss 1.1914 (1.3616)	grad_norm 0.4324 (0.4338)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:11:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 28 training takes 0:09:28
[2024-07-14 04:12:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 24.102 (24.102)	Loss 0.4141 (0.4141)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 04:12:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.100 Acc@5 97.278
[2024-07-14 04:12:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 04:12:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-14 04:12:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][0/2502]	eta 18:08:30 lr 0.000001	 wd 0.0000	time 26.1034 (26.1034)	loss 1.4135 (1.4135)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:13:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:18:16 lr 0.000001	 wd 0.0000	time 0.1769 (0.4566)	loss 1.4753 (1.3427)	grad_norm 0.4002 (0.4290)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:13:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:12:31 lr 0.000001	 wd 0.0000	time 0.1878 (0.3264)	loss 1.1532 (1.3577)	grad_norm 0.4498 (0.4336)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:14:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:11:00 lr 0.000001	 wd 0.0000	time 0.3050 (0.3001)	loss 1.4972 (1.3564)	grad_norm 0.4076 (0.4299)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:14:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:09:56 lr 0.000001	 wd 0.0000	time 0.2251 (0.2837)	loss 1.1865 (1.3653)	grad_norm 0.4539 (0.4344)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:14:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:08:53 lr 0.000001	 wd 0.0000	time 0.1870 (0.2664)	loss 0.9526 (1.3670)	grad_norm 0.4084 (0.4353)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:15:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:05 lr 0.000000	 wd 0.0000	time 0.2053 (0.2554)	loss 1.3481 (1.3680)	grad_norm 0.3913 (0.4350)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:15:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:29 lr 0.000000	 wd 0.0000	time 0.1867 (0.2492)	loss 1.5775 (1.3687)	grad_norm 0.4510 (0.4335)	loss_scale 4096.0000 (4096.0000)	mem 5279MB
[2024-07-14 04:15:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:07:16 lr 0.000000	 wd 0.0000	time 0.1805 (0.2566)	loss 0.8040 (1.3698)	grad_norm 0.4117 (0.4324)	loss_scale 8192.0000 (4167.5905)	mem 5279MB
[2024-07-14 04:16:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:06:41 lr 0.000000	 wd 0.0000	time 0.1514 (0.2504)	loss 1.4247 (1.3696)	grad_norm 0.4276 (0.4329)	loss_scale 8192.0000 (4614.2508)	mem 5279MB
[2024-07-14 04:16:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:08 lr 0.000000	 wd 0.0000	time 0.1977 (0.2453)	loss 1.3360 (1.3693)	grad_norm 0.4139 (0.4323)	loss_scale 8192.0000 (4971.6683)	mem 5279MB
[2024-07-14 04:16:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:38 lr 0.000000	 wd 0.0000	time 0.2304 (0.2417)	loss 1.4687 (1.3698)	grad_norm 0.3947 (0.4318)	loss_scale 8192.0000 (5264.1599)	mem 5279MB
[2024-07-14 04:17:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:15 lr 0.000000	 wd 0.0000	time 0.1930 (0.2426)	loss 1.2734 (1.3667)	grad_norm 0.4111 (0.4312)	loss_scale 8192.0000 (5507.9434)	mem 5279MB
[2024-07-14 04:17:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:04:48 lr 0.000000	 wd 0.0000	time 0.1732 (0.2399)	loss 1.5484 (1.3676)	grad_norm 0.4483 (0.4315)	loss_scale 8192.0000 (5714.2506)	mem 5279MB
[2024-07-14 04:18:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:21 lr 0.000000	 wd 0.0000	time 0.2115 (0.2372)	loss 1.7695 (1.3664)	grad_norm 0.4302 (0.4313)	loss_scale 8192.0000 (5891.1064)	mem 5279MB
[2024-07-14 04:18:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:03:55 lr 0.000000	 wd 0.0000	time 0.1891 (0.2346)	loss 1.2997 (1.3677)	grad_norm 0.5041 (0.4313)	loss_scale 8192.0000 (6044.3971)	mem 5279MB
[2024-07-14 04:18:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:30 lr 0.000000	 wd 0.0000	time 0.2283 (0.2335)	loss 1.4813 (1.3691)	grad_norm 0.4108 (0.4307)	loss_scale 8192.0000 (6178.5384)	mem 5279MB
[2024-07-14 04:19:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:07 lr 0.000000	 wd 0.0000	time 0.2219 (0.2333)	loss 1.3088 (1.3661)	grad_norm 0.4254 (0.4304)	loss_scale 8192.0000 (6296.9077)	mem 5279MB
[2024-07-14 04:19:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:42 lr 0.000000	 wd 0.0000	time 0.2287 (0.2317)	loss 1.1733 (1.3677)	grad_norm 0.4444 (0.4301)	loss_scale 8192.0000 (6402.1321)	mem 5279MB
[2024-07-14 04:19:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:18 lr 0.000000	 wd 0.0000	time 0.1700 (0.2302)	loss 1.2342 (1.3675)	grad_norm 0.4290 (0.4294)	loss_scale 8192.0000 (6496.2862)	mem 5279MB
[2024-07-14 04:20:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:01:54 lr 0.000000	 wd 0.0000	time 0.1955 (0.2289)	loss 1.5014 (1.3675)	grad_norm 0.4701 (0.4300)	loss_scale 8192.0000 (6581.0295)	mem 5279MB
[2024-07-14 04:20:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:32 lr 0.000000	 wd 0.0000	time 0.1941 (0.2289)	loss 1.5039 (1.3680)	grad_norm 0.4141 (0.4297)	loss_scale 8192.0000 (6657.7059)	mem 5279MB
[2024-07-14 04:20:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:09 lr 0.000000	 wd 0.0000	time 0.1822 (0.2291)	loss 1.4207 (1.3697)	grad_norm 0.4638 (0.4296)	loss_scale 8192.0000 (6727.4148)	mem 5279MB
[2024-07-14 04:21:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:46 lr 0.000000	 wd 0.0000	time 0.1866 (0.2280)	loss 1.4378 (1.3710)	grad_norm 0.4738 (0.4296)	loss_scale 8192.0000 (6791.0648)	mem 5279MB
[2024-07-14 04:21:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.1982 (0.2270)	loss 1.4101 (1.3716)	grad_norm 0.4517 (0.4300)	loss_scale 8192.0000 (6849.4127)	mem 5279MB
[2024-07-14 04:21:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000000	 wd 0.0000	time 0.1546 (0.2250)	loss 1.5762 (1.3708)	grad_norm 0.4274 (0.4296)	loss_scale 8192.0000 (6903.0948)	mem 5279MB
[2024-07-14 04:22:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 29 training takes 0:09:29
[2024-07-14 04:22:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_29.pth saving......
[2024-07-14 04:22:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_29.pth saved !!!
[2024-07-14 04:22:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 36.331 (36.331)	Loss 0.4141 (0.4141)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 5279MB
[2024-07-14 04:22:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.112 Acc@5 97.278
[2024-07-14 04:22:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 04:22:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-14 04:22:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2] (main.py 189): INFO Training time 5:11:27
