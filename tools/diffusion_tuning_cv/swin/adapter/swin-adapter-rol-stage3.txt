[2024-07-15 20:07:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft/config.json
[2024-07-15 20:07:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_swin_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 9
    - 3
    DIMS:
    - 96
    - 192
    - 384
    - 768
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: false
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: fullfinetune
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 4.0e-05
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.0e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 4.0e-08
  WEIGHT_DECAY: 1.0e-08

[2024-07-15 20:07:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/swin/diffusion_ft_adapter_swin_base_patch4_window7_224_22kto1k_squence_stage_process3.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-15 20:07:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 108): INFO Creating model:adapter_swin_diffusion_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft
[2024-07-15 20:07:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 110): INFO Adapter_SwinTransformer_Diffusion_Finetune(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (uma): UMA(filter_strategy1=23, filter_strategy2=7,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-15 20:07:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 113): INFO number of params: 4531880
[2024-07-15 20:07:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 116): INFO number of GFLOPs: 15.438473216
[2024-07-15 20:07:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 150): INFO no checkpoint found in pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft, ignoring auto resume
[2024-07-15 20:07:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth for fine-tuning......
[2024-07-15 20:07:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])
[2024-07-15 20:07:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth'
[2024-07-15 20:08:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 74.831 (74.831)	Loss 0.4177 (0.4177)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 1490MB
[2024-07-15 20:09:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.176 Acc@5 97.258
[2024-07-15 20:09:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 162): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 20:09:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 168): INFO Start training
[2024-07-15 20:09:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][0/2502]	eta 12:22:29 lr 0.000000	 wd 0.0000	time 17.8056 (17.8056)	loss 1.6037 (1.6037)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 7938MB
[2024-07-15 20:10:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:22:52 lr 0.000000	 wd 0.0000	time 0.2314 (0.5716)	loss 1.4073 (1.3969)	grad_norm 0.4549 (nan)	loss_scale 32768.0000 (62940.5149)	mem 7984MB
[2024-07-15 20:10:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:15:25 lr 0.000001	 wd 0.0000	time 0.2242 (0.4022)	loss 1.4201 (1.3818)	grad_norm 0.5014 (nan)	loss_scale 16384.0000 (41734.3682)	mem 7984MB
[2024-07-15 20:10:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:38 lr 0.000001	 wd 0.0000	time 0.2134 (0.3443)	loss 1.4304 (1.3625)	grad_norm 0.4862 (nan)	loss_scale 16384.0000 (33312.3189)	mem 7984MB
[2024-07-15 20:11:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:11:07 lr 0.000001	 wd 0.0000	time 0.2475 (0.3177)	loss 1.8235 (1.3653)	grad_norm 0.4944 (nan)	loss_scale 16384.0000 (29090.7930)	mem 7984MB
[2024-07-15 20:11:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:10:45 lr 0.000002	 wd 0.0000	time 0.2487 (0.3225)	loss 1.4759 (1.3639)	grad_norm 0.5052 (nan)	loss_scale 16384.0000 (26554.5070)	mem 7984MB
[2024-07-15 20:12:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:44 lr 0.000002	 wd 0.0000	time 0.2272 (0.3070)	loss 1.1483 (1.3633)	grad_norm 0.5384 (nan)	loss_scale 8192.0000 (24480.5857)	mem 7984MB
[2024-07-15 20:12:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:54 lr 0.000002	 wd 0.0000	time 0.2217 (0.2968)	loss 1.4113 (1.3593)	grad_norm 0.6110 (nan)	loss_scale 8192.0000 (22156.9643)	mem 7984MB
[2024-07-15 20:13:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:08:14 lr 0.000003	 wd 0.0000	time 0.3045 (0.2908)	loss 1.5253 (1.3603)	grad_norm 0.4851 (nan)	loss_scale 8192.0000 (20413.5231)	mem 7984MB
[2024-07-15 20:13:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:39 lr 0.000003	 wd 0.0000	time 0.2042 (0.2868)	loss 1.5476 (1.3555)	grad_norm 0.4550 (nan)	loss_scale 8192.0000 (19057.0832)	mem 7984MB
[2024-07-15 20:13:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:07:02 lr 0.000003	 wd 0.0000	time 0.2430 (0.2813)	loss 1.3635 (1.3551)	grad_norm 0.7040 (nan)	loss_scale 8192.0000 (17971.6603)	mem 7984MB
[2024-07-15 20:14:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:28 lr 0.000004	 wd 0.0000	time 0.2060 (0.2770)	loss 1.5162 (1.3560)	grad_norm 0.4882 (nan)	loss_scale 8192.0000 (17083.4078)	mem 7984MB
[2024-07-15 20:14:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:57 lr 0.000004	 wd 0.0000	time 0.2261 (0.2743)	loss 1.4757 (1.3581)	grad_norm 0.5109 (nan)	loss_scale 8192.0000 (16343.0741)	mem 7984MB
[2024-07-15 20:15:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:27 lr 0.000004	 wd 0.0000	time 0.2156 (0.2727)	loss 1.4404 (1.3601)	grad_norm 0.4552 (nan)	loss_scale 8192.0000 (15716.5503)	mem 7984MB
[2024-07-15 20:15:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:57 lr 0.000005	 wd 0.0000	time 0.2187 (0.2699)	loss 1.5563 (1.3611)	grad_norm 0.4545 (nan)	loss_scale 8192.0000 (15179.4661)	mem 7984MB
[2024-07-15 20:15:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:27 lr 0.000005	 wd 0.0000	time 0.2643 (0.2674)	loss 1.4644 (1.3609)	grad_norm 0.9094 (nan)	loss_scale 8192.0000 (14713.9454)	mem 7984MB
[2024-07-15 20:16:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:59 lr 0.000005	 wd 0.0000	time 0.2658 (0.2658)	loss 1.5828 (1.3615)	grad_norm 0.4891 (nan)	loss_scale 8192.0000 (14306.5784)	mem 7984MB
[2024-07-15 20:16:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:33 lr 0.000005	 wd 0.0000	time 0.2222 (0.2659)	loss 1.4752 (1.3605)	grad_norm 0.4819 (nan)	loss_scale 8192.0000 (13947.1088)	mem 7984MB
[2024-07-15 20:17:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:03:05 lr 0.000006	 wd 0.0000	time 0.1935 (0.2641)	loss 1.2143 (1.3611)	grad_norm 0.4863 (nan)	loss_scale 8192.0000 (13627.5580)	mem 7984MB
[2024-07-15 20:17:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:37 lr 0.000006	 wd 0.0000	time 0.2111 (0.2624)	loss 1.6239 (1.3605)	grad_norm 0.7548 (nan)	loss_scale 8192.0000 (13341.6265)	mem 7984MB
[2024-07-15 20:17:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:11 lr 0.000006	 wd 0.0000	time 0.2270 (0.2615)	loss 1.4925 (1.3586)	grad_norm 0.5069 (nan)	loss_scale 8192.0000 (13084.2739)	mem 7984MB
[2024-07-15 20:18:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:45 lr 0.000007	 wd 0.0000	time 0.2496 (0.2615)	loss 1.3516 (1.3591)	grad_norm 0.4922 (nan)	loss_scale 8192.0000 (12851.4193)	mem 7984MB
[2024-07-15 20:18:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:18 lr 0.000007	 wd 0.0000	time 0.2330 (0.2603)	loss 1.6081 (1.3599)	grad_norm 0.4889 (nan)	loss_scale 8192.0000 (12639.7238)	mem 7984MB
[2024-07-15 20:19:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:52 lr 0.000007	 wd 0.0000	time 0.2398 (0.2591)	loss 1.5317 (1.3587)	grad_norm 0.5391 (nan)	loss_scale 8192.0000 (12446.4285)	mem 7984MB
[2024-07-15 20:19:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:26 lr 0.000008	 wd 0.0000	time 0.2646 (0.2584)	loss 1.3870 (1.3589)	grad_norm 0.5205 (nan)	loss_scale 8192.0000 (12269.2345)	mem 7984MB
[2024-07-15 20:19:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1778 (0.2565)	loss 1.6336 (1.3590)	grad_norm 0.4330 (nan)	loss_scale 8192.0000 (12106.2103)	mem 7984MB
[2024-07-15 20:19:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 0 training takes 0:10:49
[2024-07-15 20:19:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft/ckpt_epoch_0.pth saving......
[2024-07-15 20:19:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft/ckpt_epoch_0.pth saved !!!
[2024-07-15 20:20:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 41.410 (41.410)	Loss 0.4163 (0.4163)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-15 20:20:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.156 Acc@5 97.264
[2024-07-15 20:20:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 20:20:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.16%
[2024-07-15 20:20:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft/ckpt_epoch_best.pth saving......
[2024-07-15 20:20:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft/ckpt_epoch_best.pth saved !!!
[2024-07-15 20:21:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][0/2502]	eta 1 day, 2:00:37 lr 0.000008	 wd 0.0000	time 37.4249 (37.4249)	loss 1.2129 (1.2129)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 20:21:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:24:11 lr 0.000008	 wd 0.0000	time 0.2438 (0.6042)	loss 1.1511 (1.3968)	grad_norm 0.4885 (0.5128)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 20:22:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:16:00 lr 0.000009	 wd 0.0000	time 0.2468 (0.4173)	loss 1.3482 (1.3964)	grad_norm 0.4936 (0.5109)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 20:22:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:13:14 lr 0.000009	 wd 0.0000	time 0.2473 (0.3608)	loss 1.6828 (1.3758)	grad_norm 0.4546 (0.5111)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 20:23:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:11:33 lr 0.000009	 wd 0.0000	time 0.2173 (0.3298)	loss 0.9760 (1.3657)	grad_norm 0.4924 (0.5066)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 20:23:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:10:19 lr 0.000010	 wd 0.0000	time 0.2610 (0.3092)	loss 1.5175 (1.3643)	grad_norm 0.5840 (0.5099)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 20:23:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:09:22 lr 0.000010	 wd 0.0000	time 0.2077 (0.2957)	loss 1.4276 (1.3637)	grad_norm 0.5159 (0.5098)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 20:24:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:39 lr 0.000010	 wd 0.0000	time 0.2206 (0.2881)	loss 1.6102 (1.3623)	grad_norm 0.4735 (0.5083)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 20:24:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:08:04 lr 0.000011	 wd 0.0000	time 0.2406 (0.2848)	loss 1.5428 (1.3658)	grad_norm 0.4409 (0.5086)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 20:25:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:26 lr 0.000011	 wd 0.0000	time 0.2129 (0.2789)	loss 1.5918 (1.3630)	grad_norm 0.5107 (0.5065)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 20:25:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:51 lr 0.000011	 wd 0.0000	time 0.2448 (0.2742)	loss 1.6753 (1.3619)	grad_norm 0.5231 (0.5062)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 20:25:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:06:20 lr 0.000012	 wd 0.0000	time 0.2379 (0.2714)	loss 1.0764 (1.3610)	grad_norm 0.4679 (0.5076)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 20:26:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:52 lr 0.000012	 wd 0.0000	time 0.1881 (0.2710)	loss 1.3425 (1.3637)	grad_norm 0.4765 (0.5073)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 20:26:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:22 lr 0.000012	 wd 0.0000	time 0.2160 (0.2683)	loss 1.5449 (1.3669)	grad_norm 0.5336 (0.5074)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 20:27:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:52 lr 0.000012	 wd 0.0000	time 0.2187 (0.2657)	loss 1.4233 (1.3650)	grad_norm 0.4707 (0.5076)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 20:27:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:24 lr 0.000013	 wd 0.0000	time 0.2199 (0.2640)	loss 0.9831 (1.3634)	grad_norm 0.4930 (0.5083)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 20:27:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:58 lr 0.000013	 wd 0.0000	time 0.2182 (0.2644)	loss 0.9252 (1.3620)	grad_norm 0.4599 (0.5084)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 20:28:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:30 lr 0.000013	 wd 0.0000	time 0.2233 (0.2626)	loss 1.3389 (1.3613)	grad_norm 0.5191 (0.5085)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 20:28:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:03:03 lr 0.000014	 wd 0.0000	time 0.2229 (0.2611)	loss 1.4274 (1.3614)	grad_norm 0.4486 (nan)	loss_scale 4096.0000 (7991.8623)	mem 7984MB
[2024-07-15 20:29:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:36 lr 0.000014	 wd 0.0000	time 0.2448 (0.2601)	loss 1.4406 (1.3625)	grad_norm 0.5019 (nan)	loss_scale 4096.0000 (7786.9248)	mem 7984MB
[2024-07-15 20:29:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:10 lr 0.000014	 wd 0.0000	time 0.2501 (0.2604)	loss 1.3270 (1.3618)	grad_norm 0.4647 (nan)	loss_scale 4096.0000 (7602.4708)	mem 7984MB
[2024-07-15 20:29:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:44 lr 0.000015	 wd 0.0000	time 0.2536 (0.2593)	loss 1.3879 (1.3627)	grad_norm 0.4671 (nan)	loss_scale 4096.0000 (7435.5754)	mem 7984MB
[2024-07-15 20:30:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:17 lr 0.000015	 wd 0.0000	time 0.2018 (0.2581)	loss 1.2065 (1.3639)	grad_norm 0.4825 (nan)	loss_scale 4096.0000 (7283.8455)	mem 7984MB
[2024-07-15 20:30:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:52 lr 0.000015	 wd 0.0000	time 0.2531 (0.2575)	loss 1.6160 (1.3643)	grad_norm 0.5080 (nan)	loss_scale 4096.0000 (7145.3038)	mem 7984MB
[2024-07-15 20:31:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:26 lr 0.000016	 wd 0.0000	time 0.2121 (0.2574)	loss 1.4462 (1.3624)	grad_norm 0.4722 (nan)	loss_scale 4096.0000 (7018.3024)	mem 7984MB
[2024-07-15 20:31:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1743 (0.2554)	loss 1.1055 (1.3637)	grad_norm 0.5776 (nan)	loss_scale 4096.0000 (6901.4570)	mem 7984MB
[2024-07-15 20:31:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 1 training takes 0:10:43
[2024-07-15 20:32:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 23.262 (23.262)	Loss 0.4177 (0.4177)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-15 20:32:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.162 Acc@5 97.256
[2024-07-15 20:32:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 20:32:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.16%
[2024-07-15 20:32:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft/ckpt_epoch_best.pth saving......
[2024-07-15 20:32:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft/ckpt_epoch_best.pth saved !!!
[2024-07-15 20:32:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][0/2502]	eta 1 day, 0:54:45 lr 0.000016	 wd 0.0000	time 35.8456 (35.8456)	loss 1.6370 (1.6370)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:33:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:23:18 lr 0.000016	 wd 0.0000	time 0.2460 (0.5823)	loss 1.4073 (1.3353)	grad_norm 0.4760 (0.5175)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:33:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:15:30 lr 0.000017	 wd 0.0000	time 0.2225 (0.4041)	loss 1.4319 (1.3551)	grad_norm 0.4188 (0.5614)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:34:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:12:52 lr 0.000017	 wd 0.0000	time 0.2595 (0.3508)	loss 1.2957 (1.3660)	grad_norm 0.4938 (0.5547)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:34:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:11:19 lr 0.000017	 wd 0.0000	time 0.2332 (0.3235)	loss 1.5181 (1.3638)	grad_norm 0.4902 (0.5393)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:34:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:10:08 lr 0.000018	 wd 0.0000	time 0.2397 (0.3041)	loss 1.5330 (1.3623)	grad_norm 0.5089 (0.5344)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:35:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:09:15 lr 0.000018	 wd 0.0000	time 0.2269 (0.2922)	loss 1.2666 (1.3568)	grad_norm 0.4728 (0.5313)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:35:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:08:32 lr 0.000018	 wd 0.0000	time 0.2653 (0.2844)	loss 1.2500 (1.3589)	grad_norm 0.4891 (0.5281)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:35:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:57 lr 0.000019	 wd 0.0000	time 0.2070 (0.2806)	loss 1.4428 (1.3572)	grad_norm 0.4733 (0.5243)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:36:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:07:20 lr 0.000019	 wd 0.0000	time 0.2272 (0.2751)	loss 1.5183 (1.3616)	grad_norm 0.5392 (0.5224)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:36:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:46 lr 0.000019	 wd 0.0000	time 0.2085 (0.2710)	loss 1.4511 (1.3627)	grad_norm 0.4619 (0.5221)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:37:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:06:16 lr 0.000020	 wd 0.0000	time 0.2919 (0.2683)	loss 1.1708 (1.3622)	grad_norm 0.5620 (0.5212)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:37:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:49 lr 0.000020	 wd 0.0000	time 0.2165 (0.2683)	loss 1.2547 (1.3612)	grad_norm 0.5325 (0.5196)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:38:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:05:19 lr 0.000020	 wd 0.0000	time 0.2242 (0.2656)	loss 1.6975 (1.3640)	grad_norm 0.6002 (0.5204)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:38:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:49 lr 0.000020	 wd 0.0000	time 0.2233 (0.2631)	loss 1.4322 (1.3640)	grad_norm 0.4910 (0.5206)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:38:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:21 lr 0.000021	 wd 0.0000	time 0.2247 (0.2612)	loss 1.4919 (1.3621)	grad_norm 0.5007 (0.5187)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:39:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:56 lr 0.000021	 wd 0.0000	time 0.1985 (0.2617)	loss 1.2743 (1.3623)	grad_norm 0.5798 (0.5178)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:39:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:28 lr 0.000021	 wd 0.0000	time 0.2032 (0.2602)	loss 1.4487 (1.3620)	grad_norm 0.4971 (0.5185)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:40:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:03:01 lr 0.000022	 wd 0.0000	time 0.2279 (0.2588)	loss 1.3478 (1.3621)	grad_norm 0.5250 (0.5181)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:40:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:35 lr 0.000022	 wd 0.0000	time 0.2297 (0.2576)	loss 1.0768 (1.3605)	grad_norm 0.5644 (0.5177)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:40:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:02:09 lr 0.000022	 wd 0.0000	time 0.2496 (0.2577)	loss 1.1018 (1.3587)	grad_norm 0.4682 (0.5171)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:41:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:43 lr 0.000023	 wd 0.0000	time 0.2464 (0.2565)	loss 1.4419 (1.3588)	grad_norm 0.5028 (0.5172)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:41:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:17 lr 0.000023	 wd 0.0000	time 0.2181 (0.2555)	loss 1.4922 (1.3588)	grad_norm 0.4679 (0.5174)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:42:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:51 lr 0.000023	 wd 0.0000	time 0.2124 (0.2547)	loss 1.5779 (1.3588)	grad_norm 0.4986 (0.5174)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:42:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:25 lr 0.000024	 wd 0.0000	time 0.2136 (0.2548)	loss 1.4122 (1.3577)	grad_norm 0.4827 (0.5177)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:42:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1709 (0.2529)	loss 1.4385 (1.3576)	grad_norm 0.4623 (0.5177)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:42:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 2 training takes 0:10:37
[2024-07-15 20:43:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 24.214 (24.214)	Loss 0.4116 (0.4116)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-15 20:43:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.132 Acc@5 97.288
[2024-07-15 20:43:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 20:43:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.16%
[2024-07-15 20:44:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][0/2502]	eta 22:57:08 lr 0.000024	 wd 0.0000	time 33.0248 (33.0248)	loss 1.0869 (1.0869)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:44:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:22:19 lr 0.000024	 wd 0.0000	time 0.2130 (0.5578)	loss 1.6755 (1.3435)	grad_norm 0.5116 (0.5053)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:44:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:15:04 lr 0.000025	 wd 0.0000	time 0.2120 (0.3930)	loss 1.4863 (1.3557)	grad_norm 0.4588 (0.5106)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:45:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:12:27 lr 0.000025	 wd 0.0000	time 0.2435 (0.3396)	loss 1.3956 (1.3447)	grad_norm 0.4436 (0.5107)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:45:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:11:10 lr 0.000025	 wd 0.0000	time 0.2266 (0.3189)	loss 1.5186 (1.3509)	grad_norm 0.4433 (0.5089)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:46:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:10:02 lr 0.000026	 wd 0.0000	time 0.2236 (0.3010)	loss 1.3834 (1.3483)	grad_norm 0.5033 (0.5089)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:46:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:09:10 lr 0.000026	 wd 0.0000	time 0.2265 (0.2894)	loss 1.4513 (1.3479)	grad_norm 0.4824 (0.5116)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:46:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:08:26 lr 0.000026	 wd 0.0000	time 0.2223 (0.2812)	loss 1.4896 (1.3500)	grad_norm 1.4668 (0.5136)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 20:47:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:52 lr 0.000027	 wd 0.0000	time 0.2265 (0.2778)	loss 1.1325 (1.3504)	grad_norm 0.4466 (0.5194)	loss_scale 8192.0000 (4566.4519)	mem 7984MB
[2024-07-15 20:47:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:07:18 lr 0.000027	 wd 0.0000	time 0.2323 (0.2736)	loss 1.3335 (1.3519)	grad_norm 0.4883 (nan)	loss_scale 2048.0000 (4750.6326)	mem 7984MB
[2024-07-15 20:47:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:44 lr 0.000027	 wd 0.0000	time 0.2297 (0.2693)	loss 1.5954 (1.3552)	grad_norm 0.4529 (nan)	loss_scale 2048.0000 (4480.6394)	mem 7984MB
[2024-07-15 20:48:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:06:12 lr 0.000028	 wd 0.0000	time 0.2161 (0.2657)	loss 1.3825 (1.3573)	grad_norm 0.5545 (nan)	loss_scale 2048.0000 (4259.6912)	mem 7984MB
[2024-07-15 20:48:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:44 lr 0.000028	 wd 0.0000	time 0.2809 (0.2642)	loss 1.2987 (1.3563)	grad_norm 0.4241 (nan)	loss_scale 2048.0000 (4075.5371)	mem 7984MB
[2024-07-15 20:49:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:05:16 lr 0.000028	 wd 0.0000	time 0.2435 (0.2631)	loss 1.2152 (1.3590)	grad_norm 0.4966 (nan)	loss_scale 2048.0000 (3919.6925)	mem 7984MB
[2024-07-15 20:49:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:47 lr 0.000028	 wd 0.0000	time 0.2418 (0.2609)	loss 1.2221 (1.3598)	grad_norm 0.7146 (nan)	loss_scale 2048.0000 (3786.0956)	mem 7984MB
[2024-07-15 20:49:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:19 lr 0.000029	 wd 0.0000	time 0.2334 (0.2588)	loss 1.3743 (1.3601)	grad_norm 0.5563 (nan)	loss_scale 2048.0000 (3670.2998)	mem 7984MB
[2024-07-15 20:50:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:52 lr 0.000029	 wd 0.0000	time 0.2555 (0.2581)	loss 1.4085 (1.3589)	grad_norm 0.4624 (nan)	loss_scale 2048.0000 (3568.9694)	mem 7984MB
[2024-07-15 20:50:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:27 lr 0.000029	 wd 0.0000	time 0.2401 (0.2585)	loss 1.0629 (1.3580)	grad_norm 0.5003 (nan)	loss_scale 2048.0000 (3479.5532)	mem 7984MB
[2024-07-15 20:51:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:03:00 lr 0.000030	 wd 0.0000	time 0.2351 (0.2571)	loss 1.6136 (1.3596)	grad_norm 0.5211 (nan)	loss_scale 2048.0000 (3400.0666)	mem 7984MB
[2024-07-15 20:51:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:33 lr 0.000030	 wd 0.0000	time 0.2378 (0.2558)	loss 1.5319 (1.3594)	grad_norm 0.4753 (nan)	loss_scale 2048.0000 (3328.9427)	mem 7984MB
[2024-07-15 20:52:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:08 lr 0.000030	 wd 0.0000	time 0.3564 (0.2555)	loss 1.1626 (1.3601)	grad_norm 0.6896 (nan)	loss_scale 2048.0000 (3264.9275)	mem 7984MB
[2024-07-15 20:52:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:42 lr 0.000031	 wd 0.0000	time 0.2289 (0.2551)	loss 1.2102 (1.3584)	grad_norm 0.4716 (nan)	loss_scale 2048.0000 (3207.0062)	mem 7984MB
[2024-07-15 20:52:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:16 lr 0.000031	 wd 0.0000	time 0.2067 (0.2540)	loss 1.3499 (1.3596)	grad_norm 0.6092 (nan)	loss_scale 2048.0000 (3154.3480)	mem 7984MB
[2024-07-15 20:53:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:51 lr 0.000031	 wd 0.0000	time 0.2506 (0.2531)	loss 1.5217 (1.3602)	grad_norm 0.4580 (nan)	loss_scale 2048.0000 (3106.2668)	mem 7984MB
[2024-07-15 20:53:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:25 lr 0.000032	 wd 0.0000	time 0.2241 (0.2528)	loss 0.9765 (1.3595)	grad_norm 0.4735 (nan)	loss_scale 2048.0000 (3062.1908)	mem 7984MB
[2024-07-15 20:53:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000032	 wd 0.0000	time 0.1714 (0.2515)	loss 1.5432 (1.3600)	grad_norm 0.5793 (nan)	loss_scale 2048.0000 (3021.6393)	mem 7984MB
[2024-07-15 20:54:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 3 training takes 0:10:35
[2024-07-15 20:54:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 22.979 (22.979)	Loss 0.4165 (0.4165)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-15 20:54:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.142 Acc@5 97.266
[2024-07-15 20:54:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 20:54:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.16%
[2024-07-15 20:55:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][0/2502]	eta 16:27:40 lr 0.000032	 wd 0.0000	time 23.6854 (23.6854)	loss 1.4208 (1.4208)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 20:55:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:19:32 lr 0.000032	 wd 0.0000	time 0.2399 (0.4883)	loss 1.1435 (1.3690)	grad_norm 0.4649 (0.5275)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 20:55:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:13:42 lr 0.000033	 wd 0.0000	time 0.2125 (0.3574)	loss 1.1290 (1.3707)	grad_norm 0.5424 (0.5310)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 20:56:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:11:32 lr 0.000033	 wd 0.0000	time 0.2315 (0.3143)	loss 1.1067 (1.3706)	grad_norm 0.4859 (0.5266)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 20:56:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:10:20 lr 0.000033	 wd 0.0000	time 0.2347 (0.2954)	loss 1.5799 (1.3664)	grad_norm 0.4540 (0.5255)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 20:57:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:09:31 lr 0.000034	 wd 0.0000	time 0.2426 (0.2855)	loss 1.3348 (1.3597)	grad_norm 0.4975 (0.5216)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 20:57:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:08:46 lr 0.000034	 wd 0.0000	time 0.2244 (0.2766)	loss 1.4845 (1.3557)	grad_norm 0.5235 (0.5203)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 20:57:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:08:06 lr 0.000034	 wd 0.0000	time 0.2095 (0.2699)	loss 1.2692 (1.3556)	grad_norm 0.4684 (0.5169)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 20:58:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:32 lr 0.000035	 wd 0.0000	time 0.2382 (0.2657)	loss 1.4688 (1.3550)	grad_norm 0.6633 (0.5232)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 20:58:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:07:04 lr 0.000035	 wd 0.0000	time 0.2058 (0.2651)	loss 1.4782 (1.3561)	grad_norm 0.4738 (0.5244)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 20:59:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:33 lr 0.000035	 wd 0.0000	time 0.2179 (0.2618)	loss 1.5225 (1.3570)	grad_norm 0.4365 (0.5249)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 20:59:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:06:03 lr 0.000036	 wd 0.0000	time 0.2176 (0.2592)	loss 1.5210 (1.3578)	grad_norm 0.4915 (0.5237)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 20:59:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:34 lr 0.000036	 wd 0.0000	time 0.2338 (0.2571)	loss 1.0756 (1.3565)	grad_norm 0.4543 (0.5236)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:00:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:05:09 lr 0.000036	 wd 0.0000	time 0.2135 (0.2572)	loss 1.5637 (1.3558)	grad_norm 0.4909 (0.5225)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:00:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:41 lr 0.000036	 wd 0.0000	time 0.2489 (0.2558)	loss 1.5000 (1.3560)	grad_norm 0.5618 (0.5233)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:01:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:14 lr 0.000037	 wd 0.0000	time 0.2383 (0.2542)	loss 1.2579 (1.3584)	grad_norm 0.4497 (0.5217)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:01:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:48 lr 0.000037	 wd 0.0000	time 0.2385 (0.2529)	loss 1.0607 (1.3580)	grad_norm 0.4870 (0.5198)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:01:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:23 lr 0.000037	 wd 0.0000	time 0.4306 (0.2538)	loss 1.5394 (1.3574)	grad_norm 0.6667 (0.5204)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:02:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:57 lr 0.000038	 wd 0.0000	time 0.2201 (0.2532)	loss 1.3652 (1.3573)	grad_norm 0.5049 (0.5194)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:02:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:31 lr 0.000038	 wd 0.0000	time 0.2182 (0.2522)	loss 1.6451 (1.3572)	grad_norm 0.5246 (0.5185)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:03:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:02:06 lr 0.000038	 wd 0.0000	time 0.2624 (0.2514)	loss 1.4634 (1.3566)	grad_norm 0.5546 (0.5176)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:03:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:41 lr 0.000039	 wd 0.0000	time 0.2051 (0.2517)	loss 1.4289 (1.3570)	grad_norm 0.5176 (0.5184)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:03:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:15 lr 0.000039	 wd 0.0000	time 0.2009 (0.2510)	loss 0.9916 (1.3547)	grad_norm 0.4224 (0.5187)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:04:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:50 lr 0.000039	 wd 0.0000	time 0.2385 (0.2503)	loss 1.2911 (1.3549)	grad_norm 0.6017 (0.5181)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:04:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:25 lr 0.000040	 wd 0.0000	time 0.2784 (0.2498)	loss 1.5747 (1.3547)	grad_norm 0.4579 (0.5170)	loss_scale 4096.0000 (2056.5298)	mem 7984MB
[2024-07-15 21:05:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1724 (0.2484)	loss 0.9233 (1.3546)	grad_norm 0.5285 (0.5169)	loss_scale 4096.0000 (2138.0760)	mem 7984MB
[2024-07-15 21:05:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 4 training takes 0:10:30
[2024-07-15 21:05:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 24.135 (24.135)	Loss 0.4150 (0.4150)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-15 21:05:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.206 Acc@5 97.268
[2024-07-15 21:05:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 21:05:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.21%
[2024-07-15 21:05:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft/ckpt_epoch_best.pth saving......
[2024-07-15 21:05:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft/ckpt_epoch_best.pth saved !!!
[2024-07-15 21:06:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][0/2502]	eta 11:03:23 lr 0.000040	 wd 0.0000	time 15.9088 (15.9088)	loss 1.5933 (1.5933)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:06:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:16:12 lr 0.000040	 wd 0.0000	time 0.2319 (0.4050)	loss 1.2921 (1.3750)	grad_norm 0.6232 (0.5207)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:06:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:12:25 lr 0.000040	 wd 0.0000	time 0.2198 (0.3240)	loss 1.4651 (1.3785)	grad_norm 0.4561 (0.5199)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:07:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:40 lr 0.000040	 wd 0.0000	time 0.2200 (0.2909)	loss 1.6132 (1.3681)	grad_norm 0.5396 (0.5134)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:07:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:37 lr 0.000040	 wd 0.0000	time 0.2098 (0.2749)	loss 0.9950 (1.3693)	grad_norm 0.4698 (0.5151)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:08:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:08:56 lr 0.000040	 wd 0.0000	time 0.3153 (0.2679)	loss 1.5092 (1.3648)	grad_norm 0.4583 (0.5123)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:08:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:24 lr 0.000040	 wd 0.0000	time 0.2117 (0.2654)	loss 1.4243 (1.3656)	grad_norm 0.4480 (0.5180)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:08:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:48 lr 0.000040	 wd 0.0000	time 0.2272 (0.2600)	loss 1.4536 (1.3633)	grad_norm 0.5346 (0.5183)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:09:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:16 lr 0.000040	 wd 0.0000	time 0.2258 (0.2564)	loss 0.9267 (1.3572)	grad_norm 0.7674 (0.5228)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:09:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:47 lr 0.000040	 wd 0.0000	time 0.2566 (0.2546)	loss 0.9060 (1.3565)	grad_norm 0.5256 (0.5217)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:10:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:23 lr 0.000040	 wd 0.0000	time 0.2672 (0.2551)	loss 1.5213 (1.3595)	grad_norm 0.4920 (0.5207)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:10:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:54 lr 0.000040	 wd 0.0000	time 0.2491 (0.2530)	loss 1.5348 (1.3556)	grad_norm 0.5242 (0.5198)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:10:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:27 lr 0.000040	 wd 0.0000	time 0.1955 (0.2513)	loss 1.5409 (1.3536)	grad_norm 0.4990 (0.5192)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:11:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:05:00 lr 0.000040	 wd 0.0000	time 0.2744 (0.2503)	loss 1.4862 (1.3540)	grad_norm 0.4989 (0.5181)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:11:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:36 lr 0.000040	 wd 0.0000	time 0.2632 (0.2507)	loss 1.5250 (1.3535)	grad_norm 0.4539 (0.5173)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:12:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:04:10 lr 0.000040	 wd 0.0000	time 0.2239 (0.2496)	loss 1.3821 (1.3536)	grad_norm 0.9252 (0.5177)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:12:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:44 lr 0.000040	 wd 0.0000	time 0.2206 (0.2486)	loss 1.4348 (1.3556)	grad_norm 0.5896 (0.5223)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:12:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:18 lr 0.000040	 wd 0.0000	time 0.2372 (0.2480)	loss 1.3351 (1.3552)	grad_norm 0.6640 (0.5228)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:13:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:54 lr 0.000040	 wd 0.0000	time 0.2309 (0.2491)	loss 0.9854 (1.3546)	grad_norm 0.5257 (0.5242)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:13:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:29 lr 0.000040	 wd 0.0000	time 0.2155 (0.2487)	loss 1.4667 (1.3567)	grad_norm 0.4822 (0.5246)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:14:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:02:04 lr 0.000040	 wd 0.0000	time 0.2256 (0.2481)	loss 1.5088 (1.3576)	grad_norm 0.4788 (0.5250)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:14:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:39 lr 0.000040	 wd 0.0000	time 0.2789 (0.2477)	loss 1.4943 (1.3581)	grad_norm 0.4655 (0.5237)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:14:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:14 lr 0.000040	 wd 0.0000	time 0.1879 (0.2483)	loss 1.2312 (1.3561)	grad_norm 0.4842 (0.5227)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:15:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:50 lr 0.000040	 wd 0.0000	time 0.1883 (0.2479)	loss 0.8936 (1.3553)	grad_norm 0.4794 (0.5220)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:15:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:25 lr 0.000040	 wd 0.0000	time 0.2131 (0.2474)	loss 1.4983 (1.3554)	grad_norm 0.4978 (0.5218)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:16:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1752 (0.2456)	loss 1.5101 (1.3553)	grad_norm 0.5425 (nan)	loss_scale 2048.0000 (4091.0868)	mem 7984MB
[2024-07-15 21:16:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 5 training takes 0:10:18
[2024-07-15 21:16:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 34.844 (34.844)	Loss 0.4116 (0.4116)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-15 21:16:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.124 Acc@5 97.250
[2024-07-15 21:16:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 21:16:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.21%
[2024-07-15 21:17:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][0/2502]	eta 11:06:38 lr 0.000040	 wd 0.0000	time 15.9868 (15.9868)	loss 1.5601 (1.5601)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:17:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:15:35 lr 0.000040	 wd 0.0000	time 0.2647 (0.3897)	loss 1.2114 (1.3272)	grad_norm 0.5121 (0.5129)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:18:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:12:29 lr 0.000040	 wd 0.0000	time 0.2149 (0.3257)	loss 1.5828 (1.3476)	grad_norm 0.4590 (0.5261)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:18:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:10:47 lr 0.000040	 wd 0.0000	time 0.2192 (0.2942)	loss 1.4562 (1.3582)	grad_norm 0.7237 (0.5426)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:18:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:09:42 lr 0.000040	 wd 0.0000	time 0.2055 (0.2772)	loss 1.3676 (1.3520)	grad_norm 0.5583 (0.5362)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:19:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:08:53 lr 0.000040	 wd 0.0000	time 0.2528 (0.2666)	loss 1.3481 (1.3465)	grad_norm 0.4772 (0.5277)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:19:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:08:21 lr 0.000040	 wd 0.0000	time 0.2461 (0.2638)	loss 1.5822 (1.3505)	grad_norm 0.5041 (0.5258)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:19:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:07:51 lr 0.000040	 wd 0.0000	time 0.2020 (0.2615)	loss 1.4113 (1.3528)	grad_norm 0.6241 (0.5245)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:20:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:18 lr 0.000040	 wd 0.0000	time 0.2068 (0.2577)	loss 0.9998 (1.3519)	grad_norm 0.5085 (0.5218)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:20:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:06:47 lr 0.000040	 wd 0.0000	time 0.1954 (0.2546)	loss 1.6342 (1.3558)	grad_norm 0.4288 (0.5229)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:21:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:22 lr 0.000040	 wd 0.0000	time 0.2271 (0.2543)	loss 1.2993 (1.3513)	grad_norm 0.4903 (0.5228)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:21:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:55 lr 0.000040	 wd 0.0000	time 0.2279 (0.2536)	loss 1.1935 (1.3504)	grad_norm 0.4972 (0.5207)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:21:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:27 lr 0.000040	 wd 0.0000	time 0.2151 (0.2519)	loss 1.0483 (1.3520)	grad_norm 0.4834 (0.5212)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:22:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:05:00 lr 0.000040	 wd 0.0000	time 0.2113 (0.2502)	loss 1.4003 (1.3511)	grad_norm 0.4867 (0.5204)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:22:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:35 lr 0.000040	 wd 0.0000	time 0.2234 (0.2496)	loss 1.6453 (1.3498)	grad_norm 0.4808 (0.5199)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:23:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:10 lr 0.000040	 wd 0.0000	time 0.2128 (0.2497)	loss 1.4591 (1.3514)	grad_norm 0.5363 (0.5179)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:23:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:44 lr 0.000040	 wd 0.0000	time 0.2188 (0.2487)	loss 1.5330 (1.3501)	grad_norm 0.4869 (0.5174)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:23:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:18 lr 0.000040	 wd 0.0000	time 0.2149 (0.2477)	loss 1.4967 (1.3495)	grad_norm 0.6208 (0.5198)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:24:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:53 lr 0.000040	 wd 0.0000	time 0.2490 (0.2477)	loss 1.1515 (1.3493)	grad_norm 0.4602 (0.5235)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:24:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:29 lr 0.000040	 wd 0.0000	time 0.2017 (0.2484)	loss 1.2762 (1.3487)	grad_norm 0.6024 (0.5245)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:25:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:02:04 lr 0.000039	 wd 0.0000	time 0.1993 (0.2476)	loss 0.9884 (1.3487)	grad_norm 0.5010 (0.5232)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:25:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:39 lr 0.000039	 wd 0.0000	time 0.2292 (0.2468)	loss 1.5583 (1.3483)	grad_norm 0.4846 (0.5224)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:25:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:14 lr 0.000039	 wd 0.0000	time 0.2412 (0.2467)	loss 1.2540 (1.3488)	grad_norm 0.6851 (0.5235)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:26:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:49 lr 0.000039	 wd 0.0000	time 0.2366 (0.2469)	loss 1.4431 (1.3495)	grad_norm 0.4938 (0.5225)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:26:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:25 lr 0.000039	 wd 0.0000	time 0.2282 (0.2463)	loss 1.1828 (1.3487)	grad_norm 0.4410 (0.5226)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:27:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1722 (0.2446)	loss 1.0293 (1.3494)	grad_norm 0.5257 (0.5226)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:27:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 6 training takes 0:10:16
[2024-07-15 21:27:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 35.911 (35.911)	Loss 0.4146 (0.4146)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 7984MB
[2024-07-15 21:28:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.100 Acc@5 97.258
[2024-07-15 21:28:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 21:28:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.21%
[2024-07-15 21:28:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][0/2502]	eta 11:24:16 lr 0.000039	 wd 0.0000	time 16.4096 (16.4096)	loss 1.5831 (1.5831)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:28:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:15:39 lr 0.000039	 wd 0.0000	time 0.2377 (0.3911)	loss 1.2269 (1.3748)	grad_norm 0.5176 (0.5198)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:29:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:12:08 lr 0.000039	 wd 0.0000	time 0.2853 (0.3163)	loss 1.4400 (1.3494)	grad_norm 0.5111 (0.5167)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:29:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:10:52 lr 0.000039	 wd 0.0000	time 0.2241 (0.2965)	loss 1.3101 (1.3471)	grad_norm 0.4732 (0.5384)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:29:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:09:48 lr 0.000039	 wd 0.0000	time 0.2101 (0.2799)	loss 1.3322 (1.3489)	grad_norm 0.4772 (0.5450)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:30:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:08:58 lr 0.000039	 wd 0.0000	time 0.2223 (0.2690)	loss 1.4320 (1.3444)	grad_norm 0.7279 (0.5367)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:30:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:20 lr 0.000039	 wd 0.0000	time 0.2919 (0.2633)	loss 1.3220 (1.3482)	grad_norm 0.4518 (0.5372)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:31:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:07:52 lr 0.000039	 wd 0.0000	time 0.2246 (0.2623)	loss 1.4850 (1.3520)	grad_norm 0.4912 (0.5362)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:31:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:07:19 lr 0.000039	 wd 0.0000	time 0.2114 (0.2583)	loss 0.8922 (1.3543)	grad_norm 0.4888 (0.5367)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:31:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:06:48 lr 0.000039	 wd 0.0000	time 0.2379 (0.2552)	loss 1.0902 (1.3560)	grad_norm 0.4788 (0.5352)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:32:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:19 lr 0.000039	 wd 0.0000	time 0.1943 (0.2528)	loss 1.1742 (1.3520)	grad_norm 0.4929 (0.5331)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:32:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:54 lr 0.000039	 wd 0.0000	time 0.2228 (0.2527)	loss 1.2299 (1.3505)	grad_norm 0.4541 (0.5350)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:33:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:27 lr 0.000039	 wd 0.0000	time 0.2433 (0.2513)	loss 1.4105 (1.3493)	grad_norm 0.4641 (0.5331)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:33:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:05:00 lr 0.000039	 wd 0.0000	time 0.2369 (0.2498)	loss 1.4750 (1.3494)	grad_norm 0.4662 (0.5322)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:33:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:33 lr 0.000039	 wd 0.0000	time 0.2249 (0.2484)	loss 1.4119 (1.3503)	grad_norm 0.4565 (0.5323)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 21:34:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:09 lr 0.000039	 wd 0.0000	time 0.8790 (0.2495)	loss 1.6403 (1.3496)	grad_norm 0.5258 (0.5312)	loss_scale 4096.0000 (2061.6442)	mem 7984MB
[2024-07-15 21:34:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:44 lr 0.000039	 wd 0.0000	time 0.2323 (0.2491)	loss 1.5150 (1.3515)	grad_norm 0.4800 (0.5306)	loss_scale 4096.0000 (2188.7121)	mem 7984MB
[2024-07-15 21:35:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:18 lr 0.000039	 wd 0.0000	time 0.2135 (0.2481)	loss 1.5645 (1.3517)	grad_norm 0.4806 (0.5287)	loss_scale 4096.0000 (2300.8395)	mem 7984MB
[2024-07-15 21:35:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:53 lr 0.000039	 wd 0.0000	time 0.2655 (0.2475)	loss 1.1217 (1.3512)	grad_norm 0.5508 (0.5284)	loss_scale 4096.0000 (2400.5153)	mem 7984MB
[2024-07-15 21:35:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:29 lr 0.000039	 wd 0.0000	time 0.2183 (0.2479)	loss 1.3089 (1.3507)	grad_norm 0.5114 (0.5264)	loss_scale 4096.0000 (2489.7044)	mem 7984MB
[2024-07-15 21:36:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:02:04 lr 0.000039	 wd 0.0000	time 0.2111 (0.2476)	loss 1.4132 (1.3517)	grad_norm 0.5899 (0.5260)	loss_scale 4096.0000 (2569.9790)	mem 7984MB
[2024-07-15 21:36:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:39 lr 0.000039	 wd 0.0000	time 0.2143 (0.2470)	loss 1.5010 (1.3528)	grad_norm 0.5511 (0.5252)	loss_scale 4096.0000 (2642.6121)	mem 7984MB
[2024-07-15 21:37:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:14 lr 0.000039	 wd 0.0000	time 0.2426 (0.2464)	loss 1.0984 (1.3509)	grad_norm 0.4493 (0.5249)	loss_scale 4096.0000 (2708.6452)	mem 7984MB
[2024-07-15 21:37:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:49 lr 0.000039	 wd 0.0000	time 0.2148 (0.2470)	loss 1.5570 (1.3514)	grad_norm 0.4445 (0.5241)	loss_scale 4096.0000 (2768.9387)	mem 7984MB
[2024-07-15 21:37:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:25 lr 0.000039	 wd 0.0000	time 0.2260 (0.2465)	loss 1.4548 (1.3509)	grad_norm 0.4654 (0.5230)	loss_scale 4096.0000 (2824.2099)	mem 7984MB
[2024-07-15 21:38:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1754 (0.2448)	loss 1.2670 (1.3511)	grad_norm 0.4803 (0.5218)	loss_scale 4096.0000 (2875.0612)	mem 7984MB
[2024-07-15 21:38:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 7 training takes 0:10:17
[2024-07-15 21:38:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 18.624 (18.624)	Loss 0.4209 (0.4209)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 7984MB
[2024-07-15 21:38:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.164 Acc@5 97.316
[2024-07-15 21:38:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 21:38:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.21%
[2024-07-15 21:39:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][0/2502]	eta 23:02:59 lr 0.000039	 wd 0.0000	time 33.1651 (33.1651)	loss 1.4144 (1.4144)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:39:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:22:14 lr 0.000039	 wd 0.0000	time 0.2345 (0.5558)	loss 1.4432 (1.3887)	grad_norm 0.4841 (0.5015)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:40:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:15:00 lr 0.000039	 wd 0.0000	time 0.2260 (0.3911)	loss 1.5177 (1.3640)	grad_norm 0.7259 (0.5035)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:40:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:13:30 lr 0.000038	 wd 0.0000	time 0.2499 (0.3680)	loss 1.3471 (1.3609)	grad_norm 0.5418 (0.5052)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:41:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:11:42 lr 0.000038	 wd 0.0000	time 0.2367 (0.3343)	loss 1.6199 (1.3572)	grad_norm 0.6027 (0.5263)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:41:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:10:25 lr 0.000038	 wd 0.0000	time 0.2211 (0.3126)	loss 1.4328 (1.3602)	grad_norm 0.4821 (0.5221)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:41:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:09:27 lr 0.000038	 wd 0.0000	time 0.2254 (0.2985)	loss 1.5209 (1.3646)	grad_norm 0.4636 (0.5187)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:42:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:08:46 lr 0.000038	 wd 0.0000	time 0.3212 (0.2923)	loss 1.6317 (1.3627)	grad_norm 0.4745 (0.5211)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:42:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:08:07 lr 0.000038	 wd 0.0000	time 0.2229 (0.2867)	loss 1.4651 (1.3603)	grad_norm 0.4307 (0.5225)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:43:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:07:29 lr 0.000038	 wd 0.0000	time 0.2088 (0.2806)	loss 1.6481 (1.3605)	grad_norm 0.4699 (0.5221)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:43:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:54 lr 0.000038	 wd 0.0000	time 0.2512 (0.2757)	loss 1.4942 (1.3569)	grad_norm 0.6745 (0.5230)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:43:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:06:23 lr 0.000038	 wd 0.0000	time 0.2331 (0.2733)	loss 1.3303 (1.3538)	grad_norm 0.6145 (0.5259)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:44:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:52 lr 0.000038	 wd 0.0000	time 0.2201 (0.2710)	loss 1.4486 (1.3540)	grad_norm 0.5182 (0.5258)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:44:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:05:22 lr 0.000038	 wd 0.0000	time 0.2199 (0.2680)	loss 1.1727 (1.3526)	grad_norm 0.4873 (0.5268)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:45:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:52 lr 0.000038	 wd 0.0000	time 0.2594 (0.2653)	loss 0.9653 (1.3544)	grad_norm 0.6213 (0.5259)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:45:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:04:24 lr 0.000038	 wd 0.0000	time 0.2136 (0.2642)	loss 0.8201 (1.3521)	grad_norm 0.5019 (0.5265)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:45:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:58 lr 0.000038	 wd 0.0000	time 0.2548 (0.2639)	loss 1.2117 (1.3493)	grad_norm 0.4751 (0.5259)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:46:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:30 lr 0.000038	 wd 0.0000	time 0.2112 (0.2622)	loss 1.1732 (1.3510)	grad_norm 0.5221 (0.5253)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:46:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:03:02 lr 0.000038	 wd 0.0000	time 0.2143 (0.2606)	loss 1.5357 (1.3520)	grad_norm 0.6021 (0.5249)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:47:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:36 lr 0.000038	 wd 0.0000	time 0.2266 (0.2598)	loss 1.2880 (1.3512)	grad_norm 0.4603 (0.5257)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:47:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:02:10 lr 0.000038	 wd 0.0000	time 0.2155 (0.2595)	loss 1.6819 (1.3533)	grad_norm 0.4603 (0.5244)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:47:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:43 lr 0.000038	 wd 0.0000	time 0.2366 (0.2582)	loss 1.4036 (1.3524)	grad_norm 0.4897 (0.5231)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:48:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:17 lr 0.000038	 wd 0.0000	time 0.2551 (0.2571)	loss 1.5562 (1.3510)	grad_norm 0.4938 (0.5231)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:48:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:51 lr 0.000038	 wd 0.0000	time 0.2146 (0.2565)	loss 1.4738 (1.3517)	grad_norm 0.5225 (0.5248)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:49:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:26 lr 0.000038	 wd 0.0000	time 0.2599 (0.2559)	loss 1.3126 (1.3533)	grad_norm 0.5311 (0.5284)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:49:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000038	 wd 0.0000	time 0.2017 (0.2539)	loss 1.7370 (1.3547)	grad_norm 0.4576 (0.5273)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:49:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 8 training takes 0:10:39
[2024-07-15 21:49:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 18.844 (18.844)	Loss 0.4209 (0.4209)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-15 21:50:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.190 Acc@5 97.270
[2024-07-15 21:50:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 21:50:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.21%
[2024-07-15 21:50:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][0/2502]	eta 23:46:06 lr 0.000038	 wd 0.0000	time 34.1994 (34.1994)	loss 1.3461 (1.3461)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:50:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:22:39 lr 0.000038	 wd 0.0000	time 0.2197 (0.5658)	loss 1.2288 (1.3187)	grad_norm 0.5490 (0.6103)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:51:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:15:11 lr 0.000037	 wd 0.0000	time 0.1873 (0.3958)	loss 1.4858 (1.3319)	grad_norm 0.5077 (0.5634)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:51:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:12:39 lr 0.000037	 wd 0.0000	time 0.2351 (0.3449)	loss 1.4330 (1.3437)	grad_norm 0.4694 (0.5505)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:52:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:11:14 lr 0.000037	 wd 0.0000	time 0.2054 (0.3207)	loss 1.5762 (1.3388)	grad_norm 0.4732 (0.5421)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 21:52:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:10:04 lr 0.000037	 wd 0.0000	time 0.2258 (0.3018)	loss 1.3725 (1.3455)	grad_norm 0.4964 (0.5355)	loss_scale 8192.0000 (4210.4591)	mem 7984MB
[2024-07-15 21:52:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:09:10 lr 0.000037	 wd 0.0000	time 0.2162 (0.2894)	loss 1.4898 (1.3401)	grad_norm 0.4721 (nan)	loss_scale 4096.0000 (4573.0715)	mem 7984MB
[2024-07-15 21:53:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:08:27 lr 0.000037	 wd 0.0000	time 0.2308 (0.2817)	loss 1.5127 (1.3418)	grad_norm 0.4678 (nan)	loss_scale 4096.0000 (4505.0157)	mem 7984MB
[2024-07-15 21:53:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:54 lr 0.000037	 wd 0.0000	time 0.2190 (0.2786)	loss 1.3824 (1.3446)	grad_norm 0.5319 (nan)	loss_scale 4096.0000 (4453.9526)	mem 7984MB
[2024-07-15 21:54:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:07:18 lr 0.000037	 wd 0.0000	time 0.2213 (0.2734)	loss 1.5819 (1.3418)	grad_norm 0.4617 (nan)	loss_scale 4096.0000 (4414.2242)	mem 7984MB
[2024-07-15 21:54:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:44 lr 0.000037	 wd 0.0000	time 0.2132 (0.2691)	loss 1.4652 (1.3445)	grad_norm 0.4610 (nan)	loss_scale 4096.0000 (4382.4336)	mem 7984MB
[2024-07-15 21:54:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:06:12 lr 0.000037	 wd 0.0000	time 0.2558 (0.2659)	loss 1.3759 (1.3475)	grad_norm 0.4649 (nan)	loss_scale 4096.0000 (4356.4178)	mem 7984MB
[2024-07-15 21:55:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:45 lr 0.000037	 wd 0.0000	time 0.2381 (0.2656)	loss 1.5381 (1.3485)	grad_norm 0.4450 (nan)	loss_scale 4096.0000 (4334.7344)	mem 7984MB
[2024-07-15 21:55:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:05:16 lr 0.000037	 wd 0.0000	time 0.2175 (0.2633)	loss 0.9645 (1.3465)	grad_norm 0.4888 (nan)	loss_scale 4096.0000 (4316.3843)	mem 7984MB
[2024-07-15 21:56:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:47 lr 0.000037	 wd 0.0000	time 0.2158 (0.2611)	loss 1.3305 (1.3478)	grad_norm 0.4433 (nan)	loss_scale 4096.0000 (4300.6538)	mem 7984MB
[2024-07-15 21:56:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:04:19 lr 0.000037	 wd 0.0000	time 0.2420 (0.2592)	loss 1.4566 (1.3498)	grad_norm 0.4953 (nan)	loss_scale 4096.0000 (4287.0193)	mem 7984MB
[2024-07-15 21:56:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:53 lr 0.000037	 wd 0.0000	time 0.3415 (0.2590)	loss 0.9188 (1.3488)	grad_norm 0.4702 (nan)	loss_scale 4096.0000 (4275.0881)	mem 7984MB
[2024-07-15 21:57:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:26 lr 0.000037	 wd 0.0000	time 0.2237 (0.2577)	loss 1.1009 (1.3501)	grad_norm 1.6785 (nan)	loss_scale 4096.0000 (4264.5597)	mem 7984MB
[2024-07-15 21:57:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:59 lr 0.000037	 wd 0.0000	time 0.2268 (0.2563)	loss 1.5304 (1.3505)	grad_norm 0.5811 (nan)	loss_scale 4096.0000 (4255.2004)	mem 7984MB
[2024-07-15 21:58:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:33 lr 0.000037	 wd 0.0000	time 0.2245 (0.2552)	loss 1.3177 (1.3492)	grad_norm 0.5002 (nan)	loss_scale 4096.0000 (4246.8259)	mem 7984MB
[2024-07-15 21:58:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:02:08 lr 0.000037	 wd 0.0000	time 0.2367 (0.2552)	loss 1.4798 (1.3494)	grad_norm 0.4598 (nan)	loss_scale 4096.0000 (4239.2884)	mem 7984MB
[2024-07-15 21:58:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:42 lr 0.000036	 wd 0.0000	time 0.2204 (0.2544)	loss 1.0703 (1.3495)	grad_norm 0.6422 (nan)	loss_scale 4096.0000 (4232.4683)	mem 7984MB
[2024-07-15 21:59:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:16 lr 0.000036	 wd 0.0000	time 0.2228 (0.2534)	loss 1.4811 (1.3505)	grad_norm 0.4720 (nan)	loss_scale 4096.0000 (4226.2681)	mem 7984MB
[2024-07-15 21:59:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:51 lr 0.000036	 wd 0.0000	time 0.2466 (0.2526)	loss 1.4196 (1.3512)	grad_norm 0.4920 (nan)	loss_scale 4096.0000 (4220.6067)	mem 7984MB
[2024-07-15 22:00:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:25 lr 0.000036	 wd 0.0000	time 0.2258 (0.2525)	loss 1.2582 (1.3509)	grad_norm 0.4863 (nan)	loss_scale 4096.0000 (4215.4169)	mem 7984MB
[2024-07-15 22:00:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000036	 wd 0.0000	time 0.1890 (0.2509)	loss 1.1181 (1.3519)	grad_norm 0.4836 (nan)	loss_scale 4096.0000 (4210.6421)	mem 7984MB
[2024-07-15 22:00:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 9 training takes 0:10:32
[2024-07-15 22:00:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 21.496 (21.496)	Loss 0.4131 (0.4131)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-15 22:01:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.170 Acc@5 97.266
[2024-07-15 22:01:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 22:01:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.21%
[2024-07-15 22:01:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][0/2502]	eta 14:48:40 lr 0.000036	 wd 0.0000	time 21.3112 (21.3112)	loss 1.2845 (1.2845)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:01:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:18:38 lr 0.000036	 wd 0.0000	time 0.2038 (0.4657)	loss 1.3451 (1.3329)	grad_norm 0.4708 (0.4966)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:02:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:13:17 lr 0.000036	 wd 0.0000	time 0.2320 (0.3464)	loss 1.2864 (1.3533)	grad_norm 0.4703 (0.5118)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:02:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:11:14 lr 0.000036	 wd 0.0000	time 0.2097 (0.3064)	loss 0.8757 (1.3504)	grad_norm 0.4862 (0.5214)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:03:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:10:09 lr 0.000036	 wd 0.0000	time 0.2191 (0.2898)	loss 1.5037 (1.3538)	grad_norm 0.5114 (0.5243)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:03:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:09:23 lr 0.000036	 wd 0.0000	time 0.2104 (0.2813)	loss 1.4014 (1.3498)	grad_norm 0.4383 (0.5221)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:03:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:39 lr 0.000036	 wd 0.0000	time 0.2015 (0.2732)	loss 1.5068 (1.3502)	grad_norm 0.5578 (0.5233)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:04:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:08:01 lr 0.000036	 wd 0.0000	time 0.1981 (0.2671)	loss 1.4669 (1.3462)	grad_norm 0.5204 (0.5246)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:04:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:07:27 lr 0.000036	 wd 0.0000	time 0.2300 (0.2630)	loss 1.2366 (1.3454)	grad_norm 0.4652 (0.5232)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:05:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:59 lr 0.000036	 wd 0.0000	time 0.2142 (0.2618)	loss 1.5264 (1.3456)	grad_norm 0.5452 (0.5216)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:05:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:28 lr 0.000036	 wd 0.0000	time 0.2204 (0.2588)	loss 1.4962 (1.3442)	grad_norm 0.5190 (0.5198)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:05:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:59 lr 0.000036	 wd 0.0000	time 0.2405 (0.2563)	loss 1.2951 (1.3417)	grad_norm 0.4479 (0.5197)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:06:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:31 lr 0.000035	 wd 0.0000	time 0.2517 (0.2545)	loss 1.3353 (1.3423)	grad_norm 0.6386 (0.5199)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:06:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:05:06 lr 0.000035	 wd 0.0000	time 0.2095 (0.2547)	loss 1.5759 (1.3449)	grad_norm 0.5396 (0.5203)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:07:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:39 lr 0.000035	 wd 0.0000	time 0.2327 (0.2533)	loss 1.3281 (1.3454)	grad_norm 0.5311 (0.5196)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:07:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:04:12 lr 0.000035	 wd 0.0000	time 0.2337 (0.2519)	loss 1.2501 (1.3454)	grad_norm 0.4767 (0.5186)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:07:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:46 lr 0.000035	 wd 0.0000	time 0.2224 (0.2507)	loss 1.2224 (1.3468)	grad_norm 0.4685 (0.5179)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:08:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:21 lr 0.000035	 wd 0.0000	time 0.2209 (0.2513)	loss 1.3128 (1.3478)	grad_norm 0.5095 (0.5179)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:08:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:56 lr 0.000035	 wd 0.0000	time 0.2271 (0.2512)	loss 1.4001 (1.3486)	grad_norm 0.5370 (0.5172)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:09:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:30 lr 0.000035	 wd 0.0000	time 0.2154 (0.2501)	loss 1.4951 (1.3500)	grad_norm 0.5052 (0.5167)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:09:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:02:05 lr 0.000035	 wd 0.0000	time 0.2334 (0.2493)	loss 1.2465 (1.3511)	grad_norm 0.4844 (0.5172)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:09:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:40 lr 0.000035	 wd 0.0000	time 0.2371 (0.2494)	loss 1.5405 (1.3528)	grad_norm 0.4759 (0.5174)	loss_scale 8192.0000 (4185.6792)	mem 7984MB
[2024-07-15 22:10:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:15 lr 0.000035	 wd 0.0000	time 0.2204 (0.2488)	loss 0.9521 (1.3526)	grad_norm 0.4920 (0.5186)	loss_scale 8192.0000 (4367.7020)	mem 7984MB
[2024-07-15 22:10:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:50 lr 0.000035	 wd 0.0000	time 0.2097 (0.2481)	loss 1.4740 (1.3522)	grad_norm 0.4832 (0.5178)	loss_scale 8192.0000 (4533.9035)	mem 7984MB
[2024-07-15 22:11:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:25 lr 0.000035	 wd 0.0000	time 0.2098 (0.2475)	loss 1.5116 (1.3520)	grad_norm 0.4475 (0.5175)	loss_scale 8192.0000 (4686.2607)	mem 7984MB
[2024-07-15 22:11:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1683 (0.2460)	loss 1.3298 (1.3512)	grad_norm 0.5814 (0.5181)	loss_scale 8192.0000 (4826.4342)	mem 7984MB
[2024-07-15 22:11:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 10 training takes 0:10:25
[2024-07-15 22:11:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 25.679 (25.679)	Loss 0.4180 (0.4180)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-15 22:12:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.140 Acc@5 97.276
[2024-07-15 22:12:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 22:12:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.21%
[2024-07-15 22:12:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][0/2502]	eta 10:55:40 lr 0.000035	 wd 0.0000	time 15.7235 (15.7235)	loss 1.4851 (1.4851)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:12:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:16:03 lr 0.000035	 wd 0.0000	time 0.2343 (0.4013)	loss 1.3920 (1.3422)	grad_norm 0.4998 (0.5041)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:13:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:12:27 lr 0.000034	 wd 0.0000	time 0.2406 (0.3246)	loss 1.4583 (1.3464)	grad_norm 0.4783 (0.5011)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:13:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:10:42 lr 0.000034	 wd 0.0000	time 0.2245 (0.2916)	loss 1.3248 (1.3491)	grad_norm 0.4753 (0.5022)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:14:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:09:38 lr 0.000034	 wd 0.0000	time 0.2103 (0.2753)	loss 1.5339 (1.3486)	grad_norm 0.5017 (0.5023)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:14:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:08:54 lr 0.000034	 wd 0.0000	time 0.2344 (0.2671)	loss 1.3721 (1.3457)	grad_norm 0.4436 (0.5025)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:14:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:24 lr 0.000034	 wd 0.0000	time 0.2218 (0.2650)	loss 1.4679 (1.3434)	grad_norm 0.5024 (inf)	loss_scale 4096.0000 (7837.6040)	mem 7984MB
[2024-07-15 22:15:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:07:48 lr 0.000034	 wd 0.0000	time 0.2088 (0.2600)	loss 1.4694 (1.3440)	grad_norm 0.4773 (inf)	loss_scale 4096.0000 (7303.8516)	mem 7984MB
[2024-07-15 22:15:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:07:16 lr 0.000034	 wd 0.0000	time 0.2192 (0.2566)	loss 1.5920 (1.3465)	grad_norm 0.5193 (inf)	loss_scale 4096.0000 (6903.3708)	mem 7984MB
[2024-07-15 22:16:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:06:46 lr 0.000034	 wd 0.0000	time 0.2190 (0.2540)	loss 1.4911 (1.3465)	grad_norm 0.4699 (inf)	loss_scale 4096.0000 (6591.7869)	mem 7984MB
[2024-07-15 22:16:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:21 lr 0.000034	 wd 0.0000	time 0.1828 (0.2541)	loss 1.4424 (1.3487)	grad_norm 0.4946 (inf)	loss_scale 4096.0000 (6342.4575)	mem 7984MB
[2024-07-15 22:16:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:53 lr 0.000034	 wd 0.0000	time 0.2438 (0.2523)	loss 1.5389 (1.3500)	grad_norm 0.5015 (inf)	loss_scale 4096.0000 (6138.4196)	mem 7984MB
[2024-07-15 22:17:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:26 lr 0.000034	 wd 0.0000	time 0.2270 (0.2505)	loss 1.6872 (1.3498)	grad_norm 0.5734 (inf)	loss_scale 4096.0000 (5968.3597)	mem 7984MB
[2024-07-15 22:17:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:04:59 lr 0.000034	 wd 0.0000	time 0.2474 (0.2493)	loss 0.8978 (1.3488)	grad_norm 0.4566 (inf)	loss_scale 4096.0000 (5824.4427)	mem 7984MB
[2024-07-15 22:18:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:35 lr 0.000034	 wd 0.0000	time 0.2018 (0.2501)	loss 0.8734 (1.3483)	grad_norm 0.4484 (inf)	loss_scale 4096.0000 (5701.0707)	mem 7984MB
[2024-07-15 22:18:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:04:09 lr 0.000034	 wd 0.0000	time 0.2094 (0.2491)	loss 1.4286 (1.3474)	grad_norm 0.4403 (inf)	loss_scale 4096.0000 (5594.1372)	mem 7984MB
[2024-07-15 22:18:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:43 lr 0.000034	 wd 0.0000	time 0.2022 (0.2480)	loss 1.2537 (1.3484)	grad_norm 0.4788 (inf)	loss_scale 4096.0000 (5500.5621)	mem 7984MB
[2024-07-15 22:19:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:18 lr 0.000033	 wd 0.0000	time 0.2302 (0.2472)	loss 1.4472 (1.3477)	grad_norm 0.4724 (inf)	loss_scale 4096.0000 (5417.9894)	mem 7984MB
[2024-07-15 22:19:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:54 lr 0.000033	 wd 0.0000	time 0.2234 (0.2483)	loss 1.2797 (1.3493)	grad_norm 0.4830 (inf)	loss_scale 4096.0000 (5344.5863)	mem 7984MB
[2024-07-15 22:20:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:29 lr 0.000033	 wd 0.0000	time 0.2062 (0.2479)	loss 1.4944 (1.3495)	grad_norm 0.4744 (inf)	loss_scale 4096.0000 (5278.9058)	mem 7984MB
[2024-07-15 22:20:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:02:04 lr 0.000033	 wd 0.0000	time 0.2199 (0.2471)	loss 1.1092 (1.3489)	grad_norm 0.4363 (inf)	loss_scale 4096.0000 (5219.7901)	mem 7984MB
[2024-07-15 22:20:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:39 lr 0.000033	 wd 0.0000	time 0.2486 (0.2466)	loss 1.5339 (1.3487)	grad_norm 0.5392 (inf)	loss_scale 4096.0000 (5166.3018)	mem 7984MB
[2024-07-15 22:21:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:14 lr 0.000033	 wd 0.0000	time 0.2177 (0.2466)	loss 1.2622 (1.3496)	grad_norm 0.5037 (inf)	loss_scale 4096.0000 (5117.6738)	mem 7984MB
[2024-07-15 22:21:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:49 lr 0.000033	 wd 0.0000	time 0.2183 (0.2460)	loss 1.5062 (1.3493)	grad_norm 0.4725 (inf)	loss_scale 4096.0000 (5073.2725)	mem 7984MB
[2024-07-15 22:22:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:25 lr 0.000033	 wd 0.0000	time 0.2208 (0.2455)	loss 1.2579 (1.3485)	grad_norm 0.4756 (inf)	loss_scale 4096.0000 (5032.5698)	mem 7984MB
[2024-07-15 22:22:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000033	 wd 0.0000	time 0.1724 (0.2438)	loss 1.3897 (1.3480)	grad_norm 0.5289 (inf)	loss_scale 4096.0000 (4995.1220)	mem 7984MB
[2024-07-15 22:22:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 11 training takes 0:10:14
[2024-07-15 22:23:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 35.185 (35.185)	Loss 0.4153 (0.4153)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-15 22:23:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.254 Acc@5 97.272
[2024-07-15 22:23:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-15 22:23:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.25%
[2024-07-15 22:23:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft/ckpt_epoch_best.pth saving......
[2024-07-15 22:23:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft/ckpt_epoch_best.pth saved !!!
[2024-07-15 22:23:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][0/2502]	eta 10:42:25 lr 0.000033	 wd 0.0000	time 15.4060 (15.4060)	loss 1.6065 (1.6065)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:23:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:15:12 lr 0.000033	 wd 0.0000	time 0.2385 (0.3800)	loss 1.4938 (1.3536)	grad_norm 0.5341 (0.5115)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:24:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:12:17 lr 0.000033	 wd 0.0000	time 0.2109 (0.3202)	loss 0.9766 (1.3598)	grad_norm 0.4455 (0.5193)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:24:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:43 lr 0.000033	 wd 0.0000	time 0.2042 (0.2923)	loss 1.2932 (1.3600)	grad_norm 0.5763 (0.5194)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:25:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:41 lr 0.000033	 wd 0.0000	time 0.2381 (0.2764)	loss 1.2270 (1.3527)	grad_norm 0.4595 (0.5210)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:25:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:08:53 lr 0.000032	 wd 0.0000	time 0.2373 (0.2667)	loss 1.0058 (1.3534)	grad_norm 0.4487 (0.5225)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:25:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:08:27 lr 0.000032	 wd 0.0000	time 0.3044 (0.2670)	loss 1.3408 (1.3506)	grad_norm 0.5232 (0.5218)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:26:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:59 lr 0.000032	 wd 0.0000	time 0.2334 (0.2662)	loss 1.4527 (1.3482)	grad_norm 0.5376 (0.5182)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:26:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:07:25 lr 0.000032	 wd 0.0000	time 0.1874 (0.2619)	loss 1.4343 (1.3561)	grad_norm 0.5008 (0.5173)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:27:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:53 lr 0.000032	 wd 0.0000	time 0.2194 (0.2580)	loss 1.0436 (1.3565)	grad_norm 0.4827 (0.5194)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:27:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:26 lr 0.000032	 wd 0.0000	time 0.2544 (0.2572)	loss 1.6277 (1.3541)	grad_norm 0.4890 (0.5197)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:27:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:59 lr 0.000032	 wd 0.0000	time 0.2049 (0.2564)	loss 1.4702 (1.3581)	grad_norm 0.4492 (0.5212)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:28:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:30 lr 0.000032	 wd 0.0000	time 0.2236 (0.2541)	loss 1.5012 (1.3571)	grad_norm 0.5192 (0.5213)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:28:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:05:02 lr 0.000032	 wd 0.0000	time 0.2023 (0.2520)	loss 1.4346 (1.3576)	grad_norm 0.5785 (0.5258)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:29:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:37 lr 0.000032	 wd 0.0000	time 0.2142 (0.2522)	loss 1.5830 (1.3575)	grad_norm 0.4797 (0.5245)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:29:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:04:12 lr 0.000032	 wd 0.0000	time 0.2160 (0.2522)	loss 1.4224 (1.3582)	grad_norm 0.4682 (0.5233)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:29:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:46 lr 0.000032	 wd 0.0000	time 0.2376 (0.2511)	loss 1.4097 (1.3570)	grad_norm 0.5951 (0.5221)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:30:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:20 lr 0.000031	 wd 0.0000	time 0.2300 (0.2500)	loss 1.5644 (1.3580)	grad_norm 0.5310 (0.5239)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:30:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:55 lr 0.000031	 wd 0.0000	time 0.2188 (0.2500)	loss 1.2698 (1.3588)	grad_norm 0.5152 (0.5226)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:31:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:30 lr 0.000031	 wd 0.0000	time 0.2471 (0.2505)	loss 1.4003 (1.3583)	grad_norm 0.5006 (0.5219)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:31:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:02:05 lr 0.000031	 wd 0.0000	time 0.2135 (0.2497)	loss 1.3888 (1.3573)	grad_norm 0.4797 (0.5215)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:31:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:40 lr 0.000031	 wd 0.0000	time 0.2266 (0.2488)	loss 1.4165 (1.3585)	grad_norm 0.7238 (0.5215)	loss_scale 8192.0000 (4201.2756)	mem 7984MB
[2024-07-15 22:32:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:15 lr 0.000031	 wd 0.0000	time 0.2299 (0.2486)	loss 1.5606 (1.3600)	grad_norm 0.4642 (0.5216)	loss_scale 8192.0000 (4382.5897)	mem 7984MB
[2024-07-15 22:32:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:50 lr 0.000031	 wd 0.0000	time 0.2196 (0.2486)	loss 1.4279 (1.3600)	grad_norm 0.4730 (0.5219)	loss_scale 8192.0000 (4548.1443)	mem 7984MB
[2024-07-15 22:33:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:25 lr 0.000031	 wd 0.0000	time 0.2469 (0.2480)	loss 1.4999 (1.3597)	grad_norm 0.5159 (0.5241)	loss_scale 8192.0000 (4699.9084)	mem 7984MB
[2024-07-15 22:33:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000031	 wd 0.0000	time 0.1796 (0.2462)	loss 1.1179 (1.3585)	grad_norm 0.5472 (0.5235)	loss_scale 8192.0000 (4839.5362)	mem 7984MB
[2024-07-15 22:33:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 12 training takes 0:10:20
[2024-07-15 22:34:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 34.149 (34.149)	Loss 0.4148 (0.4148)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-15 22:34:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.250 Acc@5 97.276
[2024-07-15 22:34:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-15 22:34:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.25%
[2024-07-15 22:34:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][0/2502]	eta 11:12:40 lr 0.000031	 wd 0.0000	time 16.1313 (16.1313)	loss 1.3600 (1.3600)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:35:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:15:35 lr 0.000031	 wd 0.0000	time 0.2308 (0.3895)	loss 1.3771 (1.3474)	grad_norm 0.4974 (0.5091)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:35:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:12:06 lr 0.000031	 wd 0.0000	time 0.2375 (0.3154)	loss 1.6784 (1.3490)	grad_norm 0.4902 (0.5108)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:35:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:10:55 lr 0.000031	 wd 0.0000	time 0.2261 (0.2975)	loss 1.4413 (1.3568)	grad_norm 0.9215 (0.5123)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:36:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:09:48 lr 0.000030	 wd 0.0000	time 0.2230 (0.2798)	loss 1.3225 (1.3555)	grad_norm 0.4975 (0.5112)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:36:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:08:57 lr 0.000030	 wd 0.0000	time 0.2320 (0.2687)	loss 1.5191 (1.3500)	grad_norm 0.5661 (0.5099)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:37:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:20 lr 0.000030	 wd 0.0000	time 0.2319 (0.2630)	loss 1.5242 (1.3563)	grad_norm 0.5158 (0.5092)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:37:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:07:52 lr 0.000030	 wd 0.0000	time 0.2787 (0.2623)	loss 1.4222 (1.3518)	grad_norm 0.4814 (0.5070)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:37:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:20 lr 0.000030	 wd 0.0000	time 0.2462 (0.2586)	loss 1.5325 (1.3556)	grad_norm 0.4454 (0.5103)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:38:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:06:48 lr 0.000030	 wd 0.0000	time 0.1887 (0.2553)	loss 1.5125 (1.3526)	grad_norm 0.5169 (0.5111)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:38:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:20 lr 0.000030	 wd 0.0000	time 0.2341 (0.2532)	loss 1.5904 (1.3582)	grad_norm 0.5078 (0.5116)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:39:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:55 lr 0.000030	 wd 0.0000	time 0.2539 (0.2534)	loss 1.3884 (1.3596)	grad_norm 0.5349 (0.5142)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:39:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:28 lr 0.000030	 wd 0.0000	time 0.2254 (0.2520)	loss 1.5497 (1.3560)	grad_norm 0.5112 (0.5134)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:39:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:05:01 lr 0.000030	 wd 0.0000	time 0.2347 (0.2505)	loss 1.4236 (1.3546)	grad_norm 0.4593 (0.5151)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:40:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:34 lr 0.000030	 wd 0.0000	time 0.2219 (0.2492)	loss 1.6335 (1.3552)	grad_norm 0.5009 (0.5155)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:40:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:04:10 lr 0.000030	 wd 0.0000	time 0.1989 (0.2497)	loss 1.6223 (1.3540)	grad_norm 0.5356 (0.5152)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:41:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:44 lr 0.000029	 wd 0.0000	time 0.2367 (0.2492)	loss 1.5685 (1.3536)	grad_norm 0.7735 (0.5145)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:41:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:19 lr 0.000029	 wd 0.0000	time 0.2231 (0.2483)	loss 0.8570 (1.3512)	grad_norm 0.4747 (0.5155)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:41:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:53 lr 0.000029	 wd 0.0000	time 0.2642 (0.2475)	loss 1.4172 (1.3529)	grad_norm 0.4723 (0.5165)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:42:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:29 lr 0.000029	 wd 0.0000	time 0.2567 (0.2480)	loss 1.2010 (1.3533)	grad_norm 0.7012 (0.5174)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:42:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:02:04 lr 0.000029	 wd 0.0000	time 0.2044 (0.2478)	loss 1.4283 (1.3543)	grad_norm 0.4774 (0.5166)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:43:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:39 lr 0.000029	 wd 0.0000	time 0.2239 (0.2471)	loss 1.0986 (1.3541)	grad_norm 0.4787 (0.5171)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:43:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:14 lr 0.000029	 wd 0.0000	time 0.2415 (0.2464)	loss 1.5207 (1.3555)	grad_norm 0.4835 (0.5170)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:43:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:49 lr 0.000029	 wd 0.0000	time 0.3402 (0.2468)	loss 1.3080 (1.3549)	grad_norm 0.5338 (0.5175)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:44:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:25 lr 0.000029	 wd 0.0000	time 0.2133 (0.2465)	loss 1.6658 (1.3561)	grad_norm 0.5288 (0.5187)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:44:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000029	 wd 0.0000	time 0.1914 (0.2450)	loss 1.5161 (1.3555)	grad_norm 0.4496 (0.5198)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:44:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 13 training takes 0:10:17
[2024-07-15 22:45:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 22.376 (22.376)	Loss 0.4121 (0.4121)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-15 22:45:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.182 Acc@5 97.300
[2024-07-15 22:45:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 22:45:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.25%
[2024-07-15 22:45:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][0/2502]	eta 20:16:22 lr 0.000029	 wd 0.0000	time 29.1695 (29.1695)	loss 1.4830 (1.4830)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:46:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:20:49 lr 0.000029	 wd 0.0000	time 0.1987 (0.5204)	loss 1.5286 (1.3653)	grad_norm 0.4443 (0.5108)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:46:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:14:19 lr 0.000028	 wd 0.0000	time 0.1970 (0.3735)	loss 1.3131 (1.3851)	grad_norm 0.4838 (0.5089)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:46:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:12:17 lr 0.000028	 wd 0.0000	time 0.2404 (0.3348)	loss 1.0129 (1.3726)	grad_norm 0.5381 (0.5156)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:47:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:10:56 lr 0.000028	 wd 0.0000	time 0.2286 (0.3123)	loss 1.1987 (1.3578)	grad_norm 0.4775 (0.5146)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:47:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:09:52 lr 0.000028	 wd 0.0000	time 0.2255 (0.2961)	loss 1.2755 (1.3606)	grad_norm 0.4869 (0.5163)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:48:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:09:01 lr 0.000028	 wd 0.0000	time 0.2226 (0.2848)	loss 1.6497 (1.3659)	grad_norm 0.5346 (0.5168)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:48:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:08:23 lr 0.000028	 wd 0.0000	time 0.2346 (0.2792)	loss 1.4274 (1.3619)	grad_norm 0.4886 (0.5160)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:48:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:48 lr 0.000028	 wd 0.0000	time 0.2215 (0.2752)	loss 1.3786 (1.3581)	grad_norm 0.5047 (0.5191)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 22:49:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:07:12 lr 0.000028	 wd 0.0000	time 0.2281 (0.2699)	loss 1.4242 (1.3542)	grad_norm 0.5149 (nan)	loss_scale 4096.0000 (8010.1576)	mem 7984MB
[2024-07-15 22:49:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:06:39 lr 0.000028	 wd 0.0000	time 0.2165 (0.2660)	loss 1.3088 (1.3527)	grad_norm 0.4739 (nan)	loss_scale 4096.0000 (7619.1329)	mem 7984MB
[2024-07-15 22:50:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:06:09 lr 0.000028	 wd 0.0000	time 0.2858 (0.2636)	loss 1.4772 (1.3504)	grad_norm 0.4315 (nan)	loss_scale 4096.0000 (7299.1390)	mem 7984MB
[2024-07-15 22:50:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:41 lr 0.000028	 wd 0.0000	time 0.2167 (0.2626)	loss 1.4131 (1.3506)	grad_norm 0.4558 (nan)	loss_scale 4096.0000 (7032.4330)	mem 7984MB
[2024-07-15 22:50:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:05:12 lr 0.000027	 wd 0.0000	time 0.2233 (0.2601)	loss 1.1703 (1.3508)	grad_norm 0.4835 (nan)	loss_scale 4096.0000 (6806.7271)	mem 7984MB
[2024-07-15 22:51:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:44 lr 0.000027	 wd 0.0000	time 0.2074 (0.2579)	loss 1.6417 (1.3498)	grad_norm 0.5354 (nan)	loss_scale 4096.0000 (6613.2420)	mem 7984MB
[2024-07-15 22:51:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:04:17 lr 0.000027	 wd 0.0000	time 0.2390 (0.2565)	loss 1.3693 (1.3506)	grad_norm 0.4557 (nan)	loss_scale 4096.0000 (6445.5376)	mem 7984MB
[2024-07-15 22:52:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:51 lr 0.000027	 wd 0.0000	time 0.1929 (0.2571)	loss 1.3082 (1.3504)	grad_norm 0.5449 (nan)	loss_scale 4096.0000 (6298.7833)	mem 7984MB
[2024-07-15 22:52:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:25 lr 0.000027	 wd 0.0000	time 0.2104 (0.2558)	loss 1.1757 (1.3498)	grad_norm 0.5068 (nan)	loss_scale 4096.0000 (6169.2840)	mem 7984MB
[2024-07-15 22:52:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:58 lr 0.000027	 wd 0.0000	time 0.2134 (0.2546)	loss 1.2999 (1.3496)	grad_norm 0.7020 (nan)	loss_scale 4096.0000 (6054.1655)	mem 7984MB
[2024-07-15 22:53:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:32 lr 0.000027	 wd 0.0000	time 0.2253 (0.2537)	loss 1.5288 (1.3497)	grad_norm 0.6258 (nan)	loss_scale 4096.0000 (5951.1583)	mem 7984MB
[2024-07-15 22:53:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:02:07 lr 0.000027	 wd 0.0000	time 0.2429 (0.2536)	loss 1.0569 (1.3516)	grad_norm 0.4897 (nan)	loss_scale 4096.0000 (5858.4468)	mem 7984MB
[2024-07-15 22:54:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:41 lr 0.000027	 wd 0.0000	time 0.2029 (0.2526)	loss 1.5470 (1.3513)	grad_norm 0.6956 (nan)	loss_scale 4096.0000 (5774.5607)	mem 7984MB
[2024-07-15 22:54:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:16 lr 0.000027	 wd 0.0000	time 0.2413 (0.2517)	loss 1.2174 (1.3516)	grad_norm 0.4802 (nan)	loss_scale 4096.0000 (5698.2971)	mem 7984MB
[2024-07-15 22:54:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:50 lr 0.000027	 wd 0.0000	time 0.2533 (0.2512)	loss 1.3776 (1.3524)	grad_norm 0.7784 (nan)	loss_scale 4096.0000 (5628.6623)	mem 7984MB
[2024-07-15 22:55:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:25 lr 0.000026	 wd 0.0000	time 0.2648 (0.2514)	loss 1.1210 (1.3534)	grad_norm 0.6272 (nan)	loss_scale 4096.0000 (5564.8280)	mem 7984MB
[2024-07-15 22:55:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1660 (0.2495)	loss 1.2568 (1.3526)	grad_norm 0.8072 (nan)	loss_scale 4096.0000 (5506.0984)	mem 7984MB
[2024-07-15 22:55:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 14 training takes 0:10:28
[2024-07-15 22:56:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 20.373 (20.373)	Loss 0.4116 (0.4116)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-15 22:56:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.190 Acc@5 97.286
[2024-07-15 22:56:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 22:56:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.25%
[2024-07-15 22:56:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][0/2502]	eta 21:59:14 lr 0.000026	 wd 0.0000	time 31.6364 (31.6364)	loss 1.4493 (1.4493)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:57:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:22:09 lr 0.000026	 wd 0.0000	time 0.2205 (0.5535)	loss 1.0116 (1.3387)	grad_norm 0.4621 (0.4979)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:57:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:14:59 lr 0.000026	 wd 0.0000	time 0.2296 (0.3909)	loss 1.4358 (1.3539)	grad_norm 0.5122 (0.5074)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:57:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:12:20 lr 0.000026	 wd 0.0000	time 0.2449 (0.3362)	loss 1.3927 (1.3412)	grad_norm 0.4489 (0.5076)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:58:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:11:02 lr 0.000026	 wd 0.0000	time 0.2254 (0.3154)	loss 1.3868 (1.3449)	grad_norm 0.5268 (0.5059)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:58:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:09:56 lr 0.000026	 wd 0.0000	time 0.2536 (0.2982)	loss 0.8676 (1.3428)	grad_norm 0.4568 (0.5110)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:59:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:09:05 lr 0.000026	 wd 0.0000	time 0.2182 (0.2869)	loss 0.8399 (1.3463)	grad_norm 0.4799 (0.5126)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:59:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:08:21 lr 0.000026	 wd 0.0000	time 0.2305 (0.2786)	loss 1.0987 (1.3488)	grad_norm 0.5427 (0.5138)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 22:59:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:07:48 lr 0.000026	 wd 0.0000	time 0.2785 (0.2751)	loss 1.4029 (1.3492)	grad_norm 0.4824 (0.5128)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:00:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:07:15 lr 0.000025	 wd 0.0000	time 0.2376 (0.2717)	loss 1.2194 (1.3500)	grad_norm 0.5135 (0.5154)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:00:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:06:41 lr 0.000025	 wd 0.0000	time 0.1828 (0.2675)	loss 1.4318 (1.3515)	grad_norm 0.4524 (0.5138)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:01:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:06:09 lr 0.000025	 wd 0.0000	time 0.1976 (0.2639)	loss 1.2442 (1.3487)	grad_norm 0.5192 (0.5139)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:01:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:42 lr 0.000025	 wd 0.0000	time 0.2340 (0.2627)	loss 1.3884 (1.3493)	grad_norm 0.5123 (0.5138)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:01:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:05:14 lr 0.000025	 wd 0.0000	time 0.2114 (0.2614)	loss 1.3514 (1.3477)	grad_norm 0.4822 (0.5134)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:02:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:45 lr 0.000025	 wd 0.0000	time 0.2081 (0.2590)	loss 1.4441 (1.3479)	grad_norm 0.4785 (0.5129)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:02:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:04:17 lr 0.000025	 wd 0.0000	time 0.2021 (0.2569)	loss 1.5621 (1.3476)	grad_norm 0.4824 (0.5141)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:03:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:51 lr 0.000025	 wd 0.0000	time 0.2327 (0.2562)	loss 1.2709 (1.3500)	grad_norm 0.4903 (0.5146)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:03:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:25 lr 0.000025	 wd 0.0000	time 0.2193 (0.2569)	loss 1.4239 (1.3490)	grad_norm 0.4950 (0.5146)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:03:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:59 lr 0.000025	 wd 0.0000	time 0.2438 (0.2556)	loss 1.0597 (1.3488)	grad_norm 0.5609 (0.5150)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:04:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:33 lr 0.000024	 wd 0.0000	time 0.2367 (0.2545)	loss 1.5934 (1.3493)	grad_norm 0.4589 (0.5158)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:04:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:02:07 lr 0.000024	 wd 0.0000	time 0.2286 (0.2540)	loss 1.8216 (1.3515)	grad_norm 0.4973 (0.5156)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:05:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:42 lr 0.000024	 wd 0.0000	time 0.2376 (0.2538)	loss 1.4931 (1.3522)	grad_norm 0.5459 (0.5157)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:05:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:16 lr 0.000024	 wd 0.0000	time 0.2229 (0.2529)	loss 1.0594 (1.3534)	grad_norm 0.4647 (0.5157)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:05:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:50 lr 0.000024	 wd 0.0000	time 0.2185 (0.2519)	loss 1.5754 (1.3535)	grad_norm 0.4898 (0.5157)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:06:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:25 lr 0.000024	 wd 0.0000	time 0.2378 (0.2515)	loss 1.0611 (1.3524)	grad_norm 0.6152 (0.5168)	loss_scale 8192.0000 (4167.6501)	mem 7984MB
[2024-07-15 23:06:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1721 (0.2499)	loss 1.2072 (1.3525)	grad_norm 0.5056 (0.5171)	loss_scale 8192.0000 (4328.5598)	mem 7984MB
[2024-07-15 23:06:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 15 training takes 0:10:30
[2024-07-15 23:06:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft/ckpt_epoch_15.pth saving......
[2024-07-15 23:06:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft/ckpt_epoch_15.pth saved !!!
[2024-07-15 23:07:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 17.793 (17.793)	Loss 0.4121 (0.4121)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-15 23:07:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.170 Acc@5 97.274
[2024-07-15 23:07:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 23:07:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.25%
[2024-07-15 23:07:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][0/2502]	eta 11:27:31 lr 0.000024	 wd 0.0000	time 16.4872 (16.4872)	loss 1.2761 (1.2761)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 23:08:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:16:37 lr 0.000024	 wd 0.0000	time 0.2145 (0.4154)	loss 1.4670 (1.3468)	grad_norm 0.4821 (0.5274)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 23:08:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:12:35 lr 0.000024	 wd 0.0000	time 0.2095 (0.3280)	loss 1.3073 (1.3557)	grad_norm 0.6189 (0.5254)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 23:08:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:10:48 lr 0.000024	 wd 0.0000	time 0.2243 (0.2945)	loss 1.3509 (1.3677)	grad_norm 0.4434 (0.5249)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 23:09:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:09:42 lr 0.000024	 wd 0.0000	time 0.2044 (0.2773)	loss 1.2672 (1.3617)	grad_norm 0.5362 (0.5226)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 23:09:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:09:02 lr 0.000023	 wd 0.0000	time 0.2556 (0.2708)	loss 1.2471 (1.3718)	grad_norm 0.5172 (0.5233)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 23:10:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:24 lr 0.000023	 wd 0.0000	time 0.2120 (0.2652)	loss 1.0390 (1.3641)	grad_norm 0.5331 (0.5244)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 23:10:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:48 lr 0.000023	 wd 0.0000	time 0.2457 (0.2598)	loss 1.3214 (1.3659)	grad_norm 0.5017 (0.5237)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 23:10:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:07:15 lr 0.000023	 wd 0.0000	time 0.2027 (0.2560)	loss 1.3876 (1.3604)	grad_norm 0.4654 (0.5275)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-15 23:11:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:47 lr 0.000023	 wd 0.0000	time 0.2545 (0.2546)	loss 1.5529 (1.3583)	grad_norm 0.4776 (inf)	loss_scale 4096.0000 (7937.4206)	mem 7984MB
[2024-07-15 23:11:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:06:22 lr 0.000023	 wd 0.0000	time 0.2172 (0.2546)	loss 1.5441 (1.3586)	grad_norm 0.5695 (inf)	loss_scale 4096.0000 (7553.6623)	mem 7984MB
[2024-07-15 23:11:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:54 lr 0.000023	 wd 0.0000	time 0.1886 (0.2526)	loss 1.3167 (1.3596)	grad_norm 0.5167 (inf)	loss_scale 4096.0000 (7239.6149)	mem 7984MB
[2024-07-15 23:12:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:26 lr 0.000023	 wd 0.0000	time 0.2037 (0.2508)	loss 1.3945 (1.3609)	grad_norm 0.5112 (inf)	loss_scale 4096.0000 (6977.8651)	mem 7984MB
[2024-07-15 23:12:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:05:00 lr 0.000023	 wd 0.0000	time 0.2293 (0.2499)	loss 1.0938 (1.3613)	grad_norm 0.4932 (inf)	loss_scale 4096.0000 (6756.3536)	mem 7984MB
[2024-07-15 23:13:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:35 lr 0.000023	 wd 0.0000	time 0.2374 (0.2504)	loss 1.2007 (1.3586)	grad_norm 0.5056 (inf)	loss_scale 4096.0000 (6566.4640)	mem 7984MB
[2024-07-15 23:13:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:04:09 lr 0.000022	 wd 0.0000	time 0.2301 (0.2491)	loss 1.4001 (1.3556)	grad_norm 0.5020 (inf)	loss_scale 4096.0000 (6401.8761)	mem 7984MB
[2024-07-15 23:13:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:43 lr 0.000022	 wd 0.0000	time 0.2414 (0.2480)	loss 1.3805 (1.3559)	grad_norm 0.5941 (inf)	loss_scale 4096.0000 (6257.8488)	mem 7984MB
[2024-07-15 23:14:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:18 lr 0.000022	 wd 0.0000	time 0.2051 (0.2475)	loss 1.1077 (1.3540)	grad_norm 0.5129 (inf)	loss_scale 4096.0000 (6130.7560)	mem 7984MB
[2024-07-15 23:14:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:54 lr 0.000022	 wd 0.0000	time 0.2572 (0.2483)	loss 1.2474 (1.3523)	grad_norm 0.4886 (inf)	loss_scale 4096.0000 (6017.7768)	mem 7984MB
[2024-07-15 23:15:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:28 lr 0.000022	 wd 0.0000	time 0.2241 (0.2475)	loss 1.1941 (1.3512)	grad_norm 0.4960 (inf)	loss_scale 4096.0000 (5916.6839)	mem 7984MB
[2024-07-15 23:15:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:02:03 lr 0.000022	 wd 0.0000	time 0.2137 (0.2467)	loss 1.4648 (1.3514)	grad_norm 0.4876 (inf)	loss_scale 4096.0000 (5825.6952)	mem 7984MB
[2024-07-15 23:15:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:39 lr 0.000022	 wd 0.0000	time 0.2429 (0.2463)	loss 1.3466 (1.3509)	grad_norm 0.5304 (inf)	loss_scale 4096.0000 (5743.3679)	mem 7984MB
[2024-07-15 23:16:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:14 lr 0.000022	 wd 0.0000	time 0.2725 (0.2464)	loss 1.4661 (1.3516)	grad_norm 0.4885 (inf)	loss_scale 4096.0000 (5668.5216)	mem 7984MB
[2024-07-15 23:16:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:49 lr 0.000022	 wd 0.0000	time 0.2056 (0.2458)	loss 1.2132 (1.3517)	grad_norm 0.5519 (inf)	loss_scale 4096.0000 (5600.1808)	mem 7984MB
[2024-07-15 23:17:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:25 lr 0.000022	 wd 0.0000	time 0.2427 (0.2453)	loss 1.5343 (1.3518)	grad_norm 0.5635 (inf)	loss_scale 4096.0000 (5537.5327)	mem 7984MB
[2024-07-15 23:17:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1782 (0.2436)	loss 1.3603 (1.3518)	grad_norm 0.4938 (inf)	loss_scale 4096.0000 (5479.8944)	mem 7984MB
[2024-07-15 23:17:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 16 training takes 0:10:13
[2024-07-15 23:18:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 84.485 (84.485)	Loss 0.4119 (0.4119)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-15 23:19:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.228 Acc@5 97.280
[2024-07-15 23:19:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 23:19:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.25%
[2024-07-15 23:19:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][0/2502]	eta 1 day, 6:00:03 lr 0.000021	 wd 0.0000	time 43.1668 (43.1668)	loss 1.4454 (1.4454)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:20:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:26:18 lr 0.000021	 wd 0.0000	time 0.2088 (0.6570)	loss 1.5553 (1.3255)	grad_norm 0.5186 (0.5056)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:20:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:16:58 lr 0.000021	 wd 0.0000	time 0.2491 (0.4425)	loss 1.5830 (1.3410)	grad_norm 0.6509 (0.5410)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:21:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:13:57 lr 0.000021	 wd 0.0000	time 0.2170 (0.3803)	loss 1.3239 (1.3374)	grad_norm 0.4819 (0.5413)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:21:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:12:01 lr 0.000021	 wd 0.0000	time 0.2013 (0.3431)	loss 1.1150 (1.3317)	grad_norm 0.4678 (0.5340)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:21:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:10:39 lr 0.000021	 wd 0.0000	time 0.2195 (0.3196)	loss 1.3597 (1.3316)	grad_norm 0.5270 (0.5323)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:22:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:09:39 lr 0.000021	 wd 0.0000	time 0.2441 (0.3048)	loss 1.1804 (1.3385)	grad_norm 0.4881 (0.5350)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:22:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:08:55 lr 0.000021	 wd 0.0000	time 0.2804 (0.2972)	loss 1.3255 (1.3442)	grad_norm 1.0105 (0.5399)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:23:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:08:13 lr 0.000021	 wd 0.0000	time 0.1899 (0.2899)	loss 1.3601 (1.3479)	grad_norm 0.4883 (0.5379)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:23:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:07:33 lr 0.000021	 wd 0.0000	time 0.2045 (0.2832)	loss 1.5912 (1.3494)	grad_norm 0.4770 (0.5355)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:23:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:56 lr 0.000020	 wd 0.0000	time 0.1994 (0.2776)	loss 1.5229 (1.3479)	grad_norm 0.4840 (0.5332)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:24:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:06:24 lr 0.000020	 wd 0.0000	time 0.2223 (0.2746)	loss 1.1037 (1.3484)	grad_norm 0.4569 (0.5312)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:24:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:54 lr 0.000020	 wd 0.0000	time 0.2270 (0.2726)	loss 1.5745 (1.3502)	grad_norm 0.5352 (0.5307)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:25:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:05:23 lr 0.000020	 wd 0.0000	time 0.2329 (0.2694)	loss 1.1591 (1.3502)	grad_norm 0.5131 (0.5308)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:25:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:53 lr 0.000020	 wd 0.0000	time 0.2102 (0.2665)	loss 1.4833 (1.3510)	grad_norm 0.4759 (0.5307)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:25:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:04:25 lr 0.000020	 wd 0.0000	time 0.2127 (0.2648)	loss 1.3983 (1.3518)	grad_norm 0.5794 (0.5310)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:26:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:58 lr 0.000020	 wd 0.0000	time 0.2542 (0.2640)	loss 1.5444 (1.3531)	grad_norm 0.4434 (0.5335)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:26:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:30 lr 0.000020	 wd 0.0000	time 0.2386 (0.2620)	loss 1.5708 (1.3551)	grad_norm 0.4859 (0.5331)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:27:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:03:02 lr 0.000020	 wd 0.0000	time 0.2088 (0.2606)	loss 1.2890 (1.3558)	grad_norm 0.4813 (0.5320)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:27:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:36 lr 0.000020	 wd 0.0000	time 0.2274 (0.2597)	loss 1.1505 (1.3566)	grad_norm 0.5156 (0.5346)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:27:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:02:10 lr 0.000019	 wd 0.0000	time 0.2301 (0.2598)	loss 1.5480 (1.3545)	grad_norm 0.4973 (0.5328)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:28:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:43 lr 0.000019	 wd 0.0000	time 0.2166 (0.2584)	loss 1.4289 (1.3542)	grad_norm 0.6507 (0.5324)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:28:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:17 lr 0.000019	 wd 0.0000	time 0.2526 (0.2571)	loss 1.3366 (1.3554)	grad_norm 0.4727 (0.5325)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-15 23:29:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:51 lr 0.000019	 wd 0.0000	time 0.2234 (0.2565)	loss 1.4507 (1.3547)	grad_norm 0.4857 (inf)	loss_scale 2048.0000 (4042.5971)	mem 7984MB
[2024-07-15 23:29:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:26 lr 0.000019	 wd 0.0000	time 0.2332 (0.2561)	loss 1.4473 (1.3534)	grad_norm 0.4593 (inf)	loss_scale 2048.0000 (3959.5235)	mem 7984MB
[2024-07-15 23:29:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000019	 wd 0.0000	time 0.1769 (0.2538)	loss 1.4867 (1.3539)	grad_norm 0.7545 (inf)	loss_scale 2048.0000 (3883.0932)	mem 7984MB
[2024-07-15 23:29:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 17 training takes 0:10:39
[2024-07-15 23:30:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 21.528 (21.528)	Loss 0.4116 (0.4116)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-15 23:30:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.230 Acc@5 97.266
[2024-07-15 23:30:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 23:30:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.25%
[2024-07-15 23:31:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][0/2502]	eta 23:40:13 lr 0.000019	 wd 0.0000	time 34.0580 (34.0580)	loss 1.6018 (1.6018)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:31:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:22:30 lr 0.000019	 wd 0.0000	time 0.1997 (0.5622)	loss 1.5467 (1.3937)	grad_norm 0.4805 (0.5193)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:31:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:15:08 lr 0.000019	 wd 0.0000	time 0.2171 (0.3948)	loss 1.4675 (1.3746)	grad_norm 0.4681 (0.5754)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:32:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:12:33 lr 0.000019	 wd 0.0000	time 0.2707 (0.3422)	loss 1.7021 (1.3739)	grad_norm 0.4613 (0.5641)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:32:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:11:12 lr 0.000019	 wd 0.0000	time 0.2138 (0.3200)	loss 1.4391 (1.3670)	grad_norm 0.5378 (0.5549)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:32:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:10:03 lr 0.000018	 wd 0.0000	time 0.2167 (0.3013)	loss 1.3086 (1.3565)	grad_norm 0.4822 (0.5485)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:33:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:09:09 lr 0.000018	 wd 0.0000	time 0.2229 (0.2891)	loss 1.6249 (1.3572)	grad_norm 0.4244 (0.5430)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:33:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:08:26 lr 0.000018	 wd 0.0000	time 0.2347 (0.2811)	loss 1.4281 (1.3575)	grad_norm 0.4240 (0.5395)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:34:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:54 lr 0.000018	 wd 0.0000	time 0.2480 (0.2785)	loss 1.0875 (1.3550)	grad_norm 0.5025 (0.5394)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:34:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:07:17 lr 0.000018	 wd 0.0000	time 0.1983 (0.2734)	loss 1.1686 (1.3513)	grad_norm 0.5944 (0.5387)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:34:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:43 lr 0.000018	 wd 0.0000	time 0.2239 (0.2689)	loss 1.0307 (1.3548)	grad_norm 0.4680 (0.5386)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:35:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:06:12 lr 0.000018	 wd 0.0000	time 0.2172 (0.2654)	loss 1.2408 (1.3544)	grad_norm 0.4640 (0.5362)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:35:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:45 lr 0.000018	 wd 0.0000	time 0.2029 (0.2651)	loss 1.6477 (1.3547)	grad_norm 0.5149 (0.5363)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:36:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:05:15 lr 0.000018	 wd 0.0000	time 0.2099 (0.2628)	loss 1.3962 (1.3553)	grad_norm 0.4791 (0.5342)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:36:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:47 lr 0.000018	 wd 0.0000	time 0.2286 (0.2606)	loss 1.2125 (1.3551)	grad_norm 0.4612 (0.5346)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:36:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:04:19 lr 0.000017	 wd 0.0000	time 0.2530 (0.2586)	loss 1.5834 (1.3543)	grad_norm 0.4773 (0.5346)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:37:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:52 lr 0.000017	 wd 0.0000	time 0.2288 (0.2583)	loss 1.4759 (1.3537)	grad_norm 0.5071 (0.5336)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:37:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:26 lr 0.000017	 wd 0.0000	time 0.2068 (0.2576)	loss 1.4724 (1.3540)	grad_norm 0.5596 (0.5333)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:38:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:59 lr 0.000017	 wd 0.0000	time 0.2334 (0.2563)	loss 1.3122 (1.3548)	grad_norm 0.4624 (0.5324)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:38:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:33 lr 0.000017	 wd 0.0000	time 0.2267 (0.2550)	loss 1.4603 (1.3540)	grad_norm 0.5052 (0.5323)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:38:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:02:08 lr 0.000017	 wd 0.0000	time 0.2152 (0.2550)	loss 1.3744 (1.3561)	grad_norm 0.4613 (0.5322)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:39:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:42 lr 0.000017	 wd 0.0000	time 0.1974 (0.2545)	loss 1.4449 (1.3554)	grad_norm 1.6789 (0.5332)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:39:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:16 lr 0.000017	 wd 0.0000	time 0.2302 (0.2536)	loss 1.3335 (1.3555)	grad_norm 0.4422 (0.5337)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:40:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:51 lr 0.000017	 wd 0.0000	time 0.2247 (0.2527)	loss 1.4950 (1.3558)	grad_norm 0.5326 (0.5329)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:40:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:25 lr 0.000017	 wd 0.0000	time 0.3482 (0.2525)	loss 1.4970 (1.3572)	grad_norm 0.4895 (0.5327)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:40:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1860 (0.2508)	loss 1.4883 (1.3567)	grad_norm 0.5692 (0.5322)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:41:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 18 training takes 0:10:33
[2024-07-15 23:41:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 19.486 (19.486)	Loss 0.4121 (0.4121)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-15 23:41:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.252 Acc@5 97.268
[2024-07-15 23:41:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-15 23:41:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.25%
[2024-07-15 23:41:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][0/2502]	eta 11:13:55 lr 0.000016	 wd 0.0000	time 16.1613 (16.1613)	loss 1.4248 (1.4248)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:42:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:18:20 lr 0.000016	 wd 0.0000	time 0.2282 (0.4582)	loss 1.0928 (1.3689)	grad_norm 0.5971 (0.5186)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:42:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:13:09 lr 0.000016	 wd 0.0000	time 0.2243 (0.3430)	loss 1.4317 (1.3624)	grad_norm 0.5203 (0.5170)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:43:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:11:09 lr 0.000016	 wd 0.0000	time 0.2283 (0.3042)	loss 1.3068 (1.3747)	grad_norm 0.4928 (0.5174)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:43:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:09:59 lr 0.000016	 wd 0.0000	time 0.2229 (0.2853)	loss 1.5040 (1.3742)	grad_norm 0.7267 (0.5266)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:43:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:09:19 lr 0.000016	 wd 0.0000	time 0.3937 (0.2795)	loss 1.4986 (1.3693)	grad_norm 0.5222 (0.5262)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:44:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:36 lr 0.000016	 wd 0.0000	time 0.2085 (0.2717)	loss 1.4703 (1.3644)	grad_norm 0.4650 (0.5292)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:44:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:07:59 lr 0.000016	 wd 0.0000	time 0.2396 (0.2659)	loss 1.6258 (1.3662)	grad_norm 0.5252 (0.5292)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:45:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:07:24 lr 0.000016	 wd 0.0000	time 0.2294 (0.2610)	loss 1.3567 (1.3650)	grad_norm 0.7478 (0.5300)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:45:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:06:57 lr 0.000016	 wd 0.0000	time 0.2234 (0.2606)	loss 1.2295 (1.3645)	grad_norm 0.4367 (0.5313)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:45:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:28 lr 0.000016	 wd 0.0000	time 0.2116 (0.2586)	loss 1.5767 (1.3653)	grad_norm 0.6034 (0.5344)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:46:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:58 lr 0.000015	 wd 0.0000	time 0.2094 (0.2560)	loss 0.9151 (1.3638)	grad_norm 0.5384 (0.5353)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:46:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:30 lr 0.000015	 wd 0.0000	time 0.2502 (0.2537)	loss 1.1161 (1.3621)	grad_norm 0.5043 (0.5333)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:47:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:05:04 lr 0.000015	 wd 0.0000	time 0.2235 (0.2532)	loss 1.5711 (1.3626)	grad_norm 0.4964 (0.5338)	loss_scale 4096.0000 (2148.7471)	mem 7984MB
[2024-07-15 23:47:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:38 lr 0.000015	 wd 0.0000	time 0.2194 (0.2527)	loss 1.4466 (1.3635)	grad_norm 0.4885 (0.5329)	loss_scale 4096.0000 (2287.7373)	mem 7984MB
[2024-07-15 23:47:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:04:11 lr 0.000015	 wd 0.0000	time 0.2228 (0.2514)	loss 1.2074 (1.3632)	grad_norm 0.4510 (0.5345)	loss_scale 4096.0000 (2408.2079)	mem 7984MB
[2024-07-15 23:48:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:45 lr 0.000015	 wd 0.0000	time 0.2358 (0.2501)	loss 1.2946 (1.3635)	grad_norm 0.5337 (0.5336)	loss_scale 4096.0000 (2513.6290)	mem 7984MB
[2024-07-15 23:48:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:20 lr 0.000015	 wd 0.0000	time 0.2258 (0.2500)	loss 1.3935 (1.3642)	grad_norm 0.4784 (0.5325)	loss_scale 4096.0000 (2606.6549)	mem 7984MB
[2024-07-15 23:49:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:56 lr 0.000015	 wd 0.0000	time 0.2090 (0.2512)	loss 1.3261 (1.3637)	grad_norm 0.4937 (0.5316)	loss_scale 4096.0000 (2689.3504)	mem 7984MB
[2024-07-15 23:49:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:30 lr 0.000015	 wd 0.0000	time 0.2148 (0.2502)	loss 1.4097 (1.3640)	grad_norm 0.4761 (0.5310)	loss_scale 4096.0000 (2763.3456)	mem 7984MB
[2024-07-15 23:49:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:02:05 lr 0.000015	 wd 0.0000	time 0.2158 (0.2492)	loss 1.0553 (1.3635)	grad_norm 0.5637 (0.5296)	loss_scale 4096.0000 (2829.9450)	mem 7984MB
[2024-07-15 23:50:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:40 lr 0.000014	 wd 0.0000	time 0.2236 (0.2491)	loss 1.1765 (1.3624)	grad_norm 0.4751 (0.5294)	loss_scale 4096.0000 (2890.2047)	mem 7984MB
[2024-07-15 23:50:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:15 lr 0.000014	 wd 0.0000	time 0.2779 (0.2492)	loss 1.4833 (1.3603)	grad_norm 0.5767 (0.5285)	loss_scale 4096.0000 (2944.9886)	mem 7984MB
[2024-07-15 23:51:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:50 lr 0.000014	 wd 0.0000	time 0.2427 (0.2485)	loss 1.3956 (1.3600)	grad_norm 0.5670 (0.5285)	loss_scale 4096.0000 (2995.0109)	mem 7984MB
[2024-07-15 23:51:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:25 lr 0.000014	 wd 0.0000	time 0.2318 (0.2478)	loss 1.5363 (1.3614)	grad_norm 0.5278 (nan)	loss_scale 2048.0000 (2982.8638)	mem 7984MB
[2024-07-15 23:51:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1780 (0.2463)	loss 1.2220 (1.3612)	grad_norm 0.5033 (nan)	loss_scale 2048.0000 (2945.4842)	mem 7984MB
[2024-07-15 23:51:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 19 training takes 0:10:20
[2024-07-15 23:52:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 34.222 (34.222)	Loss 0.4121 (0.4121)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-15 23:52:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.218 Acc@5 97.276
[2024-07-15 23:52:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 23:52:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.25%
[2024-07-15 23:52:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][0/2502]	eta 11:34:35 lr 0.000014	 wd 0.0000	time 16.6568 (16.6568)	loss 0.9853 (0.9853)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:53:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:16:21 lr 0.000014	 wd 0.0000	time 0.2433 (0.4085)	loss 1.5670 (1.3567)	grad_norm 0.5734 (0.5153)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:53:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:12:41 lr 0.000014	 wd 0.0000	time 0.2288 (0.3308)	loss 1.4179 (1.3580)	grad_norm 0.5182 (0.5194)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:54:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:10:52 lr 0.000014	 wd 0.0000	time 0.1848 (0.2964)	loss 1.4691 (1.3541)	grad_norm 0.4985 (0.5263)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:54:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:09:45 lr 0.000014	 wd 0.0000	time 0.2071 (0.2786)	loss 1.3960 (1.3634)	grad_norm 0.4736 (0.5274)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:54:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:08:59 lr 0.000014	 wd 0.0000	time 0.2338 (0.2697)	loss 1.5326 (1.3656)	grad_norm 0.5428 (0.5297)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:55:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:08:28 lr 0.000014	 wd 0.0000	time 0.2034 (0.2672)	loss 1.3289 (1.3622)	grad_norm 0.4753 (0.5330)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:55:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:52 lr 0.000013	 wd 0.0000	time 0.2036 (0.2622)	loss 1.4737 (1.3645)	grad_norm 0.4704 (0.5322)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:56:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:07:19 lr 0.000013	 wd 0.0000	time 0.2178 (0.2580)	loss 1.2621 (1.3616)	grad_norm 0.4769 (0.5319)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:56:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:49 lr 0.000013	 wd 0.0000	time 0.2189 (0.2556)	loss 1.5935 (1.3644)	grad_norm 0.4644 (0.5325)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:56:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:24 lr 0.000013	 wd 0.0000	time 0.2250 (0.2557)	loss 1.2855 (1.3635)	grad_norm 0.4480 (0.5343)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:57:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:55 lr 0.000013	 wd 0.0000	time 0.2225 (0.2536)	loss 1.3466 (1.3611)	grad_norm 0.6449 (0.5325)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:57:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:27 lr 0.000013	 wd 0.0000	time 0.2104 (0.2519)	loss 1.4129 (1.3580)	grad_norm 0.4670 (0.5306)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:58:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:05:01 lr 0.000013	 wd 0.0000	time 0.2463 (0.2506)	loss 1.3049 (1.3567)	grad_norm 0.5275 (0.5330)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:58:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:36 lr 0.000013	 wd 0.0000	time 0.2783 (0.2509)	loss 1.3896 (1.3584)	grad_norm 0.4704 (0.5327)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:58:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:04:10 lr 0.000013	 wd 0.0000	time 0.2324 (0.2498)	loss 1.4351 (1.3590)	grad_norm 0.5018 (0.5345)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:59:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:44 lr 0.000013	 wd 0.0000	time 0.2385 (0.2488)	loss 1.6746 (1.3593)	grad_norm 0.5128 (0.5345)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-15 23:59:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:18 lr 0.000012	 wd 0.0000	time 0.2415 (0.2478)	loss 1.5203 (1.3586)	grad_norm 0.5418 (0.5359)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:00:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:54 lr 0.000012	 wd 0.0000	time 0.1880 (0.2486)	loss 1.3038 (1.3579)	grad_norm 0.4856 (0.5351)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:00:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:29 lr 0.000012	 wd 0.0000	time 0.2268 (0.2481)	loss 1.5276 (1.3599)	grad_norm 0.4719 (0.5355)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:00:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:02:04 lr 0.000012	 wd 0.0000	time 0.2211 (0.2474)	loss 1.4912 (1.3594)	grad_norm 0.4757 (0.5343)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:01:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:39 lr 0.000012	 wd 0.0000	time 0.2330 (0.2468)	loss 1.2970 (1.3600)	grad_norm 0.4493 (0.5327)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:01:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:14 lr 0.000012	 wd 0.0000	time 0.2314 (0.2473)	loss 1.2465 (1.3616)	grad_norm 0.5142 (0.5318)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:02:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:49 lr 0.000012	 wd 0.0000	time 0.2151 (0.2468)	loss 1.3907 (1.3616)	grad_norm 0.8585 (0.5331)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:02:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:25 lr 0.000012	 wd 0.0000	time 0.1860 (0.2462)	loss 1.3570 (1.3619)	grad_norm 0.4658 (0.5317)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:02:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000012	 wd 0.0000	time 0.1997 (0.2445)	loss 1.6072 (1.3626)	grad_norm 0.5974 (0.5307)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:02:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 20 training takes 0:10:16
[2024-07-16 00:03:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 35.179 (35.179)	Loss 0.4138 (0.4138)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-16 00:03:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.210 Acc@5 97.296
[2024-07-16 00:03:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-16 00:03:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.25%
[2024-07-16 00:04:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][0/2502]	eta 11:53:26 lr 0.000012	 wd 0.0000	time 17.1090 (17.1090)	loss 1.5565 (1.5565)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:04:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:15:34 lr 0.000012	 wd 0.0000	time 0.1960 (0.3891)	loss 1.4492 (1.3817)	grad_norm 0.6022 (0.5600)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:04:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:13:51 lr 0.000012	 wd 0.0000	time 0.2683 (0.3614)	loss 0.8898 (1.3632)	grad_norm 0.5198 (0.5473)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:05:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:11:41 lr 0.000012	 wd 0.0000	time 0.2129 (0.3185)	loss 1.4003 (1.3563)	grad_norm 0.5231 (0.5349)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:05:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:10:20 lr 0.000011	 wd 0.0000	time 0.2355 (0.2954)	loss 1.4360 (1.3574)	grad_norm 0.4941 (0.5297)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:06:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:09:23 lr 0.000011	 wd 0.0000	time 0.2382 (0.2813)	loss 1.3508 (1.3567)	grad_norm 0.5701 (0.5296)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:06:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:46 lr 0.000011	 wd 0.0000	time 0.3425 (0.2770)	loss 1.1908 (1.3573)	grad_norm 0.4998 (0.5317)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:06:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:08:08 lr 0.000011	 wd 0.0000	time 0.2254 (0.2713)	loss 1.2768 (1.3519)	grad_norm 0.4633 (0.5298)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:07:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:32 lr 0.000011	 wd 0.0000	time 0.1995 (0.2661)	loss 1.2209 (1.3514)	grad_norm 0.4573 (0.5292)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:07:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:59 lr 0.000011	 wd 0.0000	time 0.2264 (0.2620)	loss 1.5256 (1.3521)	grad_norm 0.5297 (0.5280)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:08:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:31 lr 0.000011	 wd 0.0000	time 0.2194 (0.2607)	loss 1.0456 (1.3511)	grad_norm 0.4646 (0.5255)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:08:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:06:03 lr 0.000011	 wd 0.0000	time 0.2373 (0.2595)	loss 1.4584 (1.3512)	grad_norm 0.4831 (0.5282)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:08:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:34 lr 0.000011	 wd 0.0000	time 0.1999 (0.2570)	loss 1.3208 (1.3522)	grad_norm 0.4834 (0.5267)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:09:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:05:06 lr 0.000011	 wd 0.0000	time 0.2237 (0.2552)	loss 1.5071 (1.3524)	grad_norm 0.4597 (0.5258)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:09:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:40 lr 0.000011	 wd 0.0000	time 0.2497 (0.2546)	loss 1.4270 (1.3528)	grad_norm 0.5213 (0.5277)	loss_scale 4096.0000 (2153.2505)	mem 7984MB
[2024-07-16 00:10:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:04:15 lr 0.000010	 wd 0.0000	time 0.2403 (0.2548)	loss 1.6433 (1.3525)	grad_norm 0.5289 (0.5273)	loss_scale 4096.0000 (2282.6809)	mem 7984MB
[2024-07-16 00:10:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:48 lr 0.000010	 wd 0.0000	time 0.2017 (0.2534)	loss 1.2117 (1.3519)	grad_norm 0.5217 (0.5286)	loss_scale 4096.0000 (2395.9425)	mem 7984MB
[2024-07-16 00:10:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:22 lr 0.000010	 wd 0.0000	time 0.2365 (0.2520)	loss 1.4815 (1.3520)	grad_norm 0.5343 (0.5287)	loss_scale 4096.0000 (2495.8871)	mem 7984MB
[2024-07-16 00:11:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:56 lr 0.000010	 wd 0.0000	time 0.2296 (0.2518)	loss 1.0238 (1.3525)	grad_norm 0.5421 (0.5280)	loss_scale 4096.0000 (2584.7329)	mem 7984MB
[2024-07-16 00:11:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:31 lr 0.000010	 wd 0.0000	time 0.2626 (0.2522)	loss 0.9972 (1.3511)	grad_norm 0.5234 (0.5293)	loss_scale 4096.0000 (2664.2315)	mem 7984MB
[2024-07-16 00:12:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:02:06 lr 0.000010	 wd 0.0000	time 0.2417 (0.2513)	loss 1.3872 (1.3506)	grad_norm 0.5448 (0.5299)	loss_scale 4096.0000 (2735.7841)	mem 7984MB
[2024-07-16 00:12:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:40 lr 0.000010	 wd 0.0000	time 0.2288 (0.2503)	loss 1.1866 (1.3509)	grad_norm 0.5525 (0.5307)	loss_scale 4096.0000 (2800.5255)	mem 7984MB
[2024-07-16 00:12:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:15 lr 0.000010	 wd 0.0000	time 0.2359 (0.2500)	loss 1.5627 (1.3489)	grad_norm 0.4435 (0.5302)	loss_scale 4096.0000 (2859.3839)	mem 7984MB
[2024-07-16 00:13:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:50 lr 0.000010	 wd 0.0000	time 0.2554 (0.2508)	loss 1.5626 (1.3486)	grad_norm 0.5283 (0.5301)	loss_scale 4096.0000 (2913.1265)	mem 7984MB
[2024-07-16 00:13:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:25 lr 0.000010	 wd 0.0000	time 0.2138 (0.2501)	loss 1.3760 (1.3500)	grad_norm 0.4945 (0.5293)	loss_scale 4096.0000 (2962.3923)	mem 7984MB
[2024-07-16 00:14:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1734 (0.2481)	loss 1.3100 (1.3497)	grad_norm 0.5121 (0.5288)	loss_scale 4096.0000 (3007.7185)	mem 7984MB
[2024-07-16 00:14:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 21 training takes 0:10:25
[2024-07-16 00:14:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 36.935 (36.935)	Loss 0.4116 (0.4116)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-16 00:14:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.238 Acc@5 97.274
[2024-07-16 00:14:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-16 00:14:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.25%
[2024-07-16 00:15:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][0/2502]	eta 10:52:48 lr 0.000010	 wd 0.0000	time 15.6550 (15.6550)	loss 1.3098 (1.3098)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:15:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:15:35 lr 0.000010	 wd 0.0000	time 0.2172 (0.3895)	loss 1.2574 (1.3602)	grad_norm 0.4710 (0.5078)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:16:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:12:11 lr 0.000009	 wd 0.0000	time 0.2431 (0.3179)	loss 1.1726 (1.3566)	grad_norm 0.4660 (0.5717)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:16:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:10:51 lr 0.000009	 wd 0.0000	time 0.2317 (0.2960)	loss 1.5060 (1.3608)	grad_norm 0.4965 (0.5581)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:16:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:09:47 lr 0.000009	 wd 0.0000	time 0.2085 (0.2793)	loss 1.4262 (1.3645)	grad_norm 0.6432 (0.5555)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:17:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:08:57 lr 0.000009	 wd 0.0000	time 0.2143 (0.2686)	loss 0.8915 (1.3639)	grad_norm 0.5419 (0.5525)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:17:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:21 lr 0.000009	 wd 0.0000	time 0.2255 (0.2635)	loss 1.3639 (1.3669)	grad_norm 0.5295 (0.5498)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:18:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:54 lr 0.000009	 wd 0.0000	time 0.2022 (0.2630)	loss 0.8957 (1.3624)	grad_norm 0.5638 (0.5446)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:18:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:07:21 lr 0.000009	 wd 0.0000	time 0.2277 (0.2592)	loss 1.3647 (1.3584)	grad_norm 0.6212 (0.5406)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:18:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:49 lr 0.000009	 wd 0.0000	time 0.2552 (0.2559)	loss 1.3405 (1.3575)	grad_norm 0.4765 (0.5384)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:19:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:21 lr 0.000009	 wd 0.0000	time 0.2525 (0.2540)	loss 1.5465 (1.3597)	grad_norm 0.5116 (0.5387)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:19:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:56 lr 0.000009	 wd 0.0000	time 0.2933 (0.2543)	loss 1.4073 (1.3571)	grad_norm 0.4823 (0.5370)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:20:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:28 lr 0.000009	 wd 0.0000	time 0.2590 (0.2523)	loss 1.3431 (1.3560)	grad_norm 0.4776 (0.5364)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:20:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:05:01 lr 0.000009	 wd 0.0000	time 0.2202 (0.2506)	loss 0.9372 (1.3566)	grad_norm 0.5068 (0.5344)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:20:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:34 lr 0.000008	 wd 0.0000	time 0.2439 (0.2495)	loss 1.5636 (1.3586)	grad_norm 0.5510 (0.5355)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:21:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:04:10 lr 0.000008	 wd 0.0000	time 0.2107 (0.2497)	loss 1.3178 (1.3593)	grad_norm 0.4971 (0.5348)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:21:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:44 lr 0.000008	 wd 0.0000	time 0.2423 (0.2488)	loss 1.5409 (1.3596)	grad_norm 0.5091 (0.5359)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:22:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:18 lr 0.000008	 wd 0.0000	time 0.2142 (0.2478)	loss 1.3056 (1.3593)	grad_norm 0.6141 (0.5352)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:22:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:53 lr 0.000008	 wd 0.0000	time 0.2512 (0.2471)	loss 1.5846 (1.3587)	grad_norm 0.5357 (0.5338)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:22:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:29 lr 0.000008	 wd 0.0000	time 0.3358 (0.2479)	loss 1.5368 (1.3581)	grad_norm 0.7448 (0.5328)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:23:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:02:04 lr 0.000008	 wd 0.0000	time 0.1939 (0.2476)	loss 1.5109 (1.3572)	grad_norm 0.4411 (0.5324)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:23:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:39 lr 0.000008	 wd 0.0000	time 0.2084 (0.2470)	loss 1.4301 (1.3578)	grad_norm 0.5019 (0.5317)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:24:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:14 lr 0.000008	 wd 0.0000	time 0.2659 (0.2464)	loss 1.4303 (1.3560)	grad_norm 0.4951 (0.5306)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:24:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:49 lr 0.000008	 wd 0.0000	time 0.2682 (0.2468)	loss 1.4946 (1.3561)	grad_norm 0.4851 (0.5309)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:24:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:25 lr 0.000008	 wd 0.0000	time 0.2301 (0.2465)	loss 1.2025 (1.3554)	grad_norm 0.5420 (0.5303)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:25:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1746 (0.2449)	loss 0.9886 (1.3545)	grad_norm 0.5167 (0.5295)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:25:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 22 training takes 0:10:17
[2024-07-16 00:25:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 27.561 (27.561)	Loss 0.4128 (0.4128)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-16 00:26:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.270 Acc@5 97.276
[2024-07-16 00:26:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-16 00:26:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.27%
[2024-07-16 00:26:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft/ckpt_epoch_best.pth saving......
[2024-07-16 00:26:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft/ckpt_epoch_best.pth saved !!!
[2024-07-16 00:26:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][0/2502]	eta 11:15:50 lr 0.000008	 wd 0.0000	time 16.2071 (16.2071)	loss 1.1595 (1.1595)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:26:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:15:48 lr 0.000008	 wd 0.0000	time 0.2066 (0.3947)	loss 1.5637 (1.3926)	grad_norm 0.4540 (0.5195)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:27:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:11:57 lr 0.000007	 wd 0.0000	time 0.2504 (0.3115)	loss 1.5402 (1.3718)	grad_norm 0.4850 (0.5164)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:27:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:10:48 lr 0.000007	 wd 0.0000	time 0.2612 (0.2947)	loss 1.5150 (1.3650)	grad_norm 0.4951 (0.5228)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 00:28:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:09:45 lr 0.000007	 wd 0.0000	time 0.2032 (0.2785)	loss 1.5230 (1.3564)	grad_norm 0.5357 (0.5221)	loss_scale 8192.0000 (4872.2993)	mem 7984MB
[2024-07-16 00:28:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:08:55 lr 0.000007	 wd 0.0000	time 0.2091 (0.2677)	loss 1.6821 (1.3611)	grad_norm 0.5658 (inf)	loss_scale 4096.0000 (4864.5110)	mem 7984MB
[2024-07-16 00:28:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:08:17 lr 0.000007	 wd 0.0000	time 0.2329 (0.2613)	loss 1.1312 (1.3608)	grad_norm 0.5127 (inf)	loss_scale 4096.0000 (4736.6389)	mem 7984MB
[2024-07-16 00:29:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:49 lr 0.000007	 wd 0.0000	time 0.6835 (0.2606)	loss 1.4112 (1.3581)	grad_norm 0.5075 (inf)	loss_scale 4096.0000 (4645.2496)	mem 7984MB
[2024-07-16 00:29:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:07:20 lr 0.000007	 wd 0.0000	time 0.2056 (0.2589)	loss 1.6886 (1.3569)	grad_norm 0.4328 (inf)	loss_scale 4096.0000 (4576.6792)	mem 7984MB
[2024-07-16 00:29:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:06:49 lr 0.000007	 wd 0.0000	time 0.2326 (0.2559)	loss 1.7040 (1.3535)	grad_norm 0.5096 (inf)	loss_scale 4096.0000 (4523.3296)	mem 7984MB
[2024-07-16 00:30:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:20 lr 0.000007	 wd 0.0000	time 0.2372 (0.2531)	loss 1.1468 (1.3516)	grad_norm 0.5870 (inf)	loss_scale 4096.0000 (4480.6394)	mem 7984MB
[2024-07-16 00:30:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:54 lr 0.000007	 wd 0.0000	time 0.2291 (0.2529)	loss 0.8777 (1.3473)	grad_norm 0.4974 (inf)	loss_scale 4096.0000 (4445.7039)	mem 7984MB
[2024-07-16 00:31:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:28 lr 0.000007	 wd 0.0000	time 0.2316 (0.2524)	loss 1.5612 (1.3492)	grad_norm 0.5481 (inf)	loss_scale 4096.0000 (4416.5862)	mem 7984MB
[2024-07-16 00:31:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:05:01 lr 0.000007	 wd 0.0000	time 0.2176 (0.2507)	loss 1.4464 (1.3506)	grad_norm 0.6592 (inf)	loss_scale 4096.0000 (4391.9447)	mem 7984MB
[2024-07-16 00:31:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:34 lr 0.000007	 wd 0.0000	time 0.2394 (0.2492)	loss 1.5897 (1.3506)	grad_norm 0.4794 (inf)	loss_scale 4096.0000 (4370.8208)	mem 7984MB
[2024-07-16 00:32:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:04:09 lr 0.000006	 wd 0.0000	time 0.2339 (0.2490)	loss 1.2672 (1.3528)	grad_norm 0.5249 (inf)	loss_scale 4096.0000 (4352.5117)	mem 7984MB
[2024-07-16 00:32:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:45 lr 0.000006	 wd 0.0000	time 0.2095 (0.2499)	loss 1.1700 (1.3521)	grad_norm 0.4921 (inf)	loss_scale 4096.0000 (4336.4897)	mem 7984MB
[2024-07-16 00:33:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:19 lr 0.000006	 wd 0.0000	time 0.2546 (0.2490)	loss 1.3137 (1.3524)	grad_norm 0.5158 (inf)	loss_scale 4096.0000 (4322.3516)	mem 7984MB
[2024-07-16 00:33:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:54 lr 0.000006	 wd 0.0000	time 0.2357 (0.2481)	loss 1.4274 (1.3518)	grad_norm 0.6649 (inf)	loss_scale 4096.0000 (4309.7835)	mem 7984MB
[2024-07-16 00:34:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:29 lr 0.000006	 wd 0.0000	time 0.2499 (0.2480)	loss 1.2292 (1.3545)	grad_norm 0.4957 (inf)	loss_scale 4096.0000 (4298.5376)	mem 7984MB
[2024-07-16 00:34:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:02:04 lr 0.000006	 wd 0.0000	time 0.2696 (0.2484)	loss 1.4525 (1.3533)	grad_norm 0.5144 (nan)	loss_scale 2048.0000 (4218.8186)	mem 7984MB
[2024-07-16 00:34:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:39 lr 0.000006	 wd 0.0000	time 0.2313 (0.2477)	loss 1.6956 (1.3537)	grad_norm 0.4814 (nan)	loss_scale 2048.0000 (4115.4955)	mem 7984MB
[2024-07-16 00:35:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:14 lr 0.000006	 wd 0.0000	time 0.2388 (0.2469)	loss 1.4684 (1.3515)	grad_norm 0.5279 (nan)	loss_scale 2048.0000 (4021.5611)	mem 7984MB
[2024-07-16 00:35:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:49 lr 0.000006	 wd 0.0000	time 0.2420 (0.2467)	loss 1.5841 (1.3517)	grad_norm 0.5399 (nan)	loss_scale 2048.0000 (3935.7914)	mem 7984MB
[2024-07-16 00:36:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:25 lr 0.000006	 wd 0.0000	time 0.2284 (0.2467)	loss 1.5323 (1.3522)	grad_norm 0.4782 (nan)	loss_scale 2048.0000 (3857.1662)	mem 7984MB
[2024-07-16 00:36:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000006	 wd 0.0000	time 0.1861 (0.2449)	loss 1.4297 (1.3529)	grad_norm 0.5123 (nan)	loss_scale 2048.0000 (3784.8285)	mem 7984MB
[2024-07-16 00:36:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 23 training takes 0:10:19
[2024-07-16 00:36:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 19.389 (19.389)	Loss 0.4119 (0.4119)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-16 00:37:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.230 Acc@5 97.262
[2024-07-16 00:37:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-16 00:37:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.27%
[2024-07-16 00:37:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][0/2502]	eta 1 day, 1:18:28 lr 0.000006	 wd 0.0000	time 36.4141 (36.4141)	loss 1.5849 (1.5849)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:38:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:23:36 lr 0.000006	 wd 0.0000	time 0.2296 (0.5898)	loss 1.1443 (1.3921)	grad_norm 0.4811 (0.5244)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:38:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:15:39 lr 0.000006	 wd 0.0000	time 0.1959 (0.4080)	loss 1.4044 (1.3741)	grad_norm 0.4558 (0.5187)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:38:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:13:09 lr 0.000006	 wd 0.0000	time 0.2156 (0.3586)	loss 1.6207 (1.3672)	grad_norm 0.5196 (0.5167)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:39:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:11:31 lr 0.000005	 wd 0.0000	time 0.2092 (0.3291)	loss 1.4031 (1.3638)	grad_norm 0.4838 (0.5175)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:39:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:10:17 lr 0.000005	 wd 0.0000	time 0.2195 (0.3083)	loss 1.6600 (1.3651)	grad_norm 0.5325 (0.5185)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:40:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:09:20 lr 0.000005	 wd 0.0000	time 0.2377 (0.2948)	loss 1.3925 (1.3621)	grad_norm 0.6005 (0.5192)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:40:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:08:39 lr 0.000005	 wd 0.0000	time 0.2612 (0.2881)	loss 1.3440 (1.3632)	grad_norm 0.4844 (0.5175)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:40:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:08:00 lr 0.000005	 wd 0.0000	time 0.2105 (0.2825)	loss 1.4079 (1.3642)	grad_norm 0.5102 (0.5188)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:41:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:07:23 lr 0.000005	 wd 0.0000	time 0.2028 (0.2769)	loss 1.5511 (1.3612)	grad_norm 0.5028 (0.5188)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:41:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:48 lr 0.000005	 wd 0.0000	time 0.2018 (0.2722)	loss 1.2224 (1.3616)	grad_norm 0.5046 (0.5189)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:42:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:06:17 lr 0.000005	 wd 0.0000	time 0.2408 (0.2696)	loss 1.4960 (1.3605)	grad_norm 0.4790 (0.5197)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:42:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:49 lr 0.000005	 wd 0.0000	time 0.2401 (0.2682)	loss 1.2502 (1.3586)	grad_norm 0.5549 (0.5188)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:42:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:05:18 lr 0.000005	 wd 0.0000	time 0.2527 (0.2652)	loss 1.3934 (1.3580)	grad_norm 0.7989 (0.5191)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:43:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:49 lr 0.000005	 wd 0.0000	time 0.2173 (0.2628)	loss 1.3430 (1.3564)	grad_norm 0.6653 (0.5185)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:43:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:21 lr 0.000005	 wd 0.0000	time 0.2650 (0.2613)	loss 0.9693 (1.3547)	grad_norm 0.4753 (0.5198)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:44:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:55 lr 0.000005	 wd 0.0000	time 0.2737 (0.2612)	loss 1.5008 (1.3544)	grad_norm 0.5561 (0.5209)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:44:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:28 lr 0.000005	 wd 0.0000	time 0.2232 (0.2596)	loss 1.6869 (1.3556)	grad_norm 0.4732 (0.5221)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:44:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:03:01 lr 0.000005	 wd 0.0000	time 0.2103 (0.2582)	loss 1.1353 (1.3535)	grad_norm 0.6321 (0.5226)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:45:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:34 lr 0.000005	 wd 0.0000	time 0.2251 (0.2574)	loss 1.4069 (1.3546)	grad_norm 0.4635 (0.5240)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:45:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:02:09 lr 0.000004	 wd 0.0000	time 0.2034 (0.2576)	loss 1.3728 (1.3553)	grad_norm 0.4848 (0.5229)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:46:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:43 lr 0.000004	 wd 0.0000	time 0.2163 (0.2565)	loss 1.5412 (1.3544)	grad_norm 0.4932 (0.5226)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:46:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:17 lr 0.000004	 wd 0.0000	time 0.2283 (0.2554)	loss 1.3962 (1.3542)	grad_norm 0.4836 (0.5227)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:46:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:51 lr 0.000004	 wd 0.0000	time 0.2445 (0.2548)	loss 1.7348 (1.3539)	grad_norm 0.4820 (0.5223)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:47:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:25 lr 0.000004	 wd 0.0000	time 0.2321 (0.2547)	loss 1.4951 (1.3538)	grad_norm 0.7441 (0.5228)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:47:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000004	 wd 0.0000	time 0.1821 (0.2527)	loss 1.2614 (1.3539)	grad_norm 0.5719 (0.5238)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:47:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 24 training takes 0:10:37
[2024-07-16 00:48:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 20.955 (20.955)	Loss 0.4128 (0.4128)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-16 00:48:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.258 Acc@5 97.278
[2024-07-16 00:48:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-16 00:48:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.27%
[2024-07-16 00:48:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][0/2502]	eta 23:35:34 lr 0.000004	 wd 0.0000	time 33.9467 (33.9467)	loss 1.2515 (1.2515)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:49:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:22:36 lr 0.000004	 wd 0.0000	time 0.1934 (0.5646)	loss 1.3867 (1.3230)	grad_norm 0.5108 (0.5157)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:49:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:15:11 lr 0.000004	 wd 0.0000	time 0.2511 (0.3959)	loss 1.4788 (1.3498)	grad_norm 0.4487 (0.5537)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:50:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:12:38 lr 0.000004	 wd 0.0000	time 0.2288 (0.3446)	loss 1.1196 (1.3396)	grad_norm 0.4355 (0.5416)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:50:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:11:11 lr 0.000004	 wd 0.0000	time 0.2135 (0.3195)	loss 1.2500 (1.3547)	grad_norm 0.5758 (0.5379)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:50:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:10:01 lr 0.000004	 wd 0.0000	time 0.2360 (0.3004)	loss 1.5517 (1.3549)	grad_norm 0.4817 (0.5375)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:51:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:09:08 lr 0.000004	 wd 0.0000	time 0.2098 (0.2884)	loss 1.1398 (1.3564)	grad_norm 0.5442 (0.5414)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:51:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:08:26 lr 0.000004	 wd 0.0000	time 0.2446 (0.2809)	loss 1.2345 (1.3569)	grad_norm 0.4944 (0.5391)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:52:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:07:53 lr 0.000004	 wd 0.0000	time 0.2115 (0.2784)	loss 0.9920 (1.3571)	grad_norm 0.5702 (0.5375)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:52:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:07:17 lr 0.000004	 wd 0.0000	time 0.2201 (0.2733)	loss 1.5053 (1.3589)	grad_norm 0.4955 (0.5342)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 00:52:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:44 lr 0.000004	 wd 0.0000	time 0.2021 (0.2690)	loss 1.2362 (1.3594)	grad_norm 0.9214 (0.5355)	loss_scale 4096.0000 (2195.3087)	mem 7984MB
[2024-07-16 00:53:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:06:13 lr 0.000004	 wd 0.0000	time 0.2172 (0.2664)	loss 1.2917 (1.3576)	grad_norm 0.6714 (0.5341)	loss_scale 4096.0000 (2367.9419)	mem 7984MB
[2024-07-16 00:53:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:45 lr 0.000004	 wd 0.0000	time 0.2316 (0.2650)	loss 1.3499 (1.3601)	grad_norm 0.4886 (0.5328)	loss_scale 4096.0000 (2511.8268)	mem 7984MB
[2024-07-16 00:54:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:05:15 lr 0.000003	 wd 0.0000	time 0.1991 (0.2627)	loss 1.4768 (1.3617)	grad_norm 0.5469 (0.5311)	loss_scale 4096.0000 (2633.5926)	mem 7984MB
[2024-07-16 00:54:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:47 lr 0.000003	 wd 0.0000	time 0.2079 (0.2605)	loss 1.1210 (1.3612)	grad_norm 0.4697 (0.5308)	loss_scale 4096.0000 (2737.9757)	mem 7984MB
[2024-07-16 00:54:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:04:19 lr 0.000003	 wd 0.0000	time 0.2452 (0.2587)	loss 1.2390 (1.3613)	grad_norm 0.4888 (0.5325)	loss_scale 4096.0000 (2828.4504)	mem 7984MB
[2024-07-16 00:55:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:53 lr 0.000003	 wd 0.0000	time 0.2296 (0.2591)	loss 1.4887 (1.3606)	grad_norm 0.4646 (0.5331)	loss_scale 4096.0000 (2907.6227)	mem 7984MB
[2024-07-16 00:55:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:26 lr 0.000003	 wd 0.0000	time 0.2363 (0.2579)	loss 1.3738 (1.3599)	grad_norm 0.5176 (0.5328)	loss_scale 4096.0000 (2977.4862)	mem 7984MB
[2024-07-16 00:56:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:03:00 lr 0.000003	 wd 0.0000	time 0.2025 (0.2565)	loss 1.5521 (1.3598)	grad_norm 0.5119 (0.5327)	loss_scale 4096.0000 (3039.5913)	mem 7984MB
[2024-07-16 00:56:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:33 lr 0.000003	 wd 0.0000	time 0.2220 (0.2555)	loss 1.9591 (1.3596)	grad_norm 0.4749 (0.5322)	loss_scale 4096.0000 (3095.1625)	mem 7984MB
[2024-07-16 00:56:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:02:08 lr 0.000003	 wd 0.0000	time 0.2583 (0.2560)	loss 1.2625 (1.3590)	grad_norm 0.4831 (0.5306)	loss_scale 4096.0000 (3145.1794)	mem 7984MB
[2024-07-16 00:57:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:42 lr 0.000003	 wd 0.0000	time 0.2227 (0.2555)	loss 0.8766 (1.3589)	grad_norm 0.5047 (0.5323)	loss_scale 4096.0000 (3190.4350)	mem 7984MB
[2024-07-16 00:57:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:16 lr 0.000003	 wd 0.0000	time 0.1980 (0.2545)	loss 1.4368 (1.3577)	grad_norm 0.5093 (0.5319)	loss_scale 4096.0000 (3231.5784)	mem 7984MB
[2024-07-16 00:58:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:51 lr 0.000003	 wd 0.0000	time 0.2134 (0.2536)	loss 1.2016 (1.3564)	grad_norm 0.4414 (0.5328)	loss_scale 4096.0000 (3269.1456)	mem 7984MB
[2024-07-16 00:58:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:25 lr 0.000003	 wd 0.0000	time 0.2419 (0.2537)	loss 1.3948 (1.3579)	grad_norm 0.4737 (0.5329)	loss_scale 4096.0000 (3303.5835)	mem 7984MB
[2024-07-16 00:58:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1831 (0.2518)	loss 1.4837 (1.3579)	grad_norm 0.4974 (0.5330)	loss_scale 4096.0000 (3335.2675)	mem 7984MB
[2024-07-16 00:59:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 25 training takes 0:10:40
[2024-07-16 00:59:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 21.191 (21.191)	Loss 0.4131 (0.4131)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-16 00:59:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.226 Acc@5 97.282
[2024-07-16 00:59:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-16 00:59:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.27%
[2024-07-16 01:00:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][0/2502]	eta 22:53:54 lr 0.000003	 wd 0.0000	time 32.9475 (32.9475)	loss 1.3236 (1.3236)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:00:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:22:08 lr 0.000003	 wd 0.0000	time 0.2008 (0.5529)	loss 1.5072 (1.3501)	grad_norm 0.4934 (0.6030)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:00:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:14:59 lr 0.000003	 wd 0.0000	time 0.2236 (0.3907)	loss 1.4730 (1.3707)	grad_norm 0.4815 (0.5684)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:01:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:12:26 lr 0.000003	 wd 0.0000	time 0.2261 (0.3390)	loss 1.4872 (1.3622)	grad_norm 0.4977 (0.5481)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:01:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:11:04 lr 0.000003	 wd 0.0000	time 0.2228 (0.3164)	loss 1.6361 (1.3639)	grad_norm 0.4739 (0.5464)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:02:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:09:57 lr 0.000003	 wd 0.0000	time 0.1941 (0.2982)	loss 1.6210 (1.3706)	grad_norm 0.4848 (0.5393)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:02:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:09:05 lr 0.000003	 wd 0.0000	time 0.2566 (0.2867)	loss 1.4119 (1.3658)	grad_norm 0.4685 (0.5406)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:02:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:08:23 lr 0.000003	 wd 0.0000	time 0.2120 (0.2792)	loss 1.5376 (1.3617)	grad_norm 0.4668 (0.5388)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:03:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:07:50 lr 0.000002	 wd 0.0000	time 0.2299 (0.2762)	loss 1.6073 (1.3604)	grad_norm 0.5087 (0.5410)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:03:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:07:14 lr 0.000002	 wd 0.0000	time 0.2110 (0.2713)	loss 1.3872 (1.3604)	grad_norm 0.4823 (0.5387)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:04:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:41 lr 0.000002	 wd 0.0000	time 0.2147 (0.2674)	loss 1.4088 (1.3610)	grad_norm 0.4947 (0.5391)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:04:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:06:10 lr 0.000002	 wd 0.0000	time 0.2332 (0.2643)	loss 1.5733 (1.3625)	grad_norm 0.5627 (0.5376)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:04:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:43 lr 0.000002	 wd 0.0000	time 0.2689 (0.2637)	loss 1.0811 (1.3629)	grad_norm 0.5295 (0.5367)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:05:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:05:14 lr 0.000002	 wd 0.0000	time 0.2085 (0.2615)	loss 0.9511 (1.3613)	grad_norm 0.5251 (0.5356)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:05:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:45 lr 0.000002	 wd 0.0000	time 0.2203 (0.2592)	loss 1.5933 (1.3606)	grad_norm 0.4859 (inf)	loss_scale 2048.0000 (4049.2220)	mem 7984MB
[2024-07-16 01:06:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:04:17 lr 0.000002	 wd 0.0000	time 0.2295 (0.2573)	loss 1.4005 (1.3594)	grad_norm 0.5385 (inf)	loss_scale 2048.0000 (3915.8961)	mem 7984MB
[2024-07-16 01:06:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:51 lr 0.000002	 wd 0.0000	time 0.3841 (0.2570)	loss 1.4488 (1.3583)	grad_norm 0.5158 (inf)	loss_scale 2048.0000 (3799.2255)	mem 7984MB
[2024-07-16 01:06:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:25 lr 0.000002	 wd 0.0000	time 0.1969 (0.2568)	loss 1.2830 (1.3594)	grad_norm 0.5106 (inf)	loss_scale 2048.0000 (3696.2728)	mem 7984MB
[2024-07-16 01:07:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:59 lr 0.000002	 wd 0.0000	time 0.2261 (0.2555)	loss 1.5218 (1.3622)	grad_norm 0.4761 (inf)	loss_scale 2048.0000 (3604.7529)	mem 7984MB
[2024-07-16 01:07:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:33 lr 0.000002	 wd 0.0000	time 0.2213 (0.2544)	loss 0.9761 (1.3608)	grad_norm 0.4617 (inf)	loss_scale 2048.0000 (3522.8617)	mem 7984MB
[2024-07-16 01:08:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:02:07 lr 0.000002	 wd 0.0000	time 0.2115 (0.2545)	loss 0.9079 (1.3598)	grad_norm 0.5773 (inf)	loss_scale 2048.0000 (3449.1554)	mem 7984MB
[2024-07-16 01:08:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:42 lr 0.000002	 wd 0.0000	time 0.2162 (0.2546)	loss 1.1292 (1.3587)	grad_norm 0.5040 (inf)	loss_scale 2048.0000 (3382.4655)	mem 7984MB
[2024-07-16 01:08:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:16 lr 0.000002	 wd 0.0000	time 0.2274 (0.2536)	loss 0.9532 (1.3584)	grad_norm 0.4938 (inf)	loss_scale 2048.0000 (3321.8355)	mem 7984MB
[2024-07-16 01:09:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:51 lr 0.000002	 wd 0.0000	time 0.2321 (0.2527)	loss 1.2008 (1.3573)	grad_norm 0.4783 (inf)	loss_scale 2048.0000 (3266.4754)	mem 7984MB
[2024-07-16 01:09:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:25 lr 0.000002	 wd 0.0000	time 0.2412 (0.2526)	loss 1.1075 (1.3574)	grad_norm 0.5163 (inf)	loss_scale 2048.0000 (3215.7268)	mem 7984MB
[2024-07-16 01:10:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1761 (0.2507)	loss 0.9459 (1.3556)	grad_norm 0.5026 (inf)	loss_scale 2048.0000 (3169.0364)	mem 7984MB
[2024-07-16 01:10:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 26 training takes 0:10:39
[2024-07-16 01:10:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 21.730 (21.730)	Loss 0.4131 (0.4131)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-16 01:10:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.224 Acc@5 97.302
[2024-07-16 01:10:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-16 01:10:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.27%
[2024-07-16 01:11:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][0/2502]	eta 1 day, 1:24:05 lr 0.000002	 wd 0.0000	time 36.5491 (36.5491)	loss 0.9337 (0.9337)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:11:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:23:26 lr 0.000002	 wd 0.0000	time 0.2084 (0.5855)	loss 1.4879 (1.3619)	grad_norm 0.4898 (0.5129)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:12:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:15:35 lr 0.000002	 wd 0.0000	time 0.2094 (0.4064)	loss 1.5726 (1.3567)	grad_norm 0.6373 (0.5252)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:12:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:12:56 lr 0.000002	 wd 0.0000	time 0.2144 (0.3527)	loss 1.3565 (1.3570)	grad_norm 0.4871 (0.5200)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:13:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:11:26 lr 0.000002	 wd 0.0000	time 0.2347 (0.3266)	loss 1.4473 (1.3549)	grad_norm 0.5266 (0.5229)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:13:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:10:12 lr 0.000002	 wd 0.0000	time 0.2081 (0.3060)	loss 0.9801 (1.3507)	grad_norm 0.5617 (0.5280)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:13:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:09:17 lr 0.000002	 wd 0.0000	time 0.2208 (0.2930)	loss 1.2686 (1.3539)	grad_norm 0.4755 (0.5339)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:14:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:08:34 lr 0.000002	 wd 0.0000	time 0.2752 (0.2853)	loss 1.4778 (1.3597)	grad_norm 0.5041 (0.5328)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:14:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:58 lr 0.000002	 wd 0.0000	time 0.2243 (0.2812)	loss 1.5230 (1.3632)	grad_norm 0.4952 (0.5310)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:15:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:07:21 lr 0.000001	 wd 0.0000	time 0.2318 (0.2757)	loss 1.2816 (1.3679)	grad_norm 0.4874 (0.5320)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:15:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:46 lr 0.000001	 wd 0.0000	time 0.2256 (0.2708)	loss 1.4013 (1.3661)	grad_norm 0.5156 (0.5302)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:15:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:06:15 lr 0.000001	 wd 0.0000	time 0.2338 (0.2677)	loss 1.5175 (1.3660)	grad_norm 0.4974 (0.5309)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:16:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:47 lr 0.000001	 wd 0.0000	time 0.2227 (0.2669)	loss 1.4829 (1.3659)	grad_norm 0.4885 (0.5305)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:16:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:05:17 lr 0.000001	 wd 0.0000	time 0.2137 (0.2643)	loss 1.4812 (1.3632)	grad_norm 0.4933 (0.5290)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:17:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:48 lr 0.000001	 wd 0.0000	time 0.2139 (0.2620)	loss 1.2654 (1.3636)	grad_norm 0.4736 (0.5293)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:17:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:04:20 lr 0.000001	 wd 0.0000	time 0.2365 (0.2601)	loss 1.5217 (1.3633)	grad_norm 0.4852 (0.5291)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:17:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:54 lr 0.000001	 wd 0.0000	time 0.2277 (0.2597)	loss 1.5530 (1.3612)	grad_norm 0.4927 (0.5282)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:18:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:27 lr 0.000001	 wd 0.0000	time 0.2281 (0.2584)	loss 1.3905 (1.3590)	grad_norm 0.4830 (0.5285)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:18:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:03:00 lr 0.000001	 wd 0.0000	time 0.2023 (0.2569)	loss 1.5080 (1.3596)	grad_norm 0.5050 (0.5294)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:19:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:33 lr 0.000001	 wd 0.0000	time 0.2617 (0.2558)	loss 1.0878 (1.3611)	grad_norm 0.6022 (0.5344)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:19:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:02:08 lr 0.000001	 wd 0.0000	time 0.1905 (0.2559)	loss 1.0529 (1.3599)	grad_norm 0.4979 (0.5334)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:19:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:42 lr 0.000001	 wd 0.0000	time 0.2239 (0.2551)	loss 1.6962 (1.3592)	grad_norm 0.4964 (0.5324)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:20:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:16 lr 0.000001	 wd 0.0000	time 0.2410 (0.2541)	loss 1.0850 (1.3599)	grad_norm 0.5069 (0.5335)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:20:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:51 lr 0.000001	 wd 0.0000	time 0.2370 (0.2533)	loss 1.4494 (1.3600)	grad_norm 0.4793 (0.5342)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:21:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:25 lr 0.000001	 wd 0.0000	time 0.4333 (0.2537)	loss 1.3697 (1.3596)	grad_norm 0.4967 (0.5337)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:21:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1853 (0.2518)	loss 1.5013 (1.3580)	grad_norm 0.4556 (0.5323)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:21:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 27 training takes 0:10:38
[2024-07-16 01:21:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 21.421 (21.421)	Loss 0.4133 (0.4133)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-16 01:22:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.230 Acc@5 97.302
[2024-07-16 01:22:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-16 01:22:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.27%
[2024-07-16 01:22:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][0/2502]	eta 1 day, 0:08:00 lr 0.000001	 wd 0.0000	time 34.7244 (34.7244)	loss 1.2841 (1.2841)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:23:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:23:01 lr 0.000001	 wd 0.0000	time 0.2082 (0.5750)	loss 1.0669 (1.3390)	grad_norm 0.5990 (0.5369)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:23:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:15:22 lr 0.000001	 wd 0.0000	time 0.2401 (0.4008)	loss 1.0692 (1.3428)	grad_norm 0.5472 (0.5266)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:24:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:12:42 lr 0.000001	 wd 0.0000	time 0.2378 (0.3465)	loss 1.6361 (1.3527)	grad_norm 0.4701 (0.5231)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-16 01:24:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:11:15 lr 0.000001	 wd 0.0000	time 0.2267 (0.3215)	loss 1.3798 (1.3572)	grad_norm 0.4679 (0.5250)	loss_scale 4096.0000 (2231.8603)	mem 7984MB
[2024-07-16 01:24:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:10:05 lr 0.000001	 wd 0.0000	time 0.2032 (0.3024)	loss 1.5628 (1.3595)	grad_norm 0.5100 (0.5233)	loss_scale 4096.0000 (2603.9441)	mem 7984MB
[2024-07-16 01:25:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:09:11 lr 0.000001	 wd 0.0000	time 0.2468 (0.2901)	loss 1.3744 (1.3594)	grad_norm 0.4995 (0.5216)	loss_scale 4096.0000 (2852.2063)	mem 7984MB
[2024-07-16 01:25:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:08:28 lr 0.000001	 wd 0.0000	time 0.2203 (0.2819)	loss 1.0273 (1.3613)	grad_norm 0.4790 (0.5222)	loss_scale 4096.0000 (3029.6377)	mem 7984MB
[2024-07-16 01:26:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:55 lr 0.000001	 wd 0.0000	time 0.2410 (0.2796)	loss 1.6114 (1.3584)	grad_norm 0.4898 (0.5270)	loss_scale 4096.0000 (3162.7665)	mem 7984MB
[2024-07-16 01:26:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:07:19 lr 0.000001	 wd 0.0000	time 0.2271 (0.2743)	loss 1.5246 (1.3591)	grad_norm 0.6680 (0.5254)	loss_scale 4096.0000 (3266.3441)	mem 7984MB
[2024-07-16 01:26:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:45 lr 0.000001	 wd 0.0000	time 0.1958 (0.2699)	loss 1.5482 (1.3617)	grad_norm 0.4622 (0.5246)	loss_scale 4096.0000 (3349.2268)	mem 7984MB
[2024-07-16 01:27:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:06:13 lr 0.000001	 wd 0.0000	time 0.2421 (0.2667)	loss 0.9417 (1.3582)	grad_norm 0.5223 (0.5242)	loss_scale 4096.0000 (3417.0536)	mem 7984MB
[2024-07-16 01:27:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:47 lr 0.000001	 wd 0.0000	time 0.1788 (0.2667)	loss 1.2168 (1.3585)	grad_norm 0.5578 (0.5228)	loss_scale 4096.0000 (3473.5853)	mem 7984MB
[2024-07-16 01:28:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:05:17 lr 0.000001	 wd 0.0000	time 0.2380 (0.2642)	loss 1.5557 (1.3553)	grad_norm 0.5529 (0.5223)	loss_scale 4096.0000 (3521.4266)	mem 7984MB
[2024-07-16 01:28:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:48 lr 0.000001	 wd 0.0000	time 0.2099 (0.2618)	loss 0.9254 (1.3563)	grad_norm 0.5543 (0.5240)	loss_scale 4096.0000 (3562.4383)	mem 7984MB
[2024-07-16 01:28:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:04:20 lr 0.000001	 wd 0.0000	time 0.2998 (0.2599)	loss 1.4803 (1.3549)	grad_norm 0.4737 (0.5282)	loss_scale 4096.0000 (3597.9853)	mem 7984MB
[2024-07-16 01:29:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:54 lr 0.000001	 wd 0.0000	time 0.3595 (0.2597)	loss 1.1863 (1.3543)	grad_norm 0.4914 (0.5271)	loss_scale 4096.0000 (3629.0918)	mem 7984MB
[2024-07-16 01:29:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:27 lr 0.000001	 wd 0.0000	time 0.2141 (0.2584)	loss 1.4170 (1.3558)	grad_norm 0.5083 (0.5263)	loss_scale 4096.0000 (3656.5409)	mem 7984MB
[2024-07-16 01:30:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:03:00 lr 0.000001	 wd 0.0000	time 0.2113 (0.2571)	loss 1.3736 (1.3555)	grad_norm 0.5137 (0.5266)	loss_scale 4096.0000 (3680.9417)	mem 7984MB
[2024-07-16 01:30:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:34 lr 0.000001	 wd 0.0000	time 0.2476 (0.2558)	loss 1.5389 (1.3544)	grad_norm 0.4977 (0.5266)	loss_scale 4096.0000 (3702.7754)	mem 7984MB
[2024-07-16 01:30:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:02:08 lr 0.000001	 wd 0.0000	time 0.1688 (0.2564)	loss 0.8815 (1.3543)	grad_norm 0.4814 (0.5284)	loss_scale 4096.0000 (3722.4268)	mem 7984MB
[2024-07-16 01:31:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:42 lr 0.000001	 wd 0.0000	time 0.2121 (0.2559)	loss 1.0881 (1.3546)	grad_norm 0.4635 (0.5272)	loss_scale 4096.0000 (3740.2075)	mem 7984MB
[2024-07-16 01:31:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:16 lr 0.000001	 wd 0.0000	time 0.2359 (0.2549)	loss 1.5262 (1.3534)	grad_norm 0.4720 (0.5262)	loss_scale 4096.0000 (3756.3726)	mem 7984MB
[2024-07-16 01:32:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:51 lr 0.000001	 wd 0.0000	time 0.2587 (0.2540)	loss 1.0860 (1.3535)	grad_norm 0.4907 (0.5259)	loss_scale 4096.0000 (3771.1326)	mem 7984MB
[2024-07-16 01:32:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:25 lr 0.000001	 wd 0.0000	time 0.2046 (0.2539)	loss 1.5674 (1.3520)	grad_norm 0.6058 (0.5255)	loss_scale 4096.0000 (3784.6631)	mem 7984MB
[2024-07-16 01:32:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1748 (0.2522)	loss 1.1959 (1.3512)	grad_norm 0.5558 (0.5250)	loss_scale 4096.0000 (3797.1116)	mem 7984MB
[2024-07-16 01:32:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 28 training takes 0:10:41
[2024-07-16 01:33:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 23.237 (23.237)	Loss 0.4131 (0.4131)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-16 01:33:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.226 Acc@5 97.300
[2024-07-16 01:33:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-16 01:33:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.27%
[2024-07-16 01:34:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][0/2502]	eta 1 day, 1:23:09 lr 0.000001	 wd 0.0000	time 36.5266 (36.5266)	loss 1.4074 (1.4074)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:34:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:23:48 lr 0.000001	 wd 0.0000	time 0.2315 (0.5946)	loss 1.4599 (1.3322)	grad_norm 0.4602 (0.5145)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:35:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:15:42 lr 0.000001	 wd 0.0000	time 0.1993 (0.4096)	loss 1.1576 (1.3472)	grad_norm 0.5060 (0.5187)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:35:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:13:05 lr 0.000001	 wd 0.0000	time 0.2809 (0.3565)	loss 1.4866 (1.3465)	grad_norm 0.4861 (0.5206)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:35:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:11:32 lr 0.000001	 wd 0.0000	time 0.2049 (0.3295)	loss 1.1774 (1.3553)	grad_norm 0.5321 (0.5164)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:36:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:10:18 lr 0.000001	 wd 0.0000	time 0.2350 (0.3087)	loss 0.9472 (1.3567)	grad_norm 0.5312 (0.5155)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:36:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:09:21 lr 0.000000	 wd 0.0000	time 0.2042 (0.2953)	loss 1.3457 (1.3576)	grad_norm 0.4313 (0.5155)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:37:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:08:38 lr 0.000000	 wd 0.0000	time 0.2276 (0.2880)	loss 1.5661 (1.3585)	grad_norm 0.5344 (0.5205)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:37:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:08:04 lr 0.000000	 wd 0.0000	time 0.2052 (0.2847)	loss 0.7892 (1.3595)	grad_norm 0.4727 (0.5198)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:37:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:07:26 lr 0.000000	 wd 0.0000	time 0.2030 (0.2785)	loss 1.4178 (1.3593)	grad_norm 0.8761 (0.5212)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:38:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:51 lr 0.000000	 wd 0.0000	time 0.2104 (0.2738)	loss 1.3194 (1.3591)	grad_norm 0.4643 (0.5226)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:38:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:06:19 lr 0.000000	 wd 0.0000	time 0.2293 (0.2708)	loss 1.4620 (1.3597)	grad_norm 0.4472 (0.5214)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:39:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:50 lr 0.000000	 wd 0.0000	time 0.3128 (0.2694)	loss 1.2701 (1.3566)	grad_norm 0.5057 (0.5225)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:39:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:05:20 lr 0.000000	 wd 0.0000	time 0.2250 (0.2665)	loss 1.5395 (1.3574)	grad_norm 0.5369 (0.5218)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:39:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:50 lr 0.000000	 wd 0.0000	time 0.2083 (0.2640)	loss 1.7595 (1.3563)	grad_norm 0.4931 (0.5217)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:40:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:04:22 lr 0.000000	 wd 0.0000	time 0.2343 (0.2622)	loss 1.2881 (1.3576)	grad_norm 0.4792 (0.5236)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:40:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:56 lr 0.000000	 wd 0.0000	time 0.2062 (0.2622)	loss 1.4731 (1.3589)	grad_norm 0.4957 (0.5286)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:41:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:28 lr 0.000000	 wd 0.0000	time 0.2241 (0.2604)	loss 1.2876 (1.3559)	grad_norm 0.5465 (0.5284)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:41:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:03:01 lr 0.000000	 wd 0.0000	time 0.2159 (0.2588)	loss 1.1548 (1.3575)	grad_norm 0.5482 (0.5269)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-16 01:41:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:35 lr 0.000000	 wd 0.0000	time 0.2586 (0.2577)	loss 1.2255 (1.3572)	grad_norm 0.5496 (0.5266)	loss_scale 8192.0000 (4177.8769)	mem 7984MB
[2024-07-16 01:42:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:02:09 lr 0.000000	 wd 0.0000	time 0.2481 (0.2580)	loss 1.4866 (1.3573)	grad_norm 0.5745 (0.5259)	loss_scale 8192.0000 (4378.4828)	mem 7984MB
[2024-07-16 01:42:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:43 lr 0.000000	 wd 0.0000	time 0.2207 (0.2572)	loss 1.4963 (1.3579)	grad_norm 0.5026 (0.5262)	loss_scale 8192.0000 (4559.9924)	mem 7984MB
[2024-07-16 01:43:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:17 lr 0.000000	 wd 0.0000	time 0.2047 (0.2560)	loss 1.3952 (1.3595)	grad_norm 0.4923 (0.5255)	loss_scale 8192.0000 (4725.0086)	mem 7984MB
[2024-07-16 01:43:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:51 lr 0.000000	 wd 0.0000	time 0.2271 (0.2552)	loss 1.4064 (1.3608)	grad_norm 0.5259 (0.5250)	loss_scale 8192.0000 (4875.6819)	mem 7984MB
[2024-07-16 01:43:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.2138 (0.2552)	loss 1.4080 (1.3614)	grad_norm 0.5148 (0.5260)	loss_scale 8192.0000 (5013.8042)	mem 7984MB
[2024-07-16 01:44:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000000	 wd 0.0000	time 0.1748 (0.2532)	loss 1.5543 (1.3605)	grad_norm 0.5002 (0.5259)	loss_scale 8192.0000 (5140.8812)	mem 7984MB
[2024-07-16 01:44:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 249): INFO EPOCH 29 training takes 0:10:42
[2024-07-16 01:44:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft/ckpt_epoch_29.pth saving......
[2024-07-16 01:44:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag3-full-ft/ckpt_epoch_29.pth saved !!!
[2024-07-16 01:44:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 18.167 (18.167)	Loss 0.4131 (0.4131)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-16 01:45:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 296): INFO  * Acc@1 84.242 Acc@5 97.306
[2024-07-16 01:45:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-16 01:45:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 182): INFO Max accuracy: 84.27%
[2024-07-16 01:45:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process3-efficient-ft] (main.py 189): INFO Training time 5:35:53
