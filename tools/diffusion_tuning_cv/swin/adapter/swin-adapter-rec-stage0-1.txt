[2024-07-13 17:49:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/config.json
[2024-07-13 17:49:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_swin_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 9
    - 3
    DIMS:
    - 96
    - 192
    - 384
    - 768
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: false
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: stage1
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_swin_b_22kto1k_step_stag1
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 4.0e-05
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.0e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 4.0e-08
  WEIGHT_DECAY: 1.0e-08

[2024-07-13 17:49:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/swin/diffusion_ft_adapter_swin_base_patch4_window7_224_22kto1k_step_stage_process1.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_adapter_swin_b_22kto1k_step_stag1", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-13 17:49:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 108): INFO Creating model:adapter_swin_diffusion_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1
[2024-07-13 17:49:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 110): INFO Adapter_SwinTransformer_Diffusion_Finetune(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (uma): UMA(filter_strategy1=23, filter_strategy2=7,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-13 17:49:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 113): INFO number of params: 1093224
[2024-07-13 17:49:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 116): INFO number of GFLOPs: 15.438473216
[2024-07-13 17:49:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 150): INFO no checkpoint found in pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1, ignoring auto resume
[2024-07-13 17:49:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth for fine-tuning......
[2024-07-13 17:49:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])
[2024-07-13 17:49:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth'
[2024-07-13 17:50:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 73.129 (73.129)	Loss 0.4214 (0.4214)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 1477MB
[2024-07-13 17:51:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.698 Acc@5 97.104
[2024-07-13 17:51:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 162): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 17:51:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 168): INFO Start training
[2024-07-13 17:51:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][0/2502]	eta 13:24:40 lr 0.000000	 wd 0.0000	time 19.2967 (19.2967)	loss 1.6336 (1.6336)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 5859MB
[2024-07-13 17:52:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:23:38 lr 0.000000	 wd 0.0000	time 0.2031 (0.5904)	loss 1.4144 (1.4237)	grad_norm 0.3673 (0.3822)	loss_scale 65536.0000 (65536.0000)	mem 5866MB
[2024-07-13 17:52:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:15:24 lr 0.000001	 wd 0.0000	time 0.1991 (0.4017)	loss 1.4586 (1.4080)	grad_norm 0.3811 (nan)	loss_scale 16384.0000 (51189.8109)	mem 5866MB
[2024-07-13 17:52:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:09 lr 0.000001	 wd 0.0000	time 0.1826 (0.3314)	loss 1.4531 (1.3881)	grad_norm 0.3801 (nan)	loss_scale 16384.0000 (39626.4186)	mem 5866MB
[2024-07-13 17:53:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:23 lr 0.000001	 wd 0.0000	time 0.2208 (0.2966)	loss 1.8673 (1.3908)	grad_norm 0.3747 (nan)	loss_scale 8192.0000 (33299.1521)	mem 5866MB
[2024-07-13 17:53:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:10:26 lr 0.000002	 wd 0.0000	time 0.3468 (0.3128)	loss 1.5220 (1.3899)	grad_norm 0.3801 (nan)	loss_scale 8192.0000 (28287.7445)	mem 5866MB
[2024-07-13 17:54:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:24 lr 0.000002	 wd 0.0000	time 0.2006 (0.2970)	loss 1.2025 (1.3899)	grad_norm 0.3749 (nan)	loss_scale 8192.0000 (24944.0266)	mem 5866MB
[2024-07-13 17:54:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:29 lr 0.000002	 wd 0.0000	time 0.1885 (0.2826)	loss 1.4474 (1.3860)	grad_norm 0.3657 (nan)	loss_scale 8192.0000 (22554.2939)	mem 5866MB
[2024-07-13 17:54:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:42 lr 0.000003	 wd 0.0000	time 0.2537 (0.2719)	loss 1.5510 (1.3867)	grad_norm 0.3628 (nan)	loss_scale 8192.0000 (20761.2484)	mem 5866MB
[2024-07-13 17:55:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:32 lr 0.000003	 wd 0.0000	time 0.2245 (0.2823)	loss 1.5835 (1.3816)	grad_norm 0.3674 (nan)	loss_scale 8192.0000 (19366.2153)	mem 5866MB
[2024-07-13 17:55:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:06:51 lr 0.000003	 wd 0.0000	time 0.1943 (0.2741)	loss 1.3680 (1.3812)	grad_norm 0.4227 (nan)	loss_scale 8192.0000 (18249.9101)	mem 5866MB
[2024-07-13 17:56:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:14 lr 0.000004	 wd 0.0000	time 0.1900 (0.2669)	loss 1.5411 (1.3820)	grad_norm 0.3522 (nan)	loss_scale 8192.0000 (17336.3851)	mem 5866MB
[2024-07-13 17:56:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:39 lr 0.000004	 wd 0.0000	time 0.2132 (0.2610)	loss 1.4997 (1.3843)	grad_norm 0.3672 (nan)	loss_scale 8192.0000 (16574.9875)	mem 5866MB
[2024-07-13 17:56:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:20 lr 0.000004	 wd 0.0000	time 0.2380 (0.2664)	loss 1.4644 (1.3863)	grad_norm 0.3835 (nan)	loss_scale 8192.0000 (15930.6380)	mem 5866MB
[2024-07-13 17:57:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:48 lr 0.000005	 wd 0.0000	time 0.2049 (0.2616)	loss 1.5777 (1.3875)	grad_norm 0.3722 (nan)	loss_scale 8192.0000 (15378.2727)	mem 5866MB
[2024-07-13 17:57:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:17 lr 0.000005	 wd 0.0000	time 0.1685 (0.2569)	loss 1.5022 (1.3874)	grad_norm 0.3858 (nan)	loss_scale 8192.0000 (14899.5070)	mem 5866MB
[2024-07-13 17:57:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:48 lr 0.000005	 wd 0.0000	time 0.1600 (0.2528)	loss 1.6203 (1.3880)	grad_norm 0.3826 (nan)	loss_scale 8192.0000 (14480.5497)	mem 5866MB
[2024-07-13 17:58:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:21 lr 0.000005	 wd 0.0000	time 0.2075 (0.2508)	loss 1.5177 (1.3871)	grad_norm 0.3800 (nan)	loss_scale 8192.0000 (14110.8524)	mem 5866MB
[2024-07-13 17:58:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:02:55 lr 0.000006	 wd 0.0000	time 0.2363 (0.2502)	loss 1.2371 (1.3877)	grad_norm 0.3910 (nan)	loss_scale 8192.0000 (13782.2099)	mem 5866MB
[2024-07-13 17:58:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:28 lr 0.000006	 wd 0.0000	time 0.2238 (0.2474)	loss 1.6567 (1.3872)	grad_norm 0.3755 (nan)	loss_scale 8192.0000 (13488.1431)	mem 5866MB
[2024-07-13 17:59:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:02 lr 0.000006	 wd 0.0000	time 0.1867 (0.2448)	loss 1.5074 (1.3852)	grad_norm 0.3563 (nan)	loss_scale 8192.0000 (13223.4683)	mem 5866MB
[2024-07-13 17:59:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:37 lr 0.000007	 wd 0.0000	time 0.1950 (0.2426)	loss 1.3929 (1.3858)	grad_norm 0.3765 (nan)	loss_scale 8192.0000 (12983.9886)	mem 5866MB
[2024-07-13 18:00:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:13 lr 0.000007	 wd 0.0000	time 0.1668 (0.2424)	loss 1.6374 (1.3865)	grad_norm 0.3591 (nan)	loss_scale 8192.0000 (12766.2699)	mem 5866MB
[2024-07-13 18:00:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:48 lr 0.000007	 wd 0.0000	time 0.2127 (0.2410)	loss 1.5398 (1.3853)	grad_norm 0.3885 (nan)	loss_scale 8192.0000 (12567.4750)	mem 5866MB
[2024-07-13 18:00:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:24 lr 0.000008	 wd 0.0000	time 0.2325 (0.2392)	loss 1.4312 (1.3854)	grad_norm 0.3951 (nan)	loss_scale 8192.0000 (12385.2395)	mem 5866MB
[2024-07-13 18:00:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1413 (0.2362)	loss 1.6615 (1.3856)	grad_norm 0.3558 (nan)	loss_scale 8192.0000 (12217.5770)	mem 5866MB
[2024-07-13 18:01:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 0 training takes 0:09:55
[2024-07-13 18:01:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_0.pth saving......
[2024-07-13 18:01:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_0.pth saved !!!
[2024-07-13 18:02:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 62.183 (62.183)	Loss 0.4214 (0.4214)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 5866MB
[2024-07-13 18:02:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.684 Acc@5 97.106
[2024-07-13 18:02:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 18:02:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.68%
[2024-07-13 18:02:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saving......
[2024-07-13 18:02:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-13 18:02:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][0/2502]	eta 11:16:28 lr 0.000008	 wd 0.0000	time 16.2226 (16.2226)	loss 1.2312 (1.2312)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 18:03:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:16:46 lr 0.000008	 wd 0.0000	time 0.5739 (0.4190)	loss 1.1700 (1.4238)	grad_norm 0.3759 (nan)	loss_scale 4096.0000 (7786.4554)	mem 5866MB
[2024-07-13 18:03:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:15:00 lr 0.000009	 wd 0.0000	time 0.1730 (0.3912)	loss 1.3846 (1.4237)	grad_norm 0.3823 (nan)	loss_scale 4096.0000 (5950.4080)	mem 5866MB
[2024-07-13 18:03:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:54 lr 0.000009	 wd 0.0000	time 0.1812 (0.3245)	loss 1.7127 (1.4026)	grad_norm 0.3708 (nan)	loss_scale 4096.0000 (5334.3256)	mem 5866MB
[2024-07-13 18:04:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:10:09 lr 0.000009	 wd 0.0000	time 0.1736 (0.2898)	loss 0.9911 (1.3916)	grad_norm 0.3754 (nan)	loss_scale 4096.0000 (5025.5162)	mem 5866MB
[2024-07-13 18:04:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:10:08 lr 0.000010	 wd 0.0000	time 6.4984 (0.3042)	loss 1.5364 (1.3902)	grad_norm 0.3909 (nan)	loss_scale 4096.0000 (4839.9840)	mem 5866MB
[2024-07-13 18:05:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:09:40 lr 0.000010	 wd 0.0000	time 0.1820 (0.3051)	loss 1.4401 (1.3898)	grad_norm 0.3885 (nan)	loss_scale 4096.0000 (4716.1930)	mem 5866MB
[2024-07-13 18:05:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:41 lr 0.000010	 wd 0.0000	time 0.1969 (0.2894)	loss 1.6733 (1.3888)	grad_norm 0.4018 (nan)	loss_scale 4096.0000 (4627.7204)	mem 5866MB
[2024-07-13 18:06:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:52 lr 0.000011	 wd 0.0000	time 0.2568 (0.2777)	loss 1.5976 (1.3926)	grad_norm 0.4474 (nan)	loss_scale 4096.0000 (4561.3383)	mem 5866MB
[2024-07-13 18:06:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:34 lr 0.000011	 wd 0.0000	time 0.1918 (0.2836)	loss 1.6075 (1.3898)	grad_norm 0.3809 (nan)	loss_scale 4096.0000 (4509.6915)	mem 5866MB
[2024-07-13 18:06:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:52 lr 0.000011	 wd 0.0000	time 0.1900 (0.2747)	loss 1.6907 (1.3885)	grad_norm 0.3804 (nan)	loss_scale 4096.0000 (4468.3636)	mem 5866MB
[2024-07-13 18:07:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:06:14 lr 0.000012	 wd 0.0000	time 0.1942 (0.2670)	loss 1.0884 (1.3875)	grad_norm 0.3795 (nan)	loss_scale 4096.0000 (4434.5431)	mem 5866MB
[2024-07-13 18:07:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:39 lr 0.000012	 wd 0.0000	time 0.1733 (0.2607)	loss 1.3761 (1.3901)	grad_norm 0.3551 (nan)	loss_scale 4096.0000 (4406.3547)	mem 5866MB
[2024-07-13 18:07:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:11 lr 0.000012	 wd 0.0000	time 0.2719 (0.2591)	loss 1.5814 (1.3937)	grad_norm 0.3676 (nan)	loss_scale 4096.0000 (4382.4996)	mem 5866MB
[2024-07-13 18:08:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:43 lr 0.000012	 wd 0.0000	time 0.1999 (0.2570)	loss 1.4585 (1.3917)	grad_norm 0.3828 (nan)	loss_scale 4096.0000 (4362.0500)	mem 5866MB
[2024-07-13 18:08:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:13 lr 0.000013	 wd 0.0000	time 0.1696 (0.2529)	loss 0.9833 (1.3900)	grad_norm 0.3841 (nan)	loss_scale 4096.0000 (4344.3251)	mem 5866MB
[2024-07-13 18:08:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:45 lr 0.000013	 wd 0.0000	time 0.2007 (0.2495)	loss 0.9386 (1.3886)	grad_norm 0.3827 (nan)	loss_scale 4096.0000 (4328.8145)	mem 5866MB
[2024-07-13 18:09:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:17 lr 0.000013	 wd 0.0000	time 0.2474 (0.2466)	loss 1.3685 (1.3879)	grad_norm 0.3887 (nan)	loss_scale 4096.0000 (4315.1276)	mem 5866MB
[2024-07-13 18:09:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:54 lr 0.000014	 wd 0.0000	time 0.1975 (0.2480)	loss 1.4703 (1.3880)	grad_norm 0.3638 (nan)	loss_scale 4096.0000 (4302.9606)	mem 5866MB
[2024-07-13 18:10:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:27 lr 0.000014	 wd 0.0000	time 0.1782 (0.2458)	loss 1.4896 (1.3891)	grad_norm 0.4225 (nan)	loss_scale 4096.0000 (4292.0736)	mem 5866MB
[2024-07-13 18:10:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:02 lr 0.000014	 wd 0.0000	time 0.2051 (0.2434)	loss 1.3496 (1.3884)	grad_norm 0.3673 (nan)	loss_scale 4096.0000 (4282.2749)	mem 5866MB
[2024-07-13 18:10:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:36 lr 0.000015	 wd 0.0000	time 0.1826 (0.2409)	loss 1.4126 (1.3894)	grad_norm 0.3793 (nan)	loss_scale 4096.0000 (4273.4089)	mem 5866MB
[2024-07-13 18:11:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:12 lr 0.000015	 wd 0.0000	time 0.2159 (0.2399)	loss 1.2247 (1.3906)	grad_norm 0.3792 (nan)	loss_scale 4096.0000 (4265.3485)	mem 5866MB
[2024-07-13 18:11:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:48 lr 0.000015	 wd 0.0000	time 0.2059 (0.2391)	loss 1.6471 (1.3912)	grad_norm 0.3860 (nan)	loss_scale 4096.0000 (4257.9887)	mem 5866MB
[2024-07-13 18:11:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:24 lr 0.000016	 wd 0.0000	time 0.1670 (0.2374)	loss 1.4805 (1.3891)	grad_norm 0.3933 (nan)	loss_scale 4096.0000 (4251.2420)	mem 5866MB
[2024-07-13 18:12:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1347 (0.2343)	loss 1.1006 (1.3905)	grad_norm 0.3563 (nan)	loss_scale 4096.0000 (4245.0348)	mem 5866MB
[2024-07-13 18:12:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 1 training takes 0:09:50
[2024-07-13 18:12:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 49.652 (49.652)	Loss 0.4204 (0.4204)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 5866MB
[2024-07-13 18:13:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.704 Acc@5 97.104
[2024-07-13 18:13:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 18:13:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.70%
[2024-07-13 18:13:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saving......
[2024-07-13 18:13:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-13 18:13:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][0/2502]	eta 11:38:34 lr 0.000016	 wd 0.0000	time 16.7525 (16.7525)	loss 1.6540 (1.6540)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:13:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:14:17 lr 0.000016	 wd 0.0000	time 0.1564 (0.3571)	loss 1.4505 (1.3620)	grad_norm 0.3805 (0.3800)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:14:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:11:05 lr 0.000017	 wd 0.0000	time 0.3608 (0.2889)	loss 1.4535 (1.3828)	grad_norm 0.3439 (0.3826)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:14:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:11:49 lr 0.000017	 wd 0.0000	time 0.1811 (0.3223)	loss 1.3173 (1.3940)	grad_norm 0.3764 (0.3829)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:15:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:10:08 lr 0.000017	 wd 0.0000	time 0.1873 (0.2897)	loss 1.5642 (1.3918)	grad_norm 0.3928 (0.3822)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:15:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:08:58 lr 0.000018	 wd 0.0000	time 0.1668 (0.2691)	loss 1.5786 (1.3900)	grad_norm 0.3669 (0.3812)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:15:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:13 lr 0.000018	 wd 0.0000	time 0.3765 (0.2596)	loss 1.2914 (1.3845)	grad_norm 0.3711 (0.3815)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:16:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:08:14 lr 0.000018	 wd 0.0000	time 0.1714 (0.2746)	loss 1.2752 (1.3867)	grad_norm 0.3816 (0.3812)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:16:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:29 lr 0.000019	 wd 0.0000	time 0.2266 (0.2641)	loss 1.4689 (1.3848)	grad_norm 0.3621 (0.3822)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:17:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:49 lr 0.000019	 wd 0.0000	time 0.1765 (0.2558)	loss 1.5599 (1.3893)	grad_norm 0.3970 (0.3823)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:17:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:16 lr 0.000019	 wd 0.0000	time 0.3320 (0.2508)	loss 1.4699 (1.3905)	grad_norm 0.4272 (0.3821)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:18:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:06:05 lr 0.000020	 wd 0.0000	time 0.1806 (0.2604)	loss 1.1999 (1.3899)	grad_norm 0.3650 (0.3832)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:18:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:31 lr 0.000020	 wd 0.0000	time 0.2001 (0.2547)	loss 1.2786 (1.3890)	grad_norm 0.3804 (0.3832)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:18:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:05:00 lr 0.000020	 wd 0.0000	time 0.2026 (0.2497)	loss 1.7347 (1.3917)	grad_norm 0.4088 (0.3835)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:19:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:31 lr 0.000020	 wd 0.0000	time 0.2509 (0.2463)	loss 1.4707 (1.3918)	grad_norm 0.3809 (0.3839)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:19:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:10 lr 0.000021	 wd 0.0000	time 0.1996 (0.2496)	loss 1.5187 (1.3898)	grad_norm 0.3620 (0.3837)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:19:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:41 lr 0.000021	 wd 0.0000	time 0.1755 (0.2461)	loss 1.3066 (1.3900)	grad_norm 0.4037 (0.3841)	loss_scale 8192.0000 (4126.7008)	mem 5866MB
[2024-07-13 18:20:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:14 lr 0.000021	 wd 0.0000	time 0.1918 (0.2431)	loss 1.4489 (1.3897)	grad_norm 0.3819 (0.3837)	loss_scale 8192.0000 (4365.6955)	mem 5866MB
[2024-07-13 18:20:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:48 lr 0.000022	 wd 0.0000	time 0.1865 (0.2404)	loss 1.3686 (1.3897)	grad_norm 0.3708 (0.3834)	loss_scale 8192.0000 (4578.1499)	mem 5866MB
[2024-07-13 18:20:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:24 lr 0.000022	 wd 0.0000	time 0.2807 (0.2395)	loss 1.0807 (1.3883)	grad_norm 0.4256 (0.3833)	loss_scale 8192.0000 (4768.2525)	mem 5866MB
[2024-07-13 18:21:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:02:00 lr 0.000022	 wd 0.0000	time 0.1920 (0.2394)	loss 1.1251 (1.3863)	grad_norm 0.3625 (0.3832)	loss_scale 8192.0000 (4939.3543)	mem 5866MB
[2024-07-13 18:21:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:35 lr 0.000023	 wd 0.0000	time 0.1700 (0.2374)	loss 1.4630 (1.3866)	grad_norm 0.3882 (0.3833)	loss_scale 8192.0000 (5094.1685)	mem 5866MB
[2024-07-13 18:21:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:11 lr 0.000023	 wd 0.0000	time 0.2021 (0.2355)	loss 1.5461 (1.3867)	grad_norm 0.4337 (0.3834)	loss_scale 8192.0000 (5234.9150)	mem 5866MB
[2024-07-13 18:22:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:47 lr 0.000023	 wd 0.0000	time 0.2148 (0.2341)	loss 1.5978 (1.3868)	grad_norm 0.4215 (0.3836)	loss_scale 8192.0000 (5363.4281)	mem 5866MB
[2024-07-13 18:22:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:23 lr 0.000024	 wd 0.0000	time 0.1968 (0.2342)	loss 1.4557 (1.3858)	grad_norm 0.3805 (0.3835)	loss_scale 8192.0000 (5481.2362)	mem 5866MB
[2024-07-13 18:22:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1483 (0.2318)	loss 1.4596 (1.3856)	grad_norm 0.3576 (nan)	loss_scale 4096.0000 (5556.8685)	mem 5866MB
[2024-07-13 18:23:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 2 training takes 0:09:45
[2024-07-13 18:23:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 29.444 (29.444)	Loss 0.4194 (0.4194)	Acc@1 92.383 (92.383)	Acc@5 98.242 (98.242)	Mem 5866MB
[2024-07-13 18:23:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.708 Acc@5 97.112
[2024-07-13 18:23:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 18:23:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.71%
[2024-07-13 18:23:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saving......
[2024-07-13 18:23:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-13 18:24:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][0/2502]	eta 22:45:15 lr 0.000024	 wd 0.0000	time 32.7401 (32.7401)	loss 1.0838 (1.0838)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:24:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:20:52 lr 0.000024	 wd 0.0000	time 0.1830 (0.5216)	loss 1.6965 (1.3706)	grad_norm 0.3924 (0.3859)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:24:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:13:40 lr 0.000025	 wd 0.0000	time 0.1674 (0.3564)	loss 1.5081 (1.3833)	grad_norm 0.3785 (0.3959)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:25:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:11:03 lr 0.000025	 wd 0.0000	time 0.1617 (0.3015)	loss 1.4154 (1.3719)	grad_norm 0.3569 (0.3924)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:25:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:10:05 lr 0.000025	 wd 0.0000	time 0.4632 (0.2880)	loss 1.5603 (1.3789)	grad_norm 0.3706 (0.3905)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:26:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:09:53 lr 0.000026	 wd 0.0000	time 0.1642 (0.2966)	loss 1.4303 (1.3762)	grad_norm 0.3799 (0.3889)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:26:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:08:51 lr 0.000026	 wd 0.0000	time 0.1814 (0.2792)	loss 1.4790 (1.3757)	grad_norm 0.3759 (0.3874)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:26:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:08:00 lr 0.000026	 wd 0.0000	time 0.1693 (0.2664)	loss 1.5266 (1.3777)	grad_norm 0.3810 (0.3877)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:27:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:22 lr 0.000027	 wd 0.0000	time 0.3736 (0.2597)	loss 1.1371 (1.3784)	grad_norm 0.3559 (0.3879)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:27:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:07:08 lr 0.000027	 wd 0.0000	time 0.1827 (0.2672)	loss 1.3592 (1.3800)	grad_norm 0.3742 (0.3885)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:28:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:30 lr 0.000027	 wd 0.0000	time 0.1980 (0.2597)	loss 1.6287 (1.3835)	grad_norm 0.3593 (0.3882)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:28:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:05:55 lr 0.000028	 wd 0.0000	time 0.1733 (0.2534)	loss 1.4207 (1.3859)	grad_norm 0.4258 (0.3888)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:28:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:24 lr 0.000028	 wd 0.0000	time 0.2179 (0.2491)	loss 1.3152 (1.3847)	grad_norm 0.3382 (0.3895)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:29:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:05:06 lr 0.000028	 wd 0.0000	time 0.1885 (0.2546)	loss 1.2474 (1.3876)	grad_norm 0.3596 (0.3892)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:29:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:35 lr 0.000028	 wd 0.0000	time 0.1851 (0.2500)	loss 1.2377 (1.3883)	grad_norm 0.3821 (0.3887)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:29:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:07 lr 0.000029	 wd 0.0000	time 0.1957 (0.2470)	loss 1.4039 (1.3886)	grad_norm 0.3647 (0.3882)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:30:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:39 lr 0.000029	 wd 0.0000	time 0.1947 (0.2439)	loss 1.4308 (1.3874)	grad_norm 0.3738 (0.3878)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:30:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:14 lr 0.000029	 wd 0.0000	time 1.1789 (0.2430)	loss 1.0792 (1.3864)	grad_norm 0.3615 (0.3885)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:30:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:49 lr 0.000030	 wd 0.0000	time 0.1954 (0.2420)	loss 1.6580 (1.3879)	grad_norm 0.3886 (0.3884)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:31:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:24 lr 0.000030	 wd 0.0000	time 0.1926 (0.2396)	loss 1.5580 (1.3876)	grad_norm 0.3628 (0.3880)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:31:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:01:59 lr 0.000030	 wd 0.0000	time 0.1901 (0.2373)	loss 1.1584 (1.3883)	grad_norm 0.4667 (0.3877)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:31:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:34 lr 0.000031	 wd 0.0000	time 0.2559 (0.2358)	loss 1.2438 (1.3867)	grad_norm 0.3647 (0.3870)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:32:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:11 lr 0.000031	 wd 0.0000	time 0.2437 (0.2357)	loss 1.3834 (1.3878)	grad_norm 0.3946 (0.3869)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:32:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:47 lr 0.000031	 wd 0.0000	time 0.1940 (0.2341)	loss 1.5773 (1.3884)	grad_norm 0.3707 (0.3871)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:33:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:23 lr 0.000032	 wd 0.0000	time 0.1801 (0.2326)	loss 1.0065 (1.3876)	grad_norm 0.3716 (0.3867)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:33:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000032	 wd 0.0000	time 0.1374 (0.2297)	loss 1.5635 (1.3881)	grad_norm 0.3734 (0.3866)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:33:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 3 training takes 0:09:39
[2024-07-13 18:34:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 43.580 (43.580)	Loss 0.4219 (0.4219)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 5866MB
[2024-07-13 18:34:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.716 Acc@5 97.140
[2024-07-13 18:34:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 18:34:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.72%
[2024-07-13 18:34:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saving......
[2024-07-13 18:34:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-13 18:34:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][0/2502]	eta 11:21:19 lr 0.000032	 wd 0.0000	time 16.3388 (16.3388)	loss 1.4618 (1.4618)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:34:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:14:01 lr 0.000032	 wd 0.0000	time 0.1671 (0.3504)	loss 1.1720 (1.3997)	grad_norm 0.3723 (0.3854)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:35:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:11:37 lr 0.000033	 wd 0.0000	time 0.4806 (0.3030)	loss 1.1459 (1.4016)	grad_norm 0.3805 (0.3812)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:35:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:11:07 lr 0.000033	 wd 0.0000	time 0.1826 (0.3032)	loss 1.1251 (1.4009)	grad_norm 0.3853 (0.3863)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:36:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:09:37 lr 0.000033	 wd 0.0000	time 0.1921 (0.2747)	loss 1.5820 (1.3963)	grad_norm 0.3528 (0.3853)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:36:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:08:34 lr 0.000034	 wd 0.0000	time 0.1803 (0.2570)	loss 1.3492 (1.3895)	grad_norm 0.3861 (0.3853)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:36:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:07:55 lr 0.000034	 wd 0.0000	time 0.3586 (0.2503)	loss 1.4994 (1.3854)	grad_norm 0.3742 (0.3859)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:37:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:08:00 lr 0.000034	 wd 0.0000	time 0.1860 (0.2665)	loss 1.2947 (1.3855)	grad_norm 0.3773 (0.3851)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:37:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:17 lr 0.000035	 wd 0.0000	time 0.2295 (0.2572)	loss 1.5014 (1.3849)	grad_norm 0.3737 (0.3836)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:38:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:06:40 lr 0.000035	 wd 0.0000	time 0.1954 (0.2499)	loss 1.4966 (1.3861)	grad_norm 0.3570 (0.3843)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:38:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:08 lr 0.000035	 wd 0.0000	time 0.2044 (0.2452)	loss 1.5386 (1.3868)	grad_norm 0.3539 (0.3836)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:39:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:05:58 lr 0.000036	 wd 0.0000	time 0.2071 (0.2560)	loss 1.5452 (1.3875)	grad_norm 0.3555 (0.3827)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:39:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:26 lr 0.000036	 wd 0.0000	time 0.1962 (0.2506)	loss 1.0940 (1.3861)	grad_norm 0.3699 (0.3822)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:39:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:04:55 lr 0.000036	 wd 0.0000	time 0.1847 (0.2460)	loss 1.6104 (1.3854)	grad_norm 0.4898 (0.3837)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:40:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:27 lr 0.000036	 wd 0.0000	time 0.1662 (0.2429)	loss 1.5317 (1.3854)	grad_norm 0.3928 (0.3836)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:40:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:03 lr 0.000037	 wd 0.0000	time 0.2356 (0.2430)	loss 1.2749 (1.3880)	grad_norm 0.3954 (0.3840)	loss_scale 8192.0000 (4161.4923)	mem 5866MB
[2024-07-13 18:40:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:36 lr 0.000037	 wd 0.0000	time 0.1798 (0.2405)	loss 1.0686 (1.3876)	grad_norm 0.3802 (0.3838)	loss_scale 8192.0000 (4413.2417)	mem 5866MB
[2024-07-13 18:41:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:10 lr 0.000037	 wd 0.0000	time 0.2024 (0.2379)	loss 1.5805 (1.3870)	grad_norm 0.3713 (0.3842)	loss_scale 8192.0000 (4635.3909)	mem 5866MB
[2024-07-13 18:41:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:45 lr 0.000038	 wd 0.0000	time 0.2001 (0.2354)	loss 1.4097 (1.3869)	grad_norm 0.3767 (0.3845)	loss_scale 8192.0000 (4832.8706)	mem 5866MB
[2024-07-13 18:41:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:21 lr 0.000038	 wd 0.0000	time 0.2475 (0.2346)	loss 1.6592 (1.3866)	grad_norm 0.3877 (0.3843)	loss_scale 8192.0000 (5009.5739)	mem 5866MB
[2024-07-13 18:42:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:01:57 lr 0.000038	 wd 0.0000	time 0.2441 (0.2349)	loss 1.4686 (1.3860)	grad_norm 0.3793 (0.3844)	loss_scale 8192.0000 (5168.6157)	mem 5866MB
[2024-07-13 18:42:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:33 lr 0.000039	 wd 0.0000	time 0.1846 (0.2333)	loss 1.4374 (1.3864)	grad_norm 0.3885 (0.3848)	loss_scale 8192.0000 (5312.5178)	mem 5866MB
[2024-07-13 18:42:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:09 lr 0.000039	 wd 0.0000	time 0.1822 (0.2317)	loss 0.9908 (1.3841)	grad_norm 0.3352 (0.3847)	loss_scale 8192.0000 (5443.3439)	mem 5866MB
[2024-07-13 18:43:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:46 lr 0.000039	 wd 0.0000	time 0.2040 (0.2303)	loss 1.3417 (1.3843)	grad_norm 0.3579 (0.3846)	loss_scale 8192.0000 (5562.7988)	mem 5866MB
[2024-07-13 18:43:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:23 lr 0.000040	 wd 0.0000	time 0.1844 (0.2309)	loss 1.5902 (1.3842)	grad_norm 0.3529 (0.3848)	loss_scale 8192.0000 (5672.3032)	mem 5866MB
[2024-07-13 18:43:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1494 (0.2283)	loss 0.9283 (1.3841)	grad_norm 0.3644 (0.3849)	loss_scale 8192.0000 (5773.0508)	mem 5866MB
[2024-07-13 18:43:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 4 training takes 0:09:36
[2024-07-13 18:44:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 22.176 (22.176)	Loss 0.4192 (0.4192)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 5866MB
[2024-07-13 18:44:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.720 Acc@5 97.138
[2024-07-13 18:44:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 18:44:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.72%
[2024-07-13 18:44:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saving......
[2024-07-13 18:44:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-13 18:44:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][0/2502]	eta 14:49:10 lr 0.000040	 wd 0.0000	time 21.3230 (21.3230)	loss 1.6319 (1.6319)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 18:45:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:17:55 lr 0.000040	 wd 0.0000	time 0.2212 (0.4478)	loss 1.2864 (1.4038)	grad_norm 0.4163 (0.3826)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 18:45:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:12:18 lr 0.000040	 wd 0.0000	time 0.1687 (0.3209)	loss 1.4970 (1.4076)	grad_norm 0.3853 (0.3844)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 18:45:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:11 lr 0.000040	 wd 0.0000	time 0.1889 (0.2778)	loss 1.6344 (1.3974)	grad_norm 0.4935 (0.3848)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 18:46:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:08:56 lr 0.000040	 wd 0.0000	time 0.1944 (0.2551)	loss 0.9976 (1.3987)	grad_norm 0.3875 (0.3834)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 18:46:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:08:22 lr 0.000040	 wd 0.0000	time 0.3149 (0.2508)	loss 1.5535 (1.3943)	grad_norm 0.3639 (0.3836)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 18:47:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:13 lr 0.000040	 wd 0.0000	time 0.1874 (0.2595)	loss 1.4466 (1.3952)	grad_norm 0.3565 (0.3827)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 18:47:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:30 lr 0.000040	 wd 0.0000	time 0.1946 (0.2498)	loss 1.4780 (1.3928)	grad_norm 0.6861 (0.3830)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 18:47:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:06:52 lr 0.000040	 wd 0.0000	time 0.1790 (0.2423)	loss 0.9472 (1.3869)	grad_norm 0.3674 (0.3826)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 18:48:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:21 lr 0.000040	 wd 0.0000	time 0.2482 (0.2383)	loss 0.9118 (1.3862)	grad_norm 0.3701 (0.3825)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 18:48:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:06 lr 0.000040	 wd 0.0000	time 0.1898 (0.2439)	loss 1.5479 (1.3893)	grad_norm 0.3612 (0.3834)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 18:48:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:34 lr 0.000040	 wd 0.0000	time 0.1754 (0.2389)	loss 1.5709 (1.3852)	grad_norm 0.3679 (0.3841)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 18:49:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:06 lr 0.000040	 wd 0.0000	time 0.1883 (0.2351)	loss 1.5602 (1.3832)	grad_norm 0.3773 (0.3839)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 18:49:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:38 lr 0.000040	 wd 0.0000	time 0.2208 (0.2320)	loss 1.5133 (1.3837)	grad_norm 0.3957 (0.3841)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 18:49:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:15 lr 0.000040	 wd 0.0000	time 0.2195 (0.2316)	loss 1.5456 (1.3834)	grad_norm 0.3707 (0.3836)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 18:50:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:03:51 lr 0.000040	 wd 0.0000	time 0.1816 (0.2314)	loss 1.4247 (1.3833)	grad_norm 0.3744 (nan)	loss_scale 4096.0000 (8099.2192)	mem 5866MB
[2024-07-13 18:50:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:26 lr 0.000040	 wd 0.0000	time 0.1926 (0.2290)	loss 1.4563 (1.3852)	grad_norm 0.3824 (nan)	loss_scale 4096.0000 (7849.1743)	mem 5866MB
[2024-07-13 18:50:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:02 lr 0.000040	 wd 0.0000	time 0.1893 (0.2269)	loss 1.3801 (1.3848)	grad_norm 0.3766 (nan)	loss_scale 4096.0000 (7628.5291)	mem 5866MB
[2024-07-13 18:51:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:38 lr 0.000040	 wd 0.0000	time 0.2261 (0.2257)	loss 1.0066 (1.3842)	grad_norm 0.4130 (nan)	loss_scale 4096.0000 (7432.3865)	mem 5866MB
[2024-07-13 18:51:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:16 lr 0.000040	 wd 0.0000	time 0.2251 (0.2265)	loss 1.4955 (1.3862)	grad_norm 0.3897 (nan)	loss_scale 4096.0000 (7256.8795)	mem 5866MB
[2024-07-13 18:52:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:01:53 lr 0.000040	 wd 0.0000	time 0.1820 (0.2257)	loss 1.5525 (1.3872)	grad_norm 0.3728 (nan)	loss_scale 4096.0000 (7098.9145)	mem 5866MB
[2024-07-13 18:52:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:30 lr 0.000040	 wd 0.0000	time 0.1812 (0.2244)	loss 1.5401 (1.3877)	grad_norm 0.3769 (nan)	loss_scale 4096.0000 (6955.9867)	mem 5866MB
[2024-07-13 18:52:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:07 lr 0.000040	 wd 0.0000	time 0.1922 (0.2229)	loss 1.2568 (1.3857)	grad_norm 0.3814 (nan)	loss_scale 4096.0000 (6826.0463)	mem 5866MB
[2024-07-13 18:53:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:44 lr 0.000040	 wd 0.0000	time 0.2044 (0.2226)	loss 0.9093 (1.3848)	grad_norm 0.3557 (nan)	loss_scale 4096.0000 (6707.4003)	mem 5866MB
[2024-07-13 18:53:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:22 lr 0.000040	 wd 0.0000	time 0.1741 (0.2226)	loss 1.5176 (1.3849)	grad_norm 0.3968 (nan)	loss_scale 4096.0000 (6598.6372)	mem 5866MB
[2024-07-13 18:53:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1396 (0.2203)	loss 1.5538 (1.3849)	grad_norm 0.3711 (nan)	loss_scale 4096.0000 (6498.5718)	mem 5866MB
[2024-07-13 18:53:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 5 training takes 0:09:15
[2024-07-13 18:54:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 20.099 (20.099)	Loss 0.4185 (0.4185)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 5866MB
[2024-07-13 18:54:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.718 Acc@5 97.138
[2024-07-13 18:54:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 18:54:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.72%
[2024-07-13 18:54:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][0/2502]	eta 1 day, 1:04:31 lr 0.000040	 wd 0.0000	time 36.0797 (36.0797)	loss 1.5797 (1.5797)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:55:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:21:57 lr 0.000040	 wd 0.0000	time 0.1915 (0.5487)	loss 1.2389 (1.3549)	grad_norm 0.3916 (0.3926)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:55:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:14:12 lr 0.000040	 wd 0.0000	time 0.1883 (0.3702)	loss 1.6280 (1.3772)	grad_norm 0.3788 (0.3876)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:55:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:11:21 lr 0.000040	 wd 0.0000	time 0.1824 (0.3097)	loss 1.4842 (1.3878)	grad_norm 0.4005 (0.3875)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:56:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:10:10 lr 0.000040	 wd 0.0000	time 0.3181 (0.2905)	loss 1.3770 (1.3816)	grad_norm 0.3666 (0.3860)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:56:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:09:59 lr 0.000040	 wd 0.0000	time 0.2126 (0.2997)	loss 1.3806 (1.3760)	grad_norm 0.3554 (0.3850)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:57:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:08:54 lr 0.000040	 wd 0.0000	time 0.1836 (0.2811)	loss 1.6281 (1.3803)	grad_norm 0.3643 (0.3858)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:57:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:08:02 lr 0.000040	 wd 0.0000	time 0.1865 (0.2678)	loss 1.4298 (1.3826)	grad_norm 0.3900 (0.3850)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:57:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:24 lr 0.000040	 wd 0.0000	time 0.3065 (0.2613)	loss 1.0212 (1.3815)	grad_norm 0.3942 (0.3858)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:58:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:07:11 lr 0.000040	 wd 0.0000	time 0.1791 (0.2694)	loss 1.6849 (1.3857)	grad_norm 0.3442 (0.3863)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:58:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:32 lr 0.000040	 wd 0.0000	time 0.1843 (0.2616)	loss 1.3301 (1.3810)	grad_norm 0.3792 (0.3867)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:59:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:57 lr 0.000040	 wd 0.0000	time 0.1705 (0.2549)	loss 1.2324 (1.3802)	grad_norm 0.3681 (0.3864)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:59:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:26 lr 0.000040	 wd 0.0000	time 0.2163 (0.2507)	loss 1.0843 (1.3818)	grad_norm 0.3788 (0.3861)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 18:59:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:04:59 lr 0.000040	 wd 0.0000	time 0.2168 (0.2493)	loss 1.4211 (1.3810)	grad_norm 0.3910 (0.3862)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 19:00:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:30 lr 0.000040	 wd 0.0000	time 0.2021 (0.2459)	loss 1.6740 (1.3795)	grad_norm 0.3735 (0.3858)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 19:00:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:03 lr 0.000040	 wd 0.0000	time 0.1935 (0.2426)	loss 1.4965 (1.3810)	grad_norm 0.3753 (0.3852)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 19:00:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:35 lr 0.000040	 wd 0.0000	time 0.1865 (0.2394)	loss 1.5802 (1.3796)	grad_norm 0.3867 (0.3851)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 19:01:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:10 lr 0.000040	 wd 0.0000	time 0.2149 (0.2375)	loss 1.5332 (1.3788)	grad_norm 0.3662 (0.3855)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 19:01:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:46 lr 0.000040	 wd 0.0000	time 0.4071 (0.2377)	loss 1.1891 (1.3786)	grad_norm 0.3652 (0.3855)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 19:01:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:21 lr 0.000040	 wd 0.0000	time 0.2091 (0.2357)	loss 1.2854 (1.3780)	grad_norm 0.3733 (0.3860)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 19:02:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:01:57 lr 0.000039	 wd 0.0000	time 0.1918 (0.2337)	loss 1.0102 (1.3779)	grad_norm 0.3793 (0.3858)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 19:02:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:33 lr 0.000039	 wd 0.0000	time 0.1877 (0.2318)	loss 1.5804 (1.3775)	grad_norm 0.3761 (0.3858)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 19:02:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:09 lr 0.000039	 wd 0.0000	time 0.2013 (0.2309)	loss 1.2757 (1.3779)	grad_norm 0.4350 (0.3856)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 19:03:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:46 lr 0.000039	 wd 0.0000	time 0.2627 (0.2299)	loss 1.4940 (1.3787)	grad_norm 0.3864 (0.3857)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 19:03:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:23 lr 0.000039	 wd 0.0000	time 0.2094 (0.2286)	loss 1.2215 (1.3778)	grad_norm 0.3583 (0.3855)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 19:03:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1384 (0.2260)	loss 1.0419 (1.3785)	grad_norm 0.3607 (0.3856)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 19:03:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 6 training takes 0:09:29
[2024-07-13 19:04:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 33.832 (33.832)	Loss 0.4180 (0.4180)	Acc@1 92.383 (92.383)	Acc@5 98.242 (98.242)	Mem 5866MB
[2024-07-13 19:04:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.724 Acc@5 97.136
[2024-07-13 19:04:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 19:04:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.72%
[2024-07-13 19:04:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saving......
[2024-07-13 19:04:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-13 19:05:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][0/2502]	eta 11:24:01 lr 0.000039	 wd 0.0000	time 16.4035 (16.4035)	loss 1.6272 (1.6272)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 19:05:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:14:14 lr 0.000039	 wd 0.0000	time 0.2106 (0.3556)	loss 1.2526 (1.4039)	grad_norm 0.4574 (0.3845)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 19:05:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:10:25 lr 0.000039	 wd 0.0000	time 0.1818 (0.2718)	loss 1.4903 (1.3791)	grad_norm 0.3805 (0.3869)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 19:06:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:11:22 lr 0.000039	 wd 0.0000	time 0.3747 (0.3100)	loss 1.3304 (1.3766)	grad_norm 0.3813 (0.3868)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 19:06:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:10:03 lr 0.000039	 wd 0.0000	time 0.1895 (0.2869)	loss 1.3652 (1.3781)	grad_norm 0.3835 (0.3853)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 19:06:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:08:55 lr 0.000039	 wd 0.0000	time 0.1981 (0.2674)	loss 1.4629 (1.3737)	grad_norm 0.3670 (0.3847)	loss_scale 8192.0000 (4406.6747)	mem 5866MB
[2024-07-13 19:07:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:03 lr 0.000039	 wd 0.0000	time 0.1906 (0.2542)	loss 1.3598 (1.3776)	grad_norm 0.3759 (0.3838)	loss_scale 8192.0000 (5036.5125)	mem 5866MB
[2024-07-13 19:07:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:08:03 lr 0.000039	 wd 0.0000	time 0.7234 (0.2682)	loss 1.4993 (1.3814)	grad_norm 0.3796 (0.3834)	loss_scale 8192.0000 (5486.6534)	mem 5866MB
[2024-07-13 19:08:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:07:27 lr 0.000039	 wd 0.0000	time 0.1676 (0.2629)	loss 0.8988 (1.3838)	grad_norm 0.3846 (0.3839)	loss_scale 8192.0000 (5824.3995)	mem 5866MB
[2024-07-13 19:08:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:06:48 lr 0.000039	 wd 0.0000	time 0.2060 (0.2551)	loss 1.1173 (1.3857)	grad_norm 0.3605 (0.3839)	loss_scale 8192.0000 (6087.1743)	mem 5866MB
[2024-07-13 19:08:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:13 lr 0.000039	 wd 0.0000	time 0.2038 (0.2484)	loss 1.2076 (1.3815)	grad_norm 0.3756 (0.3835)	loss_scale 8192.0000 (6297.4466)	mem 5866MB
[2024-07-13 19:09:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:44 lr 0.000039	 wd 0.0000	time 0.2204 (0.2454)	loss 1.2628 (1.3800)	grad_norm 0.3841 (0.3835)	loss_scale 8192.0000 (6469.5223)	mem 5866MB
[2024-07-13 19:09:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:18 lr 0.000039	 wd 0.0000	time 0.1582 (0.2447)	loss 1.4266 (1.3786)	grad_norm 0.3836 (0.3842)	loss_scale 8192.0000 (6612.9425)	mem 5866MB
[2024-07-13 19:09:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:04:49 lr 0.000039	 wd 0.0000	time 0.1832 (0.2409)	loss 1.4991 (1.3786)	grad_norm 0.3701 (0.3842)	loss_scale 8192.0000 (6734.3151)	mem 5866MB
[2024-07-13 19:10:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:21 lr 0.000039	 wd 0.0000	time 0.1870 (0.2374)	loss 1.4252 (1.3793)	grad_norm 0.3634 (0.3841)	loss_scale 8192.0000 (6838.3612)	mem 5866MB
[2024-07-13 19:10:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:03:55 lr 0.000039	 wd 0.0000	time 0.2306 (0.2347)	loss 1.6589 (1.3786)	grad_norm 0.3994 (0.3838)	loss_scale 8192.0000 (6928.5436)	mem 5866MB
[2024-07-13 19:11:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:32 lr 0.000039	 wd 0.0000	time 0.2055 (0.2356)	loss 1.5501 (1.3805)	grad_norm 0.3884 (0.3838)	loss_scale 8192.0000 (7007.4603)	mem 5866MB
[2024-07-13 19:11:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:07 lr 0.000039	 wd 0.0000	time 0.1701 (0.2339)	loss 1.5833 (1.3808)	grad_norm 0.4009 (0.3833)	loss_scale 8192.0000 (7077.0982)	mem 5866MB
[2024-07-13 19:11:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:42 lr 0.000039	 wd 0.0000	time 0.1839 (0.2316)	loss 1.1495 (1.3805)	grad_norm 0.3901 (0.3836)	loss_scale 8192.0000 (7139.0028)	mem 5866MB
[2024-07-13 19:12:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:18 lr 0.000039	 wd 0.0000	time 0.1769 (0.2296)	loss 1.3271 (1.3798)	grad_norm 0.3945 (0.3841)	loss_scale 8192.0000 (7194.3945)	mem 5866MB
[2024-07-13 19:12:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:01:54 lr 0.000039	 wd 0.0000	time 0.2104 (0.2287)	loss 1.4635 (1.3809)	grad_norm 0.3723 (0.3842)	loss_scale 8192.0000 (7244.2499)	mem 5866MB
[2024-07-13 19:12:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:32 lr 0.000039	 wd 0.0000	time 0.1384 (0.2293)	loss 1.4998 (1.3820)	grad_norm 0.3880 (0.3845)	loss_scale 8192.0000 (7289.3594)	mem 5866MB
[2024-07-13 19:13:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:08 lr 0.000039	 wd 0.0000	time 0.1875 (0.2280)	loss 1.1317 (1.3802)	grad_norm 0.3620 (0.3848)	loss_scale 8192.0000 (7330.3698)	mem 5866MB
[2024-07-13 19:13:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:45 lr 0.000039	 wd 0.0000	time 0.1944 (0.2266)	loss 1.6232 (1.3806)	grad_norm 0.4080 (0.3847)	loss_scale 8192.0000 (7367.8157)	mem 5866MB
[2024-07-13 19:13:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:22 lr 0.000039	 wd 0.0000	time 0.1897 (0.2251)	loss 1.4953 (1.3802)	grad_norm 0.3756 (0.3850)	loss_scale 8192.0000 (7402.1424)	mem 5866MB
[2024-07-13 19:14:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1536 (0.2230)	loss 1.3080 (1.3804)	grad_norm 0.3950 (0.3853)	loss_scale 8192.0000 (7433.7241)	mem 5866MB
[2024-07-13 19:14:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 7 training takes 0:09:22
[2024-07-13 19:14:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 37.431 (37.431)	Loss 0.4216 (0.4216)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 5866MB
[2024-07-13 19:14:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.702 Acc@5 97.138
[2024-07-13 19:14:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 19:14:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.72%
[2024-07-13 19:15:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][0/2502]	eta 11:00:54 lr 0.000039	 wd 0.0000	time 15.8490 (15.8490)	loss 1.4568 (1.4568)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:15:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:14:56 lr 0.000039	 wd 0.0000	time 0.2247 (0.3731)	loss 1.4909 (1.4173)	grad_norm 0.3567 (0.3817)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:16:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:12:38 lr 0.000039	 wd 0.0000	time 0.1906 (0.3294)	loss 1.5608 (1.3927)	grad_norm 0.3743 (0.3828)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:16:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:10:23 lr 0.000038	 wd 0.0000	time 0.1579 (0.2833)	loss 1.3817 (1.3901)	grad_norm 0.7124 (0.3835)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:16:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:09:05 lr 0.000038	 wd 0.0000	time 0.1859 (0.2595)	loss 1.6509 (1.3859)	grad_norm 0.3877 (0.3866)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:16:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:08:10 lr 0.000038	 wd 0.0000	time 0.1910 (0.2452)	loss 1.4571 (1.3892)	grad_norm 0.3777 (0.3859)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:17:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:04 lr 0.000038	 wd 0.0000	time 0.2091 (0.2550)	loss 1.5592 (1.3940)	grad_norm 0.3984 (0.3855)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:17:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:24 lr 0.000038	 wd 0.0000	time 0.1786 (0.2464)	loss 1.6809 (1.3922)	grad_norm 0.3861 (0.3852)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:18:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:06:47 lr 0.000038	 wd 0.0000	time 0.1910 (0.2397)	loss 1.4992 (1.3898)	grad_norm 0.3661 (0.3868)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:18:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:15 lr 0.000038	 wd 0.0000	time 0.1728 (0.2344)	loss 1.6644 (1.3898)	grad_norm 0.3667 (0.3864)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:18:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:05:48 lr 0.000038	 wd 0.0000	time 0.2476 (0.2323)	loss 1.5113 (1.3859)	grad_norm 0.3557 (0.3863)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:19:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:26 lr 0.000038	 wd 0.0000	time 0.2085 (0.2330)	loss 1.3582 (1.3828)	grad_norm 0.3730 (0.3860)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:19:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:04:59 lr 0.000038	 wd 0.0000	time 0.1607 (0.2298)	loss 1.4686 (1.3831)	grad_norm 0.3802 (0.3864)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:19:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:32 lr 0.000038	 wd 0.0000	time 0.1834 (0.2269)	loss 1.1786 (1.3815)	grad_norm 0.3714 (0.3859)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:20:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:07 lr 0.000038	 wd 0.0000	time 0.1909 (0.2243)	loss 0.9595 (1.3832)	grad_norm 0.3858 (0.3865)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:20:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:03:44 lr 0.000038	 wd 0.0000	time 0.2526 (0.2236)	loss 0.8448 (1.3810)	grad_norm 0.3910 (0.3868)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:20:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:21 lr 0.000038	 wd 0.0000	time 0.2107 (0.2238)	loss 1.2322 (1.3782)	grad_norm 0.3720 (0.3861)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:21:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:02:58 lr 0.000038	 wd 0.0000	time 0.1722 (0.2222)	loss 1.1874 (1.3801)	grad_norm 0.3757 (0.3868)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:21:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:34 lr 0.000038	 wd 0.0000	time 0.2034 (0.2207)	loss 1.5588 (1.3812)	grad_norm 0.3651 (0.3864)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:21:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:12 lr 0.000038	 wd 0.0000	time 0.1796 (0.2195)	loss 1.3147 (1.3804)	grad_norm 0.3696 (0.3862)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:22:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:50 lr 0.000038	 wd 0.0000	time 0.1614 (0.2199)	loss 1.6995 (1.3824)	grad_norm 0.3740 (0.3861)	loss_scale 16384.0000 (8355.7581)	mem 5866MB
[2024-07-13 19:22:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:28 lr 0.000038	 wd 0.0000	time 0.1745 (0.2196)	loss 1.4189 (1.3815)	grad_norm 0.3809 (0.3857)	loss_scale 16384.0000 (8737.8734)	mem 5866MB
[2024-07-13 19:22:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:05 lr 0.000038	 wd 0.0000	time 0.1822 (0.2185)	loss 1.5688 (1.3800)	grad_norm 0.4051 (0.3861)	loss_scale 16384.0000 (9085.2667)	mem 5866MB
[2024-07-13 19:23:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:43 lr 0.000038	 wd 0.0000	time 0.1892 (0.2173)	loss 1.5229 (1.3808)	grad_norm 0.4149 (0.3862)	loss_scale 16384.0000 (9402.4650)	mem 5866MB
[2024-07-13 19:23:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:22 lr 0.000038	 wd 0.0000	time 0.1921 (0.2168)	loss 1.3439 (1.3823)	grad_norm 0.3971 (0.3861)	loss_scale 16384.0000 (9693.2411)	mem 5866MB
[2024-07-13 19:23:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000038	 wd 0.0000	time 0.1431 (0.2152)	loss 1.7758 (1.3838)	grad_norm 0.3649 (0.3859)	loss_scale 16384.0000 (9960.7645)	mem 5866MB
[2024-07-13 19:24:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 8 training takes 0:09:07
[2024-07-13 19:24:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 20.962 (20.962)	Loss 0.4197 (0.4197)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 5866MB
[2024-07-13 19:24:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.750 Acc@5 97.158
[2024-07-13 19:24:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 19:24:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.75%
[2024-07-13 19:24:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saving......
[2024-07-13 19:24:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-13 19:24:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][0/2502]	eta 11:29:57 lr 0.000038	 wd 0.0000	time 16.5458 (16.5458)	loss 1.3774 (1.3774)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:25:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:15:59 lr 0.000038	 wd 0.0000	time 0.3705 (0.3997)	loss 1.2441 (1.3483)	grad_norm 0.3701 (0.3863)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:25:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:12:55 lr 0.000037	 wd 0.0000	time 0.2127 (0.3369)	loss 1.5044 (1.3609)	grad_norm 0.3875 (0.3895)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:26:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:33 lr 0.000037	 wd 0.0000	time 0.1825 (0.2878)	loss 1.4562 (1.3725)	grad_norm 0.3756 (0.3893)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:26:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:13 lr 0.000037	 wd 0.0000	time 0.1756 (0.2633)	loss 1.5844 (1.3676)	grad_norm 0.3636 (0.3877)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:26:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:08:18 lr 0.000037	 wd 0.0000	time 0.2081 (0.2491)	loss 1.4095 (1.3742)	grad_norm 0.3765 (0.3863)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:27:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:30 lr 0.000037	 wd 0.0000	time 0.2711 (0.2685)	loss 1.5081 (1.3685)	grad_norm 0.3572 (0.3866)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:27:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:44 lr 0.000037	 wd 0.0000	time 0.1970 (0.2577)	loss 1.5608 (1.3701)	grad_norm 0.3604 (0.3854)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:27:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:04 lr 0.000037	 wd 0.0000	time 0.1951 (0.2497)	loss 1.4011 (1.3730)	grad_norm 0.3950 (0.3849)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:28:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:28 lr 0.000037	 wd 0.0000	time 0.2419 (0.2428)	loss 1.6209 (1.3702)	grad_norm 0.3785 (0.3842)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:28:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:17 lr 0.000037	 wd 0.0000	time 0.2376 (0.2511)	loss 1.4856 (1.3729)	grad_norm 0.3676 (0.3847)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:29:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:44 lr 0.000037	 wd 0.0000	time 0.1792 (0.2457)	loss 1.4120 (1.3760)	grad_norm 0.4045 (0.3845)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:29:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:13 lr 0.000037	 wd 0.0000	time 0.1826 (0.2410)	loss 1.5527 (1.3770)	grad_norm 0.3631 (0.3857)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:29:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:45 lr 0.000037	 wd 0.0000	time 0.1910 (0.2373)	loss 0.9869 (1.3751)	grad_norm 0.3698 (0.3854)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:30:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:19 lr 0.000037	 wd 0.0000	time 0.2426 (0.2352)	loss 1.3607 (1.3765)	grad_norm 0.3638 (0.3854)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:30:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:03:54 lr 0.000037	 wd 0.0000	time 0.1573 (0.2344)	loss 1.5021 (1.3785)	grad_norm 0.3806 (0.3853)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:30:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:29 lr 0.000037	 wd 0.0000	time 0.1903 (0.2322)	loss 0.9358 (1.3777)	grad_norm 0.3531 (0.3854)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:31:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:04 lr 0.000037	 wd 0.0000	time 0.1724 (0.2299)	loss 1.1304 (1.3790)	grad_norm 0.3617 (0.3854)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:31:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:39 lr 0.000037	 wd 0.0000	time 0.1891 (0.2279)	loss 1.5578 (1.3794)	grad_norm 0.3896 (0.3856)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:31:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:16 lr 0.000037	 wd 0.0000	time 0.2379 (0.2271)	loss 1.3397 (1.3781)	grad_norm 0.3707 (0.3857)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:32:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:01:54 lr 0.000037	 wd 0.0000	time 0.1845 (0.2274)	loss 1.5043 (1.3782)	grad_norm 0.3603 (0.3859)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:32:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:30 lr 0.000036	 wd 0.0000	time 0.1930 (0.2258)	loss 1.0823 (1.3784)	grad_norm 0.3931 (0.3858)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:32:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:07 lr 0.000036	 wd 0.0000	time 0.1799 (0.2243)	loss 1.5071 (1.3795)	grad_norm 0.3653 (0.3857)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:33:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:45 lr 0.000036	 wd 0.0000	time 0.2534 (0.2232)	loss 1.4441 (1.3801)	grad_norm 0.3615 (0.3857)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 19:33:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:22 lr 0.000036	 wd 0.0000	time 0.2026 (0.2233)	loss 1.2973 (1.3798)	grad_norm 0.3780 (nan)	loss_scale 8192.0000 (16274.8188)	mem 5866MB
[2024-07-13 19:33:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000036	 wd 0.0000	time 0.1353 (0.2211)	loss 1.1391 (1.3810)	grad_norm 0.3609 (nan)	loss_scale 8192.0000 (15951.6353)	mem 5866MB
[2024-07-13 19:33:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 9 training takes 0:09:18
[2024-07-13 19:34:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 20.233 (20.233)	Loss 0.4138 (0.4138)	Acc@1 92.383 (92.383)	Acc@5 98.242 (98.242)	Mem 5866MB
[2024-07-13 19:34:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.742 Acc@5 97.154
[2024-07-13 19:34:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 19:34:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.75%
[2024-07-13 19:34:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][0/2502]	eta 14:49:36 lr 0.000036	 wd 0.0000	time 21.3337 (21.3337)	loss 1.3084 (1.3084)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:35:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:18:17 lr 0.000036	 wd 0.0000	time 0.1581 (0.4570)	loss 1.3574 (1.3611)	grad_norm 0.3612 (0.3917)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:35:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:12:31 lr 0.000036	 wd 0.0000	time 0.1905 (0.3266)	loss 1.3144 (1.3820)	grad_norm 0.3788 (0.3891)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:35:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:19 lr 0.000036	 wd 0.0000	time 0.1801 (0.2813)	loss 0.8811 (1.3798)	grad_norm 0.3815 (0.3860)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:36:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:02 lr 0.000036	 wd 0.0000	time 0.1786 (0.2579)	loss 1.5338 (1.3827)	grad_norm 0.3854 (0.3846)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:36:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:08:28 lr 0.000036	 wd 0.0000	time 0.3976 (0.2541)	loss 1.4236 (1.3784)	grad_norm 0.4554 (0.3850)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:37:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:18 lr 0.000036	 wd 0.0000	time 0.1801 (0.2623)	loss 1.5362 (1.3786)	grad_norm 0.3718 (0.3880)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:37:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:34 lr 0.000036	 wd 0.0000	time 0.1899 (0.2521)	loss 1.4924 (1.3745)	grad_norm 0.3621 (0.3887)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:37:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:06:56 lr 0.000036	 wd 0.0000	time 0.2177 (0.2444)	loss 1.2769 (1.3739)	grad_norm 0.3555 (0.3877)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:38:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:24 lr 0.000036	 wd 0.0000	time 0.2169 (0.2397)	loss 1.5583 (1.3739)	grad_norm 0.3857 (0.3869)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:38:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:01 lr 0.000036	 wd 0.0000	time 0.2042 (0.2408)	loss 1.5010 (1.3724)	grad_norm 0.3873 (0.3869)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:38:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:31 lr 0.000036	 wd 0.0000	time 0.1786 (0.2367)	loss 1.3303 (1.3703)	grad_norm 0.3597 (0.3869)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:39:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:03 lr 0.000035	 wd 0.0000	time 0.1772 (0.2330)	loss 1.3505 (1.3709)	grad_norm 0.3841 (0.3867)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:39:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:36 lr 0.000035	 wd 0.0000	time 0.1662 (0.2298)	loss 1.5989 (1.3734)	grad_norm 0.3652 (0.3865)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:39:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:11 lr 0.000035	 wd 0.0000	time 0.2006 (0.2284)	loss 1.3715 (1.3739)	grad_norm 0.3942 (0.3867)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:40:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:03:48 lr 0.000035	 wd 0.0000	time 0.1771 (0.2278)	loss 1.2694 (1.3739)	grad_norm 0.3455 (0.3863)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:40:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:23 lr 0.000035	 wd 0.0000	time 0.1675 (0.2259)	loss 1.2483 (1.3754)	grad_norm 0.3789 (0.3864)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:40:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:02:59 lr 0.000035	 wd 0.0000	time 0.2034 (0.2239)	loss 1.3158 (1.3764)	grad_norm 0.3584 (0.3862)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:41:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:35 lr 0.000035	 wd 0.0000	time 0.1898 (0.2222)	loss 1.4151 (1.3771)	grad_norm 0.4659 (0.3862)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:41:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:13 lr 0.000035	 wd 0.0000	time 0.2035 (0.2217)	loss 1.5379 (1.3787)	grad_norm 0.3952 (0.3875)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:41:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:51 lr 0.000035	 wd 0.0000	time 0.2177 (0.2223)	loss 1.2671 (1.3796)	grad_norm 0.3850 (0.3875)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:42:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:28 lr 0.000035	 wd 0.0000	time 0.2023 (0.2211)	loss 1.5819 (1.3814)	grad_norm 0.3858 (0.3872)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:42:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:06 lr 0.000035	 wd 0.0000	time 0.1691 (0.2198)	loss 0.9750 (1.3813)	grad_norm 0.4569 (0.3869)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:42:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:44 lr 0.000035	 wd 0.0000	time 0.2388 (0.2188)	loss 1.5125 (1.3809)	grad_norm 0.3964 (0.3868)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:43:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:22 lr 0.000035	 wd 0.0000	time 0.1822 (0.2191)	loss 1.5357 (1.3808)	grad_norm 0.3584 (0.3866)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:43:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1502 (0.2171)	loss 1.3648 (1.3799)	grad_norm 0.4077 (0.3865)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:43:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 10 training takes 0:09:08
[2024-07-13 19:43:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 18.953 (18.953)	Loss 0.4185 (0.4185)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 5866MB
[2024-07-13 19:44:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.744 Acc@5 97.138
[2024-07-13 19:44:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 19:44:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.75%
[2024-07-13 19:44:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][0/2502]	eta 12:38:45 lr 0.000035	 wd 0.0000	time 18.1955 (18.1955)	loss 1.5374 (1.5374)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:44:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:18:20 lr 0.000035	 wd 0.0000	time 0.1959 (0.4583)	loss 1.3862 (1.3722)	grad_norm 0.3817 (0.4090)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:45:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:12:27 lr 0.000034	 wd 0.0000	time 0.1655 (0.3248)	loss 1.4981 (1.3760)	grad_norm 0.3695 (0.3939)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:45:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:10:15 lr 0.000034	 wd 0.0000	time 0.1929 (0.2796)	loss 1.3532 (1.3774)	grad_norm 0.4133 (0.3909)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:45:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:08:59 lr 0.000034	 wd 0.0000	time 0.1649 (0.2568)	loss 1.5725 (1.3775)	grad_norm 0.3808 (0.3879)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:46:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:08:22 lr 0.000034	 wd 0.0000	time 0.3136 (0.2510)	loss 1.3999 (1.3743)	grad_norm 0.3513 (0.3870)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:46:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:26 lr 0.000034	 wd 0.0000	time 0.1739 (0.2665)	loss 1.4944 (1.3720)	grad_norm 0.4101 (0.3890)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:47:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:07:40 lr 0.000034	 wd 0.0000	time 0.1957 (0.2557)	loss 1.4970 (1.3723)	grad_norm 0.3836 (0.3888)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:47:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:07:00 lr 0.000034	 wd 0.0000	time 0.1644 (0.2473)	loss 1.6374 (1.3747)	grad_norm 0.3633 (0.3895)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:47:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:06:28 lr 0.000034	 wd 0.0000	time 0.2024 (0.2425)	loss 1.5543 (1.3747)	grad_norm 0.3703 (0.3886)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:48:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:16 lr 0.000034	 wd 0.0000	time 0.1870 (0.2507)	loss 1.4807 (1.3769)	grad_norm 0.3924 (0.3892)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:48:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:43 lr 0.000034	 wd 0.0000	time 0.1777 (0.2449)	loss 1.5759 (1.3784)	grad_norm 0.3810 (0.3894)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:48:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:12 lr 0.000034	 wd 0.0000	time 0.1883 (0.2401)	loss 1.7094 (1.3783)	grad_norm 0.3889 (0.3892)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:49:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:04:44 lr 0.000034	 wd 0.0000	time 0.2341 (0.2365)	loss 0.9158 (1.3771)	grad_norm 0.3543 (0.3885)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:49:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:19 lr 0.000034	 wd 0.0000	time 0.1604 (0.2352)	loss 0.8868 (1.3767)	grad_norm 0.3550 (0.3884)	loss_scale 16384.0000 (8402.5011)	mem 5866MB
[2024-07-13 19:49:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:03:54 lr 0.000034	 wd 0.0000	time 0.2522 (0.2339)	loss 1.4516 (1.3759)	grad_norm 0.3582 (0.3880)	loss_scale 16384.0000 (8934.2465)	mem 5866MB
[2024-07-13 19:50:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:28 lr 0.000034	 wd 0.0000	time 0.2124 (0.2312)	loss 1.2744 (1.3769)	grad_norm 0.3887 (0.3877)	loss_scale 16384.0000 (9399.5653)	mem 5866MB
[2024-07-13 19:50:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:03 lr 0.000033	 wd 0.0000	time 0.2006 (0.2289)	loss 1.5006 (1.3761)	grad_norm 0.3720 (0.3874)	loss_scale 16384.0000 (9810.1728)	mem 5866MB
[2024-07-13 19:50:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:39 lr 0.000033	 wd 0.0000	time 0.1988 (0.2275)	loss 1.3084 (1.3778)	grad_norm 0.3607 (0.3876)	loss_scale 16384.0000 (10175.1827)	mem 5866MB
[2024-07-13 19:51:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:17 lr 0.000033	 wd 0.0000	time 0.1994 (0.2282)	loss 1.5178 (1.3781)	grad_norm 0.3676 (0.3879)	loss_scale 16384.0000 (10501.7906)	mem 5866MB
[2024-07-13 19:51:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:01:53 lr 0.000033	 wd 0.0000	time 0.2037 (0.2268)	loss 1.1264 (1.3774)	grad_norm 0.3592 (0.3880)	loss_scale 16384.0000 (10795.7541)	mem 5866MB
[2024-07-13 19:52:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:30 lr 0.000033	 wd 0.0000	time 0.1745 (0.2253)	loss 1.5816 (1.3772)	grad_norm 0.3904 (0.3878)	loss_scale 16384.0000 (11061.7344)	mem 5866MB
[2024-07-13 19:52:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:07 lr 0.000033	 wd 0.0000	time 0.1892 (0.2238)	loss 1.3049 (1.3781)	grad_norm 0.3674 (0.3879)	loss_scale 16384.0000 (11303.5457)	mem 5866MB
[2024-07-13 19:52:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:45 lr 0.000033	 wd 0.0000	time 0.1969 (0.2232)	loss 1.5728 (1.3778)	grad_norm 0.3942 (nan)	loss_scale 8192.0000 (11310.7275)	mem 5866MB
[2024-07-13 19:53:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:22 lr 0.000033	 wd 0.0000	time 0.2596 (0.2229)	loss 1.2737 (1.3771)	grad_norm 0.3797 (nan)	loss_scale 8192.0000 (11180.8347)	mem 5866MB
[2024-07-13 19:53:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000033	 wd 0.0000	time 0.1431 (0.2205)	loss 1.4210 (1.3768)	grad_norm 0.3758 (nan)	loss_scale 8192.0000 (11061.3291)	mem 5866MB
[2024-07-13 19:53:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 11 training takes 0:09:16
[2024-07-13 19:53:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 20.696 (20.696)	Loss 0.4185 (0.4185)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 5866MB
[2024-07-13 19:53:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.778 Acc@5 97.136
[2024-07-13 19:53:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 19:53:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.78%
[2024-07-13 19:53:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saving......
[2024-07-13 19:53:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-13 19:54:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][0/2502]	eta 20:54:17 lr 0.000033	 wd 0.0000	time 30.0788 (30.0788)	loss 1.6430 (1.6430)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:54:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:20:55 lr 0.000033	 wd 0.0000	time 0.1868 (0.5226)	loss 1.5186 (1.3840)	grad_norm 0.3678 (0.3900)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:55:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:13:41 lr 0.000033	 wd 0.0000	time 0.1865 (0.3567)	loss 0.9937 (1.3895)	grad_norm 0.3491 (0.3879)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:55:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:11:03 lr 0.000033	 wd 0.0000	time 0.1874 (0.3013)	loss 1.3161 (1.3889)	grad_norm 0.4069 (0.3845)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:55:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:43 lr 0.000033	 wd 0.0000	time 0.2402 (0.2776)	loss 1.2465 (1.3812)	grad_norm 0.3445 (0.3835)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:56:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:09:45 lr 0.000032	 wd 0.0000	time 0.1889 (0.2923)	loss 1.0126 (1.3817)	grad_norm 0.3566 (0.3845)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:56:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:08:44 lr 0.000032	 wd 0.0000	time 0.1618 (0.2756)	loss 1.3831 (1.3793)	grad_norm 0.3882 (0.3865)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:57:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:54 lr 0.000032	 wd 0.0000	time 0.2068 (0.2633)	loss 1.4802 (1.3771)	grad_norm 0.3887 (0.3861)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:57:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:07:13 lr 0.000032	 wd 0.0000	time 0.2340 (0.2545)	loss 1.4811 (1.3851)	grad_norm 0.3899 (0.3856)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:57:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:55 lr 0.000032	 wd 0.0000	time 0.1902 (0.2595)	loss 1.0553 (1.3855)	grad_norm 0.3846 (0.3876)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:58:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:19 lr 0.000032	 wd 0.0000	time 0.1692 (0.2526)	loss 1.6512 (1.3830)	grad_norm 0.3697 (0.3888)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:58:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:46 lr 0.000032	 wd 0.0000	time 0.1756 (0.2471)	loss 1.5008 (1.3872)	grad_norm 0.3886 (0.3888)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:58:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:15 lr 0.000032	 wd 0.0000	time 0.1964 (0.2423)	loss 1.5355 (1.3860)	grad_norm 0.3838 (0.3882)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:59:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:48 lr 0.000032	 wd 0.0000	time 0.2172 (0.2400)	loss 1.4542 (1.3864)	grad_norm 0.3755 (0.3878)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:59:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:23 lr 0.000032	 wd 0.0000	time 0.2547 (0.2389)	loss 1.6261 (1.3864)	grad_norm 0.3844 (0.3874)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 19:59:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:03:56 lr 0.000032	 wd 0.0000	time 0.1727 (0.2359)	loss 1.4440 (1.3872)	grad_norm 0.3637 (0.3876)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:00:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:30 lr 0.000032	 wd 0.0000	time 0.1711 (0.2334)	loss 1.4394 (1.3860)	grad_norm 0.3637 (0.3874)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:00:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:05 lr 0.000031	 wd 0.0000	time 0.2006 (0.2308)	loss 1.5807 (1.3872)	grad_norm 0.3716 (0.3883)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:00:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:41 lr 0.000031	 wd 0.0000	time 0.2326 (0.2299)	loss 1.3059 (1.3878)	grad_norm 0.4248 (0.3893)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:01:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:18 lr 0.000031	 wd 0.0000	time 0.1985 (0.2302)	loss 1.4439 (1.3874)	grad_norm 0.4019 (0.3892)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:01:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:01:54 lr 0.000031	 wd 0.0000	time 0.2051 (0.2284)	loss 1.4144 (1.3864)	grad_norm 0.3720 (0.3895)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:01:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:31 lr 0.000031	 wd 0.0000	time 0.2024 (0.2268)	loss 1.4577 (1.3876)	grad_norm 0.3951 (0.3894)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:02:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:08 lr 0.000031	 wd 0.0000	time 0.2542 (0.2257)	loss 1.5936 (1.3890)	grad_norm 0.3635 (0.3891)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:02:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:45 lr 0.000031	 wd 0.0000	time 0.4237 (0.2259)	loss 1.4492 (1.3890)	grad_norm 0.3855 (0.3889)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:02:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:22 lr 0.000031	 wd 0.0000	time 0.1619 (0.2249)	loss 1.5160 (1.3888)	grad_norm 0.4070 (0.3887)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:03:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000031	 wd 0.0000	time 0.1492 (0.2223)	loss 1.1374 (1.3876)	grad_norm 0.3735 (0.3890)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:03:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 12 training takes 0:09:20
[2024-07-13 20:03:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 18.472 (18.472)	Loss 0.4187 (0.4187)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 5866MB
[2024-07-13 20:03:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.702 Acc@5 97.156
[2024-07-13 20:03:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 20:03:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.78%
[2024-07-13 20:04:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][0/2502]	eta 1 day, 2:22:18 lr 0.000031	 wd 0.0000	time 37.9450 (37.9450)	loss 1.3899 (1.3899)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:04:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:22:45 lr 0.000031	 wd 0.0000	time 0.1694 (0.5686)	loss 1.4431 (1.3729)	grad_norm 0.3715 (0.3820)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:05:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:14:31 lr 0.000031	 wd 0.0000	time 0.1848 (0.3784)	loss 1.7168 (1.3752)	grad_norm 0.3596 (0.3815)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:05:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:11:44 lr 0.000031	 wd 0.0000	time 0.2403 (0.3198)	loss 1.4623 (1.3844)	grad_norm 0.3930 (0.3807)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:06:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:11:34 lr 0.000030	 wd 0.0000	time 0.1812 (0.3302)	loss 1.3572 (1.3832)	grad_norm 0.3773 (0.3795)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:06:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:10:05 lr 0.000030	 wd 0.0000	time 0.1906 (0.3023)	loss 1.5350 (1.3775)	grad_norm 0.4033 (0.3801)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:06:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:59 lr 0.000030	 wd 0.0000	time 0.1883 (0.2839)	loss 1.5573 (1.3836)	grad_norm 0.3823 (0.3829)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:07:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:08:07 lr 0.000030	 wd 0.0000	time 0.1944 (0.2706)	loss 1.4607 (1.3788)	grad_norm 0.3936 (0.3832)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:07:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:32 lr 0.000030	 wd 0.0000	time 0.1894 (0.2657)	loss 1.5616 (1.3827)	grad_norm 0.3451 (0.3838)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:07:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:06:56 lr 0.000030	 wd 0.0000	time 0.2954 (0.2600)	loss 1.5479 (1.3796)	grad_norm 0.3763 (0.3837)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:08:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:20 lr 0.000030	 wd 0.0000	time 0.1815 (0.2532)	loss 1.6234 (1.3851)	grad_norm 0.3687 (0.3835)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:08:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:47 lr 0.000030	 wd 0.0000	time 0.1845 (0.2480)	loss 1.4120 (1.3868)	grad_norm 0.4181 (0.3838)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:08:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:17 lr 0.000030	 wd 0.0000	time 0.2143 (0.2442)	loss 1.5777 (1.3829)	grad_norm 0.3736 (0.3843)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:09:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:04:53 lr 0.000030	 wd 0.0000	time 0.1753 (0.2438)	loss 1.4597 (1.3816)	grad_norm 0.3576 (0.3855)	loss_scale 16384.0000 (8594.9885)	mem 5866MB
[2024-07-13 20:09:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:24 lr 0.000030	 wd 0.0000	time 0.1737 (0.2403)	loss 1.6765 (1.3823)	grad_norm 0.3765 (0.3855)	loss_scale 16384.0000 (9150.9493)	mem 5866MB
[2024-07-13 20:09:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:03:57 lr 0.000030	 wd 0.0000	time 0.1662 (0.2372)	loss 1.6547 (1.3811)	grad_norm 0.3766 (0.3856)	loss_scale 16384.0000 (9632.8314)	mem 5866MB
[2024-07-13 20:10:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:31 lr 0.000029	 wd 0.0000	time 0.1790 (0.2343)	loss 1.5833 (1.3807)	grad_norm 0.5154 (0.3854)	loss_scale 16384.0000 (10054.5159)	mem 5866MB
[2024-07-13 20:10:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:06 lr 0.000029	 wd 0.0000	time 0.1830 (0.2327)	loss 0.8790 (1.3783)	grad_norm 0.3955 (0.3861)	loss_scale 16384.0000 (10426.6196)	mem 5866MB
[2024-07-13 20:10:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:43 lr 0.000029	 wd 0.0000	time 0.1807 (0.2329)	loss 1.4654 (1.3800)	grad_norm 0.3828 (0.3859)	loss_scale 16384.0000 (10757.4014)	mem 5866MB
[2024-07-13 20:11:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:19 lr 0.000029	 wd 0.0000	time 0.2285 (0.2311)	loss 1.2330 (1.3805)	grad_norm 0.3647 (0.3859)	loss_scale 16384.0000 (11053.3824)	mem 5866MB
[2024-07-13 20:11:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:55 lr 0.000029	 wd 0.0000	time 0.2017 (0.2294)	loss 1.4546 (1.3816)	grad_norm 0.4071 (0.3859)	loss_scale 16384.0000 (11319.7801)	mem 5866MB
[2024-07-13 20:11:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:31 lr 0.000029	 wd 0.0000	time 0.2189 (0.2278)	loss 1.1415 (1.3813)	grad_norm 0.3876 (0.3860)	loss_scale 16384.0000 (11560.8187)	mem 5866MB
[2024-07-13 20:12:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:08 lr 0.000029	 wd 0.0000	time 0.2138 (0.2271)	loss 1.5694 (1.3827)	grad_norm 0.3838 (0.3857)	loss_scale 16384.0000 (11779.9546)	mem 5866MB
[2024-07-13 20:12:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:45 lr 0.000029	 wd 0.0000	time 0.2172 (0.2266)	loss 1.3256 (1.3823)	grad_norm 0.3934 (0.3857)	loss_scale 16384.0000 (11980.0435)	mem 5866MB
[2024-07-13 20:12:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:22 lr 0.000029	 wd 0.0000	time 0.1956 (0.2253)	loss 1.6976 (1.3835)	grad_norm 0.3701 (0.3854)	loss_scale 16384.0000 (12163.4652)	mem 5866MB
[2024-07-13 20:13:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000029	 wd 0.0000	time 0.1344 (0.2227)	loss 1.5672 (1.3828)	grad_norm 0.3558 (0.3858)	loss_scale 16384.0000 (12332.2191)	mem 5866MB
[2024-07-13 20:13:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 13 training takes 0:09:21
[2024-07-13 20:13:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 27.173 (27.173)	Loss 0.4163 (0.4163)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 5866MB
[2024-07-13 20:13:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.764 Acc@5 97.166
[2024-07-13 20:13:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 20:13:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.78%
[2024-07-13 20:14:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][0/2502]	eta 13:01:47 lr 0.000029	 wd 0.0000	time 18.7481 (18.7481)	loss 1.5030 (1.5030)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 20:14:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:14:59 lr 0.000029	 wd 0.0000	time 0.1845 (0.3746)	loss 1.5658 (1.3925)	grad_norm 0.3661 (0.3846)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 20:14:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:10:48 lr 0.000028	 wd 0.0000	time 0.1730 (0.2816)	loss 1.3153 (1.4121)	grad_norm 0.3564 (0.3892)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 20:15:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:10:04 lr 0.000028	 wd 0.0000	time 0.4474 (0.2743)	loss 1.0214 (1.4000)	grad_norm 0.3537 (0.3884)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 20:15:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:09:49 lr 0.000028	 wd 0.0000	time 0.1781 (0.2803)	loss 1.2308 (1.3843)	grad_norm 0.3857 (0.3878)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 20:16:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:08:45 lr 0.000028	 wd 0.0000	time 0.1880 (0.2623)	loss 1.3141 (1.3873)	grad_norm 0.3778 (0.3864)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 20:16:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:07:54 lr 0.000028	 wd 0.0000	time 0.1812 (0.2497)	loss 1.6860 (1.3931)	grad_norm 0.4029 (0.3871)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 20:16:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:17 lr 0.000028	 wd 0.0000	time 0.1939 (0.2430)	loss 1.4570 (1.3890)	grad_norm 0.3836 (0.3859)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 20:17:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:04 lr 0.000028	 wd 0.0000	time 0.1777 (0.2496)	loss 1.3967 (1.3853)	grad_norm 0.3725 (0.3861)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 20:17:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:29 lr 0.000028	 wd 0.0000	time 0.1679 (0.2431)	loss 1.4570 (1.3814)	grad_norm 0.3755 (0.3862)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 20:17:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:05:57 lr 0.000028	 wd 0.0000	time 0.1988 (0.2381)	loss 1.3362 (1.3798)	grad_norm 0.3666 (0.3867)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 20:18:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:27 lr 0.000028	 wd 0.0000	time 0.2209 (0.2339)	loss 1.5075 (1.3774)	grad_norm 0.3460 (0.3879)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 20:18:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:02 lr 0.000028	 wd 0.0000	time 0.2303 (0.2325)	loss 1.4305 (1.3776)	grad_norm 0.3804 (nan)	loss_scale 8192.0000 (16015.6669)	mem 5866MB
[2024-07-13 20:18:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:04:38 lr 0.000027	 wd 0.0000	time 0.1683 (0.2313)	loss 1.2052 (1.3779)	grad_norm 0.3783 (nan)	loss_scale 8192.0000 (15414.3090)	mem 5866MB
[2024-07-13 20:19:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:11 lr 0.000027	 wd 0.0000	time 0.1957 (0.2285)	loss 1.6941 (1.3768)	grad_norm 0.5334 (nan)	loss_scale 8192.0000 (14898.7980)	mem 5866MB
[2024-07-13 20:19:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:03:46 lr 0.000027	 wd 0.0000	time 0.1634 (0.2260)	loss 1.3956 (1.3777)	grad_norm 0.3684 (nan)	loss_scale 8192.0000 (14451.9760)	mem 5866MB
[2024-07-13 20:19:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:22 lr 0.000027	 wd 0.0000	time 0.2456 (0.2241)	loss 1.3332 (1.3776)	grad_norm 0.4241 (nan)	loss_scale 8192.0000 (14060.9719)	mem 5866MB
[2024-07-13 20:20:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:00 lr 0.000027	 wd 0.0000	time 0.1769 (0.2252)	loss 1.2238 (1.3768)	grad_norm 0.3924 (nan)	loss_scale 8192.0000 (13715.9412)	mem 5866MB
[2024-07-13 20:20:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:37 lr 0.000027	 wd 0.0000	time 0.1881 (0.2243)	loss 1.3296 (1.3766)	grad_norm 0.3760 (nan)	loss_scale 8192.0000 (13409.2260)	mem 5866MB
[2024-07-13 20:21:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:14 lr 0.000027	 wd 0.0000	time 0.1822 (0.2226)	loss 1.5771 (1.3768)	grad_norm 0.3870 (nan)	loss_scale 8192.0000 (13134.7796)	mem 5866MB
[2024-07-13 20:21:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:01:51 lr 0.000027	 wd 0.0000	time 0.1664 (0.2211)	loss 1.0878 (1.3787)	grad_norm 0.3729 (nan)	loss_scale 8192.0000 (12887.7641)	mem 5866MB
[2024-07-13 20:21:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:28 lr 0.000027	 wd 0.0000	time 0.2100 (0.2205)	loss 1.5970 (1.3784)	grad_norm 0.4107 (nan)	loss_scale 8192.0000 (12664.2627)	mem 5866MB
[2024-07-13 20:22:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:06 lr 0.000027	 wd 0.0000	time 0.1912 (0.2206)	loss 1.2133 (1.3786)	grad_norm 0.3819 (nan)	loss_scale 8192.0000 (12461.0704)	mem 5866MB
[2024-07-13 20:22:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:44 lr 0.000027	 wd 0.0000	time 0.2000 (0.2197)	loss 1.4190 (1.3795)	grad_norm 2.4054 (nan)	loss_scale 8192.0000 (12275.5393)	mem 5866MB
[2024-07-13 20:22:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:22 lr 0.000026	 wd 0.0000	time 0.1836 (0.2186)	loss 1.1335 (1.3805)	grad_norm 0.5631 (nan)	loss_scale 8192.0000 (12105.4627)	mem 5866MB
[2024-07-13 20:22:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1463 (0.2164)	loss 1.2628 (1.3795)	grad_norm 0.4975 (nan)	loss_scale 8192.0000 (11948.9868)	mem 5866MB
[2024-07-13 20:23:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 14 training takes 0:09:05
[2024-07-13 20:23:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 38.539 (38.539)	Loss 0.4153 (0.4153)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 5866MB
[2024-07-13 20:23:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.752 Acc@5 97.154
[2024-07-13 20:23:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 20:23:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.78%
[2024-07-13 20:24:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][0/2502]	eta 10:45:27 lr 0.000026	 wd 0.0000	time 15.4785 (15.4785)	loss 1.4884 (1.4884)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:24:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:14:14 lr 0.000026	 wd 0.0000	time 0.1636 (0.3556)	loss 1.0237 (1.3665)	grad_norm 0.3701 (0.3830)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:24:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:10:51 lr 0.000026	 wd 0.0000	time 0.3791 (0.2830)	loss 1.4782 (1.3810)	grad_norm 0.3817 (0.3813)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:25:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:11:14 lr 0.000026	 wd 0.0000	time 0.1859 (0.3064)	loss 1.4018 (1.3683)	grad_norm 0.3655 (0.3873)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:25:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:09:43 lr 0.000026	 wd 0.0000	time 0.1914 (0.2775)	loss 1.4289 (1.3720)	grad_norm 0.5211 (0.3894)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:26:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:08:39 lr 0.000026	 wd 0.0000	time 0.1640 (0.2597)	loss 0.8782 (1.3698)	grad_norm 0.3703 (0.3889)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:26:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:07:53 lr 0.000026	 wd 0.0000	time 0.2490 (0.2489)	loss 0.8511 (1.3736)	grad_norm 0.3729 (0.3930)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:26:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:54 lr 0.000026	 wd 0.0000	time 0.1818 (0.2631)	loss 1.1050 (1.3762)	grad_norm 0.4114 (0.3921)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:27:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:07:12 lr 0.000026	 wd 0.0000	time 0.1949 (0.2538)	loss 1.4411 (1.3767)	grad_norm 0.3662 (0.3913)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:27:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:35 lr 0.000025	 wd 0.0000	time 0.1848 (0.2467)	loss 1.2370 (1.3775)	grad_norm 0.3794 (0.3914)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:27:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:06:01 lr 0.000025	 wd 0.0000	time 0.2379 (0.2408)	loss 1.4652 (1.3789)	grad_norm 0.4785 (0.3905)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:28:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:48 lr 0.000025	 wd 0.0000	time 0.1975 (0.2482)	loss 1.2717 (1.3760)	grad_norm 0.3688 (0.3897)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:28:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:17 lr 0.000025	 wd 0.0000	time 0.1597 (0.2440)	loss 1.4274 (1.3767)	grad_norm 0.3559 (0.3892)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:29:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:04:48 lr 0.000025	 wd 0.0000	time 0.1982 (0.2398)	loss 1.4109 (1.3750)	grad_norm 0.3904 (0.3894)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:29:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:20 lr 0.000025	 wd 0.0000	time 0.1884 (0.2363)	loss 1.4627 (1.3753)	grad_norm 0.3786 (0.3888)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:29:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:03:54 lr 0.000025	 wd 0.0000	time 0.2183 (0.2343)	loss 1.5913 (1.3750)	grad_norm 0.4369 (0.3884)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:30:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:31 lr 0.000025	 wd 0.0000	time 0.1778 (0.2344)	loss 1.3013 (1.3773)	grad_norm 0.3717 (0.3891)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:30:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:06 lr 0.000025	 wd 0.0000	time 0.1867 (0.2323)	loss 1.4572 (1.3765)	grad_norm 0.3765 (0.3889)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:30:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:41 lr 0.000025	 wd 0.0000	time 0.2142 (0.2303)	loss 1.1032 (1.3761)	grad_norm 0.3959 (0.3884)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:31:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:17 lr 0.000024	 wd 0.0000	time 0.2139 (0.2284)	loss 1.6333 (1.3766)	grad_norm 0.3730 (0.3881)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:31:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:01:54 lr 0.000024	 wd 0.0000	time 0.2218 (0.2278)	loss 1.8732 (1.3788)	grad_norm 0.4205 (0.3880)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:31:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:31 lr 0.000024	 wd 0.0000	time 0.1868 (0.2277)	loss 1.5518 (1.3796)	grad_norm 0.3775 (0.3877)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:32:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:08 lr 0.000024	 wd 0.0000	time 0.1761 (0.2261)	loss 1.0968 (1.3807)	grad_norm 0.3504 (0.3877)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:32:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:45 lr 0.000024	 wd 0.0000	time 0.1913 (0.2247)	loss 1.6118 (1.3808)	grad_norm 0.3869 (0.3874)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:32:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:22 lr 0.000024	 wd 0.0000	time 0.2014 (0.2236)	loss 1.0778 (1.3796)	grad_norm 0.3957 (0.3874)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:33:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1535 (0.2217)	loss 1.2458 (1.3798)	grad_norm 0.3779 (0.3872)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:33:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 15 training takes 0:09:21
[2024-07-13 20:33:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_15.pth saving......
[2024-07-13 20:33:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_15.pth saved !!!
[2024-07-13 20:33:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 28.438 (28.438)	Loss 0.4136 (0.4136)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 5866MB
[2024-07-13 20:33:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.734 Acc@5 97.152
[2024-07-13 20:33:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 20:33:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.78%
[2024-07-13 20:34:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][0/2502]	eta 11:38:43 lr 0.000024	 wd 0.0000	time 16.7561 (16.7561)	loss 1.2846 (1.2846)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:34:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:14:58 lr 0.000024	 wd 0.0000	time 0.2452 (0.3743)	loss 1.4929 (1.3741)	grad_norm 0.3891 (0.3909)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:34:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:11:41 lr 0.000024	 wd 0.0000	time 0.1829 (0.3047)	loss 1.3350 (1.3830)	grad_norm 0.3881 (0.3922)	loss_scale 16384.0000 (10555.8607)	mem 5866MB
[2024-07-13 20:35:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:09:49 lr 0.000024	 wd 0.0000	time 0.1636 (0.2677)	loss 1.3878 (1.3950)	grad_norm 0.3637 (0.3899)	loss_scale 16384.0000 (12492.1196)	mem 5866MB
[2024-07-13 20:35:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:08:41 lr 0.000024	 wd 0.0000	time 0.2002 (0.2482)	loss 1.2743 (1.3887)	grad_norm 0.3741 (0.3876)	loss_scale 16384.0000 (13462.6633)	mem 5866MB
[2024-07-13 20:35:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:07:52 lr 0.000023	 wd 0.0000	time 0.1740 (0.2359)	loss 1.2852 (1.3991)	grad_norm 0.3524 (0.3887)	loss_scale 16384.0000 (14045.7645)	mem 5866MB
[2024-07-13 20:36:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:07:41 lr 0.000023	 wd 0.0000	time 0.1287 (0.2426)	loss 1.0610 (1.3915)	grad_norm 0.3743 (0.3894)	loss_scale 16384.0000 (14434.8220)	mem 5866MB
[2024-07-13 20:36:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:23 lr 0.000023	 wd 0.0000	time 0.2061 (0.2462)	loss 1.3538 (1.3932)	grad_norm 0.4008 (0.3892)	loss_scale 16384.0000 (14712.8787)	mem 5866MB
[2024-07-13 20:37:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:06:47 lr 0.000023	 wd 0.0000	time 0.1673 (0.2391)	loss 1.4053 (1.3874)	grad_norm 0.3551 (0.3886)	loss_scale 16384.0000 (14921.5081)	mem 5866MB
[2024-07-13 20:37:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:13 lr 0.000023	 wd 0.0000	time 0.1774 (0.2333)	loss 1.5883 (1.3853)	grad_norm 0.3981 (0.3898)	loss_scale 16384.0000 (15083.8269)	mem 5866MB
[2024-07-13 20:37:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:05:46 lr 0.000023	 wd 0.0000	time 0.2264 (0.2306)	loss 1.5805 (1.3854)	grad_norm 0.4103 (nan)	loss_scale 8192.0000 (14624.4795)	mem 5866MB
[2024-07-13 20:38:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:29 lr 0.000023	 wd 0.0000	time 0.1832 (0.2353)	loss 1.3596 (1.3864)	grad_norm 0.3933 (nan)	loss_scale 8192.0000 (14040.2398)	mem 5866MB
[2024-07-13 20:38:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:01 lr 0.000023	 wd 0.0000	time 0.1752 (0.2313)	loss 1.4813 (1.3878)	grad_norm 0.3833 (nan)	loss_scale 8192.0000 (13553.2923)	mem 5866MB
[2024-07-13 20:38:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:04:34 lr 0.000023	 wd 0.0000	time 0.1710 (0.2284)	loss 1.1029 (1.3882)	grad_norm 0.3726 (nan)	loss_scale 8192.0000 (13141.2022)	mem 5866MB
[2024-07-13 20:39:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:08 lr 0.000023	 wd 0.0000	time 0.2148 (0.2256)	loss 1.2082 (1.3855)	grad_norm 0.3727 (nan)	loss_scale 8192.0000 (12787.9400)	mem 5866MB
[2024-07-13 20:39:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:03:45 lr 0.000022	 wd 0.0000	time 0.1954 (0.2250)	loss 1.4038 (1.3824)	grad_norm 0.3783 (nan)	loss_scale 8192.0000 (12481.7482)	mem 5866MB
[2024-07-13 20:39:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:23 lr 0.000022	 wd 0.0000	time 0.1721 (0.2251)	loss 1.4105 (1.3828)	grad_norm 0.3787 (nan)	loss_scale 8192.0000 (12213.8064)	mem 5866MB
[2024-07-13 20:40:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:02:59 lr 0.000022	 wd 0.0000	time 0.1714 (0.2233)	loss 1.1159 (1.3807)	grad_norm 0.3945 (nan)	loss_scale 8192.0000 (11977.3686)	mem 5866MB
[2024-07-13 20:40:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:35 lr 0.000022	 wd 0.0000	time 0.1991 (0.2217)	loss 1.2676 (1.3791)	grad_norm 0.4175 (nan)	loss_scale 8192.0000 (11767.1871)	mem 5866MB
[2024-07-13 20:40:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:12 lr 0.000022	 wd 0.0000	time 0.1893 (0.2205)	loss 1.2037 (1.3780)	grad_norm 0.3610 (nan)	loss_scale 8192.0000 (11579.1184)	mem 5866MB
[2024-07-13 20:41:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:01:50 lr 0.000022	 wd 0.0000	time 0.1830 (0.2210)	loss 1.5041 (1.3783)	grad_norm 0.3759 (nan)	loss_scale 8192.0000 (11409.8471)	mem 5866MB
[2024-07-13 20:41:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:28 lr 0.000022	 wd 0.0000	time 0.1590 (0.2203)	loss 1.3651 (1.3778)	grad_norm 0.3863 (nan)	loss_scale 8192.0000 (11256.6892)	mem 5866MB
[2024-07-13 20:42:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:06 lr 0.000022	 wd 0.0000	time 0.1933 (0.2191)	loss 1.4837 (1.3785)	grad_norm 0.3690 (nan)	loss_scale 8192.0000 (11117.4484)	mem 5866MB
[2024-07-13 20:42:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:43 lr 0.000022	 wd 0.0000	time 0.2092 (0.2178)	loss 1.2296 (1.3785)	grad_norm 0.3766 (nan)	loss_scale 8192.0000 (10990.3103)	mem 5866MB
[2024-07-13 20:42:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:22 lr 0.000022	 wd 0.0000	time 0.1924 (0.2173)	loss 1.5665 (1.3786)	grad_norm 0.3771 (nan)	loss_scale 8192.0000 (10873.7626)	mem 5866MB
[2024-07-13 20:42:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1421 (0.2154)	loss 1.4122 (1.3785)	grad_norm 0.3634 (nan)	loss_scale 8192.0000 (10766.5350)	mem 5866MB
[2024-07-13 20:43:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 16 training takes 0:09:09
[2024-07-13 20:43:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 20.846 (20.846)	Loss 0.4146 (0.4146)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 5866MB
[2024-07-13 20:43:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.784 Acc@5 97.122
[2024-07-13 20:43:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 20:43:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.78%
[2024-07-13 20:43:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saving......
[2024-07-13 20:43:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-13 20:43:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][0/2502]	eta 10:33:32 lr 0.000021	 wd 0.0000	time 15.1929 (15.1929)	loss 1.4679 (1.4679)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:44:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:15:26 lr 0.000021	 wd 0.0000	time 0.2913 (0.3857)	loss 1.5783 (1.3521)	grad_norm 0.3875 (0.3803)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:44:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:12:03 lr 0.000021	 wd 0.0000	time 0.1869 (0.3143)	loss 1.5952 (1.3680)	grad_norm 0.3995 (0.3872)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:45:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:00 lr 0.000021	 wd 0.0000	time 0.1669 (0.2725)	loss 1.3472 (1.3645)	grad_norm 0.3903 (0.3871)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:45:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:08:48 lr 0.000021	 wd 0.0000	time 0.1833 (0.2516)	loss 1.1570 (1.3587)	grad_norm 0.3591 (0.3860)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:45:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:07:59 lr 0.000021	 wd 0.0000	time 0.2285 (0.2393)	loss 1.3869 (1.3585)	grad_norm 0.3767 (0.3854)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:46:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:11 lr 0.000021	 wd 0.0000	time 0.2757 (0.2586)	loss 1.1911 (1.3654)	grad_norm 0.3951 (0.3854)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:46:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:28 lr 0.000021	 wd 0.0000	time 0.1982 (0.2491)	loss 1.3581 (1.3714)	grad_norm 0.3592 (0.3854)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:46:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:06:52 lr 0.000021	 wd 0.0000	time 0.2207 (0.2422)	loss 1.4090 (1.3755)	grad_norm 0.3881 (0.3855)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:47:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:18 lr 0.000021	 wd 0.0000	time 0.1990 (0.2360)	loss 1.6236 (1.3771)	grad_norm 0.3743 (0.3862)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:47:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:05:54 lr 0.000020	 wd 0.0000	time 0.2312 (0.2359)	loss 1.5681 (1.3755)	grad_norm 0.3803 (0.3873)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:48:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:29 lr 0.000020	 wd 0.0000	time 0.2050 (0.2351)	loss 1.1407 (1.3758)	grad_norm 0.3640 (0.3881)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:48:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:01 lr 0.000020	 wd 0.0000	time 0.1834 (0.2315)	loss 1.6378 (1.3776)	grad_norm 0.3665 (0.3882)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:48:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:04:34 lr 0.000020	 wd 0.0000	time 0.1829 (0.2284)	loss 1.1934 (1.3777)	grad_norm 0.4164 (0.3885)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:49:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:09 lr 0.000020	 wd 0.0000	time 0.2127 (0.2260)	loss 1.4949 (1.3785)	grad_norm 0.3867 (0.3885)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:49:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:03:48 lr 0.000020	 wd 0.0000	time 0.1853 (0.2276)	loss 1.4093 (1.3792)	grad_norm 0.4049 (0.3886)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:49:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:23 lr 0.000020	 wd 0.0000	time 0.1843 (0.2259)	loss 1.5777 (1.3805)	grad_norm 0.3707 (0.3886)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:50:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:02:59 lr 0.000020	 wd 0.0000	time 0.1760 (0.2240)	loss 1.5835 (1.3825)	grad_norm 0.5672 (0.3886)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:50:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:36 lr 0.000020	 wd 0.0000	time 0.1917 (0.2223)	loss 1.3284 (1.3832)	grad_norm 0.3887 (0.3888)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:50:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:13 lr 0.000020	 wd 0.0000	time 0.1879 (0.2216)	loss 1.1719 (1.3840)	grad_norm 0.3691 (0.3885)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:51:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:01:51 lr 0.000019	 wd 0.0000	time 0.1657 (0.2224)	loss 1.5902 (1.3819)	grad_norm 0.4095 (0.3883)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:51:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:28 lr 0.000019	 wd 0.0000	time 0.1734 (0.2212)	loss 1.4603 (1.3817)	grad_norm 0.3724 (0.3880)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:51:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:06 lr 0.000019	 wd 0.0000	time 0.1820 (0.2199)	loss 1.3516 (1.3828)	grad_norm 0.3591 (0.3878)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:52:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:44 lr 0.000019	 wd 0.0000	time 0.1975 (0.2186)	loss 1.4876 (1.3822)	grad_norm 0.3849 (0.3882)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:52:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:22 lr 0.000019	 wd 0.0000	time 0.1939 (0.2184)	loss 1.4812 (1.3808)	grad_norm 0.3896 (0.3886)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 20:52:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000019	 wd 0.0000	time 0.1479 (0.2175)	loss 1.5365 (1.3813)	grad_norm 0.3715 (0.3884)	loss_scale 16384.0000 (8434.3862)	mem 5866MB
[2024-07-13 20:52:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 17 training takes 0:09:13
[2024-07-13 20:53:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 23.217 (23.217)	Loss 0.4143 (0.4143)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 5866MB
[2024-07-13 20:53:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.776 Acc@5 97.136
[2024-07-13 20:53:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 20:53:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.78%
[2024-07-13 20:53:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][0/2502]	eta 15:49:36 lr 0.000019	 wd 0.0000	time 22.7726 (22.7726)	loss 1.6133 (1.6133)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 20:54:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:18:18 lr 0.000019	 wd 0.0000	time 0.1970 (0.4574)	loss 1.5797 (1.4221)	grad_norm 0.3706 (0.3821)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 20:54:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:12:29 lr 0.000019	 wd 0.0000	time 0.1699 (0.3254)	loss 1.5036 (1.4022)	grad_norm 0.3664 (0.3826)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 20:55:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:10:17 lr 0.000019	 wd 0.0000	time 0.1922 (0.2804)	loss 1.7290 (1.4010)	grad_norm 0.3706 (0.3869)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 20:55:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:09:01 lr 0.000019	 wd 0.0000	time 0.2052 (0.2574)	loss 1.4652 (1.3939)	grad_norm 0.3960 (nan)	loss_scale 8192.0000 (16138.8529)	mem 5866MB
[2024-07-13 20:55:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:08:46 lr 0.000018	 wd 0.0000	time 0.1485 (0.2629)	loss 1.3156 (1.3832)	grad_norm 0.3806 (nan)	loss_scale 8192.0000 (14552.6547)	mem 5866MB
[2024-07-13 20:56:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:08:25 lr 0.000018	 wd 0.0000	time 0.1710 (0.2659)	loss 1.6669 (1.3841)	grad_norm 0.3510 (nan)	loss_scale 8192.0000 (13494.3095)	mem 5866MB
[2024-07-13 20:56:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:07:39 lr 0.000018	 wd 0.0000	time 0.2014 (0.2553)	loss 1.4606 (1.3846)	grad_norm 0.3553 (nan)	loss_scale 8192.0000 (12737.9173)	mem 5866MB
[2024-07-13 20:56:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:06:59 lr 0.000018	 wd 0.0000	time 0.1698 (0.2467)	loss 1.1109 (1.3822)	grad_norm 0.4320 (nan)	loss_scale 8192.0000 (12170.3870)	mem 5866MB
[2024-07-13 20:57:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:06:34 lr 0.000018	 wd 0.0000	time 0.3182 (0.2464)	loss 1.1865 (1.3782)	grad_norm 0.4254 (nan)	loss_scale 8192.0000 (11728.8346)	mem 5866MB
[2024-07-13 20:57:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:12 lr 0.000018	 wd 0.0000	time 0.1983 (0.2483)	loss 1.0498 (1.3816)	grad_norm 0.3670 (nan)	loss_scale 8192.0000 (11375.5045)	mem 5866MB
[2024-07-13 20:58:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:40 lr 0.000018	 wd 0.0000	time 0.1850 (0.2428)	loss 1.3003 (1.3811)	grad_norm 0.3548 (nan)	loss_scale 8192.0000 (11086.3579)	mem 5866MB
[2024-07-13 20:58:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:10 lr 0.000018	 wd 0.0000	time 0.1734 (0.2385)	loss 1.6730 (1.3814)	grad_norm 0.3925 (nan)	loss_scale 8192.0000 (10845.3622)	mem 5866MB
[2024-07-13 20:58:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:04:43 lr 0.000018	 wd 0.0000	time 0.2241 (0.2356)	loss 1.4343 (1.3820)	grad_norm 0.3817 (nan)	loss_scale 8192.0000 (10641.4143)	mem 5866MB
[2024-07-13 20:59:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:19 lr 0.000018	 wd 0.0000	time 0.1762 (0.2357)	loss 1.2397 (1.3819)	grad_norm 0.3945 (nan)	loss_scale 8192.0000 (10466.5810)	mem 5866MB
[2024-07-13 20:59:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:03:53 lr 0.000017	 wd 0.0000	time 0.1765 (0.2331)	loss 1.6129 (1.3808)	grad_norm 0.3650 (nan)	loss_scale 8192.0000 (10315.0433)	mem 5866MB
[2024-07-13 20:59:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:27 lr 0.000017	 wd 0.0000	time 0.1730 (0.2306)	loss 1.4993 (1.3802)	grad_norm 0.3829 (nan)	loss_scale 8192.0000 (10182.4360)	mem 5866MB
[2024-07-13 21:00:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:03 lr 0.000017	 wd 0.0000	time 0.1951 (0.2283)	loss 1.4902 (1.3804)	grad_norm 0.3966 (nan)	loss_scale 8192.0000 (10065.4203)	mem 5866MB
[2024-07-13 21:00:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:39 lr 0.000017	 wd 0.0000	time 0.2611 (0.2271)	loss 1.3550 (1.3813)	grad_norm 0.3775 (nan)	loss_scale 8192.0000 (9961.3992)	mem 5866MB
[2024-07-13 21:00:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:17 lr 0.000017	 wd 0.0000	time 0.1676 (0.2279)	loss 1.5067 (1.3805)	grad_norm 0.3718 (nan)	loss_scale 8192.0000 (9868.3219)	mem 5866MB
[2024-07-13 21:01:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:01:53 lr 0.000017	 wd 0.0000	time 0.1891 (0.2264)	loss 1.3995 (1.3826)	grad_norm 0.3742 (nan)	loss_scale 8192.0000 (9784.5477)	mem 5866MB
[2024-07-13 21:01:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:30 lr 0.000017	 wd 0.0000	time 0.1426 (0.2249)	loss 1.4562 (1.3820)	grad_norm 0.3735 (nan)	loss_scale 8192.0000 (9708.7482)	mem 5866MB
[2024-07-13 21:01:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:07 lr 0.000017	 wd 0.0000	time 0.1913 (0.2233)	loss 1.3669 (1.3820)	grad_norm 0.4258 (nan)	loss_scale 8192.0000 (9639.8364)	mem 5866MB
[2024-07-13 21:02:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:45 lr 0.000017	 wd 0.0000	time 0.2426 (0.2229)	loss 1.5154 (1.3823)	grad_norm 0.3637 (nan)	loss_scale 8192.0000 (9576.9144)	mem 5866MB
[2024-07-13 21:02:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:22 lr 0.000017	 wd 0.0000	time 0.2345 (0.2231)	loss 1.5578 (1.3837)	grad_norm 0.3768 (nan)	loss_scale 8192.0000 (9519.2337)	mem 5866MB
[2024-07-13 21:02:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1347 (0.2207)	loss 1.5204 (1.3832)	grad_norm 0.3862 (nan)	loss_scale 8192.0000 (9466.1655)	mem 5866MB
[2024-07-13 21:02:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 18 training takes 0:09:18
[2024-07-13 21:03:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 20.279 (20.279)	Loss 0.4148 (0.4148)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 5866MB
[2024-07-13 21:03:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.772 Acc@5 97.132
[2024-07-13 21:03:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 21:03:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.78%
[2024-07-13 21:04:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][0/2502]	eta 1 day, 2:12:36 lr 0.000016	 wd 0.0000	time 37.7124 (37.7124)	loss 1.4692 (1.4692)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:04:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:22:35 lr 0.000016	 wd 0.0000	time 0.1857 (0.5645)	loss 1.1090 (1.3942)	grad_norm 0.3962 (0.3951)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:04:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:14:28 lr 0.000016	 wd 0.0000	time 0.2246 (0.3772)	loss 1.4645 (1.3882)	grad_norm 0.3792 (0.3997)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:05:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:11:38 lr 0.000016	 wd 0.0000	time 0.2458 (0.3174)	loss 1.3052 (1.4015)	grad_norm 0.3626 (0.3950)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:05:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:11:29 lr 0.000016	 wd 0.0000	time 0.2761 (0.3281)	loss 1.5600 (1.4004)	grad_norm 0.5471 (0.3964)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:06:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:10:03 lr 0.000016	 wd 0.0000	time 0.2152 (0.3013)	loss 1.5591 (1.3957)	grad_norm 0.4155 (0.3934)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:06:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:57 lr 0.000016	 wd 0.0000	time 0.1925 (0.2827)	loss 1.5236 (1.3906)	grad_norm 0.3731 (0.3919)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:06:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:08:05 lr 0.000016	 wd 0.0000	time 0.2300 (0.2697)	loss 1.6974 (1.3926)	grad_norm 0.3959 (0.3920)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:07:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:07:54 lr 0.000016	 wd 0.0000	time 0.2326 (0.2786)	loss 1.3716 (1.3913)	grad_norm 0.3863 (0.3915)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:07:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:07:11 lr 0.000016	 wd 0.0000	time 0.1725 (0.2693)	loss 1.2664 (1.3910)	grad_norm 0.3924 (0.3914)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:07:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:32 lr 0.000016	 wd 0.0000	time 0.1774 (0.2613)	loss 1.6115 (1.3919)	grad_norm 0.4316 (0.3907)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:08:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:57 lr 0.000015	 wd 0.0000	time 0.1742 (0.2547)	loss 0.9392 (1.3905)	grad_norm 0.3749 (0.3913)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:08:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:28 lr 0.000015	 wd 0.0000	time 0.1922 (0.2520)	loss 1.1383 (1.3887)	grad_norm 0.3957 (0.3910)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:08:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:05:01 lr 0.000015	 wd 0.0000	time 0.1619 (0.2511)	loss 1.6263 (1.3893)	grad_norm 0.4549 (0.3903)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:09:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:32 lr 0.000015	 wd 0.0000	time 0.1850 (0.2470)	loss 1.4837 (1.3903)	grad_norm 0.3967 (0.3899)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:09:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:04:03 lr 0.000015	 wd 0.0000	time 0.1712 (0.2433)	loss 1.2289 (1.3900)	grad_norm 0.6573 (0.3898)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:09:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:36 lr 0.000015	 wd 0.0000	time 0.2182 (0.2404)	loss 1.3432 (1.3903)	grad_norm 0.3770 (0.3898)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:10:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:12 lr 0.000015	 wd 0.0000	time 0.1799 (0.2401)	loss 1.4151 (1.3910)	grad_norm 0.3738 (0.3898)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:10:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:47 lr 0.000015	 wd 0.0000	time 0.1937 (0.2382)	loss 1.3477 (1.3905)	grad_norm 0.3930 (0.3896)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:11:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:22 lr 0.000015	 wd 0.0000	time 0.2228 (0.2360)	loss 1.4288 (1.3910)	grad_norm 0.3603 (0.3893)	loss_scale 16384.0000 (8252.3304)	mem 5866MB
[2024-07-13 21:11:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:57 lr 0.000015	 wd 0.0000	time 0.1825 (0.2337)	loss 1.0800 (1.3905)	grad_norm 0.4039 (0.3889)	loss_scale 16384.0000 (8658.7106)	mem 5866MB
[2024-07-13 21:11:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:33 lr 0.000014	 wd 0.0000	time 0.2577 (0.2324)	loss 1.2146 (1.3893)	grad_norm 0.3940 (0.3888)	loss_scale 16384.0000 (9026.4065)	mem 5866MB
[2024-07-13 21:12:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:10 lr 0.000014	 wd 0.0000	time 0.1831 (0.2322)	loss 1.4950 (1.3871)	grad_norm 0.3900 (0.3890)	loss_scale 16384.0000 (9360.6906)	mem 5866MB
[2024-07-13 21:12:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:46 lr 0.000014	 wd 0.0000	time 0.1826 (0.2308)	loss 1.4352 (1.3867)	grad_norm 0.4051 (0.3888)	loss_scale 16384.0000 (9665.9192)	mem 5866MB
[2024-07-13 21:12:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:23 lr 0.000014	 wd 0.0000	time 0.1540 (0.2293)	loss 1.5813 (1.3881)	grad_norm 0.3722 (0.3889)	loss_scale 16384.0000 (9945.7226)	mem 5866MB
[2024-07-13 21:12:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1394 (0.2265)	loss 1.2580 (1.3880)	grad_norm 0.3933 (0.3889)	loss_scale 16384.0000 (10203.1507)	mem 5866MB
[2024-07-13 21:13:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 19 training takes 0:09:34
[2024-07-13 21:13:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 38.310 (38.310)	Loss 0.4148 (0.4148)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 5866MB
[2024-07-13 21:14:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.786 Acc@5 97.136
[2024-07-13 21:14:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 21:14:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.79%
[2024-07-13 21:14:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saving......
[2024-07-13 21:14:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-13 21:14:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][0/2502]	eta 10:44:35 lr 0.000014	 wd 0.0000	time 15.4579 (15.4579)	loss 0.9910 (0.9910)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 21:14:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:13:42 lr 0.000014	 wd 0.0000	time 0.1925 (0.3425)	loss 1.6072 (1.3844)	grad_norm 0.3722 (0.3910)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 21:15:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:13:44 lr 0.000014	 wd 0.0000	time 0.2562 (0.3580)	loss 1.4453 (1.3853)	grad_norm 0.4069 (0.3845)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 21:15:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:11:14 lr 0.000014	 wd 0.0000	time 0.1842 (0.3065)	loss 1.4940 (1.3819)	grad_norm 0.3801 (0.3827)	loss_scale 16384.0000 (16384.0000)	mem 5866MB
[2024-07-13 21:15:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:09:42 lr 0.000014	 wd 0.0000	time 0.1584 (0.2773)	loss 1.4338 (1.3915)	grad_norm 0.3742 (nan)	loss_scale 8192.0000 (15239.9800)	mem 5866MB
[2024-07-13 21:16:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:08:38 lr 0.000014	 wd 0.0000	time 0.1715 (0.2590)	loss 1.5697 (1.3935)	grad_norm 0.3761 (nan)	loss_scale 8192.0000 (13833.1976)	mem 5866MB
[2024-07-13 21:16:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:08:13 lr 0.000014	 wd 0.0000	time 0.3693 (0.2594)	loss 1.3534 (1.3896)	grad_norm 0.3714 (nan)	loss_scale 8192.0000 (12894.5624)	mem 5866MB
[2024-07-13 21:17:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:46 lr 0.000013	 wd 0.0000	time 0.1858 (0.2587)	loss 1.4978 (1.3916)	grad_norm 0.3765 (nan)	loss_scale 8192.0000 (12223.7261)	mem 5866MB
[2024-07-13 21:17:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:07:05 lr 0.000013	 wd 0.0000	time 0.1894 (0.2502)	loss 1.2781 (1.3888)	grad_norm 0.3599 (nan)	loss_scale 8192.0000 (11720.3895)	mem 5866MB
[2024-07-13 21:17:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:30 lr 0.000013	 wd 0.0000	time 0.2001 (0.2437)	loss 1.6249 (1.3916)	grad_norm 0.3613 (nan)	loss_scale 8192.0000 (11328.7814)	mem 5866MB
[2024-07-13 21:18:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:00 lr 0.000013	 wd 0.0000	time 0.2809 (0.2403)	loss 1.3175 (1.3905)	grad_norm 0.3698 (nan)	loss_scale 8192.0000 (11015.4166)	mem 5866MB
[2024-07-13 21:18:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:47 lr 0.000013	 wd 0.0000	time 0.2010 (0.2482)	loss 1.3735 (1.3881)	grad_norm 0.3806 (nan)	loss_scale 8192.0000 (10758.9755)	mem 5866MB
[2024-07-13 21:18:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:16 lr 0.000013	 wd 0.0000	time 0.1784 (0.2434)	loss 1.4583 (1.3849)	grad_norm 0.3722 (nan)	loss_scale 8192.0000 (10545.2390)	mem 5866MB
[2024-07-13 21:19:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:04:47 lr 0.000013	 wd 0.0000	time 0.1893 (0.2392)	loss 1.3422 (1.3836)	grad_norm 0.3842 (nan)	loss_scale 8192.0000 (10364.3597)	mem 5866MB
[2024-07-13 21:19:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:20 lr 0.000013	 wd 0.0000	time 0.2014 (0.2360)	loss 1.4257 (1.3854)	grad_norm 0.3823 (nan)	loss_scale 8192.0000 (10209.3019)	mem 5866MB
[2024-07-13 21:20:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:04:02 lr 0.000013	 wd 0.0000	time 0.1955 (0.2425)	loss 1.4569 (1.3860)	grad_norm 0.4054 (nan)	loss_scale 8192.0000 (10074.9047)	mem 5866MB
[2024-07-13 21:20:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:35 lr 0.000013	 wd 0.0000	time 0.1708 (0.2393)	loss 1.7211 (1.3864)	grad_norm 0.4244 (nan)	loss_scale 8192.0000 (9957.2967)	mem 5866MB
[2024-07-13 21:20:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:09 lr 0.000012	 wd 0.0000	time 0.1800 (0.2365)	loss 1.5474 (1.3859)	grad_norm 0.3529 (nan)	loss_scale 8192.0000 (9853.5168)	mem 5866MB
[2024-07-13 21:21:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:44 lr 0.000012	 wd 0.0000	time 0.2403 (0.2341)	loss 1.3285 (1.3852)	grad_norm 0.3730 (nan)	loss_scale 8192.0000 (9761.2615)	mem 5866MB
[2024-07-13 21:21:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:20 lr 0.000012	 wd 0.0000	time 0.1967 (0.2329)	loss 1.5608 (1.3871)	grad_norm 0.3612 (nan)	loss_scale 4096.0000 (9523.5771)	mem 5866MB
[2024-07-13 21:21:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:01:56 lr 0.000012	 wd 0.0000	time 0.1785 (0.2327)	loss 1.5219 (1.3866)	grad_norm 0.3814 (nan)	loss_scale 4096.0000 (9252.3338)	mem 5866MB
[2024-07-13 21:22:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:32 lr 0.000012	 wd 0.0000	time 0.1935 (0.2311)	loss 1.3459 (1.3873)	grad_norm 0.3629 (nan)	loss_scale 4096.0000 (9006.9110)	mem 5866MB
[2024-07-13 21:22:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:09 lr 0.000012	 wd 0.0000	time 0.1708 (0.2294)	loss 1.2838 (1.3888)	grad_norm 0.3926 (nan)	loss_scale 4096.0000 (8783.7892)	mem 5866MB
[2024-07-13 21:22:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:46 lr 0.000012	 wd 0.0000	time 0.1720 (0.2280)	loss 1.4172 (1.3888)	grad_norm 0.3940 (nan)	loss_scale 4096.0000 (8580.0608)	mem 5866MB
[2024-07-13 21:23:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:23 lr 0.000012	 wd 0.0000	time 0.2036 (0.2278)	loss 1.3699 (1.3890)	grad_norm 0.3791 (nan)	loss_scale 4096.0000 (8393.3028)	mem 5866MB
[2024-07-13 21:23:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000012	 wd 0.0000	time 0.1264 (0.2253)	loss 1.6527 (1.3898)	grad_norm 0.3995 (nan)	loss_scale 4096.0000 (8221.4794)	mem 5866MB
[2024-07-13 21:23:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 20 training takes 0:09:33
[2024-07-13 21:24:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 21.971 (21.971)	Loss 0.4148 (0.4148)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 5866MB
[2024-07-13 21:24:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.786 Acc@5 97.148
[2024-07-13 21:24:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 21:24:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.79%
[2024-07-13 21:24:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saving......
[2024-07-13 21:24:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-13 21:24:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][0/2502]	eta 22:20:25 lr 0.000012	 wd 0.0000	time 32.1445 (32.1445)	loss 1.5941 (1.5941)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:25:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:20:40 lr 0.000012	 wd 0.0000	time 0.1846 (0.5166)	loss 1.4980 (1.4098)	grad_norm 0.3754 (0.3884)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:25:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:13:32 lr 0.000012	 wd 0.0000	time 0.1927 (0.3529)	loss 0.9221 (1.3900)	grad_norm 0.3963 (0.3842)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:25:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:10:58 lr 0.000012	 wd 0.0000	time 0.1870 (0.2991)	loss 1.4077 (1.3828)	grad_norm 0.4099 (0.3856)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:26:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:09:40 lr 0.000011	 wd 0.0000	time 0.2611 (0.2759)	loss 1.4695 (1.3842)	grad_norm 0.3920 (0.3848)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:26:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:09:25 lr 0.000011	 wd 0.0000	time 0.1662 (0.2826)	loss 1.3770 (1.3833)	grad_norm 0.3804 (0.3850)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:27:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:28 lr 0.000011	 wd 0.0000	time 0.1485 (0.2675)	loss 1.2259 (1.3838)	grad_norm 0.3683 (0.3842)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:27:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:07:42 lr 0.000011	 wd 0.0000	time 0.1944 (0.2564)	loss 1.3139 (1.3782)	grad_norm 0.3735 (0.3848)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:27:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:02 lr 0.000011	 wd 0.0000	time 0.2034 (0.2484)	loss 1.2279 (1.3776)	grad_norm 0.3739 (0.3865)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:28:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:48 lr 0.000011	 wd 0.0000	time 0.2167 (0.2553)	loss 1.5641 (1.3785)	grad_norm 0.4067 (0.3882)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:28:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:14 lr 0.000011	 wd 0.0000	time 0.1817 (0.2491)	loss 1.0728 (1.3777)	grad_norm 0.3824 (0.3881)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:28:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:05:41 lr 0.000011	 wd 0.0000	time 0.1676 (0.2438)	loss 1.4855 (1.3778)	grad_norm 0.3615 (0.3879)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:29:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:11 lr 0.000011	 wd 0.0000	time 0.2000 (0.2393)	loss 1.3724 (1.3789)	grad_norm 0.3766 (0.3877)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:29:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:49 lr 0.000011	 wd 0.0000	time 0.3611 (0.2407)	loss 1.5648 (1.3791)	grad_norm 0.3840 (0.3879)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:30:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:27 lr 0.000011	 wd 0.0000	time 0.1676 (0.2424)	loss 1.4496 (1.3796)	grad_norm 0.3982 (0.3879)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:30:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:03:59 lr 0.000010	 wd 0.0000	time 0.1961 (0.2386)	loss 1.6588 (1.3793)	grad_norm 0.3735 (0.3876)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:30:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:32 lr 0.000010	 wd 0.0000	time 0.2154 (0.2357)	loss 1.2319 (1.3788)	grad_norm 0.4056 (0.3873)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:30:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:07 lr 0.000010	 wd 0.0000	time 0.2087 (0.2335)	loss 1.4845 (1.3789)	grad_norm 0.4067 (0.3871)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:31:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:43 lr 0.000010	 wd 0.0000	time 0.1701 (0.2332)	loss 1.0277 (1.3793)	grad_norm 0.3771 (0.3875)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:31:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:19 lr 0.000010	 wd 0.0000	time 0.1847 (0.2320)	loss 1.0151 (1.3778)	grad_norm 0.3815 (0.3875)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:32:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:55 lr 0.000010	 wd 0.0000	time 0.1868 (0.2301)	loss 1.4464 (1.3774)	grad_norm 0.3799 (0.3875)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:32:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:31 lr 0.000010	 wd 0.0000	time 0.2124 (0.2283)	loss 1.2027 (1.3777)	grad_norm 0.3999 (0.3878)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:32:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:08 lr 0.000010	 wd 0.0000	time 0.2283 (0.2275)	loss 1.5866 (1.3757)	grad_norm 0.3824 (0.3878)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:33:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:45 lr 0.000010	 wd 0.0000	time 0.2219 (0.2277)	loss 1.5800 (1.3753)	grad_norm 0.5519 (0.3882)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:33:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:23 lr 0.000010	 wd 0.0000	time 0.1838 (0.2266)	loss 1.3916 (1.3767)	grad_norm 0.3951 (0.3887)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:33:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1372 (0.2241)	loss 1.3562 (1.3763)	grad_norm 0.3820 (0.3890)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:33:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 21 training takes 0:09:29
[2024-07-13 21:34:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 31.057 (31.057)	Loss 0.4158 (0.4158)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 5866MB
[2024-07-13 21:34:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.770 Acc@5 97.148
[2024-07-13 21:34:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 21:34:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.79%
[2024-07-13 21:35:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][0/2502]	eta 12:27:16 lr 0.000010	 wd 0.0000	time 17.9201 (17.9201)	loss 1.3351 (1.3351)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:35:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:14:41 lr 0.000010	 wd 0.0000	time 0.1938 (0.3668)	loss 1.3132 (1.3894)	grad_norm 0.3568 (0.3904)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:35:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:10:44 lr 0.000009	 wd 0.0000	time 0.2206 (0.2798)	loss 1.1898 (1.3851)	grad_norm 0.3448 (0.3884)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:36:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:11:34 lr 0.000009	 wd 0.0000	time 0.2630 (0.3155)	loss 1.5360 (1.3888)	grad_norm 0.4076 (0.3872)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:36:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:10:01 lr 0.000009	 wd 0.0000	time 0.2120 (0.2862)	loss 1.4503 (1.3922)	grad_norm 0.3786 (0.3894)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:36:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:08:53 lr 0.000009	 wd 0.0000	time 0.1622 (0.2665)	loss 0.9205 (1.3914)	grad_norm 0.3779 (0.3932)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:37:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:02 lr 0.000009	 wd 0.0000	time 0.2066 (0.2538)	loss 1.3790 (1.3945)	grad_norm 0.3883 (0.3915)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:37:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:28 lr 0.000009	 wd 0.0000	time 0.2088 (0.2491)	loss 0.9136 (1.3899)	grad_norm 0.3788 (0.3944)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:38:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:06:59 lr 0.000009	 wd 0.0000	time 0.1979 (0.2464)	loss 1.4109 (1.3855)	grad_norm 0.3817 (0.3947)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:38:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:24 lr 0.000009	 wd 0.0000	time 0.1883 (0.2402)	loss 1.3750 (1.3845)	grad_norm 0.6537 (0.3943)	loss_scale 8192.0000 (4441.5006)	mem 5866MB
[2024-07-13 21:38:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:05:53 lr 0.000009	 wd 0.0000	time 0.1756 (0.2353)	loss 1.5640 (1.3868)	grad_norm 0.3952 (0.3937)	loss_scale 8192.0000 (4816.1758)	mem 5866MB
[2024-07-13 21:39:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:25 lr 0.000009	 wd 0.0000	time 0.2188 (0.2321)	loss 1.4179 (1.3842)	grad_norm 0.3720 (0.3945)	loss_scale 8192.0000 (5122.7902)	mem 5866MB
[2024-07-13 21:39:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:10 lr 0.000009	 wd 0.0000	time 0.2045 (0.2386)	loss 1.3486 (1.3830)	grad_norm 0.4408 (0.3943)	loss_scale 8192.0000 (5378.3447)	mem 5866MB
[2024-07-13 21:39:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:04:42 lr 0.000009	 wd 0.0000	time 0.1712 (0.2349)	loss 0.9500 (1.3835)	grad_norm 0.3909 (0.3934)	loss_scale 8192.0000 (5594.6134)	mem 5866MB
[2024-07-13 21:40:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:15 lr 0.000008	 wd 0.0000	time 0.2258 (0.2317)	loss 1.5686 (1.3856)	grad_norm 0.3825 (0.3941)	loss_scale 8192.0000 (5780.0086)	mem 5866MB
[2024-07-13 21:40:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:03:49 lr 0.000008	 wd 0.0000	time 0.1717 (0.2290)	loss 1.3407 (1.3862)	grad_norm 0.5213 (0.3940)	loss_scale 8192.0000 (5940.7009)	mem 5866MB
[2024-07-13 21:41:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:31 lr 0.000008	 wd 0.0000	time 0.1911 (0.2341)	loss 1.5720 (1.3865)	grad_norm 0.3891 (0.3933)	loss_scale 8192.0000 (6081.3192)	mem 5866MB
[2024-07-13 21:41:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:05 lr 0.000008	 wd 0.0000	time 0.1718 (0.2317)	loss 1.3233 (1.3862)	grad_norm 0.3602 (0.3926)	loss_scale 8192.0000 (6205.4039)	mem 5866MB
[2024-07-13 21:41:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:41 lr 0.000008	 wd 0.0000	time 0.2199 (0.2296)	loss 1.6165 (1.3855)	grad_norm 0.3916 (0.3923)	loss_scale 8192.0000 (6315.7091)	mem 5866MB
[2024-07-13 21:41:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:17 lr 0.000008	 wd 0.0000	time 0.1773 (0.2276)	loss 1.5684 (1.3849)	grad_norm 0.4050 (0.3918)	loss_scale 8192.0000 (6414.4093)	mem 5866MB
[2024-07-13 21:42:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:53 lr 0.000008	 wd 0.0000	time 0.2337 (0.2265)	loss 1.5312 (1.3839)	grad_norm 0.3473 (0.3915)	loss_scale 8192.0000 (6503.2444)	mem 5866MB
[2024-07-13 21:42:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:31 lr 0.000008	 wd 0.0000	time 0.2077 (0.2270)	loss 1.4538 (1.3844)	grad_norm 0.3868 (0.3924)	loss_scale 8192.0000 (6583.6230)	mem 5866MB
[2024-07-13 21:43:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:08 lr 0.000008	 wd 0.0000	time 0.1816 (0.2260)	loss 1.4604 (1.3826)	grad_norm 0.4053 (0.3925)	loss_scale 8192.0000 (6656.6979)	mem 5866MB
[2024-07-13 21:43:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:45 lr 0.000008	 wd 0.0000	time 0.2106 (0.2245)	loss 1.5124 (1.3828)	grad_norm 0.3873 (0.3923)	loss_scale 8192.0000 (6723.4211)	mem 5866MB
[2024-07-13 21:43:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:22 lr 0.000008	 wd 0.0000	time 0.2044 (0.2233)	loss 1.2307 (1.3821)	grad_norm 0.3705 (0.3922)	loss_scale 8192.0000 (6784.5864)	mem 5866MB
[2024-07-13 21:43:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1353 (0.2211)	loss 1.0033 (1.3812)	grad_norm 0.4806 (0.3920)	loss_scale 8192.0000 (6840.8605)	mem 5866MB
[2024-07-13 21:44:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 22 training takes 0:09:20
[2024-07-13 21:44:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 37.509 (37.509)	Loss 0.4153 (0.4153)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 5866MB
[2024-07-13 21:45:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.792 Acc@5 97.146
[2024-07-13 21:45:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 21:45:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.79%
[2024-07-13 21:45:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saving......
[2024-07-13 21:45:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-13 21:45:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][0/2502]	eta 11:47:02 lr 0.000008	 wd 0.0000	time 16.9555 (16.9555)	loss 1.1896 (1.1896)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:45:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:18:43 lr 0.000008	 wd 0.0000	time 0.2078 (0.4676)	loss 1.6067 (1.4198)	grad_norm 0.3708 (0.3860)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 21:46:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:12:47 lr 0.000007	 wd 0.0000	time 0.1832 (0.3333)	loss 1.5828 (1.3976)	grad_norm 0.3783 (nan)	loss_scale 4096.0000 (6887.8010)	mem 5866MB
[2024-07-13 21:46:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:10:28 lr 0.000007	 wd 0.0000	time 0.1865 (0.2854)	loss 1.5492 (1.3910)	grad_norm 0.4092 (nan)	loss_scale 4096.0000 (5960.2924)	mem 5866MB
[2024-07-13 21:46:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:09:10 lr 0.000007	 wd 0.0000	time 0.1963 (0.2618)	loss 1.5490 (1.3828)	grad_norm 0.3814 (nan)	loss_scale 4096.0000 (5495.3815)	mem 5866MB
[2024-07-13 21:47:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:08:21 lr 0.000007	 wd 0.0000	time 0.1918 (0.2507)	loss 1.6856 (1.3875)	grad_norm 0.5101 (nan)	loss_scale 4096.0000 (5216.0639)	mem 5866MB
[2024-07-13 21:47:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:08:27 lr 0.000007	 wd 0.0000	time 0.1920 (0.2671)	loss 1.1504 (1.3877)	grad_norm 0.3776 (nan)	loss_scale 4096.0000 (5029.6972)	mem 5866MB
[2024-07-13 21:48:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:41 lr 0.000007	 wd 0.0000	time 0.2424 (0.2560)	loss 1.4304 (1.3852)	grad_norm 0.3847 (nan)	loss_scale 4096.0000 (4896.5021)	mem 5866MB
[2024-07-13 21:48:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:07:01 lr 0.000007	 wd 0.0000	time 0.1830 (0.2479)	loss 1.7171 (1.3839)	grad_norm 0.3706 (nan)	loss_scale 4096.0000 (4796.5643)	mem 5866MB
[2024-07-13 21:48:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:06:28 lr 0.000007	 wd 0.0000	time 0.2402 (0.2422)	loss 1.7258 (1.3803)	grad_norm 0.4019 (nan)	loss_scale 4096.0000 (4718.8102)	mem 5866MB
[2024-07-13 21:49:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:16 lr 0.000007	 wd 0.0000	time 0.1875 (0.2507)	loss 1.1609 (1.3783)	grad_norm 0.3633 (nan)	loss_scale 4096.0000 (4656.5914)	mem 5866MB
[2024-07-13 21:49:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:43 lr 0.000007	 wd 0.0000	time 0.1880 (0.2451)	loss 0.8883 (1.3738)	grad_norm 0.3736 (nan)	loss_scale 4096.0000 (4605.6748)	mem 5866MB
[2024-07-13 21:49:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:12 lr 0.000007	 wd 0.0000	time 0.1878 (0.2403)	loss 1.5828 (1.3755)	grad_norm 0.3935 (nan)	loss_scale 4096.0000 (4563.2373)	mem 5866MB
[2024-07-13 21:50:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:04:44 lr 0.000007	 wd 0.0000	time 0.1947 (0.2366)	loss 1.4757 (1.3770)	grad_norm 0.3753 (nan)	loss_scale 4096.0000 (4527.3236)	mem 5866MB
[2024-07-13 21:50:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:19 lr 0.000007	 wd 0.0000	time 0.2021 (0.2353)	loss 1.6069 (1.3771)	grad_norm 0.3691 (nan)	loss_scale 4096.0000 (4496.5368)	mem 5866MB
[2024-07-13 21:50:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:03:54 lr 0.000006	 wd 0.0000	time 0.1665 (0.2344)	loss 1.3094 (1.3792)	grad_norm 0.3794 (nan)	loss_scale 4096.0000 (4469.8521)	mem 5866MB
[2024-07-13 21:51:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:29 lr 0.000006	 wd 0.0000	time 0.1753 (0.2318)	loss 1.1881 (1.3785)	grad_norm 0.3652 (nan)	loss_scale 4096.0000 (4446.5009)	mem 5866MB
[2024-07-13 21:51:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:04 lr 0.000006	 wd 0.0000	time 0.1807 (0.2295)	loss 1.3560 (1.3787)	grad_norm 0.3758 (nan)	loss_scale 4096.0000 (4425.8954)	mem 5866MB
[2024-07-13 21:51:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:39 lr 0.000006	 wd 0.0000	time 0.1709 (0.2278)	loss 1.4865 (1.3781)	grad_norm 0.4106 (nan)	loss_scale 4096.0000 (4407.5780)	mem 5866MB
[2024-07-13 21:52:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:17 lr 0.000006	 wd 0.0000	time 0.1818 (0.2289)	loss 1.2469 (1.3808)	grad_norm 0.3710 (nan)	loss_scale 4096.0000 (4391.1878)	mem 5866MB
[2024-07-13 21:52:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:01:54 lr 0.000006	 wd 0.0000	time 0.2061 (0.2277)	loss 1.4830 (1.3797)	grad_norm 0.3872 (nan)	loss_scale 4096.0000 (4376.4358)	mem 5866MB
[2024-07-13 21:52:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:30 lr 0.000006	 wd 0.0000	time 0.1744 (0.2261)	loss 1.7055 (1.3801)	grad_norm 0.3796 (nan)	loss_scale 4096.0000 (4363.0881)	mem 5866MB
[2024-07-13 21:53:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:07 lr 0.000006	 wd 0.0000	time 0.1950 (0.2246)	loss 1.4967 (1.3780)	grad_norm 0.3960 (nan)	loss_scale 4096.0000 (4350.9532)	mem 5866MB
[2024-07-13 21:53:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:45 lr 0.000006	 wd 0.0000	time 0.2485 (0.2238)	loss 1.6214 (1.3780)	grad_norm 0.3689 (nan)	loss_scale 4096.0000 (4339.8731)	mem 5866MB
[2024-07-13 21:54:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:22 lr 0.000006	 wd 0.0000	time 0.1663 (0.2238)	loss 1.5755 (1.3785)	grad_norm 0.3667 (nan)	loss_scale 4096.0000 (4329.7160)	mem 5866MB
[2024-07-13 21:54:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000006	 wd 0.0000	time 0.1335 (0.2213)	loss 1.4609 (1.3792)	grad_norm 0.3847 (nan)	loss_scale 4096.0000 (4320.3711)	mem 5866MB
[2024-07-13 21:54:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 23 training takes 0:09:24
[2024-07-13 21:54:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 20.416 (20.416)	Loss 0.4153 (0.4153)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 5866MB
[2024-07-13 21:55:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.764 Acc@5 97.156
[2024-07-13 21:55:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 21:55:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.79%
[2024-07-13 21:55:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][0/2502]	eta 1 day, 3:15:25 lr 0.000006	 wd 0.0000	time 39.2190 (39.2190)	loss 1.6125 (1.6125)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:56:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:23:01 lr 0.000006	 wd 0.0000	time 0.1789 (0.5753)	loss 1.1636 (1.4190)	grad_norm 0.3938 (0.3989)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:56:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:14:39 lr 0.000006	 wd 0.0000	time 0.1930 (0.3823)	loss 1.4537 (1.4013)	grad_norm 0.3837 (0.3921)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:56:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:11:44 lr 0.000006	 wd 0.0000	time 0.2613 (0.3198)	loss 1.6479 (1.3941)	grad_norm 0.3985 (0.3898)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:57:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:11:28 lr 0.000005	 wd 0.0000	time 0.2053 (0.3276)	loss 1.4445 (1.3905)	grad_norm 0.3978 (0.3962)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:57:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:10:02 lr 0.000005	 wd 0.0000	time 0.1693 (0.3007)	loss 1.7044 (1.3920)	grad_norm 0.3772 (0.3980)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:57:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:08:56 lr 0.000005	 wd 0.0000	time 0.2019 (0.2819)	loss 1.4377 (1.3888)	grad_norm 0.3828 (0.3974)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:58:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:08:03 lr 0.000005	 wd 0.0000	time 0.2311 (0.2685)	loss 1.3544 (1.3895)	grad_norm 0.3902 (0.3984)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:58:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:08:00 lr 0.000005	 wd 0.0000	time 0.3009 (0.2822)	loss 1.4601 (1.3906)	grad_norm 0.3750 (0.3965)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:59:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:07:17 lr 0.000005	 wd 0.0000	time 0.2064 (0.2732)	loss 1.5880 (1.3873)	grad_norm 0.3884 (0.3954)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:59:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:37 lr 0.000005	 wd 0.0000	time 0.1815 (0.2649)	loss 1.2275 (1.3877)	grad_norm 0.3918 (0.3959)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 21:59:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:06:01 lr 0.000005	 wd 0.0000	time 0.2162 (0.2578)	loss 1.5272 (1.3866)	grad_norm 0.3873 (0.3948)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:00:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:45 lr 0.000005	 wd 0.0000	time 0.6034 (0.2652)	loss 1.2590 (1.3847)	grad_norm 0.3794 (0.3940)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:00:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:05:13 lr 0.000005	 wd 0.0000	time 0.2040 (0.2606)	loss 1.4038 (1.3840)	grad_norm 0.4290 (0.3954)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:01:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:41 lr 0.000005	 wd 0.0000	time 0.1783 (0.2555)	loss 1.3499 (1.3824)	grad_norm 0.4394 (0.3960)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:01:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:11 lr 0.000005	 wd 0.0000	time 0.1947 (0.2512)	loss 0.9944 (1.3809)	grad_norm 0.3661 (0.3951)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:01:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:44 lr 0.000005	 wd 0.0000	time 0.1858 (0.2491)	loss 1.5538 (1.3805)	grad_norm 0.3710 (0.3945)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:02:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:19 lr 0.000005	 wd 0.0000	time 0.1455 (0.2483)	loss 1.6934 (1.3818)	grad_norm 0.4056 (0.3946)	loss_scale 8192.0000 (4254.9277)	mem 5866MB
[2024-07-13 22:02:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:52 lr 0.000005	 wd 0.0000	time 0.1877 (0.2454)	loss 1.1659 (1.3797)	grad_norm 0.3816 (0.3951)	loss_scale 8192.0000 (4473.5325)	mem 5866MB
[2024-07-13 22:02:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:26 lr 0.000005	 wd 0.0000	time 0.1769 (0.2429)	loss 1.4407 (1.3807)	grad_norm 0.3743 (0.3947)	loss_scale 8192.0000 (4669.1383)	mem 5866MB
[2024-07-13 22:03:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:02:00 lr 0.000004	 wd 0.0000	time 0.2132 (0.2405)	loss 1.4188 (1.3813)	grad_norm 0.3768 (0.3944)	loss_scale 8192.0000 (4845.1934)	mem 5866MB
[2024-07-13 22:03:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:36 lr 0.000004	 wd 0.0000	time 0.3418 (0.2393)	loss 1.5664 (1.3803)	grad_norm 0.3949 (0.3938)	loss_scale 8192.0000 (5004.4893)	mem 5866MB
[2024-07-13 22:03:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:12 lr 0.000004	 wd 0.0000	time 0.1740 (0.2388)	loss 1.4470 (1.3802)	grad_norm 0.3688 (0.3936)	loss_scale 8192.0000 (5149.3103)	mem 5866MB
[2024-07-13 22:04:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:47 lr 0.000004	 wd 0.0000	time 0.1934 (0.2369)	loss 1.7567 (1.3797)	grad_norm 0.3829 (0.3934)	loss_scale 8192.0000 (5281.5437)	mem 5866MB
[2024-07-13 22:04:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:23 lr 0.000004	 wd 0.0000	time 0.1887 (0.2349)	loss 1.5381 (1.3797)	grad_norm 0.3763 (0.3929)	loss_scale 8192.0000 (5402.7622)	mem 5866MB
[2024-07-13 22:04:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000004	 wd 0.0000	time 0.1422 (0.2321)	loss 1.2615 (1.3798)	grad_norm 0.3833 (0.3928)	loss_scale 8192.0000 (5514.2871)	mem 5866MB
[2024-07-13 22:04:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 24 training takes 0:09:47
[2024-07-13 22:05:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 38.472 (38.472)	Loss 0.4153 (0.4153)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 5866MB
[2024-07-13 22:05:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.794 Acc@5 97.154
[2024-07-13 22:05:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 22:05:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.79%
[2024-07-13 22:05:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saving......
[2024-07-13 22:05:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-13 22:06:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][0/2502]	eta 10:39:49 lr 0.000004	 wd 0.0000	time 15.3435 (15.3435)	loss 1.2588 (1.2588)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:06:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:14:37 lr 0.000004	 wd 0.0000	time 0.3186 (0.3654)	loss 1.4237 (1.3473)	grad_norm 0.3658 (0.3898)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:07:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:13:14 lr 0.000004	 wd 0.0000	time 0.1995 (0.3453)	loss 1.5054 (1.3756)	grad_norm 0.3477 (0.3846)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:07:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:10:44 lr 0.000004	 wd 0.0000	time 0.1973 (0.2928)	loss 1.1233 (1.3660)	grad_norm 0.3542 (0.3878)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:07:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:09:21 lr 0.000004	 wd 0.0000	time 0.1845 (0.2670)	loss 1.2726 (1.3810)	grad_norm 0.3729 (0.3880)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:07:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:08:23 lr 0.000004	 wd 0.0000	time 0.1990 (0.2513)	loss 1.5876 (1.3815)	grad_norm 0.3630 (0.3876)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:08:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:26 lr 0.000004	 wd 0.0000	time 0.2406 (0.2665)	loss 1.2008 (1.3829)	grad_norm 0.3886 (nan)	loss_scale 4096.0000 (7524.0998)	mem 5866MB
[2024-07-13 22:08:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:07:42 lr 0.000004	 wd 0.0000	time 0.1717 (0.2567)	loss 1.2788 (1.3832)	grad_norm 0.3749 (nan)	loss_scale 4096.0000 (7035.0699)	mem 5866MB
[2024-07-13 22:09:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:07:02 lr 0.000004	 wd 0.0000	time 0.1868 (0.2485)	loss 1.0058 (1.3836)	grad_norm 0.4147 (nan)	loss_scale 4096.0000 (6668.1448)	mem 5866MB
[2024-07-13 22:09:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:06:27 lr 0.000004	 wd 0.0000	time 0.1794 (0.2416)	loss 1.5451 (1.3855)	grad_norm 0.3732 (nan)	loss_scale 4096.0000 (6382.6681)	mem 5866MB
[2024-07-13 22:09:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:07 lr 0.000004	 wd 0.0000	time 0.5537 (0.2447)	loss 1.2405 (1.3858)	grad_norm 0.3826 (nan)	loss_scale 4096.0000 (6154.2298)	mem 5866MB
[2024-07-13 22:10:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:48 lr 0.000004	 wd 0.0000	time 0.1650 (0.2489)	loss 1.3205 (1.3839)	grad_norm 0.5250 (nan)	loss_scale 4096.0000 (5967.2879)	mem 5866MB
[2024-07-13 22:10:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:17 lr 0.000004	 wd 0.0000	time 0.1705 (0.2440)	loss 1.3520 (1.3862)	grad_norm 0.3914 (nan)	loss_scale 4096.0000 (5811.4771)	mem 5866MB
[2024-07-13 22:11:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:04:47 lr 0.000003	 wd 0.0000	time 0.1461 (0.2394)	loss 1.4946 (1.3879)	grad_norm 0.3907 (nan)	loss_scale 4096.0000 (5679.6188)	mem 5866MB
[2024-07-13 22:11:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:22 lr 0.000003	 wd 0.0000	time 0.2804 (0.2383)	loss 1.1262 (1.3875)	grad_norm 0.3599 (nan)	loss_scale 4096.0000 (5566.5839)	mem 5866MB
[2024-07-13 22:11:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:04:01 lr 0.000003	 wd 0.0000	time 0.1846 (0.2408)	loss 1.2619 (1.3876)	grad_norm 0.3838 (nan)	loss_scale 4096.0000 (5468.6103)	mem 5866MB
[2024-07-13 22:12:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:34 lr 0.000003	 wd 0.0000	time 0.1813 (0.2376)	loss 1.5139 (1.3869)	grad_norm 0.3593 (nan)	loss_scale 4096.0000 (5382.8757)	mem 5866MB
[2024-07-13 22:12:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:08 lr 0.000003	 wd 0.0000	time 0.2253 (0.2349)	loss 1.4281 (1.3863)	grad_norm 0.3887 (nan)	loss_scale 4096.0000 (5307.2216)	mem 5866MB
[2024-07-13 22:12:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:43 lr 0.000003	 wd 0.0000	time 0.1797 (0.2328)	loss 1.5856 (1.3861)	grad_norm 0.3843 (nan)	loss_scale 4096.0000 (5239.9689)	mem 5866MB
[2024-07-13 22:13:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:20 lr 0.000003	 wd 0.0000	time 0.1880 (0.2331)	loss 1.9609 (1.3858)	grad_norm 0.3704 (nan)	loss_scale 4096.0000 (5179.7917)	mem 5866MB
[2024-07-13 22:13:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:01:56 lr 0.000003	 wd 0.0000	time 0.1622 (0.2317)	loss 1.2967 (1.3850)	grad_norm 0.4199 (nan)	loss_scale 4096.0000 (5125.6292)	mem 5866MB
[2024-07-13 22:13:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:32 lr 0.000003	 wd 0.0000	time 0.2270 (0.2300)	loss 0.8986 (1.3851)	grad_norm 0.4059 (nan)	loss_scale 4096.0000 (5076.6226)	mem 5866MB
[2024-07-13 22:14:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:08 lr 0.000003	 wd 0.0000	time 0.1765 (0.2283)	loss 1.4653 (1.3839)	grad_norm 0.3603 (nan)	loss_scale 4096.0000 (5032.0691)	mem 5866MB
[2024-07-13 22:14:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:45 lr 0.000003	 wd 0.0000	time 0.2670 (0.2273)	loss 1.2252 (1.3826)	grad_norm 0.3419 (nan)	loss_scale 4096.0000 (4991.3881)	mem 5866MB
[2024-07-13 22:14:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:23 lr 0.000003	 wd 0.0000	time 0.1677 (0.2272)	loss 1.4174 (1.3842)	grad_norm 0.3840 (nan)	loss_scale 4096.0000 (4954.0958)	mem 5866MB
[2024-07-13 22:15:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1304 (0.2250)	loss 1.5088 (1.3843)	grad_norm 0.4051 (nan)	loss_scale 4096.0000 (4919.7857)	mem 5866MB
[2024-07-13 22:15:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 25 training takes 0:09:31
[2024-07-13 22:15:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 19.876 (19.876)	Loss 0.4153 (0.4153)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 5866MB
[2024-07-13 22:16:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.786 Acc@5 97.150
[2024-07-13 22:16:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 22:16:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.79%
[2024-07-13 22:16:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][0/2502]	eta 23:42:50 lr 0.000003	 wd 0.0000	time 34.1208 (34.1208)	loss 1.3466 (1.3466)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:16:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:21:32 lr 0.000003	 wd 0.0000	time 0.1872 (0.5379)	loss 1.5379 (1.3787)	grad_norm 0.4644 (0.3923)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:17:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:13:56 lr 0.000003	 wd 0.0000	time 0.1871 (0.3632)	loss 1.5002 (1.3989)	grad_norm 0.3887 (0.3881)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:17:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:11:09 lr 0.000003	 wd 0.0000	time 0.1712 (0.3043)	loss 1.5043 (1.3900)	grad_norm 0.3865 (0.3870)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:17:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:10:06 lr 0.000003	 wd 0.0000	time 0.3773 (0.2887)	loss 1.6674 (1.3917)	grad_norm 0.3649 (0.3861)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:18:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:09:35 lr 0.000003	 wd 0.0000	time 0.1608 (0.2877)	loss 1.6516 (1.3980)	grad_norm 0.3838 (0.3876)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:18:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:08:36 lr 0.000003	 wd 0.0000	time 0.2101 (0.2714)	loss 1.4194 (1.3928)	grad_norm 0.3849 (0.3872)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:19:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:47 lr 0.000003	 wd 0.0000	time 0.2141 (0.2595)	loss 1.5410 (1.3887)	grad_norm 0.3511 (0.3888)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:19:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:07:10 lr 0.000002	 wd 0.0000	time 0.2635 (0.2531)	loss 1.6177 (1.3872)	grad_norm 0.3655 (0.3925)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:19:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:06:55 lr 0.000002	 wd 0.0000	time 0.1768 (0.2593)	loss 1.3846 (1.3872)	grad_norm 0.3782 (0.3918)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:20:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:19 lr 0.000002	 wd 0.0000	time 0.1733 (0.2524)	loss 1.4504 (1.3877)	grad_norm 0.4409 (0.3918)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:20:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:45 lr 0.000002	 wd 0.0000	time 0.2010 (0.2467)	loss 1.6331 (1.3894)	grad_norm 0.3587 (0.3912)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:20:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:15 lr 0.000002	 wd 0.0000	time 0.2170 (0.2423)	loss 1.0977 (1.3899)	grad_norm 0.4230 (0.3905)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:21:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:05:01 lr 0.000002	 wd 0.0000	time 0.1639 (0.2509)	loss 0.9712 (1.3881)	grad_norm 0.4070 (0.3909)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:21:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:31 lr 0.000002	 wd 0.0000	time 0.1933 (0.2466)	loss 1.6214 (1.3876)	grad_norm 0.3783 (0.3909)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:22:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:04:03 lr 0.000002	 wd 0.0000	time 0.1999 (0.2429)	loss 1.4273 (1.3863)	grad_norm 0.4088 (0.3916)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:22:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:36 lr 0.000002	 wd 0.0000	time 0.1958 (0.2395)	loss 1.4854 (1.3853)	grad_norm 0.3854 (0.3910)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:22:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:10 lr 0.000002	 wd 0.0000	time 0.2207 (0.2380)	loss 1.3029 (1.3864)	grad_norm 1.3630 (0.3918)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:23:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:46 lr 0.000002	 wd 0.0000	time 0.1959 (0.2376)	loss 1.5386 (1.3892)	grad_norm 0.3757 (0.3913)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:23:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:21 lr 0.000002	 wd 0.0000	time 0.1966 (0.2355)	loss 1.0027 (1.3877)	grad_norm 0.3717 (0.3908)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:23:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:01:57 lr 0.000002	 wd 0.0000	time 0.1915 (0.2334)	loss 0.9476 (1.3868)	grad_norm 0.4150 (0.3907)	loss_scale 4096.0000 (4096.0000)	mem 5866MB
[2024-07-13 22:24:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:33 lr 0.000002	 wd 0.0000	time 0.2672 (0.2317)	loss 1.1499 (1.3857)	grad_norm 0.4602 (0.3910)	loss_scale 8192.0000 (4290.9548)	mem 5866MB
[2024-07-13 22:24:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:10 lr 0.000002	 wd 0.0000	time 0.1849 (0.2319)	loss 0.9786 (1.3854)	grad_norm 0.3960 (0.3906)	loss_scale 8192.0000 (4468.1945)	mem 5866MB
[2024-07-13 22:24:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:46 lr 0.000002	 wd 0.0000	time 0.1746 (0.2307)	loss 1.2135 (1.3842)	grad_norm 0.3931 (0.3909)	loss_scale 8192.0000 (4630.0287)	mem 5866MB
[2024-07-13 22:25:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:23 lr 0.000002	 wd 0.0000	time 0.1995 (0.2292)	loss 1.1393 (1.3842)	grad_norm 0.3994 (0.3906)	loss_scale 8192.0000 (4778.3823)	mem 5866MB
[2024-07-13 22:25:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1399 (0.2265)	loss 0.9592 (1.3823)	grad_norm 0.3861 (0.3905)	loss_scale 8192.0000 (4914.8725)	mem 5866MB
[2024-07-13 22:25:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 26 training takes 0:09:35
[2024-07-13 22:26:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 44.495 (44.495)	Loss 0.4153 (0.4153)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 5866MB
[2024-07-13 22:26:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.794 Acc@5 97.146
[2024-07-13 22:26:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 22:26:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.79%
[2024-07-13 22:26:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saving......
[2024-07-13 22:26:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-13 22:26:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][0/2502]	eta 10:44:16 lr 0.000002	 wd 0.0000	time 15.4500 (15.4500)	loss 0.9520 (0.9520)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:27:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:13:46 lr 0.000002	 wd 0.0000	time 0.2147 (0.3442)	loss 1.5278 (1.3905)	grad_norm 0.3741 (0.3849)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:27:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:13:52 lr 0.000002	 wd 0.0000	time 0.2906 (0.3616)	loss 1.6014 (1.3846)	grad_norm 0.3862 (0.3886)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:28:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:11:19 lr 0.000002	 wd 0.0000	time 0.1743 (0.3085)	loss 1.3830 (1.3849)	grad_norm 0.3689 (0.3881)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:28:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:09:46 lr 0.000002	 wd 0.0000	time 0.1783 (0.2790)	loss 1.4691 (1.3826)	grad_norm 0.3919 (0.3910)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:28:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:08:41 lr 0.000002	 wd 0.0000	time 0.2106 (0.2607)	loss 0.9892 (1.3783)	grad_norm 0.4277 (0.3898)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:29:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:44 lr 0.000002	 wd 0.0000	time 0.1900 (0.2756)	loss 1.2810 (1.3813)	grad_norm 0.3779 (0.3883)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:29:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:58 lr 0.000002	 wd 0.0000	time 0.1707 (0.2654)	loss 1.4988 (1.3871)	grad_norm 0.3914 (0.3922)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:30:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:16 lr 0.000002	 wd 0.0000	time 0.1908 (0.2562)	loss 1.5651 (1.3906)	grad_norm 0.3735 (0.3924)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:30:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:38 lr 0.000001	 wd 0.0000	time 0.1789 (0.2485)	loss 1.3114 (1.3953)	grad_norm 0.3596 (0.3929)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:30:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:16 lr 0.000001	 wd 0.0000	time 0.4787 (0.2503)	loss 1.4734 (1.3935)	grad_norm 0.3678 (0.3933)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:31:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:54 lr 0.000001	 wd 0.0000	time 0.1989 (0.2532)	loss 1.5412 (1.3935)	grad_norm 0.3947 (0.3932)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:31:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:22 lr 0.000001	 wd 0.0000	time 0.2059 (0.2481)	loss 1.5243 (1.3935)	grad_norm 0.4432 (0.3934)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:31:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:52 lr 0.000001	 wd 0.0000	time 0.1774 (0.2435)	loss 1.5204 (1.3907)	grad_norm 0.3682 (0.3924)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:32:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:25 lr 0.000001	 wd 0.0000	time 0.2576 (0.2407)	loss 1.3152 (1.3912)	grad_norm 0.3820 (0.3922)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:32:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:04:00 lr 0.000001	 wd 0.0000	time 0.1695 (0.2401)	loss 1.5958 (1.3909)	grad_norm 0.3572 (0.3924)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:33:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:34 lr 0.000001	 wd 0.0000	time 0.1974 (0.2377)	loss 1.5787 (1.3888)	grad_norm 0.3982 (0.3929)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:33:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:08 lr 0.000001	 wd 0.0000	time 0.2063 (0.2351)	loss 1.4119 (1.3866)	grad_norm 0.3831 (0.3926)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:33:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:43 lr 0.000001	 wd 0.0000	time 0.2039 (0.2326)	loss 1.5412 (1.3871)	grad_norm 0.4004 (0.3925)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:34:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:19 lr 0.000001	 wd 0.0000	time 0.2542 (0.2316)	loss 1.1035 (1.3885)	grad_norm 0.3948 (0.3923)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:34:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:56 lr 0.000001	 wd 0.0000	time 0.1872 (0.2318)	loss 1.0664 (1.3874)	grad_norm 0.3773 (0.3919)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:34:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:32 lr 0.000001	 wd 0.0000	time 0.1592 (0.2301)	loss 1.7444 (1.3866)	grad_norm 0.3920 (0.3916)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:35:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:08 lr 0.000001	 wd 0.0000	time 0.1839 (0.2284)	loss 1.0953 (1.3873)	grad_norm 0.3777 (0.3915)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:35:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:45 lr 0.000001	 wd 0.0000	time 0.2231 (0.2271)	loss 1.4804 (1.3873)	grad_norm 0.3719 (0.3915)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:35:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:23 lr 0.000001	 wd 0.0000	time 0.1650 (0.2270)	loss 1.3913 (1.3868)	grad_norm 0.3770 (0.3913)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:36:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1578 (0.2250)	loss 1.5462 (1.3852)	grad_norm 0.3604 (0.3914)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:36:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 27 training takes 0:09:33
[2024-07-13 22:36:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 19.959 (19.959)	Loss 0.4153 (0.4153)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 5866MB
[2024-07-13 22:36:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.794 Acc@5 97.148
[2024-07-13 22:36:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 22:36:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.79%
[2024-07-13 22:36:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saving......
[2024-07-13 22:36:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-13 22:37:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][0/2502]	eta 22:22:05 lr 0.000001	 wd 0.0000	time 32.1843 (32.1843)	loss 1.3211 (1.3211)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:37:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:20:58 lr 0.000001	 wd 0.0000	time 0.1716 (0.5241)	loss 1.0731 (1.3655)	grad_norm 0.3818 (0.4037)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:38:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:13:42 lr 0.000001	 wd 0.0000	time 0.2116 (0.3573)	loss 1.0712 (1.3687)	grad_norm 0.3960 (0.3960)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:38:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:11:02 lr 0.000001	 wd 0.0000	time 0.1899 (0.3008)	loss 1.6522 (1.3791)	grad_norm 0.4073 (0.3935)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:38:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:09:49 lr 0.000001	 wd 0.0000	time 0.3334 (0.2803)	loss 1.4312 (1.3836)	grad_norm 0.3765 (0.3933)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:39:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:09:29 lr 0.000001	 wd 0.0000	time 0.1971 (0.2844)	loss 1.5864 (1.3855)	grad_norm 0.3645 (0.3932)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:39:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:31 lr 0.000001	 wd 0.0000	time 0.1921 (0.2690)	loss 1.4299 (1.3855)	grad_norm 0.3878 (0.3908)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:39:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:43 lr 0.000001	 wd 0.0000	time 0.2046 (0.2573)	loss 1.0400 (1.3876)	grad_norm 0.3761 (0.3907)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:40:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:04 lr 0.000001	 wd 0.0000	time 0.2299 (0.2496)	loss 1.6166 (1.3849)	grad_norm 0.4121 (0.3901)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:40:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:55 lr 0.000001	 wd 0.0000	time 0.1776 (0.2595)	loss 1.5633 (1.3854)	grad_norm 0.4015 (0.3901)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:41:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:19 lr 0.000001	 wd 0.0000	time 0.2136 (0.2528)	loss 1.5805 (1.3881)	grad_norm 0.3913 (0.3907)	loss_scale 16384.0000 (8224.7353)	mem 5866MB
[2024-07-13 22:41:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:46 lr 0.000001	 wd 0.0000	time 0.2076 (0.2470)	loss 0.9658 (1.3844)	grad_norm 0.4047 (nan)	loss_scale 8192.0000 (8757.4787)	mem 5866MB
[2024-07-13 22:41:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:15 lr 0.000001	 wd 0.0000	time 0.1814 (0.2421)	loss 1.2370 (1.3847)	grad_norm 0.3937 (nan)	loss_scale 8192.0000 (8710.3947)	mem 5866MB
[2024-07-13 22:42:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:04:48 lr 0.000001	 wd 0.0000	time 0.2038 (0.2404)	loss 1.6100 (1.3815)	grad_norm 0.3943 (nan)	loss_scale 8192.0000 (8670.5488)	mem 5866MB
[2024-07-13 22:42:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:23 lr 0.000001	 wd 0.0000	time 0.1834 (0.2393)	loss 0.9425 (1.3827)	grad_norm 0.3780 (nan)	loss_scale 8192.0000 (8636.3911)	mem 5866MB
[2024-07-13 22:42:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:03:56 lr 0.000001	 wd 0.0000	time 0.1709 (0.2362)	loss 1.5110 (1.3812)	grad_norm 0.3782 (nan)	loss_scale 8192.0000 (8606.7848)	mem 5866MB
[2024-07-13 22:43:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:30 lr 0.000001	 wd 0.0000	time 0.1800 (0.2333)	loss 1.1911 (1.3807)	grad_norm 0.4071 (nan)	loss_scale 8192.0000 (8580.8770)	mem 5866MB
[2024-07-13 22:43:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:05 lr 0.000001	 wd 0.0000	time 0.2152 (0.2312)	loss 1.4367 (1.3822)	grad_norm 0.3916 (nan)	loss_scale 8192.0000 (8558.0153)	mem 5866MB
[2024-07-13 22:43:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:41 lr 0.000001	 wd 0.0000	time 0.3228 (0.2302)	loss 1.3989 (1.3819)	grad_norm 0.3877 (nan)	loss_scale 8192.0000 (8537.6924)	mem 5866MB
[2024-07-13 22:44:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:18 lr 0.000001	 wd 0.0000	time 0.1822 (0.2300)	loss 1.5532 (1.3809)	grad_norm 0.4516 (nan)	loss_scale 8192.0000 (8519.5076)	mem 5866MB
[2024-07-13 22:44:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:01:54 lr 0.000001	 wd 0.0000	time 0.1899 (0.2282)	loss 0.8970 (1.3808)	grad_norm 0.3795 (nan)	loss_scale 8192.0000 (8503.1404)	mem 5866MB
[2024-07-13 22:44:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:31 lr 0.000001	 wd 0.0000	time 0.2331 (0.2264)	loss 1.1019 (1.3810)	grad_norm 0.3780 (nan)	loss_scale 8192.0000 (8488.3313)	mem 5866MB
[2024-07-13 22:45:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:08 lr 0.000001	 wd 0.0000	time 0.2104 (0.2253)	loss 1.5517 (1.3798)	grad_norm 0.3625 (nan)	loss_scale 8192.0000 (8474.8678)	mem 5866MB
[2024-07-13 22:45:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:45 lr 0.000001	 wd 0.0000	time 0.2194 (0.2254)	loss 1.1144 (1.3799)	grad_norm 0.4090 (nan)	loss_scale 8192.0000 (8462.5745)	mem 5866MB
[2024-07-13 22:45:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:22 lr 0.000001	 wd 0.0000	time 0.2212 (0.2245)	loss 1.6058 (1.3784)	grad_norm 0.3933 (nan)	loss_scale 8192.0000 (8451.3053)	mem 5866MB
[2024-07-13 22:46:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1401 (0.2223)	loss 1.1994 (1.3775)	grad_norm 0.4098 (nan)	loss_scale 8192.0000 (8440.9372)	mem 5866MB
[2024-07-13 22:46:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 28 training takes 0:09:23
[2024-07-13 22:46:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 19.341 (19.341)	Loss 0.4150 (0.4150)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 5866MB
[2024-07-13 22:46:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.792 Acc@5 97.156
[2024-07-13 22:46:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 22:46:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.79%
[2024-07-13 22:47:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][0/2502]	eta 22:55:26 lr 0.000001	 wd 0.0000	time 32.9843 (32.9843)	loss 1.4362 (1.4362)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:47:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:20:48 lr 0.000001	 wd 0.0000	time 0.2015 (0.5197)	loss 1.4863 (1.3594)	grad_norm 0.3710 (0.3868)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:48:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:13:32 lr 0.000001	 wd 0.0000	time 0.1717 (0.3532)	loss 1.1520 (1.3744)	grad_norm 0.3963 (0.3946)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:48:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:11:56 lr 0.000001	 wd 0.0000	time 0.4422 (0.3252)	loss 1.5174 (1.3722)	grad_norm 0.3644 (0.3981)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:49:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:11:00 lr 0.000001	 wd 0.0000	time 0.1971 (0.3141)	loss 1.1994 (1.3811)	grad_norm 0.3848 (0.3963)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:49:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:09:38 lr 0.000001	 wd 0.0000	time 0.1819 (0.2889)	loss 0.9503 (1.3832)	grad_norm 0.3618 (0.3946)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:49:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:36 lr 0.000000	 wd 0.0000	time 0.1894 (0.2716)	loss 1.3681 (1.3844)	grad_norm 0.3463 (0.3925)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:50:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:08:01 lr 0.000000	 wd 0.0000	time 0.3774 (0.2674)	loss 1.6018 (1.3851)	grad_norm 0.4180 (0.3929)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:50:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:07:48 lr 0.000000	 wd 0.0000	time 0.1979 (0.2750)	loss 0.8220 (1.3864)	grad_norm 0.3582 (0.3919)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:50:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:07:05 lr 0.000000	 wd 0.0000	time 0.2012 (0.2657)	loss 1.4400 (1.3863)	grad_norm 0.4818 (0.3915)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:51:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:27 lr 0.000000	 wd 0.0000	time 0.1680 (0.2582)	loss 1.3495 (1.3858)	grad_norm 0.4529 (0.3914)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:51:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:54 lr 0.000000	 wd 0.0000	time 0.2049 (0.2531)	loss 1.4814 (1.3863)	grad_norm 0.3463 (0.3909)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:52:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:36 lr 0.000000	 wd 0.0000	time 0.1691 (0.2588)	loss 1.2900 (1.3832)	grad_norm 0.3728 (0.3908)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:52:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:05:04 lr 0.000000	 wd 0.0000	time 0.2003 (0.2535)	loss 1.5660 (1.3840)	grad_norm 0.4088 (0.3903)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:52:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:34 lr 0.000000	 wd 0.0000	time 0.1747 (0.2490)	loss 1.7847 (1.3829)	grad_norm 0.3639 (0.3900)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:53:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:04:05 lr 0.000000	 wd 0.0000	time 0.1944 (0.2454)	loss 1.3055 (1.3841)	grad_norm 0.4041 (0.3910)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:53:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:40 lr 0.000000	 wd 0.0000	time 0.1798 (0.2448)	loss 1.4907 (1.3855)	grad_norm 0.3762 (0.3903)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:53:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:14 lr 0.000000	 wd 0.0000	time 0.1644 (0.2423)	loss 1.3169 (1.3823)	grad_norm 0.3861 (0.3904)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:54:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:48 lr 0.000000	 wd 0.0000	time 0.1868 (0.2397)	loss 1.1913 (1.3840)	grad_norm 0.3827 (0.3899)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:54:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:22 lr 0.000000	 wd 0.0000	time 0.1982 (0.2374)	loss 1.2531 (1.3837)	grad_norm 0.4055 (0.3898)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:54:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:01:58 lr 0.000000	 wd 0.0000	time 0.1836 (0.2357)	loss 1.5322 (1.3837)	grad_norm 0.4503 (0.3900)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:55:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:34 lr 0.000000	 wd 0.0000	time 0.1415 (0.2357)	loss 1.5304 (1.3843)	grad_norm 0.3779 (0.3899)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:55:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:10 lr 0.000000	 wd 0.0000	time 0.1883 (0.2345)	loss 1.4644 (1.3861)	grad_norm 0.3841 (0.3898)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:55:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:46 lr 0.000000	 wd 0.0000	time 0.1783 (0.2326)	loss 1.4644 (1.3873)	grad_norm 0.6501 (0.3898)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:56:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.1928 (0.2309)	loss 1.4186 (1.3879)	grad_norm 0.3908 (0.3898)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:56:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000000	 wd 0.0000	time 0.1348 (0.2285)	loss 1.6148 (1.3870)	grad_norm 0.3829 (0.3897)	loss_scale 8192.0000 (8192.0000)	mem 5866MB
[2024-07-13 22:56:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 29 training takes 0:09:39
[2024-07-13 22:56:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_29.pth saving......
[2024-07-13 22:56:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_29.pth saved !!!
[2024-07-13 22:57:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 32.173 (32.173)	Loss 0.4150 (0.4150)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 5866MB
[2024-07-13 22:57:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 83.798 Acc@5 97.154
[2024-07-13 22:57:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-13 22:57:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 83.80%
[2024-07-13 22:57:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saving......
[2024-07-13 22:57:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_step_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-13 22:57:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process1] (main.py 189): INFO Training time 5:06:24
