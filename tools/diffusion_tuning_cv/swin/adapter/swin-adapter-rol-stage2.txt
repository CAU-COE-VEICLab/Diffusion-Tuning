[2024-07-15 06:38:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/config.json
[2024-07-15 06:38:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_swin_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 9
    - 3
    DIMS:
    - 96
    - 192
    - 384
    - 768
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: false
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: sequence_stage2
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 4.0e-05
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.0e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 4.0e-08
  WEIGHT_DECAY: 1.0e-08

[2024-07-15 06:38:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/swin/diffusion_ft_adapter_swin_base_patch4_window7_224_22kto1k_squence_stage_process2.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-15 06:38:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 108): INFO Creating model:adapter_swin_diffusion_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2
[2024-07-15 06:38:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 110): INFO Adapter_SwinTransformer_Diffusion_Finetune(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (uma): UMA(filter_strategy1=23, filter_strategy2=7,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-15 06:38:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 113): INFO number of params: 3480744
[2024-07-15 06:38:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 116): INFO number of GFLOPs: 15.438473216
[2024-07-15 06:38:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 150): INFO no checkpoint found in pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2, ignoring auto resume
[2024-07-15 06:38:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_best.pth for fine-tuning......
[2024-07-15 06:38:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])
[2024-07-15 06:38:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_best.pth'
[2024-07-15 06:39:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 71.406 (71.406)	Loss 0.4199 (0.4199)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 1485MB
[2024-07-15 06:40:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.130 Acc@5 97.234
[2024-07-15 06:40:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 162): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 06:40:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 168): INFO Start training
[2024-07-15 06:40:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][0/2502]	eta 12:20:23 lr 0.000000	 wd 0.0000	time 17.7553 (17.7553)	loss 1.6050 (1.6050)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 7925MB
[2024-07-15 06:41:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:21:07 lr 0.000000	 wd 0.0000	time 1.0559 (0.5278)	loss 1.4134 (1.4025)	grad_norm 0.4493 (nan)	loss_scale 16384.0000 (32443.5644)	mem 7962MB
[2024-07-15 06:41:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:14:47 lr 0.000001	 wd 0.0000	time 0.2164 (0.3855)	loss 1.4282 (1.3872)	grad_norm 0.4616 (nan)	loss_scale 16384.0000 (24453.7313)	mem 7962MB
[2024-07-15 06:41:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:13 lr 0.000001	 wd 0.0000	time 0.2139 (0.3331)	loss 1.4426 (1.3681)	grad_norm 0.4446 (nan)	loss_scale 16384.0000 (21772.7575)	mem 7962MB
[2024-07-15 06:42:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:44 lr 0.000001	 wd 0.0000	time 0.2261 (0.3067)	loss 1.8388 (1.3710)	grad_norm 0.4219 (nan)	loss_scale 8192.0000 (18508.6085)	mem 7962MB
[2024-07-15 06:42:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:09:58 lr 0.000002	 wd 0.0000	time 0.2359 (0.2992)	loss 1.4896 (1.3696)	grad_norm 0.8058 (nan)	loss_scale 8192.0000 (16449.4052)	mem 7962MB
[2024-07-15 06:43:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:09 lr 0.000002	 wd 0.0000	time 0.2359 (0.2887)	loss 1.1623 (1.3690)	grad_norm 0.4232 (nan)	loss_scale 8192.0000 (15075.4609)	mem 7962MB
[2024-07-15 06:43:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:25 lr 0.000002	 wd 0.0000	time 0.1883 (0.2805)	loss 1.4191 (1.3650)	grad_norm 0.4399 (nan)	loss_scale 4096.0000 (13929.9058)	mem 7962MB
[2024-07-15 06:43:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:47 lr 0.000003	 wd 0.0000	time 0.2623 (0.2744)	loss 1.5364 (1.3660)	grad_norm 0.4433 (nan)	loss_scale 4096.0000 (12702.2022)	mem 7962MB
[2024-07-15 06:44:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:16 lr 0.000003	 wd 0.0000	time 0.1864 (0.2726)	loss 1.5569 (1.3611)	grad_norm 0.4746 (nan)	loss_scale 4096.0000 (11747.0189)	mem 7962MB
[2024-07-15 06:44:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:06:45 lr 0.000003	 wd 0.0000	time 0.2298 (0.2700)	loss 1.3678 (1.3607)	grad_norm 0.5916 (nan)	loss_scale 4096.0000 (10982.6813)	mem 7962MB
[2024-07-15 06:45:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:13 lr 0.000004	 wd 0.0000	time 0.2132 (0.2665)	loss 1.5201 (1.3616)	grad_norm 0.4050 (nan)	loss_scale 4096.0000 (10357.1880)	mem 7962MB
[2024-07-15 06:45:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:43 lr 0.000004	 wd 0.0000	time 0.2285 (0.2635)	loss 1.4751 (1.3638)	grad_norm 0.4366 (nan)	loss_scale 4096.0000 (9835.8568)	mem 7962MB
[2024-07-15 06:45:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:16 lr 0.000004	 wd 0.0000	time 1.4734 (0.2633)	loss 1.4434 (1.3658)	grad_norm 0.4226 (nan)	loss_scale 4096.0000 (9394.6687)	mem 7962MB
[2024-07-15 06:46:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:48 lr 0.000005	 wd 0.0000	time 0.2139 (0.2616)	loss 1.5507 (1.3668)	grad_norm 0.4558 (nan)	loss_scale 4096.0000 (9016.4625)	mem 7962MB
[2024-07-15 06:46:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:20 lr 0.000005	 wd 0.0000	time 0.2185 (0.2596)	loss 1.4747 (1.3667)	grad_norm 0.5203 (nan)	loss_scale 4096.0000 (8688.6502)	mem 7962MB
[2024-07-15 06:47:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:52 lr 0.000005	 wd 0.0000	time 0.2378 (0.2578)	loss 1.5968 (1.3673)	grad_norm 0.4243 (nan)	loss_scale 4096.0000 (8401.7889)	mem 7962MB
[2024-07-15 06:47:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:26 lr 0.000005	 wd 0.0000	time 0.2466 (0.2571)	loss 1.4891 (1.3663)	grad_norm 0.4580 (nan)	loss_scale 4096.0000 (8148.6561)	mem 7962MB
[2024-07-15 06:47:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:03:00 lr 0.000006	 wd 0.0000	time 0.2619 (0.2576)	loss 1.2208 (1.3669)	grad_norm 0.4453 (nan)	loss_scale 4096.0000 (7923.6335)	mem 7962MB
[2024-07-15 06:48:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:34 lr 0.000006	 wd 0.0000	time 0.2630 (0.2563)	loss 1.6243 (1.3663)	grad_norm 0.5224 (nan)	loss_scale 4096.0000 (7722.2851)	mem 7962MB
[2024-07-15 06:48:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:07 lr 0.000006	 wd 0.0000	time 0.2038 (0.2550)	loss 1.4977 (1.3643)	grad_norm 0.4398 (nan)	loss_scale 4096.0000 (7541.0615)	mem 7962MB
[2024-07-15 06:49:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:42 lr 0.000007	 wd 0.0000	time 0.6472 (0.2547)	loss 1.3636 (1.3648)	grad_norm 0.4652 (nan)	loss_scale 4096.0000 (7377.0890)	mem 7962MB
[2024-07-15 06:49:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:16 lr 0.000007	 wd 0.0000	time 0.2164 (0.2547)	loss 1.6144 (1.3656)	grad_norm 0.4252 (nan)	loss_scale 4096.0000 (7228.0164)	mem 7962MB
[2024-07-15 06:49:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:51 lr 0.000007	 wd 0.0000	time 0.2296 (0.2538)	loss 1.5321 (1.3645)	grad_norm 0.4505 (nan)	loss_scale 4096.0000 (7091.9009)	mem 7962MB
[2024-07-15 06:50:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:25 lr 0.000008	 wd 0.0000	time 0.2115 (0.2528)	loss 1.3973 (1.3646)	grad_norm 0.4753 (nan)	loss_scale 4096.0000 (6967.1237)	mem 7962MB
[2024-07-15 06:50:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1700 (0.2510)	loss 1.6326 (1.3648)	grad_norm 0.4451 (nan)	loss_scale 4096.0000 (6852.3247)	mem 7962MB
[2024-07-15 06:50:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 0 training takes 0:10:33
[2024-07-15 06:50:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_0.pth saving......
[2024-07-15 06:50:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_0.pth saved !!!
[2024-07-15 06:51:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 48.067 (48.067)	Loss 0.4175 (0.4175)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 06:51:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.100 Acc@5 97.240
[2024-07-15 06:51:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 06:51:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.10%
[2024-07-15 06:51:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth saving......
[2024-07-15 06:51:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth saved !!!
[2024-07-15 06:52:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][0/2502]	eta 18:49:46 lr 0.000008	 wd 0.0000	time 27.0930 (27.0930)	loss 1.2234 (1.2234)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:52:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:20:57 lr 0.000008	 wd 0.0000	time 0.2224 (0.5235)	loss 1.1593 (1.4028)	grad_norm 0.4794 (0.4781)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:53:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:14:25 lr 0.000009	 wd 0.0000	time 0.2223 (0.3758)	loss 1.3533 (1.4023)	grad_norm 0.4329 (0.4744)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:53:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:55 lr 0.000009	 wd 0.0000	time 0.2045 (0.3250)	loss 1.6939 (1.3816)	grad_norm 0.4404 (0.4814)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:53:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:10:39 lr 0.000009	 wd 0.0000	time 0.2329 (0.3042)	loss 0.9774 (1.3713)	grad_norm 0.4215 (0.4822)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:54:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:09:42 lr 0.000010	 wd 0.0000	time 0.2238 (0.2908)	loss 1.5240 (1.3698)	grad_norm 0.4449 (0.4824)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:54:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:08:51 lr 0.000010	 wd 0.0000	time 0.2026 (0.2792)	loss 1.4309 (1.3693)	grad_norm 0.4565 (0.4824)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:55:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:10 lr 0.000010	 wd 0.0000	time 0.2117 (0.2720)	loss 1.6264 (1.3679)	grad_norm 0.4249 (0.4840)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:55:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:36 lr 0.000011	 wd 0.0000	time 0.2483 (0.2683)	loss 1.5442 (1.3714)	grad_norm 0.4065 (0.4833)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:55:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:06 lr 0.000011	 wd 0.0000	time 0.2382 (0.2663)	loss 1.5922 (1.3687)	grad_norm 0.4774 (0.4830)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:56:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:34 lr 0.000011	 wd 0.0000	time 0.2166 (0.2628)	loss 1.6822 (1.3676)	grad_norm 0.5314 (0.4819)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:56:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:06:04 lr 0.000012	 wd 0.0000	time 0.2304 (0.2598)	loss 1.0799 (1.3667)	grad_norm 0.4414 (0.4828)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:57:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:35 lr 0.000012	 wd 0.0000	time 0.2456 (0.2579)	loss 1.3432 (1.3694)	grad_norm 0.4051 (0.4815)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:57:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:09 lr 0.000012	 wd 0.0000	time 0.2656 (0.2579)	loss 1.5501 (1.3727)	grad_norm 0.4679 (0.4809)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:57:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:42 lr 0.000012	 wd 0.0000	time 0.2001 (0.2561)	loss 1.4273 (1.3707)	grad_norm 0.4537 (0.4822)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:58:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:15 lr 0.000013	 wd 0.0000	time 0.2245 (0.2546)	loss 0.9813 (1.3691)	grad_norm 0.5373 (0.4814)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:58:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:48 lr 0.000013	 wd 0.0000	time 0.2481 (0.2534)	loss 0.9329 (1.3677)	grad_norm 0.5493 (0.4838)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:59:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:23 lr 0.000013	 wd 0.0000	time 0.2338 (0.2537)	loss 1.3485 (1.3670)	grad_norm 0.4489 (0.4829)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:59:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:57 lr 0.000014	 wd 0.0000	time 0.2235 (0.2528)	loss 1.4351 (1.3671)	grad_norm 0.4566 (0.4838)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 06:59:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:31 lr 0.000014	 wd 0.0000	time 0.2203 (0.2516)	loss 1.4500 (1.3683)	grad_norm 0.4697 (0.4836)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:00:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:05 lr 0.000014	 wd 0.0000	time 0.2208 (0.2507)	loss 1.3240 (1.3675)	grad_norm 0.4279 (0.4852)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:00:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:40 lr 0.000015	 wd 0.0000	time 0.2185 (0.2507)	loss 1.3945 (1.3685)	grad_norm 0.4205 (0.4844)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:01:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:15 lr 0.000015	 wd 0.0000	time 0.2062 (0.2501)	loss 1.2091 (1.3697)	grad_norm 0.4499 (0.4838)	loss_scale 8192.0000 (4151.8292)	mem 7962MB
[2024-07-15 07:01:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:50 lr 0.000015	 wd 0.0000	time 0.2040 (0.2493)	loss 1.6332 (1.3702)	grad_norm 0.4711 (0.4837)	loss_scale 8192.0000 (4327.4124)	mem 7962MB
[2024-07-15 07:01:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:25 lr 0.000016	 wd 0.0000	time 0.2219 (0.2487)	loss 1.4523 (1.3683)	grad_norm 0.4298 (0.4832)	loss_scale 8192.0000 (4488.3698)	mem 7962MB
[2024-07-15 07:02:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1755 (0.2471)	loss 1.1118 (1.3695)	grad_norm 0.4120 (nan)	loss_scale 4096.0000 (4567.6705)	mem 7962MB
[2024-07-15 07:02:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 1 training takes 0:10:28
[2024-07-15 07:02:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 26.338 (26.338)	Loss 0.4170 (0.4170)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 07:02:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.116 Acc@5 97.248
[2024-07-15 07:02:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 07:02:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-15 07:02:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth saving......
[2024-07-15 07:02:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth saved !!!
[2024-07-15 07:03:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][0/2502]	eta 11:04:00 lr 0.000016	 wd 0.0000	time 15.9233 (15.9233)	loss 1.6475 (1.6475)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:03:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:16:23 lr 0.000016	 wd 0.0000	time 0.2669 (0.4096)	loss 1.4104 (1.3412)	grad_norm 0.4581 (0.4996)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:04:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:12:31 lr 0.000017	 wd 0.0000	time 0.2197 (0.3266)	loss 1.4367 (1.3611)	grad_norm 0.4878 (0.4997)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:04:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:10:44 lr 0.000017	 wd 0.0000	time 0.2299 (0.2926)	loss 1.2931 (1.3721)	grad_norm 0.4330 (0.4863)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:04:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:09:40 lr 0.000017	 wd 0.0000	time 0.1907 (0.2760)	loss 1.5274 (1.3699)	grad_norm 0.7466 (0.4839)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:05:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:08:57 lr 0.000018	 wd 0.0000	time 0.2488 (0.2687)	loss 1.5354 (1.3683)	grad_norm 0.4263 (0.4835)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:05:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:23 lr 0.000018	 wd 0.0000	time 0.2203 (0.2646)	loss 1.2698 (1.3628)	grad_norm 0.4331 (0.4826)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:05:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:07:46 lr 0.000018	 wd 0.0000	time 0.2230 (0.2590)	loss 1.2513 (1.3650)	grad_norm 0.5266 (0.4818)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:06:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:14 lr 0.000019	 wd 0.0000	time 0.2191 (0.2552)	loss 1.4382 (1.3633)	grad_norm 0.4597 (0.4802)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:06:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:45 lr 0.000019	 wd 0.0000	time 0.2152 (0.2532)	loss 1.5276 (1.3677)	grad_norm 0.4595 (0.4815)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:07:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:21 lr 0.000019	 wd 0.0000	time 0.2164 (0.2542)	loss 1.4491 (1.3688)	grad_norm 0.4746 (0.4805)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:07:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:53 lr 0.000020	 wd 0.0000	time 0.2251 (0.2521)	loss 1.1737 (1.3683)	grad_norm 0.5115 (0.4835)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:07:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:26 lr 0.000020	 wd 0.0000	time 0.1970 (0.2506)	loss 1.2596 (1.3674)	grad_norm 0.4571 (0.4848)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:08:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:05:00 lr 0.000020	 wd 0.0000	time 0.2400 (0.2496)	loss 1.7058 (1.3702)	grad_norm 0.4341 (0.4843)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:08:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:35 lr 0.000020	 wd 0.0000	time 0.2215 (0.2501)	loss 1.4416 (1.3702)	grad_norm 0.4788 (0.4843)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:09:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:09 lr 0.000021	 wd 0.0000	time 0.2144 (0.2488)	loss 1.5011 (1.3683)	grad_norm 0.4045 (0.4835)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:09:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:43 lr 0.000021	 wd 0.0000	time 0.2345 (0.2479)	loss 1.2835 (1.3685)	grad_norm 0.4744 (0.4834)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:09:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:18 lr 0.000021	 wd 0.0000	time 0.2065 (0.2472)	loss 1.4530 (1.3682)	grad_norm 0.4674 (0.4835)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:10:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:54 lr 0.000022	 wd 0.0000	time 0.2222 (0.2486)	loss 1.3508 (1.3681)	grad_norm 0.4593 (0.4838)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:10:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:29 lr 0.000022	 wd 0.0000	time 0.2185 (0.2479)	loss 1.0799 (1.3667)	grad_norm 0.4800 (0.4831)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:11:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:02:04 lr 0.000022	 wd 0.0000	time 0.2473 (0.2471)	loss 1.1090 (1.3648)	grad_norm 0.4816 (0.4848)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:11:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:39 lr 0.000023	 wd 0.0000	time 0.2508 (0.2467)	loss 1.4439 (1.3650)	grad_norm 0.5353 (0.4845)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:12:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:14 lr 0.000023	 wd 0.0000	time 0.2412 (0.2469)	loss 1.5079 (1.3650)	grad_norm 0.5955 (0.4858)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:12:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:49 lr 0.000023	 wd 0.0000	time 0.2342 (0.2462)	loss 1.5781 (1.3650)	grad_norm 0.5086 (0.4890)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:12:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:25 lr 0.000024	 wd 0.0000	time 0.2038 (0.2456)	loss 1.4219 (1.3639)	grad_norm 0.4231 (0.4891)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:13:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1722 (0.2441)	loss 1.4419 (1.3638)	grad_norm 0.4186 (0.4894)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:13:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 2 training takes 0:10:15
[2024-07-15 07:13:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 38.317 (38.317)	Loss 0.4128 (0.4128)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 07:14:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.064 Acc@5 97.244
[2024-07-15 07:14:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 07:14:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-15 07:14:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][0/2502]	eta 11:50:21 lr 0.000024	 wd 0.0000	time 17.0348 (17.0348)	loss 1.0896 (1.0896)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:14:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:15:58 lr 0.000024	 wd 0.0000	time 0.2300 (0.3989)	loss 1.6718 (1.3494)	grad_norm 0.5187 (0.4653)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:15:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:12:42 lr 0.000025	 wd 0.0000	time 0.2289 (0.3310)	loss 1.4927 (1.3615)	grad_norm 0.4570 (0.4705)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:15:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:10:52 lr 0.000025	 wd 0.0000	time 0.2145 (0.2963)	loss 1.4039 (1.3505)	grad_norm 0.4381 (0.4712)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:15:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:09:46 lr 0.000025	 wd 0.0000	time 0.2273 (0.2789)	loss 1.5258 (1.3568)	grad_norm 0.4167 (0.4764)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:16:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:08:57 lr 0.000026	 wd 0.0000	time 0.2321 (0.2685)	loss 1.3899 (1.3544)	grad_norm 0.4470 (0.4774)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:16:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:08:27 lr 0.000026	 wd 0.0000	time 0.2138 (0.2666)	loss 1.4632 (1.3540)	grad_norm 0.4584 (0.4764)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:17:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:07:51 lr 0.000026	 wd 0.0000	time 0.2162 (0.2619)	loss 1.4898 (1.3560)	grad_norm 0.4596 (0.4798)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:17:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:18 lr 0.000027	 wd 0.0000	time 0.2026 (0.2577)	loss 1.1329 (1.3566)	grad_norm 0.5056 (0.4809)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:17:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:06:47 lr 0.000027	 wd 0.0000	time 0.2261 (0.2545)	loss 1.3393 (1.3582)	grad_norm 0.4284 (0.4834)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:18:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:22 lr 0.000027	 wd 0.0000	time 0.2498 (0.2544)	loss 1.6061 (1.3615)	grad_norm 0.4200 (0.4826)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:18:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:05:55 lr 0.000028	 wd 0.0000	time 0.2378 (0.2532)	loss 1.3962 (1.3638)	grad_norm 0.4941 (0.4859)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:19:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:27 lr 0.000028	 wd 0.0000	time 0.2307 (0.2514)	loss 1.3082 (1.3627)	grad_norm 0.3850 (0.4856)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:19:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:04:59 lr 0.000028	 wd 0.0000	time 0.2117 (0.2495)	loss 1.2189 (1.3654)	grad_norm 0.4943 (0.4870)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:19:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:34 lr 0.000028	 wd 0.0000	time 0.2246 (0.2492)	loss 1.2247 (1.3662)	grad_norm 0.4862 (0.4892)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:20:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:09 lr 0.000029	 wd 0.0000	time 0.2149 (0.2492)	loss 1.3834 (1.3665)	grad_norm 0.5042 (0.4892)	loss_scale 8192.0000 (4221.5270)	mem 7962MB
[2024-07-15 07:20:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:43 lr 0.000029	 wd 0.0000	time 0.2160 (0.2481)	loss 1.4076 (1.3652)	grad_norm 0.5707 (0.4907)	loss_scale 8192.0000 (4469.5265)	mem 7962MB
[2024-07-15 07:21:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:18 lr 0.000029	 wd 0.0000	time 0.2395 (0.2470)	loss 1.0698 (1.3643)	grad_norm 0.4303 (0.4922)	loss_scale 8192.0000 (4688.3668)	mem 7962MB
[2024-07-15 07:21:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:53 lr 0.000030	 wd 0.0000	time 0.2408 (0.2469)	loss 1.6270 (1.3659)	grad_norm 0.4891 (0.4921)	loss_scale 8192.0000 (4882.9051)	mem 7962MB
[2024-07-15 07:21:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:29 lr 0.000030	 wd 0.0000	time 0.1972 (0.2479)	loss 1.5347 (1.3656)	grad_norm 0.4476 (0.4907)	loss_scale 8192.0000 (5056.9763)	mem 7962MB
[2024-07-15 07:22:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:04 lr 0.000030	 wd 0.0000	time 0.2545 (0.2471)	loss 1.1641 (1.3664)	grad_norm 0.4381 (0.4921)	loss_scale 8192.0000 (5213.6492)	mem 7962MB
[2024-07-15 07:22:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:38 lr 0.000031	 wd 0.0000	time 0.2111 (0.2463)	loss 1.2149 (1.3647)	grad_norm 0.4891 (0.4925)	loss_scale 8192.0000 (5355.4079)	mem 7962MB
[2024-07-15 07:23:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:14 lr 0.000031	 wd 0.0000	time 0.2583 (0.2462)	loss 1.3533 (1.3659)	grad_norm 0.4760 (0.4927)	loss_scale 8192.0000 (5484.2853)	mem 7962MB
[2024-07-15 07:23:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:49 lr 0.000031	 wd 0.0000	time 0.2218 (0.2460)	loss 1.5308 (1.3665)	grad_norm 0.4286 (0.4924)	loss_scale 8192.0000 (5601.9609)	mem 7962MB
[2024-07-15 07:23:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:25 lr 0.000032	 wd 0.0000	time 0.2298 (0.2455)	loss 0.9814 (1.3658)	grad_norm 0.4120 (0.4911)	loss_scale 8192.0000 (5709.8342)	mem 7962MB
[2024-07-15 07:24:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000032	 wd 0.0000	time 0.1776 (0.2437)	loss 1.5469 (1.3663)	grad_norm 0.4445 (0.4895)	loss_scale 8192.0000 (5809.0812)	mem 7962MB
[2024-07-15 07:24:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 3 training takes 0:10:13
[2024-07-15 07:24:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 37.265 (37.265)	Loss 0.4172 (0.4172)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 07:25:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.064 Acc@5 97.240
[2024-07-15 07:25:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 07:25:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-15 07:25:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][0/2502]	eta 11:05:54 lr 0.000032	 wd 0.0000	time 15.9691 (15.9691)	loss 1.4314 (1.4314)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:25:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:15:37 lr 0.000032	 wd 0.0000	time 0.1980 (0.3902)	loss 1.1471 (1.3758)	grad_norm 0.5631 (0.5137)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:26:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:12:19 lr 0.000033	 wd 0.0000	time 0.2510 (0.3212)	loss 1.1326 (1.3775)	grad_norm 0.4383 (0.5014)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:26:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:10:55 lr 0.000033	 wd 0.0000	time 0.2218 (0.2976)	loss 1.1124 (1.3775)	grad_norm 0.5133 (0.4928)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:27:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:09:47 lr 0.000033	 wd 0.0000	time 0.2224 (0.2796)	loss 1.5808 (1.3733)	grad_norm 0.5806 (0.4901)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:27:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:08:57 lr 0.000034	 wd 0.0000	time 0.2038 (0.2683)	loss 1.3393 (1.3667)	grad_norm 0.4579 (0.4903)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:27:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:08:20 lr 0.000034	 wd 0.0000	time 0.2553 (0.2632)	loss 1.4852 (1.3626)	grad_norm 0.4752 (0.4895)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:28:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:07:53 lr 0.000034	 wd 0.0000	time 0.2852 (0.2629)	loss 1.2831 (1.3627)	grad_norm 0.4503 (0.4885)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:28:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:19 lr 0.000035	 wd 0.0000	time 0.2089 (0.2585)	loss 1.4702 (1.3621)	grad_norm 0.4444 (0.4870)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:28:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:06:48 lr 0.000035	 wd 0.0000	time 0.2577 (0.2552)	loss 1.4876 (1.3633)	grad_norm 0.4188 (0.4884)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:29:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:19 lr 0.000035	 wd 0.0000	time 0.2239 (0.2530)	loss 1.5311 (1.3640)	grad_norm 0.4005 (0.4860)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:29:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:05:54 lr 0.000036	 wd 0.0000	time 0.2594 (0.2527)	loss 1.5306 (1.3648)	grad_norm 0.4679 (0.4848)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:30:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:26 lr 0.000036	 wd 0.0000	time 0.2225 (0.2509)	loss 1.0784 (1.3633)	grad_norm 0.5859 (0.4842)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:30:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:04:59 lr 0.000036	 wd 0.0000	time 0.2244 (0.2491)	loss 1.5756 (1.3627)	grad_norm 0.4571 (0.4841)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:30:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:33 lr 0.000036	 wd 0.0000	time 0.2404 (0.2480)	loss 1.5054 (1.3628)	grad_norm 0.4833 (0.4832)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:31:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:09 lr 0.000037	 wd 0.0000	time 0.2349 (0.2487)	loss 1.2557 (1.3652)	grad_norm 0.4525 (0.4835)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:31:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:43 lr 0.000037	 wd 0.0000	time 0.2028 (0.2479)	loss 1.0601 (1.3648)	grad_norm 0.4424 (0.4832)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:32:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:18 lr 0.000037	 wd 0.0000	time 0.1980 (0.2469)	loss 1.5507 (1.3641)	grad_norm 0.4741 (0.4849)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:32:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:52 lr 0.000038	 wd 0.0000	time 0.2683 (0.2463)	loss 1.3725 (1.3640)	grad_norm 0.4322 (0.4845)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:32:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:28 lr 0.000038	 wd 0.0000	time 0.2077 (0.2469)	loss 1.6444 (1.3639)	grad_norm 0.6691 (0.4846)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:33:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:02:03 lr 0.000038	 wd 0.0000	time 0.1998 (0.2464)	loss 1.4674 (1.3633)	grad_norm 0.6776 (0.4839)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:33:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:38 lr 0.000039	 wd 0.0000	time 0.2381 (0.2457)	loss 1.4329 (1.3637)	grad_norm 0.5583 (nan)	loss_scale 4096.0000 (8153.0090)	mem 7962MB
[2024-07-15 07:34:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:14 lr 0.000039	 wd 0.0000	time 0.2304 (0.2451)	loss 0.9900 (1.3614)	grad_norm 0.6728 (nan)	loss_scale 4096.0000 (7968.6833)	mem 7962MB
[2024-07-15 07:34:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:49 lr 0.000039	 wd 0.0000	time 0.2535 (0.2453)	loss 1.2945 (1.3616)	grad_norm 0.4476 (nan)	loss_scale 4096.0000 (7800.3790)	mem 7962MB
[2024-07-15 07:34:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:24 lr 0.000040	 wd 0.0000	time 0.2313 (0.2450)	loss 1.5820 (1.3614)	grad_norm 0.3900 (nan)	loss_scale 4096.0000 (7646.0941)	mem 7962MB
[2024-07-15 07:35:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1869 (0.2434)	loss 0.9294 (1.3612)	grad_norm 0.5025 (nan)	loss_scale 4096.0000 (7504.1471)	mem 7962MB
[2024-07-15 07:35:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 4 training takes 0:10:13
[2024-07-15 07:35:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 25.131 (25.131)	Loss 0.4136 (0.4136)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 07:36:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.102 Acc@5 97.226
[2024-07-15 07:36:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 07:36:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-15 07:36:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][0/2502]	eta 17:04:15 lr 0.000040	 wd 0.0000	time 24.5625 (24.5625)	loss 1.5996 (1.5996)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:36:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:18:36 lr 0.000040	 wd 0.0000	time 0.2035 (0.4648)	loss 1.2904 (1.3813)	grad_norm 0.5580 (0.5015)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:37:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:13:14 lr 0.000040	 wd 0.0000	time 0.1981 (0.3452)	loss 1.4756 (1.3852)	grad_norm 0.4761 (0.4830)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:37:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:11:32 lr 0.000040	 wd 0.0000	time 0.2084 (0.3145)	loss 1.6156 (1.3748)	grad_norm 0.4706 (0.4812)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:38:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:10:22 lr 0.000040	 wd 0.0000	time 0.2163 (0.2963)	loss 0.9961 (1.3762)	grad_norm 0.4537 (0.4785)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:38:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:09:23 lr 0.000040	 wd 0.0000	time 0.2039 (0.2816)	loss 1.5146 (1.3716)	grad_norm 0.4193 (0.4816)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:38:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:38 lr 0.000040	 wd 0.0000	time 0.2052 (0.2724)	loss 1.4281 (1.3723)	grad_norm 0.4675 (0.4807)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:39:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:08:02 lr 0.000040	 wd 0.0000	time 0.2441 (0.2677)	loss 1.4576 (1.3699)	grad_norm 0.5123 (0.4813)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:39:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:31 lr 0.000040	 wd 0.0000	time 0.2015 (0.2655)	loss 0.9419 (1.3639)	grad_norm 0.4340 (0.4818)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:39:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:58 lr 0.000040	 wd 0.0000	time 0.2007 (0.2612)	loss 0.9064 (1.3631)	grad_norm 0.8143 (0.4814)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:40:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:27 lr 0.000040	 wd 0.0000	time 0.1959 (0.2580)	loss 1.5321 (1.3663)	grad_norm 0.4107 (0.4808)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:40:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:59 lr 0.000040	 wd 0.0000	time 0.2265 (0.2561)	loss 1.5450 (1.3622)	grad_norm 0.4420 (0.4794)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:41:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:33 lr 0.000040	 wd 0.0000	time 0.1902 (0.2558)	loss 1.5438 (1.3602)	grad_norm 0.4497 (0.4789)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:41:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:05:04 lr 0.000040	 wd 0.0000	time 0.2204 (0.2537)	loss 1.4995 (1.3607)	grad_norm 0.5359 (0.4807)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:41:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:37 lr 0.000040	 wd 0.0000	time 0.2245 (0.2521)	loss 1.5288 (1.3603)	grad_norm 0.4181 (0.4806)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:42:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:04:11 lr 0.000040	 wd 0.0000	time 0.2467 (0.2508)	loss 1.3807 (1.3602)	grad_norm 0.4976 (0.4797)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:42:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:46 lr 0.000040	 wd 0.0000	time 0.2032 (0.2516)	loss 1.4486 (1.3622)	grad_norm 0.4417 (0.4787)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:43:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:21 lr 0.000040	 wd 0.0000	time 0.2473 (0.2507)	loss 1.3474 (1.3618)	grad_norm 0.4058 (0.4804)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:43:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:55 lr 0.000040	 wd 0.0000	time 0.2301 (0.2498)	loss 0.9890 (1.3612)	grad_norm 0.9351 (0.4806)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:43:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:29 lr 0.000040	 wd 0.0000	time 0.2527 (0.2491)	loss 1.4780 (1.3633)	grad_norm 0.4604 (0.4809)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:44:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:02:05 lr 0.000040	 wd 0.0000	time 0.1972 (0.2497)	loss 1.5111 (1.3642)	grad_norm 0.4497 (0.4833)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:44:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:40 lr 0.000040	 wd 0.0000	time 0.2440 (0.2491)	loss 1.5118 (1.3648)	grad_norm 0.4217 (0.4831)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:45:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:15 lr 0.000040	 wd 0.0000	time 0.2287 (0.2484)	loss 1.2382 (1.3628)	grad_norm 0.4343 (0.4827)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:45:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:50 lr 0.000040	 wd 0.0000	time 0.2372 (0.2478)	loss 0.8998 (1.3619)	grad_norm 0.3955 (0.4825)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:45:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:25 lr 0.000040	 wd 0.0000	time 0.2190 (0.2480)	loss 1.5079 (1.3620)	grad_norm 0.5048 (0.4832)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:46:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1675 (0.2462)	loss 1.5132 (1.3619)	grad_norm 0.4446 (0.4829)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:46:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 5 training takes 0:10:20
[2024-07-15 07:46:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 22.300 (22.300)	Loss 0.4146 (0.4146)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 07:46:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.070 Acc@5 97.248
[2024-07-15 07:46:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 07:46:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-15 07:47:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][0/2502]	eta 22:30:46 lr 0.000040	 wd 0.0000	time 32.3927 (32.3927)	loss 1.5711 (1.5711)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:47:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:21:47 lr 0.000040	 wd 0.0000	time 0.2069 (0.5444)	loss 1.2101 (1.3338)	grad_norm 0.4521 (0.4877)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:48:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:14:45 lr 0.000040	 wd 0.0000	time 0.2296 (0.3846)	loss 1.5848 (1.3547)	grad_norm 0.4384 (0.4862)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:48:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:12:08 lr 0.000040	 wd 0.0000	time 0.2168 (0.3310)	loss 1.4619 (1.3651)	grad_norm 0.5255 (0.4844)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:49:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:10:55 lr 0.000040	 wd 0.0000	time 0.2070 (0.3117)	loss 1.3747 (1.3587)	grad_norm 0.4606 (0.4857)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:49:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:09:50 lr 0.000040	 wd 0.0000	time 0.2319 (0.2948)	loss 1.3498 (1.3531)	grad_norm 0.4374 (0.4821)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:49:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:08:59 lr 0.000040	 wd 0.0000	time 0.1608 (0.2836)	loss 1.5968 (1.3572)	grad_norm 1.0912 (0.4815)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:50:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:08:15 lr 0.000040	 wd 0.0000	time 0.2260 (0.2752)	loss 1.4158 (1.3597)	grad_norm 0.4795 (0.4799)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:50:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:42 lr 0.000040	 wd 0.0000	time 0.2690 (0.2717)	loss 1.0057 (1.3587)	grad_norm 0.5093 (0.4808)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:51:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:07:10 lr 0.000040	 wd 0.0000	time 0.2493 (0.2687)	loss 1.6423 (1.3626)	grad_norm 0.3824 (0.4801)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:51:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:37 lr 0.000040	 wd 0.0000	time 0.1962 (0.2647)	loss 1.3069 (1.3581)	grad_norm 0.5042 (0.4816)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 07:51:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:06:06 lr 0.000040	 wd 0.0000	time 0.2224 (0.2612)	loss 1.2023 (1.3572)	grad_norm 0.4702 (0.4803)	loss_scale 8192.0000 (4185.2861)	mem 7962MB
[2024-07-15 07:52:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:37 lr 0.000040	 wd 0.0000	time 0.2252 (0.2595)	loss 1.0494 (1.3589)	grad_norm 0.4681 (0.4828)	loss_scale 8192.0000 (4518.9009)	mem 7962MB
[2024-07-15 07:52:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:05:11 lr 0.000040	 wd 0.0000	time 0.1973 (0.2592)	loss 1.4072 (1.3580)	grad_norm 0.4403 (0.4824)	loss_scale 8192.0000 (4801.2298)	mem 7962MB
[2024-07-15 07:52:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:43 lr 0.000040	 wd 0.0000	time 0.2346 (0.2571)	loss 1.6517 (1.3567)	grad_norm 0.7669 (0.4832)	loss_scale 8192.0000 (5043.2548)	mem 7962MB
[2024-07-15 07:53:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:15 lr 0.000040	 wd 0.0000	time 0.2000 (0.2552)	loss 1.4646 (1.3583)	grad_norm 0.4168 (0.4830)	loss_scale 8192.0000 (5253.0313)	mem 7962MB
[2024-07-15 07:53:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:49 lr 0.000040	 wd 0.0000	time 0.2552 (0.2542)	loss 1.5382 (1.3570)	grad_norm 0.4750 (0.4822)	loss_scale 8192.0000 (5436.6021)	mem 7962MB
[2024-07-15 07:54:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:24 lr 0.000040	 wd 0.0000	time 0.1942 (0.2545)	loss 1.4975 (1.3563)	grad_norm 1.0139 (0.4832)	loss_scale 8192.0000 (5598.5891)	mem 7962MB
[2024-07-15 07:54:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:57 lr 0.000040	 wd 0.0000	time 0.2224 (0.2532)	loss 1.1563 (1.3561)	grad_norm 0.4587 (0.4832)	loss_scale 8192.0000 (5742.5875)	mem 7962MB
[2024-07-15 07:54:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:31 lr 0.000040	 wd 0.0000	time 0.1991 (0.2520)	loss 1.2807 (1.3555)	grad_norm 0.4493 (0.4838)	loss_scale 8192.0000 (5871.4361)	mem 7962MB
[2024-07-15 07:55:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:02:06 lr 0.000039	 wd 0.0000	time 0.2644 (0.2513)	loss 0.9900 (1.3555)	grad_norm 0.4565 (0.4829)	loss_scale 8192.0000 (5987.4063)	mem 7962MB
[2024-07-15 07:55:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:41 lr 0.000039	 wd 0.0000	time 0.2032 (0.2513)	loss 1.5634 (1.3551)	grad_norm 0.4613 (0.4834)	loss_scale 8192.0000 (6092.3370)	mem 7962MB
[2024-07-15 07:56:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:15 lr 0.000039	 wd 0.0000	time 0.2334 (0.2504)	loss 1.2550 (1.3556)	grad_norm 0.4721 (0.4828)	loss_scale 8192.0000 (6187.7328)	mem 7962MB
[2024-07-15 07:56:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:50 lr 0.000039	 wd 0.0000	time 0.2159 (0.2497)	loss 1.4536 (1.3563)	grad_norm 0.5149 (0.4831)	loss_scale 8192.0000 (6274.8370)	mem 7962MB
[2024-07-15 07:56:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:25 lr 0.000039	 wd 0.0000	time 0.1960 (0.2491)	loss 1.1979 (1.3555)	grad_norm 0.4084 (0.4829)	loss_scale 8192.0000 (6354.6855)	mem 7962MB
[2024-07-15 07:57:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1733 (0.2474)	loss 1.0349 (1.3562)	grad_norm 0.4274 (0.4816)	loss_scale 8192.0000 (6428.1487)	mem 7962MB
[2024-07-15 07:57:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 6 training takes 0:10:28
[2024-07-15 07:57:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 20.334 (20.334)	Loss 0.4163 (0.4163)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 7962MB
[2024-07-15 07:57:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.066 Acc@5 97.242
[2024-07-15 07:57:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 07:57:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-15 07:58:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][0/2502]	eta 11:55:08 lr 0.000039	 wd 0.0000	time 17.1498 (17.1498)	loss 1.5906 (1.5906)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:58:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:16:43 lr 0.000039	 wd 0.0000	time 0.2297 (0.4179)	loss 1.2348 (1.3815)	grad_norm 0.4891 (0.4623)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:59:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:12:37 lr 0.000039	 wd 0.0000	time 0.2053 (0.3290)	loss 1.4514 (1.3559)	grad_norm 0.5069 (0.4870)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 07:59:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:10:47 lr 0.000039	 wd 0.0000	time 0.1932 (0.2939)	loss 1.3152 (1.3535)	grad_norm 0.4735 (nan)	loss_scale 4096.0000 (7647.6811)	mem 7962MB
[2024-07-15 07:59:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:09:40 lr 0.000039	 wd 0.0000	time 0.2012 (0.2760)	loss 1.3360 (1.3554)	grad_norm 0.9935 (nan)	loss_scale 2048.0000 (6516.8279)	mem 7962MB
[2024-07-15 08:00:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:08:57 lr 0.000039	 wd 0.0000	time 0.2380 (0.2685)	loss 1.4362 (1.3509)	grad_norm 0.4082 (nan)	loss_scale 2048.0000 (5624.8463)	mem 7962MB
[2024-07-15 08:00:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:24 lr 0.000039	 wd 0.0000	time 0.2301 (0.2651)	loss 1.3286 (1.3546)	grad_norm 0.4339 (nan)	loss_scale 2048.0000 (5029.6972)	mem 7962MB
[2024-07-15 08:01:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:07:47 lr 0.000039	 wd 0.0000	time 0.2215 (0.2597)	loss 1.4828 (1.3585)	grad_norm 0.5283 (nan)	loss_scale 2048.0000 (4604.3481)	mem 7962MB
[2024-07-15 08:01:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:07:15 lr 0.000039	 wd 0.0000	time 0.2061 (0.2556)	loss 0.8979 (1.3609)	grad_norm 0.4341 (nan)	loss_scale 2048.0000 (4285.2035)	mem 7962MB
[2024-07-15 08:01:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:06:46 lr 0.000039	 wd 0.0000	time 0.2492 (0.2537)	loss 1.0857 (1.3627)	grad_norm 0.4492 (nan)	loss_scale 2048.0000 (4036.9012)	mem 7962MB
[2024-07-15 08:02:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:20 lr 0.000039	 wd 0.0000	time 0.2257 (0.2531)	loss 1.1743 (1.3586)	grad_norm 0.5088 (nan)	loss_scale 2048.0000 (3838.2098)	mem 7962MB
[2024-07-15 08:02:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:51 lr 0.000039	 wd 0.0000	time 0.2334 (0.2509)	loss 1.2335 (1.3572)	grad_norm 0.5087 (nan)	loss_scale 2048.0000 (3675.6113)	mem 7962MB
[2024-07-15 08:02:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:24 lr 0.000039	 wd 0.0000	time 0.1985 (0.2490)	loss 1.4112 (1.3559)	grad_norm 0.4293 (nan)	loss_scale 2048.0000 (3540.0899)	mem 7962MB
[2024-07-15 08:03:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:04:57 lr 0.000039	 wd 0.0000	time 0.2320 (0.2479)	loss 1.4730 (1.3561)	grad_norm 0.4274 (nan)	loss_scale 2048.0000 (3425.4020)	mem 7962MB
[2024-07-15 08:03:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:33 lr 0.000039	 wd 0.0000	time 0.1808 (0.2485)	loss 1.4132 (1.3569)	grad_norm 0.4358 (nan)	loss_scale 2048.0000 (3327.0864)	mem 7962MB
[2024-07-15 08:04:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:07 lr 0.000039	 wd 0.0000	time 0.1986 (0.2475)	loss 1.6483 (1.3562)	grad_norm 0.4830 (nan)	loss_scale 2048.0000 (3241.8708)	mem 7962MB
[2024-07-15 08:04:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:42 lr 0.000039	 wd 0.0000	time 0.2227 (0.2464)	loss 1.5152 (1.3580)	grad_norm 0.4445 (nan)	loss_scale 2048.0000 (3167.3004)	mem 7962MB
[2024-07-15 08:04:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:16 lr 0.000039	 wd 0.0000	time 0.2218 (0.2456)	loss 1.5741 (1.3583)	grad_norm 0.4440 (nan)	loss_scale 2048.0000 (3101.4979)	mem 7962MB
[2024-07-15 08:05:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:53 lr 0.000039	 wd 0.0000	time 0.2509 (0.2466)	loss 1.1243 (1.3578)	grad_norm 0.4892 (nan)	loss_scale 2048.0000 (3043.0028)	mem 7962MB
[2024-07-15 08:05:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:28 lr 0.000039	 wd 0.0000	time 0.2216 (0.2462)	loss 1.3132 (1.3572)	grad_norm 0.4836 (nan)	loss_scale 2048.0000 (2990.6618)	mem 7962MB
[2024-07-15 08:06:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:02:03 lr 0.000039	 wd 0.0000	time 0.2063 (0.2455)	loss 1.4191 (1.3583)	grad_norm 0.4266 (nan)	loss_scale 2048.0000 (2943.5522)	mem 7962MB
[2024-07-15 08:06:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:38 lr 0.000039	 wd 0.0000	time 0.2720 (0.2449)	loss 1.5036 (1.3594)	grad_norm 0.4582 (nan)	loss_scale 2048.0000 (2900.9272)	mem 7962MB
[2024-07-15 08:07:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:16 lr 0.000039	 wd 0.0000	time 0.1945 (0.2523)	loss 1.1033 (1.3575)	grad_norm 0.4242 (nan)	loss_scale 2048.0000 (2862.1754)	mem 7962MB
[2024-07-15 08:07:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:51 lr 0.000039	 wd 0.0000	time 0.2732 (0.2565)	loss 1.5794 (1.3579)	grad_norm 0.4297 (nan)	loss_scale 2048.0000 (2826.7918)	mem 7962MB
[2024-07-15 08:08:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:26 lr 0.000039	 wd 0.0000	time 0.2396 (0.2572)	loss 1.4718 (1.3575)	grad_norm 0.4222 (nan)	loss_scale 2048.0000 (2794.3557)	mem 7962MB
[2024-07-15 08:09:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1668 (0.2733)	loss 1.2788 (1.3577)	grad_norm 0.4559 (nan)	loss_scale 2048.0000 (2764.5134)	mem 7962MB
[2024-07-15 08:09:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 7 training takes 0:11:30
[2024-07-15 08:10:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 60.946 (60.946)	Loss 0.4233 (0.4233)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 7962MB
[2024-07-15 08:10:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.104 Acc@5 97.256
[2024-07-15 08:10:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 08:10:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-15 08:11:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][0/2502]	eta 11:13:53 lr 0.000039	 wd 0.0000	time 16.1606 (16.1606)	loss 1.4202 (1.4202)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:11:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:16:00 lr 0.000039	 wd 0.0000	time 0.2587 (0.3999)	loss 1.4541 (1.3950)	grad_norm 0.4738 (0.4813)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:11:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:12:51 lr 0.000039	 wd 0.0000	time 0.3793 (0.3353)	loss 1.5289 (1.3704)	grad_norm 0.4198 (0.4769)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:12:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:10:58 lr 0.000038	 wd 0.0000	time 0.2305 (0.2989)	loss 1.3601 (1.3673)	grad_norm 0.5246 (0.4798)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:12:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:09:50 lr 0.000038	 wd 0.0000	time 0.1997 (0.2808)	loss 1.6266 (1.3636)	grad_norm 0.5290 (0.4793)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:13:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:09:00 lr 0.000038	 wd 0.0000	time 0.2521 (0.2700)	loss 1.4406 (1.3667)	grad_norm 0.4618 (0.4778)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:13:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:24 lr 0.000038	 wd 0.0000	time 0.2156 (0.2654)	loss 1.5300 (1.3711)	grad_norm 0.4759 (0.4809)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:13:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:47 lr 0.000038	 wd 0.0000	time 0.2240 (0.2596)	loss 1.6426 (1.3694)	grad_norm 0.5064 (0.4821)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:14:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:14 lr 0.000038	 wd 0.0000	time 0.2208 (0.2555)	loss 1.4751 (1.3670)	grad_norm 0.4298 (0.4791)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:14:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:44 lr 0.000038	 wd 0.0000	time 0.2418 (0.2523)	loss 1.6540 (1.3671)	grad_norm 0.4091 (0.4783)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:14:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:18 lr 0.000038	 wd 0.0000	time 0.2256 (0.2522)	loss 1.4980 (1.3634)	grad_norm 0.6088 (0.4785)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:15:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:52 lr 0.000038	 wd 0.0000	time 0.2420 (0.2511)	loss 1.3338 (1.3604)	grad_norm 0.4407 (0.4792)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:15:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:24 lr 0.000038	 wd 0.0000	time 0.2152 (0.2492)	loss 1.4629 (1.3606)	grad_norm 0.4434 (0.4806)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:16:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:57 lr 0.000038	 wd 0.0000	time 0.1821 (0.2474)	loss 1.1794 (1.3592)	grad_norm 0.5079 (0.4821)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:16:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:32 lr 0.000038	 wd 0.0000	time 0.2568 (0.2473)	loss 0.9621 (1.3609)	grad_norm 0.4510 (0.4830)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:16:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:04:07 lr 0.000038	 wd 0.0000	time 0.2351 (0.2475)	loss 0.8271 (1.3587)	grad_norm 0.4512 (0.4830)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:17:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:42 lr 0.000038	 wd 0.0000	time 0.2293 (0.2464)	loss 1.2268 (1.3559)	grad_norm 0.4185 (0.4822)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:17:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:16 lr 0.000038	 wd 0.0000	time 0.2088 (0.2453)	loss 1.1795 (1.3577)	grad_norm 0.4661 (0.4812)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:18:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:52 lr 0.000038	 wd 0.0000	time 0.2282 (0.2453)	loss 1.5361 (1.3588)	grad_norm 0.4150 (0.4836)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:18:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:28 lr 0.000038	 wd 0.0000	time 0.1922 (0.2461)	loss 1.3008 (1.3580)	grad_norm 0.4555 (0.4840)	loss_scale 4096.0000 (2101.8664)	mem 7962MB
[2024-07-15 08:18:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:02:03 lr 0.000038	 wd 0.0000	time 0.2404 (0.2453)	loss 1.6908 (1.3600)	grad_norm 0.4460 (0.4835)	loss_scale 4096.0000 (2201.5232)	mem 7962MB
[2024-07-15 08:19:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:38 lr 0.000038	 wd 0.0000	time 0.2022 (0.2445)	loss 1.4119 (1.3591)	grad_norm 0.4676 (0.4828)	loss_scale 4096.0000 (2291.6935)	mem 7962MB
[2024-07-15 08:19:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:13 lr 0.000038	 wd 0.0000	time 0.2320 (0.2445)	loss 1.5544 (1.3577)	grad_norm 0.4560 (0.4827)	loss_scale 4096.0000 (2373.6701)	mem 7962MB
[2024-07-15 08:20:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:49 lr 0.000038	 wd 0.0000	time 0.2721 (0.2445)	loss 1.4815 (1.3584)	grad_norm 0.4684 (0.4823)	loss_scale 4096.0000 (2448.5215)	mem 7962MB
[2024-07-15 08:20:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:24 lr 0.000038	 wd 0.0000	time 0.2554 (0.2439)	loss 1.3145 (1.3600)	grad_norm 0.4694 (0.4826)	loss_scale 4096.0000 (2517.1379)	mem 7962MB
[2024-07-15 08:20:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000038	 wd 0.0000	time 0.1733 (0.2422)	loss 1.7450 (1.3614)	grad_norm 0.4114 (0.4835)	loss_scale 4096.0000 (2580.2671)	mem 7962MB
[2024-07-15 08:20:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 8 training takes 0:10:10
[2024-07-15 08:21:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 38.514 (38.514)	Loss 0.4214 (0.4214)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 08:21:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.116 Acc@5 97.248
[2024-07-15 08:21:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 08:21:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-15 08:21:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth saving......
[2024-07-15 08:21:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth saved !!!
[2024-07-15 08:22:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][0/2502]	eta 11:25:57 lr 0.000038	 wd 0.0000	time 16.4500 (16.4500)	loss 1.3607 (1.3607)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 08:22:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:15:37 lr 0.000038	 wd 0.0000	time 0.2308 (0.3902)	loss 1.2349 (1.3258)	grad_norm 0.4496 (0.5248)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 08:22:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:12:07 lr 0.000037	 wd 0.0000	time 0.2549 (0.3161)	loss 1.4915 (1.3385)	grad_norm 0.5916 (0.5045)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 08:23:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:48 lr 0.000037	 wd 0.0000	time 0.2281 (0.2944)	loss 1.4351 (1.3504)	grad_norm 0.4707 (0.5009)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 08:23:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:42 lr 0.000037	 wd 0.0000	time 0.1816 (0.2771)	loss 1.5757 (1.3456)	grad_norm 0.4338 (0.4911)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 08:24:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:08:53 lr 0.000037	 wd 0.0000	time 0.2376 (0.2663)	loss 1.3810 (1.3521)	grad_norm 0.4532 (0.4960)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 08:24:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:15 lr 0.000037	 wd 0.0000	time 0.2375 (0.2605)	loss 1.4963 (1.3467)	grad_norm 0.4253 (0.4911)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 08:24:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:49 lr 0.000037	 wd 0.0000	time 0.2314 (0.2603)	loss 1.5226 (1.3483)	grad_norm 0.4449 (0.4972)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 08:25:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:16 lr 0.000037	 wd 0.0000	time 0.2080 (0.2563)	loss 1.3882 (1.3512)	grad_norm 0.4376 (0.4938)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 08:25:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:45 lr 0.000037	 wd 0.0000	time 0.2338 (0.2532)	loss 1.5964 (1.3483)	grad_norm 0.4956 (0.4929)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 08:25:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:16 lr 0.000037	 wd 0.0000	time 0.2338 (0.2508)	loss 1.4729 (1.3510)	grad_norm 0.4474 (0.4935)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 08:26:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:52 lr 0.000037	 wd 0.0000	time 0.3052 (0.2513)	loss 1.3877 (1.3540)	grad_norm 0.4438 (0.4909)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 08:26:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:25 lr 0.000037	 wd 0.0000	time 0.2142 (0.2498)	loss 1.5464 (1.3550)	grad_norm 0.4100 (0.4905)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 08:27:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:58 lr 0.000037	 wd 0.0000	time 0.2234 (0.2483)	loss 0.9692 (1.3530)	grad_norm 0.4455 (0.4905)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 08:27:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:32 lr 0.000037	 wd 0.0000	time 0.2210 (0.2469)	loss 1.3364 (1.3544)	grad_norm 0.4825 (0.4902)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 08:27:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:04:08 lr 0.000037	 wd 0.0000	time 0.2127 (0.2477)	loss 1.4609 (1.3564)	grad_norm 0.4777 (0.4897)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 08:28:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:42 lr 0.000037	 wd 0.0000	time 0.2132 (0.2472)	loss 0.9292 (1.3554)	grad_norm 0.4142 (0.4918)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 08:28:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:17 lr 0.000037	 wd 0.0000	time 0.2016 (0.2462)	loss 1.1000 (1.3567)	grad_norm 0.4765 (nan)	loss_scale 2048.0000 (4004.4962)	mem 7962MB
[2024-07-15 08:29:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:52 lr 0.000037	 wd 0.0000	time 0.2126 (0.2453)	loss 1.5354 (1.3571)	grad_norm 0.4643 (nan)	loss_scale 2048.0000 (3895.8623)	mem 7962MB
[2024-07-15 08:29:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:28 lr 0.000037	 wd 0.0000	time 0.2269 (0.2461)	loss 1.3316 (1.3558)	grad_norm 0.4612 (nan)	loss_scale 2048.0000 (3798.6575)	mem 7962MB
[2024-07-15 08:30:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:02:03 lr 0.000037	 wd 0.0000	time 0.2289 (0.2460)	loss 1.4874 (1.3560)	grad_norm 0.4481 (nan)	loss_scale 2048.0000 (3711.1684)	mem 7962MB
[2024-07-15 08:30:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:38 lr 0.000036	 wd 0.0000	time 0.2270 (0.2454)	loss 1.0684 (1.3561)	grad_norm 0.4793 (nan)	loss_scale 2048.0000 (3632.0076)	mem 7962MB
[2024-07-15 08:30:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:13 lr 0.000036	 wd 0.0000	time 0.2595 (0.2447)	loss 1.4822 (1.3571)	grad_norm 0.4721 (nan)	loss_scale 2048.0000 (3560.0400)	mem 7962MB
[2024-07-15 08:31:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:50 lr 0.000036	 wd 0.0000	time 9.1499 (0.2491)	loss 1.4185 (1.3578)	grad_norm 0.4735 (nan)	loss_scale 2048.0000 (3494.3277)	mem 7962MB
[2024-07-15 08:31:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:25 lr 0.000036	 wd 0.0000	time 0.4991 (0.2517)	loss 1.2619 (1.3574)	grad_norm 0.7418 (nan)	loss_scale 2048.0000 (3434.0891)	mem 7962MB
[2024-07-15 08:32:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000036	 wd 0.0000	time 0.1852 (0.2523)	loss 1.1255 (1.3585)	grad_norm 0.4547 (nan)	loss_scale 2048.0000 (3378.6677)	mem 7962MB
[2024-07-15 08:32:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 9 training takes 0:10:37
[2024-07-15 08:34:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 101.481 (101.481)	Loss 0.4153 (0.4153)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 08:34:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.056 Acc@5 97.236
[2024-07-15 08:34:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 08:34:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-15 08:34:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][0/2502]	eta 19:36:06 lr 0.000036	 wd 0.0000	time 28.2038 (28.2038)	loss 1.2881 (1.2881)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:35:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:20:09 lr 0.000036	 wd 0.0000	time 0.2067 (0.5035)	loss 1.3559 (1.3391)	grad_norm 0.4084 (0.4740)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:35:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:13:55 lr 0.000036	 wd 0.0000	time 0.2338 (0.3629)	loss 1.2969 (1.3596)	grad_norm 0.4545 (0.4741)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:36:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:11:58 lr 0.000036	 wd 0.0000	time 0.2582 (0.3263)	loss 0.8802 (1.3570)	grad_norm 0.5143 (0.4838)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:36:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:10:36 lr 0.000036	 wd 0.0000	time 0.1987 (0.3026)	loss 1.5172 (1.3603)	grad_norm 0.5076 (0.4786)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:36:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:09:33 lr 0.000036	 wd 0.0000	time 0.2361 (0.2865)	loss 1.4078 (1.3562)	grad_norm 0.6039 (0.4878)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:37:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:45 lr 0.000036	 wd 0.0000	time 0.2081 (0.2765)	loss 1.5147 (1.3566)	grad_norm 0.4233 (0.4847)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:37:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:08:09 lr 0.000036	 wd 0.0000	time 0.2643 (0.2716)	loss 1.4601 (1.3526)	grad_norm 0.4222 (0.4840)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:37:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:07:37 lr 0.000036	 wd 0.0000	time 0.2229 (0.2685)	loss 1.2377 (1.3518)	grad_norm 0.4324 (0.4844)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:38:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:07:02 lr 0.000036	 wd 0.0000	time 0.2080 (0.2639)	loss 1.5339 (1.3520)	grad_norm 0.4451 (0.4850)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:38:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:30 lr 0.000036	 wd 0.0000	time 0.1826 (0.2601)	loss 1.4882 (1.3505)	grad_norm 0.5414 (0.4855)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:39:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:06:01 lr 0.000036	 wd 0.0000	time 0.2525 (0.2579)	loss 1.3011 (1.3481)	grad_norm 0.4950 (0.4852)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:39:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:34 lr 0.000035	 wd 0.0000	time 0.2936 (0.2570)	loss 1.3416 (1.3487)	grad_norm 0.4627 (0.4841)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:39:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:05:06 lr 0.000035	 wd 0.0000	time 0.2085 (0.2547)	loss 1.5714 (1.3514)	grad_norm 0.5166 (0.4843)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:40:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:38 lr 0.000035	 wd 0.0000	time 0.2212 (0.2529)	loss 1.3317 (1.3519)	grad_norm 0.4391 (0.4843)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:40:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:04:12 lr 0.000035	 wd 0.0000	time 0.2574 (0.2516)	loss 1.2562 (1.3519)	grad_norm 0.4849 (0.4854)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:41:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:47 lr 0.000035	 wd 0.0000	time 0.2057 (0.2521)	loss 1.2283 (1.3533)	grad_norm 0.4772 (0.4866)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:41:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:21 lr 0.000035	 wd 0.0000	time 0.2271 (0.2510)	loss 1.3147 (1.3543)	grad_norm 0.4196 (0.4857)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:41:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:55 lr 0.000035	 wd 0.0000	time 0.2239 (0.2499)	loss 1.3994 (1.3550)	grad_norm 0.6211 (0.4851)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:42:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:29 lr 0.000035	 wd 0.0000	time 0.2354 (0.2491)	loss 1.5036 (1.3565)	grad_norm 0.4876 (0.4844)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:42:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:02:05 lr 0.000035	 wd 0.0000	time 0.2686 (0.2495)	loss 1.2497 (1.3575)	grad_norm 0.4589 (0.4845)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:43:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:40 lr 0.000035	 wd 0.0000	time 0.2105 (0.2488)	loss 1.5517 (1.3593)	grad_norm 0.4545 (0.4847)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:43:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:14 lr 0.000035	 wd 0.0000	time 0.2266 (0.2480)	loss 0.9602 (1.3591)	grad_norm 0.5431 (0.4838)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:43:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:49 lr 0.000035	 wd 0.0000	time 0.2440 (0.2474)	loss 1.4800 (1.3586)	grad_norm 0.4643 (0.4831)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:44:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:25 lr 0.000035	 wd 0.0000	time 0.2235 (0.2476)	loss 1.5212 (1.3585)	grad_norm 0.4254 (0.4827)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:44:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1764 (0.2458)	loss 1.3308 (1.3576)	grad_norm 0.4732 (0.4827)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:44:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 10 training takes 0:10:20
[2024-07-15 08:45:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 20.748 (20.748)	Loss 0.4207 (0.4207)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 08:45:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.078 Acc@5 97.232
[2024-07-15 08:45:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 08:45:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-15 08:45:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][0/2502]	eta 16:34:09 lr 0.000035	 wd 0.0000	time 23.8407 (23.8407)	loss 1.4957 (1.4957)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:46:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:19:57 lr 0.000035	 wd 0.0000	time 0.2049 (0.4985)	loss 1.3919 (1.3492)	grad_norm 0.4952 (0.4946)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:46:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:13:51 lr 0.000034	 wd 0.0000	time 0.2140 (0.3612)	loss 1.4653 (1.3534)	grad_norm 0.4428 (0.5023)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:46:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:11:33 lr 0.000034	 wd 0.0000	time 0.2066 (0.3149)	loss 1.3314 (1.3558)	grad_norm 0.4615 (0.4947)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:47:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:10:25 lr 0.000034	 wd 0.0000	time 0.2351 (0.2975)	loss 1.5366 (1.3555)	grad_norm 0.4432 (0.4866)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:47:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:09:30 lr 0.000034	 wd 0.0000	time 0.1885 (0.2849)	loss 1.3873 (1.3525)	grad_norm 0.3990 (0.4879)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:48:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:43 lr 0.000034	 wd 0.0000	time 0.1837 (0.2755)	loss 1.4733 (1.3502)	grad_norm 0.4703 (0.4861)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:48:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:08:04 lr 0.000034	 wd 0.0000	time 0.2086 (0.2686)	loss 1.4738 (1.3506)	grad_norm 0.8156 (0.4864)	loss_scale 4096.0000 (2281.7233)	mem 7962MB
[2024-07-15 08:48:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:07:30 lr 0.000034	 wd 0.0000	time 0.2278 (0.2649)	loss 1.6036 (1.3532)	grad_norm 0.4542 (0.4839)	loss_scale 4096.0000 (2508.2247)	mem 7962MB
[2024-07-15 08:49:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:07:02 lr 0.000034	 wd 0.0000	time 0.2349 (0.2640)	loss 1.5084 (1.3532)	grad_norm 0.4715 (0.4849)	loss_scale 4096.0000 (2684.4484)	mem 7962MB
[2024-07-15 08:49:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:31 lr 0.000034	 wd 0.0000	time 0.2271 (0.2604)	loss 1.4434 (1.3553)	grad_norm 0.5151 (0.4861)	loss_scale 4096.0000 (2825.4625)	mem 7962MB
[2024-07-15 08:49:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:06:00 lr 0.000034	 wd 0.0000	time 0.2189 (0.2574)	loss 1.5573 (1.3567)	grad_norm 0.4641 (0.4857)	loss_scale 4096.0000 (2940.8610)	mem 7962MB
[2024-07-15 08:50:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:32 lr 0.000034	 wd 0.0000	time 0.2663 (0.2554)	loss 1.6959 (1.3565)	grad_norm 0.4504 (0.4847)	loss_scale 4096.0000 (3037.0425)	mem 7962MB
[2024-07-15 08:50:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:05:06 lr 0.000034	 wd 0.0000	time 0.1953 (0.2553)	loss 0.8930 (1.3554)	grad_norm 0.4218 (0.4863)	loss_scale 4096.0000 (3118.4381)	mem 7962MB
[2024-07-15 08:51:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:39 lr 0.000034	 wd 0.0000	time 0.1953 (0.2536)	loss 0.8806 (1.3550)	grad_norm 0.4656 (0.4863)	loss_scale 4096.0000 (3188.2141)	mem 7962MB
[2024-07-15 08:51:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:04:12 lr 0.000034	 wd 0.0000	time 0.2132 (0.2519)	loss 1.4316 (1.3541)	grad_norm 0.4018 (0.4852)	loss_scale 4096.0000 (3248.6929)	mem 7962MB
[2024-07-15 08:51:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:46 lr 0.000034	 wd 0.0000	time 0.2388 (0.2506)	loss 1.2607 (1.3550)	grad_norm 0.4615 (0.4852)	loss_scale 4096.0000 (3301.6165)	mem 7962MB
[2024-07-15 08:52:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:21 lr 0.000033	 wd 0.0000	time 0.2154 (0.2511)	loss 1.4497 (1.3543)	grad_norm 0.4170 (0.4851)	loss_scale 4096.0000 (3348.3175)	mem 7962MB
[2024-07-15 08:52:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:55 lr 0.000033	 wd 0.0000	time 0.2360 (0.2503)	loss 1.2850 (1.3559)	grad_norm 0.7455 (0.4854)	loss_scale 4096.0000 (3389.8323)	mem 7962MB
[2024-07-15 08:53:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:30 lr 0.000033	 wd 0.0000	time 0.1986 (0.2493)	loss 1.5007 (1.3561)	grad_norm 0.4551 (0.4850)	loss_scale 4096.0000 (3426.9795)	mem 7962MB
[2024-07-15 08:53:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:02:04 lr 0.000033	 wd 0.0000	time 0.2425 (0.2485)	loss 1.1156 (1.3555)	grad_norm 0.4228 (0.4841)	loss_scale 4096.0000 (3460.4138)	mem 7962MB
[2024-07-15 08:53:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:39 lr 0.000033	 wd 0.0000	time 0.2290 (0.2485)	loss 1.5410 (1.3552)	grad_norm 0.4465 (0.4835)	loss_scale 4096.0000 (3490.6654)	mem 7962MB
[2024-07-15 08:54:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:14 lr 0.000033	 wd 0.0000	time 0.2130 (0.2479)	loss 1.2734 (1.3561)	grad_norm 0.4458 (inf)	loss_scale 2048.0000 (3451.1731)	mem 7962MB
[2024-07-15 08:54:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:49 lr 0.000033	 wd 0.0000	time 0.2470 (0.2470)	loss 1.5224 (1.3558)	grad_norm 0.5844 (inf)	loss_scale 2048.0000 (3390.1921)	mem 7962MB
[2024-07-15 08:55:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:25 lr 0.000033	 wd 0.0000	time 0.2312 (0.2463)	loss 1.2646 (1.3550)	grad_norm 0.5172 (inf)	loss_scale 2048.0000 (3334.2907)	mem 7962MB
[2024-07-15 08:55:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000033	 wd 0.0000	time 0.1770 (0.2447)	loss 1.3996 (1.3546)	grad_norm 0.4222 (inf)	loss_scale 2048.0000 (3282.8597)	mem 7962MB
[2024-07-15 08:55:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 11 training takes 0:10:30
[2024-07-15 08:56:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 66.412 (66.412)	Loss 0.4194 (0.4194)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 08:57:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.120 Acc@5 97.248
[2024-07-15 08:57:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 08:57:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-15 08:57:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth saving......
[2024-07-15 08:57:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth saved !!!
[2024-07-15 08:57:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][0/2502]	eta 12:36:25 lr 0.000033	 wd 0.0000	time 18.1396 (18.1396)	loss 1.6122 (1.6122)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:58:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:16:05 lr 0.000033	 wd 0.0000	time 0.2463 (0.4019)	loss 1.4940 (1.3602)	grad_norm 0.5127 (0.5118)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:58:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:12:11 lr 0.000033	 wd 0.0000	time 0.2780 (0.3177)	loss 0.9832 (1.3664)	grad_norm 0.4036 (0.5138)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:58:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:56 lr 0.000033	 wd 0.0000	time 0.2092 (0.2981)	loss 1.2937 (1.3665)	grad_norm 0.4770 (0.5018)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:59:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:47 lr 0.000033	 wd 0.0000	time 0.1952 (0.2797)	loss 1.2318 (1.3591)	grad_norm 0.5124 (0.4976)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 08:59:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:08:57 lr 0.000032	 wd 0.0000	time 0.1916 (0.2684)	loss 1.0124 (1.3598)	grad_norm 0.4614 (0.4944)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:00:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:08:17 lr 0.000032	 wd 0.0000	time 0.2361 (0.2618)	loss 1.3413 (1.3571)	grad_norm 0.4956 (0.4966)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:00:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:52 lr 0.000032	 wd 0.0000	time 0.2277 (0.2624)	loss 1.4568 (1.3547)	grad_norm 0.4394 (0.4931)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:00:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:07:18 lr 0.000032	 wd 0.0000	time 0.2093 (0.2578)	loss 1.4451 (1.3626)	grad_norm 0.4345 (0.4947)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:01:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:47 lr 0.000032	 wd 0.0000	time 0.2242 (0.2545)	loss 1.0478 (1.3630)	grad_norm 0.4196 (0.4946)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:01:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:18 lr 0.000032	 wd 0.0000	time 0.2437 (0.2519)	loss 1.6323 (1.3606)	grad_norm 0.4062 (0.4922)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:02:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:55 lr 0.000032	 wd 0.0000	time 0.2346 (0.2536)	loss 1.4798 (1.3646)	grad_norm 0.4099 (0.4909)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:02:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:27 lr 0.000032	 wd 0.0000	time 0.2311 (0.2518)	loss 1.5085 (1.3636)	grad_norm 0.4930 (0.4903)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:02:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:05:00 lr 0.000032	 wd 0.0000	time 0.2402 (0.2501)	loss 1.4515 (1.3641)	grad_norm 0.4676 (0.4896)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:03:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:33 lr 0.000032	 wd 0.0000	time 0.2471 (0.2485)	loss 1.5949 (1.3640)	grad_norm 0.4598 (0.4888)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:03:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:04:08 lr 0.000032	 wd 0.0000	time 0.3091 (0.2485)	loss 1.4332 (1.3646)	grad_norm 0.4264 (0.4876)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:04:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:43 lr 0.000032	 wd 0.0000	time 0.2163 (0.2483)	loss 1.4190 (1.3635)	grad_norm 0.5186 (0.4863)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:04:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:18 lr 0.000031	 wd 0.0000	time 0.2178 (0.2470)	loss 1.5710 (1.3645)	grad_norm 0.4478 (0.4863)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:04:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:52 lr 0.000031	 wd 0.0000	time 0.2273 (0.2461)	loss 1.2792 (1.3653)	grad_norm 0.4584 (0.4864)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:05:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:28 lr 0.000031	 wd 0.0000	time 0.2692 (0.2460)	loss 1.4145 (1.3648)	grad_norm 0.5371 (0.4860)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:05:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:02:03 lr 0.000031	 wd 0.0000	time 0.2104 (0.2464)	loss 1.3977 (1.3639)	grad_norm 0.4352 (0.4863)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:05:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:38 lr 0.000031	 wd 0.0000	time 0.2206 (0.2457)	loss 1.4334 (1.3651)	grad_norm 0.4419 (0.4858)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:06:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:13 lr 0.000031	 wd 0.0000	time 0.1802 (0.2448)	loss 1.5583 (1.3666)	grad_norm 0.4611 (0.4854)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:06:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:49 lr 0.000031	 wd 0.0000	time 0.2394 (0.2448)	loss 1.4304 (1.3665)	grad_norm 0.5743 (0.4853)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:07:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:24 lr 0.000031	 wd 0.0000	time 0.2156 (0.2449)	loss 1.5032 (1.3662)	grad_norm 0.6873 (0.4854)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:07:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000031	 wd 0.0000	time 0.1761 (0.2430)	loss 1.1205 (1.3651)	grad_norm 0.5051 (0.4857)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:07:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 12 training takes 0:10:12
[2024-07-15 09:07:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 19.023 (19.023)	Loss 0.4187 (0.4187)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 09:08:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.128 Acc@5 97.262
[2024-07-15 09:08:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 09:08:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 09:08:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth saving......
[2024-07-15 09:08:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth saved !!!
[2024-07-15 09:08:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][0/2502]	eta 1 day, 1:15:56 lr 0.000031	 wd 0.0000	time 36.3535 (36.3535)	loss 1.3632 (1.3632)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:09:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:24:02 lr 0.000031	 wd 0.0000	time 0.2246 (0.6005)	loss 1.3823 (1.3538)	grad_norm 0.4742 (0.4778)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:09:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:15:47 lr 0.000031	 wd 0.0000	time 0.2005 (0.4118)	loss 1.6833 (1.3555)	grad_norm 0.5045 (0.4742)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:10:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:13:43 lr 0.000031	 wd 0.0000	time 0.4837 (0.3741)	loss 1.4437 (1.3637)	grad_norm 0.4499 (0.4778)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:10:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:12:38 lr 0.000030	 wd 0.0000	time 0.2275 (0.3606)	loss 1.3314 (1.3625)	grad_norm 0.4450 (0.4763)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:10:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:11:08 lr 0.000030	 wd 0.0000	time 0.2445 (0.3337)	loss 1.5296 (1.3572)	grad_norm 0.8919 (0.4803)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:11:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:09:58 lr 0.000030	 wd 0.0000	time 0.2428 (0.3149)	loss 1.5377 (1.3635)	grad_norm 0.4263 (0.4796)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:11:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:09:14 lr 0.000030	 wd 0.0000	time 1.0631 (0.3078)	loss 1.4313 (1.3589)	grad_norm 0.4860 (0.4790)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:12:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:08:30 lr 0.000030	 wd 0.0000	time 0.2170 (0.3000)	loss 1.5439 (1.3628)	grad_norm 0.5120 (0.4775)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:12:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:07:47 lr 0.000030	 wd 0.0000	time 0.2665 (0.2921)	loss 1.5256 (1.3598)	grad_norm 0.4573 (0.4774)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:12:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:07:08 lr 0.000030	 wd 0.0000	time 0.1937 (0.2855)	loss 1.6057 (1.3653)	grad_norm 0.4429 (0.4803)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:13:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:06:35 lr 0.000030	 wd 0.0000	time 0.2272 (0.2818)	loss 1.3919 (1.3668)	grad_norm 0.4840 (0.4794)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:13:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:06:02 lr 0.000030	 wd 0.0000	time 0.2326 (0.2787)	loss 1.5565 (1.3631)	grad_norm 0.4344 (0.4798)	loss_scale 4096.0000 (2177.5987)	mem 7962MB
[2024-07-15 09:14:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:05:30 lr 0.000030	 wd 0.0000	time 0.2498 (0.2749)	loss 1.4252 (1.3618)	grad_norm 0.4182 (0.4793)	loss_scale 4096.0000 (2325.0546)	mem 7962MB
[2024-07-15 09:14:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:59 lr 0.000030	 wd 0.0000	time 0.2052 (0.2713)	loss 1.6521 (1.3624)	grad_norm 0.4557 (0.4792)	loss_scale 4096.0000 (2451.4604)	mem 7962MB
[2024-07-15 09:14:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:04:30 lr 0.000030	 wd 0.0000	time 0.2439 (0.2695)	loss 1.6345 (1.3611)	grad_norm 0.4397 (0.4805)	loss_scale 4096.0000 (2561.0233)	mem 7962MB
[2024-07-15 09:15:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:04:02 lr 0.000029	 wd 0.0000	time 0.2248 (0.2689)	loss 1.5744 (1.3608)	grad_norm 0.4402 (0.4798)	loss_scale 4096.0000 (2656.8994)	mem 7962MB
[2024-07-15 09:15:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:33 lr 0.000029	 wd 0.0000	time 0.2393 (0.2665)	loss 0.8619 (1.3584)	grad_norm 0.4560 (0.4799)	loss_scale 4096.0000 (2741.5026)	mem 7962MB
[2024-07-15 09:16:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:03:05 lr 0.000029	 wd 0.0000	time 0.2107 (0.2646)	loss 1.4257 (1.3600)	grad_norm 0.4694 (0.4804)	loss_scale 4096.0000 (2816.7107)	mem 7962MB
[2024-07-15 09:16:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:38 lr 0.000029	 wd 0.0000	time 0.2232 (0.2634)	loss 1.2060 (1.3605)	grad_norm 0.4403 (0.4800)	loss_scale 4096.0000 (2884.0063)	mem 7962MB
[2024-07-15 09:16:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:02:12 lr 0.000029	 wd 0.0000	time 0.2158 (0.2631)	loss 1.4353 (1.3614)	grad_norm 0.7932 (0.4800)	loss_scale 4096.0000 (2944.5757)	mem 7962MB
[2024-07-15 09:17:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:45 lr 0.000029	 wd 0.0000	time 0.1987 (0.2616)	loss 1.1120 (1.3612)	grad_norm 0.4996 (0.4799)	loss_scale 4096.0000 (2999.3793)	mem 7962MB
[2024-07-15 09:17:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:18 lr 0.000029	 wd 0.0000	time 0.2456 (0.2602)	loss 1.5321 (1.3626)	grad_norm 0.4419 (0.4789)	loss_scale 4096.0000 (3049.2031)	mem 7962MB
[2024-07-15 09:18:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:52 lr 0.000029	 wd 0.0000	time 0.2208 (0.2594)	loss 1.3118 (1.3621)	grad_norm 0.4864 (0.4790)	loss_scale 4096.0000 (3094.6962)	mem 7962MB
[2024-07-15 09:18:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:26 lr 0.000029	 wd 0.0000	time 0.2089 (0.2590)	loss 1.6840 (1.3633)	grad_norm 0.4430 (0.4791)	loss_scale 4096.0000 (3136.3998)	mem 7962MB
[2024-07-15 09:18:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000029	 wd 0.0000	time 0.1819 (0.2567)	loss 1.5200 (1.3627)	grad_norm 0.4401 (0.4782)	loss_scale 4096.0000 (3174.7685)	mem 7962MB
[2024-07-15 09:18:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 13 training takes 0:10:47
[2024-07-15 09:19:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 21.638 (21.638)	Loss 0.4189 (0.4189)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 7962MB
[2024-07-15 09:19:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.152 Acc@5 97.262
[2024-07-15 09:19:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 09:19:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-15 09:19:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth saving......
[2024-07-15 09:19:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth saved !!!
[2024-07-15 09:20:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][0/2502]	eta 23:50:55 lr 0.000029	 wd 0.0000	time 34.3148 (34.3148)	loss 1.4848 (1.4848)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:20:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:23:01 lr 0.000029	 wd 0.0000	time 0.2020 (0.5753)	loss 1.5420 (1.3729)	grad_norm 0.4066 (0.4645)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:20:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:15:22 lr 0.000028	 wd 0.0000	time 0.1994 (0.4009)	loss 1.3094 (1.3925)	grad_norm 0.4613 (0.4710)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:21:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:12:47 lr 0.000028	 wd 0.0000	time 0.2232 (0.3485)	loss 1.0189 (1.3802)	grad_norm 0.5210 (0.4729)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:21:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:11:20 lr 0.000028	 wd 0.0000	time 0.2309 (0.3236)	loss 1.2144 (1.3651)	grad_norm 0.5221 (0.4731)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:22:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:10:07 lr 0.000028	 wd 0.0000	time 0.2133 (0.3035)	loss 1.2833 (1.3679)	grad_norm 0.5940 (0.4773)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:22:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:09:12 lr 0.000028	 wd 0.0000	time 0.2297 (0.2906)	loss 1.6578 (1.3733)	grad_norm 0.4717 (0.4818)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:22:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:08:29 lr 0.000028	 wd 0.0000	time 0.2103 (0.2829)	loss 1.4361 (1.3691)	grad_norm 0.5104 (0.4805)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:23:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:55 lr 0.000028	 wd 0.0000	time 0.2669 (0.2795)	loss 1.3802 (1.3653)	grad_norm 0.5371 (0.4809)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:23:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:07:18 lr 0.000028	 wd 0.0000	time 0.2368 (0.2740)	loss 1.4372 (1.3613)	grad_norm 0.4528 (0.4804)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:24:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:06:44 lr 0.000028	 wd 0.0000	time 0.2114 (0.2696)	loss 1.3163 (1.3598)	grad_norm 0.4149 (0.4823)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:24:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:06:13 lr 0.000028	 wd 0.0000	time 0.2436 (0.2662)	loss 1.4886 (1.3574)	grad_norm 0.3960 (0.4853)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:24:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:44 lr 0.000028	 wd 0.0000	time 0.2238 (0.2649)	loss 1.4183 (1.3576)	grad_norm 0.4488 (0.4836)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:25:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:05:15 lr 0.000027	 wd 0.0000	time 0.2310 (0.2625)	loss 1.1816 (1.3578)	grad_norm 0.4178 (0.4837)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:25:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:46 lr 0.000027	 wd 0.0000	time 0.1890 (0.2601)	loss 1.6515 (1.3567)	grad_norm 0.4539 (0.4831)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:25:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:04:18 lr 0.000027	 wd 0.0000	time 0.2145 (0.2581)	loss 1.3776 (1.3576)	grad_norm 0.4148 (0.4943)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:26:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:53 lr 0.000027	 wd 0.0000	time 0.1941 (0.2587)	loss 1.3193 (1.3575)	grad_norm 0.4802 (0.4952)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:26:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:26 lr 0.000027	 wd 0.0000	time 0.3172 (0.2573)	loss 1.1892 (1.3568)	grad_norm 0.5158 (nan)	loss_scale 2048.0000 (3990.0482)	mem 7962MB
[2024-07-15 09:27:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:59 lr 0.000027	 wd 0.0000	time 0.2088 (0.2560)	loss 1.3042 (1.3567)	grad_norm 0.4420 (nan)	loss_scale 2048.0000 (3882.2165)	mem 7962MB
[2024-07-15 09:27:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:33 lr 0.000027	 wd 0.0000	time 0.2402 (0.2547)	loss 1.5399 (1.3568)	grad_norm 0.4577 (nan)	loss_scale 2048.0000 (3785.7296)	mem 7962MB
[2024-07-15 09:28:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:02:07 lr 0.000027	 wd 0.0000	time 0.2130 (0.2547)	loss 1.0657 (1.3586)	grad_norm 0.4204 (nan)	loss_scale 2048.0000 (3698.8866)	mem 7962MB
[2024-07-15 09:28:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:42 lr 0.000027	 wd 0.0000	time 0.2071 (0.2538)	loss 1.5540 (1.3584)	grad_norm 0.4881 (nan)	loss_scale 2048.0000 (3620.3103)	mem 7962MB
[2024-07-15 09:28:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:16 lr 0.000027	 wd 0.0000	time 0.2207 (0.2527)	loss 1.2214 (1.3586)	grad_norm 0.4236 (nan)	loss_scale 2048.0000 (3548.8741)	mem 7962MB
[2024-07-15 09:29:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:50 lr 0.000027	 wd 0.0000	time 0.2321 (0.2518)	loss 1.3840 (1.3594)	grad_norm 0.4598 (nan)	loss_scale 2048.0000 (3483.6471)	mem 7962MB
[2024-07-15 09:29:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:25 lr 0.000026	 wd 0.0000	time 0.2212 (0.2516)	loss 1.1281 (1.3605)	grad_norm 0.5197 (nan)	loss_scale 2048.0000 (3423.8534)	mem 7962MB
[2024-07-15 09:29:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1754 (0.2498)	loss 1.2569 (1.3596)	grad_norm 0.4680 (nan)	loss_scale 2048.0000 (3368.8413)	mem 7962MB
[2024-07-15 09:30:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 14 training takes 0:10:30
[2024-07-15 09:30:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 18.755 (18.755)	Loss 0.4170 (0.4170)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 09:30:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.148 Acc@5 97.252
[2024-07-15 09:30:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 09:30:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-15 09:30:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][0/2502]	eta 12:43:47 lr 0.000026	 wd 0.0000	time 18.3165 (18.3165)	loss 1.4565 (1.4565)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:31:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:23:03 lr 0.000026	 wd 0.0000	time 0.3055 (0.5760)	loss 1.0222 (1.3464)	grad_norm 0.4472 (0.5285)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:32:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:17:13 lr 0.000026	 wd 0.0000	time 0.6383 (0.4489)	loss 1.4436 (1.3614)	grad_norm 0.6100 (0.5027)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:32:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:15:15 lr 0.000026	 wd 0.0000	time 0.2698 (0.4155)	loss 1.3923 (1.3484)	grad_norm 0.3915 (0.4974)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:34:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:18:05 lr 0.000026	 wd 0.0000	time 0.3246 (0.5164)	loss 1.3934 (1.3520)	grad_norm 0.4559 (0.4930)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:34:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:16:23 lr 0.000026	 wd 0.0000	time 0.2053 (0.4910)	loss 0.8711 (1.3499)	grad_norm 0.4182 (0.4875)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:35:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:14:10 lr 0.000026	 wd 0.0000	time 0.2368 (0.4472)	loss 0.8467 (1.3533)	grad_norm 0.4803 (0.4835)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:35:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:12:28 lr 0.000026	 wd 0.0000	time 0.2409 (0.4156)	loss 1.1039 (1.3558)	grad_norm 0.6068 (0.4840)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:35:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:11:09 lr 0.000026	 wd 0.0000	time 0.2494 (0.3933)	loss 1.4084 (1.3562)	grad_norm 0.5124 (0.4859)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:36:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:10:04 lr 0.000025	 wd 0.0000	time 0.2168 (0.3771)	loss 1.2231 (1.3570)	grad_norm 0.4712 (0.4872)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:36:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:09:04 lr 0.000025	 wd 0.0000	time 0.2302 (0.3625)	loss 1.4294 (1.3585)	grad_norm 0.4415 (0.4860)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:36:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:08:11 lr 0.000025	 wd 0.0000	time 0.2179 (0.3503)	loss 1.2482 (1.3556)	grad_norm 0.4121 (0.4841)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:37:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:07:23 lr 0.000025	 wd 0.0000	time 0.2395 (0.3407)	loss 1.3946 (1.3563)	grad_norm 0.4154 (0.4820)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:37:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:06:41 lr 0.000025	 wd 0.0000	time 0.1908 (0.3341)	loss 1.3636 (1.3546)	grad_norm 0.4238 (0.4811)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:38:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:06:00 lr 0.000025	 wd 0.0000	time 0.2186 (0.3269)	loss 1.4498 (1.3548)	grad_norm 0.4409 (0.4806)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:38:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:05:20 lr 0.000025	 wd 0.0000	time 0.2195 (0.3203)	loss 1.5727 (1.3546)	grad_norm 0.4793 (0.4822)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:38:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:04:43 lr 0.000025	 wd 0.0000	time 0.2092 (0.3148)	loss 1.2797 (1.3569)	grad_norm 0.4306 (0.4846)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:39:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:04:09 lr 0.000025	 wd 0.0000	time 0.2036 (0.3116)	loss 1.4313 (1.3559)	grad_norm 0.8412 (0.4849)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:39:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:03:35 lr 0.000025	 wd 0.0000	time 0.2059 (0.3076)	loss 1.0703 (1.3556)	grad_norm 0.4461 (0.4841)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:40:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:03:02 lr 0.000024	 wd 0.0000	time 0.2213 (0.3037)	loss 1.6001 (1.3561)	grad_norm 0.4619 (0.4838)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:40:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:02:30 lr 0.000024	 wd 0.0000	time 0.2396 (0.3002)	loss 1.8336 (1.3583)	grad_norm 0.4805 (0.4842)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:40:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:59 lr 0.000024	 wd 0.0000	time 0.2307 (0.2976)	loss 1.5124 (1.3590)	grad_norm 0.6444 (0.4839)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:41:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:29 lr 0.000024	 wd 0.0000	time 0.2236 (0.2948)	loss 1.0676 (1.3602)	grad_norm 0.4379 (0.4836)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:41:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:58 lr 0.000024	 wd 0.0000	time 0.2164 (0.2920)	loss 1.5773 (1.3603)	grad_norm 0.5486 (0.4834)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:42:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:29 lr 0.000024	 wd 0.0000	time 0.2039 (0.2895)	loss 1.0644 (1.3592)	grad_norm 0.4618 (0.4844)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:42:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1676 (0.2862)	loss 1.2124 (1.3593)	grad_norm 0.5258 (0.4832)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:42:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 15 training takes 0:12:04
[2024-07-15 09:42:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_15.pth saving......
[2024-07-15 09:42:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_15.pth saved !!!
[2024-07-15 09:43:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 28.855 (28.855)	Loss 0.4177 (0.4177)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 09:43:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.094 Acc@5 97.248
[2024-07-15 09:43:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 09:43:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-15 09:43:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][0/2502]	eta 11:36:09 lr 0.000024	 wd 0.0000	time 16.6943 (16.6943)	loss 1.2771 (1.2771)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:44:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:16:32 lr 0.000024	 wd 0.0000	time 0.3055 (0.4132)	loss 1.4711 (1.3532)	grad_norm 0.4703 (0.5642)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:44:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:12:34 lr 0.000024	 wd 0.0000	time 0.2159 (0.3276)	loss 1.3100 (1.3625)	grad_norm 0.4881 (0.5232)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:44:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:10:46 lr 0.000024	 wd 0.0000	time 0.2144 (0.2937)	loss 1.3570 (1.3746)	grad_norm 0.4177 (0.5100)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:45:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:09:40 lr 0.000024	 wd 0.0000	time 0.2051 (0.2760)	loss 1.2742 (1.3686)	grad_norm 0.8666 (0.5033)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:45:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:08:57 lr 0.000023	 wd 0.0000	time 0.2771 (0.2686)	loss 1.2547 (1.3788)	grad_norm 0.4297 (0.5016)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:45:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:24 lr 0.000023	 wd 0.0000	time 0.1850 (0.2650)	loss 1.0391 (1.3710)	grad_norm 0.4622 (0.5014)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 09:46:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:47 lr 0.000023	 wd 0.0000	time 0.2212 (0.2596)	loss 1.3290 (1.3728)	grad_norm 0.4591 (0.5007)	loss_scale 4096.0000 (2316.7817)	mem 7962MB
[2024-07-15 09:46:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:07:14 lr 0.000023	 wd 0.0000	time 0.2299 (0.2555)	loss 1.3904 (1.3673)	grad_norm 0.4292 (0.4965)	loss_scale 4096.0000 (2538.9064)	mem 7962MB
[2024-07-15 09:47:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:46 lr 0.000023	 wd 0.0000	time 0.2632 (0.2535)	loss 1.5605 (1.3651)	grad_norm 0.4345 (0.4981)	loss_scale 4096.0000 (2711.7248)	mem 7962MB
[2024-07-15 09:47:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:06:20 lr 0.000023	 wd 0.0000	time 0.2555 (0.2533)	loss 1.5583 (1.3653)	grad_norm 0.4219 (0.4955)	loss_scale 4096.0000 (2850.0140)	mem 7962MB
[2024-07-15 09:47:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:51 lr 0.000023	 wd 0.0000	time 0.2353 (0.2510)	loss 1.3306 (1.3664)	grad_norm 0.4407 (0.4942)	loss_scale 4096.0000 (2963.1826)	mem 7962MB
[2024-07-15 09:48:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:24 lr 0.000023	 wd 0.0000	time 0.2082 (0.2491)	loss 1.4046 (1.3676)	grad_norm 0.4564 (0.4931)	loss_scale 4096.0000 (3057.5054)	mem 7962MB
[2024-07-15 09:48:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:04:57 lr 0.000023	 wd 0.0000	time 0.2151 (0.2479)	loss 1.1038 (1.3681)	grad_norm 0.4125 (0.4913)	loss_scale 4096.0000 (3137.3282)	mem 7962MB
[2024-07-15 09:49:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:33 lr 0.000023	 wd 0.0000	time 0.2090 (0.2482)	loss 1.2054 (1.3654)	grad_norm 0.4373 (0.4906)	loss_scale 4096.0000 (3205.7559)	mem 7962MB
[2024-07-15 09:49:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:04:07 lr 0.000022	 wd 0.0000	time 0.2165 (0.2472)	loss 1.4027 (1.3623)	grad_norm 0.4260 (0.4890)	loss_scale 4096.0000 (3265.0660)	mem 7962MB
[2024-07-15 09:49:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:41 lr 0.000022	 wd 0.0000	time 0.2113 (0.2461)	loss 1.3811 (1.3627)	grad_norm 0.5306 (0.4899)	loss_scale 4096.0000 (3316.9669)	mem 7962MB
[2024-07-15 09:50:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:16 lr 0.000022	 wd 0.0000	time 0.2341 (0.2453)	loss 1.1177 (1.3607)	grad_norm 0.4929 (0.4881)	loss_scale 4096.0000 (3362.7654)	mem 7962MB
[2024-07-15 09:50:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:52 lr 0.000022	 wd 0.0000	time 0.3063 (0.2463)	loss 1.2447 (1.3590)	grad_norm 0.4568 (0.4882)	loss_scale 4096.0000 (3403.4781)	mem 7962MB
[2024-07-15 09:51:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:28 lr 0.000022	 wd 0.0000	time 0.2023 (0.2460)	loss 1.1938 (1.3579)	grad_norm 0.4352 (0.4869)	loss_scale 4096.0000 (3439.9074)	mem 7962MB
[2024-07-15 09:51:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:02:03 lr 0.000022	 wd 0.0000	time 0.2290 (0.2452)	loss 1.4725 (1.3581)	grad_norm 0.4819 (0.4871)	loss_scale 4096.0000 (3472.6957)	mem 7962MB
[2024-07-15 09:51:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:38 lr 0.000022	 wd 0.0000	time 0.2272 (0.2445)	loss 1.3552 (1.3577)	grad_norm 0.4378 (0.4867)	loss_scale 4096.0000 (3502.3627)	mem 7962MB
[2024-07-15 09:52:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:17 lr 0.000022	 wd 0.0000	time 0.2232 (0.2572)	loss 1.4676 (1.3583)	grad_norm 0.5012 (0.4893)	loss_scale 4096.0000 (3529.3339)	mem 7962MB
[2024-07-15 09:53:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:52 lr 0.000022	 wd 0.0000	time 0.2831 (0.2592)	loss 1.2230 (1.3584)	grad_norm 0.4469 (0.4892)	loss_scale 4096.0000 (3553.9609)	mem 7962MB
[2024-07-15 09:53:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:26 lr 0.000022	 wd 0.0000	time 0.5549 (0.2605)	loss 1.5382 (1.3585)	grad_norm 0.7546 (0.4887)	loss_scale 4096.0000 (3576.5364)	mem 7962MB
[2024-07-15 09:54:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1721 (0.2708)	loss 1.3653 (1.3585)	grad_norm 0.4263 (0.4885)	loss_scale 4096.0000 (3597.3067)	mem 7962MB
[2024-07-15 09:54:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 16 training takes 0:11:23
[2024-07-15 09:55:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 65.200 (65.200)	Loss 0.4180 (0.4180)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 09:56:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.138 Acc@5 97.246
[2024-07-15 09:56:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 09:56:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-15 09:56:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][0/2502]	eta 11:29:51 lr 0.000021	 wd 0.0000	time 16.5432 (16.5432)	loss 1.4508 (1.4508)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:56:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:15:51 lr 0.000021	 wd 0.0000	time 0.2397 (0.3962)	loss 1.5563 (1.3319)	grad_norm 0.4536 (0.4573)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:57:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:12:45 lr 0.000021	 wd 0.0000	time 0.1973 (0.3324)	loss 1.5879 (1.3473)	grad_norm 0.4661 (0.4641)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:57:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:54 lr 0.000021	 wd 0.0000	time 0.2079 (0.2971)	loss 1.3355 (1.3438)	grad_norm 0.5040 (0.4694)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:57:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:09:47 lr 0.000021	 wd 0.0000	time 0.2208 (0.2794)	loss 1.1177 (1.3380)	grad_norm 0.4212 (0.4696)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:58:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:08:58 lr 0.000021	 wd 0.0000	time 0.2406 (0.2688)	loss 1.3687 (1.3381)	grad_norm 0.4350 (0.4700)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:58:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:23 lr 0.000021	 wd 0.0000	time 0.2295 (0.2648)	loss 1.1861 (1.3451)	grad_norm 0.4318 (0.4757)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:59:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:49 lr 0.000021	 wd 0.0000	time 0.2296 (0.2604)	loss 1.3256 (1.3508)	grad_norm 0.4780 (0.4767)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:59:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:07:16 lr 0.000021	 wd 0.0000	time 0.2695 (0.2566)	loss 1.3739 (1.3546)	grad_norm 0.4897 (0.4763)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 09:59:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:45 lr 0.000021	 wd 0.0000	time 0.2194 (0.2531)	loss 1.5953 (1.3560)	grad_norm 0.4248 (0.4767)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:00:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:18 lr 0.000020	 wd 0.0000	time 0.2240 (0.2523)	loss 1.5380 (1.3545)	grad_norm 0.4345 (0.4778)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:00:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:52 lr 0.000020	 wd 0.0000	time 0.2365 (0.2515)	loss 1.1116 (1.3550)	grad_norm 0.4077 (0.4779)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:01:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:25 lr 0.000020	 wd 0.0000	time 0.2291 (0.2498)	loss 1.5867 (1.3568)	grad_norm 0.4142 (0.4794)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:01:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:04:58 lr 0.000020	 wd 0.0000	time 0.1801 (0.2481)	loss 1.1660 (1.3568)	grad_norm 0.4594 (0.4793)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:01:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:32 lr 0.000020	 wd 0.0000	time 0.2298 (0.2477)	loss 1.4902 (1.3575)	grad_norm 0.4884 (0.4832)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:02:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:04:08 lr 0.000020	 wd 0.0000	time 0.2053 (0.2484)	loss 1.4006 (1.3583)	grad_norm 0.4864 (0.4856)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:02:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:43 lr 0.000020	 wd 0.0000	time 0.2372 (0.2473)	loss 1.5508 (1.3596)	grad_norm 0.4364 (0.4861)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:03:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:17 lr 0.000020	 wd 0.0000	time 0.2129 (0.2462)	loss 1.5768 (1.3616)	grad_norm 0.4682 (0.4871)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:03:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:52 lr 0.000020	 wd 0.0000	time 0.2793 (0.2459)	loss 1.3005 (1.3624)	grad_norm 0.5090 (0.4863)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:03:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:28 lr 0.000020	 wd 0.0000	time 0.2419 (0.2464)	loss 1.1527 (1.3632)	grad_norm 0.4452 (0.4856)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:04:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:02:03 lr 0.000019	 wd 0.0000	time 0.2314 (0.2456)	loss 1.5566 (1.3611)	grad_norm 0.4610 (0.4846)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:04:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:38 lr 0.000019	 wd 0.0000	time 0.2025 (0.2448)	loss 1.4426 (1.3608)	grad_norm 0.4358 (0.4846)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:05:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:13 lr 0.000019	 wd 0.0000	time 0.2277 (0.2445)	loss 1.3364 (1.3619)	grad_norm 0.4566 (0.4848)	loss_scale 8192.0000 (4270.9314)	mem 7962MB
[2024-07-15 10:05:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:49 lr 0.000019	 wd 0.0000	time 0.2219 (0.2449)	loss 1.4654 (1.3613)	grad_norm 0.4677 (0.4846)	loss_scale 8192.0000 (4441.3385)	mem 7962MB
[2024-07-15 10:05:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:24 lr 0.000019	 wd 0.0000	time 0.2212 (0.2443)	loss 1.4640 (1.3600)	grad_norm 0.5471 (0.4850)	loss_scale 8192.0000 (4597.5510)	mem 7962MB
[2024-07-15 10:06:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000019	 wd 0.0000	time 0.1670 (0.2425)	loss 1.4962 (1.3605)	grad_norm 0.4542 (0.4856)	loss_scale 8192.0000 (4741.2715)	mem 7962MB
[2024-07-15 10:06:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 17 training takes 0:10:10
[2024-07-15 10:06:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 31.717 (31.717)	Loss 0.4160 (0.4160)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 10:07:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.136 Acc@5 97.252
[2024-07-15 10:07:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 10:07:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-15 10:07:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][0/2502]	eta 12:20:44 lr 0.000019	 wd 0.0000	time 17.7635 (17.7635)	loss 1.6049 (1.6049)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 10:07:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:15:53 lr 0.000019	 wd 0.0000	time 0.2123 (0.3969)	loss 1.5511 (1.4001)	grad_norm 0.4299 (0.4979)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 10:08:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:11:59 lr 0.000019	 wd 0.0000	time 0.2424 (0.3125)	loss 1.4750 (1.3809)	grad_norm 0.4303 (0.4940)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 10:08:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:10:52 lr 0.000019	 wd 0.0000	time 0.2306 (0.2964)	loss 1.7128 (1.3803)	grad_norm 0.4249 (0.5005)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 10:08:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:09:46 lr 0.000019	 wd 0.0000	time 0.2208 (0.2789)	loss 1.4473 (1.3733)	grad_norm 0.5634 (nan)	loss_scale 4096.0000 (7926.4239)	mem 7962MB
[2024-07-15 10:09:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:08:56 lr 0.000018	 wd 0.0000	time 0.2289 (0.2678)	loss 1.3107 (1.3628)	grad_norm 0.4463 (nan)	loss_scale 4096.0000 (7161.8683)	mem 7962MB
[2024-07-15 10:09:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:08:16 lr 0.000018	 wd 0.0000	time 0.2489 (0.2610)	loss 1.6304 (1.3636)	grad_norm 0.4094 (nan)	loss_scale 4096.0000 (6651.7404)	mem 7962MB
[2024-07-15 10:10:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:07:49 lr 0.000018	 wd 0.0000	time 0.2511 (0.2606)	loss 1.4351 (1.3640)	grad_norm 0.4203 (nan)	loss_scale 4096.0000 (6287.1555)	mem 7962MB
[2024-07-15 10:10:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:18 lr 0.000018	 wd 0.0000	time 0.2140 (0.2575)	loss 1.0989 (1.3614)	grad_norm 0.4404 (nan)	loss_scale 4096.0000 (6013.6030)	mem 7962MB
[2024-07-15 10:10:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:06:47 lr 0.000018	 wd 0.0000	time 0.2261 (0.2544)	loss 1.1791 (1.3576)	grad_norm 0.5335 (nan)	loss_scale 4096.0000 (5800.7725)	mem 7962MB
[2024-07-15 10:11:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:17 lr 0.000018	 wd 0.0000	time 0.2015 (0.2514)	loss 1.0388 (1.3612)	grad_norm 0.4498 (nan)	loss_scale 4096.0000 (5630.4655)	mem 7962MB
[2024-07-15 10:11:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:52 lr 0.000018	 wd 0.0000	time 0.2776 (0.2511)	loss 1.2497 (1.3607)	grad_norm 0.4235 (nan)	loss_scale 4096.0000 (5491.0954)	mem 7962MB
[2024-07-15 10:12:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:26 lr 0.000018	 wd 0.0000	time 0.2095 (0.2509)	loss 1.6583 (1.3610)	grad_norm 0.4189 (nan)	loss_scale 4096.0000 (5374.9342)	mem 7962MB
[2024-07-15 10:12:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:04:59 lr 0.000018	 wd 0.0000	time 0.1996 (0.2493)	loss 1.4089 (1.3617)	grad_norm 0.4426 (nan)	loss_scale 4096.0000 (5276.6303)	mem 7962MB
[2024-07-15 10:12:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:32 lr 0.000018	 wd 0.0000	time 0.2290 (0.2477)	loss 1.2163 (1.3615)	grad_norm 0.4527 (nan)	loss_scale 4096.0000 (5192.3597)	mem 7962MB
[2024-07-15 10:13:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:04:07 lr 0.000017	 wd 0.0000	time 0.2203 (0.2474)	loss 1.5865 (1.3606)	grad_norm 0.4320 (nan)	loss_scale 4096.0000 (5119.3178)	mem 7962MB
[2024-07-15 10:13:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:43 lr 0.000017	 wd 0.0000	time 0.2010 (0.2475)	loss 1.4832 (1.3600)	grad_norm 0.5998 (nan)	loss_scale 4096.0000 (5055.4004)	mem 7962MB
[2024-07-15 10:14:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:17 lr 0.000017	 wd 0.0000	time 0.2212 (0.2465)	loss 1.4753 (1.3603)	grad_norm 0.4475 (nan)	loss_scale 4096.0000 (4998.9982)	mem 7962MB
[2024-07-15 10:14:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:52 lr 0.000017	 wd 0.0000	time 0.2831 (0.2456)	loss 1.3209 (1.3611)	grad_norm 0.4317 (nan)	loss_scale 4096.0000 (4948.8595)	mem 7962MB
[2024-07-15 10:14:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:27 lr 0.000017	 wd 0.0000	time 0.2427 (0.2455)	loss 1.4681 (1.3604)	grad_norm 0.4261 (nan)	loss_scale 4096.0000 (4903.9958)	mem 7962MB
[2024-07-15 10:15:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:02:03 lr 0.000017	 wd 0.0000	time 0.2225 (0.2463)	loss 1.3761 (1.3625)	grad_norm 0.4346 (nan)	loss_scale 4096.0000 (4863.6162)	mem 7962MB
[2024-07-15 10:15:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:38 lr 0.000017	 wd 0.0000	time 0.2423 (0.2457)	loss 1.4470 (1.3618)	grad_norm 0.4162 (nan)	loss_scale 4096.0000 (4827.0804)	mem 7962MB
[2024-07-15 10:16:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:13 lr 0.000017	 wd 0.0000	time 0.2293 (0.2450)	loss 1.3404 (1.3618)	grad_norm 0.4440 (nan)	loss_scale 4096.0000 (4793.8646)	mem 7962MB
[2024-07-15 10:16:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:49 lr 0.000017	 wd 0.0000	time 0.2492 (0.2449)	loss 1.4992 (1.3622)	grad_norm 0.4669 (nan)	loss_scale 4096.0000 (4763.5359)	mem 7962MB
[2024-07-15 10:17:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:25 lr 0.000017	 wd 0.0000	time 0.3038 (0.2546)	loss 1.5066 (1.3635)	grad_norm 0.4746 (nan)	loss_scale 4096.0000 (4735.7334)	mem 7962MB
[2024-07-15 10:17:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1727 (0.2546)	loss 1.4919 (1.3630)	grad_norm 0.4584 (nan)	loss_scale 4096.0000 (4710.1543)	mem 7962MB
[2024-07-15 10:17:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 18 training takes 0:10:43
[2024-07-15 10:19:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 108.023 (108.023)	Loss 0.4172 (0.4172)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 10:20:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.174 Acc@5 97.242
[2024-07-15 10:20:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 10:20:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.17%
[2024-07-15 10:20:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth saving......
[2024-07-15 10:20:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth saved !!!
[2024-07-15 10:20:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][0/2502]	eta 12:20:51 lr 0.000016	 wd 0.0000	time 17.7663 (17.7663)	loss 1.4307 (1.4307)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:20:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:16:02 lr 0.000016	 wd 0.0000	time 0.2436 (0.4005)	loss 1.0966 (1.3752)	grad_norm 0.4722 (0.4838)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:21:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:12:22 lr 0.000016	 wd 0.0000	time 0.2756 (0.3226)	loss 1.4394 (1.3688)	grad_norm 0.4691 (0.4894)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:21:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:10:57 lr 0.000016	 wd 0.0000	time 0.2440 (0.2988)	loss 1.3119 (1.3809)	grad_norm 0.4503 (0.4817)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:21:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:09:49 lr 0.000016	 wd 0.0000	time 0.2141 (0.2807)	loss 1.5081 (1.3804)	grad_norm 0.4136 (0.4786)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:22:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:08:59 lr 0.000016	 wd 0.0000	time 0.2333 (0.2694)	loss 1.5101 (1.3755)	grad_norm 0.4718 (0.4850)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:22:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:20 lr 0.000016	 wd 0.0000	time 0.2250 (0.2629)	loss 1.4758 (1.3705)	grad_norm 0.5812 (0.4870)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:23:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:07:54 lr 0.000016	 wd 0.0000	time 0.2208 (0.2631)	loss 1.6406 (1.3725)	grad_norm 0.4801 (0.4878)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:23:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:07:20 lr 0.000016	 wd 0.0000	time 0.2285 (0.2588)	loss 1.3659 (1.3712)	grad_norm 0.4567 (0.4898)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:23:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:06:49 lr 0.000016	 wd 0.0000	time 0.2127 (0.2555)	loss 1.2361 (1.3708)	grad_norm 0.4189 (0.4892)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:24:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:20 lr 0.000016	 wd 0.0000	time 0.2288 (0.2531)	loss 1.5848 (1.3716)	grad_norm 0.4926 (0.4882)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:24:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:56 lr 0.000015	 wd 0.0000	time 0.1944 (0.2539)	loss 0.9204 (1.3701)	grad_norm 0.4071 (0.4878)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:25:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:28 lr 0.000015	 wd 0.0000	time 0.2157 (0.2521)	loss 1.1242 (1.3685)	grad_norm 0.4825 (0.4862)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:25:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:05:01 lr 0.000015	 wd 0.0000	time 0.2180 (0.2504)	loss 1.5776 (1.3689)	grad_norm 0.4373 (0.4912)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:25:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:34 lr 0.000015	 wd 0.0000	time 0.2191 (0.2488)	loss 1.4518 (1.3698)	grad_norm 0.4465 (0.4902)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:26:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:04:09 lr 0.000015	 wd 0.0000	time 0.2305 (0.2493)	loss 1.2114 (1.3696)	grad_norm 0.5200 (0.4896)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:26:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:44 lr 0.000015	 wd 0.0000	time 0.2182 (0.2487)	loss 1.3055 (1.3698)	grad_norm 0.4296 (0.4915)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:27:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:18 lr 0.000015	 wd 0.0000	time 0.1994 (0.2476)	loss 1.4007 (1.3705)	grad_norm 0.4982 (0.4912)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:27:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:53 lr 0.000015	 wd 0.0000	time 0.2282 (0.2468)	loss 1.3352 (1.3700)	grad_norm 0.4796 (0.4920)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:27:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:28 lr 0.000015	 wd 0.0000	time 0.2011 (0.2475)	loss 1.4161 (1.3703)	grad_norm 0.4110 (0.4926)	loss_scale 8192.0000 (4156.3304)	mem 7962MB
[2024-07-15 10:28:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:02:04 lr 0.000015	 wd 0.0000	time 0.2478 (0.2471)	loss 1.0667 (1.3698)	grad_norm 1.0573 (0.4921)	loss_scale 8192.0000 (4358.0130)	mem 7962MB
[2024-07-15 10:28:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:39 lr 0.000014	 wd 0.0000	time 0.2290 (0.2464)	loss 1.1803 (1.3687)	grad_norm 0.4451 (0.4909)	loss_scale 8192.0000 (4540.4969)	mem 7962MB
[2024-07-15 10:29:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:14 lr 0.000014	 wd 0.0000	time 0.2224 (0.2457)	loss 1.4875 (1.3666)	grad_norm 0.4839 (0.4909)	loss_scale 8192.0000 (4706.3989)	mem 7962MB
[2024-07-15 10:29:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:49 lr 0.000014	 wd 0.0000	time 0.4350 (0.2458)	loss 1.4011 (1.3662)	grad_norm 0.5411 (0.4900)	loss_scale 8192.0000 (4857.8809)	mem 7962MB
[2024-07-15 10:29:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:25 lr 0.000014	 wd 0.0000	time 0.2141 (0.2458)	loss 1.5473 (1.3677)	grad_norm 0.4431 (0.4901)	loss_scale 8192.0000 (4996.7447)	mem 7962MB
[2024-07-15 10:30:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1866 (0.2441)	loss 1.2307 (1.3675)	grad_norm 0.4613 (0.4904)	loss_scale 8192.0000 (5124.5038)	mem 7962MB
[2024-07-15 10:30:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 19 training takes 0:10:15
[2024-07-15 10:30:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 18.369 (18.369)	Loss 0.4170 (0.4170)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 10:30:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.140 Acc@5 97.266
[2024-07-15 10:30:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 10:30:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.17%
[2024-07-15 10:31:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][0/2502]	eta 1 day, 0:37:26 lr 0.000014	 wd 0.0000	time 35.4302 (35.4302)	loss 0.9946 (0.9946)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 10:31:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:23:53 lr 0.000014	 wd 0.0000	time 0.2132 (0.5969)	loss 1.5776 (1.3634)	grad_norm 0.4113 (0.5214)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 10:32:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:15:42 lr 0.000014	 wd 0.0000	time 0.2152 (0.4094)	loss 1.4306 (1.3649)	grad_norm 0.4511 (0.5100)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 10:32:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:13:15 lr 0.000014	 wd 0.0000	time 0.4141 (0.3615)	loss 1.4752 (1.3610)	grad_norm 0.4876 (0.5121)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 10:33:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:11:50 lr 0.000014	 wd 0.0000	time 0.2110 (0.3378)	loss 1.4057 (1.3702)	grad_norm 0.4966 (0.5076)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 10:33:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:10:30 lr 0.000014	 wd 0.0000	time 0.2661 (0.3148)	loss 1.5429 (1.3723)	grad_norm 0.4467 (0.5054)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 10:33:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:09:30 lr 0.000014	 wd 0.0000	time 0.1994 (0.3001)	loss 1.3310 (1.3688)	grad_norm 0.4556 (0.5054)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 10:34:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:08:47 lr 0.000013	 wd 0.0000	time 0.2325 (0.2930)	loss 1.4774 (1.3710)	grad_norm 0.5271 (0.5054)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 10:34:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:08:07 lr 0.000013	 wd 0.0000	time 0.2437 (0.2867)	loss 1.2672 (1.3680)	grad_norm 0.4378 (0.5057)	loss_scale 8192.0000 (8192.0000)	mem 7962MB
[2024-07-15 10:35:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:07:28 lr 0.000013	 wd 0.0000	time 0.2339 (0.2802)	loss 1.5927 (1.3707)	grad_norm 0.4195 (nan)	loss_scale 4096.0000 (8055.6182)	mem 7962MB
[2024-07-15 10:35:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:52 lr 0.000013	 wd 0.0000	time 0.2108 (0.2749)	loss 1.2929 (1.3698)	grad_norm 0.4564 (nan)	loss_scale 4096.0000 (7660.0519)	mem 7962MB
[2024-07-15 10:35:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:06:21 lr 0.000013	 wd 0.0000	time 0.2295 (0.2720)	loss 1.3553 (1.3675)	grad_norm 0.4732 (nan)	loss_scale 4096.0000 (7336.3415)	mem 7962MB
[2024-07-15 10:36:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:51 lr 0.000013	 wd 0.0000	time 0.1931 (0.2700)	loss 1.4178 (1.3644)	grad_norm 0.6423 (nan)	loss_scale 4096.0000 (7066.5379)	mem 7962MB
[2024-07-15 10:36:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:05:20 lr 0.000013	 wd 0.0000	time 0.2235 (0.2667)	loss 1.3076 (1.3631)	grad_norm 0.4698 (nan)	loss_scale 4096.0000 (6838.2106)	mem 7962MB
[2024-07-15 10:37:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:50 lr 0.000013	 wd 0.0000	time 0.2075 (0.2640)	loss 1.3933 (1.3648)	grad_norm 0.4682 (nan)	loss_scale 4096.0000 (6642.4782)	mem 7962MB
[2024-07-15 10:37:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:04:22 lr 0.000013	 wd 0.0000	time 0.2100 (0.2622)	loss 1.4434 (1.3653)	grad_norm 0.4791 (nan)	loss_scale 4096.0000 (6472.8261)	mem 7962MB
[2024-07-15 10:37:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:56 lr 0.000013	 wd 0.0000	time 0.2090 (0.2624)	loss 1.6897 (1.3656)	grad_norm 0.4803 (nan)	loss_scale 4096.0000 (6324.3673)	mem 7962MB
[2024-07-15 10:38:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:28 lr 0.000012	 wd 0.0000	time 0.2073 (0.2605)	loss 1.5263 (1.3649)	grad_norm 0.4052 (nan)	loss_scale 4096.0000 (6193.3639)	mem 7962MB
[2024-07-15 10:38:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:03:01 lr 0.000012	 wd 0.0000	time 0.2509 (0.2590)	loss 1.3082 (1.3642)	grad_norm 0.4302 (nan)	loss_scale 4096.0000 (6076.9084)	mem 7962MB
[2024-07-15 10:39:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:35 lr 0.000012	 wd 0.0000	time 0.2470 (0.2579)	loss 1.5289 (1.3662)	grad_norm 0.4101 (nan)	loss_scale 4096.0000 (5972.7049)	mem 7962MB
[2024-07-15 10:39:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:02:09 lr 0.000012	 wd 0.0000	time 0.2871 (0.2579)	loss 1.4962 (1.3657)	grad_norm 0.4499 (nan)	loss_scale 4096.0000 (5878.9165)	mem 7962MB
[2024-07-15 10:39:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:43 lr 0.000012	 wd 0.0000	time 0.2278 (0.2566)	loss 1.3069 (1.3664)	grad_norm 0.4479 (nan)	loss_scale 4096.0000 (5794.0562)	mem 7962MB
[2024-07-15 10:40:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:17 lr 0.000012	 wd 0.0000	time 0.2051 (0.2555)	loss 1.2539 (1.3679)	grad_norm 0.5944 (nan)	loss_scale 4096.0000 (5716.9069)	mem 7962MB
[2024-07-15 10:40:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:51 lr 0.000012	 wd 0.0000	time 0.2428 (0.2547)	loss 1.3934 (1.3679)	grad_norm 0.4477 (nan)	loss_scale 4096.0000 (5646.4633)	mem 7962MB
[2024-07-15 10:41:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:25 lr 0.000012	 wd 0.0000	time 0.2106 (0.2543)	loss 1.3612 (1.3682)	grad_norm 0.4122 (nan)	loss_scale 4096.0000 (5581.8875)	mem 7962MB
[2024-07-15 10:41:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000012	 wd 0.0000	time 0.1835 (0.2522)	loss 1.6211 (1.3690)	grad_norm 0.4786 (nan)	loss_scale 4096.0000 (5522.4758)	mem 7962MB
[2024-07-15 10:41:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 20 training takes 0:10:35
[2024-07-15 10:41:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 18.912 (18.912)	Loss 0.4177 (0.4177)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 10:41:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.132 Acc@5 97.266
[2024-07-15 10:41:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 10:41:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.17%
[2024-07-15 10:42:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][0/2502]	eta 21:10:24 lr 0.000012	 wd 0.0000	time 30.4656 (30.4656)	loss 1.5676 (1.5676)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:42:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:21:24 lr 0.000012	 wd 0.0000	time 0.2118 (0.5348)	loss 1.4505 (1.3882)	grad_norm 0.4317 (0.4880)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:43:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:14:35 lr 0.000012	 wd 0.0000	time 0.2403 (0.3803)	loss 0.8983 (1.3690)	grad_norm 0.5663 (0.4829)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:43:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:12:01 lr 0.000012	 wd 0.0000	time 0.2200 (0.3275)	loss 1.4047 (1.3619)	grad_norm 0.4669 (0.4941)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:44:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:10:49 lr 0.000011	 wd 0.0000	time 0.2389 (0.3090)	loss 1.4471 (1.3632)	grad_norm 0.5343 (0.4905)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:44:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:09:48 lr 0.000011	 wd 0.0000	time 0.2095 (0.2937)	loss 1.3550 (1.3626)	grad_norm 0.4365 (0.4910)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:44:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:58 lr 0.000011	 wd 0.0000	time 0.2288 (0.2830)	loss 1.1970 (1.3631)	grad_norm 0.4414 (0.4921)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:45:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:08:15 lr 0.000011	 wd 0.0000	time 0.2277 (0.2750)	loss 1.2851 (1.3577)	grad_norm 0.4153 (0.4897)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:45:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:42 lr 0.000011	 wd 0.0000	time 0.2291 (0.2716)	loss 1.2225 (1.3572)	grad_norm 0.4239 (0.4914)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:46:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:07:10 lr 0.000011	 wd 0.0000	time 0.2116 (0.2689)	loss 1.5395 (1.3580)	grad_norm 0.4578 (0.4963)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:46:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:37 lr 0.000011	 wd 0.0000	time 0.2025 (0.2647)	loss 1.0493 (1.3571)	grad_norm 0.4320 (0.4939)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:46:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:06:06 lr 0.000011	 wd 0.0000	time 0.2104 (0.2613)	loss 1.4642 (1.3572)	grad_norm 0.5330 (0.4938)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:47:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:37 lr 0.000011	 wd 0.0000	time 0.2398 (0.2594)	loss 1.3309 (1.3583)	grad_norm 0.5691 (0.4955)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:47:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:05:11 lr 0.000011	 wd 0.0000	time 0.2009 (0.2589)	loss 1.5122 (1.3585)	grad_norm 0.4159 (0.4947)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:47:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:42 lr 0.000011	 wd 0.0000	time 0.2204 (0.2567)	loss 1.4376 (1.3589)	grad_norm 0.4958 (0.4949)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:48:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:04:15 lr 0.000010	 wd 0.0000	time 0.2120 (0.2550)	loss 1.6413 (1.3585)	grad_norm 0.4899 (0.4935)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:48:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:49 lr 0.000010	 wd 0.0000	time 0.2145 (0.2540)	loss 1.2141 (1.3579)	grad_norm 0.5520 (0.4925)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:49:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:23 lr 0.000010	 wd 0.0000	time 0.1978 (0.2541)	loss 1.4865 (1.3580)	grad_norm 0.5688 (0.4933)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:49:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:57 lr 0.000010	 wd 0.0000	time 0.1912 (0.2529)	loss 1.0293 (1.3585)	grad_norm 0.4678 (0.4926)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:49:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:31 lr 0.000010	 wd 0.0000	time 0.2181 (0.2518)	loss 0.9988 (1.3571)	grad_norm 0.4478 (0.4922)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:50:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:02:06 lr 0.000010	 wd 0.0000	time 0.2356 (0.2511)	loss 1.3966 (1.3566)	grad_norm 0.4371 (0.4916)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:50:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:40 lr 0.000010	 wd 0.0000	time 0.2074 (0.2512)	loss 1.1883 (1.3569)	grad_norm 0.5579 (0.4904)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:51:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:15 lr 0.000010	 wd 0.0000	time 0.1955 (0.2504)	loss 1.5659 (1.3549)	grad_norm 0.4222 (0.4897)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:51:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:50 lr 0.000010	 wd 0.0000	time 0.2102 (0.2495)	loss 1.5686 (1.3547)	grad_norm 0.4559 (0.4893)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:51:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:25 lr 0.000010	 wd 0.0000	time 0.2227 (0.2490)	loss 1.3787 (1.3560)	grad_norm 0.4637 (inf)	loss_scale 4096.0000 (4126.7072)	mem 7962MB
[2024-07-15 10:52:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1781 (0.2475)	loss 1.3246 (1.3557)	grad_norm 0.4841 (inf)	loss_scale 4096.0000 (4125.4794)	mem 7962MB
[2024-07-15 10:52:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 21 training takes 0:10:35
[2024-07-15 10:53:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 62.397 (62.397)	Loss 0.4167 (0.4167)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 10:54:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.140 Acc@5 97.246
[2024-07-15 10:54:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 10:54:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.17%
[2024-07-15 10:54:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][0/2502]	eta 12:59:50 lr 0.000010	 wd 0.0000	time 18.7014 (18.7014)	loss 1.3159 (1.3159)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:54:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:16:22 lr 0.000010	 wd 0.0000	time 0.2202 (0.4092)	loss 1.2674 (1.3662)	grad_norm 0.5157 (0.5068)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:55:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:12:29 lr 0.000009	 wd 0.0000	time 0.2379 (0.3254)	loss 1.1891 (1.3630)	grad_norm 0.4284 (0.4869)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:55:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:11:08 lr 0.000009	 wd 0.0000	time 0.2131 (0.3036)	loss 1.5118 (1.3672)	grad_norm 0.4803 (0.4812)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:55:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:09:57 lr 0.000009	 wd 0.0000	time 0.2186 (0.2841)	loss 1.4358 (1.3710)	grad_norm 0.4820 (0.4821)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:56:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:09:05 lr 0.000009	 wd 0.0000	time 0.2225 (0.2724)	loss 0.8968 (1.3702)	grad_norm 0.5014 (0.4827)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:56:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:24 lr 0.000009	 wd 0.0000	time 0.2418 (0.2655)	loss 1.3671 (1.3732)	grad_norm 0.4620 (0.4872)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:57:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:55 lr 0.000009	 wd 0.0000	time 0.2323 (0.2637)	loss 0.8961 (1.3687)	grad_norm 0.4842 (0.4857)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:57:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:07:22 lr 0.000009	 wd 0.0000	time 0.2185 (0.2598)	loss 1.3731 (1.3646)	grad_norm 0.4214 (0.4855)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:57:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:50 lr 0.000009	 wd 0.0000	time 0.2446 (0.2564)	loss 1.3459 (1.3637)	grad_norm 0.5081 (0.4853)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:58:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:21 lr 0.000009	 wd 0.0000	time 0.2461 (0.2537)	loss 1.5558 (1.3659)	grad_norm 0.4707 (0.4850)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:58:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:54 lr 0.000009	 wd 0.0000	time 0.2022 (0.2531)	loss 1.4020 (1.3634)	grad_norm 0.4667 (0.4847)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:59:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:27 lr 0.000009	 wd 0.0000	time 0.2201 (0.2514)	loss 1.3463 (1.3621)	grad_norm 0.4327 (0.4854)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:59:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:05:00 lr 0.000009	 wd 0.0000	time 0.2483 (0.2498)	loss 0.9339 (1.3627)	grad_norm 0.4460 (0.4842)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 10:59:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:33 lr 0.000008	 wd 0.0000	time 0.2423 (0.2483)	loss 1.5692 (1.3648)	grad_norm 0.4418 (0.4848)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:00:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:04:09 lr 0.000008	 wd 0.0000	time 0.1894 (0.2486)	loss 1.3176 (1.3654)	grad_norm 0.6781 (0.4853)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:00:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:43 lr 0.000008	 wd 0.0000	time 0.2213 (0.2480)	loss 1.5428 (1.3658)	grad_norm 0.4798 (0.4843)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:01:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:18 lr 0.000008	 wd 0.0000	time 0.1981 (0.2470)	loss 1.3111 (1.3654)	grad_norm 0.4591 (0.4838)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:01:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:52 lr 0.000008	 wd 0.0000	time 0.2114 (0.2460)	loss 1.5884 (1.3648)	grad_norm 0.4962 (0.4864)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:01:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:28 lr 0.000008	 wd 0.0000	time 0.2247 (0.2460)	loss 1.5469 (1.3643)	grad_norm 0.5545 (nan)	loss_scale 2048.0000 (4080.9174)	mem 7962MB
[2024-07-15 11:02:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:02:03 lr 0.000008	 wd 0.0000	time 0.2097 (0.2466)	loss 1.5138 (1.3634)	grad_norm 0.4204 (nan)	loss_scale 2048.0000 (3979.3223)	mem 7962MB
[2024-07-15 11:02:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:38 lr 0.000008	 wd 0.0000	time 0.2301 (0.2459)	loss 1.4376 (1.3639)	grad_norm 0.7017 (nan)	loss_scale 2048.0000 (3887.3984)	mem 7962MB
[2024-07-15 11:03:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:14 lr 0.000008	 wd 0.0000	time 0.2249 (0.2451)	loss 1.4372 (1.3621)	grad_norm 0.5005 (nan)	loss_scale 2048.0000 (3803.8274)	mem 7962MB
[2024-07-15 11:03:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:49 lr 0.000008	 wd 0.0000	time 0.2571 (0.2449)	loss 1.5032 (1.3622)	grad_norm 0.4634 (nan)	loss_scale 2048.0000 (3727.5202)	mem 7962MB
[2024-07-15 11:03:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:24 lr 0.000008	 wd 0.0000	time 0.2139 (0.2450)	loss 1.2088 (1.3616)	grad_norm 0.4835 (nan)	loss_scale 2048.0000 (3657.5693)	mem 7962MB
[2024-07-15 11:04:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1787 (0.2434)	loss 0.9914 (1.3607)	grad_norm 0.4470 (nan)	loss_scale 2048.0000 (3593.2123)	mem 7962MB
[2024-07-15 11:04:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 22 training takes 0:10:14
[2024-07-15 11:04:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 18.418 (18.418)	Loss 0.4177 (0.4177)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 11:04:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.176 Acc@5 97.258
[2024-07-15 11:04:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 11:04:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-15 11:04:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth saving......
[2024-07-15 11:04:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_best.pth saved !!!
[2024-07-15 11:05:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][0/2502]	eta 23:26:39 lr 0.000008	 wd 0.0000	time 33.7327 (33.7327)	loss 1.1596 (1.1596)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:05:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:22:27 lr 0.000008	 wd 0.0000	time 0.2225 (0.5609)	loss 1.5712 (1.3982)	grad_norm 0.4317 (0.4941)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:06:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:15:00 lr 0.000007	 wd 0.0000	time 0.2155 (0.3910)	loss 1.5478 (1.3774)	grad_norm 0.4311 (0.4871)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:06:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:12:34 lr 0.000007	 wd 0.0000	time 0.2301 (0.3426)	loss 1.5186 (1.3704)	grad_norm 0.4565 (0.4853)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:07:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:11:07 lr 0.000007	 wd 0.0000	time 0.2061 (0.3174)	loss 1.5306 (1.3619)	grad_norm 0.5925 (0.4822)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:07:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:09:58 lr 0.000007	 wd 0.0000	time 0.1834 (0.2987)	loss 1.6831 (1.3666)	grad_norm 0.6352 (0.4786)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:07:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:09:05 lr 0.000007	 wd 0.0000	time 0.2174 (0.2869)	loss 1.1406 (1.3665)	grad_norm 0.4195 (0.4775)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:08:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:08:24 lr 0.000007	 wd 0.0000	time 0.2638 (0.2798)	loss 1.4154 (1.3637)	grad_norm 0.4729 (0.4845)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:08:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:07:49 lr 0.000007	 wd 0.0000	time 0.2196 (0.2759)	loss 1.6974 (1.3625)	grad_norm 0.4199 (0.4842)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:08:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:07:13 lr 0.000007	 wd 0.0000	time 0.2109 (0.2705)	loss 1.7061 (1.3591)	grad_norm 0.4506 (0.4850)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:09:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:39 lr 0.000007	 wd 0.0000	time 0.2258 (0.2661)	loss 1.1487 (1.3571)	grad_norm 0.4107 (0.4873)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:09:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:06:09 lr 0.000007	 wd 0.0000	time 0.2202 (0.2632)	loss 0.8858 (1.3528)	grad_norm 0.4932 (0.4871)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:10:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:41 lr 0.000007	 wd 0.0000	time 0.2097 (0.2622)	loss 1.5705 (1.3547)	grad_norm 0.5403 (0.4871)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:10:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:05:12 lr 0.000007	 wd 0.0000	time 0.2027 (0.2599)	loss 1.4471 (1.3561)	grad_norm 0.4603 (0.4876)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:10:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:44 lr 0.000007	 wd 0.0000	time 0.2098 (0.2578)	loss 1.5881 (1.3561)	grad_norm 0.4782 (0.4933)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:11:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:04:16 lr 0.000006	 wd 0.0000	time 0.2151 (0.2561)	loss 1.2737 (1.3583)	grad_norm 0.5607 (0.4932)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:11:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:50 lr 0.000006	 wd 0.0000	time 0.2851 (0.2560)	loss 1.1713 (1.3576)	grad_norm 0.4474 (0.4928)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:12:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:24 lr 0.000006	 wd 0.0000	time 0.1993 (0.2548)	loss 1.3151 (1.3579)	grad_norm 0.4753 (0.4918)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:12:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:57 lr 0.000006	 wd 0.0000	time 0.2544 (0.2535)	loss 1.4401 (1.3573)	grad_norm 0.4921 (0.4928)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:12:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:31 lr 0.000006	 wd 0.0000	time 0.2268 (0.2524)	loss 1.2330 (1.3600)	grad_norm 0.4577 (0.4922)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:13:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:02:06 lr 0.000006	 wd 0.0000	time 0.2031 (0.2528)	loss 1.4570 (1.3587)	grad_norm 0.4833 (0.4912)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:13:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:41 lr 0.000006	 wd 0.0000	time 0.2128 (0.2525)	loss 1.7045 (1.3592)	grad_norm 0.4732 (0.4909)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:14:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:15 lr 0.000006	 wd 0.0000	time 0.2034 (0.2516)	loss 1.4748 (1.3570)	grad_norm 0.4432 (0.4904)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:14:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:50 lr 0.000006	 wd 0.0000	time 0.2796 (0.2507)	loss 1.5921 (1.3572)	grad_norm 0.4711 (0.4897)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:14:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:25 lr 0.000006	 wd 0.0000	time 0.2238 (0.2510)	loss 1.5433 (1.3578)	grad_norm 0.4428 (0.4893)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:15:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000006	 wd 0.0000	time 0.1711 (0.2490)	loss 1.4414 (1.3585)	grad_norm 0.4578 (0.4884)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:15:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 23 training takes 0:10:32
[2024-07-15 11:15:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 20.331 (20.331)	Loss 0.4160 (0.4160)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 11:16:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.160 Acc@5 97.262
[2024-07-15 11:16:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 11:16:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-15 11:16:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][0/2502]	eta 23:05:04 lr 0.000006	 wd 0.0000	time 33.2150 (33.2150)	loss 1.5889 (1.5889)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:17:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:22:06 lr 0.000006	 wd 0.0000	time 0.2261 (0.5521)	loss 1.1518 (1.3974)	grad_norm 0.4740 (0.5037)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:17:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:14:54 lr 0.000006	 wd 0.0000	time 0.1954 (0.3888)	loss 1.4125 (1.3795)	grad_norm 0.4595 (0.5557)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:17:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:12:16 lr 0.000006	 wd 0.0000	time 0.2219 (0.3345)	loss 1.6235 (1.3726)	grad_norm 0.4518 (0.5346)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:18:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:11:05 lr 0.000005	 wd 0.0000	time 0.1992 (0.3164)	loss 1.4136 (1.3693)	grad_norm 0.6114 (0.5482)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:18:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:09:56 lr 0.000005	 wd 0.0000	time 0.2306 (0.2979)	loss 1.6678 (1.3706)	grad_norm 0.5266 (0.5322)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:18:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:09:04 lr 0.000005	 wd 0.0000	time 0.2011 (0.2862)	loss 1.3977 (1.3677)	grad_norm 0.4955 (0.5285)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:19:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:08:20 lr 0.000005	 wd 0.0000	time 0.1948 (0.2778)	loss 1.3472 (1.3687)	grad_norm 0.4709 (0.5224)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:19:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:07:46 lr 0.000005	 wd 0.0000	time 0.2477 (0.2742)	loss 1.4138 (1.3697)	grad_norm 0.4734 (0.5167)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:20:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:07:12 lr 0.000005	 wd 0.0000	time 0.2217 (0.2699)	loss 1.5523 (1.3666)	grad_norm 0.6404 (0.5141)	loss_scale 4096.0000 (2088.9145)	mem 7962MB
[2024-07-15 11:20:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:39 lr 0.000005	 wd 0.0000	time 0.2102 (0.2658)	loss 1.2237 (1.3669)	grad_norm 0.4911 (0.5096)	loss_scale 4096.0000 (2289.4226)	mem 7962MB
[2024-07-15 11:20:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:06:07 lr 0.000005	 wd 0.0000	time 0.2011 (0.2621)	loss 1.4996 (1.3658)	grad_norm 0.6044 (0.5067)	loss_scale 4096.0000 (2453.5077)	mem 7962MB
[2024-07-15 11:21:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:39 lr 0.000005	 wd 0.0000	time 0.2267 (0.2606)	loss 1.2527 (1.3639)	grad_norm 0.4356 (0.5084)	loss_scale 4096.0000 (2590.2681)	mem 7962MB
[2024-07-15 11:21:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:05:12 lr 0.000005	 wd 0.0000	time 0.2076 (0.2601)	loss 1.3941 (1.3633)	grad_norm 0.6343 (0.5059)	loss_scale 4096.0000 (2706.0046)	mem 7962MB
[2024-07-15 11:22:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:44 lr 0.000005	 wd 0.0000	time 0.2245 (0.2580)	loss 1.3492 (1.3617)	grad_norm 0.4837 (0.5035)	loss_scale 4096.0000 (2805.2191)	mem 7962MB
[2024-07-15 11:22:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:16 lr 0.000005	 wd 0.0000	time 0.1902 (0.2560)	loss 0.9760 (1.3601)	grad_norm 0.5359 (0.5016)	loss_scale 4096.0000 (2891.2139)	mem 7962MB
[2024-07-15 11:22:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:50 lr 0.000005	 wd 0.0000	time 0.2590 (0.2552)	loss 1.5098 (1.3598)	grad_norm 0.4943 (0.4998)	loss_scale 4096.0000 (2966.4660)	mem 7962MB
[2024-07-15 11:23:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:24 lr 0.000005	 wd 0.0000	time 0.2414 (0.2548)	loss 1.6890 (1.3610)	grad_norm 0.4496 (0.5006)	loss_scale 4096.0000 (3032.8701)	mem 7962MB
[2024-07-15 11:23:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:57 lr 0.000005	 wd 0.0000	time 0.2379 (0.2534)	loss 1.1424 (1.3589)	grad_norm 0.4201 (0.5013)	loss_scale 4096.0000 (3091.9001)	mem 7962MB
[2024-07-15 11:24:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:31 lr 0.000005	 wd 0.0000	time 0.2159 (0.2523)	loss 1.4111 (1.3600)	grad_norm 0.4418 (0.4999)	loss_scale 4096.0000 (3144.7196)	mem 7962MB
[2024-07-15 11:24:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:02:06 lr 0.000004	 wd 0.0000	time 0.2632 (0.2519)	loss 1.3830 (1.3606)	grad_norm 0.4581 (0.4996)	loss_scale 4096.0000 (3192.2599)	mem 7962MB
[2024-07-15 11:24:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:41 lr 0.000004	 wd 0.0000	time 0.2826 (0.2523)	loss 1.5474 (1.3597)	grad_norm 0.5132 (0.4986)	loss_scale 4096.0000 (3235.2746)	mem 7962MB
[2024-07-15 11:25:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:15 lr 0.000004	 wd 0.0000	time 0.2227 (0.2513)	loss 1.4051 (1.3596)	grad_norm 0.4541 (nan)	loss_scale 2048.0000 (3181.3321)	mem 7962MB
[2024-07-15 11:25:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:50 lr 0.000004	 wd 0.0000	time 0.2176 (0.2505)	loss 1.7351 (1.3592)	grad_norm 0.4677 (nan)	loss_scale 2048.0000 (3132.0782)	mem 7962MB
[2024-07-15 11:26:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:25 lr 0.000004	 wd 0.0000	time 0.2272 (0.2500)	loss 1.5000 (1.3591)	grad_norm 0.4258 (nan)	loss_scale 2048.0000 (3086.9271)	mem 7962MB
[2024-07-15 11:26:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000004	 wd 0.0000	time 0.1872 (0.2485)	loss 1.2633 (1.3593)	grad_norm 0.4805 (nan)	loss_scale 2048.0000 (3045.3866)	mem 7962MB
[2024-07-15 11:26:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 24 training takes 0:10:33
[2024-07-15 11:26:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 20.858 (20.858)	Loss 0.4165 (0.4165)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 11:27:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.126 Acc@5 97.264
[2024-07-15 11:27:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 11:27:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-15 11:27:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][0/2502]	eta 14:57:16 lr 0.000004	 wd 0.0000	time 21.5172 (21.5172)	loss 1.2560 (1.2560)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:28:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:23:33 lr 0.000004	 wd 0.0000	time 0.1725 (0.5884)	loss 1.3889 (1.3280)	grad_norm 0.4870 (0.4756)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:28:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:17:20 lr 0.000004	 wd 0.0000	time 0.4022 (0.4520)	loss 1.4874 (1.3555)	grad_norm 0.4016 (0.4703)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:29:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:14:40 lr 0.000004	 wd 0.0000	time 0.2348 (0.3997)	loss 1.1288 (1.3455)	grad_norm 0.4041 (0.4929)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:30:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:17:23 lr 0.000004	 wd 0.0000	time 0.4307 (0.4965)	loss 1.2505 (1.3606)	grad_norm 0.4758 (0.4953)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:31:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:15:39 lr 0.000004	 wd 0.0000	time 0.2355 (0.4691)	loss 1.5600 (1.3608)	grad_norm 0.4365 (0.4909)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:31:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:13:36 lr 0.000004	 wd 0.0000	time 0.2035 (0.4295)	loss 1.1498 (1.3622)	grad_norm 0.4163 (0.4909)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:31:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:12:01 lr 0.000004	 wd 0.0000	time 0.1989 (0.4003)	loss 1.2373 (1.3627)	grad_norm 0.4351 (0.4913)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:32:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:10:44 lr 0.000004	 wd 0.0000	time 0.2305 (0.3789)	loss 0.9998 (1.3629)	grad_norm 0.5022 (0.4905)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:32:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:09:44 lr 0.000004	 wd 0.0000	time 0.1916 (0.3647)	loss 1.5200 (1.3648)	grad_norm 0.4337 (0.4894)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:33:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:08:48 lr 0.000004	 wd 0.0000	time 0.1891 (0.3516)	loss 1.2385 (1.3653)	grad_norm 0.4914 (0.4880)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:33:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:07:57 lr 0.000004	 wd 0.0000	time 0.2006 (0.3407)	loss 1.2965 (1.3634)	grad_norm 0.4707 (0.4856)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:33:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:07:11 lr 0.000004	 wd 0.0000	time 0.2290 (0.3311)	loss 1.3493 (1.3658)	grad_norm 0.5135 (0.4853)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:34:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:06:31 lr 0.000003	 wd 0.0000	time 1.0627 (0.3254)	loss 1.4820 (1.3675)	grad_norm 0.7522 (0.4877)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:34:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:05:51 lr 0.000003	 wd 0.0000	time 0.2263 (0.3193)	loss 1.1267 (1.3670)	grad_norm 0.4231 (0.4875)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:35:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:05:13 lr 0.000003	 wd 0.0000	time 0.2173 (0.3134)	loss 1.2395 (1.3671)	grad_norm 0.4463 (0.4871)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:35:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:04:37 lr 0.000003	 wd 0.0000	time 0.2255 (0.3080)	loss 1.4931 (1.3664)	grad_norm 0.4610 (0.4884)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:35:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:04:03 lr 0.000003	 wd 0.0000	time 0.2254 (0.3042)	loss 1.3791 (1.3657)	grad_norm 0.4264 (0.4874)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:36:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:03:31 lr 0.000003	 wd 0.0000	time 0.2092 (0.3020)	loss 1.5578 (1.3656)	grad_norm 0.4831 (0.4880)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:36:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:59 lr 0.000003	 wd 0.0000	time 0.2097 (0.2984)	loss 1.9493 (1.3654)	grad_norm 0.4437 (0.4869)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:37:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:02:28 lr 0.000003	 wd 0.0000	time 0.2095 (0.2950)	loss 1.2697 (1.3647)	grad_norm 0.4410 (0.4859)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:37:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:57 lr 0.000003	 wd 0.0000	time 0.2300 (0.2926)	loss 0.8829 (1.3647)	grad_norm 0.4690 (0.4851)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:37:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:27 lr 0.000003	 wd 0.0000	time 0.2092 (0.2911)	loss 1.4413 (1.3635)	grad_norm 0.4764 (0.4854)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:38:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:58 lr 0.000003	 wd 0.0000	time 0.2279 (0.2886)	loss 1.2082 (1.3621)	grad_norm 0.3828 (0.4851)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:38:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:29 lr 0.000003	 wd 0.0000	time 0.2115 (0.2860)	loss 1.3965 (1.3636)	grad_norm 0.4725 (0.4859)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:39:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1911 (0.2830)	loss 1.4878 (1.3637)	grad_norm 0.4740 (0.4853)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:39:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 25 training takes 0:11:55
[2024-07-15 11:39:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 32.647 (32.647)	Loss 0.4167 (0.4167)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 11:40:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.150 Acc@5 97.264
[2024-07-15 11:40:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 11:40:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-15 11:40:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][0/2502]	eta 10:25:27 lr 0.000003	 wd 0.0000	time 14.9988 (14.9988)	loss 1.3266 (1.3266)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:40:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:16:31 lr 0.000003	 wd 0.0000	time 0.2937 (0.4127)	loss 1.5154 (1.3558)	grad_norm 0.4583 (0.4921)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:41:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:12:30 lr 0.000003	 wd 0.0000	time 0.2312 (0.3262)	loss 1.4768 (1.3763)	grad_norm 0.4932 (0.4833)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:41:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:10:43 lr 0.000003	 wd 0.0000	time 0.2097 (0.2921)	loss 1.4896 (1.3680)	grad_norm 0.8007 (0.4828)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:41:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:09:37 lr 0.000003	 wd 0.0000	time 0.1905 (0.2746)	loss 1.6475 (1.3697)	grad_norm 0.4320 (0.4832)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:42:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:08:55 lr 0.000003	 wd 0.0000	time 0.2338 (0.2673)	loss 1.6345 (1.3763)	grad_norm 0.5940 (0.4822)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:42:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:08:21 lr 0.000003	 wd 0.0000	time 0.2368 (0.2637)	loss 1.4145 (1.3715)	grad_norm 0.4303 (0.4824)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:43:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:44 lr 0.000003	 wd 0.0000	time 0.2209 (0.2580)	loss 1.5372 (1.3674)	grad_norm 0.4372 (0.4838)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:43:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:07:12 lr 0.000002	 wd 0.0000	time 0.1973 (0.2542)	loss 1.6037 (1.3660)	grad_norm 0.4120 (0.4856)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:43:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:06:43 lr 0.000002	 wd 0.0000	time 0.2083 (0.2520)	loss 1.3893 (1.3660)	grad_norm 0.4301 (0.4834)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:44:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:19 lr 0.000002	 wd 0.0000	time 0.2136 (0.2528)	loss 1.4143 (1.3665)	grad_norm 0.5443 (0.4826)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 11:44:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:51 lr 0.000002	 wd 0.0000	time 0.2397 (0.2506)	loss 1.5833 (1.3681)	grad_norm 0.4805 (0.4838)	loss_scale 4096.0000 (2055.4405)	mem 7962MB
[2024-07-15 11:45:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:23 lr 0.000002	 wd 0.0000	time 0.2266 (0.2487)	loss 1.0826 (1.3686)	grad_norm 0.4671 (0.4829)	loss_scale 4096.0000 (2225.3455)	mem 7962MB
[2024-07-15 11:45:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:04:57 lr 0.000002	 wd 0.0000	time 0.2703 (0.2476)	loss 0.9519 (1.3668)	grad_norm 0.4736 (0.4829)	loss_scale 4096.0000 (2369.1314)	mem 7962MB
[2024-07-15 11:45:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:33 lr 0.000002	 wd 0.0000	time 0.2349 (0.2480)	loss 1.6021 (1.3663)	grad_norm 0.4814 (0.4838)	loss_scale 4096.0000 (2492.3911)	mem 7962MB
[2024-07-15 11:46:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:04:07 lr 0.000002	 wd 0.0000	time 0.2109 (0.2469)	loss 1.4011 (1.3650)	grad_norm 0.4483 (0.4851)	loss_scale 4096.0000 (2599.2272)	mem 7962MB
[2024-07-15 11:46:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:41 lr 0.000002	 wd 0.0000	time 0.2284 (0.2458)	loss 1.4502 (1.3639)	grad_norm 0.4713 (0.4844)	loss_scale 4096.0000 (2692.7171)	mem 7962MB
[2024-07-15 11:46:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:16 lr 0.000002	 wd 0.0000	time 0.2349 (0.2451)	loss 1.2797 (1.3650)	grad_norm 0.4727 (0.4897)	loss_scale 4096.0000 (2775.2146)	mem 7962MB
[2024-07-15 11:47:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:52 lr 0.000002	 wd 0.0000	time 0.3292 (0.2460)	loss 1.5261 (1.3679)	grad_norm 0.4223 (0.4928)	loss_scale 4096.0000 (2848.5508)	mem 7962MB
[2024-07-15 11:47:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:27 lr 0.000002	 wd 0.0000	time 0.2350 (0.2455)	loss 0.9829 (1.3664)	grad_norm 0.4091 (0.4918)	loss_scale 4096.0000 (2914.1715)	mem 7962MB
[2024-07-15 11:48:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:02:02 lr 0.000002	 wd 0.0000	time 0.2351 (0.2447)	loss 0.9205 (1.3655)	grad_norm 0.4683 (0.4929)	loss_scale 4096.0000 (2973.2334)	mem 7962MB
[2024-07-15 11:48:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:38 lr 0.000002	 wd 0.0000	time 0.2497 (0.2440)	loss 1.1237 (1.3644)	grad_norm 0.4763 (0.4919)	loss_scale 4096.0000 (3026.6730)	mem 7962MB
[2024-07-15 11:49:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:13 lr 0.000002	 wd 0.0000	time 0.2955 (0.2443)	loss 0.9640 (1.3641)	grad_norm 0.4840 (0.4913)	loss_scale 4096.0000 (3075.2567)	mem 7962MB
[2024-07-15 11:49:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:49 lr 0.000002	 wd 0.0000	time 0.2261 (0.2444)	loss 1.2033 (1.3630)	grad_norm 0.4483 (0.4929)	loss_scale 4096.0000 (3119.6176)	mem 7962MB
[2024-07-15 11:49:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:24 lr 0.000002	 wd 0.0000	time 0.2067 (0.2438)	loss 1.1188 (1.3631)	grad_norm 0.6216 (0.4927)	loss_scale 4096.0000 (3160.2832)	mem 7962MB
[2024-07-15 11:50:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1997 (0.2422)	loss 0.9504 (1.3612)	grad_norm 0.4403 (0.4921)	loss_scale 4096.0000 (3197.6969)	mem 7962MB
[2024-07-15 11:50:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 26 training takes 0:10:14
[2024-07-15 11:50:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 34.578 (34.578)	Loss 0.4167 (0.4167)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 11:51:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.160 Acc@5 97.268
[2024-07-15 11:51:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 11:51:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-15 11:51:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][0/2502]	eta 11:29:59 lr 0.000002	 wd 0.0000	time 16.5464 (16.5464)	loss 0.9353 (0.9353)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:51:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:16:09 lr 0.000002	 wd 0.0000	time 0.2943 (0.4036)	loss 1.4930 (1.3679)	grad_norm 0.4589 (0.5033)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:52:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:12:36 lr 0.000002	 wd 0.0000	time 0.1896 (0.3288)	loss 1.5763 (1.3631)	grad_norm 0.4600 (0.5539)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:52:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:10:49 lr 0.000002	 wd 0.0000	time 0.2031 (0.2949)	loss 1.3615 (1.3631)	grad_norm 0.4299 (0.5305)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:53:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:09:43 lr 0.000002	 wd 0.0000	time 0.2027 (0.2774)	loss 1.4470 (1.3610)	grad_norm 0.4275 (0.5150)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:53:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:08:53 lr 0.000002	 wd 0.0000	time 0.2547 (0.2667)	loss 0.9798 (1.3567)	grad_norm 0.4644 (0.5063)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:53:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:25 lr 0.000002	 wd 0.0000	time 0.2473 (0.2657)	loss 1.2779 (1.3600)	grad_norm 0.4393 (0.5017)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:54:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:49 lr 0.000002	 wd 0.0000	time 0.2199 (0.2604)	loss 1.4866 (1.3658)	grad_norm 0.4537 (0.4991)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:54:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:16 lr 0.000002	 wd 0.0000	time 0.2363 (0.2564)	loss 1.5364 (1.3694)	grad_norm 0.4472 (0.4985)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:54:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:45 lr 0.000001	 wd 0.0000	time 0.2423 (0.2533)	loss 1.2899 (1.3741)	grad_norm 0.4238 (0.4969)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:55:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:21 lr 0.000001	 wd 0.0000	time 0.2162 (0.2543)	loss 1.4171 (1.3722)	grad_norm 0.4623 (0.4955)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:55:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:53 lr 0.000001	 wd 0.0000	time 0.2074 (0.2522)	loss 1.5226 (1.3721)	grad_norm 0.4291 (0.4960)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:56:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:25 lr 0.000001	 wd 0.0000	time 0.2298 (0.2503)	loss 1.4849 (1.3721)	grad_norm 0.5000 (0.4951)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:56:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:58 lr 0.000001	 wd 0.0000	time 0.2527 (0.2486)	loss 1.4928 (1.3692)	grad_norm 0.4183 (0.4930)	loss_scale 4096.0000 (4096.0000)	mem 7962MB
[2024-07-15 11:56:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:33 lr 0.000001	 wd 0.0000	time 0.2656 (0.2483)	loss 1.2713 (1.3696)	grad_norm 0.4202 (nan)	loss_scale 2048.0000 (4037.5275)	mem 7962MB
[2024-07-15 11:57:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:04:09 lr 0.000001	 wd 0.0000	time 0.2463 (0.2488)	loss 1.5356 (1.3693)	grad_norm 0.4213 (nan)	loss_scale 2048.0000 (3904.9807)	mem 7962MB
[2024-07-15 11:57:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:43 lr 0.000001	 wd 0.0000	time 0.2146 (0.2477)	loss 1.5581 (1.3672)	grad_norm 0.5271 (nan)	loss_scale 2048.0000 (3788.9919)	mem 7962MB
[2024-07-15 11:58:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:17 lr 0.000001	 wd 0.0000	time 0.2183 (0.2465)	loss 1.3973 (1.3650)	grad_norm 0.4572 (nan)	loss_scale 2048.0000 (3686.6408)	mem 7962MB
[2024-07-15 11:58:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:52 lr 0.000001	 wd 0.0000	time 0.2543 (0.2463)	loss 1.5191 (1.3656)	grad_norm 0.4730 (nan)	loss_scale 2048.0000 (3595.6557)	mem 7962MB
[2024-07-15 11:59:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:28 lr 0.000001	 wd 0.0000	time 0.2223 (0.2471)	loss 1.0839 (1.3671)	grad_norm 0.4498 (nan)	loss_scale 2048.0000 (3514.2430)	mem 7962MB
[2024-07-15 11:59:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:02:03 lr 0.000001	 wd 0.0000	time 0.2323 (0.2463)	loss 1.0533 (1.3659)	grad_norm 0.4923 (nan)	loss_scale 2048.0000 (3440.9675)	mem 7962MB
[2024-07-15 11:59:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:38 lr 0.000001	 wd 0.0000	time 0.2279 (0.2455)	loss 1.7027 (1.3652)	grad_norm 0.5254 (nan)	loss_scale 2048.0000 (3374.6673)	mem 7962MB
[2024-07-15 12:00:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:14 lr 0.000001	 wd 0.0000	time 0.2422 (0.2455)	loss 1.0856 (1.3658)	grad_norm 0.4674 (nan)	loss_scale 2048.0000 (3314.3916)	mem 7962MB
[2024-07-15 12:00:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:49 lr 0.000001	 wd 0.0000	time 0.2000 (0.2457)	loss 1.4530 (1.3659)	grad_norm 0.4468 (nan)	loss_scale 2048.0000 (3259.3551)	mem 7962MB
[2024-07-15 12:00:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:25 lr 0.000001	 wd 0.0000	time 0.1987 (0.2452)	loss 1.3732 (1.3655)	grad_norm 0.4453 (nan)	loss_scale 2048.0000 (3208.9030)	mem 7962MB
[2024-07-15 12:01:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1676 (0.2433)	loss 1.5066 (1.3639)	grad_norm 0.4103 (nan)	loss_scale 2048.0000 (3162.4854)	mem 7962MB
[2024-07-15 12:01:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 27 training takes 0:10:15
[2024-07-15 12:02:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 34.654 (34.654)	Loss 0.4172 (0.4172)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 12:02:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.154 Acc@5 97.270
[2024-07-15 12:02:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 12:02:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-15 12:02:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][0/2502]	eta 11:39:58 lr 0.000001	 wd 0.0000	time 16.7860 (16.7860)	loss 1.2857 (1.2857)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:02:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:15:32 lr 0.000001	 wd 0.0000	time 0.1915 (0.3884)	loss 1.0692 (1.3448)	grad_norm 0.4473 (0.4864)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:03:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:12:16 lr 0.000001	 wd 0.0000	time 0.2612 (0.3201)	loss 1.0668 (1.3485)	grad_norm 0.4446 (0.4884)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:03:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:10:47 lr 0.000001	 wd 0.0000	time 0.2363 (0.2939)	loss 1.6449 (1.3585)	grad_norm 0.4571 (0.4823)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:04:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:09:41 lr 0.000001	 wd 0.0000	time 0.2194 (0.2766)	loss 1.3908 (1.3630)	grad_norm 0.4226 (0.4990)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:04:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:08:51 lr 0.000001	 wd 0.0000	time 0.2090 (0.2657)	loss 1.5707 (1.3652)	grad_norm 0.4749 (0.4971)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:04:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:16 lr 0.000001	 wd 0.0000	time 0.2169 (0.2611)	loss 1.3851 (1.3652)	grad_norm 0.4324 (0.4913)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:05:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:47 lr 0.000001	 wd 0.0000	time 0.2593 (0.2593)	loss 1.0280 (1.3670)	grad_norm 0.5739 (0.4950)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:05:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:14 lr 0.000001	 wd 0.0000	time 0.2019 (0.2552)	loss 1.6130 (1.3642)	grad_norm 0.4942 (0.5034)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:06:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:43 lr 0.000001	 wd 0.0000	time 0.2275 (0.2521)	loss 1.5328 (1.3649)	grad_norm 0.6042 (0.5035)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:06:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:16 lr 0.000001	 wd 0.0000	time 0.2227 (0.2505)	loss 1.5581 (1.3675)	grad_norm 0.4204 (0.5028)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:06:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:52 lr 0.000001	 wd 0.0000	time 0.2854 (0.2512)	loss 0.9469 (1.3639)	grad_norm 0.4875 (0.5015)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:07:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:24 lr 0.000001	 wd 0.0000	time 0.2285 (0.2493)	loss 1.2182 (1.3642)	grad_norm 0.5219 (0.4996)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:07:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:04:57 lr 0.000001	 wd 0.0000	time 0.1958 (0.2477)	loss 1.5624 (1.3611)	grad_norm 0.4629 (0.4983)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:08:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:31 lr 0.000001	 wd 0.0000	time 0.2077 (0.2467)	loss 0.9283 (1.3621)	grad_norm 0.4280 (0.4994)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:08:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:04:08 lr 0.000001	 wd 0.0000	time 0.2449 (0.2476)	loss 1.4913 (1.3606)	grad_norm 0.4414 (0.4980)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:08:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:42 lr 0.000001	 wd 0.0000	time 0.2695 (0.2466)	loss 1.1915 (1.3601)	grad_norm 0.5458 (0.4967)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:09:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:17 lr 0.000001	 wd 0.0000	time 0.2101 (0.2457)	loss 1.4230 (1.3615)	grad_norm 0.4804 (0.4966)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:09:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:52 lr 0.000001	 wd 0.0000	time 0.2343 (0.2451)	loss 1.3800 (1.3613)	grad_norm 0.5233 (0.4957)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:10:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:28 lr 0.000001	 wd 0.0000	time 0.1968 (0.2466)	loss 1.5424 (1.3602)	grad_norm 0.4728 (0.4954)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:10:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:02:03 lr 0.000001	 wd 0.0000	time 0.2290 (0.2459)	loss 0.8794 (1.3601)	grad_norm 0.4754 (0.4949)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:10:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:38 lr 0.000001	 wd 0.0000	time 0.2109 (0.2452)	loss 1.0924 (1.3603)	grad_norm 0.4314 (0.4944)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:11:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:13 lr 0.000001	 wd 0.0000	time 0.2580 (0.2448)	loss 1.5315 (1.3592)	grad_norm 0.7649 (0.4940)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:11:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:49 lr 0.000001	 wd 0.0000	time 0.1903 (0.2452)	loss 1.0920 (1.3593)	grad_norm 0.4823 (0.4944)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:12:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:24 lr 0.000001	 wd 0.0000	time 0.2376 (0.2446)	loss 1.5732 (1.3578)	grad_norm 0.4445 (0.4944)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:12:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1742 (0.2428)	loss 1.2010 (1.3570)	grad_norm 0.4689 (0.4948)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:12:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 28 training takes 0:10:15
[2024-07-15 12:13:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 31.720 (31.720)	Loss 0.4172 (0.4172)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 12:13:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.154 Acc@5 97.268
[2024-07-15 12:13:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 12:13:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-15 12:13:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][0/2502]	eta 11:38:07 lr 0.000001	 wd 0.0000	time 16.7416 (16.7416)	loss 1.4133 (1.4133)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:14:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:15:37 lr 0.000001	 wd 0.0000	time 0.2271 (0.3904)	loss 1.4679 (1.3385)	grad_norm 0.4385 (0.4917)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:14:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:12:04 lr 0.000001	 wd 0.0000	time 0.2939 (0.3146)	loss 1.1602 (1.3534)	grad_norm 0.4707 (0.4972)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:14:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:10:46 lr 0.000001	 wd 0.0000	time 0.2193 (0.2936)	loss 1.4882 (1.3524)	grad_norm 0.4747 (0.4932)	loss_scale 2048.0000 (2048.0000)	mem 7962MB
[2024-07-15 12:15:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:09:40 lr 0.000001	 wd 0.0000	time 0.1798 (0.2761)	loss 1.1839 (1.3612)	grad_norm 0.5762 (0.4892)	loss_scale 4096.0000 (2272.7182)	mem 7962MB
[2024-07-15 12:15:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:08:51 lr 0.000001	 wd 0.0000	time 0.2116 (0.2655)	loss 0.9514 (1.3627)	grad_norm 0.4518 (0.4889)	loss_scale 4096.0000 (2636.6467)	mem 7962MB
[2024-07-15 12:16:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:14 lr 0.000000	 wd 0.0000	time 0.2123 (0.2597)	loss 1.3441 (1.3635)	grad_norm 0.6923 (0.4870)	loss_scale 4096.0000 (2879.4676)	mem 7962MB
[2024-07-15 12:16:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:46 lr 0.000000	 wd 0.0000	time 0.2373 (0.2591)	loss 1.5749 (1.3643)	grad_norm 0.4910 (0.4854)	loss_scale 4096.0000 (3053.0100)	mem 7962MB
[2024-07-15 12:16:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:07:14 lr 0.000000	 wd 0.0000	time 0.2034 (0.2554)	loss 0.7967 (1.3653)	grad_norm 0.4161 (0.4847)	loss_scale 4096.0000 (3183.2210)	mem 7962MB
[2024-07-15 12:17:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:06:44 lr 0.000000	 wd 0.0000	time 0.2072 (0.2522)	loss 1.4175 (1.3651)	grad_norm 0.4611 (0.4875)	loss_scale 4096.0000 (3284.5283)	mem 7962MB
[2024-07-15 12:17:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:14 lr 0.000000	 wd 0.0000	time 0.2034 (0.2496)	loss 1.3295 (1.3648)	grad_norm 0.4439 (0.4860)	loss_scale 4096.0000 (3365.5944)	mem 7962MB
[2024-07-15 12:18:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:50 lr 0.000000	 wd 0.0000	time 0.1845 (0.2503)	loss 1.4673 (1.3654)	grad_norm 0.3985 (0.4846)	loss_scale 4096.0000 (3431.9346)	mem 7962MB
[2024-07-15 12:18:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:24 lr 0.000000	 wd 0.0000	time 0.2520 (0.2489)	loss 1.2683 (1.3623)	grad_norm 0.4386 (0.4846)	loss_scale 4096.0000 (3487.2273)	mem 7962MB
[2024-07-15 12:18:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:04:57 lr 0.000000	 wd 0.0000	time 0.2187 (0.2474)	loss 1.5475 (1.3632)	grad_norm 0.4494 (0.4859)	loss_scale 4096.0000 (3534.0200)	mem 7962MB
[2024-07-15 12:19:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:31 lr 0.000000	 wd 0.0000	time 0.2404 (0.2460)	loss 1.7610 (1.3620)	grad_norm 0.4463 (0.4870)	loss_scale 4096.0000 (3574.1328)	mem 7962MB
[2024-07-15 12:19:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:04:07 lr 0.000000	 wd 0.0000	time 1.4299 (0.2469)	loss 1.2887 (1.3633)	grad_norm 0.4422 (0.4872)	loss_scale 4096.0000 (3608.9007)	mem 7962MB
[2024-07-15 12:20:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:42 lr 0.000000	 wd 0.0000	time 0.2225 (0.2468)	loss 1.4780 (1.3647)	grad_norm 0.4559 (0.4876)	loss_scale 4096.0000 (3639.3254)	mem 7962MB
[2024-07-15 12:20:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:17 lr 0.000000	 wd 0.0000	time 0.1910 (0.2457)	loss 1.3050 (1.3616)	grad_norm 0.4731 (0.4875)	loss_scale 4096.0000 (3666.1728)	mem 7962MB
[2024-07-15 12:20:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:51 lr 0.000000	 wd 0.0000	time 0.2442 (0.2448)	loss 1.1617 (1.3632)	grad_norm 0.4600 (0.4864)	loss_scale 4096.0000 (3690.0389)	mem 7962MB
[2024-07-15 12:21:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:27 lr 0.000000	 wd 0.0000	time 0.2167 (0.2448)	loss 1.2314 (1.3629)	grad_norm 0.5051 (0.4860)	loss_scale 4096.0000 (3711.3940)	mem 7962MB
[2024-07-15 12:21:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:02:03 lr 0.000000	 wd 0.0000	time 0.2240 (0.2452)	loss 1.4963 (1.3630)	grad_norm 0.4898 (0.4870)	loss_scale 4096.0000 (3730.6147)	mem 7962MB
[2024-07-15 12:22:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:38 lr 0.000000	 wd 0.0000	time 0.2409 (0.2447)	loss 1.5011 (1.3635)	grad_norm 0.6164 (0.4882)	loss_scale 4096.0000 (3748.0057)	mem 7962MB
[2024-07-15 12:22:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:13 lr 0.000000	 wd 0.0000	time 0.2213 (0.2439)	loss 1.4111 (1.3652)	grad_norm 0.4462 (0.4872)	loss_scale 4096.0000 (3763.8164)	mem 7962MB
[2024-07-15 12:22:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:49 lr 0.000000	 wd 0.0000	time 0.2425 (0.2439)	loss 1.4163 (1.3665)	grad_norm 0.6036 (0.4874)	loss_scale 4096.0000 (3778.2529)	mem 7962MB
[2024-07-15 12:23:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.3250 (0.2563)	loss 1.4115 (1.3671)	grad_norm 0.4807 (0.4877)	loss_scale 4096.0000 (3791.4869)	mem 7962MB
[2024-07-15 12:24:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000000	 wd 0.0000	time 0.1798 (0.2550)	loss 1.5631 (1.3662)	grad_norm 0.4426 (0.4866)	loss_scale 4096.0000 (3803.6625)	mem 7962MB
[2024-07-15 12:24:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 29 training takes 0:10:49
[2024-07-15 12:24:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_29.pth saving......
[2024-07-15 12:24:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag2/ckpt_epoch_29.pth saved !!!
[2024-07-15 12:25:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 79.308 (79.308)	Loss 0.4172 (0.4172)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7962MB
[2024-07-15 12:26:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.150 Acc@5 97.270
[2024-07-15 12:26:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-15 12:26:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-15 12:26:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 189): INFO Training time 5:45:55
