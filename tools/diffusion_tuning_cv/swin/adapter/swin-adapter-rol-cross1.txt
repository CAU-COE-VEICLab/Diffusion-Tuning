[2024-07-10 09:24:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full/config.json
[2024-07-10 09:24:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process0/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer0/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_swin_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    DEPTHS:
    - 3
    - 3
    - 9
    - 3
    DIMS:
    - 96
    - 192
    - 384
    - 768
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: false
    AB_NORM_LTM: false
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: fullfinetune
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 4.0e-05
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.0e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 4.0e-08
  WEIGHT_DECAY: 1.0e-08

[2024-07-10 09:24:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/swin/diffusion_ft_adapter_swin_base_patch4_window7_224_22kto1k_sequence_cross_process1.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process0/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer0/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-10 09:24:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 108): INFO Creating model:adapter_swin_diffusion_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft
[2024-07-10 09:24:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 110): INFO Adapter_SwinTransformer_Diffusion_Finetune(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (uma): UMA(filter_strategy1=23, filter_strategy2=7,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-10 09:24:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 113): INFO number of params: 4531880
[2024-07-10 09:24:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 116): INFO number of GFLOPs: 15.438473216
[2024-07-10 09:24:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 150): INFO no checkpoint found in pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full, ignoring auto resume
[2024-07-10 09:24:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process0/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer0/ckpt_epoch_best.pth for fine-tuning......
[2024-07-10 09:24:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])
[2024-07-10 09:24:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process0/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer0/ckpt_epoch_best.pth'
[2024-07-10 09:25:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 78.338 (78.338)	Loss 0.4192 (0.4192)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 1490MB
[2024-07-10 09:26:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.042 Acc@5 97.226
[2024-07-10 09:26:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 162): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-10 09:26:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 168): INFO Start training
[2024-07-10 09:26:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][0/2502]	eta 14:54:38 lr 0.000000	 wd 0.0000	time 21.4541 (21.4541)	loss 1.6051 (1.6051)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 7938MB
[2024-07-10 09:26:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:17:46 lr 0.000000	 wd 0.0000	time 0.2397 (0.4440)	loss 1.4205 (1.4051)	grad_norm 0.4556 (inf)	loss_scale 16384.0000 (22386.0594)	mem 7984MB
[2024-07-10 09:27:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:16:04 lr 0.000001	 wd 0.0000	time 0.2570 (0.4189)	loss 1.4343 (1.3900)	grad_norm 0.5219 (inf)	loss_scale 16384.0000 (19399.9602)	mem 7984MB
[2024-07-10 09:27:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:13:03 lr 0.000001	 wd 0.0000	time 0.1971 (0.3558)	loss 1.4429 (1.3709)	grad_norm 0.5006 (inf)	loss_scale 16384.0000 (18397.9801)	mem 7984MB
[2024-07-10 09:28:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:11:19 lr 0.000001	 wd 0.0000	time 0.2216 (0.3234)	loss 1.8422 (1.3735)	grad_norm 0.4628 (inf)	loss_scale 16384.0000 (17895.7406)	mem 7984MB
[2024-07-10 09:28:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:10:18 lr 0.000002	 wd 0.0000	time 0.2647 (0.3091)	loss 1.4952 (1.3722)	grad_norm 0.4964 (inf)	loss_scale 16384.0000 (17593.9960)	mem 7984MB
[2024-07-10 09:29:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:33 lr 0.000002	 wd 0.0000	time 0.2588 (0.3013)	loss 1.1682 (1.3717)	grad_norm 0.4524 (inf)	loss_scale 16384.0000 (17392.6656)	mem 7984MB
[2024-07-10 09:29:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:46 lr 0.000002	 wd 0.0000	time 0.2218 (0.2920)	loss 1.4230 (1.3677)	grad_norm 0.5016 (inf)	loss_scale 16384.0000 (17248.7760)	mem 7984MB
[2024-07-10 09:29:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:08:04 lr 0.000003	 wd 0.0000	time 0.2306 (0.2846)	loss 1.5373 (1.3687)	grad_norm 0.9268 (inf)	loss_scale 16384.0000 (17140.8140)	mem 7984MB
[2024-07-10 09:30:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:30 lr 0.000003	 wd 0.0000	time 0.2487 (0.2815)	loss 1.5621 (1.3638)	grad_norm 0.5155 (inf)	loss_scale 16384.0000 (17056.8169)	mem 7984MB
[2024-07-10 09:30:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:07:00 lr 0.000003	 wd 0.0000	time 0.2410 (0.2797)	loss 1.3695 (1.3634)	grad_norm 0.5072 (inf)	loss_scale 16384.0000 (16989.6024)	mem 7984MB
[2024-07-10 09:31:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:26 lr 0.000004	 wd 0.0000	time 0.2370 (0.2756)	loss 1.5212 (1.3643)	grad_norm 0.4284 (nan)	loss_scale 8192.0000 (16250.0708)	mem 7984MB
[2024-07-10 09:31:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:53 lr 0.000004	 wd 0.0000	time 0.2031 (0.2718)	loss 1.4728 (1.3664)	grad_norm 0.4749 (nan)	loss_scale 8192.0000 (15579.1241)	mem 7984MB
[2024-07-10 09:31:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:24 lr 0.000004	 wd 0.0000	time 0.2294 (0.2702)	loss 1.4451 (1.3684)	grad_norm 0.4538 (nan)	loss_scale 4096.0000 (14897.9800)	mem 7984MB
[2024-07-10 09:32:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:56 lr 0.000005	 wd 0.0000	time 0.2039 (0.2689)	loss 1.5560 (1.3695)	grad_norm 0.4571 (nan)	loss_scale 4096.0000 (14126.9607)	mem 7984MB
[2024-07-10 09:32:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:27 lr 0.000005	 wd 0.0000	time 0.2475 (0.2666)	loss 1.4810 (1.3694)	grad_norm 0.4945 (nan)	loss_scale 4096.0000 (13458.6755)	mem 7984MB
[2024-07-10 09:33:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:58 lr 0.000005	 wd 0.0000	time 0.2073 (0.2644)	loss 1.5999 (1.3700)	grad_norm 0.5137 (nan)	loss_scale 4096.0000 (12873.8738)	mem 7984MB
[2024-07-10 09:33:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:31 lr 0.000005	 wd 0.0000	time 0.2632 (0.2635)	loss 1.4907 (1.3690)	grad_norm 0.7602 (nan)	loss_scale 4096.0000 (12357.8319)	mem 7984MB
[2024-07-10 09:33:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:03:05 lr 0.000006	 wd 0.0000	time 0.2019 (0.2641)	loss 1.2248 (1.3696)	grad_norm 0.4714 (nan)	loss_scale 4096.0000 (11899.0961)	mem 7984MB
[2024-07-10 09:34:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:38 lr 0.000006	 wd 0.0000	time 0.2305 (0.2627)	loss 1.6306 (1.3690)	grad_norm 0.4703 (nan)	loss_scale 4096.0000 (11488.6228)	mem 7984MB
[2024-07-10 09:34:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:11 lr 0.000006	 wd 0.0000	time 0.2197 (0.2612)	loss 1.5027 (1.3671)	grad_norm 0.4419 (nan)	loss_scale 4096.0000 (11119.1764)	mem 7984MB
[2024-07-10 09:35:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:44 lr 0.000007	 wd 0.0000	time 0.2579 (0.2606)	loss 1.3684 (1.3676)	grad_norm 0.5129 (nan)	loss_scale 4096.0000 (10784.8986)	mem 7984MB
[2024-07-10 09:35:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:18 lr 0.000007	 wd 0.0000	time 0.2258 (0.2601)	loss 1.6199 (1.3684)	grad_norm 0.4435 (nan)	loss_scale 4096.0000 (10480.9959)	mem 7984MB
[2024-07-10 09:35:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:52 lr 0.000007	 wd 0.0000	time 0.2127 (0.2589)	loss 1.5370 (1.3673)	grad_norm 0.4998 (nan)	loss_scale 4096.0000 (10203.5080)	mem 7984MB
[2024-07-10 09:36:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:26 lr 0.000008	 wd 0.0000	time 0.2079 (0.2577)	loss 1.4023 (1.3674)	grad_norm 0.6783 (nan)	loss_scale 4096.0000 (9949.1345)	mem 7984MB
[2024-07-10 09:36:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1688 (0.2557)	loss 1.6328 (1.3676)	grad_norm 0.4258 (nan)	loss_scale 4096.0000 (9715.1028)	mem 7984MB
[2024-07-10 09:36:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 0 training takes 0:10:44
[2024-07-10 09:36:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full/ckpt_epoch_0.pth saving......
[2024-07-10 09:36:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full/ckpt_epoch_0.pth saved !!!
[2024-07-10 09:37:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 53.297 (53.297)	Loss 0.4199 (0.4199)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 09:37:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.034 Acc@5 97.208
[2024-07-10 09:37:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-10 09:37:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.03%
[2024-07-10 09:37:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full/ckpt_epoch_best.pth saving......
[2024-07-10 09:37:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full/ckpt_epoch_best.pth saved !!!
[2024-07-10 09:38:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][0/2502]	eta 1 day, 1:08:22 lr 0.000008	 wd 0.0000	time 36.1719 (36.1719)	loss 1.2210 (1.2210)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:38:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:24:35 lr 0.000008	 wd 0.0000	time 0.1978 (0.6145)	loss 1.1598 (1.4058)	grad_norm 0.4879 (0.5188)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:39:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:16:13 lr 0.000009	 wd 0.0000	time 0.2591 (0.4228)	loss 1.3566 (1.4055)	grad_norm 0.5412 (0.5123)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:39:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:13:09 lr 0.000009	 wd 0.0000	time 0.2812 (0.3587)	loss 1.7018 (1.3847)	grad_norm 0.4661 (0.5194)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:40:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:11:54 lr 0.000009	 wd 0.0000	time 0.2046 (0.3401)	loss 0.9827 (1.3743)	grad_norm 0.7559 (0.5193)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:40:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:10:35 lr 0.000010	 wd 0.0000	time 0.2068 (0.3176)	loss 1.5253 (1.3726)	grad_norm 0.4507 (0.5182)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:40:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:09:35 lr 0.000010	 wd 0.0000	time 0.2064 (0.3025)	loss 1.4374 (1.3722)	grad_norm 0.5174 (0.5154)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:41:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:46 lr 0.000010	 wd 0.0000	time 0.2236 (0.2923)	loss 1.6318 (1.3709)	grad_norm 0.4881 (0.5155)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:41:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:08:14 lr 0.000011	 wd 0.0000	time 0.2508 (0.2905)	loss 1.5499 (1.3744)	grad_norm 0.4723 (0.5174)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:42:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:34 lr 0.000011	 wd 0.0000	time 0.2085 (0.2840)	loss 1.5966 (1.3717)	grad_norm 0.5125 (0.5164)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:42:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:59 lr 0.000011	 wd 0.0000	time 0.2090 (0.2794)	loss 1.6870 (1.3706)	grad_norm 0.5623 (0.5176)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:42:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:06:26 lr 0.000012	 wd 0.0000	time 0.2510 (0.2754)	loss 1.0838 (1.3697)	grad_norm 0.4613 (0.5158)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:43:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:57 lr 0.000012	 wd 0.0000	time 0.2738 (0.2747)	loss 1.3507 (1.3723)	grad_norm 0.4306 (0.5140)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:43:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:26 lr 0.000012	 wd 0.0000	time 0.2170 (0.2719)	loss 1.5504 (1.3757)	grad_norm 0.5340 (0.5128)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:44:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:56 lr 0.000012	 wd 0.0000	time 0.2597 (0.2693)	loss 1.4277 (1.3737)	grad_norm 0.5876 (0.5120)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:44:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:27 lr 0.000013	 wd 0.0000	time 0.2155 (0.2670)	loss 0.9847 (1.3721)	grad_norm 0.5865 (0.5107)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:45:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:04:00 lr 0.000013	 wd 0.0000	time 0.2119 (0.2669)	loss 0.9384 (1.3707)	grad_norm 0.5058 (0.5107)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:45:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:33 lr 0.000013	 wd 0.0000	time 0.2067 (0.2658)	loss 1.3524 (1.3700)	grad_norm 0.4894 (0.5103)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:45:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:03:05 lr 0.000014	 wd 0.0000	time 0.2243 (0.2642)	loss 1.4377 (1.3701)	grad_norm 0.5413 (0.5107)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:46:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:38 lr 0.000014	 wd 0.0000	time 0.2288 (0.2628)	loss 1.4575 (1.3713)	grad_norm 0.4989 (0.5106)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:46:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:11 lr 0.000014	 wd 0.0000	time 0.2201 (0.2629)	loss 1.3247 (1.3705)	grad_norm 0.4505 (0.5109)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:47:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:45 lr 0.000015	 wd 0.0000	time 0.2764 (0.2621)	loss 1.4043 (1.3715)	grad_norm 0.5278 (0.5104)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:47:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:18 lr 0.000015	 wd 0.0000	time 0.2124 (0.2609)	loss 1.2108 (1.3727)	grad_norm 0.4948 (0.5112)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:47:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:52 lr 0.000015	 wd 0.0000	time 0.2353 (0.2599)	loss 1.6358 (1.3732)	grad_norm 0.4693 (0.5109)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:48:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:26 lr 0.000016	 wd 0.0000	time 0.2013 (0.2600)	loss 1.4543 (1.3712)	grad_norm 0.4476 (0.5108)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:48:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1668 (0.2579)	loss 1.1121 (1.3725)	grad_norm 0.4280 (0.5110)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:48:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 1 training takes 0:10:50
[2024-07-10 09:49:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 24.274 (24.274)	Loss 0.4209 (0.4209)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 09:49:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.044 Acc@5 97.208
[2024-07-10 09:49:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-10 09:49:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.04%
[2024-07-10 09:49:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full/ckpt_epoch_best.pth saving......
[2024-07-10 09:49:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full/ckpt_epoch_best.pth saved !!!
[2024-07-10 09:49:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][0/2502]	eta 22:19:37 lr 0.000016	 wd 0.0000	time 32.1253 (32.1253)	loss 1.6525 (1.6525)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:50:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:22:01 lr 0.000016	 wd 0.0000	time 0.1945 (0.5501)	loss 1.4138 (1.3447)	grad_norm 0.5099 (0.5151)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:50:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:14:54 lr 0.000017	 wd 0.0000	time 0.2152 (0.3887)	loss 1.4440 (1.3646)	grad_norm 0.4443 (0.5071)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 09:51:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:12:18 lr 0.000017	 wd 0.0000	time 0.2690 (0.3356)	loss 1.2941 (1.3754)	grad_norm 0.5310 (0.5030)	loss_scale 8192.0000 (4640.3189)	mem 7984MB
[2024-07-10 09:51:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:11:29 lr 0.000017	 wd 0.0000	time 0.2309 (0.3282)	loss 1.5292 (1.3731)	grad_norm 0.5240 (0.4999)	loss_scale 8192.0000 (5526.0249)	mem 7984MB
[2024-07-10 09:51:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:10:17 lr 0.000018	 wd 0.0000	time 0.2253 (0.3084)	loss 1.5325 (1.3714)	grad_norm 0.4803 (0.5071)	loss_scale 8192.0000 (6058.1557)	mem 7984MB
[2024-07-10 09:52:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:09:21 lr 0.000018	 wd 0.0000	time 0.2323 (0.2953)	loss 1.2692 (1.3659)	grad_norm 0.4613 (0.5067)	loss_scale 8192.0000 (6413.2047)	mem 7984MB
[2024-07-10 09:52:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:08:36 lr 0.000018	 wd 0.0000	time 0.2709 (0.2865)	loss 1.2511 (1.3682)	grad_norm 0.4971 (inf)	loss_scale 4096.0000 (6176.1369)	mem 7984MB
[2024-07-10 09:53:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:08:02 lr 0.000019	 wd 0.0000	time 0.2880 (0.2832)	loss 1.4396 (1.3664)	grad_norm 0.5200 (inf)	loss_scale 4096.0000 (5916.4444)	mem 7984MB
[2024-07-10 09:53:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:07:24 lr 0.000019	 wd 0.0000	time 0.2415 (0.2777)	loss 1.5325 (1.3709)	grad_norm 0.4816 (inf)	loss_scale 4096.0000 (5714.3973)	mem 7984MB
[2024-07-10 09:53:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:49 lr 0.000019	 wd 0.0000	time 0.2351 (0.2730)	loss 1.4547 (1.3721)	grad_norm 0.4613 (inf)	loss_scale 4096.0000 (5552.7193)	mem 7984MB
[2024-07-10 09:54:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:06:18 lr 0.000020	 wd 0.0000	time 0.2176 (0.2700)	loss 1.1813 (1.3716)	grad_norm 0.4789 (inf)	loss_scale 4096.0000 (5420.4105)	mem 7984MB
[2024-07-10 09:54:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:51 lr 0.000020	 wd 0.0000	time 0.2433 (0.2700)	loss 1.2591 (1.3707)	grad_norm 0.5859 (inf)	loss_scale 4096.0000 (5310.1349)	mem 7984MB
[2024-07-10 09:55:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:05:21 lr 0.000020	 wd 0.0000	time 0.2081 (0.2673)	loss 1.7119 (1.3735)	grad_norm 0.5542 (inf)	loss_scale 4096.0000 (5216.8117)	mem 7984MB
[2024-07-10 09:55:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:51 lr 0.000020	 wd 0.0000	time 0.2175 (0.2648)	loss 1.4429 (1.3734)	grad_norm 0.4978 (inf)	loss_scale 4096.0000 (5136.8108)	mem 7984MB
[2024-07-10 09:55:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:23 lr 0.000021	 wd 0.0000	time 0.2133 (0.2627)	loss 1.5041 (1.3716)	grad_norm 0.4682 (inf)	loss_scale 4096.0000 (5067.4697)	mem 7984MB
[2024-07-10 09:56:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:57 lr 0.000021	 wd 0.0000	time 0.2328 (0.2631)	loss 1.2842 (1.3718)	grad_norm 1.0307 (inf)	loss_scale 4096.0000 (5006.7908)	mem 7984MB
[2024-07-10 09:56:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:29 lr 0.000021	 wd 0.0000	time 0.2354 (0.2614)	loss 1.4532 (1.3715)	grad_norm 0.4573 (inf)	loss_scale 4096.0000 (4953.2463)	mem 7984MB
[2024-07-10 09:57:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:03:02 lr 0.000022	 wd 0.0000	time 0.2374 (0.2599)	loss 1.3519 (1.3716)	grad_norm 0.4951 (inf)	loss_scale 4096.0000 (4905.6480)	mem 7984MB
[2024-07-10 09:57:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:35 lr 0.000022	 wd 0.0000	time 0.2198 (0.2587)	loss 1.0839 (1.3701)	grad_norm 0.4692 (inf)	loss_scale 4096.0000 (4863.0573)	mem 7984MB
[2024-07-10 09:58:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:02:10 lr 0.000022	 wd 0.0000	time 0.2086 (0.2591)	loss 1.1158 (1.3682)	grad_norm 0.4975 (inf)	loss_scale 4096.0000 (4824.7236)	mem 7984MB
[2024-07-10 09:58:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:43 lr 0.000023	 wd 0.0000	time 0.2423 (0.2582)	loss 1.4495 (1.3685)	grad_norm 0.5151 (inf)	loss_scale 4096.0000 (4790.0390)	mem 7984MB
[2024-07-10 09:58:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:17 lr 0.000023	 wd 0.0000	time 0.2043 (0.2571)	loss 1.5064 (1.3684)	grad_norm 0.4994 (inf)	loss_scale 4096.0000 (4758.5061)	mem 7984MB
[2024-07-10 09:59:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:51 lr 0.000023	 wd 0.0000	time 0.2582 (0.2562)	loss 1.5780 (1.3685)	grad_norm 0.4621 (inf)	loss_scale 4096.0000 (4729.7140)	mem 7984MB
[2024-07-10 09:59:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:26 lr 0.000024	 wd 0.0000	time 0.2114 (0.2562)	loss 1.4229 (1.3673)	grad_norm 0.4457 (inf)	loss_scale 4096.0000 (4703.3203)	mem 7984MB
[2024-07-10 09:59:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1804 (0.2542)	loss 1.4441 (1.3672)	grad_norm 0.4972 (inf)	loss_scale 4096.0000 (4679.0372)	mem 7984MB
[2024-07-10 10:00:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 2 training takes 0:10:41
[2024-07-10 10:00:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 22.784 (22.784)	Loss 0.4158 (0.4158)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 10:00:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 83.970 Acc@5 97.236
[2024-07-10 10:00:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-10 10:00:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.04%
[2024-07-10 10:01:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][0/2502]	eta 23:12:14 lr 0.000024	 wd 0.0000	time 33.3871 (33.3871)	loss 1.0937 (1.0937)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:01:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:22:28 lr 0.000024	 wd 0.0000	time 0.2087 (0.5615)	loss 1.6783 (1.3527)	grad_norm 0.5072 (0.5012)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:01:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:15:06 lr 0.000025	 wd 0.0000	time 0.2164 (0.3939)	loss 1.4993 (1.3650)	grad_norm 0.4656 (0.5120)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:02:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:12:22 lr 0.000025	 wd 0.0000	time 0.2223 (0.3372)	loss 1.4140 (1.3540)	grad_norm 0.5226 (0.5114)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:02:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:11:06 lr 0.000025	 wd 0.0000	time 0.2728 (0.3169)	loss 1.5251 (1.3603)	grad_norm 0.4726 (0.5081)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:03:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:10:00 lr 0.000026	 wd 0.0000	time 0.2290 (0.2998)	loss 1.3903 (1.3579)	grad_norm 0.4701 (0.5073)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:03:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:09:08 lr 0.000026	 wd 0.0000	time 0.2205 (0.2885)	loss 1.4690 (1.3575)	grad_norm 0.5119 (0.5161)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:03:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:08:24 lr 0.000026	 wd 0.0000	time 0.2233 (0.2798)	loss 1.4990 (1.3596)	grad_norm 0.4930 (0.5185)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:04:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:50 lr 0.000027	 wd 0.0000	time 0.2624 (0.2766)	loss 1.1349 (1.3601)	grad_norm 0.4480 (0.5202)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:04:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:07:18 lr 0.000027	 wd 0.0000	time 0.2265 (0.2740)	loss 1.3459 (1.3617)	grad_norm 0.4670 (0.5176)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:05:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:45 lr 0.000027	 wd 0.0000	time 0.2236 (0.2697)	loss 1.6044 (1.3650)	grad_norm 0.4387 (0.5153)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:05:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:06:12 lr 0.000028	 wd 0.0000	time 0.2302 (0.2659)	loss 1.4050 (1.3672)	grad_norm 0.7233 (0.5164)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:05:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:44 lr 0.000028	 wd 0.0000	time 0.2361 (0.2648)	loss 1.3057 (1.3662)	grad_norm 0.4100 (0.5157)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:06:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:05:16 lr 0.000028	 wd 0.0000	time 0.2811 (0.2634)	loss 1.2262 (1.3689)	grad_norm 0.4510 (0.5170)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:06:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:47 lr 0.000028	 wd 0.0000	time 0.2062 (0.2610)	loss 1.2249 (1.3697)	grad_norm 0.4938 (0.5161)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:07:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:19 lr 0.000029	 wd 0.0000	time 0.2391 (0.2590)	loss 1.3926 (1.3700)	grad_norm 0.4608 (0.5149)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:07:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:52 lr 0.000029	 wd 0.0000	time 0.2400 (0.2582)	loss 1.4160 (1.3687)	grad_norm 0.4591 (0.5147)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:07:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:27 lr 0.000029	 wd 0.0000	time 0.2283 (0.2588)	loss 1.0683 (1.3678)	grad_norm 0.4393 (0.5155)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:08:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:03:00 lr 0.000030	 wd 0.0000	time 0.2274 (0.2575)	loss 1.6336 (1.3694)	grad_norm 0.4995 (0.5176)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:08:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:34 lr 0.000030	 wd 0.0000	time 0.2325 (0.2562)	loss 1.5423 (1.3691)	grad_norm 0.4767 (0.5164)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:09:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:08 lr 0.000030	 wd 0.0000	time 0.2223 (0.2559)	loss 1.1635 (1.3699)	grad_norm 0.4784 (0.5170)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:09:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:42 lr 0.000031	 wd 0.0000	time 0.1834 (0.2559)	loss 1.2314 (1.3682)	grad_norm 0.4553 (0.5169)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:09:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:16 lr 0.000031	 wd 0.0000	time 0.2123 (0.2549)	loss 1.3548 (1.3693)	grad_norm 0.5170 (0.5176)	loss_scale 8192.0000 (4256.0436)	mem 7984MB
[2024-07-10 10:10:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:51 lr 0.000031	 wd 0.0000	time 0.2265 (0.2539)	loss 1.5341 (1.3700)	grad_norm 0.6588 (0.5176)	loss_scale 8192.0000 (4427.0978)	mem 7984MB
[2024-07-10 10:10:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:25 lr 0.000032	 wd 0.0000	time 0.2315 (0.2536)	loss 0.9828 (1.3693)	grad_norm 0.4619 (0.5176)	loss_scale 8192.0000 (4583.9034)	mem 7984MB
[2024-07-10 10:11:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000032	 wd 0.0000	time 0.1731 (0.2521)	loss 1.5519 (1.3698)	grad_norm 0.4893 (0.5181)	loss_scale 8192.0000 (4728.1695)	mem 7984MB
[2024-07-10 10:11:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 3 training takes 0:10:37
[2024-07-10 10:11:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 23.938 (23.938)	Loss 0.4189 (0.4189)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 10:11:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.002 Acc@5 97.220
[2024-07-10 10:11:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-10 10:11:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.04%
[2024-07-10 10:12:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][0/2502]	eta 16:52:03 lr 0.000032	 wd 0.0000	time 24.2699 (24.2699)	loss 1.4333 (1.4333)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 10:12:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:19:43 lr 0.000032	 wd 0.0000	time 0.2467 (0.4926)	loss 1.1495 (1.3802)	grad_norm 0.5057 (0.5038)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 10:13:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:13:47 lr 0.000033	 wd 0.0000	time 0.2234 (0.3597)	loss 1.1388 (1.3813)	grad_norm 0.4998 (0.5006)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 10:13:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:11:36 lr 0.000033	 wd 0.0000	time 0.2166 (0.3162)	loss 1.1134 (1.3811)	grad_norm 0.4745 (0.5066)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 10:13:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:10:22 lr 0.000033	 wd 0.0000	time 0.2217 (0.2961)	loss 1.5856 (1.3769)	grad_norm 0.4448 (0.5073)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 10:14:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:09:31 lr 0.000034	 wd 0.0000	time 0.1833 (0.2855)	loss 1.3400 (1.3704)	grad_norm 0.4984 (0.5080)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 10:14:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:08:45 lr 0.000034	 wd 0.0000	time 0.1942 (0.2763)	loss 1.4973 (1.3663)	grad_norm 0.6238 (0.5178)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 10:14:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:08:05 lr 0.000034	 wd 0.0000	time 0.2137 (0.2693)	loss 1.2877 (1.3663)	grad_norm 0.5330 (0.5181)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 10:15:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:30 lr 0.000035	 wd 0.0000	time 0.2466 (0.2647)	loss 1.4785 (1.3657)	grad_norm 0.4640 (0.5152)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 10:15:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:07:02 lr 0.000035	 wd 0.0000	time 0.2435 (0.2639)	loss 1.4952 (1.3669)	grad_norm 0.4880 (0.5127)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 10:16:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:32 lr 0.000035	 wd 0.0000	time 0.2263 (0.2611)	loss 1.5348 (1.3676)	grad_norm 0.5761 (0.5115)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 10:16:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:06:02 lr 0.000036	 wd 0.0000	time 0.2506 (0.2584)	loss 1.5380 (1.3684)	grad_norm 0.5477 (0.5113)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 10:16:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:33 lr 0.000036	 wd 0.0000	time 0.2516 (0.2561)	loss 1.0800 (1.3669)	grad_norm 0.5239 (0.5114)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 10:17:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:05:09 lr 0.000036	 wd 0.0000	time 0.2229 (0.2579)	loss 1.5747 (1.3662)	grad_norm 0.5344 (0.5122)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 10:17:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:42 lr 0.000036	 wd 0.0000	time 0.2274 (0.2559)	loss 1.5064 (1.3663)	grad_norm 0.4743 (0.5122)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 10:18:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:14 lr 0.000037	 wd 0.0000	time 0.2104 (0.2542)	loss 1.2586 (1.3687)	grad_norm 0.4582 (0.5121)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 10:18:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:48 lr 0.000037	 wd 0.0000	time 0.2965 (0.2530)	loss 1.0607 (1.3683)	grad_norm 0.4530 (0.5109)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 10:19:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:23 lr 0.000037	 wd 0.0000	time 0.2058 (0.2535)	loss 1.5567 (1.3677)	grad_norm 0.4567 (0.5110)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 10:19:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:57 lr 0.000038	 wd 0.0000	time 0.2094 (0.2530)	loss 1.3753 (1.3676)	grad_norm 0.4607 (inf)	loss_scale 4096.0000 (8005.5081)	mem 7984MB
[2024-07-10 10:19:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:31 lr 0.000038	 wd 0.0000	time 0.2286 (0.2520)	loss 1.6492 (1.3675)	grad_norm 0.4793 (inf)	loss_scale 4096.0000 (7799.8527)	mem 7984MB
[2024-07-10 10:20:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:02:06 lr 0.000038	 wd 0.0000	time 0.2507 (0.2511)	loss 1.4732 (1.3669)	grad_norm 0.4836 (inf)	loss_scale 4096.0000 (7614.7526)	mem 7984MB
[2024-07-10 10:20:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:41 lr 0.000039	 wd 0.0000	time 0.2079 (0.2514)	loss 1.4320 (1.3674)	grad_norm 0.4743 (inf)	loss_scale 4096.0000 (7447.2727)	mem 7984MB
[2024-07-10 10:21:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:15 lr 0.000039	 wd 0.0000	time 0.2150 (0.2508)	loss 0.9915 (1.3650)	grad_norm 0.4008 (inf)	loss_scale 4096.0000 (7295.0114)	mem 7984MB
[2024-07-10 10:21:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:50 lr 0.000039	 wd 0.0000	time 0.2518 (0.2499)	loss 1.2988 (1.3652)	grad_norm 0.5046 (inf)	loss_scale 4096.0000 (7155.9844)	mem 7984MB
[2024-07-10 10:21:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:25 lr 0.000040	 wd 0.0000	time 0.2416 (0.2494)	loss 1.5786 (1.3651)	grad_norm 0.4377 (inf)	loss_scale 4096.0000 (7028.5381)	mem 7984MB
[2024-07-10 10:22:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1730 (0.2479)	loss 0.9301 (1.3649)	grad_norm 0.4350 (inf)	loss_scale 4096.0000 (6911.2835)	mem 7984MB
[2024-07-10 10:22:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 4 training takes 0:10:29
[2024-07-10 10:22:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 25.180 (25.180)	Loss 0.4172 (0.4172)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 10:22:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.044 Acc@5 97.224
[2024-07-10 10:22:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-10 10:22:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.04%
[2024-07-10 10:23:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][0/2502]	eta 11:00:03 lr 0.000040	 wd 0.0000	time 15.8285 (15.8285)	loss 1.6047 (1.6047)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:23:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:16:15 lr 0.000040	 wd 0.0000	time 0.2249 (0.4060)	loss 1.2960 (1.3852)	grad_norm 0.7529 (0.5163)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:24:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:12:29 lr 0.000040	 wd 0.0000	time 0.2050 (0.3256)	loss 1.4770 (1.3885)	grad_norm 0.4906 (0.5113)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:24:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:43 lr 0.000040	 wd 0.0000	time 0.2030 (0.2925)	loss 1.6190 (1.3782)	grad_norm 0.4880 (0.5078)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:24:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:39 lr 0.000040	 wd 0.0000	time 0.2110 (0.2758)	loss 1.0088 (1.3798)	grad_norm 0.5060 (0.5065)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:25:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:08:56 lr 0.000040	 wd 0.0000	time 0.2437 (0.2679)	loss 1.5218 (1.3752)	grad_norm 0.4514 (0.5055)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:25:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:23 lr 0.000040	 wd 0.0000	time 0.2169 (0.2650)	loss 1.4361 (1.3760)	grad_norm 0.4292 (0.5055)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:26:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:47 lr 0.000040	 wd 0.0000	time 0.2303 (0.2596)	loss 1.4572 (1.3736)	grad_norm 0.5413 (0.5071)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:26:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:15 lr 0.000040	 wd 0.0000	time 0.2240 (0.2560)	loss 0.9429 (1.3676)	grad_norm 0.6528 (0.5045)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:26:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:46 lr 0.000040	 wd 0.0000	time 0.2404 (0.2540)	loss 0.9095 (1.3668)	grad_norm 0.4536 (0.5052)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:27:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:22 lr 0.000040	 wd 0.0000	time 0.2811 (0.2546)	loss 1.5311 (1.3700)	grad_norm 0.4461 (0.5046)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:27:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:53 lr 0.000040	 wd 0.0000	time 0.2400 (0.2523)	loss 1.5497 (1.3660)	grad_norm 0.4534 (0.5068)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:27:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:26 lr 0.000040	 wd 0.0000	time 0.2076 (0.2506)	loss 1.5514 (1.3640)	grad_norm 0.4511 (0.5067)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:28:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:59 lr 0.000040	 wd 0.0000	time 0.2705 (0.2495)	loss 1.5041 (1.3645)	grad_norm 0.4781 (0.5063)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:28:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:36 lr 0.000040	 wd 0.0000	time 0.1951 (0.2506)	loss 1.5332 (1.3640)	grad_norm 0.4623 (0.5058)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:29:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:04:10 lr 0.000040	 wd 0.0000	time 0.2642 (0.2495)	loss 1.3886 (1.3640)	grad_norm 0.4451 (0.5053)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:29:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:44 lr 0.000040	 wd 0.0000	time 0.2078 (0.2486)	loss 1.4565 (1.3659)	grad_norm 0.5010 (0.5038)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:29:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:18 lr 0.000040	 wd 0.0000	time 0.2229 (0.2478)	loss 1.3500 (1.3656)	grad_norm 0.4459 (0.5049)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:30:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:54 lr 0.000040	 wd 0.0000	time 0.2187 (0.2486)	loss 0.9958 (1.3649)	grad_norm 0.4504 (0.5045)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:30:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:29 lr 0.000040	 wd 0.0000	time 0.2225 (0.2481)	loss 1.4811 (1.3669)	grad_norm 0.4827 (0.5037)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:31:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:02:04 lr 0.000040	 wd 0.0000	time 0.2015 (0.2472)	loss 1.5124 (1.3679)	grad_norm 0.4831 (0.5038)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:31:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:39 lr 0.000040	 wd 0.0000	time 0.2420 (0.2468)	loss 1.5079 (1.3684)	grad_norm 0.4533 (0.5033)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:32:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:14 lr 0.000040	 wd 0.0000	time 0.2246 (0.2471)	loss 1.2400 (1.3664)	grad_norm 0.4522 (0.5042)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:32:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:49 lr 0.000040	 wd 0.0000	time 0.2311 (0.2468)	loss 0.9004 (1.3655)	grad_norm 0.4293 (0.5038)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:32:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:25 lr 0.000040	 wd 0.0000	time 0.2092 (0.2463)	loss 1.5154 (1.3656)	grad_norm 0.4832 (0.5035)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:33:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1743 (0.2446)	loss 1.5220 (1.3655)	grad_norm 0.4993 (0.5033)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:33:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 5 training takes 0:10:16
[2024-07-10 10:33:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 38.102 (38.102)	Loss 0.4138 (0.4138)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 10:34:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.014 Acc@5 97.230
[2024-07-10 10:34:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-10 10:34:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.04%
[2024-07-10 10:34:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][0/2502]	eta 11:34:55 lr 0.000040	 wd 0.0000	time 16.6649 (16.6649)	loss 1.5596 (1.5596)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:34:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:15:49 lr 0.000040	 wd 0.0000	time 0.2300 (0.3952)	loss 1.2092 (1.3361)	grad_norm 0.5448 (0.4967)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:35:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:12:41 lr 0.000040	 wd 0.0000	time 0.2186 (0.3308)	loss 1.5935 (1.3569)	grad_norm 0.4701 (0.5029)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:35:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:10:54 lr 0.000040	 wd 0.0000	time 0.2271 (0.2974)	loss 1.4690 (1.3677)	grad_norm 0.6917 (0.4984)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:35:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:09:48 lr 0.000040	 wd 0.0000	time 0.2183 (0.2802)	loss 1.3735 (1.3615)	grad_norm 0.4891 (0.4997)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:36:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:08:58 lr 0.000040	 wd 0.0000	time 0.2001 (0.2691)	loss 1.3516 (1.3559)	grad_norm 0.4721 (0.5011)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:36:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:08:29 lr 0.000040	 wd 0.0000	time 0.2098 (0.2677)	loss 1.5972 (1.3600)	grad_norm 0.4643 (0.5093)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:37:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:07:56 lr 0.000040	 wd 0.0000	time 0.2334 (0.2642)	loss 1.4158 (1.3625)	grad_norm 0.6058 (0.5115)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:37:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:21 lr 0.000040	 wd 0.0000	time 0.2002 (0.2597)	loss 1.0092 (1.3615)	grad_norm 0.5253 (0.5096)	loss_scale 8192.0000 (4535.7703)	mem 7984MB
[2024-07-10 10:37:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:06:50 lr 0.000040	 wd 0.0000	time 0.2448 (0.2561)	loss 1.6508 (1.3655)	grad_norm 0.4223 (0.5076)	loss_scale 8192.0000 (4941.5671)	mem 7984MB
[2024-07-10 10:38:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:25 lr 0.000040	 wd 0.0000	time 0.1772 (0.2567)	loss 1.3049 (1.3609)	grad_norm 0.4494 (0.5090)	loss_scale 8192.0000 (5266.2857)	mem 7984MB
[2024-07-10 10:38:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:57 lr 0.000040	 wd 0.0000	time 0.2305 (0.2547)	loss 1.2014 (1.3601)	grad_norm 0.4910 (0.5072)	loss_scale 8192.0000 (5532.0182)	mem 7984MB
[2024-07-10 10:39:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:29 lr 0.000040	 wd 0.0000	time 0.2170 (0.2529)	loss 1.0529 (1.3617)	grad_norm 0.5497 (0.5060)	loss_scale 8192.0000 (5753.4988)	mem 7984MB
[2024-07-10 10:39:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:05:01 lr 0.000040	 wd 0.0000	time 0.2292 (0.2510)	loss 1.4089 (1.3609)	grad_norm 0.4800 (nan)	loss_scale 4096.0000 (5877.9646)	mem 7984MB
[2024-07-10 10:39:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:36 lr 0.000040	 wd 0.0000	time 0.2745 (0.2506)	loss 1.6535 (1.3595)	grad_norm 0.5861 (nan)	loss_scale 4096.0000 (5750.7723)	mem 7984MB
[2024-07-10 10:40:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:11 lr 0.000040	 wd 0.0000	time 0.1922 (0.2506)	loss 1.4609 (1.3611)	grad_norm 0.4669 (nan)	loss_scale 4096.0000 (5640.5276)	mem 7984MB
[2024-07-10 10:40:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:45 lr 0.000040	 wd 0.0000	time 0.2350 (0.2496)	loss 1.5342 (1.3598)	grad_norm 0.6074 (nan)	loss_scale 4096.0000 (5544.0550)	mem 7984MB
[2024-07-10 10:41:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:19 lr 0.000040	 wd 0.0000	time 0.2278 (0.2484)	loss 1.5107 (1.3591)	grad_norm 0.5322 (nan)	loss_scale 4096.0000 (5458.9253)	mem 7984MB
[2024-07-10 10:41:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:54 lr 0.000040	 wd 0.0000	time 0.2228 (0.2484)	loss 1.1618 (1.3589)	grad_norm 0.4716 (nan)	loss_scale 4096.0000 (5383.2493)	mem 7984MB
[2024-07-10 10:41:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:29 lr 0.000040	 wd 0.0000	time 0.2062 (0.2491)	loss 1.2790 (1.3584)	grad_norm 0.5580 (nan)	loss_scale 4096.0000 (5315.5350)	mem 7984MB
[2024-07-10 10:42:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:02:04 lr 0.000039	 wd 0.0000	time 0.2276 (0.2483)	loss 0.9899 (1.3583)	grad_norm 0.4726 (nan)	loss_scale 4096.0000 (5254.5887)	mem 7984MB
[2024-07-10 10:42:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:39 lr 0.000039	 wd 0.0000	time 0.2307 (0.2475)	loss 1.5674 (1.3579)	grad_norm 0.5407 (nan)	loss_scale 4096.0000 (5199.4441)	mem 7984MB
[2024-07-10 10:43:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:14 lr 0.000039	 wd 0.0000	time 0.2775 (0.2475)	loss 1.2635 (1.3584)	grad_norm 0.4644 (nan)	loss_scale 4096.0000 (5149.3103)	mem 7984MB
[2024-07-10 10:43:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:50 lr 0.000039	 wd 0.0000	time 0.2606 (0.2476)	loss 1.4538 (1.3591)	grad_norm 0.4801 (nan)	loss_scale 4096.0000 (5103.5341)	mem 7984MB
[2024-07-10 10:43:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:25 lr 0.000039	 wd 0.0000	time 0.2192 (0.2470)	loss 1.1917 (1.3583)	grad_norm 0.4301 (nan)	loss_scale 4096.0000 (5061.5710)	mem 7984MB
[2024-07-10 10:44:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1683 (0.2453)	loss 1.0365 (1.3590)	grad_norm 0.4542 (nan)	loss_scale 4096.0000 (5022.9636)	mem 7984MB
[2024-07-10 10:44:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 6 training takes 0:10:17
[2024-07-10 10:44:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 35.926 (35.926)	Loss 0.4187 (0.4187)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 7984MB
[2024-07-10 10:45:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.030 Acc@5 97.232
[2024-07-10 10:45:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-10 10:45:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.04%
[2024-07-10 10:45:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][0/2502]	eta 11:26:43 lr 0.000039	 wd 0.0000	time 16.4682 (16.4682)	loss 1.5942 (1.5942)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:45:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:15:36 lr 0.000039	 wd 0.0000	time 0.2055 (0.3900)	loss 1.2334 (1.3843)	grad_norm 0.4787 (0.5106)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:46:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:12:12 lr 0.000039	 wd 0.0000	time 0.2535 (0.3183)	loss 1.4480 (1.3588)	grad_norm 1.2659 (0.5239)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:46:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:10:49 lr 0.000039	 wd 0.0000	time 0.2167 (0.2948)	loss 1.3105 (1.3564)	grad_norm 0.8330 (0.5175)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:47:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:09:42 lr 0.000039	 wd 0.0000	time 0.2191 (0.2772)	loss 1.3334 (1.3584)	grad_norm 0.4869 (0.5188)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:47:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:08:54 lr 0.000039	 wd 0.0000	time 0.2338 (0.2671)	loss 1.4416 (1.3538)	grad_norm 0.5585 (0.5174)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:47:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:17 lr 0.000039	 wd 0.0000	time 0.2226 (0.2617)	loss 1.3323 (1.3576)	grad_norm 0.4341 (0.5157)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:48:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:07:50 lr 0.000039	 wd 0.0000	time 0.2389 (0.2610)	loss 1.4835 (1.3614)	grad_norm 0.5093 (0.5141)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:48:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:07:17 lr 0.000039	 wd 0.0000	time 0.2251 (0.2572)	loss 0.9038 (1.3636)	grad_norm 0.4808 (0.5151)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:49:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:06:47 lr 0.000039	 wd 0.0000	time 0.2111 (0.2541)	loss 1.0899 (1.3655)	grad_norm 0.4702 (0.5153)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:49:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:19 lr 0.000039	 wd 0.0000	time 0.2934 (0.2525)	loss 1.1713 (1.3615)	grad_norm 0.4608 (0.5139)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:49:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:54 lr 0.000039	 wd 0.0000	time 0.1900 (0.2528)	loss 1.2380 (1.3600)	grad_norm 0.4508 (0.5139)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:50:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:27 lr 0.000039	 wd 0.0000	time 0.2235 (0.2512)	loss 1.4202 (1.3587)	grad_norm 0.4979 (0.5138)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:50:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:05:00 lr 0.000039	 wd 0.0000	time 0.2348 (0.2498)	loss 1.4768 (1.3588)	grad_norm 0.4868 (0.5124)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:51:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:33 lr 0.000039	 wd 0.0000	time 0.2277 (0.2486)	loss 1.4092 (1.3596)	grad_norm 0.4638 (0.5119)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:51:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:09 lr 0.000039	 wd 0.0000	time 0.2048 (0.2489)	loss 1.6496 (1.3589)	grad_norm 0.6803 (0.5115)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:51:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:43 lr 0.000039	 wd 0.0000	time 0.2091 (0.2481)	loss 1.5154 (1.3607)	grad_norm 0.4930 (0.5104)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:52:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:18 lr 0.000039	 wd 0.0000	time 0.2017 (0.2472)	loss 1.5733 (1.3610)	grad_norm 0.4829 (0.5110)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:52:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:53 lr 0.000039	 wd 0.0000	time 0.2728 (0.2466)	loss 1.1309 (1.3605)	grad_norm 0.8664 (0.5107)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:53:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:28 lr 0.000039	 wd 0.0000	time 0.2274 (0.2474)	loss 1.3158 (1.3599)	grad_norm 0.4989 (0.5104)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:53:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:02:04 lr 0.000039	 wd 0.0000	time 0.2336 (0.2473)	loss 1.4264 (1.3610)	grad_norm 0.4902 (0.5109)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:53:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:39 lr 0.000039	 wd 0.0000	time 0.2155 (0.2466)	loss 1.5040 (1.3621)	grad_norm 0.5452 (0.5102)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:54:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:14 lr 0.000039	 wd 0.0000	time 0.2373 (0.2460)	loss 1.1062 (1.3602)	grad_norm 0.4551 (0.5101)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:54:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:49 lr 0.000039	 wd 0.0000	time 0.2280 (0.2464)	loss 1.5798 (1.3607)	grad_norm 0.4372 (0.5102)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:55:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:25 lr 0.000039	 wd 0.0000	time 0.2296 (0.2460)	loss 1.4616 (1.3602)	grad_norm 0.4642 (0.5103)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:55:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1691 (0.2443)	loss 1.2787 (1.3604)	grad_norm 0.5143 (0.5094)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:55:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 7 training takes 0:10:15
[2024-07-10 10:55:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 23.801 (23.801)	Loss 0.4231 (0.4231)	Acc@1 91.797 (91.797)	Acc@5 98.438 (98.438)	Mem 7984MB
[2024-07-10 10:56:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.120 Acc@5 97.250
[2024-07-10 10:56:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-10 10:56:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-10 10:56:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full/ckpt_epoch_best.pth saving......
[2024-07-10 10:56:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full/ckpt_epoch_best.pth saved !!!
[2024-07-10 10:56:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][0/2502]	eta 12:32:00 lr 0.000039	 wd 0.0000	time 18.0337 (18.0337)	loss 1.4233 (1.4233)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:56:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:16:17 lr 0.000039	 wd 0.0000	time 0.2021 (0.4068)	loss 1.4546 (1.3977)	grad_norm 0.4429 (0.4896)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:57:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:12:10 lr 0.000039	 wd 0.0000	time 0.2415 (0.3172)	loss 1.5339 (1.3726)	grad_norm 0.4725 (0.4944)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 10:57:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:10:49 lr 0.000038	 wd 0.0000	time 0.2689 (0.2952)	loss 1.3559 (1.3695)	grad_norm 0.4777 (0.4962)	loss_scale 8192.0000 (4422.5914)	mem 7984MB
[2024-07-10 10:58:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:09:54 lr 0.000038	 wd 0.0000	time 0.2110 (0.2830)	loss 1.6240 (1.3658)	grad_norm 0.5877 (0.5050)	loss_scale 8192.0000 (5362.5935)	mem 7984MB
[2024-07-10 10:58:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:09:02 lr 0.000038	 wd 0.0000	time 0.2229 (0.2712)	loss 1.4439 (1.3690)	grad_norm 0.4545 (0.5046)	loss_scale 8192.0000 (5927.3453)	mem 7984MB
[2024-07-10 10:58:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:22 lr 0.000038	 wd 0.0000	time 0.2325 (0.2642)	loss 1.5301 (1.3736)	grad_norm 0.4618 (0.5047)	loss_scale 8192.0000 (6304.1597)	mem 7984MB
[2024-07-10 10:59:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:49 lr 0.000038	 wd 0.0000	time 0.2365 (0.2603)	loss 1.6355 (1.3717)	grad_norm 0.5851 (0.5066)	loss_scale 8192.0000 (6573.4665)	mem 7984MB
[2024-07-10 10:59:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:20 lr 0.000038	 wd 0.0000	time 0.2108 (0.2587)	loss 1.4794 (1.3694)	grad_norm 0.4388 (0.5097)	loss_scale 8192.0000 (6775.5306)	mem 7984MB
[2024-07-10 10:59:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:49 lr 0.000038	 wd 0.0000	time 0.2287 (0.2556)	loss 1.6557 (1.3695)	grad_norm 0.4820 (0.5104)	loss_scale 8192.0000 (6932.7414)	mem 7984MB
[2024-07-10 11:00:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:19 lr 0.000038	 wd 0.0000	time 0.2295 (0.2529)	loss 1.4997 (1.3658)	grad_norm 0.4607 (0.5098)	loss_scale 8192.0000 (7058.5415)	mem 7984MB
[2024-07-10 11:00:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:52 lr 0.000038	 wd 0.0000	time 0.2510 (0.2513)	loss 1.3379 (1.3627)	grad_norm 0.9699 (0.5088)	loss_scale 8192.0000 (7161.4896)	mem 7984MB
[2024-07-10 11:01:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:28 lr 0.000038	 wd 0.0000	time 0.2014 (0.2523)	loss 1.4566 (1.3630)	grad_norm 0.4956 (0.5092)	loss_scale 8192.0000 (7247.2939)	mem 7984MB
[2024-07-10 11:01:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:05:01 lr 0.000038	 wd 0.0000	time 0.2100 (0.2509)	loss 1.1814 (1.3615)	grad_norm 0.5280 (nan)	loss_scale 4096.0000 (7080.6334)	mem 7984MB
[2024-07-10 11:01:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:35 lr 0.000038	 wd 0.0000	time 0.2302 (0.2497)	loss 0.9625 (1.3633)	grad_norm 0.5044 (nan)	loss_scale 4096.0000 (6867.5974)	mem 7984MB
[2024-07-10 11:02:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:04:09 lr 0.000038	 wd 0.0000	time 0.2545 (0.2487)	loss 0.8293 (1.3610)	grad_norm 0.5064 (nan)	loss_scale 4096.0000 (6682.9474)	mem 7984MB
[2024-07-10 11:02:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:45 lr 0.000038	 wd 0.0000	time 0.2170 (0.2495)	loss 1.2273 (1.3582)	grad_norm 0.4681 (nan)	loss_scale 4096.0000 (6521.3641)	mem 7984MB
[2024-07-10 11:03:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:19 lr 0.000038	 wd 0.0000	time 0.2213 (0.2488)	loss 1.1803 (1.3600)	grad_norm 0.4825 (nan)	loss_scale 4096.0000 (6378.7795)	mem 7984MB
[2024-07-10 11:03:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:54 lr 0.000038	 wd 0.0000	time 0.2407 (0.2482)	loss 1.5330 (1.3610)	grad_norm 0.4453 (nan)	loss_scale 4096.0000 (6252.0289)	mem 7984MB
[2024-07-10 11:04:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:29 lr 0.000038	 wd 0.0000	time 0.2224 (0.2476)	loss 1.3111 (1.3602)	grad_norm 3.0952 (nan)	loss_scale 4096.0000 (6138.6134)	mem 7984MB
[2024-07-10 11:04:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:02:04 lr 0.000038	 wd 0.0000	time 0.2858 (0.2486)	loss 1.6936 (1.3623)	grad_norm 0.4689 (nan)	loss_scale 4096.0000 (6036.5337)	mem 7984MB
[2024-07-10 11:04:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:39 lr 0.000038	 wd 0.0000	time 0.2088 (0.2481)	loss 1.4079 (1.3614)	grad_norm 0.6610 (nan)	loss_scale 4096.0000 (5944.1713)	mem 7984MB
[2024-07-10 11:05:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:14 lr 0.000038	 wd 0.0000	time 0.2213 (0.2475)	loss 1.5600 (1.3599)	grad_norm 0.5916 (nan)	loss_scale 4096.0000 (5860.2017)	mem 7984MB
[2024-07-10 11:05:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:49 lr 0.000038	 wd 0.0000	time 0.2343 (0.2470)	loss 1.4880 (1.3607)	grad_norm 0.5256 (nan)	loss_scale 4096.0000 (5783.5306)	mem 7984MB
[2024-07-10 11:06:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:25 lr 0.000038	 wd 0.0000	time 0.2063 (0.2474)	loss 1.3166 (1.3622)	grad_norm 0.4919 (nan)	loss_scale 4096.0000 (5713.2461)	mem 7984MB
[2024-07-10 11:06:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000038	 wd 0.0000	time 0.1883 (0.2456)	loss 1.7487 (1.3636)	grad_norm 0.4376 (nan)	loss_scale 4096.0000 (5648.5822)	mem 7984MB
[2024-07-10 11:06:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 8 training takes 0:10:19
[2024-07-10 11:06:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 20.997 (20.997)	Loss 0.4229 (0.4229)	Acc@1 91.602 (91.602)	Acc@5 98.438 (98.438)	Mem 7984MB
[2024-07-10 11:07:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.074 Acc@5 97.262
[2024-07-10 11:07:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-10 11:07:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-10 11:07:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][0/2502]	eta 18:37:26 lr 0.000038	 wd 0.0000	time 26.7970 (26.7970)	loss 1.3681 (1.3681)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:07:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:20:37 lr 0.000038	 wd 0.0000	time 0.2248 (0.5150)	loss 1.2366 (1.3285)	grad_norm 0.4647 (0.4820)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:08:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:14:14 lr 0.000037	 wd 0.0000	time 0.2157 (0.3711)	loss 1.4944 (1.3410)	grad_norm 0.6003 (0.4981)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:08:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:11:48 lr 0.000037	 wd 0.0000	time 0.2159 (0.3218)	loss 1.4396 (1.3527)	grad_norm 0.5005 (0.5013)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:09:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:10:38 lr 0.000037	 wd 0.0000	time 0.2440 (0.3039)	loss 1.5758 (1.3476)	grad_norm 0.4944 (0.5042)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:09:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:09:40 lr 0.000037	 wd 0.0000	time 0.2288 (0.2899)	loss 1.3820 (1.3543)	grad_norm 0.4619 (0.5034)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:09:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:52 lr 0.000037	 wd 0.0000	time 0.2345 (0.2801)	loss 1.4971 (1.3489)	grad_norm 0.4469 (0.5041)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:10:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:08:11 lr 0.000037	 wd 0.0000	time 0.2248 (0.2728)	loss 1.5246 (1.3505)	grad_norm 0.4788 (0.5075)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:10:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:38 lr 0.000037	 wd 0.0000	time 0.2240 (0.2693)	loss 1.3841 (1.3533)	grad_norm 0.5139 (0.5083)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:11:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:07:07 lr 0.000037	 wd 0.0000	time 0.2066 (0.2669)	loss 1.5919 (1.3503)	grad_norm 0.4729 (0.5066)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:11:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:35 lr 0.000037	 wd 0.0000	time 0.2228 (0.2631)	loss 1.4709 (1.3531)	grad_norm 0.9821 (0.5073)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:11:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:06:04 lr 0.000037	 wd 0.0000	time 0.2236 (0.2601)	loss 1.3875 (1.3561)	grad_norm 0.4565 (0.5086)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:12:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:36 lr 0.000037	 wd 0.0000	time 0.2270 (0.2585)	loss 1.5414 (1.3572)	grad_norm 0.4587 (0.5083)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:12:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:05:10 lr 0.000037	 wd 0.0000	time 0.2208 (0.2586)	loss 0.9644 (1.3551)	grad_norm 0.4479 (0.5079)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:13:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:42 lr 0.000037	 wd 0.0000	time 0.1998 (0.2568)	loss 1.3377 (1.3564)	grad_norm 0.4449 (0.5091)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:13:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:04:15 lr 0.000037	 wd 0.0000	time 0.2105 (0.2550)	loss 1.4673 (1.3584)	grad_norm 0.7391 (0.5084)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:13:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:49 lr 0.000037	 wd 0.0000	time 0.2498 (0.2541)	loss 0.9349 (1.3574)	grad_norm 0.4458 (0.5093)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:14:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:23 lr 0.000037	 wd 0.0000	time 0.2228 (0.2543)	loss 1.1038 (1.3586)	grad_norm 0.4679 (0.5084)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:14:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:57 lr 0.000037	 wd 0.0000	time 0.2207 (0.2533)	loss 1.5342 (1.3590)	grad_norm 0.4873 (0.5084)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:15:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:31 lr 0.000037	 wd 0.0000	time 0.2149 (0.2523)	loss 1.3309 (1.3577)	grad_norm 0.5401 (0.5106)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:15:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:02:06 lr 0.000037	 wd 0.0000	time 0.2536 (0.2517)	loss 1.4929 (1.3579)	grad_norm 0.4583 (0.5101)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:15:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:41 lr 0.000036	 wd 0.0000	time 0.2098 (0.2517)	loss 1.0721 (1.3580)	grad_norm 0.4945 (0.5092)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:16:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:15 lr 0.000036	 wd 0.0000	time 0.2279 (0.2509)	loss 1.4843 (1.3590)	grad_norm 0.4576 (0.5099)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:16:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:50 lr 0.000036	 wd 0.0000	time 0.2203 (0.2501)	loss 1.4278 (1.3596)	grad_norm 0.5103 (0.5104)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:17:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:25 lr 0.000036	 wd 0.0000	time 0.2941 (0.2497)	loss 1.2685 (1.3593)	grad_norm 0.4881 (0.5098)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:17:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000036	 wd 0.0000	time 0.1705 (0.2482)	loss 1.1237 (1.3604)	grad_norm 0.4258 (0.5097)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:17:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 9 training takes 0:10:30
[2024-07-10 11:17:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 21.088 (21.088)	Loss 0.4138 (0.4138)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 11:18:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.046 Acc@5 97.244
[2024-07-10 11:18:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-10 11:18:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-10 11:18:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][0/2502]	eta 11:53:51 lr 0.000036	 wd 0.0000	time 17.1189 (17.1189)	loss 1.2814 (1.2814)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:18:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:16:54 lr 0.000036	 wd 0.0000	time 0.2325 (0.4222)	loss 1.3544 (1.3408)	grad_norm 0.4441 (0.5117)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:19:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:12:47 lr 0.000036	 wd 0.0000	time 0.2246 (0.3334)	loss 1.2974 (1.3612)	grad_norm 0.4524 (0.5044)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:19:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:54 lr 0.000036	 wd 0.0000	time 0.2447 (0.2971)	loss 0.8887 (1.3584)	grad_norm 0.4747 (nan)	loss_scale 4096.0000 (4749.1827)	mem 7984MB
[2024-07-10 11:19:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:45 lr 0.000036	 wd 0.0000	time 0.1965 (0.2786)	loss 1.5147 (1.3617)	grad_norm 0.5059 (nan)	loss_scale 4096.0000 (4586.2943)	mem 7984MB
[2024-07-10 11:20:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:09:03 lr 0.000036	 wd 0.0000	time 0.2260 (0.2713)	loss 1.4160 (1.3577)	grad_norm 0.4769 (nan)	loss_scale 4096.0000 (4488.4311)	mem 7984MB
[2024-07-10 11:20:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:31 lr 0.000036	 wd 0.0000	time 0.2560 (0.2688)	loss 1.5127 (1.3580)	grad_norm 0.4730 (nan)	loss_scale 4096.0000 (4423.1348)	mem 7984MB
[2024-07-10 11:21:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:53 lr 0.000036	 wd 0.0000	time 0.2216 (0.2629)	loss 1.4684 (1.3539)	grad_norm 0.4474 (nan)	loss_scale 4096.0000 (4376.4679)	mem 7984MB
[2024-07-10 11:21:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:07:20 lr 0.000036	 wd 0.0000	time 0.2159 (0.2589)	loss 1.2417 (1.3532)	grad_norm 0.4339 (nan)	loss_scale 4096.0000 (4341.4532)	mem 7984MB
[2024-07-10 11:21:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:52 lr 0.000036	 wd 0.0000	time 0.2547 (0.2575)	loss 1.5363 (1.3533)	grad_norm 0.4859 (nan)	loss_scale 4096.0000 (4314.2109)	mem 7984MB
[2024-07-10 11:22:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:25 lr 0.000036	 wd 0.0000	time 0.2271 (0.2567)	loss 1.4961 (1.3519)	grad_norm 0.5315 (nan)	loss_scale 4096.0000 (4292.4116)	mem 7984MB
[2024-07-10 11:22:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:56 lr 0.000036	 wd 0.0000	time 0.2141 (0.2542)	loss 1.2982 (1.3495)	grad_norm 0.4849 (nan)	loss_scale 4096.0000 (4274.5722)	mem 7984MB
[2024-07-10 11:23:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:28 lr 0.000035	 wd 0.0000	time 0.2146 (0.2521)	loss 1.3440 (1.3501)	grad_norm 0.4569 (nan)	loss_scale 4096.0000 (4259.7036)	mem 7984MB
[2024-07-10 11:23:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:05:01 lr 0.000035	 wd 0.0000	time 0.2328 (0.2512)	loss 1.5824 (1.3528)	grad_norm 0.4645 (nan)	loss_scale 4096.0000 (4247.1207)	mem 7984MB
[2024-07-10 11:23:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:36 lr 0.000035	 wd 0.0000	time 0.2174 (0.2513)	loss 1.3375 (1.3533)	grad_norm 0.4707 (nan)	loss_scale 4096.0000 (4236.3340)	mem 7984MB
[2024-07-10 11:24:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:04:10 lr 0.000035	 wd 0.0000	time 0.2129 (0.2501)	loss 1.2515 (1.3533)	grad_norm 0.5200 (nan)	loss_scale 4096.0000 (4226.9847)	mem 7984MB
[2024-07-10 11:24:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:44 lr 0.000035	 wd 0.0000	time 0.2203 (0.2490)	loss 1.2313 (1.3547)	grad_norm 0.4894 (nan)	loss_scale 4096.0000 (4218.8032)	mem 7984MB
[2024-07-10 11:25:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:19 lr 0.000035	 wd 0.0000	time 0.2515 (0.2485)	loss 1.3193 (1.3558)	grad_norm 0.4916 (nan)	loss_scale 4096.0000 (4211.5838)	mem 7984MB
[2024-07-10 11:25:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:55 lr 0.000035	 wd 0.0000	time 0.2052 (0.2496)	loss 1.4023 (1.3565)	grad_norm 0.5527 (nan)	loss_scale 4096.0000 (4205.1660)	mem 7984MB
[2024-07-10 11:25:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:29 lr 0.000035	 wd 0.0000	time 0.2164 (0.2488)	loss 1.5060 (1.3579)	grad_norm 0.5603 (nan)	loss_scale 4096.0000 (4199.4235)	mem 7984MB
[2024-07-10 11:26:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:02:04 lr 0.000035	 wd 0.0000	time 0.2505 (0.2480)	loss 1.2504 (1.3590)	grad_norm 0.4905 (nan)	loss_scale 4096.0000 (4194.2549)	mem 7984MB
[2024-07-10 11:26:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:39 lr 0.000035	 wd 0.0000	time 0.2164 (0.2477)	loss 1.5540 (1.3607)	grad_norm 0.4803 (nan)	loss_scale 4096.0000 (4189.5783)	mem 7984MB
[2024-07-10 11:27:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:14 lr 0.000035	 wd 0.0000	time 0.3087 (0.2478)	loss 0.9562 (1.3605)	grad_norm 0.4940 (nan)	loss_scale 4096.0000 (4185.3267)	mem 7984MB
[2024-07-10 11:27:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:49 lr 0.000035	 wd 0.0000	time 0.2171 (0.2471)	loss 1.4857 (1.3601)	grad_norm 0.4701 (nan)	loss_scale 4096.0000 (4181.4446)	mem 7984MB
[2024-07-10 11:27:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:25 lr 0.000035	 wd 0.0000	time 0.2276 (0.2466)	loss 1.5229 (1.3599)	grad_norm 0.4493 (nan)	loss_scale 4096.0000 (4177.8859)	mem 7984MB
[2024-07-10 11:28:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1954 (0.2448)	loss 1.3293 (1.3590)	grad_norm 0.6915 (nan)	loss_scale 4096.0000 (4174.6118)	mem 7984MB
[2024-07-10 11:28:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 10 training takes 0:10:17
[2024-07-10 11:28:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 36.532 (36.532)	Loss 0.4207 (0.4207)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 11:29:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.058 Acc@5 97.246
[2024-07-10 11:29:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-10 11:29:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-10 11:29:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][0/2502]	eta 11:10:00 lr 0.000035	 wd 0.0000	time 16.0674 (16.0674)	loss 1.4980 (1.4980)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:29:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:15:40 lr 0.000035	 wd 0.0000	time 0.2126 (0.3915)	loss 1.3952 (1.3507)	grad_norm 0.5640 (0.5082)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:30:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:12:33 lr 0.000034	 wd 0.0000	time 0.2046 (0.3272)	loss 1.4666 (1.3547)	grad_norm 0.4884 (0.5059)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:30:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:10:48 lr 0.000034	 wd 0.0000	time 0.2269 (0.2944)	loss 1.3281 (1.3571)	grad_norm 0.4694 (0.5116)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:31:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:09:43 lr 0.000034	 wd 0.0000	time 0.2017 (0.2777)	loss 1.5369 (1.3570)	grad_norm 0.5414 (0.5088)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:31:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:08:54 lr 0.000034	 wd 0.0000	time 0.2183 (0.2669)	loss 1.3870 (1.3539)	grad_norm 0.4238 (0.5048)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:31:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:23 lr 0.000034	 wd 0.0000	time 0.2145 (0.2648)	loss 1.4819 (1.3515)	grad_norm 0.4886 (0.5044)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:32:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:07:51 lr 0.000034	 wd 0.0000	time 0.2244 (0.2618)	loss 1.4745 (1.3520)	grad_norm 0.4744 (0.5034)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:32:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:07:18 lr 0.000034	 wd 0.0000	time 0.1976 (0.2577)	loss 1.6002 (1.3545)	grad_norm 0.4769 (0.5042)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:33:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:06:47 lr 0.000034	 wd 0.0000	time 0.2319 (0.2545)	loss 1.5118 (1.3544)	grad_norm 0.4954 (0.5038)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:33:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:22 lr 0.000034	 wd 0.0000	time 0.2665 (0.2546)	loss 1.4483 (1.3566)	grad_norm 0.4702 (0.5043)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:33:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:55 lr 0.000034	 wd 0.0000	time 0.2102 (0.2536)	loss 1.5616 (1.3580)	grad_norm 0.7512 (0.5051)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:34:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:27 lr 0.000034	 wd 0.0000	time 0.2109 (0.2517)	loss 1.6984 (1.3578)	grad_norm 0.5430 (0.5074)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:34:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:05:00 lr 0.000034	 wd 0.0000	time 0.2522 (0.2499)	loss 0.8923 (1.3567)	grad_norm 0.5008 (0.5093)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:35:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:35 lr 0.000034	 wd 0.0000	time 0.2224 (0.2501)	loss 0.8841 (1.3563)	grad_norm 0.4286 (0.5086)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:35:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:04:10 lr 0.000034	 wd 0.0000	time 0.2301 (0.2500)	loss 1.4302 (1.3553)	grad_norm 0.4523 (0.5078)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:35:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:44 lr 0.000034	 wd 0.0000	time 0.2403 (0.2489)	loss 1.2609 (1.3563)	grad_norm 0.4985 (0.5077)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:36:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:18 lr 0.000033	 wd 0.0000	time 0.2176 (0.2479)	loss 1.4589 (1.3555)	grad_norm 0.4848 (0.5067)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:36:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:54 lr 0.000033	 wd 0.0000	time 0.2752 (0.2479)	loss 1.2774 (1.3571)	grad_norm 0.5394 (0.5063)	loss_scale 8192.0000 (4173.3259)	mem 7984MB
[2024-07-10 11:37:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:29 lr 0.000033	 wd 0.0000	time 0.2333 (0.2489)	loss 1.4959 (1.3572)	grad_norm 0.4604 (0.5054)	loss_scale 8192.0000 (4384.7238)	mem 7984MB
[2024-07-10 11:37:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:02:04 lr 0.000033	 wd 0.0000	time 0.2198 (0.2480)	loss 1.1144 (1.3566)	grad_norm 0.5919 (0.5072)	loss_scale 8192.0000 (4574.9925)	mem 7984MB
[2024-07-10 11:37:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:39 lr 0.000033	 wd 0.0000	time 0.2302 (0.2472)	loss 1.5390 (1.3564)	grad_norm 0.4922 (0.5065)	loss_scale 8192.0000 (4747.1490)	mem 7984MB
[2024-07-10 11:38:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:14 lr 0.000033	 wd 0.0000	time 0.2394 (0.2472)	loss 1.2817 (1.3573)	grad_norm 0.4717 (0.5059)	loss_scale 8192.0000 (4903.6620)	mem 7984MB
[2024-07-10 11:38:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:49 lr 0.000033	 wd 0.0000	time 0.2416 (0.2471)	loss 1.5261 (1.3569)	grad_norm 0.6078 (0.5060)	loss_scale 8192.0000 (5046.5711)	mem 7984MB
[2024-07-10 11:39:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:25 lr 0.000033	 wd 0.0000	time 0.2130 (0.2466)	loss 1.2661 (1.3561)	grad_norm 0.6293 (0.5082)	loss_scale 8192.0000 (5177.5760)	mem 7984MB
[2024-07-10 11:39:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000033	 wd 0.0000	time 0.2070 (0.2449)	loss 1.4025 (1.3557)	grad_norm 0.4728 (0.5073)	loss_scale 8192.0000 (5298.1048)	mem 7984MB
[2024-07-10 11:39:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 11 training takes 0:10:17
[2024-07-10 11:40:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 34.041 (34.041)	Loss 0.4160 (0.4160)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 11:40:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.180 Acc@5 97.248
[2024-07-10 11:40:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-10 11:40:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-10 11:40:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full/ckpt_epoch_best.pth saving......
[2024-07-10 11:40:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full/ckpt_epoch_best.pth saved !!!
[2024-07-10 11:40:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][0/2502]	eta 10:23:51 lr 0.000033	 wd 0.0000	time 14.9606 (14.9606)	loss 1.6141 (1.6141)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 11:40:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:15:06 lr 0.000033	 wd 0.0000	time 0.2302 (0.3772)	loss 1.5015 (1.3616)	grad_norm 0.4683 (0.4956)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 11:41:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:11:54 lr 0.000033	 wd 0.0000	time 0.2171 (0.3103)	loss 0.9808 (1.3674)	grad_norm 0.4226 (0.4975)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 11:41:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:40 lr 0.000033	 wd 0.0000	time 0.1940 (0.2907)	loss 1.3051 (1.3676)	grad_norm 0.4984 (0.4927)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 11:42:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:37 lr 0.000033	 wd 0.0000	time 0.1967 (0.2747)	loss 1.2295 (1.3603)	grad_norm 0.4865 (0.5022)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 11:42:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:08:51 lr 0.000032	 wd 0.0000	time 0.2074 (0.2654)	loss 1.0191 (1.3611)	grad_norm 0.4606 (nan)	loss_scale 4096.0000 (7750.5150)	mem 7984MB
[2024-07-10 11:42:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:08:15 lr 0.000032	 wd 0.0000	time 0.2388 (0.2603)	loss 1.3487 (1.3583)	grad_norm 0.4567 (nan)	loss_scale 4096.0000 (7142.4426)	mem 7984MB
[2024-07-10 11:43:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:47 lr 0.000032	 wd 0.0000	time 0.2078 (0.2594)	loss 1.4598 (1.3559)	grad_norm 0.4649 (nan)	loss_scale 4096.0000 (6707.8573)	mem 7984MB
[2024-07-10 11:43:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:07:15 lr 0.000032	 wd 0.0000	time 0.2453 (0.2559)	loss 1.4416 (1.3637)	grad_norm 0.4797 (nan)	loss_scale 4096.0000 (6381.7828)	mem 7984MB
[2024-07-10 11:44:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:45 lr 0.000032	 wd 0.0000	time 0.2160 (0.2531)	loss 1.0532 (1.3641)	grad_norm 0.4728 (nan)	loss_scale 4096.0000 (6128.0888)	mem 7984MB
[2024-07-10 11:44:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:17 lr 0.000032	 wd 0.0000	time 0.2297 (0.2510)	loss 1.6288 (1.3616)	grad_norm 0.4558 (nan)	loss_scale 4096.0000 (5925.0829)	mem 7984MB
[2024-07-10 11:44:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:52 lr 0.000032	 wd 0.0000	time 0.2005 (0.2516)	loss 1.4766 (1.3656)	grad_norm 0.6920 (nan)	loss_scale 4096.0000 (5758.9537)	mem 7984MB
[2024-07-10 11:45:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:25 lr 0.000032	 wd 0.0000	time 0.2179 (0.2501)	loss 1.5108 (1.3646)	grad_norm 0.5108 (nan)	loss_scale 4096.0000 (5620.4896)	mem 7984MB
[2024-07-10 11:45:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:58 lr 0.000032	 wd 0.0000	time 0.2302 (0.2486)	loss 1.4335 (1.3650)	grad_norm 0.4806 (nan)	loss_scale 4096.0000 (5503.3113)	mem 7984MB
[2024-07-10 11:46:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:32 lr 0.000032	 wd 0.0000	time 0.2702 (0.2473)	loss 1.6016 (1.3649)	grad_norm 0.5574 (nan)	loss_scale 4096.0000 (5402.8608)	mem 7984MB
[2024-07-10 11:46:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:04:08 lr 0.000032	 wd 0.0000	time 0.3606 (0.2480)	loss 1.4256 (1.3656)	grad_norm 0.4516 (nan)	loss_scale 4096.0000 (5315.7948)	mem 7984MB
[2024-07-10 11:46:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:43 lr 0.000032	 wd 0.0000	time 0.2175 (0.2474)	loss 1.4204 (1.3644)	grad_norm 0.4934 (nan)	loss_scale 4096.0000 (5239.6052)	mem 7984MB
[2024-07-10 11:47:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:17 lr 0.000031	 wd 0.0000	time 0.2098 (0.2465)	loss 1.5728 (1.3654)	grad_norm 0.5040 (nan)	loss_scale 4096.0000 (5172.3739)	mem 7984MB
[2024-07-10 11:47:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:52 lr 0.000031	 wd 0.0000	time 0.2452 (0.2457)	loss 1.2757 (1.3662)	grad_norm 0.4826 (nan)	loss_scale 4096.0000 (5112.6086)	mem 7984MB
[2024-07-10 11:48:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:28 lr 0.000031	 wd 0.0000	time 0.2163 (0.2463)	loss 1.4097 (1.3657)	grad_norm 0.4994 (nan)	loss_scale 4096.0000 (5059.1310)	mem 7984MB
[2024-07-10 11:48:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:02:03 lr 0.000031	 wd 0.0000	time 0.2256 (0.2461)	loss 1.4002 (1.3648)	grad_norm 0.4667 (nan)	loss_scale 4096.0000 (5010.9985)	mem 7984MB
[2024-07-10 11:48:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:38 lr 0.000031	 wd 0.0000	time 0.2504 (0.2455)	loss 1.4271 (1.3660)	grad_norm 0.4713 (nan)	loss_scale 4096.0000 (4967.4479)	mem 7984MB
[2024-07-10 11:49:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:13 lr 0.000031	 wd 0.0000	time 0.2351 (0.2449)	loss 1.5626 (1.3674)	grad_norm 0.4579 (nan)	loss_scale 4096.0000 (4927.8546)	mem 7984MB
[2024-07-10 11:49:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:49 lr 0.000031	 wd 0.0000	time 0.2206 (0.2452)	loss 1.4317 (1.3674)	grad_norm 0.4723 (nan)	loss_scale 4096.0000 (4891.7027)	mem 7984MB
[2024-07-10 11:50:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:24 lr 0.000031	 wd 0.0000	time 0.2072 (0.2451)	loss 1.5042 (1.3671)	grad_norm 0.5364 (nan)	loss_scale 4096.0000 (4858.5623)	mem 7984MB
[2024-07-10 11:50:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000031	 wd 0.0000	time 0.1886 (0.2433)	loss 1.1173 (1.3659)	grad_norm 0.4909 (nan)	loss_scale 4096.0000 (4828.0720)	mem 7984MB
[2024-07-10 11:50:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 12 training takes 0:10:12
[2024-07-10 11:50:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 19.106 (19.106)	Loss 0.4163 (0.4163)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 7984MB
[2024-07-10 11:51:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.118 Acc@5 97.246
[2024-07-10 11:51:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-10 11:51:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-10 11:51:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][0/2502]	eta 1 day, 0:25:06 lr 0.000031	 wd 0.0000	time 35.1346 (35.1346)	loss 1.3565 (1.3565)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:52:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:22:58 lr 0.000031	 wd 0.0000	time 0.2336 (0.5740)	loss 1.3782 (1.3528)	grad_norm 0.4854 (0.5195)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:52:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:15:20 lr 0.000031	 wd 0.0000	time 0.2432 (0.3997)	loss 1.6796 (1.3543)	grad_norm 0.4999 (0.5135)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:52:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:12:57 lr 0.000031	 wd 0.0000	time 0.2434 (0.3529)	loss 1.4462 (1.3623)	grad_norm 0.7661 (0.5225)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:53:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:11:25 lr 0.000030	 wd 0.0000	time 0.2126 (0.3260)	loss 1.3357 (1.3612)	grad_norm 0.4781 (0.5170)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:53:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:10:12 lr 0.000030	 wd 0.0000	time 0.2347 (0.3058)	loss 1.5332 (1.3558)	grad_norm 0.5475 (0.5228)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:53:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:09:17 lr 0.000030	 wd 0.0000	time 0.2248 (0.2932)	loss 1.5360 (1.3622)	grad_norm 0.5355 (0.5206)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:54:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:08:35 lr 0.000030	 wd 0.0000	time 0.2651 (0.2859)	loss 1.4302 (1.3576)	grad_norm 0.4918 (0.5178)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:54:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:08:00 lr 0.000030	 wd 0.0000	time 0.2118 (0.2825)	loss 1.5383 (1.3615)	grad_norm 0.4582 (0.5183)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:55:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:07:22 lr 0.000030	 wd 0.0000	time 0.2175 (0.2762)	loss 1.5254 (1.3585)	grad_norm 0.4796 (0.5167)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:55:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:47 lr 0.000030	 wd 0.0000	time 0.2376 (0.2715)	loss 1.6043 (1.3640)	grad_norm 0.4322 (0.5153)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:55:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:06:16 lr 0.000030	 wd 0.0000	time 0.2775 (0.2689)	loss 1.3949 (1.3654)	grad_norm 0.4922 (0.5153)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:56:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:48 lr 0.000030	 wd 0.0000	time 0.2239 (0.2676)	loss 1.5517 (1.3617)	grad_norm 0.9709 (0.5157)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 11:56:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:05:18 lr 0.000030	 wd 0.0000	time 0.2080 (0.2647)	loss 1.4243 (1.3603)	grad_norm 0.4806 (nan)	loss_scale 2048.0000 (4051.9231)	mem 7984MB
[2024-07-10 11:57:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:49 lr 0.000030	 wd 0.0000	time 0.2210 (0.2623)	loss 1.6493 (1.3609)	grad_norm 0.5287 (nan)	loss_scale 2048.0000 (3908.8879)	mem 7984MB
[2024-07-10 11:57:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:04:21 lr 0.000030	 wd 0.0000	time 0.2261 (0.2608)	loss 1.6308 (1.3596)	grad_norm 0.4706 (nan)	loss_scale 2048.0000 (3784.9114)	mem 7984MB
[2024-07-10 11:58:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:55 lr 0.000029	 wd 0.0000	time 0.2514 (0.2607)	loss 1.5706 (1.3593)	grad_norm 0.5016 (nan)	loss_scale 2048.0000 (3676.4222)	mem 7984MB
[2024-07-10 11:58:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:27 lr 0.000029	 wd 0.0000	time 0.2128 (0.2592)	loss 0.8614 (1.3569)	grad_norm 0.4796 (nan)	loss_scale 2048.0000 (3580.6890)	mem 7984MB
[2024-07-10 11:58:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:03:01 lr 0.000029	 wd 0.0000	time 0.2182 (0.2579)	loss 1.4265 (1.3586)	grad_norm 0.4730 (nan)	loss_scale 2048.0000 (3495.5869)	mem 7984MB
[2024-07-10 11:59:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:34 lr 0.000029	 wd 0.0000	time 0.2377 (0.2569)	loss 1.2088 (1.3591)	grad_norm 0.6787 (nan)	loss_scale 2048.0000 (3419.4382)	mem 7984MB
[2024-07-10 11:59:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:02:08 lr 0.000029	 wd 0.0000	time 0.2224 (0.2568)	loss 1.4298 (1.3601)	grad_norm 0.4712 (nan)	loss_scale 2048.0000 (3350.9005)	mem 7984MB
[2024-07-10 11:59:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:42 lr 0.000029	 wd 0.0000	time 0.2237 (0.2556)	loss 1.1094 (1.3598)	grad_norm 0.4850 (nan)	loss_scale 2048.0000 (3288.8872)	mem 7984MB
[2024-07-10 12:00:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:16 lr 0.000029	 wd 0.0000	time 0.1993 (0.2546)	loss 1.5370 (1.3612)	grad_norm 0.4780 (nan)	loss_scale 2048.0000 (3232.5089)	mem 7984MB
[2024-07-10 12:00:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:51 lr 0.000029	 wd 0.0000	time 0.2515 (0.2539)	loss 1.3068 (1.3606)	grad_norm 0.5130 (nan)	loss_scale 2048.0000 (3181.0309)	mem 7984MB
[2024-07-10 12:01:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:25 lr 0.000029	 wd 0.0000	time 0.2183 (0.2538)	loss 1.6865 (1.3618)	grad_norm 0.4576 (nan)	loss_scale 2048.0000 (3133.8409)	mem 7984MB
[2024-07-10 12:01:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000029	 wd 0.0000	time 0.1749 (0.2517)	loss 1.5154 (1.3612)	grad_norm 0.4949 (nan)	loss_scale 2048.0000 (3090.4246)	mem 7984MB
[2024-07-10 12:01:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 13 training takes 0:10:34
[2024-07-10 12:01:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 22.447 (22.447)	Loss 0.4126 (0.4126)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 12:02:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.126 Acc@5 97.272
[2024-07-10 12:02:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-10 12:02:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-10 12:02:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][0/2502]	eta 21:28:53 lr 0.000029	 wd 0.0000	time 30.9085 (30.9085)	loss 1.4843 (1.4843)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:03:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:21:37 lr 0.000029	 wd 0.0000	time 0.1968 (0.5401)	loss 1.5524 (1.3713)	grad_norm 0.4383 (0.4908)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:03:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:14:43 lr 0.000028	 wd 0.0000	time 0.1919 (0.3838)	loss 1.3019 (1.3905)	grad_norm 0.4459 (0.5175)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:03:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:12:07 lr 0.000028	 wd 0.0000	time 0.2560 (0.3306)	loss 1.0172 (1.3784)	grad_norm 0.4838 (0.5218)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:04:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:10:54 lr 0.000028	 wd 0.0000	time 0.2723 (0.3114)	loss 1.2091 (1.3636)	grad_norm 0.4940 (0.5209)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:04:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:09:52 lr 0.000028	 wd 0.0000	time 0.2578 (0.2962)	loss 1.2835 (1.3664)	grad_norm 0.4884 (0.5208)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:05:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:09:02 lr 0.000028	 wd 0.0000	time 0.2064 (0.2850)	loss 1.6574 (1.3718)	grad_norm 0.5546 (0.5175)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:05:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:08:19 lr 0.000028	 wd 0.0000	time 0.2179 (0.2769)	loss 1.4417 (1.3677)	grad_norm 0.5061 (0.5137)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:05:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:45 lr 0.000028	 wd 0.0000	time 0.2471 (0.2736)	loss 1.3740 (1.3639)	grad_norm 0.5170 (0.5122)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:06:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:07:14 lr 0.000028	 wd 0.0000	time 0.2172 (0.2714)	loss 1.4400 (1.3599)	grad_norm 0.5438 (0.5096)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:06:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:06:41 lr 0.000028	 wd 0.0000	time 0.2176 (0.2673)	loss 1.3221 (1.3584)	grad_norm 0.4690 (0.5087)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:07:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:06:09 lr 0.000028	 wd 0.0000	time 0.2237 (0.2637)	loss 1.4882 (1.3560)	grad_norm 0.4411 (0.5097)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:07:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:41 lr 0.000028	 wd 0.0000	time 0.2739 (0.2623)	loss 1.4140 (1.3561)	grad_norm 0.4475 (0.5091)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:07:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:05:14 lr 0.000027	 wd 0.0000	time 0.2252 (0.2619)	loss 1.1848 (1.3563)	grad_norm 0.4769 (0.5089)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:08:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:46 lr 0.000027	 wd 0.0000	time 0.2617 (0.2598)	loss 1.6494 (1.3552)	grad_norm 0.4605 (0.5070)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:08:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:04:18 lr 0.000027	 wd 0.0000	time 0.2330 (0.2578)	loss 1.3744 (1.3561)	grad_norm 0.4416 (0.5060)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:09:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:51 lr 0.000027	 wd 0.0000	time 0.2496 (0.2571)	loss 1.3127 (1.3559)	grad_norm 0.5127 (0.5063)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:09:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:26 lr 0.000027	 wd 0.0000	time 0.2705 (0.2574)	loss 1.1849 (1.3552)	grad_norm 0.5095 (0.5072)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:09:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:59 lr 0.000027	 wd 0.0000	time 0.2192 (0.2561)	loss 1.3054 (1.3551)	grad_norm 0.4764 (0.5087)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:10:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:33 lr 0.000027	 wd 0.0000	time 0.2204 (0.2547)	loss 1.5334 (1.3552)	grad_norm 0.5055 (0.5086)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:10:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:02:07 lr 0.000027	 wd 0.0000	time 0.2666 (0.2543)	loss 1.0696 (1.3571)	grad_norm 0.4650 (0.5083)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:11:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:42 lr 0.000027	 wd 0.0000	time 0.2298 (0.2539)	loss 1.5482 (1.3568)	grad_norm 0.4935 (0.5096)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:11:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:16 lr 0.000027	 wd 0.0000	time 0.2074 (0.2530)	loss 1.2127 (1.3570)	grad_norm 0.4894 (0.5100)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:11:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:50 lr 0.000027	 wd 0.0000	time 0.2296 (0.2520)	loss 1.3806 (1.3578)	grad_norm 0.5223 (0.5099)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:12:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:25 lr 0.000026	 wd 0.0000	time 0.2401 (0.2517)	loss 1.1288 (1.3589)	grad_norm 0.5309 (0.5093)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:12:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1914 (0.2507)	loss 1.2543 (1.3580)	grad_norm 0.4738 (0.5098)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:12:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 14 training takes 0:10:32
[2024-07-10 12:13:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 19.498 (19.498)	Loss 0.4141 (0.4141)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 12:13:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.108 Acc@5 97.260
[2024-07-10 12:13:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-10 12:13:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-10 12:13:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][0/2502]	eta 10:44:46 lr 0.000026	 wd 0.0000	time 15.4624 (15.4624)	loss 1.4578 (1.4578)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:13:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:16:39 lr 0.000026	 wd 0.0000	time 0.2152 (0.4163)	loss 1.0237 (1.3444)	grad_norm 0.4501 (0.4998)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:14:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:12:37 lr 0.000026	 wd 0.0000	time 0.2178 (0.3292)	loss 1.4484 (1.3598)	grad_norm 0.5396 (0.5048)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:14:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:10:48 lr 0.000026	 wd 0.0000	time 0.2109 (0.2943)	loss 1.3982 (1.3469)	grad_norm 0.5115 (0.5078)	loss_scale 4096.0000 (2265.7276)	mem 7984MB
[2024-07-10 12:15:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:09:41 lr 0.000026	 wd 0.0000	time 0.2016 (0.2765)	loss 1.3877 (1.3504)	grad_norm 0.4880 (0.5047)	loss_scale 4096.0000 (2722.1546)	mem 7984MB
[2024-07-10 12:15:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:09:01 lr 0.000026	 wd 0.0000	time 0.2113 (0.2705)	loss 0.8669 (1.3483)	grad_norm 0.4795 (0.5029)	loss_scale 4096.0000 (2996.3752)	mem 7984MB
[2024-07-10 12:15:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:08:22 lr 0.000026	 wd 0.0000	time 0.2150 (0.2643)	loss 0.8471 (1.3518)	grad_norm 0.5274 (0.5034)	loss_scale 4096.0000 (3179.3411)	mem 7984MB
[2024-07-10 12:16:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:47 lr 0.000026	 wd 0.0000	time 0.2289 (0.2594)	loss 1.1000 (1.3543)	grad_norm 0.6137 (0.5047)	loss_scale 4096.0000 (3310.1056)	mem 7984MB
[2024-07-10 12:16:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:07:14 lr 0.000026	 wd 0.0000	time 0.2128 (0.2554)	loss 1.4078 (1.3547)	grad_norm 0.4377 (0.5074)	loss_scale 4096.0000 (3408.2197)	mem 7984MB
[2024-07-10 12:17:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:46 lr 0.000025	 wd 0.0000	time 0.2787 (0.2539)	loss 1.2217 (1.3555)	grad_norm 0.5164 (0.5090)	loss_scale 4096.0000 (3484.5549)	mem 7984MB
[2024-07-10 12:17:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:06:21 lr 0.000025	 wd 0.0000	time 0.2561 (0.2537)	loss 1.4278 (1.3569)	grad_norm 0.4384 (0.5063)	loss_scale 4096.0000 (3545.6384)	mem 7984MB
[2024-07-10 12:17:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:52 lr 0.000025	 wd 0.0000	time 0.2360 (0.2516)	loss 1.2498 (1.3540)	grad_norm 0.4481 (0.5081)	loss_scale 4096.0000 (3595.6258)	mem 7984MB
[2024-07-10 12:18:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:24 lr 0.000025	 wd 0.0000	time 0.2139 (0.2496)	loss 1.3908 (1.3547)	grad_norm 0.4446 (0.5079)	loss_scale 4096.0000 (3637.2889)	mem 7984MB
[2024-07-10 12:18:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:04:59 lr 0.000025	 wd 0.0000	time 0.2758 (0.2489)	loss 1.3609 (1.3530)	grad_norm 0.4606 (0.5076)	loss_scale 4096.0000 (3672.5473)	mem 7984MB
[2024-07-10 12:19:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:34 lr 0.000025	 wd 0.0000	time 0.2172 (0.2490)	loss 1.4482 (1.3532)	grad_norm 0.5740 (0.5080)	loss_scale 4096.0000 (3702.7723)	mem 7984MB
[2024-07-10 12:19:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:04:08 lr 0.000025	 wd 0.0000	time 0.2089 (0.2479)	loss 1.5711 (1.3529)	grad_norm 0.4824 (0.5088)	loss_scale 4096.0000 (3728.9700)	mem 7984MB
[2024-07-10 12:19:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:42 lr 0.000025	 wd 0.0000	time 0.2296 (0.2468)	loss 1.2722 (1.3552)	grad_norm 0.4411 (0.5091)	loss_scale 4096.0000 (3751.8951)	mem 7984MB
[2024-07-10 12:20:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:17 lr 0.000025	 wd 0.0000	time 0.2055 (0.2465)	loss 1.4270 (1.3543)	grad_norm 0.4629 (0.5118)	loss_scale 4096.0000 (3772.1246)	mem 7984MB
[2024-07-10 12:20:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:53 lr 0.000025	 wd 0.0000	time 0.2324 (0.2478)	loss 1.0687 (1.3540)	grad_norm 0.5484 (0.5126)	loss_scale 4096.0000 (3790.1077)	mem 7984MB
[2024-07-10 12:21:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:28 lr 0.000024	 wd 0.0000	time 0.2174 (0.2471)	loss 1.6022 (1.3545)	grad_norm 0.7167 (0.5130)	loss_scale 4096.0000 (3806.1988)	mem 7984MB
[2024-07-10 12:21:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:02:03 lr 0.000024	 wd 0.0000	time 0.2171 (0.2463)	loss 1.8333 (1.3567)	grad_norm 0.5512 (0.5148)	loss_scale 4096.0000 (3820.6817)	mem 7984MB
[2024-07-10 12:21:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:38 lr 0.000024	 wd 0.0000	time 0.2282 (0.2460)	loss 1.5114 (1.3575)	grad_norm 0.5095 (0.5142)	loss_scale 4096.0000 (3833.7858)	mem 7984MB
[2024-07-10 12:22:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:14 lr 0.000024	 wd 0.0000	time 0.2283 (0.2463)	loss 1.0623 (1.3586)	grad_norm 0.4652 (0.5135)	loss_scale 4096.0000 (3845.6992)	mem 7984MB
[2024-07-10 12:22:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:49 lr 0.000024	 wd 0.0000	time 0.2411 (0.2457)	loss 1.5792 (1.3588)	grad_norm 0.4784 (0.5131)	loss_scale 4096.0000 (3856.5771)	mem 7984MB
[2024-07-10 12:23:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:25 lr 0.000024	 wd 0.0000	time 0.2137 (0.2452)	loss 1.0609 (1.3576)	grad_norm 0.6819 (0.5153)	loss_scale 4096.0000 (3866.5489)	mem 7984MB
[2024-07-10 12:23:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1902 (0.2437)	loss 1.2126 (1.3577)	grad_norm 0.5009 (0.5158)	loss_scale 4096.0000 (3875.7233)	mem 7984MB
[2024-07-10 12:23:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 15 training takes 0:10:14
[2024-07-10 12:23:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full/ckpt_epoch_15.pth saving......
[2024-07-10 12:23:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full/ckpt_epoch_15.pth saved !!!
[2024-07-10 12:24:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 34.192 (34.192)	Loss 0.4136 (0.4136)	Acc@1 92.969 (92.969)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 12:24:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.072 Acc@5 97.284
[2024-07-10 12:24:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-10 12:24:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-10 12:24:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][0/2502]	eta 10:51:15 lr 0.000024	 wd 0.0000	time 15.6176 (15.6176)	loss 1.2735 (1.2735)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 12:24:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:15:32 lr 0.000024	 wd 0.0000	time 0.2272 (0.3884)	loss 1.4689 (1.3519)	grad_norm 0.5016 (0.4938)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 12:25:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:13:19 lr 0.000024	 wd 0.0000	time 0.2250 (0.3475)	loss 1.3106 (1.3607)	grad_norm 0.5229 (0.5071)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 12:25:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:11:16 lr 0.000024	 wd 0.0000	time 0.2109 (0.3074)	loss 1.3536 (1.3730)	grad_norm 0.4258 (0.5030)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 12:26:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:10:02 lr 0.000024	 wd 0.0000	time 0.2016 (0.2869)	loss 1.2735 (1.3670)	grad_norm 0.4801 (0.5026)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 12:26:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:09:10 lr 0.000023	 wd 0.0000	time 0.2025 (0.2749)	loss 1.2515 (1.3770)	grad_norm 0.4754 (0.5054)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 12:27:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:37 lr 0.000023	 wd 0.0000	time 0.2009 (0.2722)	loss 1.0398 (1.3693)	grad_norm 0.8336 (0.5125)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 12:27:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:08:01 lr 0.000023	 wd 0.0000	time 0.2179 (0.2670)	loss 1.3195 (1.3709)	grad_norm 0.4906 (0.5171)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 12:27:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:07:26 lr 0.000023	 wd 0.0000	time 0.1913 (0.2623)	loss 1.3916 (1.3654)	grad_norm 0.4464 (0.5168)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 12:28:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:54 lr 0.000023	 wd 0.0000	time 0.2459 (0.2586)	loss 1.5574 (1.3632)	grad_norm 0.4960 (0.5157)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 12:28:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:06:27 lr 0.000023	 wd 0.0000	time 0.2132 (0.2581)	loss 1.5482 (1.3634)	grad_norm 0.4701 (0.5139)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 12:29:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:59 lr 0.000023	 wd 0.0000	time 0.1893 (0.2565)	loss 1.3323 (1.3644)	grad_norm 0.6827 (0.5134)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 12:29:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:31 lr 0.000023	 wd 0.0000	time 0.2275 (0.2544)	loss 1.3984 (1.3657)	grad_norm 0.5389 (0.5119)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 12:29:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:05:03 lr 0.000023	 wd 0.0000	time 0.2614 (0.2524)	loss 1.0956 (1.3662)	grad_norm 0.4435 (0.5115)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 12:30:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:38 lr 0.000023	 wd 0.0000	time 0.2206 (0.2524)	loss 1.2019 (1.3635)	grad_norm 0.5512 (0.5120)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 12:30:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:04:12 lr 0.000022	 wd 0.0000	time 0.1920 (0.2520)	loss 1.4040 (1.3605)	grad_norm 0.4872 (0.5132)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 12:31:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:46 lr 0.000022	 wd 0.0000	time 0.2306 (0.2509)	loss 1.3854 (1.3608)	grad_norm 0.5345 (0.5128)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 12:31:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:20 lr 0.000022	 wd 0.0000	time 0.2208 (0.2497)	loss 1.1082 (1.3589)	grad_norm 0.5609 (0.5123)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 12:31:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:55 lr 0.000022	 wd 0.0000	time 0.2838 (0.2498)	loss 1.2387 (1.3572)	grad_norm 0.5025 (0.5116)	loss_scale 8192.0000 (4173.3259)	mem 7984MB
[2024-07-10 12:32:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:30 lr 0.000022	 wd 0.0000	time 0.2618 (0.2506)	loss 1.1920 (1.3560)	grad_norm 0.4477 (0.5110)	loss_scale 8192.0000 (4384.7238)	mem 7984MB
[2024-07-10 12:32:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:02:05 lr 0.000022	 wd 0.0000	time 0.2448 (0.2498)	loss 1.4668 (1.3563)	grad_norm 0.4717 (0.5107)	loss_scale 8192.0000 (4574.9925)	mem 7984MB
[2024-07-10 12:33:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:40 lr 0.000022	 wd 0.0000	time 0.2344 (0.2488)	loss 1.3491 (1.3559)	grad_norm 0.4952 (0.5109)	loss_scale 8192.0000 (4747.1490)	mem 7984MB
[2024-07-10 12:33:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:15 lr 0.000022	 wd 0.0000	time 0.3299 (0.2489)	loss 1.4688 (1.3565)	grad_norm 0.4442 (0.5117)	loss_scale 8192.0000 (4903.6620)	mem 7984MB
[2024-07-10 12:33:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:50 lr 0.000022	 wd 0.0000	time 0.1924 (0.2490)	loss 1.2189 (1.3565)	grad_norm 0.4842 (0.5119)	loss_scale 8192.0000 (5046.5711)	mem 7984MB
[2024-07-10 12:34:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:25 lr 0.000022	 wd 0.0000	time 0.2014 (0.2483)	loss 1.5366 (1.3567)	grad_norm 0.4817 (0.5115)	loss_scale 8192.0000 (5177.5760)	mem 7984MB
[2024-07-10 12:34:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1843 (0.2467)	loss 1.3628 (1.3567)	grad_norm 0.4501 (0.5111)	loss_scale 8192.0000 (5298.1048)	mem 7984MB
[2024-07-10 12:34:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 16 training takes 0:10:21
[2024-07-10 12:35:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 40.923 (40.923)	Loss 0.4153 (0.4153)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 12:35:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.198 Acc@5 97.266
[2024-07-10 12:35:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-10 12:35:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.20%
[2024-07-10 12:35:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full/ckpt_epoch_best.pth saving......
[2024-07-10 12:35:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full/ckpt_epoch_best.pth saved !!!
[2024-07-10 12:35:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][0/2502]	eta 10:25:30 lr 0.000021	 wd 0.0000	time 15.0000 (15.0000)	loss 1.4543 (1.4543)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:36:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:15:03 lr 0.000021	 wd 0.0000	time 0.2361 (0.3762)	loss 1.5617 (1.3302)	grad_norm 0.5292 (0.5396)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:36:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:12:14 lr 0.000021	 wd 0.0000	time 0.2390 (0.3192)	loss 1.5863 (1.3454)	grad_norm 0.6689 (0.5315)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:37:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:49 lr 0.000021	 wd 0.0000	time 0.2211 (0.2949)	loss 1.3280 (1.3419)	grad_norm 0.5391 (0.5212)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:37:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:09:43 lr 0.000021	 wd 0.0000	time 0.2423 (0.2775)	loss 1.1156 (1.3363)	grad_norm 0.4487 (0.5231)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:37:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:08:54 lr 0.000021	 wd 0.0000	time 0.2106 (0.2668)	loss 1.3592 (1.3363)	grad_norm 0.5287 (0.5191)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:38:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:21 lr 0.000021	 wd 0.0000	time 0.2435 (0.2637)	loss 1.1826 (1.3432)	grad_norm 2.9101 (0.5233)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:38:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:53 lr 0.000021	 wd 0.0000	time 0.2514 (0.2627)	loss 1.3253 (1.3490)	grad_norm 0.4750 (0.5255)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:39:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:07:20 lr 0.000021	 wd 0.0000	time 0.2007 (0.2586)	loss 1.3687 (1.3528)	grad_norm 0.5535 (0.5234)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:39:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:48 lr 0.000021	 wd 0.0000	time 0.2272 (0.2551)	loss 1.5943 (1.3541)	grad_norm 0.4644 (0.5243)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:39:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:21 lr 0.000020	 wd 0.0000	time 0.2325 (0.2541)	loss 1.5279 (1.3527)	grad_norm 1.1616 (0.5253)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:40:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:56 lr 0.000020	 wd 0.0000	time 0.2207 (0.2542)	loss 1.1108 (1.3532)	grad_norm 0.4691 (0.5238)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:40:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:27 lr 0.000020	 wd 0.0000	time 0.2332 (0.2519)	loss 1.5995 (1.3550)	grad_norm 0.4471 (0.5239)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:41:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:05:00 lr 0.000020	 wd 0.0000	time 0.2374 (0.2502)	loss 1.1612 (1.3550)	grad_norm 0.5096 (0.5230)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:41:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:35 lr 0.000020	 wd 0.0000	time 0.2462 (0.2497)	loss 1.4856 (1.3558)	grad_norm 0.4992 (0.5228)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:41:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:04:10 lr 0.000020	 wd 0.0000	time 0.2072 (0.2502)	loss 1.3944 (1.3566)	grad_norm 0.4975 (0.5225)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:42:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:44 lr 0.000020	 wd 0.0000	time 0.2337 (0.2492)	loss 1.5477 (1.3579)	grad_norm 0.4541 (0.5211)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:42:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:19 lr 0.000020	 wd 0.0000	time 0.2167 (0.2483)	loss 1.5782 (1.3598)	grad_norm 0.4531 (0.5213)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:43:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:54 lr 0.000020	 wd 0.0000	time 0.2127 (0.2482)	loss 1.2969 (1.3606)	grad_norm 0.5772 (0.5223)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:43:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:30 lr 0.000020	 wd 0.0000	time 0.2406 (0.2492)	loss 1.1519 (1.3613)	grad_norm 0.6655 (0.5209)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:43:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:02:04 lr 0.000019	 wd 0.0000	time 0.2364 (0.2485)	loss 1.5532 (1.3592)	grad_norm 0.5038 (0.5192)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:44:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:39 lr 0.000019	 wd 0.0000	time 0.2238 (0.2477)	loss 1.4361 (1.3590)	grad_norm 0.4565 (0.5187)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:44:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:14 lr 0.000019	 wd 0.0000	time 0.2507 (0.2475)	loss 1.3377 (1.3601)	grad_norm 0.4568 (0.5186)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:45:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:49 lr 0.000019	 wd 0.0000	time 0.2256 (0.2474)	loss 1.4555 (1.3595)	grad_norm 0.4987 (0.5178)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:45:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:25 lr 0.000019	 wd 0.0000	time 0.2461 (0.2467)	loss 1.4511 (1.3581)	grad_norm 0.4860 (0.5171)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:45:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000019	 wd 0.0000	time 0.1854 (0.2454)	loss 1.4909 (1.3587)	grad_norm 0.4664 (0.5171)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:45:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 17 training takes 0:10:18
[2024-07-10 12:46:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 40.130 (40.130)	Loss 0.4158 (0.4158)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 12:46:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.168 Acc@5 97.240
[2024-07-10 12:46:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-10 12:46:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.20%
[2024-07-10 12:47:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][0/2502]	eta 11:53:44 lr 0.000019	 wd 0.0000	time 17.1161 (17.1161)	loss 1.6044 (1.6044)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 12:47:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:15:42 lr 0.000019	 wd 0.0000	time 0.2091 (0.3925)	loss 1.5491 (1.3985)	grad_norm 0.4641 (nan)	loss_scale 4096.0000 (7056.4752)	mem 7984MB
[2024-07-10 12:47:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:12:17 lr 0.000019	 wd 0.0000	time 0.2931 (0.3204)	loss 1.4742 (1.3789)	grad_norm 0.4696 (nan)	loss_scale 4096.0000 (5583.6020)	mem 7984MB
[2024-07-10 12:48:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:10:59 lr 0.000019	 wd 0.0000	time 0.2117 (0.2993)	loss 1.7166 (1.3784)	grad_norm 0.4646 (nan)	loss_scale 4096.0000 (5089.3821)	mem 7984MB
[2024-07-10 12:48:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:09:50 lr 0.000019	 wd 0.0000	time 0.1864 (0.2811)	loss 1.4402 (1.3715)	grad_norm 0.5314 (nan)	loss_scale 4096.0000 (4841.6559)	mem 7984MB
[2024-07-10 12:49:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:09:00 lr 0.000018	 wd 0.0000	time 0.2424 (0.2700)	loss 1.3128 (1.3611)	grad_norm 0.5484 (nan)	loss_scale 4096.0000 (4692.8224)	mem 7984MB
[2024-07-10 12:49:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:08:22 lr 0.000018	 wd 0.0000	time 0.2356 (0.2641)	loss 1.6233 (1.3618)	grad_norm 0.4373 (nan)	loss_scale 4096.0000 (4593.5175)	mem 7984MB
[2024-07-10 12:49:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:07:54 lr 0.000018	 wd 0.0000	time 0.1953 (0.2632)	loss 1.4389 (1.3623)	grad_norm 0.4516 (nan)	loss_scale 4096.0000 (4522.5449)	mem 7984MB
[2024-07-10 12:50:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:20 lr 0.000018	 wd 0.0000	time 0.2405 (0.2588)	loss 1.0945 (1.3596)	grad_norm 0.5358 (nan)	loss_scale 4096.0000 (4469.2934)	mem 7984MB
[2024-07-10 12:50:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:06:49 lr 0.000018	 wd 0.0000	time 0.2101 (0.2555)	loss 1.1777 (1.3559)	grad_norm 0.7540 (nan)	loss_scale 4096.0000 (4427.8624)	mem 7984MB
[2024-07-10 12:51:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:20 lr 0.000018	 wd 0.0000	time 0.2052 (0.2532)	loss 1.0333 (1.3594)	grad_norm 0.4592 (nan)	loss_scale 4096.0000 (4394.7093)	mem 7984MB
[2024-07-10 12:51:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:55 lr 0.000018	 wd 0.0000	time 0.2068 (0.2538)	loss 1.2461 (1.3590)	grad_norm 0.4376 (nan)	loss_scale 2048.0000 (4229.9292)	mem 7984MB
[2024-07-10 12:51:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:28 lr 0.000018	 wd 0.0000	time 0.2002 (0.2521)	loss 1.6542 (1.3593)	grad_norm 0.4911 (nan)	loss_scale 2048.0000 (4048.2531)	mem 7984MB
[2024-07-10 12:52:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:05:01 lr 0.000018	 wd 0.0000	time 0.2274 (0.2504)	loss 1.4114 (1.3599)	grad_norm 0.5148 (nan)	loss_scale 2048.0000 (3894.5058)	mem 7984MB
[2024-07-10 12:52:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:34 lr 0.000018	 wd 0.0000	time 0.2399 (0.2492)	loss 1.2195 (1.3598)	grad_norm 0.8037 (nan)	loss_scale 2048.0000 (3762.7066)	mem 7984MB
[2024-07-10 12:53:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:04:10 lr 0.000017	 wd 0.0000	time 0.1896 (0.2502)	loss 1.5977 (1.3589)	grad_norm 0.4568 (nan)	loss_scale 2048.0000 (3648.4690)	mem 7984MB
[2024-07-10 12:53:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:44 lr 0.000017	 wd 0.0000	time 0.1947 (0.2492)	loss 1.4809 (1.3583)	grad_norm 0.4900 (nan)	loss_scale 2048.0000 (3548.5022)	mem 7984MB
[2024-07-10 12:53:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:19 lr 0.000017	 wd 0.0000	time 0.2226 (0.2482)	loss 1.4763 (1.3586)	grad_norm 0.6847 (nan)	loss_scale 2048.0000 (3460.2892)	mem 7984MB
[2024-07-10 12:54:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:53 lr 0.000017	 wd 0.0000	time 0.2245 (0.2475)	loss 1.3185 (1.3594)	grad_norm 0.4530 (nan)	loss_scale 2048.0000 (3381.8723)	mem 7984MB
[2024-07-10 12:54:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:29 lr 0.000017	 wd 0.0000	time 0.1911 (0.2479)	loss 1.4729 (1.3586)	grad_norm 0.4932 (nan)	loss_scale 2048.0000 (3311.7054)	mem 7984MB
[2024-07-10 12:55:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:02:04 lr 0.000017	 wd 0.0000	time 0.2130 (0.2475)	loss 1.3773 (1.3607)	grad_norm 0.4717 (nan)	loss_scale 2048.0000 (3248.5517)	mem 7984MB
[2024-07-10 12:55:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:39 lr 0.000017	 wd 0.0000	time 0.2423 (0.2469)	loss 1.4455 (1.3601)	grad_norm 0.4490 (nan)	loss_scale 2048.0000 (3191.4098)	mem 7984MB
[2024-07-10 12:55:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:14 lr 0.000017	 wd 0.0000	time 0.2361 (0.2463)	loss 1.3446 (1.3601)	grad_norm 0.4455 (nan)	loss_scale 2048.0000 (3139.4602)	mem 7984MB
[2024-07-10 12:56:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:49 lr 0.000017	 wd 0.0000	time 0.2520 (0.2466)	loss 1.4962 (1.3604)	grad_norm 0.5076 (nan)	loss_scale 2048.0000 (3092.0261)	mem 7984MB
[2024-07-10 12:56:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:25 lr 0.000017	 wd 0.0000	time 0.2016 (0.2462)	loss 1.5025 (1.3618)	grad_norm 0.4776 (nan)	loss_scale 2048.0000 (3048.5431)	mem 7984MB
[2024-07-10 12:56:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1659 (0.2445)	loss 1.4918 (1.3613)	grad_norm 0.4912 (nan)	loss_scale 2048.0000 (3008.5374)	mem 7984MB
[2024-07-10 12:57:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 18 training takes 0:10:15
[2024-07-10 12:57:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 18.833 (18.833)	Loss 0.4153 (0.4153)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 12:57:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.174 Acc@5 97.262
[2024-07-10 12:57:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-10 12:57:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.20%
[2024-07-10 12:58:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][0/2502]	eta 22:54:10 lr 0.000016	 wd 0.0000	time 32.9540 (32.9540)	loss 1.4336 (1.4336)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:58:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:22:09 lr 0.000016	 wd 0.0000	time 0.2148 (0.5534)	loss 1.0930 (1.3734)	grad_norm 0.6144 (0.5422)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:58:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:14:54 lr 0.000016	 wd 0.0000	time 0.2294 (0.3887)	loss 1.4304 (1.3668)	grad_norm 0.5019 (0.5255)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:59:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:12:38 lr 0.000016	 wd 0.0000	time 0.2589 (0.3444)	loss 1.3104 (1.3791)	grad_norm 0.5459 (0.5234)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 12:59:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:11:07 lr 0.000016	 wd 0.0000	time 0.2079 (0.3175)	loss 1.5089 (1.3784)	grad_norm 0.7265 (0.5193)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:00:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:09:57 lr 0.000016	 wd 0.0000	time 0.2311 (0.2986)	loss 1.5084 (1.3735)	grad_norm 0.7509 (0.5213)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:00:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:09:05 lr 0.000016	 wd 0.0000	time 0.2102 (0.2867)	loss 1.4723 (1.3685)	grad_norm 0.4650 (0.5174)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:00:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:08:26 lr 0.000016	 wd 0.0000	time 0.1993 (0.2809)	loss 1.6424 (1.3705)	grad_norm 0.4909 (0.5150)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:01:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:07:52 lr 0.000016	 wd 0.0000	time 0.2431 (0.2775)	loss 1.3565 (1.3693)	grad_norm 0.4769 (0.5129)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:01:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:07:15 lr 0.000016	 wd 0.0000	time 0.2532 (0.2720)	loss 1.2304 (1.3689)	grad_norm 0.4301 (0.5115)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:02:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:41 lr 0.000016	 wd 0.0000	time 0.1980 (0.2676)	loss 1.5804 (1.3696)	grad_norm 0.5766 (0.5115)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:02:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:06:12 lr 0.000015	 wd 0.0000	time 0.2386 (0.2656)	loss 0.9202 (1.3682)	grad_norm 0.4949 (0.5107)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:02:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:44 lr 0.000015	 wd 0.0000	time 0.2187 (0.2643)	loss 1.1176 (1.3665)	grad_norm 0.5386 (0.5116)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:03:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:05:14 lr 0.000015	 wd 0.0000	time 0.2431 (0.2620)	loss 1.5658 (1.3669)	grad_norm 0.5054 (0.5122)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:03:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:46 lr 0.000015	 wd 0.0000	time 0.2319 (0.2597)	loss 1.4452 (1.3677)	grad_norm 0.5073 (0.5122)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:04:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:04:19 lr 0.000015	 wd 0.0000	time 0.2532 (0.2585)	loss 1.2156 (1.3675)	grad_norm 0.4834 (0.5124)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:04:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:53 lr 0.000015	 wd 0.0000	time 0.2022 (0.2585)	loss 1.2992 (1.3677)	grad_norm 0.4939 (0.5131)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:04:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:26 lr 0.000015	 wd 0.0000	time 0.2280 (0.2570)	loss 1.4030 (1.3684)	grad_norm 0.9689 (0.5165)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:05:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:59 lr 0.000015	 wd 0.0000	time 0.2232 (0.2557)	loss 1.3347 (1.3679)	grad_norm 0.4809 (0.5169)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:05:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:33 lr 0.000015	 wd 0.0000	time 0.2306 (0.2550)	loss 1.4140 (1.3682)	grad_norm 0.4436 (0.5184)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:06:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:02:08 lr 0.000015	 wd 0.0000	time 0.2240 (0.2556)	loss 1.0684 (1.3678)	grad_norm 0.4899 (0.5175)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:06:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:42 lr 0.000014	 wd 0.0000	time 0.2301 (0.2546)	loss 1.1808 (1.3667)	grad_norm 0.5046 (0.5172)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:06:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:16 lr 0.000014	 wd 0.0000	time 0.2072 (0.2536)	loss 1.4894 (1.3645)	grad_norm 0.6690 (0.5176)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:07:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:51 lr 0.000014	 wd 0.0000	time 0.2323 (0.2531)	loss 1.4035 (1.3642)	grad_norm 0.4924 (0.5175)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:07:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:25 lr 0.000014	 wd 0.0000	time 0.2482 (0.2533)	loss 1.5415 (1.3656)	grad_norm 0.4834 (0.5182)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:08:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1665 (0.2513)	loss 1.2275 (1.3655)	grad_norm 0.5893 (0.5177)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:08:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 19 training takes 0:10:32
[2024-07-10 13:08:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 21.083 (21.083)	Loss 0.4141 (0.4141)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 13:08:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.156 Acc@5 97.288
[2024-07-10 13:08:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-10 13:08:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.20%
[2024-07-10 13:09:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][0/2502]	eta 22:24:28 lr 0.000014	 wd 0.0000	time 32.2415 (32.2415)	loss 0.9954 (0.9954)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-10 13:09:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:22:32 lr 0.000014	 wd 0.0000	time 0.2109 (0.5633)	loss 1.5719 (1.3610)	grad_norm 0.5287 (0.5468)	loss_scale 4096.0000 (3629.6238)	mem 7984MB
[2024-07-10 13:10:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:15:08 lr 0.000014	 wd 0.0000	time 0.2076 (0.3946)	loss 1.4301 (1.3626)	grad_norm 0.4755 (0.5448)	loss_scale 4096.0000 (3861.6517)	mem 7984MB
[2024-07-10 13:10:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:12:28 lr 0.000014	 wd 0.0000	time 0.2084 (0.3398)	loss 1.4658 (1.3587)	grad_norm 0.5236 (0.5359)	loss_scale 4096.0000 (3939.5083)	mem 7984MB
[2024-07-10 13:10:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:11:10 lr 0.000014	 wd 0.0000	time 0.2206 (0.3188)	loss 1.4026 (1.3678)	grad_norm 0.4614 (0.5407)	loss_scale 4096.0000 (3978.5337)	mem 7984MB
[2024-07-10 13:11:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:10:00 lr 0.000014	 wd 0.0000	time 0.2107 (0.3000)	loss 1.5373 (1.3701)	grad_norm 0.4739 (0.5433)	loss_scale 4096.0000 (4001.9800)	mem 7984MB
[2024-07-10 13:11:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:09:08 lr 0.000014	 wd 0.0000	time 0.2020 (0.2883)	loss 1.3319 (1.3666)	grad_norm 0.4792 (0.5354)	loss_scale 4096.0000 (4017.6240)	mem 7984MB
[2024-07-10 13:11:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:08:24 lr 0.000013	 wd 0.0000	time 0.2333 (0.2801)	loss 1.4769 (1.3689)	grad_norm 0.4521 (0.5311)	loss_scale 4096.0000 (4028.8046)	mem 7984MB
[2024-07-10 13:12:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:07:53 lr 0.000013	 wd 0.0000	time 0.2103 (0.2785)	loss 1.2670 (1.3660)	grad_norm 0.4393 (0.5303)	loss_scale 4096.0000 (4037.1935)	mem 7984MB
[2024-07-10 13:12:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:07:18 lr 0.000013	 wd 0.0000	time 0.2133 (0.2735)	loss 1.5947 (1.3687)	grad_norm 0.4447 (0.5328)	loss_scale 4096.0000 (4043.7203)	mem 7984MB
[2024-07-10 13:13:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:44 lr 0.000013	 wd 0.0000	time 0.2048 (0.2695)	loss 1.2903 (1.3678)	grad_norm 0.4459 (0.5297)	loss_scale 4096.0000 (4048.9431)	mem 7984MB
[2024-07-10 13:13:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:06:12 lr 0.000013	 wd 0.0000	time 0.2159 (0.2657)	loss 1.3490 (1.3654)	grad_norm 0.4712 (0.5270)	loss_scale 4096.0000 (4053.2171)	mem 7984MB
[2024-07-10 13:14:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:45 lr 0.000013	 wd 0.0000	time 0.1826 (0.2656)	loss 1.4091 (1.3624)	grad_norm 0.4392 (0.5252)	loss_scale 4096.0000 (4056.7794)	mem 7984MB
[2024-07-10 13:14:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:05:16 lr 0.000013	 wd 0.0000	time 0.2177 (0.2635)	loss 1.3040 (1.3610)	grad_norm 0.5097 (0.5238)	loss_scale 4096.0000 (4059.7940)	mem 7984MB
[2024-07-10 13:14:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:47 lr 0.000013	 wd 0.0000	time 0.2217 (0.2611)	loss 1.3978 (1.3628)	grad_norm 0.5737 (0.5244)	loss_scale 4096.0000 (4062.3783)	mem 7984MB
[2024-07-10 13:15:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:04:19 lr 0.000013	 wd 0.0000	time 0.2396 (0.2590)	loss 1.4377 (1.3633)	grad_norm 0.5026 (0.5240)	loss_scale 4096.0000 (4064.6183)	mem 7984MB
[2024-07-10 13:15:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:53 lr 0.000013	 wd 0.0000	time 0.3226 (0.2585)	loss 1.6916 (1.3636)	grad_norm 0.4996 (0.5230)	loss_scale 4096.0000 (4066.5784)	mem 7984MB
[2024-07-10 13:16:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:27 lr 0.000012	 wd 0.0000	time 0.2017 (0.2584)	loss 1.5191 (1.3629)	grad_norm 0.4720 (0.5231)	loss_scale 4096.0000 (4068.3081)	mem 7984MB
[2024-07-10 13:16:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:03:00 lr 0.000012	 wd 0.0000	time 0.2219 (0.2571)	loss 1.3038 (1.3621)	grad_norm 0.4649 (0.5250)	loss_scale 4096.0000 (4069.8456)	mem 7984MB
[2024-07-10 13:16:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:34 lr 0.000012	 wd 0.0000	time 0.2018 (0.2558)	loss 1.5259 (1.3641)	grad_norm 0.4373 (0.5262)	loss_scale 4096.0000 (4071.2215)	mem 7984MB
[2024-07-10 13:17:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:02:08 lr 0.000012	 wd 0.0000	time 0.2216 (0.2553)	loss 1.5010 (1.3637)	grad_norm 0.4662 (0.5252)	loss_scale 4096.0000 (4072.4598)	mem 7984MB
[2024-07-10 13:17:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:42 lr 0.000012	 wd 0.0000	time 0.2225 (0.2551)	loss 1.3052 (1.3643)	grad_norm 0.4643 (0.5250)	loss_scale 4096.0000 (4073.5802)	mem 7984MB
[2024-07-10 13:18:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:16 lr 0.000012	 wd 0.0000	time 0.2493 (0.2542)	loss 1.2469 (1.3658)	grad_norm 0.5043 (0.5265)	loss_scale 4096.0000 (4074.5988)	mem 7984MB
[2024-07-10 13:18:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:51 lr 0.000012	 wd 0.0000	time 0.2345 (0.2533)	loss 1.3988 (1.3658)	grad_norm 0.4850 (0.5257)	loss_scale 4096.0000 (4075.5289)	mem 7984MB
[2024-07-10 13:18:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:25 lr 0.000012	 wd 0.0000	time 0.2349 (0.2531)	loss 1.3572 (1.3661)	grad_norm 0.5954 (0.5255)	loss_scale 4096.0000 (4076.3815)	mem 7984MB
[2024-07-10 13:19:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000012	 wd 0.0000	time 0.1699 (0.2514)	loss 1.6160 (1.3669)	grad_norm 0.4725 (0.5247)	loss_scale 4096.0000 (4077.1659)	mem 7984MB
[2024-07-10 13:19:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 20 training takes 0:10:34
[2024-07-10 13:19:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 21.156 (21.156)	Loss 0.4155 (0.4155)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 13:19:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.148 Acc@5 97.244
[2024-07-10 13:19:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-10 13:19:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.20%
[2024-07-10 13:20:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][0/2502]	eta 14:23:47 lr 0.000012	 wd 0.0000	time 20.7145 (20.7145)	loss 1.5561 (1.5561)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:20:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:18:25 lr 0.000012	 wd 0.0000	time 0.2188 (0.4600)	loss 1.4589 (1.3856)	grad_norm 0.4749 (0.4941)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:21:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:13:13 lr 0.000012	 wd 0.0000	time 0.1993 (0.3448)	loss 0.8933 (1.3669)	grad_norm 0.5221 (0.5146)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:21:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:11:12 lr 0.000012	 wd 0.0000	time 0.2115 (0.3053)	loss 1.3926 (1.3599)	grad_norm 0.5059 (0.5133)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:21:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:10:02 lr 0.000011	 wd 0.0000	time 0.2447 (0.2868)	loss 1.4386 (1.3611)	grad_norm 0.4793 (0.5197)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:22:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:09:30 lr 0.000011	 wd 0.0000	time 0.2340 (0.2849)	loss 1.3535 (1.3605)	grad_norm 0.4878 (0.5156)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:22:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:43 lr 0.000011	 wd 0.0000	time 0.1834 (0.2752)	loss 1.2000 (1.3611)	grad_norm 0.4543 (0.5207)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:23:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:08:04 lr 0.000011	 wd 0.0000	time 0.2219 (0.2690)	loss 1.2839 (1.3556)	grad_norm 0.5024 (0.5210)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:23:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:29 lr 0.000011	 wd 0.0000	time 0.2590 (0.2644)	loss 1.2249 (1.3552)	grad_norm 0.4940 (0.5212)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:23:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:07:02 lr 0.000011	 wd 0.0000	time 0.2499 (0.2639)	loss 1.5372 (1.3559)	grad_norm 0.7007 (0.5194)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:24:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:32 lr 0.000011	 wd 0.0000	time 0.2178 (0.2613)	loss 1.0505 (1.3549)	grad_norm 0.4478 (0.5172)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:24:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:06:02 lr 0.000011	 wd 0.0000	time 0.2330 (0.2586)	loss 1.4532 (1.3550)	grad_norm 0.4604 (0.5162)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:25:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:34 lr 0.000011	 wd 0.0000	time 0.2438 (0.2566)	loss 1.3230 (1.3561)	grad_norm 0.4681 (0.5176)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:25:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:05:09 lr 0.000011	 wd 0.0000	time 0.2323 (0.2575)	loss 1.5119 (1.3562)	grad_norm 0.4613 (0.5184)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:25:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:41 lr 0.000011	 wd 0.0000	time 0.2223 (0.2558)	loss 1.4326 (1.3567)	grad_norm 0.5261 (0.5195)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:26:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:04:14 lr 0.000010	 wd 0.0000	time 0.1972 (0.2541)	loss 1.6446 (1.3563)	grad_norm 0.4861 (0.5185)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:26:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:47 lr 0.000010	 wd 0.0000	time 0.2288 (0.2528)	loss 1.2136 (1.3557)	grad_norm 0.5300 (0.5194)	loss_scale 8192.0000 (4300.6721)	mem 7984MB
[2024-07-10 13:27:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:22 lr 0.000010	 wd 0.0000	time 0.3054 (0.2531)	loss 1.4736 (1.3559)	grad_norm 0.5089 (0.5195)	loss_scale 8192.0000 (4529.4392)	mem 7984MB
[2024-07-10 13:27:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:57 lr 0.000010	 wd 0.0000	time 0.2193 (0.2525)	loss 1.0227 (1.3563)	grad_norm 0.6094 (0.5198)	loss_scale 8192.0000 (4732.8018)	mem 7984MB
[2024-07-10 13:27:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:31 lr 0.000010	 wd 0.0000	time 0.2015 (0.2516)	loss 1.0000 (1.3550)	grad_norm 0.7784 (0.5201)	loss_scale 8192.0000 (4914.7691)	mem 7984MB
[2024-07-10 13:28:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:02:05 lr 0.000010	 wd 0.0000	time 0.2436 (0.2507)	loss 1.3918 (1.3545)	grad_norm 0.4739 (0.5194)	loss_scale 8192.0000 (5078.5487)	mem 7984MB
[2024-07-10 13:28:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:40 lr 0.000010	 wd 0.0000	time 0.2457 (0.2509)	loss 1.1897 (1.3548)	grad_norm 0.4956 (0.5191)	loss_scale 8192.0000 (5226.7377)	mem 7984MB
[2024-07-10 13:29:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:15 lr 0.000010	 wd 0.0000	time 0.2019 (0.2503)	loss 1.5616 (1.3528)	grad_norm 0.4945 (0.5190)	loss_scale 8192.0000 (5361.4612)	mem 7984MB
[2024-07-10 13:29:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:50 lr 0.000010	 wd 0.0000	time 0.2003 (0.2496)	loss 1.5694 (1.3525)	grad_norm 0.4865 (0.5188)	loss_scale 8192.0000 (5484.4746)	mem 7984MB
[2024-07-10 13:29:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:25 lr 0.000010	 wd 0.0000	time 0.2137 (0.2489)	loss 1.3770 (1.3539)	grad_norm 0.4727 (0.5193)	loss_scale 8192.0000 (5597.2411)	mem 7984MB
[2024-07-10 13:30:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.2148 (0.2476)	loss 1.3182 (1.3536)	grad_norm 0.5777 (0.5185)	loss_scale 8192.0000 (5700.9900)	mem 7984MB
[2024-07-10 13:30:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 21 training takes 0:10:30
[2024-07-10 13:30:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 27.941 (27.941)	Loss 0.4138 (0.4138)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 13:31:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.176 Acc@5 97.244
[2024-07-10 13:31:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-10 13:31:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.20%
[2024-07-10 13:31:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][0/2502]	eta 11:09:54 lr 0.000010	 wd 0.0000	time 16.0648 (16.0648)	loss 1.3092 (1.3092)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:31:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:16:31 lr 0.000010	 wd 0.0000	time 0.2290 (0.4126)	loss 1.2641 (1.3641)	grad_norm 0.4372 (0.5335)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:32:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:12:28 lr 0.000009	 wd 0.0000	time 0.2216 (0.3253)	loss 1.1870 (1.3607)	grad_norm 0.4294 (0.5129)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:32:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:10:43 lr 0.000009	 wd 0.0000	time 0.2224 (0.2921)	loss 1.5137 (1.3649)	grad_norm 0.5157 (0.5089)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:32:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:09:38 lr 0.000009	 wd 0.0000	time 0.1907 (0.2754)	loss 1.4306 (1.3687)	grad_norm 0.5527 (0.5070)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:33:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:08:59 lr 0.000009	 wd 0.0000	time 0.2431 (0.2696)	loss 0.8967 (1.3680)	grad_norm 0.4868 (0.5090)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:33:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:26 lr 0.000009	 wd 0.0000	time 0.2100 (0.2664)	loss 1.3668 (1.3711)	grad_norm 0.6216 (0.5161)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:34:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:50 lr 0.000009	 wd 0.0000	time 0.2500 (0.2612)	loss 0.8984 (1.3665)	grad_norm 0.4736 (0.5149)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:34:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:07:17 lr 0.000009	 wd 0.0000	time 0.2183 (0.2573)	loss 1.3726 (1.3625)	grad_norm 0.4877 (0.5144)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:34:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:49 lr 0.000009	 wd 0.0000	time 0.2225 (0.2558)	loss 1.3456 (1.3616)	grad_norm 0.4929 (0.5139)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:35:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:24 lr 0.000009	 wd 0.0000	time 0.2254 (0.2561)	loss 1.5549 (1.3638)	grad_norm 0.5516 (0.5178)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:35:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:55 lr 0.000009	 wd 0.0000	time 0.1948 (0.2536)	loss 1.4074 (1.3613)	grad_norm 0.5496 (0.5166)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:36:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:27 lr 0.000009	 wd 0.0000	time 0.2421 (0.2518)	loss 1.3424 (1.3601)	grad_norm 0.4553 (0.5188)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:36:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:05:01 lr 0.000009	 wd 0.0000	time 0.2641 (0.2512)	loss 0.9304 (1.3607)	grad_norm 0.4639 (0.5204)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:36:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:37 lr 0.000008	 wd 0.0000	time 0.2762 (0.2516)	loss 1.5699 (1.3627)	grad_norm 0.4733 (0.5201)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:37:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:04:10 lr 0.000008	 wd 0.0000	time 0.2123 (0.2504)	loss 1.3201 (1.3634)	grad_norm 0.5019 (0.5197)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:37:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:44 lr 0.000008	 wd 0.0000	time 0.2415 (0.2492)	loss 1.5450 (1.3637)	grad_norm 0.5464 (0.5194)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:38:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:19 lr 0.000008	 wd 0.0000	time 0.2411 (0.2488)	loss 1.3138 (1.3634)	grad_norm 0.9722 (0.5191)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:38:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:55 lr 0.000008	 wd 0.0000	time 0.2559 (0.2497)	loss 1.5878 (1.3627)	grad_norm 0.5101 (0.5193)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:38:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:29 lr 0.000008	 wd 0.0000	time 0.2137 (0.2488)	loss 1.5418 (1.3622)	grad_norm 0.5299 (0.5184)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 13:39:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:02:04 lr 0.000008	 wd 0.0000	time 0.2442 (0.2480)	loss 1.5104 (1.3613)	grad_norm 0.4328 (nan)	loss_scale 4096.0000 (8146.9665)	mem 7984MB
[2024-07-10 13:39:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:39 lr 0.000008	 wd 0.0000	time 0.2407 (0.2477)	loss 1.4339 (1.3618)	grad_norm 0.4699 (nan)	loss_scale 4096.0000 (7954.1552)	mem 7984MB
[2024-07-10 13:40:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:14 lr 0.000008	 wd 0.0000	time 0.2209 (0.2481)	loss 1.4389 (1.3600)	grad_norm 0.5582 (nan)	loss_scale 4096.0000 (7778.8642)	mem 7984MB
[2024-07-10 13:40:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:50 lr 0.000008	 wd 0.0000	time 0.2215 (0.2477)	loss 1.4993 (1.3601)	grad_norm 0.4934 (nan)	loss_scale 4096.0000 (7618.8092)	mem 7984MB
[2024-07-10 13:40:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:25 lr 0.000008	 wd 0.0000	time 0.2356 (0.2471)	loss 1.2070 (1.3594)	grad_norm 0.4677 (nan)	loss_scale 4096.0000 (7472.0866)	mem 7984MB
[2024-07-10 13:41:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1845 (0.2452)	loss 0.9894 (1.3585)	grad_norm 0.5371 (nan)	loss_scale 4096.0000 (7337.0972)	mem 7984MB
[2024-07-10 13:41:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 22 training takes 0:10:19
[2024-07-10 13:42:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 36.365 (36.365)	Loss 0.4146 (0.4146)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 13:42:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.174 Acc@5 97.264
[2024-07-10 13:42:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-10 13:42:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.20%
[2024-07-10 13:42:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][0/2502]	eta 11:33:16 lr 0.000008	 wd 0.0000	time 16.6252 (16.6252)	loss 1.1617 (1.1617)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:42:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:16:05 lr 0.000008	 wd 0.0000	time 0.2119 (0.4020)	loss 1.5697 (1.3963)	grad_norm 0.4664 (0.5057)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:43:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:12:45 lr 0.000007	 wd 0.0000	time 0.2511 (0.3325)	loss 1.5463 (1.3750)	grad_norm 0.8077 (0.5119)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:43:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:10:54 lr 0.000007	 wd 0.0000	time 0.2289 (0.2970)	loss 1.5104 (1.3683)	grad_norm 0.4774 (0.5088)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:44:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:09:47 lr 0.000007	 wd 0.0000	time 0.2085 (0.2797)	loss 1.5328 (1.3599)	grad_norm 0.5481 (0.5135)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:44:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:09:00 lr 0.000007	 wd 0.0000	time 0.2279 (0.2700)	loss 1.6878 (1.3647)	grad_norm 0.5572 (0.5126)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:44:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:08:32 lr 0.000007	 wd 0.0000	time 0.2390 (0.2697)	loss 1.1339 (1.3644)	grad_norm 0.4475 (0.5143)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:45:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:56 lr 0.000007	 wd 0.0000	time 0.2410 (0.2643)	loss 1.4183 (1.3617)	grad_norm 0.4852 (0.5128)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:45:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:07:22 lr 0.000007	 wd 0.0000	time 0.2386 (0.2601)	loss 1.6902 (1.3605)	grad_norm 0.5574 (0.5137)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:46:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:06:52 lr 0.000007	 wd 0.0000	time 0.2630 (0.2575)	loss 1.7061 (1.3571)	grad_norm 0.5781 (0.5143)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:46:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:28 lr 0.000007	 wd 0.0000	time 0.2299 (0.2584)	loss 1.1473 (1.3551)	grad_norm 0.4844 (0.5125)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:46:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:58 lr 0.000007	 wd 0.0000	time 0.2253 (0.2559)	loss 0.8795 (1.3508)	grad_norm 0.4727 (0.5132)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:47:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:30 lr 0.000007	 wd 0.0000	time 0.2448 (0.2538)	loss 1.5638 (1.3526)	grad_norm 0.4648 (0.5122)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:47:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:05:03 lr 0.000007	 wd 0.0000	time 0.2140 (0.2521)	loss 1.4477 (1.3540)	grad_norm 0.6469 (0.5134)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:48:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:38 lr 0.000007	 wd 0.0000	time 0.2228 (0.2525)	loss 1.5890 (1.3539)	grad_norm 0.5456 (0.5134)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:48:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:04:11 lr 0.000006	 wd 0.0000	time 0.2103 (0.2515)	loss 1.2743 (1.3562)	grad_norm 0.5180 (0.5129)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:48:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:45 lr 0.000006	 wd 0.0000	time 0.2541 (0.2502)	loss 1.1690 (1.3555)	grad_norm 0.4589 (0.5145)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:49:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:19 lr 0.000006	 wd 0.0000	time 0.2336 (0.2493)	loss 1.3109 (1.3558)	grad_norm 0.5049 (0.5155)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:49:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:55 lr 0.000006	 wd 0.0000	time 0.3254 (0.2501)	loss 1.4333 (1.3552)	grad_norm 0.5217 (0.5152)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:50:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:30 lr 0.000006	 wd 0.0000	time 0.2141 (0.2495)	loss 1.2361 (1.3579)	grad_norm 0.4652 (0.5140)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:50:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:02:04 lr 0.000006	 wd 0.0000	time 0.2316 (0.2486)	loss 1.4534 (1.3566)	grad_norm 0.6767 (0.5136)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:50:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:39 lr 0.000006	 wd 0.0000	time 0.2180 (0.2480)	loss 1.7030 (1.3571)	grad_norm 0.5025 (0.5141)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:51:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:14 lr 0.000006	 wd 0.0000	time 0.2606 (0.2483)	loss 1.4687 (1.3549)	grad_norm 0.5187 (0.5144)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:51:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:50 lr 0.000006	 wd 0.0000	time 0.2422 (0.2479)	loss 1.5889 (1.3551)	grad_norm 0.4992 (0.5136)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:52:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:25 lr 0.000006	 wd 0.0000	time 0.2431 (0.2472)	loss 1.5457 (1.3556)	grad_norm 0.7698 (0.5134)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:52:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000006	 wd 0.0000	time 0.1754 (0.2454)	loss 1.4361 (1.3563)	grad_norm 0.5132 (0.5156)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:52:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 23 training takes 0:10:20
[2024-07-10 13:53:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 34.277 (34.277)	Loss 0.4141 (0.4141)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 13:53:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.152 Acc@5 97.248
[2024-07-10 13:53:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-10 13:53:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.20%
[2024-07-10 13:53:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][0/2502]	eta 11:28:23 lr 0.000006	 wd 0.0000	time 16.5082 (16.5082)	loss 1.5906 (1.5906)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:54:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:15:35 lr 0.000006	 wd 0.0000	time 0.2482 (0.3893)	loss 1.1524 (1.3952)	grad_norm 0.4701 (0.5350)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:54:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:12:46 lr 0.000006	 wd 0.0000	time 0.2444 (0.3328)	loss 1.4099 (1.3771)	grad_norm 0.6263 (0.5252)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:54:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:10:56 lr 0.000006	 wd 0.0000	time 0.2166 (0.2980)	loss 1.6213 (1.3705)	grad_norm 0.5435 (0.5204)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:55:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:09:49 lr 0.000005	 wd 0.0000	time 0.2113 (0.2803)	loss 1.4074 (1.3670)	grad_norm 0.4858 (0.5241)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:55:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:08:57 lr 0.000005	 wd 0.0000	time 0.2409 (0.2687)	loss 1.6628 (1.3683)	grad_norm 0.4936 (0.5263)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:56:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:08:25 lr 0.000005	 wd 0.0000	time 0.2722 (0.2660)	loss 1.3938 (1.3654)	grad_norm 0.4857 (0.5248)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:56:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:07:53 lr 0.000005	 wd 0.0000	time 0.2118 (0.2630)	loss 1.3451 (1.3664)	grad_norm 0.5167 (0.5214)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:56:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:07:20 lr 0.000005	 wd 0.0000	time 0.2305 (0.2590)	loss 1.4114 (1.3674)	grad_norm 0.5903 (0.5191)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:57:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:06:49 lr 0.000005	 wd 0.0000	time 0.2110 (0.2556)	loss 1.5551 (1.3644)	grad_norm 0.5011 (0.5184)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 13:57:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:23 lr 0.000005	 wd 0.0000	time 0.2045 (0.2553)	loss 1.2223 (1.3648)	grad_norm 0.4683 (0.5174)	loss_scale 8192.0000 (4202.3896)	mem 7984MB
[2024-07-10 13:58:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:05:57 lr 0.000005	 wd 0.0000	time 0.1889 (0.2551)	loss 1.4981 (1.3637)	grad_norm 0.4593 (0.5170)	loss_scale 8192.0000 (4564.7520)	mem 7984MB
[2024-07-10 13:58:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:29 lr 0.000005	 wd 0.0000	time 0.2227 (0.2533)	loss 1.2533 (1.3619)	grad_norm 0.4732 (0.5166)	loss_scale 8192.0000 (4866.7710)	mem 7984MB
[2024-07-10 13:58:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:05:01 lr 0.000005	 wd 0.0000	time 0.2081 (0.2512)	loss 1.3928 (1.3612)	grad_norm 0.5498 (0.5170)	loss_scale 8192.0000 (5122.3613)	mem 7984MB
[2024-07-10 13:59:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:36 lr 0.000005	 wd 0.0000	time 0.2425 (0.2513)	loss 1.3468 (1.3596)	grad_norm 0.5427 (0.5163)	loss_scale 8192.0000 (5341.4647)	mem 7984MB
[2024-07-10 13:59:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:11 lr 0.000005	 wd 0.0000	time 0.2509 (0.2511)	loss 0.9719 (1.3580)	grad_norm 0.4672 (0.5149)	loss_scale 8192.0000 (5531.3738)	mem 7984MB
[2024-07-10 14:00:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:45 lr 0.000005	 wd 0.0000	time 0.2313 (0.2499)	loss 1.5106 (1.3576)	grad_norm 0.4593 (0.5156)	loss_scale 8192.0000 (5697.5590)	mem 7984MB
[2024-07-10 14:00:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:19 lr 0.000005	 wd 0.0000	time 0.2243 (0.2488)	loss 1.6842 (1.3588)	grad_norm 0.6022 (0.5161)	loss_scale 8192.0000 (5844.2046)	mem 7984MB
[2024-07-10 14:00:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:54 lr 0.000005	 wd 0.0000	time 0.2296 (0.2487)	loss 1.1377 (1.3568)	grad_norm 0.4520 (0.5160)	loss_scale 8192.0000 (5974.5652)	mem 7984MB
[2024-07-10 14:01:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:29 lr 0.000005	 wd 0.0000	time 0.2648 (0.2491)	loss 1.4051 (1.3578)	grad_norm 0.5225 (0.5195)	loss_scale 8192.0000 (6091.2109)	mem 7984MB
[2024-07-10 14:01:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:02:04 lr 0.000004	 wd 0.0000	time 0.2410 (0.2482)	loss 1.3799 (1.3584)	grad_norm 0.4866 (0.5200)	loss_scale 8192.0000 (6196.1979)	mem 7984MB
[2024-07-10 14:02:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:39 lr 0.000004	 wd 0.0000	time 0.2288 (0.2476)	loss 1.5364 (1.3575)	grad_norm 0.5087 (0.5204)	loss_scale 8192.0000 (6291.1909)	mem 7984MB
[2024-07-10 14:02:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:14 lr 0.000004	 wd 0.0000	time 0.2403 (0.2476)	loss 1.4006 (1.3574)	grad_norm 0.4940 (0.5205)	loss_scale 8192.0000 (6377.5520)	mem 7984MB
[2024-07-10 14:02:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:49 lr 0.000004	 wd 0.0000	time 0.2108 (0.2475)	loss 1.7325 (1.3570)	grad_norm 0.4981 (0.5202)	loss_scale 8192.0000 (6456.4068)	mem 7984MB
[2024-07-10 14:03:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:25 lr 0.000004	 wd 0.0000	time 0.2278 (0.2468)	loss 1.5017 (1.3569)	grad_norm 0.4742 (0.5201)	loss_scale 8192.0000 (6528.6930)	mem 7984MB
[2024-07-10 14:03:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000004	 wd 0.0000	time 0.1729 (0.2453)	loss 1.2671 (1.3571)	grad_norm 0.5183 (0.5207)	loss_scale 8192.0000 (6595.1987)	mem 7984MB
[2024-07-10 14:03:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 24 training takes 0:10:20
[2024-07-10 14:04:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 36.935 (36.935)	Loss 0.4146 (0.4146)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 14:04:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.162 Acc@5 97.266
[2024-07-10 14:04:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-10 14:04:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.20%
[2024-07-10 14:04:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][0/2502]	eta 10:50:43 lr 0.000004	 wd 0.0000	time 15.6049 (15.6049)	loss 1.2558 (1.2558)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:05:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:15:34 lr 0.000004	 wd 0.0000	time 0.2006 (0.3891)	loss 1.3843 (1.3257)	grad_norm 0.4934 (0.5337)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:05:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:12:25 lr 0.000004	 wd 0.0000	time 0.2411 (0.3240)	loss 1.4873 (1.3532)	grad_norm 0.5043 (0.5277)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:06:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:10:54 lr 0.000004	 wd 0.0000	time 0.2233 (0.2971)	loss 1.1216 (1.3430)	grad_norm 0.4774 (0.5326)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:06:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:09:47 lr 0.000004	 wd 0.0000	time 0.2068 (0.2796)	loss 1.2529 (1.3581)	grad_norm 0.4729 (0.5261)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:06:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:08:57 lr 0.000004	 wd 0.0000	time 0.2291 (0.2683)	loss 1.5530 (1.3584)	grad_norm 0.4682 (0.5332)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:07:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:23 lr 0.000004	 wd 0.0000	time 0.2613 (0.2646)	loss 1.1507 (1.3599)	grad_norm 0.4507 (0.5280)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:07:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:07:52 lr 0.000004	 wd 0.0000	time 0.2017 (0.2625)	loss 1.2420 (1.3604)	grad_norm 0.4898 (0.5249)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:08:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:07:19 lr 0.000004	 wd 0.0000	time 0.2349 (0.2583)	loss 1.0035 (1.3605)	grad_norm 0.5298 (0.5240)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:08:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:06:48 lr 0.000004	 wd 0.0000	time 0.2239 (0.2551)	loss 1.5146 (1.3624)	grad_norm 0.6978 (0.5226)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:08:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:21 lr 0.000004	 wd 0.0000	time 0.2516 (0.2543)	loss 1.2317 (1.3629)	grad_norm 0.4735 (0.5218)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:09:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:57 lr 0.000004	 wd 0.0000	time 0.2075 (0.2548)	loss 1.2997 (1.3610)	grad_norm 0.4896 (0.5211)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:09:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:29 lr 0.000004	 wd 0.0000	time 0.2739 (0.2528)	loss 1.3533 (1.3634)	grad_norm 0.5000 (0.5188)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:10:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:05:01 lr 0.000003	 wd 0.0000	time 0.1994 (0.2510)	loss 1.4782 (1.3651)	grad_norm 0.5178 (0.5178)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:10:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:35 lr 0.000003	 wd 0.0000	time 0.2429 (0.2503)	loss 1.1259 (1.3646)	grad_norm 0.5011 (0.5175)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:10:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:04:11 lr 0.000003	 wd 0.0000	time 0.1781 (0.2511)	loss 1.2415 (1.3646)	grad_norm 0.4793 (nan)	loss_scale 4096.0000 (7951.8614)	mem 7984MB
[2024-07-10 14:11:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:45 lr 0.000003	 wd 0.0000	time 0.2180 (0.2499)	loss 1.4923 (1.3640)	grad_norm 0.5580 (nan)	loss_scale 4096.0000 (7711.0206)	mem 7984MB
[2024-07-10 14:11:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:19 lr 0.000003	 wd 0.0000	time 0.2226 (0.2488)	loss 1.3752 (1.3633)	grad_norm 0.4618 (nan)	loss_scale 4096.0000 (7498.4974)	mem 7984MB
[2024-07-10 14:12:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:54 lr 0.000003	 wd 0.0000	time 0.2459 (0.2483)	loss 1.5539 (1.3632)	grad_norm 0.4893 (nan)	loss_scale 4096.0000 (7309.5747)	mem 7984MB
[2024-07-10 14:12:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:30 lr 0.000003	 wd 0.0000	time 0.2530 (0.2493)	loss 1.9542 (1.3630)	grad_norm 0.4642 (nan)	loss_scale 4096.0000 (7140.5281)	mem 7984MB
[2024-07-10 14:13:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:02:04 lr 0.000003	 wd 0.0000	time 0.2354 (0.2485)	loss 1.2643 (1.3623)	grad_norm 0.5199 (nan)	loss_scale 4096.0000 (6988.3778)	mem 7984MB
[2024-07-10 14:13:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:39 lr 0.000003	 wd 0.0000	time 0.2642 (0.2478)	loss 0.8816 (1.3623)	grad_norm 0.4785 (nan)	loss_scale 4096.0000 (6850.7111)	mem 7984MB
[2024-07-10 14:13:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:14 lr 0.000003	 wd 0.0000	time 0.2289 (0.2474)	loss 1.4314 (1.3610)	grad_norm 0.4484 (nan)	loss_scale 4096.0000 (6725.5538)	mem 7984MB
[2024-07-10 14:14:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:50 lr 0.000003	 wd 0.0000	time 0.2444 (0.2477)	loss 1.2099 (1.3597)	grad_norm 0.4459 (nan)	loss_scale 4096.0000 (6611.2751)	mem 7984MB
[2024-07-10 14:14:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:25 lr 0.000003	 wd 0.0000	time 0.2783 (0.2471)	loss 1.3943 (1.3613)	grad_norm 0.4870 (nan)	loss_scale 4096.0000 (6506.5156)	mem 7984MB
[2024-07-10 14:14:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1673 (0.2452)	loss 1.4860 (1.3613)	grad_norm 0.5345 (nan)	loss_scale 4096.0000 (6410.1335)	mem 7984MB
[2024-07-10 14:15:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 25 training takes 0:10:20
[2024-07-10 14:15:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 39.611 (39.611)	Loss 0.4146 (0.4146)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 14:16:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.160 Acc@5 97.268
[2024-07-10 14:16:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-10 14:16:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.20%
[2024-07-10 14:16:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][0/2502]	eta 11:30:31 lr 0.000003	 wd 0.0000	time 16.5593 (16.5593)	loss 1.3198 (1.3198)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:16:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:15:26 lr 0.000003	 wd 0.0000	time 0.2036 (0.3857)	loss 1.5047 (1.3535)	grad_norm 0.7568 (0.5125)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:17:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:12:21 lr 0.000003	 wd 0.0000	time 0.3052 (0.3221)	loss 1.4797 (1.3742)	grad_norm 0.5487 (0.5048)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:17:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:10:50 lr 0.000003	 wd 0.0000	time 0.2265 (0.2955)	loss 1.4944 (1.3658)	grad_norm 0.4765 (0.5027)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:17:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:09:45 lr 0.000003	 wd 0.0000	time 0.2445 (0.2784)	loss 1.6461 (1.3675)	grad_norm 0.4644 (0.5018)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:18:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:08:56 lr 0.000003	 wd 0.0000	time 0.1815 (0.2678)	loss 1.6271 (1.3741)	grad_norm 0.4860 (0.5111)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:18:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:08:21 lr 0.000003	 wd 0.0000	time 0.2206 (0.2636)	loss 1.4082 (1.3692)	grad_norm 0.4689 (0.5132)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:19:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:53 lr 0.000003	 wd 0.0000	time 0.2262 (0.2626)	loss 1.5290 (1.3652)	grad_norm 0.5047 (0.5138)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:19:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:07:19 lr 0.000002	 wd 0.0000	time 0.2070 (0.2585)	loss 1.6028 (1.3639)	grad_norm 0.4582 (0.5139)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:19:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:06:49 lr 0.000002	 wd 0.0000	time 0.1830 (0.2553)	loss 1.3839 (1.3639)	grad_norm 0.5346 (0.5171)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:20:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:21 lr 0.000002	 wd 0.0000	time 0.2199 (0.2541)	loss 1.4094 (1.3644)	grad_norm 0.4751 (0.5150)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:20:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:56 lr 0.000002	 wd 0.0000	time 0.2463 (0.2544)	loss 1.5803 (1.3660)	grad_norm 0.5087 (0.5161)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:21:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:28 lr 0.000002	 wd 0.0000	time 0.1921 (0.2524)	loss 1.0819 (1.3664)	grad_norm 0.5403 (0.5197)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:21:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:05:00 lr 0.000002	 wd 0.0000	time 0.2255 (0.2504)	loss 0.9566 (1.3648)	grad_norm 0.4937 (0.5210)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:21:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:35 lr 0.000002	 wd 0.0000	time 0.2222 (0.2496)	loss 1.6012 (1.3641)	grad_norm 0.5751 (0.5196)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:22:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:04:11 lr 0.000002	 wd 0.0000	time 0.3558 (0.2507)	loss 1.3999 (1.3629)	grad_norm 0.5308 (0.5183)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:22:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:45 lr 0.000002	 wd 0.0000	time 0.2356 (0.2496)	loss 1.4523 (1.3618)	grad_norm 0.5154 (0.5186)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:23:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:19 lr 0.000002	 wd 0.0000	time 0.2307 (0.2486)	loss 1.2780 (1.3629)	grad_norm 0.5135 (0.5183)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:23:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:54 lr 0.000002	 wd 0.0000	time 0.2149 (0.2480)	loss 1.5232 (1.3657)	grad_norm 0.5445 (0.5179)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:23:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:29 lr 0.000002	 wd 0.0000	time 0.2273 (0.2489)	loss 0.9808 (1.3642)	grad_norm 0.4490 (0.5186)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:24:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:02:04 lr 0.000002	 wd 0.0000	time 0.2248 (0.2481)	loss 0.9204 (1.3633)	grad_norm 0.5116 (0.5190)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:24:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:39 lr 0.000002	 wd 0.0000	time 0.2000 (0.2472)	loss 1.1295 (1.3622)	grad_norm 0.4758 (0.5182)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:25:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:14 lr 0.000002	 wd 0.0000	time 0.2459 (0.2469)	loss 0.9585 (1.3619)	grad_norm 0.5336 (0.5178)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:25:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:49 lr 0.000002	 wd 0.0000	time 0.2237 (0.2472)	loss 1.1977 (1.3607)	grad_norm 0.5022 (0.5165)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:25:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:25 lr 0.000002	 wd 0.0000	time 0.2201 (0.2467)	loss 1.1199 (1.3609)	grad_norm 0.5002 (0.5170)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:26:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1900 (0.2452)	loss 0.9485 (1.3590)	grad_norm 1.1411 (0.5181)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:26:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 26 training takes 0:10:19
[2024-07-10 14:27:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 39.325 (39.325)	Loss 0.4146 (0.4146)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 14:27:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.138 Acc@5 97.268
[2024-07-10 14:27:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-10 14:27:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.20%
[2024-07-10 14:27:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][0/2502]	eta 11:06:09 lr 0.000002	 wd 0.0000	time 15.9751 (15.9751)	loss 0.9325 (0.9325)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:28:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:15:40 lr 0.000002	 wd 0.0000	time 0.2094 (0.3916)	loss 1.4920 (1.3655)	grad_norm 0.5652 (0.4927)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:28:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:12:22 lr 0.000002	 wd 0.0000	time 0.2858 (0.3224)	loss 1.5745 (1.3603)	grad_norm 0.5216 (0.4985)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:28:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:11:01 lr 0.000002	 wd 0.0000	time 0.2183 (0.3002)	loss 1.3584 (1.3604)	grad_norm 0.4799 (0.4973)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:29:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:09:52 lr 0.000002	 wd 0.0000	time 0.2100 (0.2820)	loss 1.4486 (1.3584)	grad_norm 0.4910 (0.5006)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-10 14:29:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:09:02 lr 0.000002	 wd 0.0000	time 0.2151 (0.2710)	loss 0.9800 (1.3543)	grad_norm 0.5475 (0.5001)	loss_scale 8192.0000 (4848.1597)	mem 7984MB
[2024-07-10 14:30:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:26 lr 0.000002	 wd 0.0000	time 0.2601 (0.2662)	loss 1.2675 (1.3575)	grad_norm 0.5147 (0.5056)	loss_scale 8192.0000 (5404.5391)	mem 7984MB
[2024-07-10 14:30:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:55 lr 0.000002	 wd 0.0000	time 0.2457 (0.2639)	loss 1.4785 (1.3633)	grad_norm 0.4834 (0.5082)	loss_scale 8192.0000 (5802.1797)	mem 7984MB
[2024-07-10 14:30:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:21 lr 0.000002	 wd 0.0000	time 0.2069 (0.2597)	loss 1.5279 (1.3669)	grad_norm 0.6091 (0.5103)	loss_scale 8192.0000 (6100.5343)	mem 7984MB
[2024-07-10 14:31:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:50 lr 0.000001	 wd 0.0000	time 0.2404 (0.2560)	loss 1.2806 (1.3715)	grad_norm 0.4968 (0.5134)	loss_scale 8192.0000 (6332.6615)	mem 7984MB
[2024-07-10 14:31:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:21 lr 0.000001	 wd 0.0000	time 0.2675 (0.2542)	loss 1.4104 (1.3697)	grad_norm 0.4731 (0.5128)	loss_scale 8192.0000 (6518.4096)	mem 7984MB
[2024-07-10 14:32:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:56 lr 0.000001	 wd 0.0000	time 0.1987 (0.2544)	loss 1.5218 (1.3695)	grad_norm 0.6245 (0.5121)	loss_scale 8192.0000 (6670.4160)	mem 7984MB
[2024-07-10 14:32:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:28 lr 0.000001	 wd 0.0000	time 0.2302 (0.2525)	loss 1.4900 (1.3694)	grad_norm 0.5038 (0.5111)	loss_scale 8192.0000 (6797.1091)	mem 7984MB
[2024-07-10 14:32:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:05:01 lr 0.000001	 wd 0.0000	time 0.2187 (0.2508)	loss 1.4931 (1.3667)	grad_norm 0.4652 (0.5129)	loss_scale 8192.0000 (6904.3259)	mem 7984MB
[2024-07-10 14:33:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:35 lr 0.000001	 wd 0.0000	time 0.2210 (0.2498)	loss 1.2661 (1.3671)	grad_norm 0.4537 (0.5109)	loss_scale 8192.0000 (6996.2370)	mem 7984MB
[2024-07-10 14:33:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:04:10 lr 0.000001	 wd 0.0000	time 0.2093 (0.2503)	loss 1.5332 (1.3668)	grad_norm 0.4687 (0.5122)	loss_scale 8192.0000 (7075.9014)	mem 7984MB
[2024-07-10 14:33:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:44 lr 0.000001	 wd 0.0000	time 0.2083 (0.2493)	loss 1.5630 (1.3647)	grad_norm 0.5752 (0.5137)	loss_scale 8192.0000 (7145.6140)	mem 7984MB
[2024-07-10 14:34:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:19 lr 0.000001	 wd 0.0000	time 0.2089 (0.2482)	loss 1.3960 (1.3625)	grad_norm 0.5611 (0.5133)	loss_scale 8192.0000 (7207.1299)	mem 7984MB
[2024-07-10 14:34:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:53 lr 0.000001	 wd 0.0000	time 0.2501 (0.2476)	loss 1.5156 (1.3631)	grad_norm 0.4694 (0.5142)	loss_scale 8192.0000 (7261.8145)	mem 7984MB
[2024-07-10 14:35:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:29 lr 0.000001	 wd 0.0000	time 0.1879 (0.2486)	loss 1.0865 (1.3646)	grad_norm 0.4888 (0.5144)	loss_scale 8192.0000 (7310.7459)	mem 7984MB
[2024-07-10 14:35:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:02:04 lr 0.000001	 wd 0.0000	time 0.2258 (0.2479)	loss 1.0482 (1.3634)	grad_norm 0.4646 (0.5154)	loss_scale 8192.0000 (7354.7866)	mem 7984MB
[2024-07-10 14:35:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:39 lr 0.000001	 wd 0.0000	time 0.2197 (0.2471)	loss 1.7021 (1.3627)	grad_norm 0.5054 (0.5159)	loss_scale 8192.0000 (7394.6349)	mem 7984MB
[2024-07-10 14:36:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:14 lr 0.000001	 wd 0.0000	time 0.2364 (0.2467)	loss 1.0801 (1.3634)	grad_norm 0.5685 (0.5160)	loss_scale 8192.0000 (7430.8623)	mem 7984MB
[2024-07-10 14:36:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:49 lr 0.000001	 wd 0.0000	time 0.1982 (0.2471)	loss 1.4516 (1.3634)	grad_norm 0.4536 (0.5158)	loss_scale 8192.0000 (7463.9409)	mem 7984MB
[2024-07-10 14:37:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:25 lr 0.000001	 wd 0.0000	time 0.2186 (0.2466)	loss 1.3713 (1.3631)	grad_norm 0.4749 (0.5157)	loss_scale 8192.0000 (7494.2641)	mem 7984MB
[2024-07-10 14:37:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1746 (0.2449)	loss 1.5020 (1.3614)	grad_norm 0.4336 (0.5152)	loss_scale 8192.0000 (7522.1623)	mem 7984MB
[2024-07-10 14:37:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 27 training takes 0:10:18
[2024-07-10 14:38:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 41.552 (41.552)	Loss 0.4150 (0.4150)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 14:38:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.168 Acc@5 97.272
[2024-07-10 14:38:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-10 14:38:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.20%
[2024-07-10 14:38:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][0/2502]	eta 11:34:44 lr 0.000001	 wd 0.0000	time 16.6604 (16.6604)	loss 1.2775 (1.2775)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:39:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:15:39 lr 0.000001	 wd 0.0000	time 0.2398 (0.3910)	loss 1.0697 (1.3426)	grad_norm 0.4979 (0.5414)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:39:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:12:24 lr 0.000001	 wd 0.0000	time 0.3266 (0.3233)	loss 1.0687 (1.3459)	grad_norm 0.4698 (0.5259)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:40:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:11:37 lr 0.000001	 wd 0.0000	time 0.2110 (0.3167)	loss 1.6446 (1.3559)	grad_norm 0.4755 (0.5197)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:40:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:10:17 lr 0.000001	 wd 0.0000	time 0.1958 (0.2935)	loss 1.3830 (1.3605)	grad_norm 0.4621 (0.5205)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:41:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:09:18 lr 0.000001	 wd 0.0000	time 0.2057 (0.2789)	loss 1.5639 (1.3627)	grad_norm 0.4801 (0.5210)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:41:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:40 lr 0.000001	 wd 0.0000	time 0.2769 (0.2737)	loss 1.3755 (1.3626)	grad_norm 0.4954 (0.5188)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:41:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:08:05 lr 0.000001	 wd 0.0000	time 0.2265 (0.2696)	loss 1.0307 (1.3645)	grad_norm 0.4781 (0.5222)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:42:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:30 lr 0.000001	 wd 0.0000	time 0.2316 (0.2647)	loss 1.6111 (1.3617)	grad_norm 0.4938 (0.5216)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:42:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:57 lr 0.000001	 wd 0.0000	time 0.2332 (0.2607)	loss 1.5264 (1.3623)	grad_norm 0.5519 (0.5229)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:43:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:29 lr 0.000001	 wd 0.0000	time 0.2314 (0.2592)	loss 1.5534 (1.3649)	grad_norm 0.4565 (0.5216)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:43:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:06:02 lr 0.000001	 wd 0.0000	time 0.2185 (0.2582)	loss 0.9456 (1.3614)	grad_norm 0.4832 (0.5267)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:43:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:32 lr 0.000001	 wd 0.0000	time 0.1987 (0.2557)	loss 1.2142 (1.3617)	grad_norm 0.4935 (0.5256)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:44:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:05:04 lr 0.000001	 wd 0.0000	time 0.2305 (0.2537)	loss 1.5672 (1.3585)	grad_norm 0.5578 (0.5234)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:44:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:38 lr 0.000001	 wd 0.0000	time 0.2390 (0.2527)	loss 0.9303 (1.3595)	grad_norm 0.4735 (0.5238)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:45:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:04:13 lr 0.000001	 wd 0.0000	time 0.1749 (0.2532)	loss 1.4891 (1.3581)	grad_norm 0.4867 (0.5262)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:45:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:47 lr 0.000001	 wd 0.0000	time 0.2375 (0.2518)	loss 1.1874 (1.3576)	grad_norm 0.5183 (0.5285)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:45:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:20 lr 0.000001	 wd 0.0000	time 0.1897 (0.2506)	loss 1.4198 (1.3590)	grad_norm 0.4871 (0.5282)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:46:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:55 lr 0.000001	 wd 0.0000	time 0.2408 (0.2501)	loss 1.3743 (1.3587)	grad_norm 0.5032 (0.5270)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:46:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:31 lr 0.000001	 wd 0.0000	time 0.2206 (0.2511)	loss 1.5384 (1.3577)	grad_norm 0.5707 (0.5266)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:47:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:02:05 lr 0.000001	 wd 0.0000	time 0.2231 (0.2501)	loss 0.8830 (1.3576)	grad_norm 0.5258 (0.5258)	loss_scale 16384.0000 (8576.8316)	mem 7984MB
[2024-07-10 14:47:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:40 lr 0.000001	 wd 0.0000	time 0.2572 (0.2492)	loss 1.0876 (1.3578)	grad_norm 0.4621 (inf)	loss_scale 8192.0000 (8925.0300)	mem 7984MB
[2024-07-10 14:47:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:15 lr 0.000001	 wd 0.0000	time 0.2650 (0.2487)	loss 1.5307 (1.3567)	grad_norm 0.5216 (inf)	loss_scale 8192.0000 (8891.7256)	mem 7984MB
[2024-07-10 14:48:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:50 lr 0.000001	 wd 0.0000	time 0.2177 (0.2489)	loss 1.0864 (1.3568)	grad_norm 0.5637 (inf)	loss_scale 8192.0000 (8861.3159)	mem 7984MB
[2024-07-10 14:48:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:25 lr 0.000001	 wd 0.0000	time 0.2312 (0.2482)	loss 1.5765 (1.3553)	grad_norm 0.4853 (inf)	loss_scale 8192.0000 (8833.4394)	mem 7984MB
[2024-07-10 14:48:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1705 (0.2465)	loss 1.1946 (1.3545)	grad_norm 0.4799 (inf)	loss_scale 8192.0000 (8807.7921)	mem 7984MB
[2024-07-10 14:49:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 28 training takes 0:10:24
[2024-07-10 14:49:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 39.864 (39.864)	Loss 0.4150 (0.4150)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 14:50:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.148 Acc@5 97.272
[2024-07-10 14:50:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-10 14:50:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.20%
[2024-07-10 14:50:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][0/2502]	eta 11:39:37 lr 0.000001	 wd 0.0000	time 16.7776 (16.7776)	loss 1.4112 (1.4112)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:50:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:15:36 lr 0.000001	 wd 0.0000	time 0.1833 (0.3901)	loss 1.4691 (1.3363)	grad_norm 0.4542 (0.5037)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:51:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:12:23 lr 0.000001	 wd 0.0000	time 0.2471 (0.3231)	loss 1.1505 (1.3511)	grad_norm 0.5025 (0.5168)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-10 14:51:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:10:57 lr 0.000001	 wd 0.0000	time 0.2242 (0.2984)	loss 1.4911 (1.3502)	grad_norm 0.4716 (nan)	loss_scale 4096.0000 (7919.8405)	mem 7984MB
[2024-07-10 14:51:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:09:47 lr 0.000001	 wd 0.0000	time 0.2043 (0.2796)	loss 1.1791 (1.3589)	grad_norm 0.5123 (nan)	loss_scale 4096.0000 (6966.2643)	mem 7984MB
[2024-07-10 14:52:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:08:57 lr 0.000001	 wd 0.0000	time 0.2035 (0.2686)	loss 0.9446 (1.3604)	grad_norm 0.4610 (nan)	loss_scale 4096.0000 (6393.3573)	mem 7984MB
[2024-07-10 14:52:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:23 lr 0.000000	 wd 0.0000	time 0.2376 (0.2646)	loss 1.3488 (1.3612)	grad_norm 0.6150 (nan)	loss_scale 4096.0000 (6011.1015)	mem 7984MB
[2024-07-10 14:53:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:53 lr 0.000000	 wd 0.0000	time 0.2042 (0.2626)	loss 1.5763 (1.3619)	grad_norm 0.5025 (nan)	loss_scale 4096.0000 (5737.9058)	mem 7984MB
[2024-07-10 14:53:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:07:20 lr 0.000000	 wd 0.0000	time 0.2227 (0.2585)	loss 0.7933 (1.3630)	grad_norm 0.4778 (nan)	loss_scale 4096.0000 (5532.9238)	mem 7984MB
[2024-07-10 14:53:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:06:49 lr 0.000000	 wd 0.0000	time 0.1975 (0.2554)	loss 1.4207 (1.3627)	grad_norm 0.5176 (nan)	loss_scale 4096.0000 (5373.4428)	mem 7984MB
[2024-07-10 14:54:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:21 lr 0.000000	 wd 0.0000	time 0.2131 (0.2543)	loss 1.3236 (1.3625)	grad_norm 0.8719 (nan)	loss_scale 4096.0000 (5245.8262)	mem 7984MB
[2024-07-10 14:54:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:56 lr 0.000000	 wd 0.0000	time 0.2205 (0.2543)	loss 1.4578 (1.3630)	grad_norm 0.4595 (nan)	loss_scale 4096.0000 (5141.3915)	mem 7984MB
[2024-07-10 14:55:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:28 lr 0.000000	 wd 0.0000	time 0.2066 (0.2523)	loss 1.2706 (1.3600)	grad_norm 0.7851 (nan)	loss_scale 4096.0000 (5054.3480)	mem 7984MB
[2024-07-10 14:55:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:05:01 lr 0.000000	 wd 0.0000	time 0.2163 (0.2509)	loss 1.5522 (1.3608)	grad_norm 0.4965 (nan)	loss_scale 4096.0000 (4980.6856)	mem 7984MB
[2024-07-10 14:55:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:35 lr 0.000000	 wd 0.0000	time 0.3070 (0.2502)	loss 1.7627 (1.3597)	grad_norm 0.4719 (nan)	loss_scale 4096.0000 (4917.5389)	mem 7984MB
[2024-07-10 14:56:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:04:10 lr 0.000000	 wd 0.0000	time 0.2187 (0.2504)	loss 1.2909 (1.3610)	grad_norm 0.5685 (nan)	loss_scale 4096.0000 (4862.8061)	mem 7984MB
[2024-07-10 14:56:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:44 lr 0.000000	 wd 0.0000	time 0.1937 (0.2492)	loss 1.4786 (1.3624)	grad_norm 0.4796 (nan)	loss_scale 4096.0000 (4814.9107)	mem 7984MB
[2024-07-10 14:57:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:18 lr 0.000000	 wd 0.0000	time 0.2194 (0.2480)	loss 1.2973 (1.3593)	grad_norm 0.5210 (nan)	loss_scale 4096.0000 (4772.6467)	mem 7984MB
[2024-07-10 14:57:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:53 lr 0.000000	 wd 0.0000	time 0.2718 (0.2474)	loss 1.1605 (1.3609)	grad_norm 0.5202 (nan)	loss_scale 2048.0000 (4687.3159)	mem 7984MB
[2024-07-10 14:57:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:29 lr 0.000000	 wd 0.0000	time 0.3362 (0.2486)	loss 1.2264 (1.3606)	grad_norm 0.5135 (nan)	loss_scale 2048.0000 (4548.4776)	mem 7984MB
[2024-07-10 14:58:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:02:04 lr 0.000000	 wd 0.0000	time 0.2391 (0.2478)	loss 1.4941 (1.3607)	grad_norm 0.5200 (nan)	loss_scale 2048.0000 (4423.5162)	mem 7984MB
[2024-07-10 14:58:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:39 lr 0.000000	 wd 0.0000	time 0.2384 (0.2471)	loss 1.4987 (1.3612)	grad_norm 0.5113 (nan)	loss_scale 2048.0000 (4310.4503)	mem 7984MB
[2024-07-10 14:59:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:14 lr 0.000000	 wd 0.0000	time 0.2310 (0.2467)	loss 1.4077 (1.3629)	grad_norm 0.4970 (nan)	loss_scale 2048.0000 (4207.6583)	mem 7984MB
[2024-07-10 14:59:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:49 lr 0.000000	 wd 0.0000	time 0.2133 (0.2473)	loss 1.4180 (1.3641)	grad_norm 0.6541 (nan)	loss_scale 2048.0000 (4113.8010)	mem 7984MB
[2024-07-10 14:59:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.2379 (0.2467)	loss 1.4057 (1.3647)	grad_norm 0.5275 (nan)	loss_scale 2048.0000 (4027.7618)	mem 7984MB
[2024-07-10 15:00:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000000	 wd 0.0000	time 0.1729 (0.2450)	loss 1.5647 (1.3639)	grad_norm 0.8077 (nan)	loss_scale 2048.0000 (3948.6030)	mem 7984MB
[2024-07-10 15:00:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 29 training takes 0:10:20
[2024-07-10 15:00:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full/ckpt_epoch_29.pth saving......
[2024-07-10 15:00:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer1-full/ckpt_epoch_29.pth saved !!!
[2024-07-10 15:01:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 39.938 (39.938)	Loss 0.4150 (0.4150)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-10 15:01:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 84.170 Acc@5 97.274
[2024-07-10 15:01:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-10 15:01:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 84.20%
[2024-07-10 15:01:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 189): INFO Training time 5:35:21
