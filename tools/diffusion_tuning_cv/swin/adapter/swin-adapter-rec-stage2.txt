[2024-07-14 10:12:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/config.json
[2024-07-14 10:12:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_swin_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 9
    - 3
    DIMS:
    - 96
    - 192
    - 384
    - 768
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: false
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: stage3
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_swin_b_22kto1k_step_stag3
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 4.0e-05
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.0e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 4.0e-08
  WEIGHT_DECAY: 1.0e-08

[2024-07-14 10:12:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/swin/diffusion_ft_adapter_swin_base_patch4_window7_224_22kto1k_step_stage_process3.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_adapter_swin_b_22kto1k_step_stag3", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-14 10:12:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 108): INFO Creating model:adapter_swin_diffusion_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3
[2024-07-14 10:12:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 110): INFO Adapter_SwinTransformer_Diffusion_Finetune(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (uma): UMA(filter_strategy1=23, filter_strategy2=7,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-14 10:12:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 113): INFO number of params: 2078184
[2024-07-14 10:12:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 116): INFO number of GFLOPs: 15.438473216
[2024-07-14 10:12:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 150): INFO no checkpoint found in pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3, ignoring auto resume
[2024-07-14 10:12:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth for fine-tuning......
[2024-07-14 10:12:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])
[2024-07-14 10:12:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_swin_b_22kto1k_step_stag2/ckpt_epoch_best.pth'
[2024-07-14 10:13:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 60.636 (60.636)	Loss 0.4133 (0.4133)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 1480MB
[2024-07-14 10:13:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.120 Acc@5 97.270
[2024-07-14 10:13:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 162): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 10:13:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 168): INFO Start training
[2024-07-14 10:14:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][0/2502]	eta 12:29:26 lr 0.000000	 wd 0.0000	time 17.9720 (17.9720)	loss 1.6197 (1.6197)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 1481MB
[2024-07-14 10:14:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:22:59 lr 0.000000	 wd 0.0000	time 0.1995 (0.5744)	loss 1.4004 (1.4011)	grad_norm 0.3587 (0.3591)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:15:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:15:03 lr 0.000001	 wd 0.0000	time 0.1629 (0.3927)	loss 1.4333 (1.3861)	grad_norm 0.3598 (0.3583)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:15:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:11:30 lr 0.000001	 wd 0.0000	time 0.1719 (0.3137)	loss 1.4422 (1.3667)	grad_norm 0.3687 (0.3574)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:15:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:09:32 lr 0.000001	 wd 0.0000	time 0.1145 (0.2725)	loss 1.8224 (1.3694)	grad_norm 0.3551 (0.3583)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:16:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:08:55 lr 0.000002	 wd 0.0000	time 0.4704 (0.2675)	loss 1.4793 (1.3682)	grad_norm 0.3452 (0.3584)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:16:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:08:56 lr 0.000002	 wd 0.0000	time 0.1205 (0.2819)	loss 1.1585 (1.3678)	grad_norm 0.3589 (0.3578)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:16:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:07:55 lr 0.000002	 wd 0.0000	time 0.1807 (0.2641)	loss 1.4206 (1.3638)	grad_norm 0.3522 (0.3577)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:17:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:06 lr 0.000003	 wd 0.0000	time 0.1590 (0.2506)	loss 1.5310 (1.3647)	grad_norm 0.3504 (0.3578)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:17:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:06:26 lr 0.000003	 wd 0.0000	time 0.1550 (0.2410)	loss 1.5491 (1.3599)	grad_norm 0.3535 (0.3577)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:17:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:06:10 lr 0.000003	 wd 0.0000	time 0.1872 (0.2467)	loss 1.3609 (1.3596)	grad_norm 0.3778 (0.3575)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:18:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:05:35 lr 0.000004	 wd 0.0000	time 0.1766 (0.2390)	loss 1.5152 (1.3605)	grad_norm 0.3410 (0.3575)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:18:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:02 lr 0.000004	 wd 0.0000	time 0.1333 (0.2320)	loss 1.4757 (1.3626)	grad_norm 0.3543 (0.3574)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:18:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:04:32 lr 0.000004	 wd 0.0000	time 0.1346 (0.2263)	loss 1.4397 (1.3646)	grad_norm 0.3463 (0.3575)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:19:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:04 lr 0.000005	 wd 0.0000	time 0.2283 (0.2217)	loss 1.5598 (1.3657)	grad_norm 0.3587 (0.3576)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:19:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:03:41 lr 0.000005	 wd 0.0000	time 0.1338 (0.2210)	loss 1.4665 (1.3655)	grad_norm 0.3611 (0.3576)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:19:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:19 lr 0.000005	 wd 0.0000	time 0.1296 (0.2206)	loss 1.5842 (1.3660)	grad_norm 0.3600 (0.3577)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:20:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:02:54 lr 0.000005	 wd 0.0000	time 0.1195 (0.2174)	loss 1.4826 (1.3650)	grad_norm 0.3625 (0.3575)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:20:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:02:30 lr 0.000006	 wd 0.0000	time 0.1347 (0.2148)	loss 1.2218 (1.3656)	grad_norm 0.3570 (0.3575)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:20:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:07 lr 0.000006	 wd 0.0000	time 0.1353 (0.2121)	loss 1.6315 (1.3650)	grad_norm 0.3518 (0.3575)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:20:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:01:46 lr 0.000006	 wd 0.0000	time 0.2737 (0.2129)	loss 1.4815 (1.3631)	grad_norm 0.3426 (0.3574)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:21:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:26 lr 0.000007	 wd 0.0000	time 0.1958 (0.2156)	loss 1.3610 (1.3635)	grad_norm 0.3636 (0.3575)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:21:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:04 lr 0.000007	 wd 0.0000	time 0.1558 (0.2130)	loss 1.6173 (1.3643)	grad_norm 0.3424 (0.3574)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:21:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:42 lr 0.000007	 wd 0.0000	time 0.1829 (0.2112)	loss 1.5262 (1.3631)	grad_norm 0.3636 (0.3574)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:22:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:21 lr 0.000008	 wd 0.0000	time 0.1772 (0.2092)	loss 1.3868 (1.3633)	grad_norm 0.3522 (0.3573)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:22:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.0764 (0.2060)	loss 1.6381 (1.3635)	grad_norm 0.3381 (0.3572)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:22:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 0 training takes 0:08:39
[2024-07-14 10:22:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_0.pth saving......
[2024-07-14 10:22:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_0.pth saved !!!
[2024-07-14 10:23:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 62.175 (62.175)	Loss 0.4143 (0.4143)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 10:23:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.110 Acc@5 97.282
[2024-07-14 10:23:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 10:23:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.11%
[2024-07-14 10:23:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_best.pth saving......
[2024-07-14 10:23:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_best.pth saved !!!
[2024-07-14 10:24:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][0/2502]	eta 1 day, 1:38:28 lr 0.000008	 wd 0.0000	time 36.8940 (36.8940)	loss 1.2063 (1.2063)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:24:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:21:21 lr 0.000008	 wd 0.0000	time 0.1427 (0.5335)	loss 1.1541 (1.4015)	grad_norm 0.3479 (0.3548)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:24:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:13:16 lr 0.000009	 wd 0.0000	time 0.1667 (0.3461)	loss 1.3521 (1.4014)	grad_norm 0.3603 (0.3556)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:25:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:10:24 lr 0.000009	 wd 0.0000	time 0.1494 (0.2836)	loss 1.6810 (1.3804)	grad_norm 0.3524 (0.3557)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:25:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:08:49 lr 0.000009	 wd 0.0000	time 0.1775 (0.2517)	loss 0.9898 (1.3701)	grad_norm 0.3549 (0.3560)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:26:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:09:41 lr 0.000010	 wd 0.0000	time 0.1498 (0.2907)	loss 1.5171 (1.3688)	grad_norm 0.3425 (0.3562)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:26:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:08:31 lr 0.000010	 wd 0.0000	time 0.1410 (0.2692)	loss 1.4303 (1.3685)	grad_norm 0.3590 (0.3566)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:26:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:07:36 lr 0.000010	 wd 0.0000	time 0.1625 (0.2533)	loss 1.6240 (1.3672)	grad_norm 0.3581 (0.3565)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:27:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:06:49 lr 0.000011	 wd 0.0000	time 0.1712 (0.2407)	loss 1.5520 (1.3707)	grad_norm 0.3428 (0.3565)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:27:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:06:16 lr 0.000011	 wd 0.0000	time 0.3009 (0.2351)	loss 1.5944 (1.3680)	grad_norm 0.3663 (0.3565)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:27:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:05:57 lr 0.000011	 wd 0.0000	time 0.1651 (0.2378)	loss 1.6799 (1.3668)	grad_norm 0.3650 (0.3565)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:28:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:05:22 lr 0.000012	 wd 0.0000	time 0.1258 (0.2303)	loss 1.0828 (1.3658)	grad_norm 0.3650 (0.3566)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:28:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:04:52 lr 0.000012	 wd 0.0000	time 0.1369 (0.2243)	loss 1.3529 (1.3685)	grad_norm 0.3444 (0.3566)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:28:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:04:23 lr 0.000012	 wd 0.0000	time 0.1436 (0.2194)	loss 1.5580 (1.3718)	grad_norm 0.3553 (0.3567)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:28:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:03:58 lr 0.000012	 wd 0.0000	time 0.1919 (0.2162)	loss 1.4347 (1.3699)	grad_norm 0.3681 (0.3566)	loss_scale 65536.0000 (65536.0000)	mem 1503MB
[2024-07-14 10:29:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:03:48 lr 0.000013	 wd 0.0000	time 0.1238 (0.2276)	loss 0.9740 (1.3682)	grad_norm 0.3610 (0.3564)	loss_scale 131072.0000 (65710.6462)	mem 1503MB
[2024-07-14 10:29:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:21 lr 0.000013	 wd 0.0000	time 0.1686 (0.2234)	loss 0.9264 (1.3668)	grad_norm 0.3622 (0.3563)	loss_scale 131072.0000 (69793.1793)	mem 1503MB
[2024-07-14 10:30:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:02:56 lr 0.000013	 wd 0.0000	time 0.2374 (0.2198)	loss 1.3432 (1.3661)	grad_norm 0.3688 (0.3564)	loss_scale 131072.0000 (73395.6966)	mem 1503MB
[2024-07-14 10:30:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:32 lr 0.000014	 wd 0.0000	time 0.1547 (0.2167)	loss 1.4243 (1.3662)	grad_norm 0.3422 (0.3564)	loss_scale 131072.0000 (76598.1566)	mem 1503MB
[2024-07-14 10:30:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:14 lr 0.000014	 wd 0.0000	time 0.1770 (0.2236)	loss 1.4521 (1.3673)	grad_norm 0.3703 (0.3564)	loss_scale 131072.0000 (79463.6928)	mem 1503MB
[2024-07-14 10:31:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:01:51 lr 0.000014	 wd 0.0000	time 0.1402 (0.2221)	loss 1.3214 (1.3665)	grad_norm 0.3526 (0.3565)	loss_scale 131072.0000 (82042.8186)	mem 1503MB
[2024-07-14 10:31:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:28 lr 0.000015	 wd 0.0000	time 0.1460 (0.2192)	loss 1.3917 (1.3674)	grad_norm 0.3514 (0.3565)	loss_scale 131072.0000 (84376.4303)	mem 1503MB
[2024-07-14 10:31:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:05 lr 0.000015	 wd 0.0000	time 0.1835 (0.2166)	loss 1.1949 (1.3686)	grad_norm 0.3604 (0.3565)	loss_scale 131072.0000 (86497.9918)	mem 1503MB
[2024-07-14 10:32:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:43 lr 0.000015	 wd 0.0000	time 0.1639 (0.2150)	loss 1.6210 (1.3690)	grad_norm 0.3620 (0.3565)	loss_scale 131072.0000 (88435.1499)	mem 1503MB
[2024-07-14 10:32:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:22 lr 0.000016	 wd 0.0000	time 0.1702 (0.2185)	loss 1.4604 (1.3672)	grad_norm 0.3544 (0.3564)	loss_scale 131072.0000 (90210.9454)	mem 1503MB
[2024-07-14 10:32:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.0771 (0.2144)	loss 1.1072 (1.3685)	grad_norm 0.3390 (0.3563)	loss_scale 131072.0000 (91844.7341)	mem 1503MB
[2024-07-14 10:32:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 1 training takes 0:09:00
[2024-07-14 10:33:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 25.410 (25.410)	Loss 0.4146 (0.4146)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 10:33:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.074 Acc@5 97.266
[2024-07-14 10:33:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 10:33:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.11%
[2024-07-14 10:33:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][0/2502]	eta 20:24:16 lr 0.000016	 wd 0.0000	time 29.3589 (29.3589)	loss 1.6341 (1.6341)	grad_norm 0.0000 (0.0000)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:34:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:20:38 lr 0.000016	 wd 0.0000	time 0.1441 (0.5156)	loss 1.4144 (1.3400)	grad_norm 0.3635 (0.3555)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:34:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:13:00 lr 0.000017	 wd 0.0000	time 0.1601 (0.3389)	loss 1.4382 (1.3603)	grad_norm 0.3341 (0.3555)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:34:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:10:15 lr 0.000017	 wd 0.0000	time 0.1381 (0.2794)	loss 1.2993 (1.3713)	grad_norm 0.3656 (0.3561)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:35:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:08:42 lr 0.000017	 wd 0.0000	time 0.1540 (0.2484)	loss 1.5243 (1.3690)	grad_norm 0.3639 (0.3558)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:35:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:08:08 lr 0.000018	 wd 0.0000	time 0.3809 (0.2438)	loss 1.5389 (1.3674)	grad_norm 0.3482 (0.3556)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:36:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:30 lr 0.000018	 wd 0.0000	time 0.1895 (0.2684)	loss 1.2694 (1.3620)	grad_norm 0.3528 (0.3556)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:36:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:07:35 lr 0.000018	 wd 0.0000	time 0.1332 (0.2527)	loss 1.2627 (1.3642)	grad_norm 0.3565 (0.3556)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:36:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:06:48 lr 0.000019	 wd 0.0000	time 0.1331 (0.2400)	loss 1.4553 (1.3623)	grad_norm 0.3474 (0.3551)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:36:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:12 lr 0.000019	 wd 0.0000	time 0.2543 (0.2323)	loss 1.5290 (1.3668)	grad_norm 0.3725 (0.3553)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:37:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:11 lr 0.000019	 wd 0.0000	time 0.1647 (0.2476)	loss 1.4533 (1.3678)	grad_norm 0.3522 (0.3552)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:37:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:36 lr 0.000020	 wd 0.0000	time 0.1351 (0.2397)	loss 1.1717 (1.3673)	grad_norm 0.3494 (0.3551)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:38:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:03 lr 0.000020	 wd 0.0000	time 0.1189 (0.2330)	loss 1.2619 (1.3663)	grad_norm 0.3525 (0.3551)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:38:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:04:32 lr 0.000020	 wd 0.0000	time 0.1046 (0.2268)	loss 1.7018 (1.3690)	grad_norm 0.3640 (0.3554)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:38:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:06 lr 0.000020	 wd 0.0000	time 0.1335 (0.2238)	loss 1.4301 (1.3689)	grad_norm 0.3644 (0.3553)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:39:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:03:47 lr 0.000021	 wd 0.0000	time 0.1764 (0.2274)	loss 1.4871 (1.3670)	grad_norm 0.3447 (0.3551)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:39:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:21 lr 0.000021	 wd 0.0000	time 0.1818 (0.2231)	loss 1.2755 (1.3672)	grad_norm 0.3572 (0.3553)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:39:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:02:56 lr 0.000021	 wd 0.0000	time 0.0803 (0.2198)	loss 1.4604 (1.3669)	grad_norm 0.3632 (0.3551)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:39:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:32 lr 0.000022	 wd 0.0000	time 0.1334 (0.2168)	loss 1.3482 (1.3669)	grad_norm 0.3470 (0.3551)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:40:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:10 lr 0.000022	 wd 0.0000	time 0.1721 (0.2160)	loss 1.0726 (1.3654)	grad_norm 0.3585 (0.3551)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:40:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:01:48 lr 0.000022	 wd 0.0000	time 0.1883 (0.2164)	loss 1.1137 (1.3635)	grad_norm 0.3446 (0.3550)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:40:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:26 lr 0.000023	 wd 0.0000	time 0.1617 (0.2150)	loss 1.4480 (1.3637)	grad_norm 0.3649 (0.3550)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:41:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:04 lr 0.000023	 wd 0.0000	time 0.1489 (0.2129)	loss 1.4930 (1.3637)	grad_norm 0.3580 (0.3550)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:41:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:42 lr 0.000023	 wd 0.0000	time 0.1662 (0.2108)	loss 1.5847 (1.3637)	grad_norm 0.3576 (0.3549)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:41:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:21 lr 0.000024	 wd 0.0000	time 0.2410 (0.2096)	loss 1.4152 (1.3626)	grad_norm 0.3513 (0.3548)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:42:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.0764 (0.2069)	loss 1.4431 (1.3625)	grad_norm 0.3461 (0.3549)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:42:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 2 training takes 0:08:47
[2024-07-14 10:42:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 28.710 (28.710)	Loss 0.4131 (0.4131)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 10:42:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.118 Acc@5 97.280
[2024-07-14 10:42:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 10:42:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-14 10:42:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_best.pth saving......
[2024-07-14 10:42:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_best.pth saved !!!
[2024-07-14 10:43:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][0/2502]	eta 10:42:47 lr 0.000024	 wd 0.0000	time 15.4145 (15.4145)	loss 1.0842 (1.0842)	grad_norm 0.0000 (0.0000)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:43:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:16:50 lr 0.000024	 wd 0.0000	time 0.4294 (0.4206)	loss 1.6829 (1.3489)	grad_norm 0.3625 (0.3533)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:44:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:14:04 lr 0.000025	 wd 0.0000	time 0.1697 (0.3669)	loss 1.4815 (1.3607)	grad_norm 0.3510 (0.3534)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:44:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:10:52 lr 0.000025	 wd 0.0000	time 0.1621 (0.2963)	loss 1.3941 (1.3495)	grad_norm 0.3422 (0.3537)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:44:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:09:08 lr 0.000025	 wd 0.0000	time 0.1447 (0.2609)	loss 1.5428 (1.3561)	grad_norm 0.3513 (0.3535)	loss_scale 131072.0000 (131072.0000)	mem 1503MB
[2024-07-14 10:44:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:08:00 lr 0.000026	 wd 0.0000	time 0.2067 (0.2401)	loss 1.3783 (1.3532)	grad_norm 0.3566 (0.3535)	loss_scale 262144.0000 (133164.9661)	mem 1503MB
[2024-07-14 10:45:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:08:49 lr 0.000026	 wd 0.0000	time 0.1648 (0.2785)	loss 1.4528 (1.3528)	grad_norm 0.3624 (0.3536)	loss_scale 262144.0000 (154625.7038)	mem 1503MB
[2024-07-14 10:45:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:07:50 lr 0.000026	 wd 0.0000	time 0.1660 (0.2611)	loss 1.4984 (1.3547)	grad_norm 0.3605 (0.3536)	loss_scale 262144.0000 (169963.5492)	mem 1503MB
[2024-07-14 10:46:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:03 lr 0.000027	 wd 0.0000	time 0.1665 (0.2486)	loss 1.1377 (1.3551)	grad_norm 0.3446 (0.3538)	loss_scale 262144.0000 (181471.7203)	mem 1503MB
[2024-07-14 10:46:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:06:21 lr 0.000027	 wd 0.0000	time 0.1536 (0.2381)	loss 1.3491 (1.3566)	grad_norm 0.3488 (0.3539)	loss_scale 262144.0000 (190425.3585)	mem 1503MB
[2024-07-14 10:47:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:06 lr 0.000027	 wd 0.0000	time 0.2992 (0.2443)	loss 1.5930 (1.3598)	grad_norm 0.3380 (0.3539)	loss_scale 262144.0000 (197590.0579)	mem 1503MB
[2024-07-14 10:47:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:05:40 lr 0.000028	 wd 0.0000	time 0.1322 (0.2429)	loss 1.3927 (1.3621)	grad_norm 0.3572 (0.3540)	loss_scale 262144.0000 (203453.2679)	mem 1503MB
[2024-07-14 10:47:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:06 lr 0.000028	 wd 0.0000	time 0.1760 (0.2357)	loss 1.3081 (1.3610)	grad_norm 0.3282 (0.3540)	loss_scale 262144.0000 (208340.0899)	mem 1503MB
[2024-07-14 10:47:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:04:35 lr 0.000028	 wd 0.0000	time 0.1782 (0.2294)	loss 1.2183 (1.3639)	grad_norm 0.3398 (0.3540)	loss_scale 262144.0000 (212475.6710)	mem 1503MB
[2024-07-14 10:48:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:07 lr 0.000028	 wd 0.0000	time 0.1415 (0.2246)	loss 1.2288 (1.3647)	grad_norm 0.3650 (0.3540)	loss_scale 262144.0000 (216020.8765)	mem 1503MB
[2024-07-14 10:48:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:03:52 lr 0.000029	 wd 0.0000	time 0.2044 (0.2320)	loss 1.3739 (1.3651)	grad_norm 0.3474 (0.3537)	loss_scale 262144.0000 (219093.7029)	mem 1503MB
[2024-07-14 10:49:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:25 lr 0.000029	 wd 0.0000	time 0.1668 (0.2280)	loss 1.4194 (1.3638)	grad_norm 0.3597 (0.3537)	loss_scale 262144.0000 (221782.6658)	mem 1503MB
[2024-07-14 10:49:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:02:59 lr 0.000029	 wd 0.0000	time 0.1647 (0.2241)	loss 1.0713 (1.3629)	grad_norm 0.3470 (0.3536)	loss_scale 262144.0000 (224155.4662)	mem 1503MB
[2024-07-14 10:49:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:35 lr 0.000030	 wd 0.0000	time 0.1391 (0.2209)	loss 1.6237 (1.3645)	grad_norm 0.3690 (0.3535)	loss_scale 262144.0000 (226264.7685)	mem 1503MB
[2024-07-14 10:49:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:11 lr 0.000030	 wd 0.0000	time 0.2386 (0.2186)	loss 1.5298 (1.3642)	grad_norm 0.3486 (0.3534)	loss_scale 262144.0000 (228152.1557)	mem 1503MB
[2024-07-14 10:50:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:01:51 lr 0.000030	 wd 0.0000	time 0.1417 (0.2217)	loss 1.1628 (1.3650)	grad_norm 0.3444 (0.3534)	loss_scale 262144.0000 (229850.8986)	mem 1503MB
[2024-07-14 10:50:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:27 lr 0.000031	 wd 0.0000	time 0.1287 (0.2187)	loss 1.2160 (1.3633)	grad_norm 0.3475 (0.3533)	loss_scale 262144.0000 (231387.9334)	mem 1503MB
[2024-07-14 10:50:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:05 lr 0.000031	 wd 0.0000	time 0.1600 (0.2164)	loss 1.3655 (1.3644)	grad_norm 0.3585 (0.3532)	loss_scale 262144.0000 (232785.3012)	mem 1503MB
[2024-07-14 10:51:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:43 lr 0.000031	 wd 0.0000	time 0.1434 (0.2142)	loss 1.5341 (1.3651)	grad_norm 0.3488 (0.3532)	loss_scale 262144.0000 (234061.2116)	mem 1503MB
[2024-07-14 10:51:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:21 lr 0.000032	 wd 0.0000	time 0.1630 (0.2128)	loss 0.9905 (1.3644)	grad_norm 0.3440 (0.3531)	loss_scale 262144.0000 (235230.8405)	mem 1503MB
[2024-07-14 10:51:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000032	 wd 0.0000	time 0.0766 (0.2095)	loss 1.5391 (1.3648)	grad_norm 0.3534 (0.3531)	loss_scale 262144.0000 (236306.9364)	mem 1503MB
[2024-07-14 10:51:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 3 training takes 0:08:48
[2024-07-14 10:52:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 34.881 (34.881)	Loss 0.4158 (0.4158)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 10:52:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.098 Acc@5 97.256
[2024-07-14 10:52:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 10:52:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-14 10:52:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][0/2502]	eta 11:08:40 lr 0.000032	 wd 0.0000	time 16.0354 (16.0354)	loss 1.4341 (1.4341)	grad_norm 0.0000 (0.0000)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:53:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:13:05 lr 0.000032	 wd 0.0000	time 0.2407 (0.3271)	loss 1.1481 (1.3748)	grad_norm 0.3500 (0.3535)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:53:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:13:50 lr 0.000033	 wd 0.0000	time 0.1175 (0.3606)	loss 1.1340 (1.3766)	grad_norm 0.3514 (0.3532)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:53:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:10:40 lr 0.000033	 wd 0.0000	time 0.1283 (0.2908)	loss 1.1093 (1.3763)	grad_norm 0.3616 (0.3526)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:54:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:09:00 lr 0.000033	 wd 0.0000	time 0.2039 (0.2569)	loss 1.5834 (1.3719)	grad_norm 0.3375 (0.3527)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:54:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:07:52 lr 0.000034	 wd 0.0000	time 0.1880 (0.2360)	loss 1.3402 (1.3650)	grad_norm 0.3612 (0.3526)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:54:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:07:29 lr 0.000034	 wd 0.0000	time 0.3762 (0.2363)	loss 1.4756 (1.3609)	grad_norm 0.3537 (0.3525)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:55:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:07:34 lr 0.000034	 wd 0.0000	time 0.1486 (0.2525)	loss 1.2738 (1.3609)	grad_norm 0.3523 (0.3522)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:55:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:06:49 lr 0.000035	 wd 0.0000	time 0.1805 (0.2404)	loss 1.4692 (1.3603)	grad_norm 0.3571 (0.3520)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:55:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:06:09 lr 0.000035	 wd 0.0000	time 0.1493 (0.2307)	loss 1.4719 (1.3614)	grad_norm 0.3444 (0.3523)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:56:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:05:35 lr 0.000035	 wd 0.0000	time 0.2204 (0.2236)	loss 1.5262 (1.3622)	grad_norm 0.3362 (0.3522)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:56:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:05:27 lr 0.000036	 wd 0.0000	time 0.1403 (0.2337)	loss 1.5227 (1.3629)	grad_norm 0.3410 (0.3520)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:57:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:04:56 lr 0.000036	 wd 0.0000	time 0.1321 (0.2276)	loss 1.0756 (1.3616)	grad_norm 0.3504 (0.3518)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:57:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:04:27 lr 0.000036	 wd 0.0000	time 0.1552 (0.2222)	loss 1.5748 (1.3609)	grad_norm 0.3638 (0.3519)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:57:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:03:59 lr 0.000036	 wd 0.0000	time 0.1620 (0.2176)	loss 1.4996 (1.3610)	grad_norm 0.3573 (0.3520)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:57:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:03:34 lr 0.000037	 wd 0.0000	time 0.1888 (0.2144)	loss 1.2632 (1.3634)	grad_norm 0.3443 (0.3522)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:58:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:21 lr 0.000037	 wd 0.0000	time 0.1357 (0.2231)	loss 1.0658 (1.3631)	grad_norm 0.3503 (0.3522)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:58:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:02:56 lr 0.000037	 wd 0.0000	time 0.1578 (0.2196)	loss 1.5466 (1.3624)	grad_norm 0.3501 (0.3521)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:59:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:32 lr 0.000038	 wd 0.0000	time 0.1380 (0.2166)	loss 1.3724 (1.3623)	grad_norm 0.3453 (0.3520)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:59:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:08 lr 0.000038	 wd 0.0000	time 0.1459 (0.2138)	loss 1.6547 (1.3622)	grad_norm 0.3494 (0.3521)	loss_scale 262144.0000 (262144.0000)	mem 1503MB
[2024-07-14 10:59:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:01:46 lr 0.000038	 wd 0.0000	time 0.2459 (0.2126)	loss 1.4589 (1.3616)	grad_norm 0.3481 (0.3521)	loss_scale 524288.0000 (263454.0650)	mem 1503MB
[2024-07-14 11:00:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:25 lr 0.000039	 wd 0.0000	time 0.1320 (0.2134)	loss 1.4333 (1.3620)	grad_norm 0.3601 (0.3521)	loss_scale 524288.0000 (275868.8168)	mem 1503MB
[2024-07-14 11:00:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:03 lr 0.000039	 wd 0.0000	time 0.1514 (0.2114)	loss 0.9828 (1.3597)	grad_norm 0.3160 (0.3520)	loss_scale 524288.0000 (287155.4675)	mem 1503MB
[2024-07-14 11:00:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:42 lr 0.000039	 wd 0.0000	time 0.2371 (0.2093)	loss 1.3056 (1.3599)	grad_norm 0.3339 (0.3520)	loss_scale 524288.0000 (297461.0969)	mem 1503MB
[2024-07-14 11:00:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:21 lr 0.000040	 wd 0.0000	time 0.1896 (0.2077)	loss 1.5775 (1.3598)	grad_norm 0.3349 (0.3519)	loss_scale 524288.0000 (306908.2815)	mem 1503MB
[2024-07-14 11:01:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.0818 (0.2039)	loss 0.9216 (1.3597)	grad_norm 0.3427 (0.3519)	loss_scale 524288.0000 (315599.9936)	mem 1503MB
[2024-07-14 11:01:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 4 training takes 0:08:34
[2024-07-14 11:01:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 46.033 (46.033)	Loss 0.4146 (0.4146)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 11:02:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.064 Acc@5 97.290
[2024-07-14 11:02:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 11:02:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-14 11:02:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][0/2502]	eta 11:35:03 lr 0.000040	 wd 0.0000	time 16.6681 (16.6681)	loss 1.6063 (1.6063)	grad_norm 0.0000 (0.0000)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:02:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:12:41 lr 0.000040	 wd 0.0000	time 0.1324 (0.3169)	loss 1.2845 (1.3799)	grad_norm 0.3719 (0.3527)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:03:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:13:11 lr 0.000040	 wd 0.0000	time 1.0121 (0.3440)	loss 1.4582 (1.3832)	grad_norm 0.3555 (0.3524)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:03:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:55 lr 0.000040	 wd 0.0000	time 0.1532 (0.2977)	loss 1.6222 (1.3725)	grad_norm 0.3584 (0.3518)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:03:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:09 lr 0.000040	 wd 0.0000	time 0.1777 (0.2614)	loss 0.9945 (1.3740)	grad_norm 0.3605 (0.3517)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:04:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:07:59 lr 0.000040	 wd 0.0000	time 0.1304 (0.2397)	loss 1.5160 (1.3696)	grad_norm 0.3526 (0.3515)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:04:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:07:10 lr 0.000040	 wd 0.0000	time 0.1557 (0.2265)	loss 1.4316 (1.3707)	grad_norm 0.3418 (0.3514)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:05:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:33 lr 0.000040	 wd 0.0000	time 0.1495 (0.2516)	loss 1.4600 (1.3684)	grad_norm 0.3745 (0.3512)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:05:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:06:48 lr 0.000040	 wd 0.0000	time 0.1872 (0.2401)	loss 0.9216 (1.3623)	grad_norm 0.3501 (0.3513)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:05:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:09 lr 0.000040	 wd 0.0000	time 0.1357 (0.2306)	loss 0.9099 (1.3616)	grad_norm 0.3545 (0.3514)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:05:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:05:34 lr 0.000040	 wd 0.0000	time 0.1446 (0.2229)	loss 1.5088 (1.3647)	grad_norm 0.3469 (0.3514)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:06:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:07 lr 0.000040	 wd 0.0000	time 0.3515 (0.2197)	loss 1.5480 (1.3607)	grad_norm 0.3509 (0.3512)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:06:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:04 lr 0.000040	 wd 0.0000	time 0.1537 (0.2337)	loss 1.5495 (1.3587)	grad_norm 0.3425 (0.3512)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:07:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:34 lr 0.000040	 wd 0.0000	time 0.1435 (0.2280)	loss 1.4902 (1.3591)	grad_norm 0.3544 (0.3511)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:07:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:05 lr 0.000040	 wd 0.0000	time 0.2061 (0.2229)	loss 1.5301 (1.3588)	grad_norm 0.3538 (0.3509)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:07:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:03:39 lr 0.000040	 wd 0.0000	time 0.1276 (0.2187)	loss 1.3844 (1.3589)	grad_norm 0.3548 (0.3509)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:07:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:16 lr 0.000040	 wd 0.0000	time 0.1297 (0.2178)	loss 1.4357 (1.3608)	grad_norm 0.3650 (0.3509)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:08:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:02:54 lr 0.000040	 wd 0.0000	time 0.1927 (0.2174)	loss 1.3484 (1.3604)	grad_norm 0.3334 (0.3510)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:08:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:30 lr 0.000040	 wd 0.0000	time 0.1944 (0.2146)	loss 0.9800 (1.3598)	grad_norm 0.3390 (0.3509)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:08:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:07 lr 0.000040	 wd 0.0000	time 0.1809 (0.2122)	loss 1.4766 (1.3618)	grad_norm 0.3498 (0.3508)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:09:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:01:45 lr 0.000040	 wd 0.0000	time 0.1215 (0.2098)	loss 1.5298 (1.3627)	grad_norm 0.3552 (0.3509)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:09:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:24 lr 0.000040	 wd 0.0000	time 0.2097 (0.2095)	loss 1.5053 (1.3633)	grad_norm 0.3560 (0.3508)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:09:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:03 lr 0.000040	 wd 0.0000	time 0.1287 (0.2099)	loss 1.2296 (1.3612)	grad_norm 0.3476 (0.3508)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:10:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:42 lr 0.000040	 wd 0.0000	time 0.1599 (0.2081)	loss 0.8998 (1.3604)	grad_norm 0.3455 (0.3508)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:10:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:21 lr 0.000040	 wd 0.0000	time 0.2001 (0.2063)	loss 1.5070 (1.3605)	grad_norm 0.3700 (0.3507)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:10:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.0769 (0.2027)	loss 1.5143 (1.3603)	grad_norm 0.3415 (0.3507)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:10:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 5 training takes 0:08:31
[2024-07-14 11:11:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 43.003 (43.003)	Loss 0.4116 (0.4116)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 11:11:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.068 Acc@5 97.288
[2024-07-14 11:11:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 11:11:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-14 11:11:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][0/2502]	eta 11:24:14 lr 0.000040	 wd 0.0000	time 16.4087 (16.4087)	loss 1.5649 (1.5649)	grad_norm 0.0000 (0.0000)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:12:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:12:43 lr 0.000040	 wd 0.0000	time 0.1556 (0.3178)	loss 1.2164 (1.3307)	grad_norm 0.3604 (0.3500)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:12:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:09:08 lr 0.000040	 wd 0.0000	time 0.2415 (0.2382)	loss 1.5908 (1.3526)	grad_norm 0.3554 (0.3505)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:13:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:11:22 lr 0.000040	 wd 0.0000	time 0.1406 (0.3097)	loss 1.4547 (1.3631)	grad_norm 0.3646 (0.3507)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:13:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:09:30 lr 0.000040	 wd 0.0000	time 0.1938 (0.2716)	loss 1.3704 (1.3566)	grad_norm 0.3460 (0.3503)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:13:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:08:17 lr 0.000040	 wd 0.0000	time 0.1159 (0.2483)	loss 1.3563 (1.3512)	grad_norm 0.3379 (0.3502)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:13:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:07:20 lr 0.000040	 wd 0.0000	time 0.1324 (0.2318)	loss 1.5869 (1.3554)	grad_norm 0.3455 (0.3508)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:14:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:06:53 lr 0.000040	 wd 0.0000	time 0.3758 (0.2296)	loss 1.4098 (1.3577)	grad_norm 0.3603 (0.3508)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:14:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:02 lr 0.000040	 wd 0.0000	time 0.1387 (0.2484)	loss 1.0060 (1.3569)	grad_norm 0.3646 (0.3506)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:15:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:06:21 lr 0.000040	 wd 0.0000	time 0.1494 (0.2383)	loss 1.6519 (1.3609)	grad_norm 0.3293 (0.3506)	loss_scale 524288.0000 (524288.0000)	mem 1503MB
[2024-07-14 11:15:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:05:45 lr 0.000040	 wd 0.0000	time 0.1605 (0.2299)	loss 1.3050 (1.3564)	grad_norm 0.3408 (0.3507)	loss_scale 1048576.0000 (531620.6993)	mem 1503MB
[2024-07-14 11:15:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:12 lr 0.000040	 wd 0.0000	time 0.1612 (0.2232)	loss 1.1984 (1.3556)	grad_norm 0.3502 (0.3506)	loss_scale 1048576.0000 (578573.9510)	mem 1503MB
[2024-07-14 11:16:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:04:51 lr 0.000040	 wd 0.0000	time 0.7686 (0.2242)	loss 1.0546 (1.3572)	grad_norm 0.3486 (0.3506)	loss_scale 1048576.0000 (617708.1765)	mem 1503MB
[2024-07-14 11:16:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:04:24 lr 0.000040	 wd 0.0000	time 0.1318 (0.2197)	loss 1.3987 (1.3563)	grad_norm 0.3512 (0.3505)	loss_scale 1048576.0000 (650826.3797)	mem 1503MB
[2024-07-14 11:16:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:03:57 lr 0.000040	 wd 0.0000	time 0.1840 (0.2154)	loss 1.6511 (1.3549)	grad_norm 0.3516 (0.3504)	loss_scale 1048576.0000 (679216.7880)	mem 1503MB
[2024-07-14 11:16:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:03:32 lr 0.000040	 wd 0.0000	time 0.1466 (0.2118)	loss 1.4649 (1.3565)	grad_norm 0.3418 (0.3503)	loss_scale 1048576.0000 (703824.3304)	mem 1503MB
[2024-07-14 11:17:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:08 lr 0.000040	 wd 0.0000	time 0.1364 (0.2084)	loss 1.5420 (1.3552)	grad_norm 0.3559 (0.3503)	loss_scale 1048576.0000 (725357.8513)	mem 1503MB
[2024-07-14 11:17:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:02:46 lr 0.000040	 wd 0.0000	time 0.2241 (0.2071)	loss 1.4965 (1.3546)	grad_norm 0.3305 (0.3503)	loss_scale 1048576.0000 (744359.5062)	mem 1503MB
[2024-07-14 11:17:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:26 lr 0.000040	 wd 0.0000	time 0.1394 (0.2085)	loss 1.1551 (1.3543)	grad_norm 0.3470 (0.3503)	loss_scale 1048576.0000 (761251.0383)	mem 1503MB
[2024-07-14 11:18:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:04 lr 0.000040	 wd 0.0000	time 0.2009 (0.2065)	loss 1.2842 (1.3537)	grad_norm 0.3546 (0.3503)	loss_scale 1048576.0000 (776365.4498)	mem 1503MB
[2024-07-14 11:18:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:01:42 lr 0.000039	 wd 0.0000	time 0.1398 (0.2046)	loss 0.9932 (1.3537)	grad_norm 0.3530 (0.3502)	loss_scale 1048576.0000 (789969.1754)	mem 1503MB
[2024-07-14 11:18:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:21 lr 0.000039	 wd 0.0000	time 0.1689 (0.2027)	loss 1.5588 (1.3533)	grad_norm 0.3504 (0.3503)	loss_scale 1048576.0000 (802277.9248)	mem 1503MB
[2024-07-14 11:18:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:00 lr 0.000039	 wd 0.0000	time 0.1798 (0.2014)	loss 1.2485 (1.3538)	grad_norm 0.3424 (0.3502)	loss_scale 1048576.0000 (813468.2054)	mem 1503MB
[2024-07-14 11:19:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:40 lr 0.000039	 wd 0.0000	time 0.1612 (0.2018)	loss 1.4499 (1.3545)	grad_norm 0.3612 (0.3501)	loss_scale 1048576.0000 (823685.8409)	mem 1503MB
[2024-07-14 11:19:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:20 lr 0.000039	 wd 0.0000	time 0.1385 (0.2011)	loss 1.1927 (1.3538)	grad_norm 0.3362 (0.3501)	loss_scale 1048576.0000 (833052.3615)	mem 1503MB
[2024-07-14 11:19:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.0767 (0.1976)	loss 1.0277 (1.3544)	grad_norm 0.3376 (0.3500)	loss_scale 1048576.0000 (841669.8601)	mem 1503MB
[2024-07-14 11:19:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 6 training takes 0:08:18
[2024-07-14 11:20:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 18.799 (18.799)	Loss 0.4136 (0.4136)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 11:20:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.026 Acc@5 97.280
[2024-07-14 11:20:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-14 11:20:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-14 11:20:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][0/2502]	eta 22:39:20 lr 0.000039	 wd 0.0000	time 32.5980 (32.5980)	loss 1.5986 (1.5986)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:21:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:19:36 lr 0.000039	 wd 0.0000	time 0.1510 (0.4897)	loss 1.2317 (1.3798)	grad_norm 0.3647 (0.3487)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:21:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:12:22 lr 0.000039	 wd 0.0000	time 0.1362 (0.3226)	loss 1.4505 (1.3546)	grad_norm 0.3570 (0.3500)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:21:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:09:51 lr 0.000039	 wd 0.0000	time 0.2784 (0.2685)	loss 1.3109 (1.3519)	grad_norm 0.3477 (0.3501)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:21:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:08:23 lr 0.000039	 wd 0.0000	time 0.1332 (0.2395)	loss 1.3440 (1.3538)	grad_norm 0.3508 (0.3500)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:22:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:08:11 lr 0.000039	 wd 0.0000	time 0.3965 (0.2456)	loss 1.4366 (1.3494)	grad_norm 0.3462 (0.3500)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:22:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:08 lr 0.000039	 wd 0.0000	time 0.1924 (0.2566)	loss 1.3278 (1.3531)	grad_norm 0.3400 (0.3501)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:23:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:07:16 lr 0.000039	 wd 0.0000	time 0.1916 (0.2423)	loss 1.4825 (1.3568)	grad_norm 0.3502 (0.3501)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:23:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:06:33 lr 0.000039	 wd 0.0000	time 0.1715 (0.2313)	loss 0.8893 (1.3592)	grad_norm 0.3396 (0.3501)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:23:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:05:57 lr 0.000039	 wd 0.0000	time 0.2331 (0.2230)	loss 1.0882 (1.3609)	grad_norm 0.3423 (0.3502)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:24:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:01 lr 0.000039	 wd 0.0000	time 0.1683 (0.2405)	loss 1.1724 (1.3568)	grad_norm 0.3452 (0.3501)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:24:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:27 lr 0.000039	 wd 0.0000	time 0.1332 (0.2334)	loss 1.2301 (1.3553)	grad_norm 0.3422 (0.3500)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:24:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:04:55 lr 0.000039	 wd 0.0000	time 0.1319 (0.2269)	loss 1.4094 (1.3540)	grad_norm 0.3449 (0.3501)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:25:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:04:25 lr 0.000039	 wd 0.0000	time 0.1547 (0.2213)	loss 1.4705 (1.3541)	grad_norm 0.3368 (0.3501)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:25:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:02 lr 0.000039	 wd 0.0000	time 0.3515 (0.2199)	loss 1.4025 (1.3549)	grad_norm 0.3429 (0.3501)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:26:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:03:50 lr 0.000039	 wd 0.0000	time 0.1493 (0.2305)	loss 1.6469 (1.3542)	grad_norm 0.3740 (0.3500)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:26:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:24 lr 0.000039	 wd 0.0000	time 0.2468 (0.2262)	loss 1.5259 (1.3560)	grad_norm 0.3509 (0.3499)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:26:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:02:58 lr 0.000039	 wd 0.0000	time 0.1632 (0.2223)	loss 1.5635 (1.3563)	grad_norm 0.3592 (0.3499)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:26:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:33 lr 0.000039	 wd 0.0000	time 0.1826 (0.2192)	loss 1.1239 (1.3558)	grad_norm 0.3580 (0.3500)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:27:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:12 lr 0.000039	 wd 0.0000	time 0.1336 (0.2208)	loss 1.3085 (1.3553)	grad_norm 0.3663 (0.3501)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:27:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:01:49 lr 0.000039	 wd 0.0000	time 0.3137 (0.2188)	loss 1.4204 (1.3564)	grad_norm 0.3493 (0.3501)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:27:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:26 lr 0.000039	 wd 0.0000	time 0.1471 (0.2162)	loss 1.5054 (1.3574)	grad_norm 0.3658 (0.3501)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:28:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:04 lr 0.000039	 wd 0.0000	time 0.1296 (0.2138)	loss 1.1089 (1.3555)	grad_norm 0.3478 (0.3501)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:28:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:42 lr 0.000039	 wd 0.0000	time 0.1948 (0.2117)	loss 1.5612 (1.3560)	grad_norm 0.3497 (0.3501)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:28:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:21 lr 0.000039	 wd 0.0000	time 0.1848 (0.2114)	loss 1.4631 (1.3555)	grad_norm 0.3485 (0.3501)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:29:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.0766 (0.2091)	loss 1.2714 (1.3557)	grad_norm 0.3632 (0.3501)	loss_scale 2097152.0000 (1055284.2031)	mem 1503MB
[2024-07-14 11:29:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 7 training takes 0:08:48
[2024-07-14 11:29:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 21.731 (21.731)	Loss 0.4187 (0.4187)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 11:29:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.136 Acc@5 97.284
[2024-07-14 11:29:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 11:29:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.14%
[2024-07-14 11:29:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_best.pth saving......
[2024-07-14 11:29:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_best.pth saved !!!
[2024-07-14 11:30:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][0/2502]	eta 11:07:15 lr 0.000039	 wd 0.0000	time 16.0015 (16.0015)	loss 1.4246 (1.4246)	grad_norm 0.0000 (0.0000)	loss_scale 2097152.0000 (2097152.0000)	mem 1503MB
[2024-07-14 11:30:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:17:14 lr 0.000039	 wd 0.0000	time 0.4261 (0.4305)	loss 1.4494 (1.3934)	grad_norm 0.3412 (inf)	loss_scale 1048576.0000 (1391180.0396)	mem 1503MB
[2024-07-14 11:30:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:13:16 lr 0.000039	 wd 0.0000	time 0.1092 (0.3459)	loss 1.5340 (1.3696)	grad_norm 0.3368 (inf)	loss_scale 1048576.0000 (1220730.2687)	mem 1503MB
[2024-07-14 11:31:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:10:18 lr 0.000038	 wd 0.0000	time 0.1113 (0.2810)	loss 1.3556 (1.3665)	grad_norm 0.3573 (inf)	loss_scale 1048576.0000 (1163536.1595)	mem 1503MB
[2024-07-14 11:31:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:08:44 lr 0.000038	 wd 0.0000	time 0.2013 (0.2494)	loss 1.6225 (1.3626)	grad_norm 0.3605 (inf)	loss_scale 1048576.0000 (1134867.7905)	mem 1503MB
[2024-07-14 11:31:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:07:41 lr 0.000038	 wd 0.0000	time 0.1376 (0.2303)	loss 1.4382 (1.3654)	grad_norm 0.3500 (inf)	loss_scale 1048576.0000 (1117643.8802)	mem 1503MB
[2024-07-14 11:32:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:07:55 lr 0.000038	 wd 0.0000	time 0.1375 (0.2498)	loss 1.5186 (1.3697)	grad_norm 0.3519 (inf)	loss_scale 1048576.0000 (1106151.7205)	mem 1503MB
[2024-07-14 11:32:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:12 lr 0.000038	 wd 0.0000	time 0.1516 (0.2398)	loss 1.6347 (1.3679)	grad_norm 0.3632 (inf)	loss_scale 1048576.0000 (1097938.3509)	mem 1503MB
[2024-07-14 11:32:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:06:29 lr 0.000038	 wd 0.0000	time 0.1302 (0.2289)	loss 1.4643 (1.3654)	grad_norm 0.3392 (inf)	loss_scale 1048576.0000 (1091775.7603)	mem 1503MB
[2024-07-14 11:33:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:05:53 lr 0.000038	 wd 0.0000	time 0.1529 (0.2208)	loss 1.6549 (1.3654)	grad_norm 0.3471 (inf)	loss_scale 1048576.0000 (1086981.1143)	mem 1503MB
[2024-07-14 11:33:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:05:21 lr 0.000038	 wd 0.0000	time 0.1797 (0.2139)	loss 1.5012 (1.3616)	grad_norm 0.3399 (inf)	loss_scale 1048576.0000 (1083144.4396)	mem 1503MB
[2024-07-14 11:33:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:19 lr 0.000038	 wd 0.0000	time 0.2924 (0.2278)	loss 1.3349 (1.3586)	grad_norm 0.3515 (inf)	loss_scale 1048576.0000 (1080004.7084)	mem 1503MB
[2024-07-14 11:34:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:04:52 lr 0.000038	 wd 0.0000	time 0.1744 (0.2244)	loss 1.4544 (1.3589)	grad_norm 0.3434 (inf)	loss_scale 1048576.0000 (1077387.8301)	mem 1503MB
[2024-07-14 11:34:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:23 lr 0.000038	 wd 0.0000	time 0.1716 (0.2193)	loss 1.1758 (1.3575)	grad_norm 0.3536 (inf)	loss_scale 1048576.0000 (1075173.2390)	mem 1503MB
[2024-07-14 11:34:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:03:56 lr 0.000038	 wd 0.0000	time 0.2026 (0.2146)	loss 0.9632 (1.3592)	grad_norm 0.3626 (inf)	loss_scale 1048576.0000 (1073274.7923)	mem 1503MB
[2024-07-14 11:35:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:03:31 lr 0.000038	 wd 0.0000	time 0.2379 (0.2114)	loss 0.8320 (1.3570)	grad_norm 0.3613 (inf)	loss_scale 1048576.0000 (1071629.3031)	mem 1503MB
[2024-07-14 11:35:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:18 lr 0.000038	 wd 0.0000	time 0.2073 (0.2196)	loss 1.2226 (1.3542)	grad_norm 0.3409 (inf)	loss_scale 1048576.0000 (1070189.3716)	mem 1503MB
[2024-07-14 11:35:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:02:53 lr 0.000038	 wd 0.0000	time 0.1308 (0.2163)	loss 1.1722 (1.3559)	grad_norm 0.3476 (inf)	loss_scale 1048576.0000 (1068918.7443)	mem 1503MB
[2024-07-14 11:36:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:29 lr 0.000038	 wd 0.0000	time 0.1806 (0.2135)	loss 1.5317 (1.3570)	grad_norm 0.3498 (inf)	loss_scale 1048576.0000 (1067789.2193)	mem 1503MB
[2024-07-14 11:36:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:07 lr 0.000038	 wd 0.0000	time 0.1863 (0.2111)	loss 1.2997 (1.3563)	grad_norm 0.3491 (inf)	loss_scale 1048576.0000 (1066778.5292)	mem 1503MB
[2024-07-14 11:36:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:45 lr 0.000038	 wd 0.0000	time 0.2256 (0.2094)	loss 1.6704 (1.3583)	grad_norm 0.3560 (inf)	loss_scale 1048576.0000 (1065868.8576)	mem 1503MB
[2024-07-14 11:37:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:24 lr 0.000038	 wd 0.0000	time 0.1405 (0.2105)	loss 1.4003 (1.3573)	grad_norm 0.3582 (inf)	loss_scale 1048576.0000 (1065045.7801)	mem 1503MB
[2024-07-14 11:37:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:02 lr 0.000038	 wd 0.0000	time 0.1578 (0.2086)	loss 1.5578 (1.3559)	grad_norm 0.3624 (inf)	loss_scale 1048576.0000 (1064297.4939)	mem 1503MB
[2024-07-14 11:37:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:41 lr 0.000038	 wd 0.0000	time 0.1318 (0.2066)	loss 1.4865 (1.3566)	grad_norm 0.3719 (inf)	loss_scale 1048576.0000 (1063614.2477)	mem 1503MB
[2024-07-14 11:38:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:20 lr 0.000038	 wd 0.0000	time 0.1421 (0.2050)	loss 1.3096 (1.3581)	grad_norm 0.3663 (inf)	loss_scale 1048576.0000 (1062987.9150)	mem 1503MB
[2024-07-14 11:38:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000038	 wd 0.0000	time 0.0773 (0.2013)	loss 1.7558 (1.3595)	grad_norm 0.3426 (inf)	loss_scale 1048576.0000 (1062411.6689)	mem 1503MB
[2024-07-14 11:38:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 8 training takes 0:08:27
[2024-07-14 11:38:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 42.677 (42.677)	Loss 0.4177 (0.4177)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 11:39:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.126 Acc@5 97.284
[2024-07-14 11:39:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 11:39:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.14%
[2024-07-14 11:39:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][0/2502]	eta 11:56:30 lr 0.000038	 wd 0.0000	time 17.1823 (17.1823)	loss 1.3561 (1.3561)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:39:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:12:50 lr 0.000038	 wd 0.0000	time 0.1867 (0.3206)	loss 1.2307 (1.3228)	grad_norm 0.3478 (0.3501)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:40:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:10:09 lr 0.000037	 wd 0.0000	time 0.3930 (0.2649)	loss 1.4821 (1.3365)	grad_norm 0.3618 (0.3497)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:40:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:50 lr 0.000037	 wd 0.0000	time 0.1722 (0.2952)	loss 1.4330 (1.3482)	grad_norm 0.3468 (0.3503)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:40:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:05 lr 0.000037	 wd 0.0000	time 0.1548 (0.2596)	loss 1.5750 (1.3433)	grad_norm 0.3391 (0.3501)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:41:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:07:57 lr 0.000037	 wd 0.0000	time 0.1758 (0.2384)	loss 1.3791 (1.3500)	grad_norm 0.3497 (0.3500)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:41:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:07:04 lr 0.000037	 wd 0.0000	time 0.1236 (0.2234)	loss 1.5003 (1.3447)	grad_norm 0.3441 (0.3505)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:41:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:11 lr 0.000037	 wd 0.0000	time 0.2484 (0.2394)	loss 1.5243 (1.3462)	grad_norm 0.3480 (0.3504)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:42:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:06:53 lr 0.000037	 wd 0.0000	time 0.2350 (0.2428)	loss 1.3783 (1.3491)	grad_norm 0.3628 (0.3505)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:42:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:13 lr 0.000037	 wd 0.0000	time 0.2282 (0.2333)	loss 1.5820 (1.3463)	grad_norm 0.3483 (0.3503)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:42:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:05:38 lr 0.000037	 wd 0.0000	time 0.1496 (0.2252)	loss 1.4572 (1.3490)	grad_norm 0.3397 (0.3503)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:43:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:08 lr 0.000037	 wd 0.0000	time 0.1776 (0.2201)	loss 1.3893 (1.3520)	grad_norm 0.3426 (0.3504)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:43:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:04:52 lr 0.000037	 wd 0.0000	time 0.1393 (0.2250)	loss 1.5423 (1.3532)	grad_norm 0.3442 (0.3505)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:43:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:24 lr 0.000037	 wd 0.0000	time 0.1936 (0.2198)	loss 0.9589 (1.3512)	grad_norm 0.3497 (0.3506)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:44:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:03:57 lr 0.000037	 wd 0.0000	time 0.1881 (0.2152)	loss 1.3378 (1.3526)	grad_norm 0.3424 (0.3508)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:44:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:03:32 lr 0.000037	 wd 0.0000	time 0.1223 (0.2116)	loss 1.4628 (1.3545)	grad_norm 0.3515 (0.3507)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:44:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:08 lr 0.000037	 wd 0.0000	time 0.2610 (0.2088)	loss 0.9202 (1.3536)	grad_norm 0.3375 (inf)	loss_scale 1048576.0000 (1057745.3092)	mem 1503MB
[2024-07-14 11:45:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:02:47 lr 0.000037	 wd 0.0000	time 0.2666 (0.2083)	loss 1.1088 (1.3548)	grad_norm 0.3427 (inf)	loss_scale 1048576.0000 (1057206.2551)	mem 1503MB
[2024-07-14 11:45:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:26 lr 0.000037	 wd 0.0000	time 0.2044 (0.2085)	loss 1.5249 (1.3552)	grad_norm 0.3602 (inf)	loss_scale 1048576.0000 (1056727.0627)	mem 1503MB
[2024-07-14 11:45:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:04 lr 0.000037	 wd 0.0000	time 0.2024 (0.2062)	loss 1.3172 (1.3539)	grad_norm 0.3427 (inf)	loss_scale 1048576.0000 (1056298.2851)	mem 1503MB
[2024-07-14 11:46:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:01:42 lr 0.000037	 wd 0.0000	time 0.1749 (0.2042)	loss 1.4760 (1.3541)	grad_norm 0.3287 (inf)	loss_scale 1048576.0000 (1055912.3638)	mem 1503MB
[2024-07-14 11:46:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:21 lr 0.000036	 wd 0.0000	time 0.1592 (0.2023)	loss 1.0761 (1.3542)	grad_norm 0.3557 (inf)	loss_scale 1048576.0000 (1055563.1794)	mem 1503MB
[2024-07-14 11:46:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:01 lr 0.000036	 wd 0.0000	time 0.1410 (0.2021)	loss 1.4831 (1.3552)	grad_norm 0.3476 (inf)	loss_scale 1048576.0000 (1055245.7247)	mem 1503MB
[2024-07-14 11:46:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:40 lr 0.000036	 wd 0.0000	time 0.1466 (0.2026)	loss 1.4178 (1.3559)	grad_norm 0.3431 (inf)	loss_scale 1048576.0000 (1054955.8627)	mem 1503MB
[2024-07-14 11:47:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:20 lr 0.000036	 wd 0.0000	time 0.1488 (0.2011)	loss 1.2633 (1.3556)	grad_norm 0.3561 (inf)	loss_scale 1048576.0000 (1054690.1458)	mem 1503MB
[2024-07-14 11:47:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000036	 wd 0.0000	time 0.0826 (0.1976)	loss 1.1312 (1.3567)	grad_norm 0.3430 (inf)	loss_scale 1048576.0000 (1054445.6777)	mem 1503MB
[2024-07-14 11:47:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 9 training takes 0:08:18
[2024-07-14 11:47:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 20.324 (20.324)	Loss 0.4126 (0.4126)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 11:48:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.074 Acc@5 97.278
[2024-07-14 11:48:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 11:48:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.14%
[2024-07-14 11:48:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][0/2502]	eta 1 day, 3:39:35 lr 0.000036	 wd 0.0000	time 39.7984 (39.7984)	loss 1.2914 (1.2914)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:48:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:21:47 lr 0.000036	 wd 0.0000	time 0.1458 (0.5443)	loss 1.3409 (1.3380)	grad_norm 0.3374 (0.3479)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:49:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:13:24 lr 0.000036	 wd 0.0000	time 0.2132 (0.3497)	loss 1.2892 (1.3584)	grad_norm 0.3402 (0.3493)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:49:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:27 lr 0.000036	 wd 0.0000	time 0.2131 (0.2849)	loss 0.8780 (1.3558)	grad_norm 0.3561 (0.3504)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:49:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:30 lr 0.000036	 wd 0.0000	time 0.3155 (0.2715)	loss 1.5159 (1.3589)	grad_norm 0.3609 (0.3498)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:50:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:09:17 lr 0.000036	 wd 0.0000	time 0.1651 (0.2782)	loss 1.4044 (1.3550)	grad_norm 0.3433 (0.3503)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:50:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:09 lr 0.000036	 wd 0.0000	time 0.1279 (0.2574)	loss 1.5180 (1.3552)	grad_norm 0.3422 (0.3499)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:50:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:17 lr 0.000036	 wd 0.0000	time 0.1304 (0.2427)	loss 1.4809 (1.3513)	grad_norm 0.3459 (0.3502)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:51:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:06:33 lr 0.000036	 wd 0.0000	time 0.1514 (0.2310)	loss 1.2400 (1.3505)	grad_norm 0.3351 (0.3504)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:51:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:10 lr 0.000036	 wd 0.0000	time 0.4852 (0.2313)	loss 1.5260 (1.3506)	grad_norm 0.3650 (0.3502)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:52:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:02 lr 0.000036	 wd 0.0000	time 0.1515 (0.2411)	loss 1.4908 (1.3491)	grad_norm 0.3594 (0.3501)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:52:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:27 lr 0.000036	 wd 0.0000	time 0.1270 (0.2333)	loss 1.3058 (1.3467)	grad_norm 0.3411 (0.3499)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:52:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:04:55 lr 0.000035	 wd 0.0000	time 0.1419 (0.2269)	loss 1.3430 (1.3473)	grad_norm 0.3507 (0.3500)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:52:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:26 lr 0.000035	 wd 0.0000	time 0.2490 (0.2216)	loss 1.5692 (1.3498)	grad_norm 0.3469 (0.3500)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:53:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:08 lr 0.000035	 wd 0.0000	time 0.0950 (0.2251)	loss 1.3422 (1.3503)	grad_norm 0.3637 (0.3500)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:53:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:03:46 lr 0.000035	 wd 0.0000	time 0.1327 (0.2258)	loss 1.2509 (1.3501)	grad_norm 0.3348 (0.3499)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:53:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:19 lr 0.000035	 wd 0.0000	time 0.1636 (0.2216)	loss 1.2205 (1.3516)	grad_norm 0.3464 (0.3499)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:54:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:02:54 lr 0.000035	 wd 0.0000	time 0.1482 (0.2179)	loss 1.3131 (1.3526)	grad_norm 0.3312 (0.3501)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:54:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:31 lr 0.000035	 wd 0.0000	time 0.1691 (0.2155)	loss 1.4082 (1.3533)	grad_norm 0.3807 (0.3502)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:54:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:10 lr 0.000035	 wd 0.0000	time 0.3502 (0.2163)	loss 1.5069 (1.3548)	grad_norm 0.3632 (0.3502)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:55:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:47 lr 0.000035	 wd 0.0000	time 0.1401 (0.2145)	loss 1.2488 (1.3558)	grad_norm 0.3647 (0.3502)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:55:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:25 lr 0.000035	 wd 0.0000	time 0.1849 (0.2123)	loss 1.5458 (1.3576)	grad_norm 0.3660 (0.3502)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:55:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:03 lr 0.000035	 wd 0.0000	time 0.1900 (0.2102)	loss 0.9619 (1.3574)	grad_norm 0.3506 (0.3503)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:56:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:42 lr 0.000035	 wd 0.0000	time 0.1526 (0.2082)	loss 1.4775 (1.3569)	grad_norm 0.3554 (0.3503)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:56:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:21 lr 0.000035	 wd 0.0000	time 0.1954 (0.2080)	loss 1.5087 (1.3568)	grad_norm 0.3381 (0.3503)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:56:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.0769 (0.2061)	loss 1.3332 (1.3559)	grad_norm 0.3597 (0.3504)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:56:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 10 training takes 0:08:43
[2024-07-14 11:57:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 21.077 (21.077)	Loss 0.4165 (0.4165)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 11:57:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.116 Acc@5 97.260
[2024-07-14 11:57:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 11:57:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.14%
[2024-07-14 11:57:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][0/2502]	eta 10:42:39 lr 0.000035	 wd 0.0000	time 15.4117 (15.4117)	loss 1.4962 (1.4962)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:58:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:19:17 lr 0.000035	 wd 0.0000	time 0.1918 (0.4819)	loss 1.3953 (1.3471)	grad_norm 0.3527 (0.3510)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:58:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:12:59 lr 0.000034	 wd 0.0000	time 0.1498 (0.3387)	loss 1.4667 (1.3510)	grad_norm 0.3471 (0.3509)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:58:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:10:07 lr 0.000034	 wd 0.0000	time 0.1735 (0.2760)	loss 1.3268 (1.3534)	grad_norm 0.3649 (0.3513)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:59:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:08:36 lr 0.000034	 wd 0.0000	time 0.1542 (0.2457)	loss 1.5350 (1.3532)	grad_norm 0.3643 (0.3506)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:59:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:07:34 lr 0.000034	 wd 0.0000	time 0.1568 (0.2271)	loss 1.3746 (1.3502)	grad_norm 0.3377 (0.3506)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 11:59:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:05 lr 0.000034	 wd 0.0000	time 0.8345 (0.2552)	loss 1.4722 (1.3479)	grad_norm 0.3597 (inf)	loss_scale 1048576.0000 (1055554.8752)	mem 1503MB
[2024-07-14 12:00:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:07:15 lr 0.000034	 wd 0.0000	time 0.1609 (0.2417)	loss 1.4722 (1.3484)	grad_norm 0.3651 (inf)	loss_scale 1048576.0000 (1054559.3153)	mem 1503MB
[2024-07-14 12:00:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:06:33 lr 0.000034	 wd 0.0000	time 0.2038 (0.2310)	loss 1.6072 (1.3509)	grad_norm 0.3485 (inf)	loss_scale 1048576.0000 (1053812.3346)	mem 1503MB
[2024-07-14 12:00:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:05:56 lr 0.000034	 wd 0.0000	time 0.1834 (0.2223)	loss 1.5025 (1.3509)	grad_norm 0.3534 (inf)	loss_scale 1048576.0000 (1053231.1654)	mem 1503MB
[2024-07-14 12:00:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:05:24 lr 0.000034	 wd 0.0000	time 0.1641 (0.2159)	loss 1.4492 (1.3530)	grad_norm 0.3668 (inf)	loss_scale 1048576.0000 (1052766.1139)	mem 1503MB
[2024-07-14 12:01:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:22 lr 0.000034	 wd 0.0000	time 0.1581 (0.2302)	loss 1.5522 (1.3544)	grad_norm 0.3496 (inf)	loss_scale 1048576.0000 (1052385.5404)	mem 1503MB
[2024-07-14 12:01:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:04:51 lr 0.000034	 wd 0.0000	time 0.1369 (0.2239)	loss 1.6837 (1.3542)	grad_norm 0.3640 (inf)	loss_scale 1048576.0000 (1052068.3430)	mem 1503MB
[2024-07-14 12:02:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:04:22 lr 0.000034	 wd 0.0000	time 0.1842 (0.2188)	loss 0.9037 (1.3532)	grad_norm 0.3412 (inf)	loss_scale 1048576.0000 (1051799.9078)	mem 1503MB
[2024-07-14 12:02:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:03:56 lr 0.000034	 wd 0.0000	time 0.1813 (0.2142)	loss 0.8751 (1.3528)	grad_norm 0.3419 (inf)	loss_scale 1048576.0000 (1051569.7930)	mem 1503MB
[2024-07-14 12:02:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:03:32 lr 0.000034	 wd 0.0000	time 0.3274 (0.2116)	loss 1.4327 (1.3520)	grad_norm 0.3437 (inf)	loss_scale 1048576.0000 (1051370.3398)	mem 1503MB
[2024-07-14 12:03:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:18 lr 0.000034	 wd 0.0000	time 0.1500 (0.2198)	loss 1.2518 (1.3530)	grad_norm 0.3678 (inf)	loss_scale 1048576.0000 (1051195.8026)	mem 1503MB
[2024-07-14 12:03:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:02:53 lr 0.000033	 wd 0.0000	time 0.1512 (0.2163)	loss 1.4619 (1.3523)	grad_norm 0.3392 (inf)	loss_scale 1048576.0000 (1051041.7872)	mem 1503MB
[2024-07-14 12:03:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:29 lr 0.000033	 wd 0.0000	time 0.1546 (0.2134)	loss 1.2888 (1.3539)	grad_norm 0.3443 (inf)	loss_scale 1048576.0000 (1050904.8751)	mem 1503MB
[2024-07-14 12:04:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:06 lr 0.000033	 wd 0.0000	time 0.1804 (0.2109)	loss 1.4955 (1.3541)	grad_norm 0.3418 (inf)	loss_scale 1048576.0000 (1050782.3672)	mem 1503MB
[2024-07-14 12:04:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:01:45 lr 0.000033	 wd 0.0000	time 0.1654 (0.2098)	loss 1.1151 (1.3536)	grad_norm 0.3461 (inf)	loss_scale 1048576.0000 (1050672.1039)	mem 1503MB
[2024-07-14 12:04:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:24 lr 0.000033	 wd 0.0000	time 0.1514 (0.2099)	loss 1.5512 (1.3534)	grad_norm 0.3651 (inf)	loss_scale 1048576.0000 (1050572.3370)	mem 1503MB
[2024-07-14 12:05:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:02 lr 0.000033	 wd 0.0000	time 0.1631 (0.2080)	loss 1.2698 (1.3543)	grad_norm 0.3517 (inf)	loss_scale 1048576.0000 (1050481.6356)	mem 1503MB
[2024-07-14 12:05:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:41 lr 0.000033	 wd 0.0000	time 0.1417 (0.2061)	loss 1.5236 (1.3540)	grad_norm 0.3528 (inf)	loss_scale 1048576.0000 (1050398.8179)	mem 1503MB
[2024-07-14 12:05:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:20 lr 0.000033	 wd 0.0000	time 0.1343 (0.2044)	loss 1.2606 (1.3532)	grad_norm 0.3568 (inf)	loss_scale 1048576.0000 (1050322.8988)	mem 1503MB
[2024-07-14 12:05:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000033	 wd 0.0000	time 0.0766 (0.2008)	loss 1.3921 (1.3529)	grad_norm 0.3538 (inf)	loss_scale 1048576.0000 (1050253.0508)	mem 1503MB
[2024-07-14 12:05:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 11 training takes 0:08:30
[2024-07-14 12:06:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 41.561 (41.561)	Loss 0.4153 (0.4153)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 12:06:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.164 Acc@5 97.272
[2024-07-14 12:06:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 12:06:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.16%
[2024-07-14 12:06:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_best.pth saving......
[2024-07-14 12:06:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_best.pth saved !!!
[2024-07-14 12:07:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][0/2502]	eta 10:57:44 lr 0.000033	 wd 0.0000	time 15.7732 (15.7732)	loss 1.6212 (1.6212)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:07:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:12:37 lr 0.000033	 wd 0.0000	time 0.2220 (0.3152)	loss 1.4937 (1.3584)	grad_norm 0.3494 (0.3524)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:08:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:13:52 lr 0.000033	 wd 0.0000	time 0.1495 (0.3615)	loss 0.9804 (1.3646)	grad_norm 0.3347 (0.3518)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:08:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:44 lr 0.000033	 wd 0.0000	time 0.1204 (0.2926)	loss 1.2907 (1.3648)	grad_norm 0.3549 (0.3510)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:08:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:02 lr 0.000033	 wd 0.0000	time 0.1520 (0.2580)	loss 1.2254 (1.3572)	grad_norm 0.3299 (0.3510)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:08:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:07:53 lr 0.000032	 wd 0.0000	time 0.1603 (0.2367)	loss 1.0102 (1.3579)	grad_norm 0.3401 (0.3512)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:09:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:07:13 lr 0.000032	 wd 0.0000	time 0.2611 (0.2279)	loss 1.3565 (1.3553)	grad_norm 0.3545 (0.3513)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:09:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:14 lr 0.000032	 wd 0.0000	time 0.1612 (0.2413)	loss 1.4541 (1.3530)	grad_norm 0.3644 (0.3512)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:09:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:06:32 lr 0.000032	 wd 0.0000	time 0.1120 (0.2306)	loss 1.4532 (1.3610)	grad_norm 0.3529 (0.3514)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:10:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:05:56 lr 0.000032	 wd 0.0000	time 0.1374 (0.2224)	loss 1.0415 (1.3613)	grad_norm 0.3436 (0.3514)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:10:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:05:23 lr 0.000032	 wd 0.0000	time 0.1423 (0.2152)	loss 1.6371 (1.3590)	grad_norm 0.3457 (0.3512)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:10:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:04:59 lr 0.000032	 wd 0.0000	time 0.3056 (0.2140)	loss 1.4675 (1.3629)	grad_norm 0.3512 (0.3514)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:11:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:04:56 lr 0.000032	 wd 0.0000	time 0.1603 (0.2279)	loss 1.5078 (1.3619)	grad_norm 0.3569 (0.3513)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:11:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:27 lr 0.000032	 wd 0.0000	time 0.1184 (0.2226)	loss 1.4541 (1.3623)	grad_norm 0.3512 (0.3515)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:12:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:00 lr 0.000032	 wd 0.0000	time 0.1394 (0.2180)	loss 1.5935 (1.3623)	grad_norm 0.3478 (0.3515)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:12:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:03:34 lr 0.000032	 wd 0.0000	time 0.1708 (0.2139)	loss 1.4144 (1.3629)	grad_norm 0.3505 (0.3516)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:12:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:22 lr 0.000032	 wd 0.0000	time 0.2014 (0.2244)	loss 1.4151 (1.3618)	grad_norm 0.3492 (0.3516)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:13:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:02:57 lr 0.000031	 wd 0.0000	time 0.1398 (0.2208)	loss 1.5609 (1.3628)	grad_norm 0.3588 (0.3518)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:13:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:32 lr 0.000031	 wd 0.0000	time 0.1658 (0.2177)	loss 1.2731 (1.3636)	grad_norm 0.3561 (0.3518)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:13:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:09 lr 0.000031	 wd 0.0000	time 0.1869 (0.2149)	loss 1.4148 (1.3631)	grad_norm 0.3747 (0.3519)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:14:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:01:47 lr 0.000031	 wd 0.0000	time 0.1754 (0.2132)	loss 1.4027 (1.3622)	grad_norm 0.3425 (0.3518)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:14:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:25 lr 0.000031	 wd 0.0000	time 0.1708 (0.2139)	loss 1.4353 (1.3634)	grad_norm 0.3584 (inf)	loss_scale 1048576.0000 (1071533.8753)	mem 1503MB
[2024-07-14 12:14:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:04 lr 0.000031	 wd 0.0000	time 0.1929 (0.2120)	loss 1.5711 (1.3649)	grad_norm 0.3520 (inf)	loss_scale 1048576.0000 (1070490.8096)	mem 1503MB
[2024-07-14 12:14:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:42 lr 0.000031	 wd 0.0000	time 0.1479 (0.2100)	loss 1.4301 (1.3648)	grad_norm 0.3547 (inf)	loss_scale 1048576.0000 (1069538.4059)	mem 1503MB
[2024-07-14 12:15:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:21 lr 0.000031	 wd 0.0000	time 0.1383 (0.2083)	loss 1.4984 (1.3645)	grad_norm 0.3692 (inf)	loss_scale 1048576.0000 (1068665.3361)	mem 1503MB
[2024-07-14 12:15:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000031	 wd 0.0000	time 0.0766 (0.2045)	loss 1.1178 (1.3633)	grad_norm 0.3604 (inf)	loss_scale 1048576.0000 (1067862.0840)	mem 1503MB
[2024-07-14 12:15:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 12 training takes 0:08:39
[2024-07-14 12:16:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 46.742 (46.742)	Loss 0.4167 (0.4167)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 12:16:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.110 Acc@5 97.284
[2024-07-14 12:16:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 12:16:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.16%
[2024-07-14 12:16:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][0/2502]	eta 11:33:19 lr 0.000031	 wd 0.0000	time 16.6265 (16.6265)	loss 1.3600 (1.3600)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:17:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:14:08 lr 0.000031	 wd 0.0000	time 0.2705 (0.3531)	loss 1.3949 (1.3503)	grad_norm 0.3506 (0.3537)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:17:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:13:49 lr 0.000031	 wd 0.0000	time 0.1429 (0.3603)	loss 1.6800 (1.3523)	grad_norm 0.3342 (0.3522)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:18:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:10:42 lr 0.000031	 wd 0.0000	time 0.1488 (0.2916)	loss 1.4396 (1.3605)	grad_norm 0.3493 (0.3524)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:18:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:08:59 lr 0.000030	 wd 0.0000	time 0.1221 (0.2565)	loss 1.3274 (1.3593)	grad_norm 0.3468 (0.3519)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:18:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:07:50 lr 0.000030	 wd 0.0000	time 0.1548 (0.2351)	loss 1.5264 (1.3538)	grad_norm 0.3736 (0.3518)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:19:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:07:40 lr 0.000030	 wd 0.0000	time 0.5097 (0.2422)	loss 1.5274 (1.3598)	grad_norm 0.3518 (0.3519)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:19:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:07:33 lr 0.000030	 wd 0.0000	time 0.1414 (0.2517)	loss 1.4230 (1.3552)	grad_norm 0.3647 (0.3520)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:19:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:06:47 lr 0.000030	 wd 0.0000	time 0.1772 (0.2397)	loss 1.5455 (1.3589)	grad_norm 0.3285 (0.3521)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:20:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:06:08 lr 0.000030	 wd 0.0000	time 0.1421 (0.2300)	loss 1.5261 (1.3560)	grad_norm 0.3550 (0.3520)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:20:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:05:35 lr 0.000030	 wd 0.0000	time 0.2086 (0.2235)	loss 1.5999 (1.3614)	grad_norm 0.3416 (0.3521)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:21:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:37 lr 0.000030	 wd 0.0000	time 0.1567 (0.2406)	loss 1.3818 (1.3629)	grad_norm 0.3600 (0.3522)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:21:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:04 lr 0.000030	 wd 0.0000	time 0.1222 (0.2336)	loss 1.5600 (1.3592)	grad_norm 0.3506 (0.3521)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:21:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:04:33 lr 0.000030	 wd 0.0000	time 0.1464 (0.2278)	loss 1.4226 (1.3580)	grad_norm 0.3439 (0.3522)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:21:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:05 lr 0.000030	 wd 0.0000	time 0.1435 (0.2224)	loss 1.6414 (1.3585)	grad_norm 0.3579 (0.3521)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:22:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:03:40 lr 0.000030	 wd 0.0000	time 0.2581 (0.2198)	loss 1.6182 (1.3573)	grad_norm 0.3557 (0.3523)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:22:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:18 lr 0.000029	 wd 0.0000	time 0.1622 (0.2197)	loss 1.5703 (1.3569)	grad_norm 0.3542 (0.3522)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:22:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:02:54 lr 0.000029	 wd 0.0000	time 0.1572 (0.2171)	loss 0.8650 (1.3546)	grad_norm 0.3550 (0.3523)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:23:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:30 lr 0.000029	 wd 0.0000	time 0.1779 (0.2145)	loss 1.4226 (1.3562)	grad_norm 0.3431 (0.3523)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:23:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:07 lr 0.000029	 wd 0.0000	time 0.1290 (0.2120)	loss 1.2243 (1.3566)	grad_norm 0.3464 (0.3524)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:23:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:45 lr 0.000029	 wd 0.0000	time 0.2562 (0.2102)	loss 1.4307 (1.3577)	grad_norm 0.3481 (0.3524)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:24:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:26 lr 0.000029	 wd 0.0000	time 0.1694 (0.2143)	loss 1.1029 (1.3574)	grad_norm 0.3622 (0.3526)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:24:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:04 lr 0.000029	 wd 0.0000	time 0.1833 (0.2119)	loss 1.5326 (1.3589)	grad_norm 0.3650 (0.3525)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:24:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:42 lr 0.000029	 wd 0.0000	time 0.1693 (0.2100)	loss 1.2992 (1.3583)	grad_norm 0.3632 (0.3525)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:24:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:21 lr 0.000029	 wd 0.0000	time 0.1546 (0.2082)	loss 1.6675 (1.3595)	grad_norm 0.3438 (0.3524)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:25:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000029	 wd 0.0000	time 0.0768 (0.2044)	loss 1.5295 (1.3589)	grad_norm 0.3382 (0.3524)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:25:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 13 training takes 0:08:38
[2024-07-14 12:26:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 43.175 (43.175)	Loss 0.4153 (0.4153)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 12:26:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.146 Acc@5 97.290
[2024-07-14 12:26:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 12:26:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.16%
[2024-07-14 12:26:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][0/2502]	eta 10:42:17 lr 0.000029	 wd 0.0000	time 15.4029 (15.4029)	loss 1.4816 (1.4816)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:26:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:13:17 lr 0.000029	 wd 0.0000	time 0.2501 (0.3322)	loss 1.5213 (1.3685)	grad_norm 0.3472 (0.3535)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:27:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:13:17 lr 0.000028	 wd 0.0000	time 0.1718 (0.3466)	loss 1.3030 (1.3877)	grad_norm 0.3327 (0.3538)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:27:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:10:23 lr 0.000028	 wd 0.0000	time 0.1729 (0.2833)	loss 1.0103 (1.3755)	grad_norm 0.3404 (0.3530)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:28:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:08:47 lr 0.000028	 wd 0.0000	time 0.1275 (0.2511)	loss 1.1997 (1.3606)	grad_norm 0.3601 (0.3530)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:28:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:07:43 lr 0.000028	 wd 0.0000	time 0.1262 (0.2313)	loss 1.2871 (1.3634)	grad_norm 0.3558 (0.3529)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:28:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:07:34 lr 0.000028	 wd 0.0000	time 0.5078 (0.2388)	loss 1.6590 (1.3690)	grad_norm 0.3715 (0.3530)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:29:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:33 lr 0.000028	 wd 0.0000	time 0.1575 (0.2517)	loss 1.4341 (1.3650)	grad_norm 0.3628 (0.3531)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:29:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:06:47 lr 0.000028	 wd 0.0000	time 0.1621 (0.2396)	loss 1.3785 (1.3613)	grad_norm 0.3560 (0.3528)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:29:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:09 lr 0.000028	 wd 0.0000	time 0.1381 (0.2304)	loss 1.4328 (1.3575)	grad_norm 0.3406 (0.3527)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:30:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:05:34 lr 0.000028	 wd 0.0000	time 0.1827 (0.2227)	loss 1.3169 (1.3559)	grad_norm 0.3557 (0.3527)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:30:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:27 lr 0.000028	 wd 0.0000	time 0.2194 (0.2339)	loss 1.4809 (1.3536)	grad_norm 0.3338 (0.3527)	loss_scale 2097152.0000 (1063814.1617)	mem 1503MB
[2024-07-14 12:30:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:04:57 lr 0.000028	 wd 0.0000	time 0.1385 (0.2282)	loss 1.4084 (1.3538)	grad_norm 0.3553 (0.3528)	loss_scale 2097152.0000 (1149853.9484)	mem 1503MB
[2024-07-14 12:31:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:04:27 lr 0.000027	 wd 0.0000	time 0.1659 (0.2227)	loss 1.1703 (1.3540)	grad_norm 0.3563 (inf)	loss_scale 1048576.0000 (1154964.9562)	mem 1503MB
[2024-07-14 12:31:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:00 lr 0.000027	 wd 0.0000	time 0.1558 (0.2181)	loss 1.6436 (1.3530)	grad_norm 0.3553 (inf)	loss_scale 1048576.0000 (1147371.1692)	mem 1503MB
[2024-07-14 12:31:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:03:34 lr 0.000027	 wd 0.0000	time 0.1938 (0.2145)	loss 1.3610 (1.3539)	grad_norm 0.3497 (inf)	loss_scale 1048576.0000 (1140789.2125)	mem 1503MB
[2024-07-14 12:32:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:21 lr 0.000027	 wd 0.0000	time 0.1429 (0.2237)	loss 1.3147 (1.3538)	grad_norm 0.3593 (inf)	loss_scale 1048576.0000 (1135029.4866)	mem 1503MB
[2024-07-14 12:32:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:02:56 lr 0.000027	 wd 0.0000	time 0.1941 (0.2203)	loss 1.1937 (1.3531)	grad_norm 0.3653 (inf)	loss_scale 1048576.0000 (1129946.9771)	mem 1503MB
[2024-07-14 12:32:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:32 lr 0.000027	 wd 0.0000	time 0.1872 (0.2171)	loss 1.3106 (1.3530)	grad_norm 0.3503 (inf)	loss_scale 1048576.0000 (1125428.8773)	mem 1503MB
[2024-07-14 12:33:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:08 lr 0.000027	 wd 0.0000	time 0.1617 (0.2143)	loss 1.5371 (1.3531)	grad_norm 0.3541 (inf)	loss_scale 1048576.0000 (1121386.1168)	mem 1503MB
[2024-07-14 12:33:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:01:46 lr 0.000027	 wd 0.0000	time 0.2447 (0.2129)	loss 1.0639 (1.3550)	grad_norm 0.3489 (inf)	loss_scale 1048576.0000 (1117747.4303)	mem 1503MB
[2024-07-14 12:33:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:25 lr 0.000027	 wd 0.0000	time 0.2065 (0.2133)	loss 1.5612 (1.3547)	grad_norm 0.3648 (inf)	loss_scale 1048576.0000 (1114455.1204)	mem 1503MB
[2024-07-14 12:34:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:03 lr 0.000027	 wd 0.0000	time 0.1376 (0.2113)	loss 1.2126 (1.3549)	grad_norm 0.3620 (inf)	loss_scale 1048576.0000 (1111461.9755)	mem 1503MB
[2024-07-14 12:34:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:42 lr 0.000027	 wd 0.0000	time 0.1592 (0.2092)	loss 1.3895 (1.3558)	grad_norm 0.3604 (inf)	loss_scale 1048576.0000 (1108728.9909)	mem 1503MB
[2024-07-14 12:34:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:21 lr 0.000026	 wd 0.0000	time 0.1303 (0.2074)	loss 1.1256 (1.3569)	grad_norm 0.3630 (inf)	loss_scale 1048576.0000 (1106223.6601)	mem 1503MB
[2024-07-14 12:34:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.0772 (0.2036)	loss 1.2417 (1.3559)	grad_norm 0.3682 (inf)	loss_scale 1048576.0000 (1103918.6757)	mem 1503MB
[2024-07-14 12:34:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 14 training takes 0:08:37
[2024-07-14 12:35:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 48.872 (48.872)	Loss 0.4136 (0.4136)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 12:36:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.162 Acc@5 97.278
[2024-07-14 12:36:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 12:36:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.16%
[2024-07-14 12:36:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][0/2502]	eta 10:57:13 lr 0.000026	 wd 0.0000	time 15.7606 (15.7606)	loss 1.4539 (1.4539)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:36:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:14:17 lr 0.000026	 wd 0.0000	time 0.3064 (0.3571)	loss 1.0129 (1.3429)	grad_norm 0.3523 (0.3522)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:37:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:13:48 lr 0.000026	 wd 0.0000	time 0.1273 (0.3598)	loss 1.4424 (1.3580)	grad_norm 0.3614 (0.3521)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:37:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:10:41 lr 0.000026	 wd 0.0000	time 0.1221 (0.2913)	loss 1.3937 (1.3452)	grad_norm 0.3436 (0.3517)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:37:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:09:00 lr 0.000026	 wd 0.0000	time 0.1349 (0.2572)	loss 1.3960 (1.3488)	grad_norm 0.3700 (0.3512)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:38:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:07:50 lr 0.000026	 wd 0.0000	time 0.1116 (0.2353)	loss 0.8676 (1.3465)	grad_norm 0.3547 (0.3515)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:38:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:07:36 lr 0.000026	 wd 0.0000	time 0.4471 (0.2402)	loss 0.8414 (1.3499)	grad_norm 0.3563 (0.3516)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:38:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:24 lr 0.000026	 wd 0.0000	time 0.1523 (0.2464)	loss 1.1081 (1.3524)	grad_norm 0.3649 (0.3519)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:39:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:06:39 lr 0.000026	 wd 0.0000	time 0.2025 (0.2349)	loss 1.4077 (1.3528)	grad_norm 0.3369 (0.3522)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:39:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:01 lr 0.000025	 wd 0.0000	time 0.1053 (0.2259)	loss 1.2251 (1.3536)	grad_norm 0.3501 (0.3523)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:39:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:05:28 lr 0.000025	 wd 0.0000	time 0.1330 (0.2188)	loss 1.4266 (1.3551)	grad_norm 0.3496 (0.3526)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:40:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:28 lr 0.000025	 wd 0.0000	time 0.0999 (0.2344)	loss 1.2405 (1.3523)	grad_norm 0.3519 (0.3525)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:40:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:04:59 lr 0.000025	 wd 0.0000	time 0.1459 (0.2303)	loss 1.3924 (1.3529)	grad_norm 0.3458 (0.3526)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:40:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:04:30 lr 0.000025	 wd 0.0000	time 0.2205 (0.2248)	loss 1.3623 (1.3513)	grad_norm 0.3536 (0.3527)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:41:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:02 lr 0.000025	 wd 0.0000	time 0.1363 (0.2197)	loss 1.4504 (1.3516)	grad_norm 0.3566 (0.3528)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:41:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:03:36 lr 0.000025	 wd 0.0000	time 0.1625 (0.2164)	loss 1.5629 (1.3513)	grad_norm 0.3631 (0.3529)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:42:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:22 lr 0.000025	 wd 0.0000	time 0.1445 (0.2240)	loss 1.2810 (1.3537)	grad_norm 0.3499 (0.3529)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:42:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:02:56 lr 0.000025	 wd 0.0000	time 0.1538 (0.2203)	loss 1.4251 (1.3527)	grad_norm 0.3592 (0.3531)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:42:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:32 lr 0.000025	 wd 0.0000	time 0.1967 (0.2171)	loss 1.0663 (1.3525)	grad_norm 0.3562 (0.3531)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:42:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:09 lr 0.000024	 wd 0.0000	time 0.1520 (0.2145)	loss 1.5957 (1.3529)	grad_norm 0.3534 (0.3532)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:43:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:01:47 lr 0.000024	 wd 0.0000	time 0.2011 (0.2134)	loss 1.8260 (1.3551)	grad_norm 0.3585 (0.3534)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:43:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:27 lr 0.000024	 wd 0.0000	time 0.1639 (0.2167)	loss 1.4913 (1.3559)	grad_norm 0.3526 (0.3534)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:43:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:04 lr 0.000024	 wd 0.0000	time 0.1320 (0.2142)	loss 1.0674 (1.3571)	grad_norm 0.3368 (0.3533)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:44:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:42 lr 0.000024	 wd 0.0000	time 0.1499 (0.2121)	loss 1.5763 (1.3572)	grad_norm 0.3562 (0.3533)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:44:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:21 lr 0.000024	 wd 0.0000	time 0.1701 (0.2102)	loss 1.0641 (1.3560)	grad_norm 0.3500 (0.3533)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:44:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.0767 (0.2066)	loss 1.2087 (1.3561)	grad_norm 0.3452 (0.3533)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:44:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 15 training takes 0:08:45
[2024-07-14 12:44:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_15.pth saving......
[2024-07-14 12:44:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_15.pth saved !!!
[2024-07-14 12:45:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 38.694 (38.694)	Loss 0.4124 (0.4124)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 12:45:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.158 Acc@5 97.278
[2024-07-14 12:45:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 12:45:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.16%
[2024-07-14 12:46:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][0/2502]	eta 11:08:33 lr 0.000024	 wd 0.0000	time 16.0324 (16.0324)	loss 1.2678 (1.2678)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:46:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:14:39 lr 0.000024	 wd 0.0000	time 0.4141 (0.3662)	loss 1.4684 (1.3496)	grad_norm 0.3660 (0.3519)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:46:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:13:28 lr 0.000024	 wd 0.0000	time 0.1490 (0.3512)	loss 1.3105 (1.3591)	grad_norm 0.3540 (0.3540)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:47:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:10:29 lr 0.000024	 wd 0.0000	time 0.1399 (0.2857)	loss 1.3568 (1.3712)	grad_norm 0.3369 (inf)	loss_scale 1048576.0000 (1167019.8007)	mem 1503MB
[2024-07-14 12:47:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:08:51 lr 0.000024	 wd 0.0000	time 0.1425 (0.2529)	loss 1.2672 (1.3651)	grad_norm 0.3543 (inf)	loss_scale 1048576.0000 (1137482.6933)	mem 1503MB
[2024-07-14 12:47:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:07:45 lr 0.000023	 wd 0.0000	time 0.1282 (0.2325)	loss 1.2560 (1.3752)	grad_norm 0.3393 (inf)	loss_scale 1048576.0000 (1119736.8463)	mem 1503MB
[2024-07-14 12:48:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:07:29 lr 0.000023	 wd 0.0000	time 0.3545 (0.2361)	loss 1.0381 (1.3676)	grad_norm 0.3557 (inf)	loss_scale 1048576.0000 (1107896.4393)	mem 1503MB
[2024-07-14 12:48:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:34 lr 0.000023	 wd 0.0000	time 0.1704 (0.2522)	loss 1.3204 (1.3693)	grad_norm 0.3618 (inf)	loss_scale 1048576.0000 (1099434.1797)	mem 1503MB
[2024-07-14 12:49:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:06:48 lr 0.000023	 wd 0.0000	time 0.1726 (0.2402)	loss 1.3913 (1.3638)	grad_norm 0.3445 (inf)	loss_scale 1048576.0000 (1093084.8439)	mem 1503MB
[2024-07-14 12:49:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:09 lr 0.000023	 wd 0.0000	time 0.1699 (0.2308)	loss 1.5559 (1.3618)	grad_norm 0.3618 (inf)	loss_scale 1048576.0000 (1088144.9057)	mem 1503MB
[2024-07-14 12:49:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:05:38 lr 0.000023	 wd 0.0000	time 0.1968 (0.2250)	loss 1.5540 (1.3620)	grad_norm 0.3488 (inf)	loss_scale 1048576.0000 (1084191.9680)	mem 1503MB
[2024-07-14 12:50:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:29 lr 0.000023	 wd 0.0000	time 0.1684 (0.2349)	loss 1.3229 (1.3630)	grad_norm 0.3547 (inf)	loss_scale 1048576.0000 (1080957.0936)	mem 1503MB
[2024-07-14 12:50:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:04:57 lr 0.000023	 wd 0.0000	time 0.1780 (0.2282)	loss 1.4123 (1.3643)	grad_norm 0.3658 (inf)	loss_scale 1048576.0000 (1078260.9159)	mem 1503MB
[2024-07-14 12:50:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:04:27 lr 0.000023	 wd 0.0000	time 0.1395 (0.2226)	loss 1.0892 (1.3648)	grad_norm 0.3567 (inf)	loss_scale 1048576.0000 (1075979.2160)	mem 1503MB
[2024-07-14 12:50:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:03:59 lr 0.000023	 wd 0.0000	time 0.2379 (0.2177)	loss 1.2021 (1.3621)	grad_norm 0.3489 (inf)	loss_scale 1048576.0000 (1074023.2405)	mem 1503MB
[2024-07-14 12:51:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:03:34 lr 0.000022	 wd 0.0000	time 0.1662 (0.2146)	loss 1.3962 (1.3591)	grad_norm 0.3448 (inf)	loss_scale 1048576.0000 (1072327.8881)	mem 1503MB
[2024-07-14 12:51:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:23 lr 0.000022	 wd 0.0000	time 0.1321 (0.2252)	loss 1.3763 (1.3594)	grad_norm 0.3574 (inf)	loss_scale 1048576.0000 (1070844.3223)	mem 1503MB
[2024-07-14 12:52:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:02:57 lr 0.000022	 wd 0.0000	time 0.2226 (0.2215)	loss 1.1051 (1.3574)	grad_norm 0.3608 (inf)	loss_scale 1048576.0000 (1069535.1911)	mem 1503MB
[2024-07-14 12:52:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:33 lr 0.000022	 wd 0.0000	time 0.1617 (0.2182)	loss 1.2468 (1.3558)	grad_norm 0.3462 (inf)	loss_scale 1048576.0000 (1068371.4381)	mem 1503MB
[2024-07-14 12:52:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:09 lr 0.000022	 wd 0.0000	time 0.1841 (0.2155)	loss 1.1823 (1.3546)	grad_norm 0.3457 (inf)	loss_scale 1048576.0000 (1067330.1210)	mem 1503MB
[2024-07-14 12:53:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:01:48 lr 0.000022	 wd 0.0000	time 0.2136 (0.2159)	loss 1.4699 (1.3549)	grad_norm 0.3535 (inf)	loss_scale 1048576.0000 (1066392.8836)	mem 1503MB
[2024-07-14 12:53:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:27 lr 0.000022	 wd 0.0000	time 0.1489 (0.2173)	loss 1.3499 (1.3544)	grad_norm 0.3702 (inf)	loss_scale 1048576.0000 (1065544.8644)	mem 1503MB
[2024-07-14 12:53:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:04 lr 0.000022	 wd 0.0000	time 0.1554 (0.2147)	loss 1.4704 (1.3550)	grad_norm 0.3500 (inf)	loss_scale 1048576.0000 (1064773.9028)	mem 1503MB
[2024-07-14 12:53:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:42 lr 0.000022	 wd 0.0000	time 0.1253 (0.2127)	loss 1.2201 (1.3551)	grad_norm 0.3489 (inf)	loss_scale 1048576.0000 (1064069.9522)	mem 1503MB
[2024-07-14 12:54:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:21 lr 0.000022	 wd 0.0000	time 0.1534 (0.2107)	loss 1.5353 (1.3553)	grad_norm 0.3504 (inf)	loss_scale 1048576.0000 (1063424.6397)	mem 1503MB
[2024-07-14 12:54:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.0767 (0.2074)	loss 1.3729 (1.3553)	grad_norm 0.3510 (inf)	loss_scale 1048576.0000 (1062830.9316)	mem 1503MB
[2024-07-14 12:54:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 16 training takes 0:08:45
[2024-07-14 12:55:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 34.367 (34.367)	Loss 0.4128 (0.4128)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 12:55:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.158 Acc@5 97.266
[2024-07-14 12:55:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 12:55:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.16%
[2024-07-14 12:55:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][0/2502]	eta 11:20:43 lr 0.000021	 wd 0.0000	time 16.3245 (16.3245)	loss 1.4430 (1.4430)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:56:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:13:39 lr 0.000021	 wd 0.0000	time 0.3128 (0.3412)	loss 1.5578 (1.3290)	grad_norm 0.3617 (0.3536)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:56:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:13:23 lr 0.000021	 wd 0.0000	time 0.1921 (0.3490)	loss 1.5814 (1.3447)	grad_norm 0.3687 (0.3550)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:56:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:24 lr 0.000021	 wd 0.0000	time 0.1313 (0.2838)	loss 1.3281 (1.3411)	grad_norm 0.3621 (0.3549)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:57:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:08:48 lr 0.000021	 wd 0.0000	time 0.1664 (0.2516)	loss 1.1275 (1.3352)	grad_norm 0.3478 (0.3542)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:57:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:07:43 lr 0.000021	 wd 0.0000	time 0.1052 (0.2314)	loss 1.3694 (1.3353)	grad_norm 0.3539 (0.3544)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:57:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:07:10 lr 0.000021	 wd 0.0000	time 0.4083 (0.2263)	loss 1.1862 (1.3422)	grad_norm 0.3621 (0.3545)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:58:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:27 lr 0.000021	 wd 0.0000	time 0.1359 (0.2482)	loss 1.3309 (1.3480)	grad_norm 0.3409 (0.3549)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:58:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:06:42 lr 0.000021	 wd 0.0000	time 0.1675 (0.2364)	loss 1.3590 (1.3518)	grad_norm 0.3541 (0.3553)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:58:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:04 lr 0.000021	 wd 0.0000	time 0.1293 (0.2276)	loss 1.5903 (1.3533)	grad_norm 0.3579 (0.3551)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:59:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:05:30 lr 0.000020	 wd 0.0000	time 0.1654 (0.2200)	loss 1.5290 (1.3518)	grad_norm 0.3639 (0.3550)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:59:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:18 lr 0.000020	 wd 0.0000	time 5.1659 (0.2269)	loss 1.1113 (1.3523)	grad_norm 0.3385 (0.3551)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 12:59:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:04:54 lr 0.000020	 wd 0.0000	time 0.2032 (0.2263)	loss 1.5792 (1.3541)	grad_norm 0.3494 (0.3550)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:00:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:04:25 lr 0.000020	 wd 0.0000	time 0.1453 (0.2209)	loss 1.1675 (1.3541)	grad_norm 0.3657 (0.3552)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:00:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:03:58 lr 0.000020	 wd 0.0000	time 0.1540 (0.2164)	loss 1.4883 (1.3549)	grad_norm 0.3653 (0.3552)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:00:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:03:33 lr 0.000020	 wd 0.0000	time 0.2374 (0.2126)	loss 1.3907 (1.3557)	grad_norm 0.3600 (0.3554)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:01:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:20 lr 0.000020	 wd 0.0000	time 0.1946 (0.2219)	loss 1.5543 (1.3570)	grad_norm 0.3422 (0.3555)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:01:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:02:55 lr 0.000020	 wd 0.0000	time 0.1507 (0.2189)	loss 1.5620 (1.3589)	grad_norm 0.3539 (0.3555)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:01:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:31 lr 0.000020	 wd 0.0000	time 0.1290 (0.2157)	loss 1.3004 (1.3597)	grad_norm 0.3665 (0.3556)	loss_scale 2097152.0000 (1081180.2510)	mem 1503MB
[2024-07-14 13:02:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:08 lr 0.000020	 wd 0.0000	time 0.1958 (0.2131)	loss 1.1504 (1.3605)	grad_norm 0.3562 (inf)	loss_scale 1048576.0000 (1130211.5855)	mem 1503MB
[2024-07-14 13:02:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:01:46 lr 0.000019	 wd 0.0000	time 0.2499 (0.2118)	loss 1.5529 (1.3584)	grad_norm 0.3670 (inf)	loss_scale 1048576.0000 (1126131.8461)	mem 1503MB
[2024-07-14 13:03:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:27 lr 0.000019	 wd 0.0000	time 0.1686 (0.2177)	loss 1.4291 (1.3582)	grad_norm 0.3482 (inf)	loss_scale 1048576.0000 (1122440.4683)	mem 1503MB
[2024-07-14 13:03:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:04 lr 0.000019	 wd 0.0000	time 0.1642 (0.2152)	loss 1.3370 (1.3593)	grad_norm 0.3488 (inf)	loss_scale 1048576.0000 (1119084.5179)	mem 1503MB
[2024-07-14 13:03:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:43 lr 0.000019	 wd 0.0000	time 0.1429 (0.2130)	loss 1.4685 (1.3587)	grad_norm 0.3643 (inf)	loss_scale 1048576.0000 (1116020.2625)	mem 1503MB
[2024-07-14 13:03:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:21 lr 0.000019	 wd 0.0000	time 0.1504 (0.2110)	loss 1.4604 (1.3573)	grad_norm 0.3595 (inf)	loss_scale 1048576.0000 (1113211.2553)	mem 1503MB
[2024-07-14 13:04:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000019	 wd 0.0000	time 0.0775 (0.2077)	loss 1.4892 (1.3579)	grad_norm 0.3510 (inf)	loss_scale 1048576.0000 (1110626.8788)	mem 1503MB
[2024-07-14 13:04:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 17 training takes 0:08:46
[2024-07-14 13:04:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 40.202 (40.202)	Loss 0.4138 (0.4138)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 13:05:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.184 Acc@5 97.284
[2024-07-14 13:05:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 13:05:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-14 13:05:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_best.pth saving......
[2024-07-14 13:05:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_best.pth saved !!!
[2024-07-14 13:05:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][0/2502]	eta 10:49:07 lr 0.000019	 wd 0.0000	time 15.5666 (15.5666)	loss 1.6019 (1.6019)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:05:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:13:50 lr 0.000019	 wd 0.0000	time 0.3368 (0.3459)	loss 1.5573 (1.3980)	grad_norm 0.3500 (0.3555)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:06:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:13:28 lr 0.000019	 wd 0.0000	time 0.1488 (0.3511)	loss 1.4745 (1.3789)	grad_norm 0.3528 (0.3555)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:06:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:10:28 lr 0.000019	 wd 0.0000	time 0.1292 (0.2852)	loss 1.7171 (1.3783)	grad_norm 0.3491 (0.3558)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:06:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:08:51 lr 0.000019	 wd 0.0000	time 0.1120 (0.2526)	loss 1.4396 (1.3713)	grad_norm 0.3604 (0.3561)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:07:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:07:44 lr 0.000018	 wd 0.0000	time 0.1070 (0.2321)	loss 1.3066 (1.3608)	grad_norm 0.3463 (0.3559)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:07:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:08:05 lr 0.000018	 wd 0.0000	time 0.1619 (0.2554)	loss 1.6313 (1.3615)	grad_norm 0.3360 (0.3557)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:08:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:07:30 lr 0.000018	 wd 0.0000	time 0.0985 (0.2501)	loss 1.4290 (1.3618)	grad_norm 0.3322 (0.3556)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:08:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:06:45 lr 0.000018	 wd 0.0000	time 0.1492 (0.2384)	loss 1.0840 (1.3594)	grad_norm 0.3570 (0.3556)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:08:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:06:06 lr 0.000018	 wd 0.0000	time 0.1271 (0.2287)	loss 1.1772 (1.3555)	grad_norm 0.3824 (0.3556)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:08:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:05:34 lr 0.000018	 wd 0.0000	time 0.2387 (0.2225)	loss 1.0301 (1.3589)	grad_norm 0.3420 (0.3557)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:09:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:13 lr 0.000018	 wd 0.0000	time 0.1711 (0.2239)	loss 1.2548 (1.3585)	grad_norm 0.3435 (0.3557)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:09:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:04:45 lr 0.000018	 wd 0.0000	time 0.2046 (0.2189)	loss 1.6500 (1.3588)	grad_norm 0.3556 (0.3557)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:09:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:04:17 lr 0.000018	 wd 0.0000	time 0.1445 (0.2142)	loss 1.4008 (1.3593)	grad_norm 0.3634 (0.3557)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:10:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:03:51 lr 0.000018	 wd 0.0000	time 0.1647 (0.2103)	loss 1.2172 (1.3592)	grad_norm 0.3553 (0.3557)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:10:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:03:27 lr 0.000017	 wd 0.0000	time 0.1601 (0.2066)	loss 1.5983 (1.3582)	grad_norm 0.3398 (0.3556)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:10:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:07 lr 0.000017	 wd 0.0000	time 0.3652 (0.2081)	loss 1.4736 (1.3577)	grad_norm 0.3638 (0.3557)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:11:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:02:49 lr 0.000017	 wd 0.0000	time 0.1372 (0.2117)	loss 1.4616 (1.3579)	grad_norm 0.3621 (0.3558)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:11:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:26 lr 0.000017	 wd 0.0000	time 0.1225 (0.2087)	loss 1.3217 (1.3587)	grad_norm 0.3560 (0.3559)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:11:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:04 lr 0.000017	 wd 0.0000	time 0.1347 (0.2066)	loss 1.4623 (1.3579)	grad_norm 0.3580 (0.3559)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:12:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:01:42 lr 0.000017	 wd 0.0000	time 0.1138 (0.2045)	loss 1.3764 (1.3600)	grad_norm 0.3552 (0.3559)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:12:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:22 lr 0.000017	 wd 0.0000	time 0.2111 (0.2042)	loss 1.4423 (1.3593)	grad_norm 0.3546 (0.3559)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:12:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:01 lr 0.000017	 wd 0.0000	time 0.1982 (0.2045)	loss 1.3356 (1.3594)	grad_norm 0.3428 (0.3559)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:13:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:40 lr 0.000017	 wd 0.0000	time 0.1497 (0.2028)	loss 1.4959 (1.3597)	grad_norm 0.3380 (0.3558)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:13:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:20 lr 0.000017	 wd 0.0000	time 0.2414 (0.2014)	loss 1.5125 (1.3610)	grad_norm 0.3652 (0.3558)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:13:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.0768 (0.1979)	loss 1.4938 (1.3606)	grad_norm 0.3485 (0.3558)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:13:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 18 training takes 0:08:22
[2024-07-14 13:14:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 39.243 (39.243)	Loss 0.4141 (0.4141)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 13:14:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.176 Acc@5 97.276
[2024-07-14 13:14:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 13:14:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-14 13:14:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][0/2502]	eta 10:15:41 lr 0.000016	 wd 0.0000	time 14.7649 (14.7649)	loss 1.4250 (1.4250)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:15:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:12:37 lr 0.000016	 wd 0.0000	time 0.1359 (0.3152)	loss 1.0964 (1.3724)	grad_norm 0.3589 (0.3562)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:15:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:09:22 lr 0.000016	 wd 0.0000	time 0.3369 (0.2444)	loss 1.4339 (1.3658)	grad_norm 0.3626 (0.3561)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:16:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:11:07 lr 0.000016	 wd 0.0000	time 0.2325 (0.3029)	loss 1.3060 (1.3783)	grad_norm 0.3528 (0.3560)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:16:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:09:18 lr 0.000016	 wd 0.0000	time 0.1310 (0.2656)	loss 1.4968 (1.3777)	grad_norm 0.3494 (0.3559)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:16:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:08:07 lr 0.000016	 wd 0.0000	time 0.1531 (0.2434)	loss 1.5127 (1.3728)	grad_norm 0.3640 (0.3560)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:16:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:07:13 lr 0.000016	 wd 0.0000	time 0.1199 (0.2282)	loss 1.4797 (1.3678)	grad_norm 0.3548 (0.3560)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:17:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:06:49 lr 0.000016	 wd 0.0000	time 0.3781 (0.2271)	loss 1.6434 (1.3697)	grad_norm 0.3697 (0.3563)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:17:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:06:35 lr 0.000016	 wd 0.0000	time 0.1216 (0.2324)	loss 1.3540 (1.3686)	grad_norm 0.3586 (0.3562)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:17:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:05:58 lr 0.000016	 wd 0.0000	time 0.1377 (0.2235)	loss 1.2376 (1.3681)	grad_norm 0.3494 (0.3560)	loss_scale 2097152.0000 (1062541.4961)	mem 1503MB
[2024-07-14 13:18:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:05:25 lr 0.000016	 wd 0.0000	time 0.1827 (0.2169)	loss 1.5807 (1.3690)	grad_norm 0.3782 (inf)	loss_scale 1048576.0000 (1105142.5375)	mem 1503MB
[2024-07-14 13:18:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:04:55 lr 0.000015	 wd 0.0000	time 0.1581 (0.2111)	loss 0.9185 (1.3675)	grad_norm 0.3535 (inf)	loss_scale 1048576.0000 (1100004.7956)	mem 1503MB
[2024-07-14 13:19:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:04:50 lr 0.000015	 wd 0.0000	time 0.2565 (0.2233)	loss 1.1145 (1.3658)	grad_norm 0.3647 (inf)	loss_scale 1048576.0000 (1095722.6311)	mem 1503MB
[2024-07-14 13:19:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:04:30 lr 0.000015	 wd 0.0000	time 0.1690 (0.2251)	loss 1.5871 (1.3663)	grad_norm 0.3591 (inf)	loss_scale 1048576.0000 (1092098.7548)	mem 1503MB
[2024-07-14 13:19:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:02 lr 0.000015	 wd 0.0000	time 0.1400 (0.2203)	loss 1.4561 (1.3672)	grad_norm 0.3584 (inf)	loss_scale 1048576.0000 (1088992.2056)	mem 1503MB
[2024-07-14 13:19:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:03:36 lr 0.000015	 wd 0.0000	time 0.1405 (0.2159)	loss 1.2050 (1.3670)	grad_norm 0.3440 (inf)	loss_scale 1048576.0000 (1086299.5869)	mem 1503MB
[2024-07-14 13:20:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:12 lr 0.000015	 wd 0.0000	time 0.1294 (0.2130)	loss 1.2939 (1.3672)	grad_norm 0.3620 (inf)	loss_scale 1048576.0000 (1083943.3354)	mem 1503MB
[2024-07-14 13:20:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:02:53 lr 0.000015	 wd 0.0000	time 0.1524 (0.2164)	loss 1.4009 (1.3680)	grad_norm 0.3500 (inf)	loss_scale 1048576.0000 (1081864.1270)	mem 1503MB
[2024-07-14 13:20:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:29 lr 0.000015	 wd 0.0000	time 0.1304 (0.2135)	loss 1.3354 (1.3675)	grad_norm 0.3586 (inf)	loss_scale 1048576.0000 (1080015.8134)	mem 1503MB
[2024-07-14 13:21:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:07 lr 0.000015	 wd 0.0000	time 0.1851 (0.2112)	loss 1.4111 (1.3678)	grad_norm 0.3403 (inf)	loss_scale 1048576.0000 (1078361.9569)	mem 1503MB
[2024-07-14 13:21:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:44 lr 0.000015	 wd 0.0000	time 0.2495 (0.2088)	loss 1.0589 (1.3674)	grad_norm 0.3665 (inf)	loss_scale 1048576.0000 (1076873.4033)	mem 1503MB
[2024-07-14 13:21:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:23 lr 0.000014	 wd 0.0000	time 0.1766 (0.2072)	loss 1.1788 (1.3663)	grad_norm 0.3543 (inf)	loss_scale 1048576.0000 (1075526.5493)	mem 1503MB
[2024-07-14 13:22:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:02 lr 0.000014	 wd 0.0000	time 0.1654 (0.2086)	loss 1.4819 (1.3641)	grad_norm 0.3708 (inf)	loss_scale 1048576.0000 (1074302.0809)	mem 1503MB
[2024-07-14 13:22:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:41 lr 0.000014	 wd 0.0000	time 0.1107 (0.2071)	loss 1.4075 (1.3638)	grad_norm 0.3627 (inf)	loss_scale 1048576.0000 (1073184.0417)	mem 1503MB
[2024-07-14 13:22:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:20 lr 0.000014	 wd 0.0000	time 0.2516 (0.2054)	loss 1.5442 (1.3652)	grad_norm 0.3599 (inf)	loss_scale 1048576.0000 (1072159.1337)	mem 1503MB
[2024-07-14 13:22:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.0764 (0.2018)	loss 1.2275 (1.3651)	grad_norm 0.3543 (inf)	loss_scale 1048576.0000 (1071216.1855)	mem 1503MB
[2024-07-14 13:23:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 19 training takes 0:08:33
[2024-07-14 13:23:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 25.358 (25.358)	Loss 0.4136 (0.4136)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 13:24:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.166 Acc@5 97.284
[2024-07-14 13:24:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 13:24:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-14 13:24:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][0/2502]	eta 13:07:09 lr 0.000014	 wd 0.0000	time 18.8768 (18.8768)	loss 0.9853 (0.9853)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:24:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:13:53 lr 0.000014	 wd 0.0000	time 0.1202 (0.3471)	loss 1.5776 (1.3609)	grad_norm 0.3495 (0.3566)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:24:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:09:38 lr 0.000014	 wd 0.0000	time 0.1666 (0.2515)	loss 1.4246 (1.3625)	grad_norm 0.3696 (0.3555)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:25:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:09:10 lr 0.000014	 wd 0.0000	time 0.3756 (0.2499)	loss 1.4660 (1.3587)	grad_norm 0.3659 (0.3558)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:25:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:09:39 lr 0.000014	 wd 0.0000	time 0.1413 (0.2759)	loss 1.4103 (1.3680)	grad_norm 0.3581 (0.3560)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:26:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:08:23 lr 0.000014	 wd 0.0000	time 0.1528 (0.2517)	loss 1.5452 (1.3701)	grad_norm 0.3559 (0.3569)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:26:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:07:27 lr 0.000014	 wd 0.0000	time 0.1732 (0.2353)	loss 1.3241 (1.3665)	grad_norm 0.3493 (0.3568)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:26:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:06:44 lr 0.000013	 wd 0.0000	time 0.2172 (0.2247)	loss 1.4723 (1.3689)	grad_norm 0.3574 (0.3573)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:27:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:07:00 lr 0.000013	 wd 0.0000	time 0.1957 (0.2471)	loss 1.2569 (1.3659)	grad_norm 0.3436 (0.3571)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:27:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:19 lr 0.000013	 wd 0.0000	time 0.1423 (0.2371)	loss 1.5961 (1.3686)	grad_norm 0.3532 (0.3571)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:27:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:05:44 lr 0.000013	 wd 0.0000	time 0.1299 (0.2291)	loss 1.2910 (1.3676)	grad_norm 0.3532 (0.3568)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:28:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:11 lr 0.000013	 wd 0.0000	time 0.1456 (0.2220)	loss 1.3513 (1.3653)	grad_norm 0.3554 (0.3568)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:28:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:04:44 lr 0.000013	 wd 0.0000	time 0.1940 (0.2186)	loss 1.4207 (1.3622)	grad_norm 0.3477 (0.3568)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:29:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:04:35 lr 0.000013	 wd 0.0000	time 0.1464 (0.2290)	loss 1.3207 (1.3609)	grad_norm 0.3582 (0.3567)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:29:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:06 lr 0.000013	 wd 0.0000	time 0.1605 (0.2239)	loss 1.3980 (1.3627)	grad_norm 0.3605 (0.3569)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:29:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:03:40 lr 0.000013	 wd 0.0000	time 0.1810 (0.2196)	loss 1.4312 (1.3632)	grad_norm 0.3649 (0.3570)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:29:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:14 lr 0.000013	 wd 0.0000	time 0.1302 (0.2157)	loss 1.6845 (1.3635)	grad_norm 0.3698 (0.3571)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:30:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:02:53 lr 0.000012	 wd 0.0000	time 0.4111 (0.2168)	loss 1.5264 (1.3628)	grad_norm 0.3340 (0.3570)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:30:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:34 lr 0.000012	 wd 0.0000	time 0.1620 (0.2205)	loss 1.3069 (1.3621)	grad_norm 0.3623 (0.3570)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:30:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:10 lr 0.000012	 wd 0.0000	time 0.2100 (0.2173)	loss 1.5260 (1.3640)	grad_norm 0.3471 (0.3571)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:31:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:01:47 lr 0.000012	 wd 0.0000	time 0.2568 (0.2147)	loss 1.4984 (1.3635)	grad_norm 0.3612 (0.3570)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:31:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:25 lr 0.000012	 wd 0.0000	time 0.1818 (0.2125)	loss 1.3093 (1.3642)	grad_norm 0.3510 (0.3570)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:31:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:04 lr 0.000012	 wd 0.0000	time 0.1666 (0.2120)	loss 1.2578 (1.3657)	grad_norm 0.3609 (0.3571)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:32:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:42 lr 0.000012	 wd 0.0000	time 0.1795 (0.2116)	loss 1.4005 (1.3657)	grad_norm 0.3521 (0.3571)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:32:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:21 lr 0.000012	 wd 0.0000	time 0.1953 (0.2098)	loss 1.3490 (1.3660)	grad_norm 0.3427 (0.3571)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:32:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000012	 wd 0.0000	time 0.0767 (0.2059)	loss 1.6119 (1.3667)	grad_norm 0.3618 (0.3571)	loss_scale 2097152.0000 (1073731.7617)	mem 1503MB
[2024-07-14 13:32:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 20 training takes 0:08:43
[2024-07-14 13:33:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 23.521 (23.521)	Loss 0.4146 (0.4146)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 13:33:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.122 Acc@5 97.282
[2024-07-14 13:33:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 13:33:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-14 13:34:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][0/2502]	eta 14:09:27 lr 0.000012	 wd 0.0000	time 20.3708 (20.3708)	loss 1.5603 (1.5603)	grad_norm 0.0000 (0.0000)	loss_scale 2097152.0000 (2097152.0000)	mem 1503MB
[2024-07-14 13:34:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:14:30 lr 0.000012	 wd 0.0000	time 0.1381 (0.3626)	loss 1.4658 (1.3857)	grad_norm 0.3549 (inf)	loss_scale 1048576.0000 (1557291.0891)	mem 1503MB
[2024-07-14 13:34:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:09:59 lr 0.000012	 wd 0.0000	time 0.1326 (0.2603)	loss 0.8959 (1.3670)	grad_norm 0.3628 (inf)	loss_scale 1048576.0000 (1304199.0050)	mem 1503MB
[2024-07-14 13:35:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:10:48 lr 0.000012	 wd 0.0000	time 0.3226 (0.2947)	loss 1.3923 (1.3598)	grad_norm 0.3708 (inf)	loss_scale 1048576.0000 (1219274.4186)	mem 1503MB
[2024-07-14 13:35:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:09:51 lr 0.000011	 wd 0.0000	time 0.1750 (0.2813)	loss 1.4440 (1.3610)	grad_norm 0.3616 (inf)	loss_scale 1048576.0000 (1176706.2344)	mem 1503MB
[2024-07-14 13:35:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:08:33 lr 0.000011	 wd 0.0000	time 0.1390 (0.2563)	loss 1.3572 (1.3603)	grad_norm 0.3652 (inf)	loss_scale 1048576.0000 (1151131.3373)	mem 1503MB
[2024-07-14 13:36:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:07:34 lr 0.000011	 wd 0.0000	time 0.1646 (0.2389)	loss 1.2053 (1.3609)	grad_norm 0.3507 (inf)	loss_scale 1048576.0000 (1134067.2213)	mem 1503MB
[2024-07-14 13:36:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:06:55 lr 0.000011	 wd 0.0000	time 0.2609 (0.2305)	loss 1.2863 (1.3556)	grad_norm 0.3470 (inf)	loss_scale 1048576.0000 (1121871.6120)	mem 1503MB
[2024-07-14 13:37:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:10 lr 0.000011	 wd 0.0000	time 0.1640 (0.2529)	loss 1.2162 (1.3552)	grad_norm 0.3493 (inf)	loss_scale 1048576.0000 (1112721.0986)	mem 1503MB
[2024-07-14 13:37:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:27 lr 0.000011	 wd 0.0000	time 0.1605 (0.2421)	loss 1.5321 (1.3559)	grad_norm 0.3521 (inf)	loss_scale 1048576.0000 (1105601.7758)	mem 1503MB
[2024-07-14 13:37:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:05:50 lr 0.000011	 wd 0.0000	time 0.1693 (0.2335)	loss 1.0538 (1.3549)	grad_norm 0.3505 (inf)	loss_scale 1048576.0000 (1099904.8951)	mem 1503MB
[2024-07-14 13:37:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:05:17 lr 0.000011	 wd 0.0000	time 0.1645 (0.2262)	loss 1.4653 (1.3551)	grad_norm 0.3489 (inf)	loss_scale 1048576.0000 (1095242.8701)	mem 1503MB
[2024-07-14 13:38:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:04:50 lr 0.000011	 wd 0.0000	time 0.1930 (0.2230)	loss 1.3349 (1.3561)	grad_norm 0.3564 (inf)	loss_scale 1048576.0000 (1091357.2023)	mem 1503MB
[2024-07-14 13:38:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:26 lr 0.000011	 wd 0.0000	time 0.1796 (0.2218)	loss 1.5110 (1.3563)	grad_norm 0.3562 (inf)	loss_scale 1048576.0000 (1088068.8701)	mem 1503MB
[2024-07-14 13:38:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:03:59 lr 0.000011	 wd 0.0000	time 0.1287 (0.2175)	loss 1.4357 (1.3568)	grad_norm 0.3634 (inf)	loss_scale 1048576.0000 (1085249.9643)	mem 1503MB
[2024-07-14 13:39:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:03:34 lr 0.000010	 wd 0.0000	time 0.1452 (0.2137)	loss 1.6417 (1.3565)	grad_norm 0.3569 (inf)	loss_scale 1048576.0000 (1082806.6622)	mem 1503MB
[2024-07-14 13:39:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:09 lr 0.000010	 wd 0.0000	time 0.1344 (0.2103)	loss 1.2248 (1.3559)	grad_norm 0.3814 (inf)	loss_scale 1048576.0000 (1080668.5821)	mem 1503MB
[2024-07-14 13:39:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:02:46 lr 0.000010	 wd 0.0000	time 0.1193 (0.2082)	loss 1.4837 (1.3560)	grad_norm 0.3691 (inf)	loss_scale 1048576.0000 (1078781.8930)	mem 1503MB
[2024-07-14 13:40:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:31 lr 0.000010	 wd 0.0000	time 0.1452 (0.2153)	loss 1.0196 (1.3565)	grad_norm 0.3633 (inf)	loss_scale 1048576.0000 (1077104.7196)	mem 1503MB
[2024-07-14 13:40:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:07 lr 0.000010	 wd 0.0000	time 0.1281 (0.2125)	loss 1.0021 (1.3552)	grad_norm 0.3661 (inf)	loss_scale 1048576.0000 (1075603.9979)	mem 1503MB
[2024-07-14 13:40:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:45 lr 0.000010	 wd 0.0000	time 0.1720 (0.2101)	loss 1.3936 (1.3547)	grad_norm 0.3513 (inf)	loss_scale 1048576.0000 (1074253.2734)	mem 1503MB
[2024-07-14 13:41:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:23 lr 0.000010	 wd 0.0000	time 0.1251 (0.2079)	loss 1.1829 (1.3550)	grad_norm 0.3695 (inf)	loss_scale 1048576.0000 (1073031.1280)	mem 1503MB
[2024-07-14 13:41:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:02 lr 0.000010	 wd 0.0000	time 0.1712 (0.2068)	loss 1.5611 (1.3529)	grad_norm 0.3448 (inf)	loss_scale 1048576.0000 (1071920.0363)	mem 1503MB
[2024-07-14 13:41:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:41 lr 0.000010	 wd 0.0000	time 0.1611 (0.2074)	loss 1.5703 (1.3527)	grad_norm 0.3671 (inf)	loss_scale 1048576.0000 (1070905.5193)	mem 1503MB
[2024-07-14 13:42:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:20 lr 0.000010	 wd 0.0000	time 0.1230 (0.2058)	loss 1.3839 (1.3540)	grad_norm 0.3664 (inf)	loss_scale 1048576.0000 (1069975.5102)	mem 1503MB
[2024-07-14 13:42:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.0772 (0.2022)	loss 1.3229 (1.3537)	grad_norm 0.3687 (inf)	loss_scale 1048576.0000 (1069119.8721)	mem 1503MB
[2024-07-14 13:42:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 21 training takes 0:08:35
[2024-07-14 13:42:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 19.516 (19.516)	Loss 0.4146 (0.4146)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 13:42:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.174 Acc@5 97.288
[2024-07-14 13:42:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 13:42:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-14 13:43:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][0/2502]	eta 1 day, 6:22:14 lr 0.000010	 wd 0.0000	time 43.6989 (43.6989)	loss 1.3182 (1.3182)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:43:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:23:28 lr 0.000010	 wd 0.0000	time 0.1569 (0.5863)	loss 1.2751 (1.3656)	grad_norm 0.3442 (0.3581)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:44:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:14:11 lr 0.000009	 wd 0.0000	time 0.1391 (0.3700)	loss 1.1746 (1.3618)	grad_norm 0.3304 (0.3573)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:44:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:11:28 lr 0.000009	 wd 0.0000	time 0.3717 (0.3126)	loss 1.5163 (1.3656)	grad_norm 0.3605 (0.3573)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:45:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:11:39 lr 0.000009	 wd 0.0000	time 0.1794 (0.3327)	loss 1.4246 (1.3696)	grad_norm 0.3644 (0.3580)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:45:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:09:54 lr 0.000009	 wd 0.0000	time 0.1580 (0.2969)	loss 0.9011 (1.3688)	grad_norm 0.3603 (0.3578)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:45:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:39 lr 0.000009	 wd 0.0000	time 0.1472 (0.2733)	loss 1.3686 (1.3717)	grad_norm 0.3696 (0.3578)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:45:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:40 lr 0.000009	 wd 0.0000	time 0.1799 (0.2556)	loss 0.8983 (1.3673)	grad_norm 0.3588 (0.3579)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:46:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:07:13 lr 0.000009	 wd 0.0000	time 0.4512 (0.2546)	loss 1.3767 (1.3631)	grad_norm 0.3503 (0.3576)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:46:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:49 lr 0.000009	 wd 0.0000	time 0.1382 (0.2557)	loss 1.3464 (1.3622)	grad_norm 0.3676 (0.3575)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:47:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:08 lr 0.000009	 wd 0.0000	time 0.1354 (0.2454)	loss 1.5526 (1.3643)	grad_norm 0.3650 (0.3578)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:47:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:32 lr 0.000009	 wd 0.0000	time 0.1587 (0.2371)	loss 1.4042 (1.3619)	grad_norm 0.3544 (0.3580)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:47:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:04:59 lr 0.000009	 wd 0.0000	time 0.1472 (0.2301)	loss 1.3441 (1.3607)	grad_norm 0.3465 (0.3579)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:48:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:04:54 lr 0.000009	 wd 0.0000	time 0.1569 (0.2450)	loss 0.9435 (1.3612)	grad_norm 0.3576 (0.3577)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:48:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:24 lr 0.000008	 wd 0.0000	time 0.1811 (0.2400)	loss 1.5606 (1.3632)	grad_norm 0.3565 (0.3577)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:48:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:03:55 lr 0.000008	 wd 0.0000	time 0.1514 (0.2348)	loss 1.3279 (1.3638)	grad_norm 0.3562 (0.3578)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:49:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:27 lr 0.000008	 wd 0.0000	time 0.1171 (0.2298)	loss 1.5438 (1.3641)	grad_norm 0.3664 (0.3578)	loss_scale 2097152.0000 (1083943.3354)	mem 1503MB
[2024-07-14 13:49:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:02 lr 0.000008	 wd 0.0000	time 0.2331 (0.2270)	loss 1.3126 (1.3638)	grad_norm 0.3459 (inf)	loss_scale 1048576.0000 (1113919.3604)	mem 1503MB
[2024-07-14 13:49:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:39 lr 0.000008	 wd 0.0000	time 0.1333 (0.2274)	loss 1.5797 (1.3631)	grad_norm 0.3663 (inf)	loss_scale 1048576.0000 (1110291.1893)	mem 1503MB
[2024-07-14 13:50:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:15 lr 0.000008	 wd 0.0000	time 0.1344 (0.2246)	loss 1.5409 (1.3626)	grad_norm 0.3638 (inf)	loss_scale 1048576.0000 (1107044.7301)	mem 1503MB
[2024-07-14 13:50:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:51 lr 0.000008	 wd 0.0000	time 0.1829 (0.2218)	loss 1.5182 (1.3617)	grad_norm 0.3385 (inf)	loss_scale 1048576.0000 (1104122.7546)	mem 1503MB
[2024-07-14 13:50:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:28 lr 0.000008	 wd 0.0000	time 0.1454 (0.2192)	loss 1.4293 (1.3622)	grad_norm 0.3627 (inf)	loss_scale 1048576.0000 (1101478.9300)	mem 1503MB
[2024-07-14 13:50:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:05 lr 0.000008	 wd 0.0000	time 0.2068 (0.2171)	loss 1.4340 (1.3604)	grad_norm 0.3608 (inf)	loss_scale 1048576.0000 (1099075.3439)	mem 1503MB
[2024-07-14 13:51:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:43 lr 0.000008	 wd 0.0000	time 0.1658 (0.2175)	loss 1.5035 (1.3605)	grad_norm 0.3739 (inf)	loss_scale 1048576.0000 (1096880.6745)	mem 1503MB
[2024-07-14 13:51:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:22 lr 0.000008	 wd 0.0000	time 0.1552 (0.2158)	loss 1.2133 (1.3599)	grad_norm 0.3597 (inf)	loss_scale 1048576.0000 (1094868.8180)	mem 1503MB
[2024-07-14 13:51:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.0771 (0.2117)	loss 0.9897 (1.3589)	grad_norm 0.3590 (inf)	loss_scale 1048576.0000 (1093017.8457)	mem 1503MB
[2024-07-14 13:51:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 22 training takes 0:08:57
[2024-07-14 13:52:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 19.842 (19.842)	Loss 0.4141 (0.4141)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 13:52:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.168 Acc@5 97.298
[2024-07-14 13:52:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 13:52:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-14 13:53:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][0/2502]	eta 1 day, 3:59:30 lr 0.000008	 wd 0.0000	time 40.2759 (40.2759)	loss 1.1631 (1.1631)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:53:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:22:17 lr 0.000008	 wd 0.0000	time 0.1324 (0.5569)	loss 1.5780 (1.3953)	grad_norm 0.3537 (0.3601)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:53:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:13:39 lr 0.000007	 wd 0.0000	time 0.1682 (0.3559)	loss 1.5511 (1.3750)	grad_norm 0.3664 (0.3592)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:54:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:10:35 lr 0.000007	 wd 0.0000	time 0.1266 (0.2886)	loss 1.5182 (1.3683)	grad_norm 0.3659 (0.3587)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:54:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:10:45 lr 0.000007	 wd 0.0000	time 0.7755 (0.3072)	loss 1.5278 (1.3598)	grad_norm 0.3506 (0.3590)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:55:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:09:48 lr 0.000007	 wd 0.0000	time 0.1649 (0.2938)	loss 1.6837 (1.3646)	grad_norm 0.3577 (0.3591)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:55:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:08:35 lr 0.000007	 wd 0.0000	time 0.1399 (0.2709)	loss 1.1310 (1.3645)	grad_norm 0.3587 (0.3589)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:55:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:37 lr 0.000007	 wd 0.0000	time 0.1286 (0.2540)	loss 1.4186 (1.3618)	grad_norm 0.3536 (0.3587)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:55:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:07:00 lr 0.000007	 wd 0.0000	time 0.3225 (0.2468)	loss 1.6866 (1.3606)	grad_norm 0.3369 (0.3585)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:56:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:07:03 lr 0.000007	 wd 0.0000	time 0.1647 (0.2643)	loss 1.7077 (1.3572)	grad_norm 0.3709 (0.3584)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:56:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:20 lr 0.000007	 wd 0.0000	time 0.1593 (0.2535)	loss 1.1432 (1.3552)	grad_norm 0.3498 (0.3583)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:57:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:42 lr 0.000007	 wd 0.0000	time 0.1334 (0.2444)	loss 0.8838 (1.3508)	grad_norm 0.3535 (0.3584)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:57:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:08 lr 0.000007	 wd 0.0000	time 0.1577 (0.2370)	loss 1.5618 (1.3527)	grad_norm 0.3578 (0.3585)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:57:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:04:42 lr 0.000007	 wd 0.0000	time 0.2756 (0.2349)	loss 1.4500 (1.3542)	grad_norm 0.3530 (0.3587)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:58:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:18 lr 0.000007	 wd 0.0000	time 0.1599 (0.2342)	loss 1.5844 (1.3541)	grad_norm 0.3512 (0.3587)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:58:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:03:49 lr 0.000006	 wd 0.0000	time 0.1630 (0.2290)	loss 1.2788 (1.3563)	grad_norm 0.3642 (0.3586)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:58:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:22 lr 0.000006	 wd 0.0000	time 0.1483 (0.2247)	loss 1.1704 (1.3557)	grad_norm 0.3552 (0.3585)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:58:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:02:57 lr 0.000006	 wd 0.0000	time 0.2375 (0.2209)	loss 1.3224 (1.3560)	grad_norm 0.3549 (0.3586)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:59:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:34 lr 0.000006	 wd 0.0000	time 0.3617 (0.2204)	loss 1.4362 (1.3554)	grad_norm 0.3552 (0.3587)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:59:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:14 lr 0.000006	 wd 0.0000	time 0.1176 (0.2237)	loss 1.2340 (1.3581)	grad_norm 0.3598 (0.3586)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 13:59:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:01:50 lr 0.000006	 wd 0.0000	time 0.1344 (0.2206)	loss 1.4557 (1.3569)	grad_norm 0.3603 (0.3586)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:00:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:27 lr 0.000006	 wd 0.0000	time 0.1924 (0.2181)	loss 1.6975 (1.3574)	grad_norm 0.3546 (0.3585)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:00:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:05 lr 0.000006	 wd 0.0000	time 0.1424 (0.2157)	loss 1.4715 (1.3552)	grad_norm 0.3659 (0.3585)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:00:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:43 lr 0.000006	 wd 0.0000	time 0.1476 (0.2148)	loss 1.5943 (1.3554)	grad_norm 0.3544 (0.3585)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:01:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:21 lr 0.000006	 wd 0.0000	time 0.1953 (0.2142)	loss 1.5451 (1.3560)	grad_norm 0.3529 (0.3586)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:01:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000006	 wd 0.0000	time 0.0771 (0.2106)	loss 1.4371 (1.3567)	grad_norm 0.3623 (0.3586)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:01:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 23 training takes 0:08:55
[2024-07-14 14:01:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 21.304 (21.304)	Loss 0.4146 (0.4146)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 14:02:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.174 Acc@5 97.288
[2024-07-14 14:02:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 14:02:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-14 14:02:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][0/2502]	eta 1 day, 0:15:23 lr 0.000006	 wd 0.0000	time 34.9015 (34.9015)	loss 1.5842 (1.5842)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:03:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:20:19 lr 0.000006	 wd 0.0000	time 0.1062 (0.5079)	loss 1.1425 (1.3964)	grad_norm 0.3656 (0.3602)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:03:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:12:41 lr 0.000006	 wd 0.0000	time 0.2024 (0.3310)	loss 1.4162 (1.3781)	grad_norm 0.3545 (0.3590)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:03:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:10:02 lr 0.000006	 wd 0.0000	time 0.1339 (0.2734)	loss 1.6310 (1.3712)	grad_norm 0.3761 (0.3588)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:03:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:08:34 lr 0.000005	 wd 0.0000	time 0.1305 (0.2447)	loss 1.4055 (1.3677)	grad_norm 0.3629 (0.3594)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:04:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:09:19 lr 0.000005	 wd 0.0000	time 0.2490 (0.2797)	loss 1.6679 (1.3691)	grad_norm 0.3641 (0.3594)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:04:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:08:13 lr 0.000005	 wd 0.0000	time 0.1233 (0.2595)	loss 1.3984 (1.3661)	grad_norm 0.3572 (0.3597)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:05:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:07:21 lr 0.000005	 wd 0.0000	time 0.1511 (0.2448)	loss 1.3449 (1.3672)	grad_norm 0.3589 (0.3599)	loss_scale 2097152.0000 (1126359.0984)	mem 1503MB
[2024-07-14 14:05:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:06:36 lr 0.000005	 wd 0.0000	time 0.1231 (0.2329)	loss 1.4106 (1.3683)	grad_norm 0.3681 (0.3596)	loss_scale 2097152.0000 (1247556.7141)	mem 1503MB
[2024-07-14 14:05:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:06:02 lr 0.000005	 wd 0.0000	time 0.2325 (0.2261)	loss 1.5554 (1.3652)	grad_norm 0.3750 (inf)	loss_scale 1048576.0000 (1267368.7725)	mem 1503MB
[2024-07-14 14:06:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:06 lr 0.000005	 wd 0.0000	time 0.1620 (0.2441)	loss 1.2191 (1.3656)	grad_norm 0.3641 (inf)	loss_scale 1048576.0000 (1245511.3526)	mem 1503MB
[2024-07-14 14:06:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:05:30 lr 0.000005	 wd 0.0000	time 0.1526 (0.2360)	loss 1.4981 (1.3645)	grad_norm 0.3564 (inf)	loss_scale 1048576.0000 (1227624.3996)	mem 1503MB
[2024-07-14 14:06:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:04:58 lr 0.000005	 wd 0.0000	time 0.1458 (0.2294)	loss 1.2510 (1.3626)	grad_norm 0.3530 (inf)	loss_scale 1048576.0000 (1212716.1232)	mem 1503MB
[2024-07-14 14:07:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:04:29 lr 0.000005	 wd 0.0000	time 0.1978 (0.2238)	loss 1.3961 (1.3620)	grad_norm 0.3696 (inf)	loss_scale 1048576.0000 (1200099.6649)	mem 1503MB
[2024-07-14 14:07:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:16 lr 0.000005	 wd 0.0000	time 0.2711 (0.2332)	loss 1.3466 (1.3605)	grad_norm 0.3714 (inf)	loss_scale 1048576.0000 (1189284.2712)	mem 1503MB
[2024-07-14 14:07:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:03:51 lr 0.000005	 wd 0.0000	time 0.1585 (0.2307)	loss 0.9799 (1.3589)	grad_norm 0.3541 (inf)	loss_scale 1048576.0000 (1179909.9694)	mem 1503MB
[2024-07-14 14:08:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:24 lr 0.000005	 wd 0.0000	time 0.1390 (0.2262)	loss 1.5166 (1.3586)	grad_norm 0.3559 (inf)	loss_scale 1048576.0000 (1171706.7233)	mem 1503MB
[2024-07-14 14:08:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:02:58 lr 0.000005	 wd 0.0000	time 0.1711 (0.2222)	loss 1.6928 (1.3597)	grad_norm 0.3590 (inf)	loss_scale 1048576.0000 (1164467.9976)	mem 1503MB
[2024-07-14 14:08:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:34 lr 0.000005	 wd 0.0000	time 0.1801 (0.2197)	loss 1.1336 (1.3577)	grad_norm 0.3542 (inf)	loss_scale 1048576.0000 (1158033.1283)	mem 1503MB
[2024-07-14 14:09:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:12 lr 0.000005	 wd 0.0000	time 0.1590 (0.2209)	loss 1.4198 (1.3588)	grad_norm 0.3620 (inf)	loss_scale 1048576.0000 (1152275.2572)	mem 1503MB
[2024-07-14 14:09:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:01:49 lr 0.000004	 wd 0.0000	time 0.1524 (0.2185)	loss 1.3874 (1.3594)	grad_norm 0.3620 (inf)	loss_scale 1048576.0000 (1147092.8856)	mem 1503MB
[2024-07-14 14:09:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:26 lr 0.000004	 wd 0.0000	time 0.1358 (0.2160)	loss 1.5441 (1.3585)	grad_norm 0.3657 (inf)	loss_scale 1048576.0000 (1142403.8382)	mem 1503MB
[2024-07-14 14:10:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:04 lr 0.000004	 wd 0.0000	time 0.1777 (0.2137)	loss 1.4080 (1.3583)	grad_norm 0.3642 (inf)	loss_scale 1048576.0000 (1138140.8741)	mem 1503MB
[2024-07-14 14:10:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:42 lr 0.000004	 wd 0.0000	time 0.2034 (0.2118)	loss 1.7441 (1.3580)	grad_norm 0.3625 (inf)	loss_scale 1048576.0000 (1134248.4415)	mem 1503MB
[2024-07-14 14:10:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:21 lr 0.000004	 wd 0.0000	time 0.1749 (0.2113)	loss 1.4940 (1.3579)	grad_norm 0.3519 (inf)	loss_scale 1048576.0000 (1130680.2432)	mem 1503MB
[2024-07-14 14:10:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000004	 wd 0.0000	time 0.0769 (0.2088)	loss 1.2611 (1.3581)	grad_norm 0.3704 (inf)	loss_scale 1048576.0000 (1127397.3866)	mem 1503MB
[2024-07-14 14:11:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 24 training takes 0:08:52
[2024-07-14 14:11:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 19.312 (19.312)	Loss 0.4150 (0.4150)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 14:11:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.180 Acc@5 97.286
[2024-07-14 14:11:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 14:11:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-14 14:12:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][0/2502]	eta 14:45:51 lr 0.000004	 wd 0.0000	time 21.2435 (21.2435)	loss 1.2497 (1.2497)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:12:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:20:25 lr 0.000004	 wd 0.0000	time 0.1042 (0.5104)	loss 1.3942 (1.3271)	grad_norm 0.3532 (0.3577)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:12:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:12:48 lr 0.000004	 wd 0.0000	time 0.1426 (0.3337)	loss 1.4851 (1.3545)	grad_norm 0.3402 (0.3582)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:13:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:10:05 lr 0.000004	 wd 0.0000	time 0.1385 (0.2750)	loss 1.1166 (1.3445)	grad_norm 0.3488 (0.3583)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:13:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:08:36 lr 0.000004	 wd 0.0000	time 0.2004 (0.2456)	loss 1.2432 (1.3595)	grad_norm 0.3570 (0.3589)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:13:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:07:40 lr 0.000004	 wd 0.0000	time 0.2026 (0.2301)	loss 1.5618 (1.3594)	grad_norm 0.3523 (0.3591)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:14:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:06 lr 0.000004	 wd 0.0000	time 0.1636 (0.2556)	loss 1.1476 (1.3610)	grad_norm 0.3565 (0.3592)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:14:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:07:14 lr 0.000004	 wd 0.0000	time 0.0988 (0.2411)	loss 1.2383 (1.3613)	grad_norm 0.3616 (0.3591)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:14:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:06:32 lr 0.000004	 wd 0.0000	time 0.1783 (0.2307)	loss 1.0021 (1.3614)	grad_norm 0.3625 (0.3593)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:14:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:05:55 lr 0.000004	 wd 0.0000	time 0.1090 (0.2220)	loss 1.5055 (1.3633)	grad_norm 0.3562 (0.3595)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:15:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:05:27 lr 0.000004	 wd 0.0000	time 0.2721 (0.2180)	loss 1.2236 (1.3638)	grad_norm 0.3626 (0.3596)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:15:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:17 lr 0.000004	 wd 0.0000	time 0.1317 (0.2262)	loss 1.2890 (1.3618)	grad_norm 0.3716 (0.3596)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:16:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:04:46 lr 0.000004	 wd 0.0000	time 0.1675 (0.2202)	loss 1.3496 (1.3642)	grad_norm 0.3635 (0.3596)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:16:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:04:18 lr 0.000003	 wd 0.0000	time 0.1583 (0.2152)	loss 1.4841 (1.3659)	grad_norm 0.3755 (0.3596)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:16:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:03:52 lr 0.000003	 wd 0.0000	time 0.2100 (0.2110)	loss 1.1240 (1.3654)	grad_norm 0.3498 (0.3595)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:16:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:03:29 lr 0.000003	 wd 0.0000	time 0.2509 (0.2089)	loss 1.2391 (1.3655)	grad_norm 0.3619 (0.3595)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:17:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:15 lr 0.000003	 wd 0.0000	time 0.1748 (0.2164)	loss 1.4950 (1.3648)	grad_norm 0.3491 (0.3595)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:17:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:02:50 lr 0.000003	 wd 0.0000	time 0.1300 (0.2131)	loss 1.3886 (1.3641)	grad_norm 0.3570 (0.3595)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:17:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:27 lr 0.000003	 wd 0.0000	time 0.1127 (0.2104)	loss 1.5568 (1.3639)	grad_norm 0.3732 (0.3593)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:18:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:05 lr 0.000003	 wd 0.0000	time 0.1387 (0.2080)	loss 1.9443 (1.3637)	grad_norm 0.3492 (0.3592)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:18:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:01:44 lr 0.000003	 wd 0.0000	time 0.3671 (0.2083)	loss 1.2730 (1.3631)	grad_norm 0.3558 (0.3591)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:19:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:25 lr 0.000003	 wd 0.0000	time 0.1270 (0.2119)	loss 0.8831 (1.3631)	grad_norm 0.3684 (0.3591)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:19:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:03 lr 0.000003	 wd 0.0000	time 0.1225 (0.2096)	loss 1.4453 (1.3619)	grad_norm 0.3465 (0.3591)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:19:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:41 lr 0.000003	 wd 0.0000	time 0.1207 (0.2077)	loss 1.2034 (1.3605)	grad_norm 0.3287 (0.3590)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:19:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:20 lr 0.000003	 wd 0.0000	time 0.1135 (0.2058)	loss 1.3947 (1.3620)	grad_norm 0.3560 (inf)	loss_scale 1048576.0000 (1065171.5385)	mem 1503MB
[2024-07-14 14:20:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.0769 (0.2024)	loss 1.4839 (1.3621)	grad_norm 0.3752 (inf)	loss_scale 1048576.0000 (1064507.9824)	mem 1503MB
[2024-07-14 14:20:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 25 training takes 0:08:35
[2024-07-14 14:20:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 39.982 (39.982)	Loss 0.4150 (0.4150)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 14:21:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.174 Acc@5 97.290
[2024-07-14 14:21:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 14:21:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-14 14:21:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][0/2502]	eta 10:44:47 lr 0.000003	 wd 0.0000	time 15.4624 (15.4624)	loss 1.3264 (1.3264)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:21:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:16:09 lr 0.000003	 wd 0.0000	time 0.4530 (0.4038)	loss 1.5167 (1.3552)	grad_norm 0.3483 (0.3616)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:22:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:13:30 lr 0.000003	 wd 0.0000	time 0.1541 (0.3522)	loss 1.4824 (1.3758)	grad_norm 0.3604 (0.3607)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:22:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:10:27 lr 0.000003	 wd 0.0000	time 0.1366 (0.2852)	loss 1.4836 (1.3672)	grad_norm 0.3722 (0.3598)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:22:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:08:50 lr 0.000003	 wd 0.0000	time 0.1693 (0.2522)	loss 1.6399 (1.3690)	grad_norm 0.3488 (0.3594)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:23:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:07:43 lr 0.000003	 wd 0.0000	time 0.1424 (0.2317)	loss 1.6286 (1.3756)	grad_norm 0.3689 (0.3592)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:23:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:08:00 lr 0.000003	 wd 0.0000	time 0.2555 (0.2526)	loss 1.4006 (1.3707)	grad_norm 0.3655 (0.3594)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:24:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:25 lr 0.000003	 wd 0.0000	time 0.1357 (0.2473)	loss 1.5406 (1.3666)	grad_norm 0.3408 (0.3593)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:24:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:06:41 lr 0.000002	 wd 0.0000	time 0.1576 (0.2361)	loss 1.6078 (1.3654)	grad_norm 0.3570 (0.3594)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:24:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:06:03 lr 0.000002	 wd 0.0000	time 0.1090 (0.2268)	loss 1.3852 (1.3654)	grad_norm 0.3637 (0.3593)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:24:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:05:32 lr 0.000002	 wd 0.0000	time 0.2320 (0.2213)	loss 1.4211 (1.3659)	grad_norm 0.3683 (0.3593)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:25:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:32 lr 0.000002	 wd 0.0000	time 0.1834 (0.2369)	loss 1.5921 (1.3674)	grad_norm 0.3479 (0.3593)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:25:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:04:59 lr 0.000002	 wd 0.0000	time 0.1611 (0.2303)	loss 1.0815 (1.3678)	grad_norm 0.3848 (0.3593)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:26:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:04:30 lr 0.000002	 wd 0.0000	time 0.1777 (0.2248)	loss 0.9510 (1.3660)	grad_norm 0.3731 (0.3593)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:26:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:02 lr 0.000002	 wd 0.0000	time 0.1245 (0.2197)	loss 1.5885 (1.3654)	grad_norm 0.3533 (0.3594)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:26:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:03:41 lr 0.000002	 wd 0.0000	time 0.4936 (0.2215)	loss 1.4003 (1.3642)	grad_norm 0.3707 (0.3594)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:27:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:22 lr 0.000002	 wd 0.0000	time 0.1815 (0.2243)	loss 1.4538 (1.3631)	grad_norm 0.3615 (0.3593)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:27:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:02:56 lr 0.000002	 wd 0.0000	time 0.1779 (0.2205)	loss 1.2748 (1.3641)	grad_norm 0.3644 (0.3594)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:27:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:32 lr 0.000002	 wd 0.0000	time 0.1352 (0.2175)	loss 1.5290 (1.3670)	grad_norm 0.3542 (0.3595)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:28:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:09 lr 0.000002	 wd 0.0000	time 0.1476 (0.2150)	loss 0.9764 (1.3655)	grad_norm 0.3541 (0.3594)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:28:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:01:47 lr 0.000002	 wd 0.0000	time 0.1812 (0.2143)	loss 0.9078 (1.3645)	grad_norm 0.3818 (0.3594)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:28:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:26 lr 0.000002	 wd 0.0000	time 0.1183 (0.2145)	loss 1.1224 (1.3635)	grad_norm 0.3625 (0.3594)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:29:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:04 lr 0.000002	 wd 0.0000	time 0.1791 (0.2123)	loss 0.9658 (1.3632)	grad_norm 0.3711 (0.3593)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:29:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:42 lr 0.000002	 wd 0.0000	time 0.2286 (0.2104)	loss 1.2027 (1.3621)	grad_norm 0.3681 (0.3593)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:29:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:21 lr 0.000002	 wd 0.0000	time 0.1745 (0.2086)	loss 1.1192 (1.3622)	grad_norm 0.3672 (0.3593)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:29:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.0767 (0.2051)	loss 0.9474 (1.3604)	grad_norm 0.3562 (0.3593)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:29:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 26 training takes 0:08:40
[2024-07-14 14:30:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 40.551 (40.551)	Loss 0.4146 (0.4146)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 14:30:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.160 Acc@5 97.288
[2024-07-14 14:30:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 14:30:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-14 14:31:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][0/2502]	eta 10:47:52 lr 0.000002	 wd 0.0000	time 15.5365 (15.5365)	loss 0.9335 (0.9335)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:31:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:15:06 lr 0.000002	 wd 0.0000	time 0.3442 (0.3773)	loss 1.4886 (1.3674)	grad_norm 0.3546 (0.3583)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:31:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:12:33 lr 0.000002	 wd 0.0000	time 0.1648 (0.3274)	loss 1.5798 (1.3622)	grad_norm 0.3649 (0.3589)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:32:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:09:54 lr 0.000002	 wd 0.0000	time 0.1587 (0.2698)	loss 1.3619 (1.3625)	grad_norm 0.3532 (0.3590)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:32:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:08:27 lr 0.000002	 wd 0.0000	time 0.1492 (0.2415)	loss 1.4449 (1.3601)	grad_norm 0.3620 (0.3589)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:32:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:07:27 lr 0.000002	 wd 0.0000	time 0.1438 (0.2235)	loss 0.9789 (1.3560)	grad_norm 0.3811 (0.3589)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:33:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:06:59 lr 0.000002	 wd 0.0000	time 0.3244 (0.2208)	loss 1.2735 (1.3591)	grad_norm 0.3654 (0.3590)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:33:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:18 lr 0.000002	 wd 0.0000	time 0.1024 (0.2436)	loss 1.4829 (1.3648)	grad_norm 0.3646 (0.3590)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:33:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:06:35 lr 0.000002	 wd 0.0000	time 0.1580 (0.2323)	loss 1.5242 (1.3682)	grad_norm 0.3543 (0.3593)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:34:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:05:58 lr 0.000001	 wd 0.0000	time 0.1839 (0.2238)	loss 1.2857 (1.3729)	grad_norm 0.3412 (0.3594)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:34:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:05:26 lr 0.000001	 wd 0.0000	time 0.1542 (0.2172)	loss 1.4282 (1.3711)	grad_norm 0.3454 (0.3594)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:35:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:16 lr 0.000001	 wd 0.0000	time 0.1721 (0.2255)	loss 1.5155 (1.3710)	grad_norm 0.3544 (0.3595)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:35:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:04:47 lr 0.000001	 wd 0.0000	time 0.1445 (0.2206)	loss 1.4929 (1.3709)	grad_norm 0.3732 (0.3593)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:35:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:19 lr 0.000001	 wd 0.0000	time 0.1481 (0.2156)	loss 1.4850 (1.3681)	grad_norm 0.3555 (0.3591)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:35:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:03:53 lr 0.000001	 wd 0.0000	time 0.1771 (0.2115)	loss 1.2726 (1.3685)	grad_norm 0.3671 (0.3591)	loss_scale 2097152.0000 (1072526.3440)	mem 1503MB
[2024-07-14 14:36:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:03:28 lr 0.000001	 wd 0.0000	time 0.1573 (0.2080)	loss 1.5357 (1.3682)	grad_norm 0.3431 (inf)	loss_scale 1048576.0000 (1110051.4750)	mem 1503MB
[2024-07-14 14:36:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:07 lr 0.000001	 wd 0.0000	time 0.1637 (0.2074)	loss 1.5569 (1.3662)	grad_norm 0.3671 (inf)	loss_scale 1048576.0000 (1106211.6577)	mem 1503MB
[2024-07-14 14:36:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:02:46 lr 0.000001	 wd 0.0000	time 0.1987 (0.2074)	loss 1.3915 (1.3640)	grad_norm 0.3607 (inf)	loss_scale 1048576.0000 (1102823.3180)	mem 1503MB
[2024-07-14 14:37:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:24 lr 0.000001	 wd 0.0000	time 0.1209 (0.2052)	loss 1.5128 (1.3645)	grad_norm 0.3631 (inf)	loss_scale 1048576.0000 (1099811.2515)	mem 1503MB
[2024-07-14 14:37:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:02 lr 0.000001	 wd 0.0000	time 0.1452 (0.2031)	loss 1.0793 (1.3660)	grad_norm 0.3619 (inf)	loss_scale 1048576.0000 (1097116.0779)	mem 1503MB
[2024-07-14 14:37:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:41 lr 0.000001	 wd 0.0000	time 0.2349 (0.2013)	loss 1.0591 (1.3648)	grad_norm 0.3597 (inf)	loss_scale 1048576.0000 (1094690.2869)	mem 1503MB
[2024-07-14 14:37:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:20 lr 0.000001	 wd 0.0000	time 0.2785 (0.2010)	loss 1.7048 (1.3641)	grad_norm 0.3638 (inf)	loss_scale 1048576.0000 (1092495.4136)	mem 1503MB
[2024-07-14 14:38:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:00 lr 0.000001	 wd 0.0000	time 0.1805 (0.2019)	loss 1.0908 (1.3648)	grad_norm 0.3596 (inf)	loss_scale 1048576.0000 (1090499.9836)	mem 1503MB
[2024-07-14 14:38:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:40 lr 0.000001	 wd 0.0000	time 0.1998 (0.2007)	loss 1.4507 (1.3649)	grad_norm 0.3521 (inf)	loss_scale 1048576.0000 (1088677.9939)	mem 1503MB
[2024-07-14 14:38:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:20 lr 0.000001	 wd 0.0000	time 0.1448 (0.1993)	loss 1.3752 (1.3645)	grad_norm 0.3615 (inf)	loss_scale 1048576.0000 (1087007.7734)	mem 1503MB
[2024-07-14 14:39:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.0769 (0.1959)	loss 1.5045 (1.3629)	grad_norm 0.3401 (inf)	loss_scale 1048576.0000 (1085471.1172)	mem 1503MB
[2024-07-14 14:39:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 27 training takes 0:08:19
[2024-07-14 14:39:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 46.265 (46.265)	Loss 0.4150 (0.4150)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 14:40:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.168 Acc@5 97.296
[2024-07-14 14:40:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 14:40:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-14 14:40:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][0/2502]	eta 11:05:51 lr 0.000001	 wd 0.0000	time 15.9679 (15.9679)	loss 1.2949 (1.2949)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:40:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:12:54 lr 0.000001	 wd 0.0000	time 0.1612 (0.3223)	loss 1.0672 (1.3435)	grad_norm 0.3682 (0.3591)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:41:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:10:56 lr 0.000001	 wd 0.0000	time 0.4753 (0.2853)	loss 1.0684 (1.3474)	grad_norm 0.3762 (0.3598)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:41:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:11:23 lr 0.000001	 wd 0.0000	time 0.1650 (0.3103)	loss 1.6360 (1.3578)	grad_norm 0.3678 (0.3603)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:42:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:09:30 lr 0.000001	 wd 0.0000	time 0.1676 (0.2713)	loss 1.3895 (1.3623)	grad_norm 0.3541 (0.3606)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:42:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:08:15 lr 0.000001	 wd 0.0000	time 0.1396 (0.2473)	loss 1.5677 (1.3643)	grad_norm 0.3526 (0.3603)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:42:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:07:23 lr 0.000001	 wd 0.0000	time 0.1978 (0.2330)	loss 1.3928 (1.3641)	grad_norm 0.3551 (0.3598)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:43:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:33 lr 0.000001	 wd 0.0000	time 0.1807 (0.2518)	loss 1.0224 (1.3660)	grad_norm 0.3589 (0.3599)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:43:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:06:48 lr 0.000001	 wd 0.0000	time 0.1507 (0.2400)	loss 1.6178 (1.3632)	grad_norm 0.3602 (0.3600)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:43:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:09 lr 0.000001	 wd 0.0000	time 0.1699 (0.2306)	loss 1.5337 (1.3637)	grad_norm 0.3701 (0.3601)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:44:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:05:34 lr 0.000001	 wd 0.0000	time 0.1402 (0.2228)	loss 1.5523 (1.3664)	grad_norm 0.3612 (0.3602)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:44:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:06 lr 0.000001	 wd 0.0000	time 0.3549 (0.2187)	loss 0.9458 (1.3628)	grad_norm 0.3762 (0.3600)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:45:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:07 lr 0.000001	 wd 0.0000	time 0.1522 (0.2363)	loss 1.2186 (1.3631)	grad_norm 0.3749 (0.3601)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:45:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:04:36 lr 0.000001	 wd 0.0000	time 0.1736 (0.2301)	loss 1.5650 (1.3599)	grad_norm 0.3702 (0.3599)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:45:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:07 lr 0.000001	 wd 0.0000	time 0.1639 (0.2250)	loss 0.9293 (1.3610)	grad_norm 0.3628 (0.3598)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:45:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:03:40 lr 0.000001	 wd 0.0000	time 0.1596 (0.2204)	loss 1.4833 (1.3596)	grad_norm 0.3641 (0.3598)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:46:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:26 lr 0.000001	 wd 0.0000	time 0.3284 (0.2289)	loss 1.1902 (1.3591)	grad_norm 0.3685 (0.3597)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:46:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:00 lr 0.000001	 wd 0.0000	time 0.1874 (0.2256)	loss 1.4206 (1.3605)	grad_norm 0.3678 (0.3597)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:46:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:35 lr 0.000001	 wd 0.0000	time 0.1147 (0.2220)	loss 1.3831 (1.3602)	grad_norm 0.3632 (0.3598)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:47:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:11 lr 0.000001	 wd 0.0000	time 0.2074 (0.2190)	loss 1.5418 (1.3592)	grad_norm 0.3693 (0.3598)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:47:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:01:48 lr 0.000001	 wd 0.0000	time 0.1954 (0.2167)	loss 0.8802 (1.3591)	grad_norm 0.3628 (0.3598)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:47:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:27 lr 0.000001	 wd 0.0000	time 0.1849 (0.2179)	loss 1.0908 (1.3594)	grad_norm 0.3661 (0.3597)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:48:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:05 lr 0.000001	 wd 0.0000	time 0.1377 (0.2157)	loss 1.5269 (1.3583)	grad_norm 0.3543 (0.3597)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:48:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:43 lr 0.000001	 wd 0.0000	time 0.1348 (0.2135)	loss 1.0948 (1.3584)	grad_norm 0.3637 (0.3598)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:48:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:21 lr 0.000001	 wd 0.0000	time 0.2471 (0.2116)	loss 1.5665 (1.3569)	grad_norm 0.3697 (0.3597)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:48:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.0769 (0.2076)	loss 1.1951 (1.3561)	grad_norm 0.3645 (0.3597)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:49:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 28 training takes 0:08:47
[2024-07-14 14:49:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 40.986 (40.986)	Loss 0.4146 (0.4146)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 14:50:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.166 Acc@5 97.292
[2024-07-14 14:50:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 14:50:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-14 14:50:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][0/2502]	eta 11:09:14 lr 0.000001	 wd 0.0000	time 16.0490 (16.0490)	loss 1.4096 (1.4096)	grad_norm 0.0000 (0.0000)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:50:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:12:32 lr 0.000001	 wd 0.0000	time 0.1576 (0.3135)	loss 1.4685 (1.3375)	grad_norm 0.3531 (0.3577)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:51:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:13:49 lr 0.000001	 wd 0.0000	time 0.1433 (0.3605)	loss 1.1515 (1.3523)	grad_norm 0.3647 (0.3606)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:51:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:10:51 lr 0.000001	 wd 0.0000	time 0.1491 (0.2957)	loss 1.4926 (1.3510)	grad_norm 0.3514 (0.3599)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:51:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:09:07 lr 0.000001	 wd 0.0000	time 0.1934 (0.2607)	loss 1.1781 (1.3599)	grad_norm 0.3696 (0.3601)	loss_scale 1048576.0000 (1048576.0000)	mem 1503MB
[2024-07-14 14:52:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:07:58 lr 0.000001	 wd 0.0000	time 0.1908 (0.2390)	loss 0.9447 (1.3615)	grad_norm 0.3550 (0.3602)	loss_scale 2097152.0000 (1149038.3713)	mem 1503MB
[2024-07-14 14:52:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:07:09 lr 0.000000	 wd 0.0000	time 0.1734 (0.2260)	loss 1.3460 (1.3625)	grad_norm 0.3424 (inf)	loss_scale 1048576.0000 (1230026.7554)	mem 1503MB
[2024-07-14 14:53:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:35 lr 0.000000	 wd 0.0000	time 0.1617 (0.2525)	loss 1.5704 (1.3633)	grad_norm 0.3736 (inf)	loss_scale 1048576.0000 (1204142.1969)	mem 1503MB
[2024-07-14 14:53:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:06:48 lr 0.000000	 wd 0.0000	time 0.1329 (0.2402)	loss 0.8012 (1.3644)	grad_norm 0.3506 (inf)	loss_scale 1048576.0000 (1184720.6991)	mem 1503MB
[2024-07-14 14:53:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:06:10 lr 0.000000	 wd 0.0000	time 0.1674 (0.2311)	loss 1.4240 (1.3642)	grad_norm 0.3603 (inf)	loss_scale 1048576.0000 (1169610.2997)	mem 1503MB
[2024-07-14 14:53:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:05:34 lr 0.000000	 wd 0.0000	time 0.1204 (0.2230)	loss 1.3262 (1.3639)	grad_norm 0.3609 (inf)	loss_scale 1048576.0000 (1157518.9610)	mem 1503MB
[2024-07-14 14:54:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:10 lr 0.000000	 wd 0.0000	time 0.4406 (0.2212)	loss 1.4629 (1.3644)	grad_norm 0.3411 (inf)	loss_scale 1048576.0000 (1147624.0509)	mem 1503MB
[2024-07-14 14:54:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:04:56 lr 0.000000	 wd 0.0000	time 0.1452 (0.2278)	loss 1.2626 (1.3613)	grad_norm 0.3579 (inf)	loss_scale 1048576.0000 (1139376.9192)	mem 1503MB
[2024-07-14 14:54:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:04:27 lr 0.000000	 wd 0.0000	time 0.1498 (0.2224)	loss 1.5427 (1.3622)	grad_norm 0.3711 (inf)	loss_scale 1048576.0000 (1132397.6018)	mem 1503MB
[2024-07-14 14:55:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:03:59 lr 0.000000	 wd 0.0000	time 0.1362 (0.2175)	loss 1.7672 (1.3610)	grad_norm 0.3491 (inf)	loss_scale 1048576.0000 (1126414.6181)	mem 1503MB
[2024-07-14 14:55:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:03:33 lr 0.000000	 wd 0.0000	time 0.1292 (0.2135)	loss 1.2965 (1.3623)	grad_norm 0.3628 (inf)	loss_scale 1048576.0000 (1121228.8341)	mem 1503MB
[2024-07-14 14:55:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:12 lr 0.000000	 wd 0.0000	time 0.3628 (0.2135)	loss 1.4720 (1.3637)	grad_norm 0.3589 (inf)	loss_scale 1048576.0000 (1116690.8682)	mem 1503MB
[2024-07-14 14:56:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:02:56 lr 0.000000	 wd 0.0000	time 0.1647 (0.2200)	loss 1.3009 (1.3606)	grad_norm 0.3673 (inf)	loss_scale 1048576.0000 (1112686.4668)	mem 1503MB
[2024-07-14 14:56:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:32 lr 0.000000	 wd 0.0000	time 0.1986 (0.2167)	loss 1.1659 (1.3622)	grad_norm 0.3649 (inf)	loss_scale 1048576.0000 (1109126.7518)	mem 1503MB
[2024-07-14 14:56:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:08 lr 0.000000	 wd 0.0000	time 0.1305 (0.2139)	loss 1.2318 (1.3620)	grad_norm 0.3763 (inf)	loss_scale 1048576.0000 (1105941.5466)	mem 1503MB
[2024-07-14 14:57:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:01:46 lr 0.000000	 wd 0.0000	time 0.1714 (0.2116)	loss 1.4892 (1.3621)	grad_norm 0.3848 (inf)	loss_scale 1048576.0000 (1103074.7026)	mem 1503MB
[2024-07-14 14:57:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:27 lr 0.000000	 wd 0.0000	time 0.2191 (0.2183)	loss 1.4995 (1.3626)	grad_norm 0.3614 (inf)	loss_scale 1048576.0000 (1100480.7615)	mem 1503MB
[2024-07-14 14:58:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:05 lr 0.000000	 wd 0.0000	time 0.1365 (0.2159)	loss 1.4071 (1.3642)	grad_norm 0.3663 (inf)	loss_scale 1048576.0000 (1098122.5261)	mem 1503MB
[2024-07-14 14:58:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 0.1157 (0.2136)	loss 1.4303 (1.3655)	grad_norm 0.3730 (inf)	loss_scale 1048576.0000 (1095969.2655)	mem 1503MB
[2024-07-14 14:58:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.1912 (0.2115)	loss 1.4061 (1.3661)	grad_norm 0.3637 (inf)	loss_scale 1048576.0000 (1093995.3686)	mem 1503MB
[2024-07-14 14:58:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000000	 wd 0.0000	time 0.0766 (0.2076)	loss 1.5682 (1.3653)	grad_norm 0.3606 (inf)	loss_scale 1048576.0000 (1092179.3203)	mem 1503MB
[2024-07-14 14:58:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 29 training takes 0:08:47
[2024-07-14 14:58:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_29.pth saving......
[2024-07-14 14:58:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_29.pth saved !!!
[2024-07-14 14:59:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 40.705 (40.705)	Loss 0.4146 (0.4146)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 1503MB
[2024-07-14 14:59:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 84.158 Acc@5 97.294
[2024-07-14 14:59:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 14:59:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-14 14:59:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3] (main.py 189): INFO Training time 4:46:01
