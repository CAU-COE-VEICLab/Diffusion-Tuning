[2024-07-14 23:02:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/config.json
[2024-07-14 23:02:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process0/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer0/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_swin_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 9
    - 3
    DIMS:
    - 96
    - 192
    - 384
    - 768
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: false
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: sequence_stage1
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 4.0e-05
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.0e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 4.0e-08
  WEIGHT_DECAY: 1.0e-08

[2024-07-14 23:02:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/swin/diffusion_ft_adapter_swin_base_patch4_window7_224_22kto1k_squence_stage_process1.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process0/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer0/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-14 23:02:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 108): INFO Creating model:adapter_swin_diffusion_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1
[2024-07-14 23:02:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 110): INFO Adapter_SwinTransformer_Diffusion_Finetune(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (uma): UMA(filter_strategy1=23, filter_strategy2=7,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-14 23:02:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 113): INFO number of params: 1109928
[2024-07-14 23:02:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 116): INFO number of GFLOPs: 15.438473216
[2024-07-14 23:02:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 150): INFO no checkpoint found in pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1, ignoring auto resume
[2024-07-14 23:02:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process0/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer0/ckpt_epoch_best.pth for fine-tuning......
[2024-07-14 23:02:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])
[2024-07-14 23:02:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_crosslayer_process0/diffusion_ft_adapter_swin_b_22kto1k_sequence_crosslayer0/ckpt_epoch_best.pth'
[2024-07-14 23:03:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 63.092 (63.092)	Loss 0.4192 (0.4192)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 1477MB
[2024-07-14 23:03:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.042 Acc@5 97.226
[2024-07-14 23:03:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 162): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-14 23:03:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 168): INFO Start training
[2024-07-14 23:03:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][0/2502]	eta 13:44:23 lr 0.000000	 wd 0.0000	time 19.7697 (19.7697)	loss 1.6051 (1.6051)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 7639MB
[2024-07-14 23:04:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:16:16 lr 0.000000	 wd 0.0000	time 0.2547 (0.4066)	loss 1.4206 (1.4051)	grad_norm 0.3585 (inf)	loss_scale 16384.0000 (22386.0594)	mem 7646MB
[2024-07-14 23:05:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:15:54 lr 0.000001	 wd 0.0000	time 0.2462 (0.4147)	loss 1.4343 (1.3901)	grad_norm 0.4484 (inf)	loss_scale 16384.0000 (19399.9602)	mem 7646MB
[2024-07-14 23:05:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:46 lr 0.000001	 wd 0.0000	time 0.2206 (0.3479)	loss 1.4429 (1.3709)	grad_norm 0.3935 (inf)	loss_scale 16384.0000 (18397.9801)	mem 7646MB
[2024-07-14 23:05:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:56 lr 0.000001	 wd 0.0000	time 0.2086 (0.3124)	loss 1.8423 (1.3735)	grad_norm 0.3703 (inf)	loss_scale 16384.0000 (17895.7406)	mem 7646MB
[2024-07-14 23:06:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:09:48 lr 0.000002	 wd 0.0000	time 0.2056 (0.2938)	loss 1.4950 (1.3722)	grad_norm 0.5208 (nan)	loss_scale 8192.0000 (17299.6727)	mem 7646MB
[2024-07-14 23:06:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:40 lr 0.000002	 wd 0.0000	time 0.2045 (0.3052)	loss 1.1684 (1.3717)	grad_norm 0.3590 (nan)	loss_scale 8192.0000 (15784.2529)	mem 7646MB
[2024-07-14 23:07:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:45 lr 0.000002	 wd 0.0000	time 0.2232 (0.2916)	loss 1.4230 (1.3678)	grad_norm 0.4061 (nan)	loss_scale 8192.0000 (14701.1926)	mem 7646MB
[2024-07-14 23:07:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:58 lr 0.000003	 wd 0.0000	time 0.1936 (0.2812)	loss 1.5376 (1.3688)	grad_norm 0.4308 (nan)	loss_scale 8192.0000 (13888.5593)	mem 7646MB
[2024-07-14 23:07:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:21 lr 0.000003	 wd 0.0000	time 0.3371 (0.2755)	loss 1.5624 (1.3638)	grad_norm 0.4738 (nan)	loss_scale 8192.0000 (13256.3108)	mem 7646MB
[2024-07-14 23:08:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:07:00 lr 0.000003	 wd 0.0000	time 0.1937 (0.2797)	loss 1.3698 (1.3634)	grad_norm 0.4846 (nan)	loss_scale 8192.0000 (12750.3856)	mem 7646MB
[2024-07-14 23:08:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:23 lr 0.000004	 wd 0.0000	time 0.2232 (0.2733)	loss 1.5214 (1.3643)	grad_norm 0.3793 (nan)	loss_scale 8192.0000 (12336.3633)	mem 7646MB
[2024-07-14 23:08:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:49 lr 0.000004	 wd 0.0000	time 0.2177 (0.2681)	loss 1.4721 (1.3665)	grad_norm 0.3678 (nan)	loss_scale 8192.0000 (11991.2873)	mem 7646MB
[2024-07-14 23:09:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:18 lr 0.000004	 wd 0.0000	time 0.2346 (0.2647)	loss 1.4430 (1.3684)	grad_norm 0.3861 (nan)	loss_scale 8192.0000 (11699.2590)	mem 7646MB
[2024-07-14 23:09:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:50 lr 0.000005	 wd 0.0000	time 0.1821 (0.2632)	loss 1.5562 (1.3695)	grad_norm 0.4088 (nan)	loss_scale 8192.0000 (11448.9193)	mem 7646MB
[2024-07-14 23:10:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:20 lr 0.000005	 wd 0.0000	time 0.1980 (0.2597)	loss 1.4813 (1.3694)	grad_norm 0.4134 (nan)	loss_scale 8192.0000 (11231.9360)	mem 7646MB
[2024-07-14 23:10:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:51 lr 0.000005	 wd 0.0000	time 0.2065 (0.2568)	loss 1.6007 (1.3700)	grad_norm 0.4588 (nan)	loss_scale 8192.0000 (11042.0587)	mem 7646MB
[2024-07-14 23:10:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:23 lr 0.000005	 wd 0.0000	time 0.2273 (0.2543)	loss 1.4911 (1.3690)	grad_norm 0.5975 (nan)	loss_scale 8192.0000 (10874.5068)	mem 7646MB
[2024-07-14 23:11:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:02:58 lr 0.000006	 wd 0.0000	time 0.1706 (0.2542)	loss 1.2247 (1.3696)	grad_norm 0.5313 (nan)	loss_scale 8192.0000 (10725.5614)	mem 7646MB
[2024-07-14 23:11:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:32 lr 0.000006	 wd 0.0000	time 0.2007 (0.2527)	loss 1.6294 (1.3690)	grad_norm 0.4061 (nan)	loss_scale 8192.0000 (10592.2862)	mem 7646MB
[2024-07-14 23:11:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:05 lr 0.000006	 wd 0.0000	time 0.2124 (0.2508)	loss 1.5029 (1.3671)	grad_norm 0.3774 (nan)	loss_scale 8192.0000 (10472.3318)	mem 7646MB
[2024-07-14 23:12:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:40 lr 0.000007	 wd 0.0000	time 0.2293 (0.2488)	loss 1.3675 (1.3676)	grad_norm 0.4547 (nan)	loss_scale 8192.0000 (10363.7963)	mem 7646MB
[2024-07-14 23:12:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:14 lr 0.000007	 wd 0.0000	time 0.2179 (0.2478)	loss 1.6196 (1.3684)	grad_norm 0.3464 (nan)	loss_scale 8192.0000 (10265.1231)	mem 7646MB
[2024-07-14 23:13:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:49 lr 0.000007	 wd 0.0000	time 0.2050 (0.2472)	loss 1.5367 (1.3673)	grad_norm 0.3742 (nan)	loss_scale 8192.0000 (10175.0265)	mem 7646MB
[2024-07-14 23:13:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:25 lr 0.000008	 wd 0.0000	time 0.2190 (0.2457)	loss 1.4024 (1.3674)	grad_norm 0.3803 (nan)	loss_scale 8192.0000 (10092.4348)	mem 7646MB
[2024-07-14 23:13:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1513 (0.2430)	loss 1.6308 (1.3676)	grad_norm 0.3384 (nan)	loss_scale 8192.0000 (10016.4478)	mem 7646MB
[2024-07-14 23:13:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 0 training takes 0:10:12
[2024-07-14 23:13:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_0.pth saving......
[2024-07-14 23:13:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_0.pth saved !!!
[2024-07-14 23:14:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 60.164 (60.164)	Loss 0.4199 (0.4199)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-14 23:15:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.030 Acc@5 97.212
[2024-07-14 23:15:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-14 23:15:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.03%
[2024-07-14 23:15:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_best.pth saving......
[2024-07-14 23:15:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-14 23:15:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][0/2502]	eta 11:03:41 lr 0.000008	 wd 0.0000	time 15.9160 (15.9160)	loss 1.2197 (1.2197)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-14 23:15:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:16:01 lr 0.000008	 wd 0.0000	time 0.4557 (0.4005)	loss 1.1582 (1.4058)	grad_norm 0.4102 (0.3945)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-14 23:16:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:14:34 lr 0.000009	 wd 0.0000	time 0.1967 (0.3798)	loss 1.3583 (1.4055)	grad_norm 0.3990 (0.3955)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-14 23:16:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:49 lr 0.000009	 wd 0.0000	time 0.2226 (0.3221)	loss 1.7011 (1.3848)	grad_norm 0.3799 (0.4118)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-14 23:17:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:10:15 lr 0.000009	 wd 0.0000	time 0.2434 (0.2930)	loss 0.9825 (1.3743)	grad_norm 0.5239 (0.4082)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-14 23:17:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:09:19 lr 0.000010	 wd 0.0000	time 0.3214 (0.2796)	loss 1.5250 (1.3727)	grad_norm 0.3599 (0.4085)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-14 23:17:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:09:06 lr 0.000010	 wd 0.0000	time 0.2270 (0.2873)	loss 1.4374 (1.3724)	grad_norm 0.5246 (0.4069)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-14 23:18:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:17 lr 0.000010	 wd 0.0000	time 0.2307 (0.2763)	loss 1.6326 (1.3710)	grad_norm 0.3983 (0.4073)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-14 23:18:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:35 lr 0.000011	 wd 0.0000	time 0.1907 (0.2677)	loss 1.5498 (1.3745)	grad_norm 0.3484 (0.4046)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-14 23:19:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:02 lr 0.000011	 wd 0.0000	time 0.2352 (0.2635)	loss 1.5974 (1.3718)	grad_norm 0.3968 (0.4035)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-14 23:19:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:45 lr 0.000011	 wd 0.0000	time 0.1940 (0.2698)	loss 1.6856 (1.3707)	grad_norm 0.4510 (0.4077)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-14 23:19:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:06:10 lr 0.000012	 wd 0.0000	time 0.2275 (0.2643)	loss 1.0838 (1.3697)	grad_norm 0.4088 (0.4121)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-14 23:20:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:38 lr 0.000012	 wd 0.0000	time 0.2004 (0.2599)	loss 1.3504 (1.3724)	grad_norm 0.3467 (0.4133)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-14 23:20:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:09 lr 0.000012	 wd 0.0000	time 0.2168 (0.2571)	loss 1.5498 (1.3757)	grad_norm 0.3851 (0.4123)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-14 23:21:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:42 lr 0.000012	 wd 0.0000	time 0.2001 (0.2564)	loss 1.4284 (1.3737)	grad_norm 0.3728 (0.4117)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-14 23:21:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:14 lr 0.000013	 wd 0.0000	time 0.2132 (0.2537)	loss 0.9837 (1.3721)	grad_norm 0.3695 (0.4114)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-14 23:21:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:46 lr 0.000013	 wd 0.0000	time 0.2097 (0.2512)	loss 0.9403 (1.3707)	grad_norm 0.4496 (nan)	loss_scale 4096.0000 (8099.8976)	mem 7646MB
[2024-07-14 23:22:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:19 lr 0.000013	 wd 0.0000	time 0.2406 (0.2491)	loss 1.3526 (1.3700)	grad_norm 0.4531 (nan)	loss_scale 4096.0000 (7864.5126)	mem 7646MB
[2024-07-14 23:22:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:55 lr 0.000014	 wd 0.0000	time 0.1917 (0.2496)	loss 1.4393 (1.3701)	grad_norm 0.3954 (nan)	loss_scale 4096.0000 (7655.2671)	mem 7646MB
[2024-07-14 23:22:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:29 lr 0.000014	 wd 0.0000	time 0.2004 (0.2480)	loss 1.4591 (1.3713)	grad_norm 0.3795 (nan)	loss_scale 4096.0000 (7468.0358)	mem 7646MB
[2024-07-14 23:23:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:03 lr 0.000014	 wd 0.0000	time 0.2001 (0.2463)	loss 1.3254 (1.3705)	grad_norm 0.3738 (nan)	loss_scale 4096.0000 (7299.5182)	mem 7646MB
[2024-07-14 23:23:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:38 lr 0.000015	 wd 0.0000	time 0.2149 (0.2447)	loss 1.4013 (1.3715)	grad_norm 0.3702 (nan)	loss_scale 4096.0000 (7147.0424)	mem 7646MB
[2024-07-14 23:24:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:13 lr 0.000015	 wd 0.0000	time 0.2470 (0.2441)	loss 1.2084 (1.3727)	grad_norm 0.4001 (nan)	loss_scale 4096.0000 (7008.4216)	mem 7646MB
[2024-07-14 23:24:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:49 lr 0.000015	 wd 0.0000	time 0.2125 (0.2438)	loss 1.6364 (1.3732)	grad_norm 0.4016 (nan)	loss_scale 4096.0000 (6881.8496)	mem 7646MB
[2024-07-14 23:24:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:24 lr 0.000016	 wd 0.0000	time 0.2122 (0.2426)	loss 1.4547 (1.3713)	grad_norm 0.3751 (nan)	loss_scale 4096.0000 (6765.8209)	mem 7646MB
[2024-07-14 23:25:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1524 (0.2401)	loss 1.1113 (1.3726)	grad_norm 0.4266 (nan)	loss_scale 4096.0000 (6659.0708)	mem 7646MB
[2024-07-14 23:25:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 1 training takes 0:10:05
[2024-07-14 23:25:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 39.199 (39.199)	Loss 0.4194 (0.4194)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-14 23:26:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.040 Acc@5 97.214
[2024-07-14 23:26:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-14 23:26:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.04%
[2024-07-14 23:26:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_best.pth saving......
[2024-07-14 23:26:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-14 23:26:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][0/2502]	eta 11:11:55 lr 0.000016	 wd 0.0000	time 16.1133 (16.1133)	loss 1.6516 (1.6516)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:26:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:14:42 lr 0.000016	 wd 0.0000	time 0.2083 (0.3673)	loss 1.4188 (1.3449)	grad_norm 0.4425 (0.4071)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:27:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:11:17 lr 0.000017	 wd 0.0000	time 0.3213 (0.2945)	loss 1.4442 (1.3648)	grad_norm 0.3314 (0.4397)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:27:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:11:06 lr 0.000017	 wd 0.0000	time 0.2001 (0.3026)	loss 1.2922 (1.3757)	grad_norm 0.3986 (0.4300)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:27:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:09:45 lr 0.000017	 wd 0.0000	time 0.1884 (0.2787)	loss 1.5317 (1.3734)	grad_norm 0.4294 (0.4245)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:28:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:08:49 lr 0.000018	 wd 0.0000	time 0.1990 (0.2643)	loss 1.5341 (1.3718)	grad_norm 0.4099 (0.4178)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:28:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:08 lr 0.000018	 wd 0.0000	time 0.2296 (0.2567)	loss 1.2706 (1.3664)	grad_norm 0.3896 (0.4189)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:29:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:08:05 lr 0.000018	 wd 0.0000	time 0.2007 (0.2694)	loss 1.2512 (1.3685)	grad_norm 0.5263 (0.4166)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:29:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:25 lr 0.000019	 wd 0.0000	time 0.2030 (0.2616)	loss 1.4417 (1.3667)	grad_norm 0.4760 (0.4145)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:29:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:49 lr 0.000019	 wd 0.0000	time 0.2061 (0.2556)	loss 1.5346 (1.3712)	grad_norm 0.5836 (0.4158)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:30:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:18 lr 0.000019	 wd 0.0000	time 0.2482 (0.2521)	loss 1.4543 (1.3724)	grad_norm 0.3745 (0.4146)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:30:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:52 lr 0.000020	 wd 0.0000	time 0.2072 (0.2514)	loss 1.1828 (1.3719)	grad_norm 0.3653 (0.4163)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:31:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:23 lr 0.000020	 wd 0.0000	time 0.1803 (0.2485)	loss 1.2584 (1.3710)	grad_norm 0.3694 (0.4145)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:31:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:04:55 lr 0.000020	 wd 0.0000	time 0.1988 (0.2460)	loss 1.7102 (1.3737)	grad_norm 0.4021 (0.4138)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:31:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:28 lr 0.000020	 wd 0.0000	time 0.2579 (0.2433)	loss 1.4448 (1.3737)	grad_norm 0.4055 (0.4130)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:32:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:02 lr 0.000021	 wd 0.0000	time 0.2388 (0.2423)	loss 1.5047 (1.3718)	grad_norm 0.3535 (0.4134)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:32:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:38 lr 0.000021	 wd 0.0000	time 0.2257 (0.2425)	loss 1.2855 (1.3721)	grad_norm 0.3827 (0.4123)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:32:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:13 lr 0.000021	 wd 0.0000	time 0.1709 (0.2407)	loss 1.4543 (1.3718)	grad_norm 0.4008 (0.4112)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:33:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:47 lr 0.000022	 wd 0.0000	time 0.1745 (0.2390)	loss 1.3545 (1.3718)	grad_norm 0.4697 (0.4117)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:33:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:23 lr 0.000022	 wd 0.0000	time 0.2258 (0.2382)	loss 1.0834 (1.3703)	grad_norm 0.3711 (0.4116)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:34:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:01:59 lr 0.000022	 wd 0.0000	time 0.2179 (0.2385)	loss 1.1114 (1.3685)	grad_norm 0.4443 (0.4113)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:34:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:35 lr 0.000023	 wd 0.0000	time 0.2337 (0.2374)	loss 1.4530 (1.3687)	grad_norm 0.3717 (0.4113)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:34:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:11 lr 0.000023	 wd 0.0000	time 0.1942 (0.2362)	loss 1.5079 (1.3687)	grad_norm 0.3754 (0.4112)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:35:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:47 lr 0.000023	 wd 0.0000	time 0.2280 (0.2354)	loss 1.5753 (1.3687)	grad_norm 0.3849 (0.4114)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:35:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:24 lr 0.000024	 wd 0.0000	time 0.2782 (0.2353)	loss 1.4209 (1.3676)	grad_norm 0.3498 (0.4116)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:35:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1557 (0.2333)	loss 1.4452 (1.3675)	grad_norm 0.3523 (0.4111)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:35:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 2 training takes 0:09:48
[2024-07-14 23:36:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 24.564 (24.564)	Loss 0.4187 (0.4187)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-14 23:36:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.024 Acc@5 97.210
[2024-07-14 23:36:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-14 23:36:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.04%
[2024-07-14 23:37:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][0/2502]	eta 23:25:20 lr 0.000024	 wd 0.0000	time 33.7011 (33.7011)	loss 1.0953 (1.0953)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:37:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:21:46 lr 0.000024	 wd 0.0000	time 0.2145 (0.5441)	loss 1.6799 (1.3531)	grad_norm 0.3872 (0.4189)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:37:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:14:26 lr 0.000025	 wd 0.0000	time 0.2120 (0.3765)	loss 1.4965 (1.3654)	grad_norm 0.3658 (0.4211)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:38:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:11:42 lr 0.000025	 wd 0.0000	time 0.2062 (0.3191)	loss 1.4079 (1.3542)	grad_norm 0.4745 (0.4147)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:38:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:10:24 lr 0.000025	 wd 0.0000	time 0.2200 (0.2969)	loss 1.5332 (1.3607)	grad_norm 0.3567 (0.4115)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:38:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:09:24 lr 0.000026	 wd 0.0000	time 0.2148 (0.2818)	loss 1.3913 (1.3582)	grad_norm 0.3977 (0.4088)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:39:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:08:35 lr 0.000026	 wd 0.0000	time 0.2207 (0.2708)	loss 1.4653 (1.3579)	grad_norm 0.3803 (0.4076)	loss_scale 8192.0000 (4368.6123)	mem 7646MB
[2024-07-14 23:39:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:07:52 lr 0.000026	 wd 0.0000	time 0.2203 (0.2624)	loss 1.4947 (1.3599)	grad_norm 0.4085 (0.4091)	loss_scale 8192.0000 (4914.0314)	mem 7646MB
[2024-07-14 23:39:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:16 lr 0.000027	 wd 0.0000	time 0.2068 (0.2567)	loss 1.1385 (1.3605)	grad_norm 0.3730 (0.4078)	loss_scale 8192.0000 (5323.2659)	mem 7646MB
[2024-07-14 23:40:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:06:59 lr 0.000027	 wd 0.0000	time 0.2044 (0.2616)	loss 1.3457 (1.3621)	grad_norm 0.4017 (0.4075)	loss_scale 8192.0000 (5641.6604)	mem 7646MB
[2024-07-14 23:40:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:24 lr 0.000027	 wd 0.0000	time 0.1808 (0.2562)	loss 1.6091 (1.3654)	grad_norm 0.3824 (0.4077)	loss_scale 8192.0000 (5896.4396)	mem 7646MB
[2024-07-14 23:41:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:05:53 lr 0.000028	 wd 0.0000	time 0.1952 (0.2521)	loss 1.4063 (1.3677)	grad_norm 0.3685 (0.4076)	loss_scale 8192.0000 (6104.9373)	mem 7646MB
[2024-07-14 23:41:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:23 lr 0.000028	 wd 0.0000	time 0.2257 (0.2486)	loss 1.3034 (1.3666)	grad_norm 0.3245 (0.4060)	loss_scale 8192.0000 (6278.7144)	mem 7646MB
[2024-07-14 23:42:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:05:06 lr 0.000028	 wd 0.0000	time 0.2012 (0.2549)	loss 1.2237 (1.3694)	grad_norm 0.3508 (0.4056)	loss_scale 8192.0000 (6425.7771)	mem 7646MB
[2024-07-14 23:42:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:37 lr 0.000028	 wd 0.0000	time 0.1962 (0.2516)	loss 1.2270 (1.3701)	grad_norm 0.3930 (0.4048)	loss_scale 8192.0000 (6551.8458)	mem 7646MB
[2024-07-14 23:42:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:09 lr 0.000029	 wd 0.0000	time 0.2021 (0.2487)	loss 1.3911 (1.3705)	grad_norm 0.3694 (0.4043)	loss_scale 8192.0000 (6661.1166)	mem 7646MB
[2024-07-14 23:43:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:42 lr 0.000029	 wd 0.0000	time 0.2187 (0.2463)	loss 1.4125 (1.3692)	grad_norm 0.3808 (0.4044)	loss_scale 8192.0000 (6756.7370)	mem 7646MB
[2024-07-14 23:43:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:17 lr 0.000029	 wd 0.0000	time 1.9572 (0.2462)	loss 1.0674 (1.3683)	grad_norm 0.3633 (inf)	loss_scale 4096.0000 (6744.7948)	mem 7646MB
[2024-07-14 23:43:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:52 lr 0.000030	 wd 0.0000	time 0.2041 (0.2452)	loss 1.6386 (1.3699)	grad_norm 0.3980 (inf)	loss_scale 4096.0000 (6597.7213)	mem 7646MB
[2024-07-14 23:44:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:26 lr 0.000030	 wd 0.0000	time 0.2024 (0.2437)	loss 1.5443 (1.3696)	grad_norm 0.3647 (inf)	loss_scale 4096.0000 (6466.1210)	mem 7646MB
[2024-07-14 23:44:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:01 lr 0.000030	 wd 0.0000	time 0.2060 (0.2420)	loss 1.1645 (1.3703)	grad_norm 0.3741 (inf)	loss_scale 4096.0000 (6347.6742)	mem 7646MB
[2024-07-14 23:44:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:36 lr 0.000031	 wd 0.0000	time 0.2218 (0.2412)	loss 1.2277 (1.3687)	grad_norm 0.3670 (inf)	loss_scale 4096.0000 (6240.5026)	mem 7646MB
[2024-07-14 23:45:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:12 lr 0.000031	 wd 0.0000	time 0.1896 (0.2412)	loss 1.3624 (1.3698)	grad_norm 0.4825 (inf)	loss_scale 4096.0000 (6143.0695)	mem 7646MB
[2024-07-14 23:45:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:48 lr 0.000031	 wd 0.0000	time 0.1944 (0.2401)	loss 1.5365 (1.3704)	grad_norm 0.3748 (inf)	loss_scale 4096.0000 (6054.1052)	mem 7646MB
[2024-07-14 23:46:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:24 lr 0.000032	 wd 0.0000	time 0.2099 (0.2391)	loss 0.9902 (1.3697)	grad_norm 0.3751 (inf)	loss_scale 4096.0000 (5972.5514)	mem 7646MB
[2024-07-14 23:46:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000032	 wd 0.0000	time 0.1697 (0.2367)	loss 1.5473 (1.3702)	grad_norm 0.3813 (inf)	loss_scale 4096.0000 (5897.5194)	mem 7646MB
[2024-07-14 23:46:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 3 training takes 0:09:56
[2024-07-14 23:47:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 40.617 (40.617)	Loss 0.4204 (0.4204)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-14 23:47:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.016 Acc@5 97.204
[2024-07-14 23:47:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-14 23:47:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.04%
[2024-07-14 23:47:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][0/2502]	eta 11:29:53 lr 0.000032	 wd 0.0000	time 16.5441 (16.5441)	loss 1.4341 (1.4341)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:47:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:15:12 lr 0.000032	 wd 0.0000	time 0.2002 (0.3800)	loss 1.1473 (1.3812)	grad_norm 0.5080 (0.3956)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:48:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:13:17 lr 0.000033	 wd 0.0000	time 0.2356 (0.3465)	loss 1.1380 (1.3823)	grad_norm 0.3816 (0.3976)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:48:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:11:01 lr 0.000033	 wd 0.0000	time 0.2398 (0.3002)	loss 1.1204 (1.3819)	grad_norm 0.3878 (0.4021)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:49:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:09:42 lr 0.000033	 wd 0.0000	time 0.1872 (0.2771)	loss 1.5809 (1.3775)	grad_norm 0.3442 (0.4127)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:49:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:08:45 lr 0.000034	 wd 0.0000	time 0.2397 (0.2627)	loss 1.3418 (1.3711)	grad_norm 0.3945 (0.4082)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:50:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:08:31 lr 0.000034	 wd 0.0000	time 0.2344 (0.2687)	loss 1.4873 (1.3670)	grad_norm 0.3885 (0.4042)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:50:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:07:49 lr 0.000034	 wd 0.0000	time 0.1983 (0.2603)	loss 1.2887 (1.3669)	grad_norm 0.3667 (0.4026)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:50:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:12 lr 0.000035	 wd 0.0000	time 0.1906 (0.2541)	loss 1.4755 (1.3664)	grad_norm 0.3565 (0.4150)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:51:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:06:38 lr 0.000035	 wd 0.0000	time 0.1810 (0.2489)	loss 1.4932 (1.3676)	grad_norm 0.3504 (0.4154)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:51:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:24 lr 0.000035	 wd 0.0000	time 0.5670 (0.2563)	loss 1.5348 (1.3683)	grad_norm 0.4085 (0.4173)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:51:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:05:54 lr 0.000036	 wd 0.0000	time 0.1942 (0.2531)	loss 1.5381 (1.3692)	grad_norm 0.3590 (0.4151)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:52:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:24 lr 0.000036	 wd 0.0000	time 0.2186 (0.2493)	loss 1.0820 (1.3677)	grad_norm 0.3815 (0.4136)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:52:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:04:56 lr 0.000036	 wd 0.0000	time 0.2040 (0.2464)	loss 1.5803 (1.3669)	grad_norm 0.3843 (0.4114)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:53:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:30 lr 0.000036	 wd 0.0000	time 0.1904 (0.2453)	loss 1.5090 (1.3670)	grad_norm 0.4193 (0.4123)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:53:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:05 lr 0.000037	 wd 0.0000	time 0.2221 (0.2449)	loss 1.2596 (1.3695)	grad_norm 0.3538 (0.4129)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:53:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:39 lr 0.000037	 wd 0.0000	time 0.1970 (0.2430)	loss 1.0618 (1.3691)	grad_norm 0.4425 (0.4133)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:54:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:13 lr 0.000037	 wd 0.0000	time 0.1999 (0.2414)	loss 1.5559 (1.3684)	grad_norm 0.3612 (0.4128)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:54:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:48 lr 0.000038	 wd 0.0000	time 0.2221 (0.2402)	loss 1.3792 (1.3683)	grad_norm 0.3582 (0.4120)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:54:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:25 lr 0.000038	 wd 0.0000	time 0.2246 (0.2409)	loss 1.6482 (1.3682)	grad_norm 0.3814 (0.4124)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:55:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:02:00 lr 0.000038	 wd 0.0000	time 0.2409 (0.2397)	loss 1.4723 (1.3676)	grad_norm 0.3616 (0.4116)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:55:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:35 lr 0.000039	 wd 0.0000	time 0.1922 (0.2384)	loss 1.4299 (1.3681)	grad_norm 0.6764 (0.4116)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:56:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:11 lr 0.000039	 wd 0.0000	time 0.1921 (0.2373)	loss 0.9921 (1.3657)	grad_norm 0.3334 (0.4109)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:56:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:47 lr 0.000039	 wd 0.0000	time 0.3232 (0.2375)	loss 1.2995 (1.3659)	grad_norm 0.3449 (0.4105)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:56:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:24 lr 0.000040	 wd 0.0000	time 0.2040 (0.2369)	loss 1.5916 (1.3658)	grad_norm 0.3376 (0.4102)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:57:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1560 (0.2347)	loss 0.9307 (1.3656)	grad_norm 0.3770 (0.4115)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:57:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 4 training takes 0:09:51
[2024-07-14 23:57:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 22.389 (22.389)	Loss 0.4197 (0.4197)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-14 23:57:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.070 Acc@5 97.206
[2024-07-14 23:57:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 23:57:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.07%
[2024-07-14 23:57:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_best.pth saving......
[2024-07-14 23:57:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-14 23:58:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][0/2502]	eta 22:59:37 lr 0.000040	 wd 0.0000	time 33.0846 (33.0846)	loss 1.6016 (1.6016)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:58:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:21:31 lr 0.000040	 wd 0.0000	time 0.2034 (0.5379)	loss 1.2869 (1.3857)	grad_norm 0.4023 (0.3952)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:59:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:14:17 lr 0.000040	 wd 0.0000	time 0.1899 (0.3724)	loss 1.4800 (1.3896)	grad_norm 0.4069 (0.4021)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:59:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:11:52 lr 0.000040	 wd 0.0000	time 0.2477 (0.3235)	loss 1.6198 (1.3791)	grad_norm 0.4149 (0.4021)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-14 23:59:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:10:30 lr 0.000040	 wd 0.0000	time 0.2133 (0.3000)	loss 1.0049 (1.3807)	grad_norm 0.4005 (0.4080)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:00:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:09:24 lr 0.000040	 wd 0.0000	time 0.1903 (0.2818)	loss 1.5189 (1.3761)	grad_norm 0.3623 (0.4094)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:00:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:33 lr 0.000040	 wd 0.0000	time 0.1967 (0.2700)	loss 1.4351 (1.3769)	grad_norm 0.4025 (0.4077)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:00:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:50 lr 0.000040	 wd 0.0000	time 0.1904 (0.2614)	loss 1.4579 (1.3745)	grad_norm 0.4778 (0.4056)	loss_scale 8192.0000 (4353.0956)	mem 7646MB
[2024-07-15 00:01:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:23 lr 0.000040	 wd 0.0000	time 1.2797 (0.2605)	loss 0.9374 (1.3685)	grad_norm 0.4941 (0.4055)	loss_scale 8192.0000 (4832.3596)	mem 7646MB
[2024-07-15 00:01:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:49 lr 0.000040	 wd 0.0000	time 0.2414 (0.2556)	loss 0.9083 (1.3677)	grad_norm 0.4321 (0.4041)	loss_scale 8192.0000 (5205.2386)	mem 7646MB
[2024-07-15 00:01:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:17 lr 0.000040	 wd 0.0000	time 0.2034 (0.2514)	loss 1.5353 (1.3709)	grad_norm 0.3688 (0.4049)	loss_scale 8192.0000 (5503.6164)	mem 7646MB
[2024-07-15 00:02:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:46 lr 0.000040	 wd 0.0000	time 0.2027 (0.2473)	loss 1.5504 (1.3669)	grad_norm 0.3774 (0.4064)	loss_scale 8192.0000 (5747.7929)	mem 7646MB
[2024-07-15 00:02:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:19 lr 0.000040	 wd 0.0000	time 0.2332 (0.2455)	loss 1.5585 (1.3649)	grad_norm 0.3428 (0.4056)	loss_scale 8192.0000 (5951.3072)	mem 7646MB
[2024-07-15 00:03:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:54 lr 0.000040	 wd 0.0000	time 0.2072 (0.2452)	loss 1.5070 (1.3654)	grad_norm 0.3710 (0.4056)	loss_scale 8192.0000 (6123.5357)	mem 7646MB
[2024-07-15 00:03:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:27 lr 0.000040	 wd 0.0000	time 0.1886 (0.2429)	loss 1.5290 (1.3650)	grad_norm 0.3647 (0.4050)	loss_scale 8192.0000 (6271.1777)	mem 7646MB
[2024-07-15 00:03:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:04:01 lr 0.000040	 wd 0.0000	time 0.2122 (0.2407)	loss 1.3834 (1.3649)	grad_norm 0.4335 (0.4050)	loss_scale 8192.0000 (6399.1472)	mem 7646MB
[2024-07-15 00:04:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:35 lr 0.000040	 wd 0.0000	time 0.2100 (0.2393)	loss 1.4566 (1.3669)	grad_norm 0.4445 (0.4081)	loss_scale 8192.0000 (6511.1305)	mem 7646MB
[2024-07-15 00:04:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:12 lr 0.000040	 wd 0.0000	time 0.2145 (0.2396)	loss 1.3556 (1.3665)	grad_norm 0.3625 (0.4086)	loss_scale 8192.0000 (6609.9471)	mem 7646MB
[2024-07-15 00:04:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:47 lr 0.000040	 wd 0.0000	time 0.2595 (0.2389)	loss 0.9932 (1.3659)	grad_norm 0.3712 (0.4080)	loss_scale 8192.0000 (6697.7901)	mem 7646MB
[2024-07-15 00:05:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:23 lr 0.000040	 wd 0.0000	time 0.2061 (0.2376)	loss 1.4846 (1.3679)	grad_norm 0.4624 (0.4073)	loss_scale 8192.0000 (6776.3914)	mem 7646MB
[2024-07-15 00:05:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:01:58 lr 0.000040	 wd 0.0000	time 0.2080 (0.2364)	loss 1.5185 (1.3689)	grad_norm 0.3907 (0.4070)	loss_scale 8192.0000 (6847.1364)	mem 7646MB
[2024-07-15 00:06:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:34 lr 0.000040	 wd 0.0000	time 0.2009 (0.2360)	loss 1.5147 (1.3694)	grad_norm 0.3586 (0.4079)	loss_scale 8192.0000 (6911.1471)	mem 7646MB
[2024-07-15 00:06:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:11 lr 0.000040	 wd 0.0000	time 0.2419 (0.2358)	loss 1.2398 (1.3674)	grad_norm 0.3594 (nan)	loss_scale 4096.0000 (6880.0145)	mem 7646MB
[2024-07-15 00:06:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:47 lr 0.000040	 wd 0.0000	time 0.2060 (0.2349)	loss 0.9036 (1.3665)	grad_norm 0.3442 (nan)	loss_scale 4096.0000 (6759.0230)	mem 7646MB
[2024-07-15 00:07:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:23 lr 0.000040	 wd 0.0000	time 0.2277 (0.2339)	loss 1.5147 (1.3666)	grad_norm 0.4306 (nan)	loss_scale 4096.0000 (6648.1100)	mem 7646MB
[2024-07-15 00:07:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1568 (0.2318)	loss 1.5240 (1.3665)	grad_norm 0.3555 (nan)	loss_scale 4096.0000 (6546.0664)	mem 7646MB
[2024-07-15 00:07:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 5 training takes 0:09:44
[2024-07-15 00:08:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 37.152 (37.152)	Loss 0.4187 (0.4187)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 00:08:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.022 Acc@5 97.236
[2024-07-15 00:08:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-15 00:08:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.07%
[2024-07-15 00:08:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][0/2502]	eta 11:43:25 lr 0.000040	 wd 0.0000	time 16.8686 (16.8686)	loss 1.5705 (1.5705)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:08:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:15:09 lr 0.000040	 wd 0.0000	time 0.2409 (0.3786)	loss 1.2101 (1.3373)	grad_norm 0.3775 (0.3963)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:09:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:13:49 lr 0.000040	 wd 0.0000	time 0.2106 (0.3605)	loss 1.5991 (1.3587)	grad_norm 0.3818 (0.3939)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:09:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:11:25 lr 0.000040	 wd 0.0000	time 0.1956 (0.3114)	loss 1.4619 (1.3693)	grad_norm 0.5026 (0.3946)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:10:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:10:00 lr 0.000040	 wd 0.0000	time 0.2054 (0.2854)	loss 1.3746 (1.3631)	grad_norm 0.4396 (0.3943)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:10:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:09:03 lr 0.000040	 wd 0.0000	time 0.2108 (0.2713)	loss 1.3570 (1.3574)	grad_norm 0.3882 (0.3961)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:11:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:08:51 lr 0.000040	 wd 0.0000	time 0.2098 (0.2796)	loss 1.5953 (1.3616)	grad_norm 0.4337 (0.3979)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:11:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:08:05 lr 0.000040	 wd 0.0000	time 0.1989 (0.2695)	loss 1.4179 (1.3640)	grad_norm 0.3958 (0.3977)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:11:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:25 lr 0.000040	 wd 0.0000	time 0.1769 (0.2618)	loss 1.0122 (1.3630)	grad_norm 0.4592 (0.3979)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:12:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:06:50 lr 0.000040	 wd 0.0000	time 0.2020 (0.2565)	loss 1.6524 (1.3671)	grad_norm 0.3264 (0.3975)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:12:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:23 lr 0.000040	 wd 0.0000	time 0.2179 (0.2556)	loss 1.3090 (1.3625)	grad_norm 0.3575 (0.3975)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:12:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:54 lr 0.000040	 wd 0.0000	time 0.2069 (0.2526)	loss 1.2025 (1.3617)	grad_norm 0.3747 (0.3983)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:13:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:24 lr 0.000040	 wd 0.0000	time 0.2050 (0.2490)	loss 1.0563 (1.3634)	grad_norm 0.3579 (0.3983)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:13:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:04:55 lr 0.000040	 wd 0.0000	time 0.1983 (0.2459)	loss 1.4072 (1.3625)	grad_norm 0.6775 (0.3985)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:14:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:29 lr 0.000040	 wd 0.0000	time 0.2325 (0.2449)	loss 1.6558 (1.3611)	grad_norm 0.4622 (0.3996)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:14:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:05 lr 0.000040	 wd 0.0000	time 0.1831 (0.2447)	loss 1.4641 (1.3627)	grad_norm 0.3422 (0.3994)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:14:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:38 lr 0.000040	 wd 0.0000	time 0.2373 (0.2427)	loss 1.5401 (1.3614)	grad_norm 0.4090 (0.4002)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:15:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:13 lr 0.000040	 wd 0.0000	time 0.1997 (0.2409)	loss 1.5062 (1.3607)	grad_norm 1.9521 (0.4019)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:15:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:48 lr 0.000040	 wd 0.0000	time 0.2366 (0.2398)	loss 1.1612 (1.3605)	grad_norm 0.3737 (0.4034)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:15:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:24 lr 0.000040	 wd 0.0000	time 0.2928 (0.2395)	loss 1.2741 (1.3599)	grad_norm 0.4152 (0.4060)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:16:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:01:59 lr 0.000039	 wd 0.0000	time 0.2249 (0.2382)	loss 0.9898 (1.3599)	grad_norm 0.3879 (0.4083)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:16:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:35 lr 0.000039	 wd 0.0000	time 0.2045 (0.2371)	loss 1.5668 (1.3595)	grad_norm 0.3697 (0.4092)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:17:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:11 lr 0.000039	 wd 0.0000	time 0.1999 (0.2359)	loss 1.2613 (1.3600)	grad_norm 0.3681 (0.4083)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:17:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:47 lr 0.000039	 wd 0.0000	time 0.1957 (0.2361)	loss 1.4600 (1.3607)	grad_norm 0.4436 (0.4075)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:17:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:24 lr 0.000039	 wd 0.0000	time 0.2215 (0.2355)	loss 1.2008 (1.3599)	grad_norm 0.4722 (0.4071)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:18:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1745 (0.2334)	loss 1.0393 (1.3606)	grad_norm 0.3542 (0.4070)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:18:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 6 training takes 0:09:48
[2024-07-15 00:18:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 20.412 (20.412)	Loss 0.4175 (0.4175)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 00:18:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.038 Acc@5 97.206
[2024-07-15 00:18:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-15 00:18:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.07%
[2024-07-15 00:19:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][0/2502]	eta 1 day, 1:02:27 lr 0.000039	 wd 0.0000	time 36.0303 (36.0303)	loss 1.5967 (1.5967)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:19:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:22:34 lr 0.000039	 wd 0.0000	time 0.1863 (0.5639)	loss 1.2344 (1.3860)	grad_norm 0.4147 (0.3958)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:20:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:14:49 lr 0.000039	 wd 0.0000	time 0.1803 (0.3862)	loss 1.4531 (1.3605)	grad_norm 0.3818 (0.3991)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:20:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:12:10 lr 0.000039	 wd 0.0000	time 0.2814 (0.3316)	loss 1.3093 (1.3582)	grad_norm 0.3856 (0.3962)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:20:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:11:10 lr 0.000039	 wd 0.0000	time 0.2106 (0.3192)	loss 1.3466 (1.3602)	grad_norm 0.3696 (0.3976)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:21:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:09:52 lr 0.000039	 wd 0.0000	time 0.1842 (0.2961)	loss 1.4300 (1.3556)	grad_norm 0.3543 (0.3984)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:21:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:56 lr 0.000039	 wd 0.0000	time 0.2092 (0.2821)	loss 1.3409 (1.3593)	grad_norm 1.1853 (0.4018)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:21:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:08:11 lr 0.000039	 wd 0.0000	time 0.2150 (0.2727)	loss 1.4904 (1.3631)	grad_norm 0.4048 (0.4016)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:22:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:07:41 lr 0.000039	 wd 0.0000	time 0.2301 (0.2712)	loss 0.9058 (1.3654)	grad_norm 0.4328 (0.4008)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:22:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:07:04 lr 0.000039	 wd 0.0000	time 0.1901 (0.2647)	loss 1.0881 (1.3673)	grad_norm 0.5003 (0.4037)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:23:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:29 lr 0.000039	 wd 0.0000	time 0.2266 (0.2594)	loss 1.1792 (1.3633)	grad_norm 0.3982 (0.4039)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:23:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:56 lr 0.000039	 wd 0.0000	time 0.2233 (0.2546)	loss 1.2373 (1.3618)	grad_norm 0.3742 (0.4045)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:23:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:29 lr 0.000039	 wd 0.0000	time 0.2384 (0.2527)	loss 1.4146 (1.3606)	grad_norm 0.4242 (0.4096)	loss_scale 8192.0000 (4273.3455)	mem 7646MB
[2024-07-15 00:24:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:05:02 lr 0.000039	 wd 0.0000	time 0.2448 (0.2518)	loss 1.4756 (1.3607)	grad_norm 0.3877 (0.4091)	loss_scale 8192.0000 (4574.5488)	mem 7646MB
[2024-07-15 00:24:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:33 lr 0.000039	 wd 0.0000	time 0.2407 (0.2485)	loss 1.4194 (1.3615)	grad_norm 0.4462 (0.4086)	loss_scale 8192.0000 (4832.7537)	mem 7646MB
[2024-07-15 00:24:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:06 lr 0.000039	 wd 0.0000	time 0.1872 (0.2460)	loss 1.6470 (1.3608)	grad_norm 0.4177 (0.4086)	loss_scale 8192.0000 (5056.5543)	mem 7646MB
[2024-07-15 00:25:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:40 lr 0.000039	 wd 0.0000	time 0.2244 (0.2442)	loss 1.5177 (1.3625)	grad_norm 0.3895 (0.4090)	loss_scale 8192.0000 (5252.3973)	mem 7646MB
[2024-07-15 00:25:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:15 lr 0.000039	 wd 0.0000	time 0.1946 (0.2443)	loss 1.5726 (1.3628)	grad_norm 0.5753 (0.4080)	loss_scale 8192.0000 (5425.2134)	mem 7646MB
[2024-07-15 00:26:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:50 lr 0.000039	 wd 0.0000	time 0.1992 (0.2429)	loss 1.1255 (1.3623)	grad_norm 0.4601 (0.4092)	loss_scale 8192.0000 (5578.8384)	mem 7646MB
[2024-07-15 00:26:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:25 lr 0.000039	 wd 0.0000	time 0.2130 (0.2413)	loss 1.3213 (1.3617)	grad_norm 0.4190 (0.4087)	loss_scale 8192.0000 (5716.3009)	mem 7646MB
[2024-07-15 00:26:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:02:00 lr 0.000039	 wd 0.0000	time 0.2115 (0.2398)	loss 1.4313 (1.3628)	grad_norm 0.3598 (0.4089)	loss_scale 8192.0000 (5840.0240)	mem 7646MB
[2024-07-15 00:27:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:36 lr 0.000039	 wd 0.0000	time 0.2005 (0.2395)	loss 1.5069 (1.3639)	grad_norm 0.4267 (0.4085)	loss_scale 8192.0000 (5951.9695)	mem 7646MB
[2024-07-15 00:27:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:12 lr 0.000039	 wd 0.0000	time 0.1939 (0.2387)	loss 1.1107 (1.3620)	grad_norm 0.3582 (0.4084)	loss_scale 8192.0000 (6053.7428)	mem 7646MB
[2024-07-15 00:27:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:48 lr 0.000039	 wd 0.0000	time 0.2207 (0.2377)	loss 1.5904 (1.3625)	grad_norm 0.4344 (0.4076)	loss_scale 8192.0000 (6146.6701)	mem 7646MB
[2024-07-15 00:28:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:24 lr 0.000039	 wd 0.0000	time 0.2082 (0.2365)	loss 1.4653 (1.3620)	grad_norm 0.3756 (inf)	loss_scale 4096.0000 (6170.4423)	mem 7646MB
[2024-07-15 00:28:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1695 (0.2343)	loss 1.2842 (1.3623)	grad_norm 0.4112 (inf)	loss_scale 4096.0000 (6087.4978)	mem 7646MB
[2024-07-15 00:28:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 7 training takes 0:09:50
[2024-07-15 00:29:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 39.785 (39.785)	Loss 0.4233 (0.4233)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 00:29:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.034 Acc@5 97.236
[2024-07-15 00:29:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-15 00:29:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.07%
[2024-07-15 00:29:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][0/2502]	eta 12:04:52 lr 0.000039	 wd 0.0000	time 17.3832 (17.3832)	loss 1.4230 (1.4230)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:30:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:15:59 lr 0.000039	 wd 0.0000	time 0.3290 (0.3993)	loss 1.4630 (1.3995)	grad_norm 0.3678 (0.4146)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:30:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:13:37 lr 0.000039	 wd 0.0000	time 0.1888 (0.3550)	loss 1.5372 (1.3750)	grad_norm 0.3679 (0.4086)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:30:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:11:12 lr 0.000038	 wd 0.0000	time 0.2025 (0.3053)	loss 1.3636 (1.3718)	grad_norm 0.4039 (0.4043)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:31:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:09:51 lr 0.000038	 wd 0.0000	time 0.2228 (0.2813)	loss 1.6341 (1.3680)	grad_norm 0.5687 (0.4044)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:31:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:08:56 lr 0.000038	 wd 0.0000	time 0.2591 (0.2680)	loss 1.4478 (1.3712)	grad_norm 0.3972 (0.4029)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:32:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:20 lr 0.000038	 wd 0.0000	time 0.1947 (0.2630)	loss 1.5368 (1.3757)	grad_norm 0.3573 (0.4085)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:32:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:41 lr 0.000038	 wd 0.0000	time 0.1979 (0.2559)	loss 1.6410 (1.3739)	grad_norm 0.3702 (0.4091)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:32:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:05 lr 0.000038	 wd 0.0000	time 0.2186 (0.2501)	loss 1.4797 (1.3715)	grad_norm 0.3660 (0.4080)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:33:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:33 lr 0.000038	 wd 0.0000	time 0.2078 (0.2453)	loss 1.6586 (1.3716)	grad_norm 0.3698 (0.4075)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:33:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:06 lr 0.000038	 wd 0.0000	time 0.2082 (0.2443)	loss 1.4968 (1.3678)	grad_norm 0.4261 (0.4061)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:33:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:40 lr 0.000038	 wd 0.0000	time 0.2624 (0.2432)	loss 1.3352 (1.3647)	grad_norm 0.4141 (0.4068)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:34:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:13 lr 0.000038	 wd 0.0000	time 0.2241 (0.2404)	loss 1.4672 (1.3650)	grad_norm 0.3866 (0.4080)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:34:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:46 lr 0.000038	 wd 0.0000	time 0.2033 (0.2380)	loss 1.1798 (1.3635)	grad_norm 0.3675 (0.4084)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:34:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:21 lr 0.000038	 wd 0.0000	time 0.2776 (0.2370)	loss 0.9590 (1.3652)	grad_norm 0.3836 (0.4075)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:35:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:03:58 lr 0.000038	 wd 0.0000	time 0.2069 (0.2377)	loss 0.8336 (1.3630)	grad_norm 0.7917 (0.4072)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:35:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:33 lr 0.000038	 wd 0.0000	time 0.2406 (0.2362)	loss 1.2285 (1.3602)	grad_norm 0.4164 (0.4069)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:36:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:08 lr 0.000038	 wd 0.0000	time 0.2052 (0.2347)	loss 1.1788 (1.3620)	grad_norm 0.3821 (0.4067)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:36:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:43 lr 0.000038	 wd 0.0000	time 0.2231 (0.2334)	loss 1.5313 (1.3631)	grad_norm 0.3808 (0.4065)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:36:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:20 lr 0.000038	 wd 0.0000	time 0.4096 (0.2340)	loss 1.3149 (1.3623)	grad_norm 0.3645 (0.4061)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:37:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:57 lr 0.000038	 wd 0.0000	time 0.1936 (0.2338)	loss 1.6952 (1.3643)	grad_norm 0.3823 (0.4056)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:37:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:33 lr 0.000038	 wd 0.0000	time 0.2263 (0.2327)	loss 1.4096 (1.3634)	grad_norm 0.3717 (0.4076)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:37:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:09 lr 0.000038	 wd 0.0000	time 0.1930 (0.2316)	loss 1.5659 (1.3620)	grad_norm 0.4117 (0.4081)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:38:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:46 lr 0.000038	 wd 0.0000	time 0.2464 (0.2313)	loss 1.4884 (1.3627)	grad_norm 0.4139 (0.4086)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:38:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:23 lr 0.000038	 wd 0.0000	time 0.2245 (0.2318)	loss 1.3182 (1.3643)	grad_norm 0.4291 (0.4094)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:39:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000038	 wd 0.0000	time 0.1538 (0.2297)	loss 1.7557 (1.3657)	grad_norm 0.3488 (0.4086)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:39:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 8 training takes 0:09:39
[2024-07-15 00:39:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 19.397 (19.397)	Loss 0.4219 (0.4219)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 00:39:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.054 Acc@5 97.240
[2024-07-15 00:39:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 00:39:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.07%
[2024-07-15 00:40:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][0/2502]	eta 1 day, 1:44:26 lr 0.000038	 wd 0.0000	time 37.0368 (37.0368)	loss 1.3718 (1.3718)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:40:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:22:55 lr 0.000038	 wd 0.0000	time 0.1948 (0.5728)	loss 1.2372 (1.3305)	grad_norm 0.3739 (0.3983)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:40:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:14:58 lr 0.000037	 wd 0.0000	time 0.1919 (0.3904)	loss 1.4947 (1.3430)	grad_norm 0.3849 (0.3932)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:41:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:12:08 lr 0.000037	 wd 0.0000	time 0.2571 (0.3309)	loss 1.4365 (1.3547)	grad_norm 0.3810 (0.3963)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:41:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:11:13 lr 0.000037	 wd 0.0000	time 0.1792 (0.3203)	loss 1.5796 (1.3499)	grad_norm 0.3589 (0.3950)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:42:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:09:56 lr 0.000037	 wd 0.0000	time 0.1892 (0.2977)	loss 1.3848 (1.3565)	grad_norm 0.5630 (0.3977)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 00:42:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:59 lr 0.000037	 wd 0.0000	time 0.1939 (0.2835)	loss 1.5000 (1.3511)	grad_norm 0.5229 (nan)	loss_scale 2048.0000 (3932.4326)	mem 7646MB
[2024-07-15 00:42:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:08:11 lr 0.000037	 wd 0.0000	time 0.2175 (0.2729)	loss 1.5322 (1.3527)	grad_norm 0.3832 (nan)	loss_scale 2048.0000 (3663.6120)	mem 7646MB
[2024-07-15 00:43:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:51 lr 0.000037	 wd 0.0000	time 0.2405 (0.2768)	loss 1.3811 (1.3556)	grad_norm 0.3711 (nan)	loss_scale 2048.0000 (3461.9126)	mem 7646MB
[2024-07-15 00:43:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:07:12 lr 0.000037	 wd 0.0000	time 0.2287 (0.2701)	loss 1.6018 (1.3526)	grad_norm 0.3734 (nan)	loss_scale 2048.0000 (3304.9856)	mem 7646MB
[2024-07-15 00:44:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:36 lr 0.000037	 wd 0.0000	time 0.2166 (0.2641)	loss 1.4801 (1.3553)	grad_norm 0.3462 (nan)	loss_scale 2048.0000 (3179.4126)	mem 7646MB
[2024-07-15 00:44:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:06:03 lr 0.000037	 wd 0.0000	time 0.2307 (0.2591)	loss 1.3998 (1.3583)	grad_norm 0.3778 (nan)	loss_scale 2048.0000 (3076.6503)	mem 7646MB
[2024-07-15 00:44:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:35 lr 0.000037	 wd 0.0000	time 0.2234 (0.2574)	loss 1.5453 (1.3594)	grad_norm 0.3599 (nan)	loss_scale 2048.0000 (2991.0008)	mem 7646MB
[2024-07-15 00:45:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:05:06 lr 0.000037	 wd 0.0000	time 0.2112 (0.2551)	loss 0.9744 (1.3574)	grad_norm 0.4032 (nan)	loss_scale 2048.0000 (2918.5181)	mem 7646MB
[2024-07-15 00:45:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:37 lr 0.000037	 wd 0.0000	time 0.1895 (0.2520)	loss 1.3433 (1.3587)	grad_norm 0.3660 (nan)	loss_scale 2048.0000 (2856.3826)	mem 7646MB
[2024-07-15 00:45:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:04:09 lr 0.000037	 wd 0.0000	time 0.1885 (0.2492)	loss 1.4673 (1.3608)	grad_norm 0.4136 (nan)	loss_scale 2048.0000 (2802.5263)	mem 7646MB
[2024-07-15 00:46:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:42 lr 0.000037	 wd 0.0000	time 0.2206 (0.2472)	loss 0.9350 (1.3598)	grad_norm 0.3548 (nan)	loss_scale 2048.0000 (2755.3979)	mem 7646MB
[2024-07-15 00:46:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:18 lr 0.000037	 wd 0.0000	time 0.2327 (0.2471)	loss 1.1104 (1.3611)	grad_norm 0.3963 (nan)	loss_scale 2048.0000 (2713.8107)	mem 7646MB
[2024-07-15 00:46:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:52 lr 0.000037	 wd 0.0000	time 0.1973 (0.2457)	loss 1.5368 (1.3614)	grad_norm 0.3770 (nan)	loss_scale 2048.0000 (2676.8418)	mem 7646MB
[2024-07-15 00:47:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:26 lr 0.000037	 wd 0.0000	time 0.2066 (0.2440)	loss 1.3322 (1.3602)	grad_norm 0.3813 (nan)	loss_scale 2048.0000 (2643.7622)	mem 7646MB
[2024-07-15 00:47:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:02:01 lr 0.000037	 wd 0.0000	time 0.2106 (0.2423)	loss 1.4894 (1.3603)	grad_norm 0.3731 (nan)	loss_scale 2048.0000 (2613.9890)	mem 7646MB
[2024-07-15 00:48:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:37 lr 0.000036	 wd 0.0000	time 0.1616 (0.2427)	loss 1.0687 (1.3604)	grad_norm 0.3823 (nan)	loss_scale 2048.0000 (2587.0500)	mem 7646MB
[2024-07-15 00:48:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:13 lr 0.000036	 wd 0.0000	time 0.2128 (0.2418)	loss 1.4819 (1.3615)	grad_norm 0.4259 (nan)	loss_scale 2048.0000 (2562.5588)	mem 7646MB
[2024-07-15 00:48:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:48 lr 0.000036	 wd 0.0000	time 0.2060 (0.2405)	loss 1.4177 (1.3621)	grad_norm 0.4568 (nan)	loss_scale 2048.0000 (2540.1964)	mem 7646MB
[2024-07-15 00:49:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:24 lr 0.000036	 wd 0.0000	time 0.2008 (0.2392)	loss 1.2730 (1.3618)	grad_norm 0.3905 (nan)	loss_scale 2048.0000 (2519.6968)	mem 7646MB
[2024-07-15 00:49:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000036	 wd 0.0000	time 0.1561 (0.2370)	loss 1.1288 (1.3630)	grad_norm 0.3536 (nan)	loss_scale 2048.0000 (2500.8365)	mem 7646MB
[2024-07-15 00:49:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 9 training takes 0:09:57
[2024-07-15 00:50:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 36.672 (36.672)	Loss 0.4167 (0.4167)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 00:50:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.044 Acc@5 97.240
[2024-07-15 00:50:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-15 00:50:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.07%
[2024-07-15 00:50:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][0/2502]	eta 11:37:45 lr 0.000036	 wd 0.0000	time 16.7327 (16.7327)	loss 1.2935 (1.2935)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:51:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:15:29 lr 0.000036	 wd 0.0000	time 0.2685 (0.3868)	loss 1.3588 (1.3439)	grad_norm 0.3469 (0.3976)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:51:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:13:11 lr 0.000036	 wd 0.0000	time 0.2045 (0.3440)	loss 1.2978 (1.3644)	grad_norm 0.3801 (0.3992)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:51:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:58 lr 0.000036	 wd 0.0000	time 0.1999 (0.2989)	loss 0.8842 (1.3616)	grad_norm 0.3876 (0.4016)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:52:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:40 lr 0.000036	 wd 0.0000	time 0.1832 (0.2760)	loss 1.5212 (1.3649)	grad_norm 0.8314 (0.4156)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:52:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:08:44 lr 0.000036	 wd 0.0000	time 0.2558 (0.2620)	loss 1.4130 (1.3607)	grad_norm 0.3580 (0.4142)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:53:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:17 lr 0.000036	 wd 0.0000	time 0.2447 (0.2616)	loss 1.5197 (1.3610)	grad_norm 0.4216 (0.4115)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:53:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:39 lr 0.000036	 wd 0.0000	time 0.2101 (0.2550)	loss 1.4784 (1.3570)	grad_norm 0.3710 (0.4267)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:53:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:07:04 lr 0.000036	 wd 0.0000	time 0.1921 (0.2492)	loss 1.2402 (1.3562)	grad_norm 0.4027 (0.4233)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:54:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:31 lr 0.000036	 wd 0.0000	time 0.1973 (0.2446)	loss 1.5370 (1.3564)	grad_norm 0.3991 (0.4198)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:54:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:09 lr 0.000036	 wd 0.0000	time 0.4286 (0.2457)	loss 1.4870 (1.3550)	grad_norm 0.4074 (0.4201)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:54:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:48 lr 0.000036	 wd 0.0000	time 0.2072 (0.2483)	loss 1.3054 (1.3526)	grad_norm 0.3616 (0.4186)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:55:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:18 lr 0.000035	 wd 0.0000	time 0.2188 (0.2448)	loss 1.3370 (1.3531)	grad_norm 0.3771 (0.4171)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:55:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:50 lr 0.000035	 wd 0.0000	time 0.1833 (0.2421)	loss 1.5760 (1.3557)	grad_norm 0.4144 (0.4168)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:56:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:25 lr 0.000035	 wd 0.0000	time 0.2589 (0.2409)	loss 1.3367 (1.3562)	grad_norm 0.4012 (0.4147)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:56:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:04:01 lr 0.000035	 wd 0.0000	time 0.2097 (0.2408)	loss 1.2520 (1.3562)	grad_norm 0.3665 (0.4135)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:56:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:35 lr 0.000035	 wd 0.0000	time 0.2048 (0.2390)	loss 1.2296 (1.3576)	grad_norm 0.3826 (0.4122)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:57:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:10 lr 0.000035	 wd 0.0000	time 0.2000 (0.2375)	loss 1.3137 (1.3586)	grad_norm 0.4231 (0.4111)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:57:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:45 lr 0.000035	 wd 0.0000	time 0.2195 (0.2363)	loss 1.4038 (1.3593)	grad_norm 0.4515 (0.4106)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:57:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:22 lr 0.000035	 wd 0.0000	time 0.1778 (0.2366)	loss 1.5152 (1.3608)	grad_norm 0.3767 (0.4099)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:58:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:58 lr 0.000035	 wd 0.0000	time 0.2053 (0.2356)	loss 1.2534 (1.3618)	grad_norm 0.4538 (0.4095)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 00:58:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:34 lr 0.000035	 wd 0.0000	time 0.2383 (0.2345)	loss 1.5544 (1.3635)	grad_norm 0.3834 (0.4101)	loss_scale 4096.0000 (2096.7387)	mem 7646MB
[2024-07-15 00:58:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:10 lr 0.000035	 wd 0.0000	time 0.2094 (0.2334)	loss 0.9643 (1.3633)	grad_norm 0.4077 (0.4099)	loss_scale 4096.0000 (2187.5729)	mem 7646MB
[2024-07-15 00:59:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:47 lr 0.000035	 wd 0.0000	time 0.2159 (0.2332)	loss 1.4869 (1.3629)	grad_norm 0.4717 (0.4103)	loss_scale 4096.0000 (2270.5120)	mem 7646MB
[2024-07-15 00:59:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:23 lr 0.000035	 wd 0.0000	time 0.2046 (0.2332)	loss 1.5185 (1.3628)	grad_norm 0.3834 (0.4096)	loss_scale 4096.0000 (2346.5423)	mem 7646MB
[2024-07-15 01:00:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1498 (0.2311)	loss 1.3373 (1.3619)	grad_norm 0.3879 (nan)	loss_scale 2048.0000 (2401.7529)	mem 7646MB
[2024-07-15 01:00:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 10 training takes 0:09:42
[2024-07-15 01:00:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 20.460 (20.460)	Loss 0.4199 (0.4199)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 01:00:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.040 Acc@5 97.230
[2024-07-15 01:00:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-15 01:00:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.07%
[2024-07-15 01:01:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][0/2502]	eta 1 day, 0:50:26 lr 0.000035	 wd 0.0000	time 35.7418 (35.7418)	loss 1.5013 (1.5013)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:01:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:22:32 lr 0.000035	 wd 0.0000	time 0.2007 (0.5630)	loss 1.3898 (1.3541)	grad_norm 0.3921 (0.4468)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:01:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:14:47 lr 0.000034	 wd 0.0000	time 0.2099 (0.3857)	loss 1.4697 (1.3582)	grad_norm 0.4179 (0.4320)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:02:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:12:00 lr 0.000034	 wd 0.0000	time 0.2586 (0.3273)	loss 1.3295 (1.3604)	grad_norm 0.3948 (0.4228)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:02:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:11:32 lr 0.000034	 wd 0.0000	time 0.2018 (0.3295)	loss 1.5387 (1.3599)	grad_norm 0.3850 (0.4182)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:03:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:10:10 lr 0.000034	 wd 0.0000	time 0.2055 (0.3052)	loss 1.3894 (1.3569)	grad_norm 0.4095 (0.4169)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:03:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:09:08 lr 0.000034	 wd 0.0000	time 0.2142 (0.2885)	loss 1.4711 (1.3546)	grad_norm 0.3920 (0.4165)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:03:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:08:19 lr 0.000034	 wd 0.0000	time 0.2679 (0.2774)	loss 1.4787 (1.3550)	grad_norm 0.3556 (0.4145)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:04:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:08:05 lr 0.000034	 wd 0.0000	time 0.2046 (0.2854)	loss 1.6079 (1.3575)	grad_norm 0.3580 (0.4133)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:04:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:07:23 lr 0.000034	 wd 0.0000	time 0.1855 (0.2770)	loss 1.5164 (1.3574)	grad_norm 0.3582 (0.4123)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:05:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:45 lr 0.000034	 wd 0.0000	time 0.1935 (0.2700)	loss 1.4485 (1.3596)	grad_norm 0.4106 (0.4115)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:05:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:06:10 lr 0.000034	 wd 0.0000	time 0.2186 (0.2646)	loss 1.5642 (1.3610)	grad_norm 0.3904 (0.4101)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:05:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:43 lr 0.000034	 wd 0.0000	time 0.2355 (0.2635)	loss 1.7026 (1.3608)	grad_norm 0.3854 (0.4115)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:06:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:05:12 lr 0.000034	 wd 0.0000	time 0.1896 (0.2600)	loss 0.8932 (1.3596)	grad_norm 0.3542 (0.4109)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:06:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:42 lr 0.000034	 wd 0.0000	time 0.2020 (0.2566)	loss 0.8844 (1.3593)	grad_norm 0.3502 (0.4106)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:06:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:04:13 lr 0.000034	 wd 0.0000	time 0.2211 (0.2534)	loss 1.4346 (1.3583)	grad_norm 0.3762 (0.4103)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:07:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:46 lr 0.000034	 wd 0.0000	time 0.2393 (0.2516)	loss 1.2653 (1.3593)	grad_norm 0.4110 (0.4103)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:07:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:21 lr 0.000033	 wd 0.0000	time 0.2906 (0.2511)	loss 1.4650 (1.3585)	grad_norm 0.3524 (0.4101)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:08:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:54 lr 0.000033	 wd 0.0000	time 0.2084 (0.2490)	loss 1.2853 (1.3601)	grad_norm 0.3482 (0.4089)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:08:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:28 lr 0.000033	 wd 0.0000	time 0.2052 (0.2472)	loss 1.5021 (1.3603)	grad_norm 0.3834 (0.4080)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:08:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:02:03 lr 0.000033	 wd 0.0000	time 0.2285 (0.2457)	loss 1.1144 (1.3597)	grad_norm 0.3493 (0.4070)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:09:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:38 lr 0.000033	 wd 0.0000	time 0.3023 (0.2453)	loss 1.5417 (1.3595)	grad_norm 0.4070 (0.4074)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:09:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:13 lr 0.000033	 wd 0.0000	time 0.2056 (0.2442)	loss 1.2854 (1.3604)	grad_norm 0.3793 (0.4084)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:09:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:49 lr 0.000033	 wd 0.0000	time 0.1927 (0.2428)	loss 1.5270 (1.3601)	grad_norm 0.3876 (0.4095)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:10:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:24 lr 0.000033	 wd 0.0000	time 0.1964 (0.2414)	loss 1.2700 (1.3593)	grad_norm 0.4389 (0.4100)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:10:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000033	 wd 0.0000	time 0.1532 (0.2392)	loss 1.4096 (1.3589)	grad_norm 0.3861 (0.4093)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:10:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 11 training takes 0:10:02
[2024-07-15 01:11:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 33.165 (33.165)	Loss 0.4189 (0.4189)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 7646MB
[2024-07-15 01:11:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.124 Acc@5 97.232
[2024-07-15 01:11:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 01:11:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-15 01:11:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_best.pth saving......
[2024-07-15 01:11:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-15 01:11:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][0/2502]	eta 10:45:45 lr 0.000033	 wd 0.0000	time 15.4858 (15.4858)	loss 1.6227 (1.6227)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:12:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:15:02 lr 0.000033	 wd 0.0000	time 0.2829 (0.3758)	loss 1.5028 (1.3658)	grad_norm 0.3751 (0.4132)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:12:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:13:13 lr 0.000033	 wd 0.0000	time 0.1989 (0.3446)	loss 0.9867 (1.3713)	grad_norm 0.3308 (0.4236)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:12:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:56 lr 0.000033	 wd 0.0000	time 0.2001 (0.2981)	loss 1.2972 (1.3715)	grad_norm 0.4028 (0.4150)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:13:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:38 lr 0.000033	 wd 0.0000	time 0.2043 (0.2750)	loss 1.2314 (1.3638)	grad_norm 0.3663 (0.4246)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:13:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:08:46 lr 0.000032	 wd 0.0000	time 0.2480 (0.2629)	loss 1.0209 (1.3646)	grad_norm 0.3406 (0.4198)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:14:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:08:34 lr 0.000032	 wd 0.0000	time 0.2080 (0.2705)	loss 1.3553 (1.3618)	grad_norm 0.4003 (0.4167)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:14:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:51 lr 0.000032	 wd 0.0000	time 0.2137 (0.2614)	loss 1.4613 (1.3595)	grad_norm 0.3892 (0.4123)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:14:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:07:13 lr 0.000032	 wd 0.0000	time 0.2088 (0.2548)	loss 1.4483 (1.3673)	grad_norm 0.3711 (0.4104)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:15:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:40 lr 0.000032	 wd 0.0000	time 0.2241 (0.2503)	loss 1.0580 (1.3677)	grad_norm 0.3906 (0.4086)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:15:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:16 lr 0.000032	 wd 0.0000	time 0.2277 (0.2509)	loss 1.6263 (1.3653)	grad_norm 0.3468 (0.4080)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:16:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:47 lr 0.000032	 wd 0.0000	time 0.2122 (0.2476)	loss 1.4850 (1.3692)	grad_norm 0.3647 (0.4073)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:16:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:18 lr 0.000032	 wd 0.0000	time 0.1994 (0.2444)	loss 1.5138 (1.3682)	grad_norm 0.4331 (0.4052)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:16:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:50 lr 0.000032	 wd 0.0000	time 0.2076 (0.2417)	loss 1.4477 (1.3686)	grad_norm 0.3653 (0.4057)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:17:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:25 lr 0.000032	 wd 0.0000	time 0.2085 (0.2405)	loss 1.6097 (1.3686)	grad_norm 0.3941 (0.4051)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:17:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:04:00 lr 0.000032	 wd 0.0000	time 0.1966 (0.2402)	loss 1.4419 (1.3692)	grad_norm 0.3715 (0.4056)	loss_scale 4096.0000 (2078.0173)	mem 7646MB
[2024-07-15 01:17:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:35 lr 0.000032	 wd 0.0000	time 0.1854 (0.2384)	loss 1.4222 (1.3681)	grad_norm 0.3727 (0.4049)	loss_scale 4096.0000 (2204.0625)	mem 7646MB
[2024-07-15 01:18:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:10 lr 0.000031	 wd 0.0000	time 0.2066 (0.2369)	loss 1.5735 (1.3692)	grad_norm 0.3909 (0.4043)	loss_scale 4096.0000 (2315.2875)	mem 7646MB
[2024-07-15 01:18:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:45 lr 0.000031	 wd 0.0000	time 0.2337 (0.2359)	loss 1.2850 (1.3699)	grad_norm 0.4036 (0.4050)	loss_scale 4096.0000 (2414.1610)	mem 7646MB
[2024-07-15 01:18:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:22 lr 0.000031	 wd 0.0000	time 0.2614 (0.2362)	loss 1.4125 (1.3694)	grad_norm 0.4216 (0.4050)	loss_scale 4096.0000 (2502.6323)	mem 7646MB
[2024-07-15 01:19:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:01:58 lr 0.000031	 wd 0.0000	time 0.1973 (0.2353)	loss 1.3975 (1.3685)	grad_norm 0.3551 (0.4042)	loss_scale 4096.0000 (2582.2609)	mem 7646MB
[2024-07-15 01:19:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:34 lr 0.000031	 wd 0.0000	time 0.2160 (0.2342)	loss 1.4390 (1.3697)	grad_norm 0.4641 (0.4041)	loss_scale 4096.0000 (2654.3094)	mem 7646MB
[2024-07-15 01:20:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:10 lr 0.000031	 wd 0.0000	time 0.2157 (0.2332)	loss 1.5605 (1.3711)	grad_norm 0.3560 (0.4042)	loss_scale 4096.0000 (2719.8110)	mem 7646MB
[2024-07-15 01:20:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:47 lr 0.000031	 wd 0.0000	time 0.5034 (0.2331)	loss 1.4327 (1.3711)	grad_norm 0.4122 (0.4054)	loss_scale 4096.0000 (2779.6193)	mem 7646MB
[2024-07-15 01:20:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:23 lr 0.000031	 wd 0.0000	time 0.2008 (0.2330)	loss 1.5032 (1.3707)	grad_norm 0.3985 (0.4055)	loss_scale 4096.0000 (2834.4456)	mem 7646MB
[2024-07-15 01:21:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000031	 wd 0.0000	time 0.1589 (0.2309)	loss 1.1253 (1.3695)	grad_norm 0.4190 (0.4049)	loss_scale 4096.0000 (2884.8876)	mem 7646MB
[2024-07-15 01:21:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 12 training takes 0:09:42
[2024-07-15 01:21:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 19.166 (19.166)	Loss 0.4199 (0.4199)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 01:21:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.130 Acc@5 97.234
[2024-07-15 01:21:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 01:21:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 01:21:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_best.pth saving......
[2024-07-15 01:21:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_best.pth saved !!!
[2024-07-15 01:22:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][0/2502]	eta 1 day, 0:57:34 lr 0.000031	 wd 0.0000	time 35.9129 (35.9129)	loss 1.3642 (1.3642)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:22:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:22:25 lr 0.000031	 wd 0.0000	time 0.1958 (0.5601)	loss 1.3807 (1.3561)	grad_norm 0.3690 (0.3973)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:22:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:14:46 lr 0.000031	 wd 0.0000	time 0.1951 (0.3851)	loss 1.6858 (1.3579)	grad_norm 0.3516 (0.3991)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:23:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:12:03 lr 0.000031	 wd 0.0000	time 0.2384 (0.3286)	loss 1.4541 (1.3661)	grad_norm 0.3712 (0.3948)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:23:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:10:43 lr 0.000030	 wd 0.0000	time 0.2489 (0.3063)	loss 1.3360 (1.3652)	grad_norm 0.5011 (0.4020)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:24:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:09:35 lr 0.000030	 wd 0.0000	time 0.1984 (0.2874)	loss 1.5340 (1.3599)	grad_norm 0.4672 (0.4027)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:24:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:42 lr 0.000030	 wd 0.0000	time 0.2157 (0.2749)	loss 1.5384 (1.3662)	grad_norm 0.3718 (0.4036)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:24:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:07:58 lr 0.000030	 wd 0.0000	time 0.2464 (0.2653)	loss 1.4365 (1.3616)	grad_norm 0.3760 (0.4034)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:25:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:25 lr 0.000030	 wd 0.0000	time 0.1943 (0.2615)	loss 1.5380 (1.3654)	grad_norm 0.3422 (0.4023)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:25:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:06:53 lr 0.000030	 wd 0.0000	time 0.1858 (0.2579)	loss 1.5338 (1.3623)	grad_norm 0.4217 (0.4026)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:25:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:20 lr 0.000030	 wd 0.0000	time 0.2122 (0.2534)	loss 1.6118 (1.3678)	grad_norm 0.3686 (0.4020)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:26:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:49 lr 0.000030	 wd 0.0000	time 0.1998 (0.2495)	loss 1.3831 (1.3692)	grad_norm 0.3840 (0.4023)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:26:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:21 lr 0.000030	 wd 0.0000	time 0.2165 (0.2468)	loss 1.5548 (1.3655)	grad_norm 0.3816 (0.4017)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:27:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:04:56 lr 0.000030	 wd 0.0000	time 0.3018 (0.2465)	loss 1.4269 (1.3642)	grad_norm 0.3472 (0.4017)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:27:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:29 lr 0.000030	 wd 0.0000	time 0.2170 (0.2442)	loss 1.6664 (1.3647)	grad_norm 0.3651 (0.4016)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:27:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:04:02 lr 0.000030	 wd 0.0000	time 0.2285 (0.2420)	loss 1.6311 (1.3635)	grad_norm 0.3868 (0.4019)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:28:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:36 lr 0.000029	 wd 0.0000	time 0.2417 (0.2401)	loss 1.5751 (1.3632)	grad_norm 0.4013 (0.4026)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:28:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:12 lr 0.000029	 wd 0.0000	time 0.1840 (0.2395)	loss 0.8618 (1.3608)	grad_norm 0.3692 (0.4023)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:28:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:48 lr 0.000029	 wd 0.0000	time 0.2029 (0.2401)	loss 1.4337 (1.3625)	grad_norm 0.3513 (0.4023)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:29:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:23 lr 0.000029	 wd 0.0000	time 0.1893 (0.2386)	loss 1.2162 (1.3629)	grad_norm 0.3926 (0.4019)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:29:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:58 lr 0.000029	 wd 0.0000	time 0.1789 (0.2370)	loss 1.4397 (1.3638)	grad_norm 0.3707 (0.4027)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:29:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:35 lr 0.000029	 wd 0.0000	time 0.2320 (0.2365)	loss 1.1160 (1.3635)	grad_norm 0.4198 (0.4028)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:30:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:11 lr 0.000029	 wd 0.0000	time 0.2260 (0.2364)	loss 1.5437 (1.3650)	grad_norm 0.3786 (0.4030)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:30:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:47 lr 0.000029	 wd 0.0000	time 0.1842 (0.2354)	loss 1.3121 (1.3645)	grad_norm 0.4025 (0.4029)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:31:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:23 lr 0.000029	 wd 0.0000	time 0.1925 (0.2345)	loss 1.7006 (1.3657)	grad_norm 0.3710 (0.4031)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:31:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000029	 wd 0.0000	time 0.1624 (0.2323)	loss 1.5215 (1.3651)	grad_norm 0.3522 (0.4039)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:31:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 13 training takes 0:09:46
[2024-07-15 01:32:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 39.709 (39.709)	Loss 0.4189 (0.4189)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 01:32:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.096 Acc@5 97.242
[2024-07-15 01:32:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 01:32:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 01:32:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][0/2502]	eta 11:39:08 lr 0.000029	 wd 0.0000	time 16.7662 (16.7662)	loss 1.4901 (1.4901)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:32:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:15:04 lr 0.000029	 wd 0.0000	time 0.2457 (0.3765)	loss 1.5434 (1.3754)	grad_norm 0.3387 (0.3963)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:33:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:12:15 lr 0.000028	 wd 0.0000	time 0.2192 (0.3194)	loss 1.3107 (1.3945)	grad_norm 0.3430 (0.4043)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:33:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:10:24 lr 0.000028	 wd 0.0000	time 0.1950 (0.2835)	loss 1.0180 (1.3823)	grad_norm 0.3583 (0.4124)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:34:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:09:15 lr 0.000028	 wd 0.0000	time 0.1893 (0.2644)	loss 1.2207 (1.3673)	grad_norm 0.4546 (0.4134)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 01:34:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:08:25 lr 0.000028	 wd 0.0000	time 0.2259 (0.2526)	loss 1.2925 (1.3701)	grad_norm 0.3659 (0.4114)	loss_scale 8192.0000 (4308.5669)	mem 7646MB
[2024-07-15 01:34:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:07:59 lr 0.000028	 wd 0.0000	time 0.2893 (0.2519)	loss 1.6599 (1.3756)	grad_norm 0.4626 (0.4116)	loss_scale 8192.0000 (4954.7288)	mem 7646MB
[2024-07-15 01:35:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:41 lr 0.000028	 wd 0.0000	time 0.2187 (0.2561)	loss 1.4432 (1.3716)	grad_norm 0.3674 (0.4094)	loss_scale 8192.0000 (5416.5364)	mem 7646MB
[2024-07-15 01:35:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:05 lr 0.000028	 wd 0.0000	time 0.2072 (0.2498)	loss 1.3816 (1.3678)	grad_norm 0.4508 (inf)	loss_scale 4096.0000 (5650.5368)	mem 7646MB
[2024-07-15 01:36:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:32 lr 0.000028	 wd 0.0000	time 0.2044 (0.2453)	loss 1.4415 (1.3638)	grad_norm 0.3855 (inf)	loss_scale 4096.0000 (5478.0022)	mem 7646MB
[2024-07-15 01:36:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:06:06 lr 0.000028	 wd 0.0000	time 0.2179 (0.2440)	loss 1.3265 (1.3623)	grad_norm 0.3533 (inf)	loss_scale 4096.0000 (5339.9401)	mem 7646MB
[2024-07-15 01:36:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:42 lr 0.000028	 wd 0.0000	time 0.2034 (0.2441)	loss 1.4913 (1.3599)	grad_norm 0.3355 (inf)	loss_scale 4096.0000 (5226.9573)	mem 7646MB
[2024-07-15 01:37:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:14 lr 0.000028	 wd 0.0000	time 0.1955 (0.2414)	loss 1.4161 (1.3601)	grad_norm 0.3547 (inf)	loss_scale 4096.0000 (5132.7893)	mem 7646MB
[2024-07-15 01:37:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:04:47 lr 0.000027	 wd 0.0000	time 0.2339 (0.2390)	loss 1.1876 (1.3603)	grad_norm 0.3909 (inf)	loss_scale 4096.0000 (5053.0976)	mem 7646MB
[2024-07-15 01:37:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:21 lr 0.000027	 wd 0.0000	time 0.2432 (0.2371)	loss 1.6459 (1.3592)	grad_norm 0.3727 (inf)	loss_scale 4096.0000 (4984.7823)	mem 7646MB
[2024-07-15 01:38:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:03:57 lr 0.000027	 wd 0.0000	time 0.1840 (0.2375)	loss 1.3758 (1.3600)	grad_norm 0.3558 (inf)	loss_scale 4096.0000 (4925.5696)	mem 7646MB
[2024-07-15 01:38:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:33 lr 0.000027	 wd 0.0000	time 0.2039 (0.2364)	loss 1.3133 (1.3599)	grad_norm 0.3690 (nan)	loss_scale 2048.0000 (4820.0275)	mem 7646MB
[2024-07-15 01:39:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:08 lr 0.000027	 wd 0.0000	time 0.2299 (0.2350)	loss 1.1916 (1.3592)	grad_norm 0.3840 (nan)	loss_scale 2048.0000 (4657.0629)	mem 7646MB
[2024-07-15 01:39:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:44 lr 0.000027	 wd 0.0000	time 0.2258 (0.2337)	loss 1.3076 (1.3591)	grad_norm 0.4030 (nan)	loss_scale 2048.0000 (4512.1954)	mem 7646MB
[2024-07-15 01:39:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:20 lr 0.000027	 wd 0.0000	time 0.2031 (0.2332)	loss 1.5350 (1.3592)	grad_norm 0.3977 (nan)	loss_scale 2048.0000 (4382.5692)	mem 7646MB
[2024-07-15 01:40:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:01:57 lr 0.000027	 wd 0.0000	time 0.2002 (0.2338)	loss 1.0718 (1.3611)	grad_norm 0.3782 (nan)	loss_scale 2048.0000 (4265.8991)	mem 7646MB
[2024-07-15 01:40:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:33 lr 0.000027	 wd 0.0000	time 0.2296 (0.2327)	loss 1.5546 (1.3608)	grad_norm 0.3798 (nan)	loss_scale 2048.0000 (4160.3351)	mem 7646MB
[2024-07-15 01:40:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:09 lr 0.000027	 wd 0.0000	time 0.2004 (0.2317)	loss 1.2106 (1.3610)	grad_norm 0.4444 (nan)	loss_scale 2048.0000 (4064.3635)	mem 7646MB
[2024-07-15 01:41:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:46 lr 0.000027	 wd 0.0000	time 0.2401 (0.2311)	loss 1.3867 (1.3618)	grad_norm 0.4396 (nan)	loss_scale 2048.0000 (3976.7336)	mem 7646MB
[2024-07-15 01:41:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:23 lr 0.000026	 wd 0.0000	time 0.2000 (0.2310)	loss 1.1218 (1.3629)	grad_norm 0.5189 (nan)	loss_scale 2048.0000 (3896.4032)	mem 7646MB
[2024-07-15 01:41:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1582 (0.2291)	loss 1.2598 (1.3620)	grad_norm 0.3859 (nan)	loss_scale 2048.0000 (3822.4966)	mem 7646MB
[2024-07-15 01:41:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 14 training takes 0:09:37
[2024-07-15 01:42:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 20.778 (20.778)	Loss 0.4160 (0.4160)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 01:42:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.120 Acc@5 97.246
[2024-07-15 01:42:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 01:42:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 01:42:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][0/2502]	eta 17:30:01 lr 0.000026	 wd 0.0000	time 25.1804 (25.1804)	loss 1.4728 (1.4728)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:43:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:19:45 lr 0.000026	 wd 0.0000	time 0.2014 (0.4936)	loss 1.0281 (1.3493)	grad_norm 0.3637 (0.3902)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:43:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:13:28 lr 0.000026	 wd 0.0000	time 0.1973 (0.3510)	loss 1.4475 (1.3644)	grad_norm 0.3881 (0.3993)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:44:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:11:07 lr 0.000026	 wd 0.0000	time 0.1799 (0.3029)	loss 1.3974 (1.3513)	grad_norm 0.3353 (0.4012)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:44:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:09:52 lr 0.000026	 wd 0.0000	time 0.2452 (0.2817)	loss 1.3978 (1.3547)	grad_norm 0.4688 (0.4063)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:44:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:09:04 lr 0.000026	 wd 0.0000	time 0.1946 (0.2717)	loss 0.8704 (1.3527)	grad_norm 0.4191 (0.4065)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:45:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:08:19 lr 0.000026	 wd 0.0000	time 0.2058 (0.2625)	loss 0.8490 (1.3562)	grad_norm 0.4434 (0.4060)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:45:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:39 lr 0.000026	 wd 0.0000	time 0.1979 (0.2548)	loss 1.1052 (1.3588)	grad_norm 0.3866 (0.4064)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:45:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:07:03 lr 0.000026	 wd 0.0000	time 0.1950 (0.2486)	loss 1.4157 (1.3592)	grad_norm 0.3529 (0.4066)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:46:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:36 lr 0.000025	 wd 0.0000	time 0.2483 (0.2473)	loss 1.2297 (1.3599)	grad_norm 0.4333 (0.4098)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:46:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:06:09 lr 0.000025	 wd 0.0000	time 0.2294 (0.2461)	loss 1.4244 (1.3614)	grad_norm 0.3392 (0.4083)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:46:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:40 lr 0.000025	 wd 0.0000	time 0.2084 (0.2428)	loss 1.2488 (1.3585)	grad_norm 0.3586 (0.4084)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:47:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:12 lr 0.000025	 wd 0.0000	time 0.1974 (0.2401)	loss 1.3914 (1.3592)	grad_norm 0.3830 (0.4082)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:47:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:04:47 lr 0.000025	 wd 0.0000	time 0.1958 (0.2389)	loss 1.3717 (1.3575)	grad_norm 0.3572 (0.4073)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:48:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:23 lr 0.000025	 wd 0.0000	time 0.3664 (0.2388)	loss 1.4489 (1.3577)	grad_norm 0.4494 (0.4076)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:48:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:03:57 lr 0.000025	 wd 0.0000	time 0.2072 (0.2370)	loss 1.5718 (1.3574)	grad_norm 0.3711 (0.4080)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:48:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:32 lr 0.000025	 wd 0.0000	time 0.2083 (0.2354)	loss 1.2851 (1.3597)	grad_norm 0.4190 (0.4075)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:49:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:07 lr 0.000025	 wd 0.0000	time 0.2095 (0.2340)	loss 1.4383 (1.3588)	grad_norm 0.3674 (0.4070)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:49:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:44 lr 0.000025	 wd 0.0000	time 0.4570 (0.2342)	loss 1.0695 (1.3585)	grad_norm 0.3994 (0.4091)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:49:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:20 lr 0.000024	 wd 0.0000	time 0.1884 (0.2336)	loss 1.6102 (1.3590)	grad_norm 0.3578 (0.4087)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:50:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:01:56 lr 0.000024	 wd 0.0000	time 0.2209 (0.2326)	loss 1.8413 (1.3612)	grad_norm 0.4869 (0.4081)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:50:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:33 lr 0.000024	 wd 0.0000	time 0.1891 (0.2314)	loss 1.5103 (1.3620)	grad_norm 0.3750 (0.4077)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:51:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:09 lr 0.000024	 wd 0.0000	time 0.2035 (0.2312)	loss 1.0728 (1.3631)	grad_norm 0.3806 (0.4076)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:51:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:46 lr 0.000024	 wd 0.0000	time 0.1883 (0.2313)	loss 1.5865 (1.3633)	grad_norm 0.3880 (0.4068)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:51:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:23 lr 0.000024	 wd 0.0000	time 0.1938 (0.2305)	loss 1.0680 (1.3621)	grad_norm 0.3925 (0.4070)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:52:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1663 (0.2286)	loss 1.2163 (1.3622)	grad_norm 0.3467 (0.4073)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:52:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 15 training takes 0:09:36
[2024-07-15 01:52:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_15.pth saving......
[2024-07-15 01:52:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_15.pth saved !!!
[2024-07-15 01:52:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 41.326 (41.326)	Loss 0.4172 (0.4172)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 01:53:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.086 Acc@5 97.244
[2024-07-15 01:53:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 01:53:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 01:53:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][0/2502]	eta 12:20:24 lr 0.000024	 wd 0.0000	time 17.7555 (17.7555)	loss 1.2727 (1.2727)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:53:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:15:16 lr 0.000024	 wd 0.0000	time 0.2028 (0.3814)	loss 1.4701 (1.3562)	grad_norm 0.3930 (0.3956)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:54:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:11:32 lr 0.000024	 wd 0.0000	time 0.2672 (0.3010)	loss 1.3148 (1.3652)	grad_norm 0.8533 (0.4085)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:54:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:11:26 lr 0.000024	 wd 0.0000	time 0.2027 (0.3116)	loss 1.3627 (1.3777)	grad_norm 0.3937 (0.4081)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:54:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:09:59 lr 0.000024	 wd 0.0000	time 0.2174 (0.2854)	loss 1.2712 (1.3716)	grad_norm 0.3911 (0.4129)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:55:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:08:59 lr 0.000023	 wd 0.0000	time 0.2319 (0.2697)	loss 1.2620 (1.3818)	grad_norm 0.3675 (0.4090)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 01:55:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:14 lr 0.000023	 wd 0.0000	time 0.2721 (0.2602)	loss 1.0415 (1.3741)	grad_norm 0.3758 (0.4128)	loss_scale 4096.0000 (2204.7521)	mem 7646MB
[2024-07-15 01:56:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:45 lr 0.000023	 wd 0.0000	time 0.2044 (0.2581)	loss 1.3261 (1.3758)	grad_norm 0.4135 (0.4152)	loss_scale 4096.0000 (2474.5449)	mem 7646MB
[2024-07-15 01:56:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:07:09 lr 0.000023	 wd 0.0000	time 0.2144 (0.2525)	loss 1.3957 (1.3703)	grad_norm 0.3419 (0.4127)	loss_scale 4096.0000 (2676.9738)	mem 7646MB
[2024-07-15 01:56:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:37 lr 0.000023	 wd 0.0000	time 0.2135 (0.2479)	loss 1.5624 (1.3681)	grad_norm 0.3693 (0.4118)	loss_scale 4096.0000 (2834.4684)	mem 7646MB
[2024-07-15 01:57:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:06:06 lr 0.000023	 wd 0.0000	time 0.2025 (0.2438)	loss 1.5640 (1.3683)	grad_norm 0.4073 (0.4145)	loss_scale 4096.0000 (2960.4955)	mem 7646MB
[2024-07-15 01:57:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:40 lr 0.000023	 wd 0.0000	time 0.2161 (0.2426)	loss 1.3366 (1.3694)	grad_norm 0.3895 (0.4131)	loss_scale 4096.0000 (3063.6294)	mem 7646MB
[2024-07-15 01:57:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:15 lr 0.000023	 wd 0.0000	time 0.2188 (0.2420)	loss 1.4112 (1.3706)	grad_norm 0.4101 (0.4171)	loss_scale 4096.0000 (3149.5887)	mem 7646MB
[2024-07-15 01:58:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:04:47 lr 0.000023	 wd 0.0000	time 0.1906 (0.2394)	loss 1.1050 (1.3711)	grad_norm 0.3596 (0.4154)	loss_scale 4096.0000 (3222.3336)	mem 7646MB
[2024-07-15 01:58:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:21 lr 0.000023	 wd 0.0000	time 0.2172 (0.2373)	loss 1.2074 (1.3684)	grad_norm 0.3542 (0.4139)	loss_scale 4096.0000 (3284.6938)	mem 7646MB
[2024-07-15 01:58:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:03:56 lr 0.000022	 wd 0.0000	time 0.2201 (0.2360)	loss 1.4007 (1.3653)	grad_norm 0.3623 (0.4133)	loss_scale 4096.0000 (3338.7448)	mem 7646MB
[2024-07-15 01:59:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:33 lr 0.000022	 wd 0.0000	time 0.2072 (0.2370)	loss 1.3867 (1.3657)	grad_norm 0.3954 (0.4148)	loss_scale 4096.0000 (3386.0437)	mem 7646MB
[2024-07-15 01:59:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:09 lr 0.000022	 wd 0.0000	time 0.1992 (0.2357)	loss 1.1122 (1.3636)	grad_norm 0.6325 (0.4171)	loss_scale 4096.0000 (3427.7813)	mem 7646MB
[2024-07-15 02:00:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:44 lr 0.000022	 wd 0.0000	time 0.2106 (0.2344)	loss 1.2457 (1.3620)	grad_norm 0.3884 (0.4174)	loss_scale 4096.0000 (3464.8840)	mem 7646MB
[2024-07-15 02:00:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:20 lr 0.000022	 wd 0.0000	time 0.2164 (0.2333)	loss 1.1958 (1.3609)	grad_norm 0.3553 (0.4161)	loss_scale 4096.0000 (3498.0831)	mem 7646MB
[2024-07-15 02:00:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:01:57 lr 0.000022	 wd 0.0000	time 0.2742 (0.2334)	loss 1.4761 (1.3611)	grad_norm 0.4774 (0.4163)	loss_scale 4096.0000 (3527.9640)	mem 7646MB
[2024-07-15 02:01:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:33 lr 0.000022	 wd 0.0000	time 0.1973 (0.2326)	loss 1.3537 (1.3607)	grad_norm 0.3950 (0.4171)	loss_scale 4096.0000 (3555.0005)	mem 7646MB
[2024-07-15 02:01:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:10 lr 0.000022	 wd 0.0000	time 0.2396 (0.2318)	loss 1.4716 (1.3614)	grad_norm 0.3524 (0.4168)	loss_scale 4096.0000 (3579.5802)	mem 7646MB
[2024-07-15 02:01:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:46 lr 0.000022	 wd 0.0000	time 0.2241 (0.2309)	loss 1.2267 (1.3614)	grad_norm 0.3840 (0.4166)	loss_scale 4096.0000 (3602.0235)	mem 7646MB
[2024-07-15 02:02:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:23 lr 0.000022	 wd 0.0000	time 0.2172 (0.2305)	loss 1.5388 (1.3616)	grad_norm 0.3692 (0.4158)	loss_scale 4096.0000 (3622.5973)	mem 7646MB
[2024-07-15 02:02:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1595 (0.2293)	loss 1.3738 (1.3615)	grad_norm 0.3956 (0.4157)	loss_scale 4096.0000 (3641.5258)	mem 7646MB
[2024-07-15 02:02:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 16 training takes 0:09:40
[2024-07-15 02:03:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 21.774 (21.774)	Loss 0.4165 (0.4165)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 02:03:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.122 Acc@5 97.244
[2024-07-15 02:03:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 02:03:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 02:03:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][0/2502]	eta 11:03:48 lr 0.000021	 wd 0.0000	time 15.9188 (15.9188)	loss 1.4606 (1.4606)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:04:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:19:24 lr 0.000021	 wd 0.0000	time 0.2575 (0.4847)	loss 1.5576 (1.3350)	grad_norm 0.3854 (0.4046)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:04:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:13:24 lr 0.000021	 wd 0.0000	time 0.1839 (0.3495)	loss 1.5850 (1.3504)	grad_norm 0.3743 (0.4074)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:04:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:11:04 lr 0.000021	 wd 0.0000	time 0.2167 (0.3019)	loss 1.3366 (1.3471)	grad_norm 0.5620 (0.4085)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:05:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:09:43 lr 0.000021	 wd 0.0000	time 0.1784 (0.2774)	loss 1.1218 (1.3415)	grad_norm 0.3858 (0.4051)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:05:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:09:05 lr 0.000021	 wd 0.0000	time 0.3310 (0.2726)	loss 1.3710 (1.3415)	grad_norm 0.3738 (0.4024)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:06:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:31 lr 0.000021	 wd 0.0000	time 0.2102 (0.2687)	loss 1.1871 (1.3485)	grad_norm 0.3881 (0.4031)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:06:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:48 lr 0.000021	 wd 0.0000	time 0.2350 (0.2600)	loss 1.3269 (1.3542)	grad_norm 0.3709 (0.4037)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:06:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:07:11 lr 0.000021	 wd 0.0000	time 0.2233 (0.2537)	loss 1.3816 (1.3581)	grad_norm 0.3824 (0.4049)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:07:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:41 lr 0.000021	 wd 0.0000	time 0.2481 (0.2507)	loss 1.6012 (1.3595)	grad_norm 0.3534 (0.4037)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:07:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:15 lr 0.000020	 wd 0.0000	time 0.2214 (0.2497)	loss 1.5423 (1.3579)	grad_norm 0.3762 (0.4059)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:07:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:45 lr 0.000020	 wd 0.0000	time 0.1922 (0.2463)	loss 1.1164 (1.3584)	grad_norm 0.3467 (0.4071)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:08:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:16 lr 0.000020	 wd 0.0000	time 0.2521 (0.2433)	loss 1.5962 (1.3601)	grad_norm 0.3612 (0.4092)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:08:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:04:49 lr 0.000020	 wd 0.0000	time 0.2301 (0.2409)	loss 1.1677 (1.3601)	grad_norm 0.3803 (0.4088)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:08:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:25 lr 0.000020	 wd 0.0000	time 0.1905 (0.2405)	loss 1.4919 (1.3609)	grad_norm 0.3811 (0.4097)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:09:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:04:00 lr 0.000020	 wd 0.0000	time 0.1953 (0.2395)	loss 1.3864 (1.3617)	grad_norm 0.4083 (0.4100)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:09:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:34 lr 0.000020	 wd 0.0000	time 0.1945 (0.2378)	loss 1.5559 (1.3629)	grad_norm 0.3937 (0.4091)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:10:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:09 lr 0.000020	 wd 0.0000	time 0.2075 (0.2359)	loss 1.5777 (1.3649)	grad_norm 0.3762 (0.4089)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:10:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:45 lr 0.000020	 wd 0.0000	time 0.2338 (0.2354)	loss 1.3091 (1.3657)	grad_norm 0.4129 (inf)	loss_scale 2048.0000 (4084.6285)	mem 7646MB
[2024-07-15 02:10:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:22 lr 0.000020	 wd 0.0000	time 0.2061 (0.2361)	loss 1.1526 (1.3665)	grad_norm 0.3639 (inf)	loss_scale 2048.0000 (3977.4940)	mem 7646MB
[2024-07-15 02:11:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:01:57 lr 0.000019	 wd 0.0000	time 0.2347 (0.2348)	loss 1.5644 (1.3644)	grad_norm 0.4013 (inf)	loss_scale 2048.0000 (3881.0675)	mem 7646MB
[2024-07-15 02:11:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:33 lr 0.000019	 wd 0.0000	time 0.2480 (0.2337)	loss 1.4456 (1.3641)	grad_norm 0.4172 (inf)	loss_scale 2048.0000 (3793.8201)	mem 7646MB
[2024-07-15 02:11:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:10 lr 0.000019	 wd 0.0000	time 0.2294 (0.2329)	loss 1.3347 (1.3653)	grad_norm 0.3553 (inf)	loss_scale 2048.0000 (3714.5007)	mem 7646MB
[2024-07-15 02:12:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:47 lr 0.000019	 wd 0.0000	time 0.3794 (0.2333)	loss 1.4671 (1.3646)	grad_norm 0.3901 (inf)	loss_scale 2048.0000 (3642.0756)	mem 7646MB
[2024-07-15 02:12:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:23 lr 0.000019	 wd 0.0000	time 0.2058 (0.2327)	loss 1.4648 (1.3633)	grad_norm 0.3667 (inf)	loss_scale 2048.0000 (3575.6835)	mem 7646MB
[2024-07-15 02:12:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000019	 wd 0.0000	time 0.1655 (0.2307)	loss 1.5041 (1.3638)	grad_norm 0.3601 (inf)	loss_scale 2048.0000 (3514.6006)	mem 7646MB
[2024-07-15 02:13:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 17 training takes 0:09:41
[2024-07-15 02:13:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 18.771 (18.771)	Loss 0.4163 (0.4163)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 02:13:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.116 Acc@5 97.228
[2024-07-15 02:13:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 02:13:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 02:14:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][0/2502]	eta 23:46:39 lr 0.000019	 wd 0.0000	time 34.2126 (34.2126)	loss 1.6071 (1.6071)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:14:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:21:51 lr 0.000019	 wd 0.0000	time 0.1827 (0.5461)	loss 1.5494 (1.4033)	grad_norm 0.3878 (0.4061)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:14:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:14:28 lr 0.000019	 wd 0.0000	time 0.1689 (0.3773)	loss 1.4780 (1.3836)	grad_norm 0.3654 (0.4018)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:15:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:12:05 lr 0.000019	 wd 0.0000	time 0.4234 (0.3294)	loss 1.7183 (1.3833)	grad_norm 0.5059 (0.4018)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:15:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:11:14 lr 0.000019	 wd 0.0000	time 0.2177 (0.3208)	loss 1.4492 (1.3765)	grad_norm 0.3821 (0.4007)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:16:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:09:55 lr 0.000018	 wd 0.0000	time 0.1956 (0.2974)	loss 1.3101 (1.3660)	grad_norm 0.3762 (0.3986)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:16:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:08:57 lr 0.000018	 wd 0.0000	time 0.2341 (0.2826)	loss 1.6332 (1.3669)	grad_norm 0.3534 (0.4042)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:16:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:08:13 lr 0.000018	 wd 0.0000	time 0.2666 (0.2738)	loss 1.4419 (1.3674)	grad_norm 0.3318 (0.4061)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:17:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:41 lr 0.000018	 wd 0.0000	time 0.2028 (0.2714)	loss 1.1039 (1.3648)	grad_norm 0.4096 (0.4052)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:17:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:07:04 lr 0.000018	 wd 0.0000	time 0.2228 (0.2647)	loss 1.1837 (1.3610)	grad_norm 0.5094 (0.4061)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:17:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:29 lr 0.000018	 wd 0.0000	time 0.2393 (0.2592)	loss 1.0426 (1.3645)	grad_norm 0.3603 (0.4054)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:18:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:57 lr 0.000018	 wd 0.0000	time 0.2353 (0.2548)	loss 1.2613 (1.3641)	grad_norm 0.3698 (0.4058)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:18:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:30 lr 0.000018	 wd 0.0000	time 0.2197 (0.2537)	loss 1.6629 (1.3644)	grad_norm 0.4067 (0.4053)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:18:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:05:02 lr 0.000018	 wd 0.0000	time 0.1941 (0.2513)	loss 1.4180 (1.3650)	grad_norm 0.4082 (0.4082)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:19:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:33 lr 0.000018	 wd 0.0000	time 0.2172 (0.2484)	loss 1.2259 (1.3649)	grad_norm 0.3508 (0.4080)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:19:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:04:06 lr 0.000017	 wd 0.0000	time 0.2281 (0.2459)	loss 1.5921 (1.3640)	grad_norm 0.3804 (0.4074)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:20:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:40 lr 0.000017	 wd 0.0000	time 0.1977 (0.2445)	loss 1.4823 (1.3634)	grad_norm 0.3896 (0.4101)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:20:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:15 lr 0.000017	 wd 0.0000	time 0.1920 (0.2443)	loss 1.4773 (1.3637)	grad_norm 0.4239 (0.4094)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:20:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:50 lr 0.000017	 wd 0.0000	time 0.1981 (0.2425)	loss 1.3304 (1.3645)	grad_norm 0.3813 (0.4087)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:21:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:25 lr 0.000017	 wd 0.0000	time 0.2154 (0.2409)	loss 1.4758 (1.3637)	grad_norm 0.3559 (0.4088)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:21:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:02:00 lr 0.000017	 wd 0.0000	time 0.2109 (0.2396)	loss 1.3728 (1.3659)	grad_norm 0.5036 (0.4094)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:21:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:36 lr 0.000017	 wd 0.0000	time 0.2124 (0.2396)	loss 1.4502 (1.3652)	grad_norm 0.3716 (0.4119)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:22:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:12 lr 0.000017	 wd 0.0000	time 0.2010 (0.2387)	loss 1.3454 (1.3652)	grad_norm 0.4059 (0.4116)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:22:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:47 lr 0.000017	 wd 0.0000	time 0.2130 (0.2375)	loss 1.5007 (1.3655)	grad_norm 0.3610 (0.4110)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:23:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:24 lr 0.000017	 wd 0.0000	time 0.2077 (0.2363)	loss 1.5143 (1.3669)	grad_norm 0.4096 (0.4106)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:23:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1642 (0.2345)	loss 1.4936 (1.3664)	grad_norm 0.3503 (0.4100)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:23:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 18 training takes 0:09:51
[2024-07-15 02:23:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 32.405 (32.405)	Loss 0.4180 (0.4180)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 02:24:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.128 Acc@5 97.246
[2024-07-15 02:24:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 02:24:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 02:24:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][0/2502]	eta 11:05:01 lr 0.000016	 wd 0.0000	time 15.9477 (15.9477)	loss 1.4380 (1.4380)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:24:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:15:14 lr 0.000016	 wd 0.0000	time 0.2271 (0.3807)	loss 1.0982 (1.3782)	grad_norm 0.3928 (0.3900)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:25:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:13:04 lr 0.000016	 wd 0.0000	time 0.1942 (0.3410)	loss 1.4443 (1.3717)	grad_norm 0.5032 (0.3914)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:25:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:10:50 lr 0.000016	 wd 0.0000	time 0.1947 (0.2955)	loss 1.3111 (1.3842)	grad_norm 0.3950 (0.3929)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:25:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:09:35 lr 0.000016	 wd 0.0000	time 0.2127 (0.2736)	loss 1.5153 (1.3835)	grad_norm 0.3749 (0.3967)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:26:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:08:41 lr 0.000016	 wd 0.0000	time 0.2290 (0.2605)	loss 1.5153 (1.3788)	grad_norm 0.3594 (0.4036)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:26:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:26 lr 0.000016	 wd 0.0000	time 0.2009 (0.2663)	loss 1.4772 (1.3738)	grad_norm 0.3679 (0.4013)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:27:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:07:45 lr 0.000016	 wd 0.0000	time 0.1755 (0.2582)	loss 1.6476 (1.3758)	grad_norm 0.4220 (0.4010)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 02:27:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:07:08 lr 0.000016	 wd 0.0000	time 0.1942 (0.2518)	loss 1.3653 (1.3747)	grad_norm 0.3831 (0.3999)	loss_scale 4096.0000 (2083.7953)	mem 7646MB
[2024-07-15 02:27:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:06:35 lr 0.000016	 wd 0.0000	time 0.2105 (0.2469)	loss 1.2464 (1.3742)	grad_norm 1.4662 (0.4087)	loss_scale 4096.0000 (2307.1254)	mem 7646MB
[2024-07-15 02:28:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:09 lr 0.000016	 wd 0.0000	time 0.2382 (0.2461)	loss 1.5965 (1.3750)	grad_norm 0.4216 (0.4092)	loss_scale 4096.0000 (2485.8342)	mem 7646MB
[2024-07-15 02:28:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:43 lr 0.000015	 wd 0.0000	time 0.2271 (0.2447)	loss 0.9243 (1.3736)	grad_norm 0.3576 (0.4083)	loss_scale 4096.0000 (2632.0799)	mem 7646MB
[2024-07-15 02:28:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:14 lr 0.000015	 wd 0.0000	time 0.2163 (0.2415)	loss 1.1199 (1.3718)	grad_norm 0.3941 (0.4103)	loss_scale 4096.0000 (2753.9717)	mem 7646MB
[2024-07-15 02:29:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:04:47 lr 0.000015	 wd 0.0000	time 0.1965 (0.2390)	loss 1.5794 (1.3723)	grad_norm 0.6629 (0.4091)	loss_scale 4096.0000 (2857.1253)	mem 7646MB
[2024-07-15 02:29:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:21 lr 0.000015	 wd 0.0000	time 0.2221 (0.2375)	loss 1.4557 (1.3732)	grad_norm 0.3964 (0.4082)	loss_scale 4096.0000 (2945.5532)	mem 7646MB
[2024-07-15 02:30:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:03:58 lr 0.000015	 wd 0.0000	time 0.2091 (0.2377)	loss 1.2167 (1.3730)	grad_norm 0.3515 (0.4072)	loss_scale 4096.0000 (3022.1985)	mem 7646MB
[2024-07-15 02:30:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:33 lr 0.000015	 wd 0.0000	time 0.2006 (0.2365)	loss 1.3111 (1.3732)	grad_norm 0.3664 (0.4083)	loss_scale 4096.0000 (3089.2692)	mem 7646MB
[2024-07-15 02:30:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:08 lr 0.000015	 wd 0.0000	time 0.1960 (0.2350)	loss 1.4033 (1.3739)	grad_norm 0.3624 (0.4082)	loss_scale 4096.0000 (3148.4539)	mem 7646MB
[2024-07-15 02:31:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:44 lr 0.000015	 wd 0.0000	time 0.1992 (0.2337)	loss 1.3360 (1.3734)	grad_norm 0.3790 (0.4080)	loss_scale 4096.0000 (3201.0661)	mem 7646MB
[2024-07-15 02:31:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:21 lr 0.000015	 wd 0.0000	time 0.1681 (0.2348)	loss 1.4244 (1.3738)	grad_norm 0.3464 (0.4079)	loss_scale 4096.0000 (3248.1431)	mem 7646MB
[2024-07-15 02:31:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:57 lr 0.000015	 wd 0.0000	time 0.1962 (0.2341)	loss 1.0760 (1.3733)	grad_norm 0.4510 (0.4070)	loss_scale 4096.0000 (3290.5147)	mem 7646MB
[2024-07-15 02:32:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:33 lr 0.000014	 wd 0.0000	time 0.2016 (0.2331)	loss 1.1928 (1.3722)	grad_norm 0.3751 (0.4089)	loss_scale 4096.0000 (3328.8529)	mem 7646MB
[2024-07-15 02:32:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:10 lr 0.000014	 wd 0.0000	time 0.2056 (0.2320)	loss 1.4873 (1.3700)	grad_norm 0.4367 (0.4081)	loss_scale 4096.0000 (3363.7074)	mem 7646MB
[2024-07-15 02:33:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:46 lr 0.000014	 wd 0.0000	time 0.2148 (0.2317)	loss 1.4088 (1.3697)	grad_norm 0.5362 (0.4097)	loss_scale 4096.0000 (3395.5324)	mem 7646MB
[2024-07-15 02:33:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:23 lr 0.000014	 wd 0.0000	time 0.2041 (0.2318)	loss 1.5520 (1.3711)	grad_norm 0.3977 (0.4093)	loss_scale 4096.0000 (3424.7064)	mem 7646MB
[2024-07-15 02:33:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1515 (0.2298)	loss 1.2343 (1.3710)	grad_norm 0.3782 (0.4088)	loss_scale 4096.0000 (3451.5474)	mem 7646MB
[2024-07-15 02:33:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 19 training takes 0:09:39
[2024-07-15 02:34:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 21.417 (21.417)	Loss 0.4177 (0.4177)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 02:34:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.118 Acc@5 97.242
[2024-07-15 02:34:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 02:34:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 02:34:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][0/2502]	eta 21:41:13 lr 0.000014	 wd 0.0000	time 31.2044 (31.2044)	loss 1.0005 (1.0005)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:35:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:21:35 lr 0.000014	 wd 0.0000	time 0.2179 (0.5392)	loss 1.5877 (1.3671)	grad_norm 0.4765 (0.4009)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:35:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:14:17 lr 0.000014	 wd 0.0000	time 0.1913 (0.3727)	loss 1.4373 (1.3686)	grad_norm 0.3986 (0.3967)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:35:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:11:38 lr 0.000014	 wd 0.0000	time 0.2239 (0.3171)	loss 1.4801 (1.3650)	grad_norm 0.3761 (0.4086)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:36:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:10:26 lr 0.000014	 wd 0.0000	time 0.2297 (0.2983)	loss 1.4111 (1.3742)	grad_norm 0.4055 (0.4060)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:36:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:09:23 lr 0.000014	 wd 0.0000	time 0.2036 (0.2814)	loss 1.5435 (1.3761)	grad_norm 0.3702 (0.4095)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:37:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:08:32 lr 0.000014	 wd 0.0000	time 0.2156 (0.2697)	loss 1.3315 (1.3725)	grad_norm 0.4295 (0.4085)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:37:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:50 lr 0.000013	 wd 0.0000	time 0.1880 (0.2610)	loss 1.4831 (1.3747)	grad_norm 0.4182 (0.4094)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:37:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:07:16 lr 0.000013	 wd 0.0000	time 0.2595 (0.2563)	loss 1.2652 (1.3718)	grad_norm 0.3420 (0.4071)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:38:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:47 lr 0.000013	 wd 0.0000	time 0.1857 (0.2544)	loss 1.5935 (1.3744)	grad_norm 0.4146 (0.4070)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:38:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:15 lr 0.000013	 wd 0.0000	time 0.2055 (0.2503)	loss 1.2983 (1.3735)	grad_norm 0.3512 (0.4050)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:38:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:45 lr 0.000013	 wd 0.0000	time 0.2276 (0.2467)	loss 1.3554 (1.3711)	grad_norm 0.3639 (0.4061)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:39:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:17 lr 0.000013	 wd 0.0000	time 0.2186 (0.2436)	loss 1.4277 (1.3681)	grad_norm 0.4464 (0.4065)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:39:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:04:52 lr 0.000013	 wd 0.0000	time 0.3348 (0.2432)	loss 1.3156 (1.3668)	grad_norm 0.3727 (0.4062)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:40:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:26 lr 0.000013	 wd 0.0000	time 0.2820 (0.2418)	loss 1.4040 (1.3685)	grad_norm 0.3923 (0.4068)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:40:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:04:00 lr 0.000013	 wd 0.0000	time 0.1898 (0.2398)	loss 1.4435 (1.3690)	grad_norm 0.3791 (0.4064)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:40:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:34 lr 0.000013	 wd 0.0000	time 0.2172 (0.2379)	loss 1.7037 (1.3693)	grad_norm 0.4014 (0.4059)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:41:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:10 lr 0.000012	 wd 0.0000	time 0.1991 (0.2371)	loss 1.5300 (1.3687)	grad_norm 0.3668 (0.4056)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:41:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:46 lr 0.000012	 wd 0.0000	time 0.1962 (0.2377)	loss 1.3053 (1.3679)	grad_norm 0.3930 (0.4069)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:41:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:22 lr 0.000012	 wd 0.0000	time 0.2083 (0.2365)	loss 1.5291 (1.3699)	grad_norm 0.3504 (0.4074)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:42:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:01:58 lr 0.000012	 wd 0.0000	time 0.1879 (0.2352)	loss 1.4969 (1.3694)	grad_norm 0.5177 (0.4075)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:42:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:34 lr 0.000012	 wd 0.0000	time 0.2639 (0.2343)	loss 1.3150 (1.3701)	grad_norm 0.3748 (0.4066)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:42:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:10 lr 0.000012	 wd 0.0000	time 0.1875 (0.2348)	loss 1.2504 (1.3716)	grad_norm 0.3632 (0.4060)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 02:43:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:47 lr 0.000012	 wd 0.0000	time 0.1989 (0.2340)	loss 1.4053 (1.3716)	grad_norm 0.3690 (0.4058)	loss_scale 8192.0000 (4124.4815)	mem 7646MB
[2024-07-15 02:43:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:23 lr 0.000012	 wd 0.0000	time 0.2027 (0.2331)	loss 1.3589 (1.3719)	grad_norm 0.3431 (0.4060)	loss_scale 8192.0000 (4293.8909)	mem 7646MB
[2024-07-15 02:44:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000012	 wd 0.0000	time 0.1553 (0.2309)	loss 1.6357 (1.3726)	grad_norm 0.3856 (0.4058)	loss_scale 8192.0000 (4449.7529)	mem 7646MB
[2024-07-15 02:44:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 20 training takes 0:09:43
[2024-07-15 02:44:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 41.951 (41.951)	Loss 0.4180 (0.4180)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 02:45:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.120 Acc@5 97.250
[2024-07-15 02:45:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 02:45:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 02:45:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][0/2502]	eta 11:38:03 lr 0.000012	 wd 0.0000	time 16.7402 (16.7402)	loss 1.5742 (1.5742)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:45:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:14:50 lr 0.000012	 wd 0.0000	time 0.2397 (0.3709)	loss 1.4653 (1.3921)	grad_norm 0.3987 (0.4012)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:46:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:13:13 lr 0.000012	 wd 0.0000	time 0.2508 (0.3445)	loss 0.9005 (1.3726)	grad_norm 0.4093 (0.4187)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:46:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:10:57 lr 0.000012	 wd 0.0000	time 0.1972 (0.2985)	loss 1.4020 (1.3655)	grad_norm 0.4086 (0.4130)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:46:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:09:40 lr 0.000011	 wd 0.0000	time 0.2289 (0.2762)	loss 1.4458 (1.3668)	grad_norm 0.4042 (0.4146)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:47:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:08:44 lr 0.000011	 wd 0.0000	time 0.2057 (0.2619)	loss 1.3645 (1.3662)	grad_norm 0.3832 (0.4112)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:47:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:30 lr 0.000011	 wd 0.0000	time 0.3747 (0.2685)	loss 1.2059 (1.3668)	grad_norm 0.4296 (0.4094)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:48:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:07:50 lr 0.000011	 wd 0.0000	time 0.2156 (0.2613)	loss 1.2907 (1.3614)	grad_norm 0.3498 (0.4103)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:48:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:13 lr 0.000011	 wd 0.0000	time 0.1975 (0.2546)	loss 1.2260 (1.3610)	grad_norm 0.3749 (0.4105)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:48:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:39 lr 0.000011	 wd 0.0000	time 0.2013 (0.2493)	loss 1.5499 (1.3617)	grad_norm 0.3949 (0.4085)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:49:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:12 lr 0.000011	 wd 0.0000	time 0.2756 (0.2477)	loss 1.0588 (1.3609)	grad_norm 0.4280 (0.4071)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:49:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:05:46 lr 0.000011	 wd 0.0000	time 0.2113 (0.2469)	loss 1.4665 (1.3609)	grad_norm 0.3517 (0.4083)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:49:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:17 lr 0.000011	 wd 0.0000	time 0.1911 (0.2436)	loss 1.3379 (1.3621)	grad_norm 0.3688 (0.4066)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:50:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:49 lr 0.000011	 wd 0.0000	time 0.1962 (0.2410)	loss 1.5243 (1.3622)	grad_norm 0.3624 (0.4065)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:50:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:23 lr 0.000011	 wd 0.0000	time 0.2001 (0.2392)	loss 1.4418 (1.3627)	grad_norm 0.3661 (0.4058)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:51:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:04:00 lr 0.000010	 wd 0.0000	time 0.2222 (0.2397)	loss 1.6488 (1.3623)	grad_norm 0.3940 (0.4050)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:51:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:34 lr 0.000010	 wd 0.0000	time 0.2036 (0.2383)	loss 1.2160 (1.3617)	grad_norm 0.4020 (0.4054)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:51:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:09 lr 0.000010	 wd 0.0000	time 0.1875 (0.2366)	loss 1.4835 (1.3619)	grad_norm 0.4248 (0.4077)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:52:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:45 lr 0.000010	 wd 0.0000	time 0.2522 (0.2352)	loss 1.0272 (1.3623)	grad_norm 0.4235 (0.4081)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:52:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:21 lr 0.000010	 wd 0.0000	time 0.2052 (0.2348)	loss 1.0024 (1.3610)	grad_norm 0.3758 (0.4089)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:52:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:58 lr 0.000010	 wd 0.0000	time 0.2355 (0.2354)	loss 1.4069 (1.3605)	grad_norm 0.3688 (0.4083)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:53:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:34 lr 0.000010	 wd 0.0000	time 0.2056 (0.2343)	loss 1.1889 (1.3608)	grad_norm 0.3733 (0.4079)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:53:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:10 lr 0.000010	 wd 0.0000	time 0.2103 (0.2332)	loss 1.5714 (1.3587)	grad_norm 0.4629 (0.4074)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:54:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:46 lr 0.000010	 wd 0.0000	time 0.2135 (0.2326)	loss 1.5726 (1.3585)	grad_norm 0.3620 (0.4068)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:54:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:23 lr 0.000010	 wd 0.0000	time 0.2084 (0.2329)	loss 1.3789 (1.3598)	grad_norm 0.3836 (0.4065)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:54:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1453 (0.2307)	loss 1.3316 (1.3595)	grad_norm 0.4018 (0.4081)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:54:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 21 training takes 0:09:42
[2024-07-15 02:55:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 19.710 (19.710)	Loss 0.4175 (0.4175)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 02:55:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.104 Acc@5 97.252
[2024-07-15 02:55:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 02:55:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 02:55:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][0/2502]	eta 1 day, 0:19:53 lr 0.000010	 wd 0.0000	time 35.0095 (35.0095)	loss 1.3243 (1.3243)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:56:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:22:05 lr 0.000010	 wd 0.0000	time 0.2090 (0.5518)	loss 1.2726 (1.3705)	grad_norm 0.3656 (0.4009)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:56:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:14:34 lr 0.000009	 wd 0.0000	time 0.2184 (0.3799)	loss 1.1928 (1.3671)	grad_norm 0.3384 (0.4148)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:57:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:11:50 lr 0.000009	 wd 0.0000	time 0.2559 (0.3228)	loss 1.5139 (1.3711)	grad_norm 0.9529 (0.4155)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:57:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:10:36 lr 0.000009	 wd 0.0000	time 0.3339 (0.3026)	loss 1.4307 (1.3750)	grad_norm 0.4415 (0.4115)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:57:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:09:30 lr 0.000009	 wd 0.0000	time 0.2014 (0.2850)	loss 0.9031 (1.3742)	grad_norm 0.3794 (0.4087)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:58:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:38 lr 0.000009	 wd 0.0000	time 0.1986 (0.2726)	loss 1.3729 (1.3773)	grad_norm 0.3886 (0.4093)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:58:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:54 lr 0.000009	 wd 0.0000	time 0.2073 (0.2633)	loss 0.8984 (1.3727)	grad_norm 0.3909 (0.4084)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:58:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:07:20 lr 0.000009	 wd 0.0000	time 0.2538 (0.2590)	loss 1.3806 (1.3685)	grad_norm 0.3728 (0.4069)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:59:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:51 lr 0.000009	 wd 0.0000	time 0.2159 (0.2569)	loss 1.3503 (1.3676)	grad_norm 0.3930 (0.4056)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:59:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:18 lr 0.000009	 wd 0.0000	time 0.2156 (0.2522)	loss 1.5628 (1.3698)	grad_norm 0.4011 (0.4056)	loss_scale 8192.0000 (8192.0000)	mem 7646MB
[2024-07-15 02:59:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:48 lr 0.000009	 wd 0.0000	time 0.2199 (0.2483)	loss 1.4022 (1.3674)	grad_norm 0.6445 (nan)	loss_scale 4096.0000 (8177.1190)	mem 7646MB
[2024-07-15 03:00:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:19 lr 0.000009	 wd 0.0000	time 0.2409 (0.2454)	loss 1.3471 (1.3661)	grad_norm 0.4458 (nan)	loss_scale 4096.0000 (7837.3089)	mem 7646MB
[2024-07-15 03:00:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:04:55 lr 0.000009	 wd 0.0000	time 0.2036 (0.2462)	loss 0.9326 (1.3667)	grad_norm 0.3638 (nan)	loss_scale 4096.0000 (7549.7371)	mem 7646MB
[2024-07-15 03:01:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:28 lr 0.000008	 wd 0.0000	time 0.2149 (0.2439)	loss 1.5734 (1.3687)	grad_norm 1.8421 (nan)	loss_scale 4096.0000 (7303.2177)	mem 7646MB
[2024-07-15 03:01:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:04:02 lr 0.000008	 wd 0.0000	time 0.2288 (0.2417)	loss 1.3213 (1.3694)	grad_norm 0.4615 (nan)	loss_scale 4096.0000 (7089.5456)	mem 7646MB
[2024-07-15 03:01:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:36 lr 0.000008	 wd 0.0000	time 0.2027 (0.2396)	loss 1.5462 (1.3697)	grad_norm 0.3864 (nan)	loss_scale 4096.0000 (6902.5659)	mem 7646MB
[2024-07-15 03:02:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:11 lr 0.000008	 wd 0.0000	time 0.2256 (0.2390)	loss 1.3129 (1.3694)	grad_norm 0.3978 (nan)	loss_scale 4096.0000 (6737.5708)	mem 7646MB
[2024-07-15 03:02:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:47 lr 0.000008	 wd 0.0000	time 0.2560 (0.2393)	loss 1.5905 (1.3687)	grad_norm 0.3885 (nan)	loss_scale 4096.0000 (6590.8984)	mem 7646MB
[2024-07-15 03:02:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:23 lr 0.000008	 wd 0.0000	time 0.1979 (0.2379)	loss 1.5562 (1.3682)	grad_norm 0.4050 (nan)	loss_scale 4096.0000 (6459.6570)	mem 7646MB
[2024-07-15 03:03:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:58 lr 0.000008	 wd 0.0000	time 0.2504 (0.2365)	loss 1.5151 (1.3673)	grad_norm 0.3394 (nan)	loss_scale 4096.0000 (6341.5332)	mem 7646MB
[2024-07-15 03:03:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:34 lr 0.000008	 wd 0.0000	time 0.2249 (0.2358)	loss 1.4421 (1.3678)	grad_norm 0.3918 (nan)	loss_scale 4096.0000 (6234.6540)	mem 7646MB
[2024-07-15 03:04:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:11 lr 0.000008	 wd 0.0000	time 0.1808 (0.2358)	loss 1.4447 (1.3660)	grad_norm 0.3792 (nan)	loss_scale 4096.0000 (6137.4866)	mem 7646MB
[2024-07-15 03:04:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:47 lr 0.000008	 wd 0.0000	time 0.1846 (0.2347)	loss 1.5011 (1.3661)	grad_norm 0.3852 (nan)	loss_scale 4096.0000 (6048.7649)	mem 7646MB
[2024-07-15 03:04:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:23 lr 0.000008	 wd 0.0000	time 0.1979 (0.2337)	loss 1.2169 (1.3654)	grad_norm 0.3685 (nan)	loss_scale 4096.0000 (5967.4336)	mem 7646MB
[2024-07-15 03:05:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1787 (0.2316)	loss 0.9932 (1.3645)	grad_norm 0.3527 (nan)	loss_scale 4096.0000 (5892.6062)	mem 7646MB
[2024-07-15 03:05:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 22 training takes 0:09:46
[2024-07-15 03:05:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 38.060 (38.060)	Loss 0.4175 (0.4175)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 03:06:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.126 Acc@5 97.250
[2024-07-15 03:06:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 03:06:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 03:06:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][0/2502]	eta 11:07:25 lr 0.000008	 wd 0.0000	time 16.0053 (16.0053)	loss 1.1678 (1.1678)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:06:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:14:51 lr 0.000008	 wd 0.0000	time 0.2269 (0.3712)	loss 1.5820 (1.4023)	grad_norm 0.3595 (0.4087)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:07:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:13:42 lr 0.000007	 wd 0.0000	time 0.1932 (0.3574)	loss 1.5493 (1.3809)	grad_norm 0.3752 (0.4012)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:07:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:11:17 lr 0.000007	 wd 0.0000	time 0.2262 (0.3078)	loss 1.5190 (1.3744)	grad_norm 0.4230 (0.3969)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:08:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:09:53 lr 0.000007	 wd 0.0000	time 0.1965 (0.2824)	loss 1.5351 (1.3660)	grad_norm 0.3748 (0.3976)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:08:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:08:56 lr 0.000007	 wd 0.0000	time 0.2665 (0.2678)	loss 1.6901 (1.3709)	grad_norm 0.3797 (0.4006)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:08:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:08:22 lr 0.000007	 wd 0.0000	time 0.1992 (0.2640)	loss 1.1431 (1.3707)	grad_norm 0.3521 (0.4007)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:09:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:44 lr 0.000007	 wd 0.0000	time 0.2018 (0.2576)	loss 1.4181 (1.3680)	grad_norm 0.3915 (0.4029)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:09:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:07:08 lr 0.000007	 wd 0.0000	time 0.2209 (0.2518)	loss 1.6998 (1.3667)	grad_norm 0.3805 (0.4002)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:09:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:06:35 lr 0.000007	 wd 0.0000	time 0.1960 (0.2471)	loss 1.7098 (1.3633)	grad_norm 0.4397 (0.4004)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:10:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:08 lr 0.000007	 wd 0.0000	time 0.2389 (0.2454)	loss 1.1500 (1.3614)	grad_norm 0.3477 (0.4019)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:10:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:42 lr 0.000007	 wd 0.0000	time 0.2416 (0.2444)	loss 0.8881 (1.3570)	grad_norm 0.3650 (0.4015)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:10:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:14 lr 0.000007	 wd 0.0000	time 0.1863 (0.2416)	loss 1.5715 (1.3588)	grad_norm 0.4538 (0.4031)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:11:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:04:47 lr 0.000007	 wd 0.0000	time 0.2271 (0.2393)	loss 1.4517 (1.3602)	grad_norm 0.3441 (0.4055)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:11:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:21 lr 0.000007	 wd 0.0000	time 0.2047 (0.2376)	loss 1.5873 (1.3602)	grad_norm 0.3773 (0.4086)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:12:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:03:58 lr 0.000006	 wd 0.0000	time 0.1908 (0.2379)	loss 1.2806 (1.3624)	grad_norm 0.4236 (0.4087)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:12:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:33 lr 0.000006	 wd 0.0000	time 0.2055 (0.2366)	loss 1.1725 (1.3617)	grad_norm 0.3524 (0.4079)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:12:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:08 lr 0.000006	 wd 0.0000	time 0.2040 (0.2351)	loss 1.3249 (1.3620)	grad_norm 0.4924 (0.4077)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:13:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:43 lr 0.000006	 wd 0.0000	time 0.1986 (0.2336)	loss 1.4454 (1.3615)	grad_norm 0.4076 (0.4087)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:13:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:20 lr 0.000006	 wd 0.0000	time 0.2373 (0.2331)	loss 1.2438 (1.3641)	grad_norm 0.4607 (0.4089)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:13:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:01:57 lr 0.000006	 wd 0.0000	time 0.2061 (0.2333)	loss 1.4599 (1.3628)	grad_norm 0.3836 (0.4082)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:14:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:33 lr 0.000006	 wd 0.0000	time 0.1887 (0.2323)	loss 1.7088 (1.3633)	grad_norm 0.3682 (0.4083)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:14:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:09 lr 0.000006	 wd 0.0000	time 0.2381 (0.2314)	loss 1.4751 (1.3612)	grad_norm 0.4355 (inf)	loss_scale 2048.0000 (4008.5343)	mem 7646MB
[2024-07-15 03:14:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:46 lr 0.000006	 wd 0.0000	time 0.2111 (0.2308)	loss 1.5981 (1.3613)	grad_norm 0.4108 (inf)	loss_scale 2048.0000 (3923.3307)	mem 7646MB
[2024-07-15 03:15:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:23 lr 0.000006	 wd 0.0000	time 0.1861 (0.2311)	loss 1.5501 (1.3619)	grad_norm 0.3569 (inf)	loss_scale 2048.0000 (3845.2245)	mem 7646MB
[2024-07-15 03:15:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000006	 wd 0.0000	time 0.1512 (0.2291)	loss 1.4407 (1.3626)	grad_norm 0.3773 (inf)	loss_scale 2048.0000 (3773.3643)	mem 7646MB
[2024-07-15 03:15:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 23 training takes 0:09:43
[2024-07-15 03:16:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 19.650 (19.650)	Loss 0.4175 (0.4175)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 03:16:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.098 Acc@5 97.256
[2024-07-15 03:16:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 03:16:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 03:17:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][0/2502]	eta 1 day, 3:26:09 lr 0.000006	 wd 0.0000	time 39.4764 (39.4764)	loss 1.5903 (1.5903)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:17:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:24:03 lr 0.000006	 wd 0.0000	time 0.2064 (0.6010)	loss 1.1602 (1.4021)	grad_norm 0.4308 (0.4079)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:17:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:15:28 lr 0.000006	 wd 0.0000	time 0.2017 (0.4032)	loss 1.4189 (1.3839)	grad_norm 0.3808 (0.4027)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:18:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:12:39 lr 0.000006	 wd 0.0000	time 0.3018 (0.3450)	loss 1.6282 (1.3770)	grad_norm 0.3960 (0.4102)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:18:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:11:47 lr 0.000005	 wd 0.0000	time 0.1811 (0.3366)	loss 1.4172 (1.3736)	grad_norm 0.3886 (0.4130)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:19:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:10:21 lr 0.000005	 wd 0.0000	time 0.1910 (0.3102)	loss 1.6761 (1.3750)	grad_norm 0.4067 (0.4152)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:19:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:09:16 lr 0.000005	 wd 0.0000	time 0.1903 (0.2928)	loss 1.4077 (1.3719)	grad_norm 0.4353 (0.4177)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:19:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:08:29 lr 0.000005	 wd 0.0000	time 0.2409 (0.2829)	loss 1.3433 (1.3729)	grad_norm 0.3709 (0.4173)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:20:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:08:06 lr 0.000005	 wd 0.0000	time 0.2147 (0.2859)	loss 1.4259 (1.3739)	grad_norm 0.3736 (0.4142)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:20:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:07:24 lr 0.000005	 wd 0.0000	time 0.1961 (0.2772)	loss 1.5585 (1.3707)	grad_norm 0.3938 (0.4141)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:20:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:46 lr 0.000005	 wd 0.0000	time 0.1825 (0.2706)	loss 1.2248 (1.3710)	grad_norm 0.3872 (0.4134)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:21:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:06:12 lr 0.000005	 wd 0.0000	time 0.2258 (0.2658)	loss 1.5069 (1.3700)	grad_norm 0.3797 (0.4121)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:21:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:50 lr 0.000005	 wd 0.0000	time 0.2042 (0.2694)	loss 1.2554 (1.3681)	grad_norm 0.4168 (0.4113)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:22:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:05:18 lr 0.000005	 wd 0.0000	time 0.2010 (0.2647)	loss 1.3967 (1.3674)	grad_norm 0.4203 (0.4097)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:22:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:47 lr 0.000005	 wd 0.0000	time 0.2219 (0.2609)	loss 1.3480 (1.3659)	grad_norm 0.3935 (0.4091)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:22:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:18 lr 0.000005	 wd 0.0000	time 0.2489 (0.2577)	loss 0.9772 (1.3643)	grad_norm 0.3582 (0.4085)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:23:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:52 lr 0.000005	 wd 0.0000	time 0.2115 (0.2580)	loss 1.5236 (1.3639)	grad_norm 0.4697 (0.4087)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:23:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:24 lr 0.000005	 wd 0.0000	time 0.2066 (0.2555)	loss 1.6875 (1.3652)	grad_norm 0.4468 (0.4089)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:24:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:57 lr 0.000005	 wd 0.0000	time 0.1891 (0.2531)	loss 1.1412 (1.3631)	grad_norm 0.3592 (0.4097)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:24:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:30 lr 0.000005	 wd 0.0000	time 0.1976 (0.2508)	loss 1.4105 (1.3642)	grad_norm 0.3539 (0.4090)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:24:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:02:05 lr 0.000004	 wd 0.0000	time 0.2166 (0.2496)	loss 1.3851 (1.3647)	grad_norm 0.4353 (0.4091)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:25:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:40 lr 0.000004	 wd 0.0000	time 0.2375 (0.2496)	loss 1.5397 (1.3639)	grad_norm 0.3775 (0.4090)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:25:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:14 lr 0.000004	 wd 0.0000	time 0.2010 (0.2479)	loss 1.4150 (1.3637)	grad_norm 0.4527 (0.4089)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:25:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:49 lr 0.000004	 wd 0.0000	time 0.1856 (0.2464)	loss 1.7428 (1.3634)	grad_norm 0.4431 (0.4115)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:26:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:25 lr 0.000004	 wd 0.0000	time 0.1961 (0.2453)	loss 1.5093 (1.3633)	grad_norm 0.3555 (0.4105)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:26:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000004	 wd 0.0000	time 0.1524 (0.2429)	loss 1.2697 (1.3635)	grad_norm 0.3906 (0.4108)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:26:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 24 training takes 0:10:20
[2024-07-15 03:27:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 22.513 (22.513)	Loss 0.4172 (0.4172)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 03:27:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.110 Acc@5 97.244
[2024-07-15 03:27:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 03:27:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 03:27:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][0/2502]	eta 16:22:57 lr 0.000004	 wd 0.0000	time 23.5723 (23.5723)	loss 1.2643 (1.2643)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:28:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:18:41 lr 0.000004	 wd 0.0000	time 0.1876 (0.4668)	loss 1.3940 (1.3317)	grad_norm 0.3771 (0.4005)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:28:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:12:58 lr 0.000004	 wd 0.0000	time 0.1864 (0.3381)	loss 1.4944 (1.3596)	grad_norm 0.3849 (0.4019)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:28:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:10:47 lr 0.000004	 wd 0.0000	time 0.2078 (0.2939)	loss 1.1308 (1.3499)	grad_norm 0.3349 (0.4076)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:29:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:09:32 lr 0.000004	 wd 0.0000	time 0.2434 (0.2722)	loss 1.2540 (1.3651)	grad_norm 0.3556 (0.4035)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:29:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:08:49 lr 0.000004	 wd 0.0000	time 0.2204 (0.2646)	loss 1.5603 (1.3652)	grad_norm 0.3790 (0.4193)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:30:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:09 lr 0.000004	 wd 0.0000	time 0.2105 (0.2574)	loss 1.1634 (1.3667)	grad_norm 0.3385 (0.4184)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:30:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:07:31 lr 0.000004	 wd 0.0000	time 0.2134 (0.2503)	loss 1.2449 (1.3671)	grad_norm 0.3546 (0.4167)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:30:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:06:57 lr 0.000004	 wd 0.0000	time 0.2040 (0.2454)	loss 1.0086 (1.3672)	grad_norm 0.3836 (0.4202)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:31:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:06:29 lr 0.000004	 wd 0.0000	time 0.2516 (0.2431)	loss 1.5247 (1.3692)	grad_norm 0.3585 (0.4176)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:31:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:07 lr 0.000004	 wd 0.0000	time 0.1817 (0.2447)	loss 1.2378 (1.3697)	grad_norm 0.3549 (0.4173)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:31:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:38 lr 0.000004	 wd 0.0000	time 0.2010 (0.2417)	loss 1.3112 (1.3679)	grad_norm 0.3913 (0.4159)	loss_scale 2048.0000 (2048.0000)	mem 7646MB
[2024-07-15 03:32:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:11 lr 0.000004	 wd 0.0000	time 0.1743 (0.2389)	loss 1.3480 (1.3702)	grad_norm 0.3999 (0.4142)	loss_scale 4096.0000 (2215.1141)	mem 7646MB
[2024-07-15 03:32:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:04:45 lr 0.000003	 wd 0.0000	time 0.2283 (0.2371)	loss 1.4793 (1.3719)	grad_norm 0.4433 (0.4139)	loss_scale 4096.0000 (2359.6864)	mem 7646MB
[2024-07-15 03:33:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:22 lr 0.000003	 wd 0.0000	time 0.2013 (0.2385)	loss 1.1220 (1.3714)	grad_norm 0.4597 (0.4130)	loss_scale 4096.0000 (2483.6203)	mem 7646MB
[2024-07-15 03:33:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:03:57 lr 0.000003	 wd 0.0000	time 0.2115 (0.2368)	loss 1.2458 (1.3715)	grad_norm 0.3880 (0.4122)	loss_scale 4096.0000 (2591.0406)	mem 7646MB
[2024-07-15 03:33:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:32 lr 0.000003	 wd 0.0000	time 0.2086 (0.2351)	loss 1.4957 (1.3708)	grad_norm 0.3747 (0.4118)	loss_scale 4096.0000 (2685.0418)	mem 7646MB
[2024-07-15 03:34:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:07 lr 0.000003	 wd 0.0000	time 0.2304 (0.2334)	loss 1.3842 (1.3702)	grad_norm 0.3914 (0.4113)	loss_scale 4096.0000 (2767.9906)	mem 7646MB
[2024-07-15 03:34:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:43 lr 0.000003	 wd 0.0000	time 0.2166 (0.2330)	loss 1.5669 (1.3700)	grad_norm 0.4906 (0.4125)	loss_scale 4096.0000 (2841.7279)	mem 7646MB
[2024-07-15 03:34:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:20 lr 0.000003	 wd 0.0000	time 0.2610 (0.2339)	loss 1.9489 (1.3697)	grad_norm 0.3832 (0.4116)	loss_scale 4096.0000 (2907.7075)	mem 7646MB
[2024-07-15 03:35:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:01:56 lr 0.000003	 wd 0.0000	time 0.2339 (0.2327)	loss 1.2724 (1.3691)	grad_norm 0.4128 (0.4105)	loss_scale 4096.0000 (2967.0925)	mem 7646MB
[2024-07-15 03:35:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:33 lr 0.000003	 wd 0.0000	time 0.2093 (0.2318)	loss 0.8916 (1.3690)	grad_norm 0.4336 (0.4098)	loss_scale 4096.0000 (3020.8244)	mem 7646MB
[2024-07-15 03:35:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:09 lr 0.000003	 wd 0.0000	time 0.2211 (0.2312)	loss 1.4425 (1.3678)	grad_norm 0.3729 (0.4095)	loss_scale 4096.0000 (3069.6738)	mem 7646MB
[2024-07-15 03:36:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:46 lr 0.000003	 wd 0.0000	time 0.2965 (0.2317)	loss 1.2158 (1.3664)	grad_norm 0.3366 (0.4092)	loss_scale 4096.0000 (3114.2773)	mem 7646MB
[2024-07-15 03:36:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:23 lr 0.000003	 wd 0.0000	time 0.2245 (0.2311)	loss 1.3974 (1.3680)	grad_norm 0.3688 (0.4093)	loss_scale 4096.0000 (3155.1653)	mem 7646MB
[2024-07-15 03:37:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1506 (0.2291)	loss 1.4916 (1.3681)	grad_norm 0.4077 (0.4087)	loss_scale 4096.0000 (3192.7837)	mem 7646MB
[2024-07-15 03:37:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 25 training takes 0:09:40
[2024-07-15 03:37:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 34.153 (34.153)	Loss 0.4177 (0.4177)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 03:38:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.096 Acc@5 97.246
[2024-07-15 03:38:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 03:38:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 03:38:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][0/2502]	eta 11:28:21 lr 0.000003	 wd 0.0000	time 16.5073 (16.5073)	loss 1.3295 (1.3295)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:38:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:14:52 lr 0.000003	 wd 0.0000	time 0.2089 (0.3717)	loss 1.5195 (1.3608)	grad_norm 0.3566 (0.4032)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:39:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:11:12 lr 0.000003	 wd 0.0000	time 0.2674 (0.2921)	loss 1.4819 (1.3816)	grad_norm 0.3599 (0.3970)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:39:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:10:12 lr 0.000003	 wd 0.0000	time 0.1868 (0.2781)	loss 1.4993 (1.3732)	grad_norm 0.4397 (0.3996)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:39:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:09:08 lr 0.000003	 wd 0.0000	time 0.2055 (0.2610)	loss 1.6610 (1.3749)	grad_norm 0.3998 (0.4003)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:40:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:08:19 lr 0.000003	 wd 0.0000	time 0.2039 (0.2497)	loss 1.6328 (1.3813)	grad_norm 0.3580 (0.4017)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:40:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:07:41 lr 0.000003	 wd 0.0000	time 0.2000 (0.2428)	loss 1.4126 (1.3763)	grad_norm 0.4970 (0.4040)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:40:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:15 lr 0.000003	 wd 0.0000	time 0.2282 (0.2415)	loss 1.5344 (1.3722)	grad_norm 0.3782 (0.4087)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:41:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:06:54 lr 0.000002	 wd 0.0000	time 0.1900 (0.2433)	loss 1.5938 (1.3708)	grad_norm 0.3660 (0.4076)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:41:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:06:23 lr 0.000002	 wd 0.0000	time 0.2018 (0.2397)	loss 1.3858 (1.3707)	grad_norm 0.4010 (0.4064)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:42:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:05:55 lr 0.000002	 wd 0.0000	time 0.2114 (0.2366)	loss 1.4211 (1.3713)	grad_norm 0.3961 (0.4061)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:42:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:29 lr 0.000002	 wd 0.0000	time 0.3124 (0.2353)	loss 1.5886 (1.3729)	grad_norm 0.3571 (0.4049)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:42:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:07 lr 0.000002	 wd 0.0000	time 0.2163 (0.2363)	loss 1.0888 (1.3734)	grad_norm 0.3921 (0.4056)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:43:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:04:41 lr 0.000002	 wd 0.0000	time 0.2241 (0.2345)	loss 0.9615 (1.3716)	grad_norm 0.4156 (0.4071)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:43:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:16 lr 0.000002	 wd 0.0000	time 0.2029 (0.2328)	loss 1.6079 (1.3711)	grad_norm 0.3692 (0.4078)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:43:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:03:51 lr 0.000002	 wd 0.0000	time 0.2502 (0.2314)	loss 1.4063 (1.3699)	grad_norm 0.3929 (0.4066)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:44:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:28 lr 0.000002	 wd 0.0000	time 0.3487 (0.2316)	loss 1.4550 (1.3688)	grad_norm 0.3846 (0.4060)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:44:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:05 lr 0.000002	 wd 0.0000	time 0.1897 (0.2318)	loss 1.2846 (1.3699)	grad_norm 0.3830 (0.4057)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:45:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:41 lr 0.000002	 wd 0.0000	time 0.2136 (0.2308)	loss 1.5317 (1.3727)	grad_norm 0.5062 (0.4056)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:45:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:18 lr 0.000002	 wd 0.0000	time 0.1852 (0.2298)	loss 0.9904 (1.3712)	grad_norm 0.3504 (0.4056)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:45:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:01:55 lr 0.000002	 wd 0.0000	time 0.2197 (0.2297)	loss 0.9271 (1.3703)	grad_norm 0.4126 (0.4054)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:46:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:32 lr 0.000002	 wd 0.0000	time 0.2616 (0.2305)	loss 1.1215 (1.3692)	grad_norm 0.4010 (0.4047)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:46:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:09 lr 0.000002	 wd 0.0000	time 0.2141 (0.2297)	loss 0.9693 (1.3689)	grad_norm 0.4270 (0.4049)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:46:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:46 lr 0.000002	 wd 0.0000	time 0.2129 (0.2289)	loss 1.2081 (1.3678)	grad_norm 0.3789 (0.4044)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:47:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:23 lr 0.000002	 wd 0.0000	time 0.2163 (0.2283)	loss 1.1274 (1.3679)	grad_norm 0.4696 (0.4038)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:47:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1559 (0.2268)	loss 0.9501 (1.3660)	grad_norm 0.4078 (0.4039)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:47:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 26 training takes 0:09:41
[2024-07-15 03:48:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 24.197 (24.197)	Loss 0.4177 (0.4177)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 03:48:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.104 Acc@5 97.246
[2024-07-15 03:48:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 03:48:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 03:48:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][0/2502]	eta 13:51:39 lr 0.000002	 wd 0.0000	time 19.9436 (19.9436)	loss 0.9359 (0.9359)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:49:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:17:36 lr 0.000002	 wd 0.0000	time 0.2241 (0.4397)	loss 1.4981 (1.3728)	grad_norm 0.4955 (0.3968)	loss_scale 8192.0000 (4177.1089)	mem 7646MB
[2024-07-15 03:49:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:12:27 lr 0.000002	 wd 0.0000	time 0.2051 (0.3248)	loss 1.5839 (1.3678)	grad_norm 0.4146 (0.4014)	loss_scale 8192.0000 (6174.5672)	mem 7646MB
[2024-07-15 03:49:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:10:29 lr 0.000002	 wd 0.0000	time 0.1875 (0.2858)	loss 1.3643 (1.3681)	grad_norm 0.3646 (0.4016)	loss_scale 8192.0000 (6844.8106)	mem 7646MB
[2024-07-15 03:50:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:09:18 lr 0.000002	 wd 0.0000	time 0.2228 (0.2656)	loss 1.4462 (1.3659)	grad_norm 0.3785 (0.4054)	loss_scale 8192.0000 (7180.7681)	mem 7646MB
[2024-07-15 03:50:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:08:38 lr 0.000002	 wd 0.0000	time 0.2252 (0.2588)	loss 0.9809 (1.3617)	grad_norm 0.4146 (0.4024)	loss_scale 8192.0000 (7382.6108)	mem 7646MB
[2024-07-15 03:51:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:05 lr 0.000002	 wd 0.0000	time 0.2319 (0.2553)	loss 1.2771 (1.3649)	grad_norm 0.3893 (0.4063)	loss_scale 8192.0000 (7517.2845)	mem 7646MB
[2024-07-15 03:51:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:28 lr 0.000002	 wd 0.0000	time 0.1978 (0.2487)	loss 1.4915 (1.3706)	grad_norm 0.4493 (0.4098)	loss_scale 8192.0000 (7613.5350)	mem 7646MB
[2024-07-15 03:51:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:06:54 lr 0.000002	 wd 0.0000	time 0.1975 (0.2436)	loss 1.5389 (1.3741)	grad_norm 0.6461 (0.4087)	loss_scale 8192.0000 (7685.7528)	mem 7646MB
[2024-07-15 03:52:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:27 lr 0.000001	 wd 0.0000	time 0.2184 (0.2417)	loss 1.2983 (1.3787)	grad_norm 0.3777 (0.4089)	loss_scale 8192.0000 (7741.9401)	mem 7646MB
[2024-07-15 03:52:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:04 lr 0.000001	 wd 0.0000	time 0.2027 (0.2424)	loss 1.4164 (1.3769)	grad_norm 0.6049 (0.4085)	loss_scale 8192.0000 (7786.9011)	mem 7646MB
[2024-07-15 03:52:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:35 lr 0.000001	 wd 0.0000	time 0.2070 (0.2395)	loss 1.5313 (1.3768)	grad_norm 0.3684 (0.4081)	loss_scale 8192.0000 (7823.6948)	mem 7646MB
[2024-07-15 03:53:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:08 lr 0.000001	 wd 0.0000	time 0.2416 (0.2371)	loss 1.4919 (1.3767)	grad_norm 0.4176 (0.4085)	loss_scale 8192.0000 (7854.3614)	mem 7646MB
[2024-07-15 03:53:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:42 lr 0.000001	 wd 0.0000	time 0.2257 (0.2352)	loss 1.5016 (1.3738)	grad_norm 0.4454 (0.4093)	loss_scale 8192.0000 (7880.3136)	mem 7646MB
[2024-07-15 03:54:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:20 lr 0.000001	 wd 0.0000	time 0.2189 (0.2362)	loss 1.2771 (1.3743)	grad_norm 0.3597 (0.4086)	loss_scale 8192.0000 (7902.5610)	mem 7646MB
[2024-07-15 03:54:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:03:55 lr 0.000001	 wd 0.0000	time 0.2326 (0.2351)	loss 1.5485 (1.3739)	grad_norm 0.3468 (0.4091)	loss_scale 8192.0000 (7921.8441)	mem 7646MB
[2024-07-15 03:54:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:30 lr 0.000001	 wd 0.0000	time 0.2069 (0.2335)	loss 1.5625 (1.3718)	grad_norm 0.4738 (0.4089)	loss_scale 8192.0000 (7938.7183)	mem 7646MB
[2024-07-15 03:55:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:06 lr 0.000001	 wd 0.0000	time 0.2138 (0.2320)	loss 1.3984 (1.3696)	grad_norm 0.4067 (0.4091)	loss_scale 8192.0000 (7953.6085)	mem 7646MB
[2024-07-15 03:55:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:42 lr 0.000001	 wd 0.0000	time 0.2240 (0.2319)	loss 1.5201 (1.3702)	grad_norm 0.4625 (0.4092)	loss_scale 8192.0000 (7966.8451)	mem 7646MB
[2024-07-15 03:55:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:20 lr 0.000001	 wd 0.0000	time 0.2028 (0.2327)	loss 1.0846 (1.3717)	grad_norm 0.4036 (0.4084)	loss_scale 8192.0000 (7978.6891)	mem 7646MB
[2024-07-15 03:56:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:56 lr 0.000001	 wd 0.0000	time 0.2137 (0.2316)	loss 1.0550 (1.3705)	grad_norm 0.3791 (0.4083)	loss_scale 8192.0000 (7989.3493)	mem 7646MB
[2024-07-15 03:56:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:32 lr 0.000001	 wd 0.0000	time 0.2023 (0.2306)	loss 1.7128 (1.3698)	grad_norm 0.3748 (0.4077)	loss_scale 8192.0000 (7998.9948)	mem 7646MB
[2024-07-15 03:56:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:09 lr 0.000001	 wd 0.0000	time 0.2143 (0.2302)	loss 1.0827 (1.3704)	grad_norm 0.3648 (0.4070)	loss_scale 8192.0000 (8007.7637)	mem 7646MB
[2024-07-15 03:57:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:46 lr 0.000001	 wd 0.0000	time 0.2493 (0.2305)	loss 1.4596 (1.3705)	grad_norm 0.3486 (0.4074)	loss_scale 8192.0000 (8015.7705)	mem 7646MB
[2024-07-15 03:57:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:23 lr 0.000001	 wd 0.0000	time 0.1924 (0.2298)	loss 1.3772 (1.3701)	grad_norm 0.3556 (inf)	loss_scale 4096.0000 (7985.5793)	mem 7646MB
[2024-07-15 03:58:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1534 (0.2277)	loss 1.5137 (1.3685)	grad_norm 0.3614 (inf)	loss_scale 4096.0000 (7830.0584)	mem 7646MB
[2024-07-15 03:58:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 27 training takes 0:09:36
[2024-07-15 03:58:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 23.271 (23.271)	Loss 0.4175 (0.4175)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 03:58:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.100 Acc@5 97.248
[2024-07-15 03:58:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 03:58:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 03:59:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][0/2502]	eta 13:06:46 lr 0.000001	 wd 0.0000	time 18.8676 (18.8676)	loss 1.2886 (1.2886)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:59:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:15:59 lr 0.000001	 wd 0.0000	time 0.2021 (0.3993)	loss 1.0714 (1.3492)	grad_norm 0.3870 (0.4129)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 03:59:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:11:37 lr 0.000001	 wd 0.0000	time 0.1996 (0.3028)	loss 1.0668 (1.3526)	grad_norm 0.4044 (0.4135)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:00:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:10:26 lr 0.000001	 wd 0.0000	time 0.3264 (0.2846)	loss 1.6474 (1.3628)	grad_norm 0.3597 (0.4129)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:00:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:10:02 lr 0.000001	 wd 0.0000	time 0.1867 (0.2866)	loss 1.3888 (1.3673)	grad_norm 0.3656 (0.4191)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:01:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:09:00 lr 0.000001	 wd 0.0000	time 0.2063 (0.2702)	loss 1.5744 (1.3695)	grad_norm 0.3499 (0.4180)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:01:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:12 lr 0.000001	 wd 0.0000	time 0.2216 (0.2587)	loss 1.3961 (1.3694)	grad_norm 0.3649 (0.4180)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:01:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:41 lr 0.000001	 wd 0.0000	time 0.3970 (0.2564)	loss 1.0335 (1.3713)	grad_norm 0.3641 (0.4175)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:02:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:25 lr 0.000001	 wd 0.0000	time 0.2087 (0.2620)	loss 1.6118 (1.3685)	grad_norm 0.3799 (0.4143)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:02:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:49 lr 0.000001	 wd 0.0000	time 0.2079 (0.2557)	loss 1.5377 (1.3692)	grad_norm 0.4204 (0.4132)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:03:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:16 lr 0.000001	 wd 0.0000	time 0.1935 (0.2509)	loss 1.5633 (1.3718)	grad_norm 0.4666 (0.4120)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:03:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:48 lr 0.000001	 wd 0.0000	time 0.2875 (0.2483)	loss 0.9518 (1.3682)	grad_norm 0.4165 (0.4117)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:03:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:23 lr 0.000001	 wd 0.0000	time 0.1873 (0.2482)	loss 1.2184 (1.3685)	grad_norm 0.4110 (0.4111)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:04:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:04:55 lr 0.000001	 wd 0.0000	time 0.1914 (0.2456)	loss 1.5854 (1.3654)	grad_norm 0.3901 (0.4105)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:04:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:27 lr 0.000001	 wd 0.0000	time 0.2000 (0.2431)	loss 0.9340 (1.3664)	grad_norm 0.4008 (0.4090)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:04:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:04:01 lr 0.000001	 wd 0.0000	time 0.2025 (0.2408)	loss 1.4953 (1.3650)	grad_norm 0.3799 (0.4103)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:05:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:37 lr 0.000001	 wd 0.0000	time 0.1988 (0.2408)	loss 1.1961 (1.3645)	grad_norm 0.3876 (0.4104)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:05:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:12 lr 0.000001	 wd 0.0000	time 0.2014 (0.2398)	loss 1.4257 (1.3659)	grad_norm 0.4421 (0.4100)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:06:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:47 lr 0.000001	 wd 0.0000	time 0.2375 (0.2383)	loss 1.3810 (1.3656)	grad_norm 0.5014 (0.4101)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:06:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:22 lr 0.000001	 wd 0.0000	time 0.2182 (0.2367)	loss 1.5427 (1.3645)	grad_norm 0.4738 (0.4099)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:06:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:01:58 lr 0.000001	 wd 0.0000	time 0.2011 (0.2361)	loss 0.8850 (1.3644)	grad_norm 0.5098 (0.4102)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:07:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:35 lr 0.000001	 wd 0.0000	time 0.2033 (0.2365)	loss 1.0912 (1.3647)	grad_norm 0.3795 (0.4105)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:07:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:11 lr 0.000001	 wd 0.0000	time 0.2164 (0.2353)	loss 1.5304 (1.3635)	grad_norm 0.4101 (0.4095)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:07:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:47 lr 0.000001	 wd 0.0000	time 0.2029 (0.2343)	loss 1.0984 (1.3636)	grad_norm 0.3790 (0.4102)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:08:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:23 lr 0.000001	 wd 0.0000	time 0.1971 (0.2335)	loss 1.5827 (1.3621)	grad_norm 0.3656 (0.4101)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:08:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1690 (0.2317)	loss 1.2030 (1.3613)	grad_norm 0.3789 (0.4097)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:08:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 28 training takes 0:09:55
[2024-07-15 04:09:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 25.228 (25.228)	Loss 0.4177 (0.4177)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 04:09:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.090 Acc@5 97.244
[2024-07-15 04:09:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 04:09:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 04:09:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][0/2502]	eta 15:25:55 lr 0.000001	 wd 0.0000	time 22.2045 (22.2045)	loss 1.4149 (1.4149)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:10:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:18:06 lr 0.000001	 wd 0.0000	time 0.2221 (0.4525)	loss 1.4720 (1.3437)	grad_norm 0.3488 (0.4162)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:10:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:12:39 lr 0.000001	 wd 0.0000	time 0.2030 (0.3301)	loss 1.1521 (1.3583)	grad_norm 0.3871 (0.4089)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:10:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:10:37 lr 0.000001	 wd 0.0000	time 0.1953 (0.2896)	loss 1.4955 (1.3570)	grad_norm 0.4952 (0.4078)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:11:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:09:25 lr 0.000001	 wd 0.0000	time 0.2386 (0.2688)	loss 1.1824 (1.3657)	grad_norm 0.4299 (0.4215)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:11:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:08:46 lr 0.000001	 wd 0.0000	time 0.1803 (0.2632)	loss 0.9506 (1.3672)	grad_norm 0.3842 (0.4206)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:12:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:06 lr 0.000000	 wd 0.0000	time 0.2167 (0.2558)	loss 1.3561 (1.3681)	grad_norm 0.3673 (0.4151)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:12:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:28 lr 0.000000	 wd 0.0000	time 0.1797 (0.2491)	loss 1.5817 (1.3688)	grad_norm 0.4283 (0.4128)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:12:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:06:55 lr 0.000000	 wd 0.0000	time 0.1921 (0.2439)	loss 0.8034 (1.3699)	grad_norm 0.3688 (0.4100)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:13:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:06:27 lr 0.000000	 wd 0.0000	time 0.2313 (0.2420)	loss 1.4195 (1.3696)	grad_norm 0.3761 (0.4090)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:13:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:02 lr 0.000000	 wd 0.0000	time 0.1988 (0.2414)	loss 1.3348 (1.3693)	grad_norm 0.3970 (0.4110)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:13:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:34 lr 0.000000	 wd 0.0000	time 0.1924 (0.2387)	loss 1.4676 (1.3699)	grad_norm 0.3390 (0.4105)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:14:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:07 lr 0.000000	 wd 0.0000	time 0.2139 (0.2363)	loss 1.2693 (1.3668)	grad_norm 0.3814 (0.4087)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:14:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:04:41 lr 0.000000	 wd 0.0000	time 0.2471 (0.2344)	loss 1.5501 (1.3677)	grad_norm 0.4006 (0.4089)	loss_scale 4096.0000 (4096.0000)	mem 7646MB
[2024-07-15 04:15:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:19 lr 0.000000	 wd 0.0000	time 0.1442 (0.2354)	loss 1.7627 (1.3665)	grad_norm 0.4057 (0.4112)	loss_scale 8192.0000 (4172.0143)	mem 7646MB
[2024-07-15 04:15:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:03:54 lr 0.000000	 wd 0.0000	time 0.2179 (0.2338)	loss 1.2912 (1.3678)	grad_norm 0.3934 (0.4111)	loss_scale 8192.0000 (4439.8348)	mem 7646MB
[2024-07-15 04:15:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:29 lr 0.000000	 wd 0.0000	time 0.1693 (0.2323)	loss 1.4852 (1.3692)	grad_norm 0.3857 (0.4098)	loss_scale 8192.0000 (4674.1986)	mem 7646MB
[2024-07-15 04:16:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:05 lr 0.000000	 wd 0.0000	time 0.1933 (0.2310)	loss 1.3114 (1.3661)	grad_norm 0.3906 (0.4090)	loss_scale 8192.0000 (4881.0065)	mem 7646MB
[2024-07-15 04:16:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:41 lr 0.000000	 wd 0.0000	time 0.2458 (0.2307)	loss 1.1697 (1.3677)	grad_norm 0.4321 (0.4080)	loss_scale 8192.0000 (5064.8484)	mem 7646MB
[2024-07-15 04:16:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:19 lr 0.000000	 wd 0.0000	time 0.2024 (0.2314)	loss 1.2300 (1.3674)	grad_norm 0.4022 (0.4072)	loss_scale 8192.0000 (5229.3488)	mem 7646MB
[2024-07-15 04:17:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:01:55 lr 0.000000	 wd 0.0000	time 0.2155 (0.2304)	loss 1.5044 (1.3675)	grad_norm 0.4173 (0.4064)	loss_scale 8192.0000 (5377.4073)	mem 7646MB
[2024-07-15 04:17:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:32 lr 0.000000	 wd 0.0000	time 0.1991 (0.2296)	loss 1.5016 (1.3680)	grad_norm 0.3871 (0.4059)	loss_scale 8192.0000 (5511.3717)	mem 7646MB
[2024-07-15 04:17:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:09 lr 0.000000	 wd 0.0000	time 0.2214 (0.2291)	loss 1.4234 (1.3697)	grad_norm 0.3775 (0.4058)	loss_scale 8192.0000 (5633.1631)	mem 7646MB
[2024-07-15 04:18:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:46 lr 0.000000	 wd 0.0000	time 0.1805 (0.2298)	loss 1.4339 (1.3710)	grad_norm 0.4482 (0.4055)	loss_scale 8192.0000 (5744.3685)	mem 7646MB
[2024-07-15 04:18:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.1884 (0.2293)	loss 1.4092 (1.3716)	grad_norm 0.4358 (0.4051)	loss_scale 8192.0000 (5846.3107)	mem 7646MB
[2024-07-15 04:19:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000000	 wd 0.0000	time 0.1574 (0.2273)	loss 1.5748 (1.3707)	grad_norm 0.3623 (0.4046)	loss_scale 8192.0000 (5940.1008)	mem 7646MB
[2024-07-15 04:19:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 29 training takes 0:09:37
[2024-07-15 04:19:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_29.pth saving......
[2024-07-15 04:19:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_swin_b_22kto1k_sequence_stag1/ckpt_epoch_29.pth saved !!!
[2024-07-15 04:19:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 35.948 (35.948)	Loss 0.4175 (0.4175)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7646MB
[2024-07-15 04:20:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.096 Acc@5 97.248
[2024-07-15 04:20:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-15 04:20:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.13%
[2024-07-15 04:20:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 189): INFO Training time 5:16:34
