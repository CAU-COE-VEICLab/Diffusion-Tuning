[2024-07-13 12:17:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/config.json
[2024-07-13 12:17:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/swin-b/swin_base_patch4_window7_224_22k.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_swin_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 9
    - 3
    DIMS:
    - 96
    - 192
    - 384
    - 768
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: false
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_swin_b_22kto1k_step_stag0
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 4.0e-05
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.0e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 4.0e-08
  WEIGHT_DECAY: 1.0e-08

[2024-07-13 12:17:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/swin/diffusion_ft_adapter_swin_base_patch4_window7_224_22kto1k_step_stage_process0.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/swin-b/swin_base_patch4_window7_224_22k.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_adapter_swin_b_22kto1k_step_stag0", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-13 12:18:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 108): INFO Creating model:adapter_swin_diffusion_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0
[2024-07-13 12:18:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 110): INFO Adapter_SwinTransformer_Diffusion_Finetune(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (uma): UMA(filter_strategy1=23, filter_strategy2=7,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-13 12:18:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 113): INFO number of params: 1043752
[2024-07-13 12:18:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 116): INFO number of GFLOPs: 15.438473216
[2024-07-13 12:18:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 150): INFO no checkpoint found in pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0, ignoring auto resume
[2024-07-13 12:18:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/swin-b/swin_base_patch4_window7_224_22k.pth for fine-tuning......
[2024-07-13 12:18:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 112): INFO loading ImageNet-22K weight to ImageNet-1K ......
[2024-07-13 12:18:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.0.adapter.down.weight', 'layers.0.blocks.0.adapter.down.bias', 'layers.0.blocks.0.adapter.up.weight', 'layers.0.blocks.0.adapter.up.bias', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.0.blocks.1.adapter.down.weight', 'layers.0.blocks.1.adapter.down.bias', 'layers.0.blocks.1.adapter.up.weight', 'layers.0.blocks.1.adapter.up.bias', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.0.adapter.down.weight', 'layers.1.blocks.0.adapter.down.bias', 'layers.1.blocks.0.adapter.up.weight', 'layers.1.blocks.0.adapter.up.bias', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.1.blocks.1.adapter.down.weight', 'layers.1.blocks.1.adapter.down.bias', 'layers.1.blocks.1.adapter.up.weight', 'layers.1.blocks.1.adapter.up.bias', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.0.adapter.down.weight', 'layers.2.blocks.0.adapter.down.bias', 'layers.2.blocks.0.adapter.up.weight', 'layers.2.blocks.0.adapter.up.bias', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.1.adapter.down.weight', 'layers.2.blocks.1.adapter.down.bias', 'layers.2.blocks.1.adapter.up.weight', 'layers.2.blocks.1.adapter.up.bias', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.2.adapter.down.weight', 'layers.2.blocks.2.adapter.down.bias', 'layers.2.blocks.2.adapter.up.weight', 'layers.2.blocks.2.adapter.up.bias', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.3.adapter.down.weight', 'layers.2.blocks.3.adapter.down.bias', 'layers.2.blocks.3.adapter.up.weight', 'layers.2.blocks.3.adapter.up.bias', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.4.adapter.down.weight', 'layers.2.blocks.4.adapter.down.bias', 'layers.2.blocks.4.adapter.up.weight', 'layers.2.blocks.4.adapter.up.bias', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.5.adapter.down.weight', 'layers.2.blocks.5.adapter.down.bias', 'layers.2.blocks.5.adapter.up.weight', 'layers.2.blocks.5.adapter.up.bias', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.6.adapter.down.weight', 'layers.2.blocks.6.adapter.down.bias', 'layers.2.blocks.6.adapter.up.weight', 'layers.2.blocks.6.adapter.up.bias', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.7.adapter.down.weight', 'layers.2.blocks.7.adapter.down.bias', 'layers.2.blocks.7.adapter.up.weight', 'layers.2.blocks.7.adapter.up.bias', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.8.adapter.down.weight', 'layers.2.blocks.8.adapter.down.bias', 'layers.2.blocks.8.adapter.up.weight', 'layers.2.blocks.8.adapter.up.bias', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.9.adapter.down.weight', 'layers.2.blocks.9.adapter.down.bias', 'layers.2.blocks.9.adapter.up.weight', 'layers.2.blocks.9.adapter.up.bias', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.10.adapter.down.weight', 'layers.2.blocks.10.adapter.down.bias', 'layers.2.blocks.10.adapter.up.weight', 'layers.2.blocks.10.adapter.up.bias', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.11.adapter.down.weight', 'layers.2.blocks.11.adapter.down.bias', 'layers.2.blocks.11.adapter.up.weight', 'layers.2.blocks.11.adapter.up.bias', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.12.adapter.down.weight', 'layers.2.blocks.12.adapter.down.bias', 'layers.2.blocks.12.adapter.up.weight', 'layers.2.blocks.12.adapter.up.bias', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.13.adapter.down.weight', 'layers.2.blocks.13.adapter.down.bias', 'layers.2.blocks.13.adapter.up.weight', 'layers.2.blocks.13.adapter.up.bias', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.14.adapter.down.weight', 'layers.2.blocks.14.adapter.down.bias', 'layers.2.blocks.14.adapter.up.weight', 'layers.2.blocks.14.adapter.up.bias', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.15.adapter.down.weight', 'layers.2.blocks.15.adapter.down.bias', 'layers.2.blocks.15.adapter.up.weight', 'layers.2.blocks.15.adapter.up.bias', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.16.adapter.down.weight', 'layers.2.blocks.16.adapter.down.bias', 'layers.2.blocks.16.adapter.up.weight', 'layers.2.blocks.16.adapter.up.bias', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.2.blocks.17.adapter.down.weight', 'layers.2.blocks.17.adapter.down.bias', 'layers.2.blocks.17.adapter.up.weight', 'layers.2.blocks.17.adapter.up.bias', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.0.adapter.down.weight', 'layers.3.blocks.0.adapter.down.bias', 'layers.3.blocks.0.adapter.up.weight', 'layers.3.blocks.0.adapter.up.bias', 'layers.3.blocks.1.attn.relative_position_index', 'layers.3.blocks.1.adapter.down.weight', 'layers.3.blocks.1.adapter.down.bias', 'layers.3.blocks.1.adapter.up.weight', 'layers.3.blocks.1.adapter.up.bias'], unexpected_keys=[])
[2024-07-13 12:18:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/swin-b/swin_base_patch4_window7_224_22k.pth'
[2024-07-13 12:19:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 60.211 (60.211)	Loss 0.3616 (0.3616)	Acc@1 91.406 (91.406)	Acc@5 98.242 (98.242)	Mem 1476MB
[2024-07-13 12:19:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 82.636 Acc@5 96.604
[2024-07-13 12:19:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 162): INFO Accuracy of the network on the 50000 test images: 82.6%
[2024-07-13 12:19:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 168): INFO Start training
[2024-07-13 12:19:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][0/2502]	eta 23:45:24 lr 0.000000	 wd 0.0000	time 34.1824 (34.1824)	loss 1.7768 (1.7768)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 7576MB
[2024-07-13 12:20:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:24:17 lr 0.000000	 wd 0.0000	time 0.2031 (0.6067)	loss 1.5636 (1.5356)	grad_norm 0.4392 (nan)	loss_scale 16384.0000 (42825.5050)	mem 7585MB
[2024-07-13 12:20:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:15:42 lr 0.000001	 wd 0.0000	time 0.2096 (0.4094)	loss 1.5638 (1.5208)	grad_norm 0.4841 (nan)	loss_scale 16384.0000 (29670.5274)	mem 7585MB
[2024-07-13 12:21:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:35 lr 0.000001	 wd 0.0000	time 0.2020 (0.3430)	loss 1.5470 (1.4991)	grad_norm 0.5288 (nan)	loss_scale 16384.0000 (25256.3987)	mem 7585MB
[2024-07-13 12:21:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:11:34 lr 0.000001	 wd 0.0000	time 0.4293 (0.3304)	loss 2.0085 (1.5017)	grad_norm 0.4308 (nan)	loss_scale 8192.0000 (21082.6534)	mem 7585MB
[2024-07-13 12:22:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:11:13 lr 0.000002	 wd 0.0000	time 0.2015 (0.3365)	loss 1.6761 (1.5006)	grad_norm 0.5204 (nan)	loss_scale 8192.0000 (18509.6687)	mem 7585MB
[2024-07-13 12:22:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:10:00 lr 0.000002	 wd 0.0000	time 0.2191 (0.3157)	loss 1.2703 (1.5009)	grad_norm 0.4534 (nan)	loss_scale 8192.0000 (16792.9185)	mem 7585MB
[2024-07-13 12:22:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:09:02 lr 0.000002	 wd 0.0000	time 0.2000 (0.3011)	loss 1.5800 (1.4965)	grad_norm 0.4370 (nan)	loss_scale 8192.0000 (15565.9686)	mem 7585MB
[2024-07-13 12:23:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:08:46 lr 0.000003	 wd 0.0000	time 0.2458 (0.3092)	loss 1.6497 (1.4977)	grad_norm 0.4359 (nan)	loss_scale 8192.0000 (14645.3733)	mem 7585MB
[2024-07-13 12:23:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:58 lr 0.000003	 wd 0.0000	time 0.1970 (0.2985)	loss 1.7253 (1.4920)	grad_norm 0.4497 (nan)	loss_scale 8192.0000 (13929.1276)	mem 7585MB
[2024-07-13 12:24:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:07:15 lr 0.000003	 wd 0.0000	time 0.2192 (0.2896)	loss 1.4983 (1.4914)	grad_norm 0.5187 (nan)	loss_scale 8192.0000 (13355.9880)	mem 7585MB
[2024-07-13 12:24:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:36 lr 0.000004	 wd 0.0000	time 0.2400 (0.2830)	loss 1.6546 (1.4916)	grad_norm 0.4159 (nan)	loss_scale 8192.0000 (12886.9609)	mem 7585MB
[2024-07-13 12:25:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:06:10 lr 0.000004	 wd 0.0000	time 0.2297 (0.2842)	loss 1.6236 (1.4944)	grad_norm 0.4523 (nan)	loss_scale 8192.0000 (12496.0400)	mem 7585MB
[2024-07-13 12:25:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:34 lr 0.000004	 wd 0.0000	time 0.2130 (0.2784)	loss 1.5391 (1.4956)	grad_norm 0.4372 (nan)	loss_scale 4096.0000 (11970.0169)	mem 7585MB
[2024-07-13 12:25:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:05:01 lr 0.000005	 wd 0.0000	time 0.2142 (0.2737)	loss 1.7146 (1.4969)	grad_norm 0.5077 (nan)	loss_scale 4096.0000 (11407.9886)	mem 7585MB
[2024-07-13 12:26:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:30 lr 0.000005	 wd 0.0000	time 0.2086 (0.2696)	loss 1.6083 (1.4962)	grad_norm 0.4465 (nan)	loss_scale 4096.0000 (10920.8474)	mem 7585MB
[2024-07-13 12:26:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:04:03 lr 0.000005	 wd 0.0000	time 0.2175 (0.2696)	loss 1.7675 (1.4966)	grad_norm 0.4400 (nan)	loss_scale 4096.0000 (10494.5609)	mem 7585MB
[2024-07-13 12:26:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:33 lr 0.000005	 wd 0.0000	time 0.2219 (0.2667)	loss 1.6296 (1.4952)	grad_norm 0.6052 (nan)	loss_scale 4096.0000 (10118.3962)	mem 7585MB
[2024-07-13 12:27:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:03:05 lr 0.000006	 wd 0.0000	time 0.2147 (0.2637)	loss 1.3093 (1.4955)	grad_norm 0.4660 (nan)	loss_scale 4096.0000 (9784.0044)	mem 7585MB
[2024-07-13 12:27:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:37 lr 0.000006	 wd 0.0000	time 0.2165 (0.2608)	loss 1.7640 (1.4944)	grad_norm 0.4795 (nan)	loss_scale 4096.0000 (9484.7933)	mem 7585MB
[2024-07-13 12:28:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:10 lr 0.000006	 wd 0.0000	time 0.2364 (0.2595)	loss 1.6470 (1.4915)	grad_norm 0.4414 (nan)	loss_scale 4096.0000 (9215.4883)	mem 7585MB
[2024-07-13 12:28:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:44 lr 0.000007	 wd 0.0000	time 0.2996 (0.2592)	loss 1.5057 (1.4918)	grad_norm 0.4545 (nan)	loss_scale 4096.0000 (8971.8191)	mem 7585MB
[2024-07-13 12:28:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:17 lr 0.000007	 wd 0.0000	time 0.2105 (0.2570)	loss 1.7274 (1.4922)	grad_norm 0.4364 (nan)	loss_scale 4096.0000 (8750.2917)	mem 7585MB
[2024-07-13 12:29:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:51 lr 0.000007	 wd 0.0000	time 0.1964 (0.2550)	loss 1.6170 (1.4906)	grad_norm 0.4562 (nan)	loss_scale 4096.0000 (8548.0191)	mem 7585MB
[2024-07-13 12:29:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:25 lr 0.000008	 wd 0.0000	time 0.2287 (0.2537)	loss 1.5859 (1.4903)	grad_norm 0.4880 (nan)	loss_scale 4096.0000 (8362.5956)	mem 7585MB
[2024-07-13 12:29:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1668 (0.2519)	loss 1.7531 (1.4900)	grad_norm 0.4628 (nan)	loss_scale 4096.0000 (8192.0000)	mem 7585MB
[2024-07-13 12:29:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 0 training takes 0:10:37
[2024-07-13 12:29:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_0.pth saving......
[2024-07-13 12:30:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_0.pth saved !!!
[2024-07-13 12:30:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 44.605 (44.605)	Loss 0.3662 (0.3662)	Acc@1 91.211 (91.211)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 12:30:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 82.784 Acc@5 96.640
[2024-07-13 12:30:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 82.8%
[2024-07-13 12:30:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 82.78%
[2024-07-13 12:30:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 12:30:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 12:31:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][0/2502]	eta 1 day, 1:40:20 lr 0.000008	 wd 0.0000	time 36.9385 (36.9385)	loss 1.3275 (1.3275)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:31:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:23:09 lr 0.000008	 wd 0.0000	time 0.2278 (0.5786)	loss 1.2647 (1.5234)	grad_norm 0.4896 (0.4620)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:32:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:15:05 lr 0.000009	 wd 0.0000	time 0.1926 (0.3934)	loss 1.4791 (1.5201)	grad_norm 0.6690 (0.4653)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:32:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:12:20 lr 0.000009	 wd 0.0000	time 0.2309 (0.3362)	loss 1.8405 (1.4967)	grad_norm 0.4254 (0.4828)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:33:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:11:23 lr 0.000009	 wd 0.0000	time 0.1994 (0.3251)	loss 1.0486 (1.4837)	grad_norm 0.5607 (0.4801)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:33:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:10:03 lr 0.000010	 wd 0.0000	time 0.1863 (0.3013)	loss 1.6540 (1.4816)	grad_norm 0.4369 (0.4755)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:33:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:09:02 lr 0.000010	 wd 0.0000	time 0.2049 (0.2852)	loss 1.4969 (1.4802)	grad_norm 0.4547 (inf)	loss_scale 2048.0000 (3864.2795)	mem 7585MB
[2024-07-13 12:34:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:16 lr 0.000010	 wd 0.0000	time 0.2477 (0.2753)	loss 1.7786 (1.4783)	grad_norm 0.4420 (inf)	loss_scale 2048.0000 (3605.1812)	mem 7585MB
[2024-07-13 12:34:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:08:16 lr 0.000011	 wd 0.0000	time 0.2655 (0.2920)	loss 1.7367 (1.4819)	grad_norm 0.4176 (inf)	loss_scale 2048.0000 (3410.7765)	mem 7585MB
[2024-07-13 12:35:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:33 lr 0.000011	 wd 0.0000	time 0.2168 (0.2831)	loss 1.6769 (1.4784)	grad_norm 0.4683 (inf)	loss_scale 2048.0000 (3259.5250)	mem 7585MB
[2024-07-13 12:35:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:53 lr 0.000011	 wd 0.0000	time 0.1872 (0.2756)	loss 1.7570 (1.4762)	grad_norm 0.4561 (inf)	loss_scale 2048.0000 (3138.4935)	mem 7585MB
[2024-07-13 12:35:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:06:20 lr 0.000012	 wd 0.0000	time 0.2169 (0.2710)	loss 1.1184 (1.4747)	grad_norm 0.4540 (inf)	loss_scale 2048.0000 (3039.4478)	mem 7585MB
[2024-07-13 12:36:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:55 lr 0.000012	 wd 0.0000	time 0.1913 (0.2734)	loss 1.4729 (1.4768)	grad_norm 0.4250 (inf)	loss_scale 2048.0000 (2956.8959)	mem 7585MB
[2024-07-13 12:36:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:22 lr 0.000012	 wd 0.0000	time 0.2033 (0.2684)	loss 1.6794 (1.4800)	grad_norm 0.4820 (inf)	loss_scale 2048.0000 (2887.0346)	mem 7585MB
[2024-07-13 12:37:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:51 lr 0.000012	 wd 0.0000	time 0.1975 (0.2643)	loss 1.5269 (1.4770)	grad_norm 0.4813 (inf)	loss_scale 2048.0000 (2827.1463)	mem 7585MB
[2024-07-13 12:37:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:22 lr 0.000013	 wd 0.0000	time 0.2500 (0.2616)	loss 1.0119 (1.4747)	grad_norm 0.4393 (inf)	loss_scale 2048.0000 (2775.2378)	mem 7585MB
[2024-07-13 12:38:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:57 lr 0.000013	 wd 0.0000	time 0.2240 (0.2637)	loss 1.0133 (1.4725)	grad_norm 0.4651 (inf)	loss_scale 2048.0000 (2729.8139)	mem 7585MB
[2024-07-13 12:38:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:28 lr 0.000013	 wd 0.0000	time 0.2024 (0.2605)	loss 1.4406 (1.4711)	grad_norm 0.4553 (inf)	loss_scale 2048.0000 (2689.7307)	mem 7585MB
[2024-07-13 12:38:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:03:01 lr 0.000014	 wd 0.0000	time 0.2078 (0.2579)	loss 1.5484 (1.4708)	grad_norm 0.4512 (inf)	loss_scale 2048.0000 (2654.0988)	mem 7585MB
[2024-07-13 12:39:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:33 lr 0.000014	 wd 0.0000	time 0.2672 (0.2557)	loss 1.5524 (1.4713)	grad_norm 0.4546 (inf)	loss_scale 2048.0000 (2622.2157)	mem 7585MB
[2024-07-13 12:39:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:08 lr 0.000014	 wd 0.0000	time 0.1889 (0.2552)	loss 1.4666 (1.4700)	grad_norm 0.4295 (inf)	loss_scale 2048.0000 (2593.5192)	mem 7585MB
[2024-07-13 12:39:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:41 lr 0.000015	 wd 0.0000	time 0.2286 (0.2533)	loss 1.4908 (1.4706)	grad_norm 0.4771 (inf)	loss_scale 2048.0000 (2567.5545)	mem 7585MB
[2024-07-13 12:40:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:15 lr 0.000015	 wd 0.0000	time 0.2311 (0.2515)	loss 1.2569 (1.4714)	grad_norm 0.4324 (inf)	loss_scale 2048.0000 (2543.9491)	mem 7585MB
[2024-07-13 12:40:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:50 lr 0.000015	 wd 0.0000	time 0.2017 (0.2496)	loss 1.7569 (1.4715)	grad_norm 0.5247 (inf)	loss_scale 2048.0000 (2522.3955)	mem 7585MB
[2024-07-13 12:40:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:25 lr 0.000016	 wd 0.0000	time 0.2201 (0.2487)	loss 1.5504 (1.4688)	grad_norm 0.7162 (inf)	loss_scale 2048.0000 (2502.6372)	mem 7585MB
[2024-07-13 12:41:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1532 (0.2467)	loss 1.1424 (1.4697)	grad_norm 0.4206 (inf)	loss_scale 2048.0000 (2484.4590)	mem 7585MB
[2024-07-13 12:41:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 1 training takes 0:10:23
[2024-07-13 12:41:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 28.321 (28.321)	Loss 0.3818 (0.3818)	Acc@1 91.406 (91.406)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 12:42:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 82.966 Acc@5 96.674
[2024-07-13 12:42:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.0%
[2024-07-13 12:42:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 82.97%
[2024-07-13 12:42:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 12:42:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 12:42:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][0/2502]	eta 18:35:17 lr 0.000016	 wd 0.0000	time 26.7454 (26.7454)	loss 1.7510 (1.7510)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:42:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:20:07 lr 0.000016	 wd 0.0000	time 0.2024 (0.5028)	loss 1.5259 (1.4254)	grad_norm 0.4552 (0.4610)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:43:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:13:38 lr 0.000017	 wd 0.0000	time 0.1933 (0.3556)	loss 1.5289 (1.4461)	grad_norm 0.4424 (0.4545)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:43:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:11:12 lr 0.000017	 wd 0.0000	time 0.1934 (0.3053)	loss 1.3496 (1.4580)	grad_norm 0.4385 (0.4531)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:43:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:09:55 lr 0.000017	 wd 0.0000	time 0.2007 (0.2834)	loss 1.6561 (1.4550)	grad_norm 0.4356 (0.4536)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:44:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:09:55 lr 0.000018	 wd 0.0000	time 0.2140 (0.2973)	loss 1.6267 (1.4525)	grad_norm 0.4274 (0.4541)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:44:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:57 lr 0.000018	 wd 0.0000	time 0.2144 (0.2826)	loss 1.3496 (1.4466)	grad_norm 0.4343 (0.4528)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:45:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:08:10 lr 0.000018	 wd 0.0000	time 0.2008 (0.2722)	loss 1.2999 (1.4481)	grad_norm 0.4828 (0.4520)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:45:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:33 lr 0.000019	 wd 0.0000	time 0.3263 (0.2665)	loss 1.5193 (1.4460)	grad_norm 0.4142 (0.4556)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:46:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:07:17 lr 0.000019	 wd 0.0000	time 0.2109 (0.2729)	loss 1.6230 (1.4505)	grad_norm 0.4883 (0.4549)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:46:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:40 lr 0.000019	 wd 0.0000	time 0.2055 (0.2666)	loss 1.5218 (1.4515)	grad_norm 0.4246 (0.4537)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:46:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:06:06 lr 0.000020	 wd 0.0000	time 0.2105 (0.2614)	loss 1.2567 (1.4507)	grad_norm 0.4607 (0.4555)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:47:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:36 lr 0.000020	 wd 0.0000	time 0.2082 (0.2585)	loss 1.3146 (1.4491)	grad_norm 0.4129 (0.4590)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:47:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:05:15 lr 0.000020	 wd 0.0000	time 0.2226 (0.2625)	loss 1.8213 (1.4515)	grad_norm 0.4372 (0.4584)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:48:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:44 lr 0.000020	 wd 0.0000	time 0.2056 (0.2585)	loss 1.5263 (1.4511)	grad_norm 0.4388 (0.4582)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:48:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:15 lr 0.000021	 wd 0.0000	time 0.2119 (0.2553)	loss 1.5966 (1.4485)	grad_norm 0.3893 (0.4573)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:48:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:48 lr 0.000021	 wd 0.0000	time 0.2389 (0.2531)	loss 1.3712 (1.4483)	grad_norm 0.4246 (0.4624)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:49:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:22 lr 0.000021	 wd 0.0000	time 0.1916 (0.2530)	loss 1.4775 (1.4475)	grad_norm 0.4282 (0.4615)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:49:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:56 lr 0.000022	 wd 0.0000	time 0.2194 (0.2511)	loss 1.4245 (1.4472)	grad_norm 0.4900 (0.4614)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:49:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:30 lr 0.000022	 wd 0.0000	time 0.2245 (0.2492)	loss 1.1216 (1.4452)	grad_norm 0.4142 (0.4618)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:50:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:02:04 lr 0.000022	 wd 0.0000	time 0.2459 (0.2473)	loss 1.1448 (1.4427)	grad_norm 0.4042 (0.4609)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 12:50:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:39 lr 0.000023	 wd 0.0000	time 0.2136 (0.2468)	loss 1.5191 (1.4426)	grad_norm 0.4606 (0.4601)	loss_scale 4096.0000 (2116.2342)	mem 7585MB
[2024-07-13 12:51:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:14 lr 0.000023	 wd 0.0000	time 0.2127 (0.2458)	loss 1.5873 (1.4422)	grad_norm 0.4185 (0.4605)	loss_scale 4096.0000 (2206.1826)	mem 7585MB
[2024-07-13 12:51:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:49 lr 0.000023	 wd 0.0000	time 0.1926 (0.2443)	loss 1.6495 (1.4419)	grad_norm 0.5577 (0.4594)	loss_scale 4096.0000 (2288.3129)	mem 7585MB
[2024-07-13 12:51:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:24 lr 0.000024	 wd 0.0000	time 0.1793 (0.2427)	loss 1.5177 (1.4404)	grad_norm 0.4166 (0.4583)	loss_scale 4096.0000 (2363.6018)	mem 7585MB
[2024-07-13 12:52:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1578 (0.2403)	loss 1.5008 (1.4398)	grad_norm 0.3839 (0.4581)	loss_scale 4096.0000 (2432.8701)	mem 7585MB
[2024-07-13 12:52:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 2 training takes 0:10:05
[2024-07-13 12:52:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 37.773 (37.773)	Loss 0.4045 (0.4045)	Acc@1 91.602 (91.602)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 12:52:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.132 Acc@5 96.772
[2024-07-13 12:52:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.1%
[2024-07-13 12:52:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.13%
[2024-07-13 12:52:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 12:53:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 12:53:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][0/2502]	eta 11:17:08 lr 0.000024	 wd 0.0000	time 16.2385 (16.2385)	loss 1.1111 (1.1111)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:53:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:15:15 lr 0.000024	 wd 0.0000	time 0.2400 (0.3811)	loss 1.7381 (1.4147)	grad_norm 0.4276 (0.4764)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:54:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:13:11 lr 0.000025	 wd 0.0000	time 0.1956 (0.3438)	loss 1.5642 (1.4290)	grad_norm 0.3997 (0.4583)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:54:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:10:57 lr 0.000025	 wd 0.0000	time 0.2211 (0.2987)	loss 1.4608 (1.4163)	grad_norm 0.3959 (0.4530)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:54:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:09:38 lr 0.000025	 wd 0.0000	time 0.1989 (0.2753)	loss 1.6052 (1.4227)	grad_norm 0.4151 (0.4496)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:55:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:08:46 lr 0.000026	 wd 0.0000	time 0.2101 (0.2628)	loss 1.4790 (1.4198)	grad_norm 0.4455 (0.4489)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:55:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:08:46 lr 0.000026	 wd 0.0000	time 0.2158 (0.2768)	loss 1.5111 (1.4187)	grad_norm 0.4219 (0.4464)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:56:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:08:01 lr 0.000026	 wd 0.0000	time 0.2260 (0.2670)	loss 1.5705 (1.4204)	grad_norm 0.4942 (0.4468)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:56:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:22 lr 0.000027	 wd 0.0000	time 0.1888 (0.2598)	loss 1.1580 (1.4211)	grad_norm 0.4144 (0.4450)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:56:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:06:48 lr 0.000027	 wd 0.0000	time 0.2379 (0.2551)	loss 1.4047 (1.4222)	grad_norm 0.4385 (0.4441)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:57:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:36 lr 0.000027	 wd 0.0000	time 0.2097 (0.2643)	loss 1.6671 (1.4257)	grad_norm 0.4490 (0.4431)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:57:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:06:03 lr 0.000028	 wd 0.0000	time 0.1928 (0.2593)	loss 1.4694 (1.4279)	grad_norm 0.4106 (0.4421)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:58:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:32 lr 0.000028	 wd 0.0000	time 0.2195 (0.2551)	loss 1.3474 (1.4263)	grad_norm 0.3810 (0.4412)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:58:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:05:03 lr 0.000028	 wd 0.0000	time 0.2503 (0.2524)	loss 1.2680 (1.4289)	grad_norm 0.6609 (0.4422)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:58:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:39 lr 0.000028	 wd 0.0000	time 0.2345 (0.2532)	loss 1.2767 (1.4294)	grad_norm 0.4373 (0.4421)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:59:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:10 lr 0.000029	 wd 0.0000	time 0.2248 (0.2503)	loss 1.4737 (1.4293)	grad_norm 0.4291 (0.4417)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:59:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:43 lr 0.000029	 wd 0.0000	time 0.2048 (0.2477)	loss 1.4390 (1.4279)	grad_norm 0.4299 (0.4419)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 12:59:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:16 lr 0.000029	 wd 0.0000	time 0.2122 (0.2455)	loss 1.0875 (1.4264)	grad_norm 0.3953 (0.4421)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:00:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:52 lr 0.000030	 wd 0.0000	time 0.2293 (0.2454)	loss 1.7148 (1.4277)	grad_norm 0.4128 (0.4418)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:00:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:27 lr 0.000030	 wd 0.0000	time 0.1882 (0.2446)	loss 1.6160 (1.4271)	grad_norm 0.3931 (0.4408)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:01:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:02 lr 0.000030	 wd 0.0000	time 0.2011 (0.2430)	loss 1.1764 (1.4276)	grad_norm 0.5148 (0.4409)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:01:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:37 lr 0.000031	 wd 0.0000	time 0.2083 (0.2414)	loss 1.2628 (1.4257)	grad_norm 0.4060 (0.4405)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:01:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:12 lr 0.000031	 wd 0.0000	time 0.2365 (0.2408)	loss 1.4098 (1.4264)	grad_norm 0.4462 (0.4401)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:02:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:48 lr 0.000031	 wd 0.0000	time 0.2073 (0.2405)	loss 1.6236 (1.4268)	grad_norm 0.4277 (0.4397)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:02:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:24 lr 0.000032	 wd 0.0000	time 0.2168 (0.2393)	loss 1.0334 (1.4258)	grad_norm 0.3914 (0.4390)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:02:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000032	 wd 0.0000	time 0.1487 (0.2370)	loss 1.6033 (1.4260)	grad_norm 0.4362 (0.4390)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:02:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 3 training takes 0:09:57
[2024-07-13 13:03:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 41.846 (41.846)	Loss 0.4277 (0.4277)	Acc@1 91.797 (91.797)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 13:03:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.176 Acc@5 96.852
[2024-07-13 13:03:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.2%
[2024-07-13 13:03:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.18%
[2024-07-13 13:03:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 13:03:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 13:04:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][0/2502]	eta 10:56:01 lr 0.000032	 wd 0.0000	time 15.7320 (15.7320)	loss 1.4898 (1.4898)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:04:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:14:31 lr 0.000032	 wd 0.0000	time 0.1917 (0.3629)	loss 1.1989 (1.4349)	grad_norm 0.4120 (0.4235)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:04:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:11:07 lr 0.000033	 wd 0.0000	time 0.2345 (0.2899)	loss 1.1755 (1.4355)	grad_norm 0.3969 (0.4342)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:05:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:11:13 lr 0.000033	 wd 0.0000	time 0.2174 (0.3060)	loss 1.1400 (1.4338)	grad_norm 0.4305 (0.4330)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:05:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:09:51 lr 0.000033	 wd 0.0000	time 0.1812 (0.2812)	loss 1.6005 (1.4287)	grad_norm 0.4811 (0.4331)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:06:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:08:51 lr 0.000034	 wd 0.0000	time 0.1999 (0.2657)	loss 1.3543 (1.4214)	grad_norm 0.4492 (0.4333)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:06:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:08:09 lr 0.000034	 wd 0.0000	time 0.2275 (0.2573)	loss 1.5418 (1.4171)	grad_norm 0.4290 (0.4308)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:06:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:07:42 lr 0.000034	 wd 0.0000	time 0.1883 (0.2568)	loss 1.3437 (1.4172)	grad_norm 0.4007 (0.4316)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:07:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:08 lr 0.000035	 wd 0.0000	time 0.1909 (0.2516)	loss 1.5744 (1.4164)	grad_norm 0.4131 (0.4312)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:07:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:06:35 lr 0.000035	 wd 0.0000	time 0.1991 (0.2471)	loss 1.5494 (1.4176)	grad_norm 0.3987 (0.4310)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:07:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:04 lr 0.000035	 wd 0.0000	time 0.2077 (0.2430)	loss 1.5867 (1.4181)	grad_norm 0.4019 (0.4311)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:08:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:05:39 lr 0.000036	 wd 0.0000	time 0.2151 (0.2422)	loss 1.5943 (1.4188)	grad_norm 0.4042 (0.4298)	loss_scale 8192.0000 (4371.2988)	mem 7585MB
[2024-07-13 13:08:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:14 lr 0.000036	 wd 0.0000	time 0.1932 (0.2413)	loss 1.1120 (1.4171)	grad_norm 0.4537 (0.4323)	loss_scale 8192.0000 (4689.4255)	mem 7585MB
[2024-07-13 13:09:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:04:47 lr 0.000036	 wd 0.0000	time 0.2063 (0.2388)	loss 1.6413 (1.4163)	grad_norm 0.4577 (0.4318)	loss_scale 8192.0000 (4958.6472)	mem 7585MB
[2024-07-13 13:09:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:20 lr 0.000036	 wd 0.0000	time 0.1879 (0.2367)	loss 1.5554 (1.4160)	grad_norm 0.4673 (0.4315)	loss_scale 8192.0000 (5189.4361)	mem 7585MB
[2024-07-13 13:09:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:03:55 lr 0.000037	 wd 0.0000	time 0.2185 (0.2355)	loss 1.2977 (1.4186)	grad_norm 0.3901 (0.4315)	loss_scale 8192.0000 (5389.4737)	mem 7585MB
[2024-07-13 13:10:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:33 lr 0.000037	 wd 0.0000	time 0.2095 (0.2365)	loss 1.0803 (1.4180)	grad_norm 0.4015 (0.4307)	loss_scale 8192.0000 (5564.5222)	mem 7585MB
[2024-07-13 13:10:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:08 lr 0.000037	 wd 0.0000	time 0.1891 (0.2355)	loss 1.6178 (1.4173)	grad_norm 0.4374 (0.4303)	loss_scale 8192.0000 (5718.9888)	mem 7585MB
[2024-07-13 13:10:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:44 lr 0.000038	 wd 0.0000	time 0.2085 (0.2343)	loss 1.4354 (1.4169)	grad_norm 0.4046 (0.4303)	loss_scale 8192.0000 (5856.3021)	mem 7585MB
[2024-07-13 13:11:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:20 lr 0.000038	 wd 0.0000	time 0.2485 (0.2332)	loss 1.6786 (1.4166)	grad_norm 0.3978 (0.4298)	loss_scale 8192.0000 (5979.1689)	mem 7585MB
[2024-07-13 13:11:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:01:57 lr 0.000038	 wd 0.0000	time 0.2127 (0.2339)	loss 1.5035 (1.4158)	grad_norm 0.4239 (0.4296)	loss_scale 8192.0000 (6089.7551)	mem 7585MB
[2024-07-13 13:12:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:33 lr 0.000039	 wd 0.0000	time 0.2214 (0.2335)	loss 1.4568 (1.4161)	grad_norm 0.4139 (0.4291)	loss_scale 8192.0000 (6189.8144)	mem 7585MB
[2024-07-13 13:12:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:10 lr 0.000039	 wd 0.0000	time 0.2159 (0.2325)	loss 1.0247 (1.4136)	grad_norm 0.3585 (0.4291)	loss_scale 8192.0000 (6280.7815)	mem 7585MB
[2024-07-13 13:12:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:46 lr 0.000039	 wd 0.0000	time 0.1690 (0.2315)	loss 1.3729 (1.4137)	grad_norm 0.4826 (0.4297)	loss_scale 8192.0000 (6363.8418)	mem 7585MB
[2024-07-13 13:13:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:23 lr 0.000040	 wd 0.0000	time 0.2200 (0.2314)	loss 1.6252 (1.4135)	grad_norm 0.3884 (0.4298)	loss_scale 8192.0000 (6439.9833)	mem 7585MB
[2024-07-13 13:13:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1505 (0.2300)	loss 0.9433 (1.4132)	grad_norm 0.3899 (0.4291)	loss_scale 8192.0000 (6510.0360)	mem 7585MB
[2024-07-13 13:13:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 4 training takes 0:09:41
[2024-07-13 13:13:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 19.513 (19.513)	Loss 0.4370 (0.4370)	Acc@1 91.797 (91.797)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 13:14:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.246 Acc@5 96.898
[2024-07-13 13:14:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.2%
[2024-07-13 13:14:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.25%
[2024-07-13 13:14:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 13:14:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 13:14:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][0/2502]	eta 10:41:54 lr 0.000040	 wd 0.0000	time 15.3936 (15.3936)	loss 1.6398 (1.6398)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 13:14:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:16:55 lr 0.000040	 wd 0.0000	time 0.4121 (0.4227)	loss 1.3122 (1.4326)	grad_norm 0.4286 (0.4241)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 13:15:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:12:44 lr 0.000040	 wd 0.0000	time 0.2025 (0.3322)	loss 1.5364 (1.4343)	grad_norm 0.4516 (0.4254)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 13:15:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:39 lr 0.000040	 wd 0.0000	time 0.1965 (0.2904)	loss 1.6441 (1.4238)	grad_norm 0.4047 (0.4229)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 13:15:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:24 lr 0.000040	 wd 0.0000	time 0.1967 (0.2687)	loss 1.0180 (1.4253)	grad_norm 0.4304 (nan)	loss_scale 4096.0000 (7865.1372)	mem 7585MB
[2024-07-13 13:16:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:08:41 lr 0.000040	 wd 0.0000	time 0.3861 (0.2603)	loss 1.5800 (1.4203)	grad_norm 0.3880 (nan)	loss_scale 4096.0000 (7112.8144)	mem 7585MB
[2024-07-13 13:16:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:42 lr 0.000040	 wd 0.0000	time 0.2068 (0.2749)	loss 1.4753 (1.4211)	grad_norm 0.3785 (nan)	loss_scale 4096.0000 (6610.8486)	mem 7585MB
[2024-07-13 13:17:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:58 lr 0.000040	 wd 0.0000	time 0.2313 (0.2653)	loss 1.5047 (1.4184)	grad_norm 0.5211 (nan)	loss_scale 4096.0000 (6252.0970)	mem 7585MB
[2024-07-13 13:17:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:19 lr 0.000040	 wd 0.0000	time 0.1933 (0.2581)	loss 0.9691 (1.4124)	grad_norm 0.3933 (nan)	loss_scale 4096.0000 (5982.9213)	mem 7585MB
[2024-07-13 13:18:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:48 lr 0.000040	 wd 0.0000	time 0.3630 (0.2551)	loss 0.9220 (1.4114)	grad_norm 0.3907 (nan)	loss_scale 4096.0000 (5773.4961)	mem 7585MB
[2024-07-13 13:18:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:29 lr 0.000040	 wd 0.0000	time 0.2068 (0.2594)	loss 1.5744 (1.4145)	grad_norm 0.3771 (nan)	loss_scale 4096.0000 (5605.9141)	mem 7585MB
[2024-07-13 13:18:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:56 lr 0.000040	 wd 0.0000	time 0.2434 (0.2545)	loss 1.6058 (1.4103)	grad_norm 0.3866 (nan)	loss_scale 4096.0000 (5468.7738)	mem 7585MB
[2024-07-13 13:19:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:26 lr 0.000040	 wd 0.0000	time 0.1915 (0.2507)	loss 1.5944 (1.4081)	grad_norm 0.3984 (nan)	loss_scale 4096.0000 (5354.4713)	mem 7585MB
[2024-07-13 13:19:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:58 lr 0.000040	 wd 0.0000	time 0.2398 (0.2485)	loss 1.5350 (1.4085)	grad_norm 0.3957 (nan)	loss_scale 4096.0000 (5257.7402)	mem 7585MB
[2024-07-13 13:19:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:33 lr 0.000040	 wd 0.0000	time 0.2166 (0.2479)	loss 1.5684 (1.4080)	grad_norm 0.3938 (nan)	loss_scale 4096.0000 (5174.8180)	mem 7585MB
[2024-07-13 13:20:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:04:06 lr 0.000040	 wd 0.0000	time 0.2104 (0.2457)	loss 1.4635 (1.4078)	grad_norm 0.4089 (nan)	loss_scale 4096.0000 (5102.9447)	mem 7585MB
[2024-07-13 13:20:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:39 lr 0.000040	 wd 0.0000	time 0.2262 (0.2434)	loss 1.4854 (1.4095)	grad_norm 0.4955 (nan)	loss_scale 4096.0000 (5040.0500)	mem 7585MB
[2024-07-13 13:21:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:13 lr 0.000040	 wd 0.0000	time 0.1987 (0.2416)	loss 1.4051 (1.4090)	grad_norm 0.3756 (nan)	loss_scale 4096.0000 (4984.5503)	mem 7585MB
[2024-07-13 13:21:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:50 lr 0.000040	 wd 0.0000	time 0.1890 (0.2424)	loss 1.0245 (1.4083)	grad_norm 0.3876 (nan)	loss_scale 4096.0000 (4935.2138)	mem 7585MB
[2024-07-13 13:21:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:25 lr 0.000040	 wd 0.0000	time 0.1859 (0.2414)	loss 1.5136 (1.4103)	grad_norm 0.3990 (nan)	loss_scale 4096.0000 (4891.0679)	mem 7585MB
[2024-07-13 13:22:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:02:00 lr 0.000040	 wd 0.0000	time 0.2062 (0.2399)	loss 1.5487 (1.4112)	grad_norm 0.4254 (nan)	loss_scale 4096.0000 (4851.3343)	mem 7585MB
[2024-07-13 13:22:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:35 lr 0.000040	 wd 0.0000	time 0.2341 (0.2384)	loss 1.5612 (1.4117)	grad_norm 0.4266 (nan)	loss_scale 4096.0000 (4815.3832)	mem 7585MB
[2024-07-13 13:22:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:11 lr 0.000040	 wd 0.0000	time 0.1921 (0.2381)	loss 1.2912 (1.4096)	grad_norm 0.3839 (nan)	loss_scale 4096.0000 (4782.6988)	mem 7585MB
[2024-07-13 13:23:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:48 lr 0.000040	 wd 0.0000	time 0.2052 (0.2382)	loss 0.9240 (1.4086)	grad_norm 0.3873 (nan)	loss_scale 4096.0000 (4752.8553)	mem 7585MB
[2024-07-13 13:23:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:24 lr 0.000040	 wd 0.0000	time 0.2084 (0.2372)	loss 1.5321 (1.4086)	grad_norm 0.4343 (nan)	loss_scale 4096.0000 (4725.4977)	mem 7585MB
[2024-07-13 13:23:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1510 (0.2349)	loss 1.5800 (1.4085)	grad_norm 0.4031 (nan)	loss_scale 4096.0000 (4700.3279)	mem 7585MB
[2024-07-13 13:24:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 5 training takes 0:09:51
[2024-07-13 13:24:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 36.978 (36.978)	Loss 0.4390 (0.4390)	Acc@1 91.602 (91.602)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 13:24:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.344 Acc@5 96.924
[2024-07-13 13:24:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.3%
[2024-07-13 13:24:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.34%
[2024-07-13 13:24:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 13:24:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 13:25:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][0/2502]	eta 11:18:49 lr 0.000040	 wd 0.0000	time 16.2788 (16.2788)	loss 1.6155 (1.6155)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:25:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:14:32 lr 0.000040	 wd 0.0000	time 0.1936 (0.3631)	loss 1.2545 (1.3761)	grad_norm 0.8168 (0.4261)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:25:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:11:05 lr 0.000040	 wd 0.0000	time 0.2467 (0.2892)	loss 1.6607 (1.3988)	grad_norm 0.3963 (0.4243)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:26:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:11:44 lr 0.000040	 wd 0.0000	time 0.2172 (0.3200)	loss 1.5050 (1.4093)	grad_norm 0.4771 (0.4305)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:26:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:10:13 lr 0.000040	 wd 0.0000	time 0.2087 (0.2921)	loss 1.4022 (1.4028)	grad_norm 0.3898 (0.4251)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:27:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:09:10 lr 0.000040	 wd 0.0000	time 0.1928 (0.2749)	loss 1.3921 (1.3971)	grad_norm 0.4028 (0.4246)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:27:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:08:23 lr 0.000040	 wd 0.0000	time 0.2281 (0.2650)	loss 1.6650 (1.4012)	grad_norm 0.6529 (0.4247)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:28:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:08:21 lr 0.000040	 wd 0.0000	time 0.1905 (0.2783)	loss 1.4466 (1.4036)	grad_norm 0.7006 (0.4242)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:28:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:38 lr 0.000040	 wd 0.0000	time 0.2229 (0.2693)	loss 1.0395 (1.4022)	grad_norm 0.4732 (0.4230)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:28:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:07:00 lr 0.000040	 wd 0.0000	time 0.1971 (0.2624)	loss 1.7057 (1.4065)	grad_norm 0.3667 (0.4246)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:29:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:27 lr 0.000040	 wd 0.0000	time 0.2467 (0.2583)	loss 1.3419 (1.4017)	grad_norm nan (nan)	loss_scale 2048.0000 (4091.9081)	mem 7585MB
[2024-07-13 13:29:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:59 lr 0.000040	 wd 0.0000	time 0.1892 (0.2563)	loss 1.2470 (1.4008)	grad_norm 0.4224 (nan)	loss_scale 2048.0000 (3906.2670)	mem 7585MB
[2024-07-13 13:29:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:29 lr 0.000040	 wd 0.0000	time 0.2234 (0.2531)	loss 1.0962 (1.4023)	grad_norm 0.4724 (nan)	loss_scale 2048.0000 (3751.5404)	mem 7585MB
[2024-07-13 13:30:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:05:00 lr 0.000040	 wd 0.0000	time 0.1901 (0.2499)	loss 1.4351 (1.4014)	grad_norm 0.4297 (nan)	loss_scale 2048.0000 (3620.5995)	mem 7585MB
[2024-07-13 13:30:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:32 lr 0.000040	 wd 0.0000	time 0.2208 (0.2472)	loss 1.7029 (1.3999)	grad_norm 0.4041 (nan)	loss_scale 2048.0000 (3508.3512)	mem 7585MB
[2024-07-13 13:31:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:07 lr 0.000040	 wd 0.0000	time 0.3384 (0.2466)	loss 1.5100 (1.4013)	grad_norm 0.3784 (nan)	loss_scale 2048.0000 (3411.0593)	mem 7585MB
[2024-07-13 13:31:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:41 lr 0.000040	 wd 0.0000	time 0.2152 (0.2456)	loss 1.5799 (1.3998)	grad_norm 0.4292 (nan)	loss_scale 2048.0000 (3325.9213)	mem 7585MB
[2024-07-13 13:31:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:15 lr 0.000040	 wd 0.0000	time 0.2498 (0.2437)	loss 1.5649 (1.3989)	grad_norm 0.3667 (nan)	loss_scale 2048.0000 (3250.7937)	mem 7585MB
[2024-07-13 13:32:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:49 lr 0.000040	 wd 0.0000	time 0.2102 (0.2419)	loss 1.2146 (1.3986)	grad_norm 0.4146 (nan)	loss_scale 2048.0000 (3184.0089)	mem 7585MB
[2024-07-13 13:32:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:25 lr 0.000040	 wd 0.0000	time 0.2195 (0.2412)	loss 1.2876 (1.3980)	grad_norm 0.4095 (nan)	loss_scale 2048.0000 (3124.2504)	mem 7585MB
[2024-07-13 13:32:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:02:01 lr 0.000039	 wd 0.0000	time 0.2003 (0.2414)	loss 1.0170 (1.3979)	grad_norm 0.4175 (nan)	loss_scale 2048.0000 (3070.4648)	mem 7585MB
[2024-07-13 13:33:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:36 lr 0.000039	 wd 0.0000	time 0.2003 (0.2402)	loss 1.6004 (1.3974)	grad_norm 0.4167 (nan)	loss_scale 2048.0000 (3021.7991)	mem 7585MB
[2024-07-13 13:33:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:12 lr 0.000039	 wd 0.0000	time 0.2277 (0.2388)	loss 1.3054 (1.3979)	grad_norm 0.3976 (nan)	loss_scale 2048.0000 (2977.5557)	mem 7585MB
[2024-07-13 13:34:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:48 lr 0.000039	 wd 0.0000	time 0.2131 (0.2379)	loss 1.5119 (1.3986)	grad_norm 0.5003 (nan)	loss_scale 2048.0000 (2937.1578)	mem 7585MB
[2024-07-13 13:34:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:24 lr 0.000039	 wd 0.0000	time 0.3595 (0.2382)	loss 1.2259 (1.3977)	grad_norm 0.4150 (nan)	loss_scale 2048.0000 (2900.1249)	mem 7585MB
[2024-07-13 13:34:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1657 (0.2361)	loss 1.0541 (1.3984)	grad_norm 0.4186 (nan)	loss_scale 2048.0000 (2866.0536)	mem 7585MB
[2024-07-13 13:34:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 6 training takes 0:09:55
[2024-07-13 13:35:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 22.635 (22.635)	Loss 0.4380 (0.4380)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 7585MB
[2024-07-13 13:35:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.420 Acc@5 96.988
[2024-07-13 13:35:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.4%
[2024-07-13 13:35:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.42%
[2024-07-13 13:35:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 13:35:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 13:35:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][0/2502]	eta 20:29:44 lr 0.000039	 wd 0.0000	time 29.4902 (29.4902)	loss 1.6566 (1.6566)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:36:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:20:43 lr 0.000039	 wd 0.0000	time 0.1956 (0.5179)	loss 1.2752 (1.4235)	grad_norm 0.4218 (0.4134)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:36:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:13:54 lr 0.000039	 wd 0.0000	time 0.1948 (0.3625)	loss 1.5046 (1.3979)	grad_norm 0.4119 (0.4204)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:36:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:11:22 lr 0.000039	 wd 0.0000	time 0.2023 (0.3099)	loss 1.3490 (1.3958)	grad_norm 0.4170 (0.4261)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:37:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:10:08 lr 0.000039	 wd 0.0000	time 0.2135 (0.2894)	loss 1.3791 (1.3971)	grad_norm 0.4184 (0.4297)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:37:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:09:38 lr 0.000039	 wd 0.0000	time 0.2027 (0.2887)	loss 1.4943 (1.3923)	grad_norm 0.4037 (0.4273)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:38:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:42 lr 0.000039	 wd 0.0000	time 0.2081 (0.2747)	loss 1.3721 (1.3961)	grad_norm 0.4240 (0.4265)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:38:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:07:58 lr 0.000039	 wd 0.0000	time 0.1970 (0.2654)	loss 1.5032 (1.3999)	grad_norm 0.4511 (0.4237)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:38:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:07:22 lr 0.000039	 wd 0.0000	time 0.2609 (0.2600)	loss 0.9226 (1.4022)	grad_norm 0.4021 (0.4247)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:39:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:07:02 lr 0.000039	 wd 0.0000	time 0.1979 (0.2640)	loss 1.1212 (1.4041)	grad_norm 0.4168 (0.4234)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:39:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:27 lr 0.000039	 wd 0.0000	time 0.1893 (0.2583)	loss 1.2266 (1.3999)	grad_norm 0.3885 (0.4230)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:40:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:56 lr 0.000039	 wd 0.0000	time 0.2077 (0.2539)	loss 1.2761 (1.3982)	grad_norm 0.4072 (0.4233)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:40:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:26 lr 0.000039	 wd 0.0000	time 0.2072 (0.2504)	loss 1.4449 (1.3967)	grad_norm 0.3944 (0.4240)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:40:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:05:06 lr 0.000039	 wd 0.0000	time 0.2047 (0.2548)	loss 1.5132 (1.3966)	grad_norm 0.3928 (0.4276)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:41:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:36 lr 0.000039	 wd 0.0000	time 0.2155 (0.2513)	loss 1.4436 (1.3973)	grad_norm 0.3941 (0.4262)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:41:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:09 lr 0.000039	 wd 0.0000	time 0.2265 (0.2485)	loss 1.6758 (1.3964)	grad_norm 0.4396 (0.4263)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:41:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:42 lr 0.000039	 wd 0.0000	time 0.2436 (0.2462)	loss 1.5594 (1.3983)	grad_norm 0.4069 (0.4253)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:42:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:17 lr 0.000039	 wd 0.0000	time 0.1813 (0.2459)	loss 1.6035 (1.3986)	grad_norm 0.4172 (0.4246)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:42:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:52 lr 0.000039	 wd 0.0000	time 0.2152 (0.2451)	loss 1.1724 (1.3982)	grad_norm 0.4187 (0.4240)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:43:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:26 lr 0.000039	 wd 0.0000	time 0.1984 (0.2435)	loss 1.3582 (1.3975)	grad_norm 0.4407 (0.4245)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:43:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:02:01 lr 0.000039	 wd 0.0000	time 0.2177 (0.2418)	loss 1.4812 (1.3986)	grad_norm 0.3856 (0.4241)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:43:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:36 lr 0.000039	 wd 0.0000	time 0.2229 (0.2409)	loss 1.5043 (1.3996)	grad_norm 0.4835 (0.4246)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:44:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:12 lr 0.000039	 wd 0.0000	time 0.2023 (0.2409)	loss 1.1488 (1.3978)	grad_norm 0.4133 (0.4241)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:44:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:48 lr 0.000039	 wd 0.0000	time 0.2175 (0.2396)	loss 1.6517 (1.3983)	grad_norm 0.4066 (0.4237)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:44:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:24 lr 0.000039	 wd 0.0000	time 0.1943 (0.2384)	loss 1.5179 (1.3979)	grad_norm 0.4163 (0.4240)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:45:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1566 (0.2361)	loss 1.3181 (1.3981)	grad_norm 0.3995 (0.4244)	loss_scale 4096.0000 (2051.2755)	mem 7585MB
[2024-07-13 13:45:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 7 training takes 0:09:55
[2024-07-13 13:45:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 37.530 (37.530)	Loss 0.4402 (0.4402)	Acc@1 91.992 (91.992)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 13:46:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.420 Acc@5 96.966
[2024-07-13 13:46:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.4%
[2024-07-13 13:46:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.42%
[2024-07-13 13:46:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 13:46:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 13:46:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][0/2502]	eta 11:02:47 lr 0.000039	 wd 0.0000	time 15.8942 (15.8942)	loss 1.4615 (1.4615)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:46:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:14:28 lr 0.000039	 wd 0.0000	time 0.2171 (0.3616)	loss 1.4993 (1.4325)	grad_norm 0.4264 (0.4201)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:47:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:13:11 lr 0.000039	 wd 0.0000	time 0.2647 (0.3438)	loss 1.5889 (1.4081)	grad_norm 0.4168 (0.4185)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:47:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:10:58 lr 0.000038	 wd 0.0000	time 0.1904 (0.2992)	loss 1.4033 (1.4053)	grad_norm 0.3961 (0.4185)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:48:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:09:39 lr 0.000038	 wd 0.0000	time 0.1935 (0.2759)	loss 1.6653 (1.4012)	grad_norm 0.4062 (0.4235)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:48:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:08:42 lr 0.000038	 wd 0.0000	time 0.2122 (0.2612)	loss 1.4753 (1.4047)	grad_norm 0.3941 (0.4219)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:48:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:11 lr 0.000038	 wd 0.0000	time 0.2229 (0.2586)	loss 1.5862 (1.4099)	grad_norm 0.4023 (0.4260)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:49:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:42 lr 0.000038	 wd 0.0000	time 0.2173 (0.2564)	loss 1.6993 (1.4080)	grad_norm 0.4056 (0.4247)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:49:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:06 lr 0.000038	 wd 0.0000	time 0.2554 (0.2506)	loss 1.5050 (1.4056)	grad_norm 0.3672 (0.4228)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:49:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:33 lr 0.000038	 wd 0.0000	time 0.2143 (0.2459)	loss 1.6832 (1.4057)	grad_norm 0.8388 (0.4226)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:50:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:06 lr 0.000038	 wd 0.0000	time 0.1947 (0.2438)	loss 1.5208 (1.4017)	grad_norm 0.3874 (0.4216)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:50:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:40 lr 0.000038	 wd 0.0000	time 0.2575 (0.2432)	loss 1.3748 (1.3985)	grad_norm 0.4003 (0.4205)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:51:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:13 lr 0.000038	 wd 0.0000	time 0.1919 (0.2407)	loss 1.4770 (1.3987)	grad_norm 0.3923 (0.4195)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:51:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:46 lr 0.000038	 wd 0.0000	time 0.2076 (0.2384)	loss 1.1876 (1.3971)	grad_norm 0.4062 (0.4184)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:51:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:20 lr 0.000038	 wd 0.0000	time 0.2129 (0.2365)	loss 0.9711 (1.3988)	grad_norm 3.1779 (0.4231)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:52:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:03:57 lr 0.000038	 wd 0.0000	time 0.2179 (0.2375)	loss 0.8543 (1.3966)	grad_norm 0.4163 (0.4236)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:52:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:32 lr 0.000038	 wd 0.0000	time 0.1902 (0.2360)	loss 1.2422 (1.3938)	grad_norm 0.3834 (0.4234)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:52:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:08 lr 0.000038	 wd 0.0000	time 0.2034 (0.2345)	loss 1.1947 (1.3956)	grad_norm 0.3935 (0.4234)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:53:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:43 lr 0.000038	 wd 0.0000	time 0.1893 (0.2330)	loss 1.5749 (1.3966)	grad_norm 0.3905 (0.4238)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:53:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:20 lr 0.000038	 wd 0.0000	time 0.2404 (0.2327)	loss 1.3321 (1.3958)	grad_norm 0.3854 (0.4234)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 13:53:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:57 lr 0.000038	 wd 0.0000	time 0.2104 (0.2335)	loss 1.7239 (1.3977)	grad_norm 0.3957 (nan)	loss_scale 2048.0000 (4003.8861)	mem 7585MB
[2024-07-13 13:54:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:33 lr 0.000038	 wd 0.0000	time 0.1966 (0.2323)	loss 1.4232 (1.3969)	grad_norm 0.4037 (nan)	loss_scale 2048.0000 (3910.7930)	mem 7585MB
[2024-07-13 13:54:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:09 lr 0.000038	 wd 0.0000	time 0.1804 (0.2314)	loss 1.5843 (1.3954)	grad_norm 0.4070 (nan)	loss_scale 2048.0000 (3826.1590)	mem 7585MB
[2024-07-13 13:55:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:46 lr 0.000038	 wd 0.0000	time 0.2212 (0.2307)	loss 1.5428 (1.3961)	grad_norm 0.4321 (nan)	loss_scale 2048.0000 (3748.8814)	mem 7585MB
[2024-07-13 13:55:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:23 lr 0.000038	 wd 0.0000	time 0.2039 (0.2307)	loss 1.3562 (1.3976)	grad_norm 0.4176 (nan)	loss_scale 2048.0000 (3678.0408)	mem 7585MB
[2024-07-13 13:55:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000038	 wd 0.0000	time 0.1540 (0.2287)	loss 1.7960 (1.3990)	grad_norm 0.3847 (nan)	loss_scale 2048.0000 (3612.8653)	mem 7585MB
[2024-07-13 13:55:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 8 training takes 0:09:36
[2024-07-13 13:56:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 20.100 (20.100)	Loss 0.4368 (0.4368)	Acc@1 91.992 (91.992)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 13:56:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.452 Acc@5 97.024
[2024-07-13 13:56:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.5%
[2024-07-13 13:56:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.45%
[2024-07-13 13:56:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 13:56:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 13:56:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][0/2502]	eta 14:31:02 lr 0.000038	 wd 0.0000	time 20.8883 (20.8883)	loss 1.3981 (1.3981)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:57:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:17:45 lr 0.000038	 wd 0.0000	time 0.1830 (0.4434)	loss 1.2652 (1.3635)	grad_norm 0.3831 (0.4499)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:57:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:12:28 lr 0.000037	 wd 0.0000	time 0.1999 (0.3252)	loss 1.5359 (1.3757)	grad_norm 0.5726 (0.4289)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:57:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:27 lr 0.000037	 wd 0.0000	time 0.1830 (0.2849)	loss 1.4682 (1.3873)	grad_norm 0.3786 (0.4290)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:58:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:17 lr 0.000037	 wd 0.0000	time 0.2367 (0.2653)	loss 1.5849 (1.3820)	grad_norm 0.3732 (0.4290)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:58:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:09:19 lr 0.000037	 wd 0.0000	time 0.2193 (0.2793)	loss 1.4249 (1.3886)	grad_norm 0.4337 (0.4255)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:59:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:30 lr 0.000037	 wd 0.0000	time 0.2139 (0.2683)	loss 1.5348 (1.3829)	grad_norm 0.4044 (0.4232)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:59:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:47 lr 0.000037	 wd 0.0000	time 0.1904 (0.2593)	loss 1.5784 (1.3844)	grad_norm 0.3859 (0.4231)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 13:59:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:09 lr 0.000037	 wd 0.0000	time 0.2439 (0.2526)	loss 1.4148 (1.3875)	grad_norm 0.4199 (0.4236)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:00:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:07:04 lr 0.000037	 wd 0.0000	time 0.2385 (0.2651)	loss 1.6382 (1.3844)	grad_norm 0.3835 (0.4241)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:00:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:30 lr 0.000037	 wd 0.0000	time 0.2045 (0.2597)	loss 1.5063 (1.3871)	grad_norm 0.6280 (0.4238)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:01:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:57 lr 0.000037	 wd 0.0000	time 0.1936 (0.2548)	loss 1.4255 (1.3903)	grad_norm 0.3668 (0.4229)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:01:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:26 lr 0.000037	 wd 0.0000	time 0.2094 (0.2509)	loss 1.5674 (1.3912)	grad_norm 0.3960 (0.4230)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:01:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:05:06 lr 0.000037	 wd 0.0000	time 0.2246 (0.2547)	loss 0.9933 (1.3892)	grad_norm 0.3827 (0.4232)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:02:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:36 lr 0.000037	 wd 0.0000	time 0.1877 (0.2513)	loss 1.3809 (1.3907)	grad_norm 0.3877 (0.4248)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:02:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:04:08 lr 0.000037	 wd 0.0000	time 0.1999 (0.2484)	loss 1.5266 (1.3927)	grad_norm 0.4138 (0.4239)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:02:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:41 lr 0.000037	 wd 0.0000	time 0.2220 (0.2459)	loss 0.9568 (1.3919)	grad_norm 0.4208 (0.4232)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:03:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:16 lr 0.000037	 wd 0.0000	time 0.2072 (0.2448)	loss 1.1453 (1.3932)	grad_norm 0.4432 (0.4225)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:03:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:51 lr 0.000037	 wd 0.0000	time 0.1866 (0.2449)	loss 1.5652 (1.3935)	grad_norm 0.4122 (0.4237)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:04:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:26 lr 0.000037	 wd 0.0000	time 0.2320 (0.2432)	loss 1.3617 (1.3922)	grad_norm 0.3979 (0.4234)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:04:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:02:01 lr 0.000037	 wd 0.0000	time 0.2134 (0.2414)	loss 1.5251 (1.3923)	grad_norm 0.3776 (0.4235)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:04:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:36 lr 0.000036	 wd 0.0000	time 0.1902 (0.2404)	loss 1.0887 (1.3924)	grad_norm 0.4036 (0.4237)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:05:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:12 lr 0.000036	 wd 0.0000	time 0.1782 (0.2404)	loss 1.5152 (1.3935)	grad_norm 0.5221 (0.4234)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:05:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:48 lr 0.000036	 wd 0.0000	time 0.2006 (0.2393)	loss 1.4602 (1.3941)	grad_norm 0.3915 (0.4233)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:05:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:24 lr 0.000036	 wd 0.0000	time 0.2077 (0.2380)	loss 1.3099 (1.3937)	grad_norm 0.4768 (0.4229)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:06:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000036	 wd 0.0000	time 0.1757 (0.2356)	loss 1.1458 (1.3949)	grad_norm 0.3715 (0.4227)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:06:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 9 training takes 0:09:53
[2024-07-13 14:06:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 39.618 (39.618)	Loss 0.4285 (0.4285)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 14:07:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.500 Acc@5 97.046
[2024-07-13 14:07:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.5%
[2024-07-13 14:07:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.50%
[2024-07-13 14:07:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 14:07:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 14:07:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][0/2502]	eta 11:26:42 lr 0.000036	 wd 0.0000	time 16.4678 (16.4678)	loss 1.3131 (1.3131)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:07:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:14:36 lr 0.000036	 wd 0.0000	time 0.2121 (0.3651)	loss 1.3730 (1.3752)	grad_norm 0.3695 (0.4086)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:08:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:12:50 lr 0.000036	 wd 0.0000	time 0.2417 (0.3347)	loss 1.3356 (1.3957)	grad_norm 0.4040 (0.4158)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:08:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:51 lr 0.000036	 wd 0.0000	time 0.2149 (0.2961)	loss 0.8896 (1.3935)	grad_norm 0.4145 (0.4151)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:08:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:35 lr 0.000036	 wd 0.0000	time 0.2091 (0.2738)	loss 1.5538 (1.3964)	grad_norm 0.4117 (0.4110)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:09:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:08:40 lr 0.000036	 wd 0.0000	time 0.2373 (0.2601)	loss 1.4397 (1.3917)	grad_norm 0.3712 (0.4205)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:09:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:08 lr 0.000036	 wd 0.0000	time 0.4343 (0.2570)	loss 1.5404 (1.3919)	grad_norm 0.4647 (0.4186)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:10:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:54 lr 0.000036	 wd 0.0000	time 0.1927 (0.2632)	loss 1.5169 (1.3877)	grad_norm 0.3878 (0.4187)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:10:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:07:15 lr 0.000036	 wd 0.0000	time 0.2026 (0.2561)	loss 1.2953 (1.3869)	grad_norm 0.3831 (0.4184)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:10:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:41 lr 0.000036	 wd 0.0000	time 0.1926 (0.2509)	loss 1.5809 (1.3868)	grad_norm 0.4353 (0.4168)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 14:11:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:13 lr 0.000036	 wd 0.0000	time 0.2232 (0.2485)	loss 1.5024 (1.3853)	grad_norm 0.4114 (0.4162)	loss_scale 4096.0000 (2240.3197)	mem 7585MB
[2024-07-13 14:11:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:46 lr 0.000036	 wd 0.0000	time 0.1886 (0.2473)	loss 1.3394 (1.3832)	grad_norm 0.4099 (0.4160)	loss_scale 4096.0000 (2408.8647)	mem 7585MB
[2024-07-13 14:12:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:17 lr 0.000035	 wd 0.0000	time 0.1903 (0.2442)	loss 1.3556 (1.3837)	grad_norm 0.4355 (0.4157)	loss_scale 4096.0000 (2549.3422)	mem 7585MB
[2024-07-13 14:12:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:50 lr 0.000035	 wd 0.0000	time 0.2263 (0.2415)	loss 1.6201 (1.3862)	grad_norm 0.3935 (0.4158)	loss_scale 4096.0000 (2668.2244)	mem 7585MB
[2024-07-13 14:12:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:23 lr 0.000035	 wd 0.0000	time 0.1959 (0.2394)	loss 1.3764 (1.3867)	grad_norm 0.4673 (0.4169)	loss_scale 4096.0000 (2770.1356)	mem 7585MB
[2024-07-13 14:13:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:04:00 lr 0.000035	 wd 0.0000	time 0.1816 (0.2401)	loss 1.2819 (1.3867)	grad_norm 0.3670 (0.4162)	loss_scale 4096.0000 (2858.4677)	mem 7585MB
[2024-07-13 14:13:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:35 lr 0.000035	 wd 0.0000	time 0.2087 (0.2386)	loss 1.2626 (1.3882)	grad_norm 0.4021 (0.4157)	loss_scale 4096.0000 (2935.7651)	mem 7585MB
[2024-07-13 14:13:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:10 lr 0.000035	 wd 0.0000	time 0.2272 (0.2370)	loss 1.3225 (1.3892)	grad_norm 0.3651 (0.4158)	loss_scale 4096.0000 (3003.9741)	mem 7585MB
[2024-07-13 14:14:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:45 lr 0.000035	 wd 0.0000	time 0.1805 (0.2355)	loss 1.4218 (1.3899)	grad_norm 0.4618 (0.4156)	loss_scale 4096.0000 (3064.6086)	mem 7585MB
[2024-07-13 14:14:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:21 lr 0.000035	 wd 0.0000	time 0.2148 (0.2351)	loss 1.5479 (1.3914)	grad_norm 0.4136 (0.4155)	loss_scale 4096.0000 (3118.8638)	mem 7585MB
[2024-07-13 14:15:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:58 lr 0.000035	 wd 0.0000	time 0.1981 (0.2354)	loss 1.2734 (1.3922)	grad_norm 0.4057 (0.4150)	loss_scale 4096.0000 (3167.6962)	mem 7585MB
[2024-07-13 14:15:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:34 lr 0.000035	 wd 0.0000	time 0.2012 (0.2343)	loss 1.5886 (1.3940)	grad_norm 0.4106 (0.4150)	loss_scale 4096.0000 (3211.8801)	mem 7585MB
[2024-07-13 14:15:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:10 lr 0.000035	 wd 0.0000	time 0.2283 (0.2332)	loss 0.9818 (1.3939)	grad_norm 0.4123 (0.4157)	loss_scale 4096.0000 (3252.0491)	mem 7585MB
[2024-07-13 14:16:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:47 lr 0.000035	 wd 0.0000	time 0.2395 (0.2328)	loss 1.5208 (1.3934)	grad_norm 0.4079 (0.4156)	loss_scale 4096.0000 (3288.7266)	mem 7585MB
[2024-07-13 14:16:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:23 lr 0.000035	 wd 0.0000	time 0.1970 (0.2328)	loss 1.5610 (1.3934)	grad_norm 0.4438 (0.4158)	loss_scale 4096.0000 (3322.3490)	mem 7585MB
[2024-07-13 14:16:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1606 (0.2307)	loss 1.3762 (1.3924)	grad_norm 0.4289 (0.4160)	loss_scale 4096.0000 (3353.2827)	mem 7585MB
[2024-07-13 14:16:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 10 training takes 0:09:41
[2024-07-13 14:17:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 21.084 (21.084)	Loss 0.4316 (0.4316)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 14:17:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.540 Acc@5 97.072
[2024-07-13 14:17:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.5%
[2024-07-13 14:17:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.54%
[2024-07-13 14:17:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 14:17:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 14:17:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][0/2502]	eta 18:04:00 lr 0.000035	 wd 0.0000	time 25.9955 (25.9955)	loss 1.5499 (1.5499)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:18:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:20:23 lr 0.000035	 wd 0.0000	time 0.2204 (0.5094)	loss 1.3819 (1.3847)	grad_norm 0.4212 (0.4209)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:18:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:13:42 lr 0.000034	 wd 0.0000	time 0.1826 (0.3572)	loss 1.5028 (1.3885)	grad_norm 0.4457 (0.4202)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:18:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:11:15 lr 0.000034	 wd 0.0000	time 0.2087 (0.3068)	loss 1.3592 (1.3897)	grad_norm 0.4475 (0.4219)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:19:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:09:59 lr 0.000034	 wd 0.0000	time 0.2125 (0.2852)	loss 1.5770 (1.3898)	grad_norm 0.3891 (0.4241)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:19:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:09:10 lr 0.000034	 wd 0.0000	time 0.1939 (0.2748)	loss 1.4194 (1.3864)	grad_norm 0.3722 (0.4214)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:20:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:23 lr 0.000034	 wd 0.0000	time 0.2011 (0.2647)	loss 1.5005 (1.3841)	grad_norm 0.4047 (0.4202)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:20:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:07:43 lr 0.000034	 wd 0.0000	time 0.2105 (0.2570)	loss 1.5082 (1.3843)	grad_norm 0.3922 (0.4191)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:20:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:07:07 lr 0.000034	 wd 0.0000	time 0.2286 (0.2512)	loss 1.6451 (1.3867)	grad_norm 0.6496 (0.4178)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:21:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:07:01 lr 0.000034	 wd 0.0000	time 0.2107 (0.2634)	loss 1.5686 (1.3867)	grad_norm 0.3826 (0.4174)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:21:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:28 lr 0.000034	 wd 0.0000	time 0.1977 (0.2586)	loss 1.4866 (1.3888)	grad_norm 0.4410 (0.4159)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:22:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:56 lr 0.000034	 wd 0.0000	time 0.1947 (0.2540)	loss 1.5826 (1.3902)	grad_norm 0.3947 (0.4164)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:22:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:25 lr 0.000034	 wd 0.0000	time 0.2175 (0.2500)	loss 1.7265 (1.3902)	grad_norm 0.4050 (0.4180)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:22:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:05:01 lr 0.000034	 wd 0.0000	time 0.1991 (0.2511)	loss 0.9186 (1.3890)	grad_norm 0.3631 (0.4174)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:23:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:33 lr 0.000034	 wd 0.0000	time 0.1999 (0.2484)	loss 0.8963 (1.3885)	grad_norm 0.3885 (0.4181)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:23:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:04:06 lr 0.000034	 wd 0.0000	time 0.2020 (0.2457)	loss 1.4596 (1.3876)	grad_norm 0.3933 (0.4189)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:23:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:39 lr 0.000034	 wd 0.0000	time 0.1877 (0.2433)	loss 1.2801 (1.3887)	grad_norm 0.4385 (0.4181)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:24:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:14 lr 0.000033	 wd 0.0000	time 0.2120 (0.2420)	loss 1.5168 (1.3878)	grad_norm 0.3952 (0.4191)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:24:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:50 lr 0.000033	 wd 0.0000	time 0.2168 (0.2423)	loss 1.3182 (1.3894)	grad_norm 0.3726 (0.4190)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:25:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:24 lr 0.000033	 wd 0.0000	time 0.2001 (0.2408)	loss 1.5236 (1.3897)	grad_norm 0.4122 (0.4191)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:25:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:02:00 lr 0.000033	 wd 0.0000	time 0.2150 (0.2392)	loss 1.1314 (1.3889)	grad_norm 0.3788 (0.4195)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:25:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:35 lr 0.000033	 wd 0.0000	time 0.2273 (0.2381)	loss 1.5859 (1.3887)	grad_norm 0.3997 (0.4194)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:26:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:11 lr 0.000033	 wd 0.0000	time 0.1933 (0.2379)	loss 1.3113 (1.3896)	grad_norm 0.4162 (0.4190)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:26:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:47 lr 0.000033	 wd 0.0000	time 0.2157 (0.2371)	loss 1.5924 (1.3894)	grad_norm 0.4032 (0.4186)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:26:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:24 lr 0.000033	 wd 0.0000	time 0.2096 (0.2360)	loss 1.2877 (1.3886)	grad_norm 0.4023 (0.4188)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:27:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000033	 wd 0.0000	time 0.1529 (0.2336)	loss 1.4304 (1.3883)	grad_norm 0.3939 (0.4183)	loss_scale 8192.0000 (4253.2235)	mem 7585MB
[2024-07-13 14:27:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 11 training takes 0:09:48
[2024-07-13 14:27:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 38.796 (38.796)	Loss 0.4304 (0.4304)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 14:28:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.560 Acc@5 97.086
[2024-07-13 14:28:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.6%
[2024-07-13 14:28:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.56%
[2024-07-13 14:28:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 14:28:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 14:28:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][0/2502]	eta 11:06:38 lr 0.000033	 wd 0.0000	time 15.9868 (15.9868)	loss 1.6548 (1.6548)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:28:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:14:31 lr 0.000033	 wd 0.0000	time 0.1946 (0.3626)	loss 1.5270 (1.3958)	grad_norm 0.4127 (0.4064)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:29:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:11:36 lr 0.000033	 wd 0.0000	time 0.4302 (0.3027)	loss 0.9968 (1.4010)	grad_norm 0.3565 (0.4107)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:29:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:54 lr 0.000033	 wd 0.0000	time 0.1870 (0.2970)	loss 1.3297 (1.3999)	grad_norm 0.4196 (0.4149)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:29:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:35 lr 0.000033	 wd 0.0000	time 0.2315 (0.2739)	loss 1.2611 (1.3922)	grad_norm 0.3683 (0.4165)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:30:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:08:40 lr 0.000032	 wd 0.0000	time 0.2067 (0.2600)	loss 1.0246 (1.3926)	grad_norm 0.3711 (0.4173)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:30:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:08:02 lr 0.000032	 wd 0.0000	time 0.2369 (0.2536)	loss 1.3949 (1.3902)	grad_norm 0.4057 (0.4174)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:31:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:51 lr 0.000032	 wd 0.0000	time 0.2471 (0.2615)	loss 1.4978 (1.3882)	grad_norm 0.3980 (0.4155)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:31:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:07:13 lr 0.000032	 wd 0.0000	time 0.1872 (0.2547)	loss 1.4859 (1.3962)	grad_norm 0.3895 (0.4171)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:31:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:39 lr 0.000032	 wd 0.0000	time 0.2022 (0.2493)	loss 1.0706 (1.3965)	grad_norm 0.3939 (0.4173)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:32:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:09 lr 0.000032	 wd 0.0000	time 0.2464 (0.2460)	loss 1.6513 (1.3940)	grad_norm 0.3911 (0.4151)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:32:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:44 lr 0.000032	 wd 0.0000	time 0.1939 (0.2460)	loss 1.5083 (1.3982)	grad_norm 0.5513 (0.4151)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:32:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:16 lr 0.000032	 wd 0.0000	time 0.1936 (0.2434)	loss 1.5420 (1.3969)	grad_norm 0.3965 (0.4150)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:33:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:49 lr 0.000032	 wd 0.0000	time 0.2047 (0.2407)	loss 1.4534 (1.3973)	grad_norm 0.3954 (0.4180)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:33:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:22 lr 0.000032	 wd 0.0000	time 0.2439 (0.2383)	loss 1.6430 (1.3972)	grad_norm 0.4078 (0.4178)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:34:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:03:57 lr 0.000032	 wd 0.0000	time 0.1996 (0.2371)	loss 1.4634 (1.3980)	grad_norm 0.3937 (0.4169)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:34:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:34 lr 0.000032	 wd 0.0000	time 0.2163 (0.2376)	loss 1.4546 (1.3967)	grad_norm 0.3785 (0.4164)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:34:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:09 lr 0.000031	 wd 0.0000	time 0.2278 (0.2359)	loss 1.5914 (1.3980)	grad_norm 0.3964 (0.4160)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:35:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:44 lr 0.000031	 wd 0.0000	time 0.1964 (0.2345)	loss 1.3241 (1.3986)	grad_norm 0.4045 (0.4162)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 14:35:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:20 lr 0.000031	 wd 0.0000	time 0.2210 (0.2336)	loss 1.4486 (1.3982)	grad_norm 0.4655 (inf)	loss_scale 4096.0000 (8148.9069)	mem 7585MB
[2024-07-13 14:35:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:01:57 lr 0.000031	 wd 0.0000	time 0.2398 (0.2341)	loss 1.4196 (1.3971)	grad_norm 0.3720 (inf)	loss_scale 4096.0000 (7946.3628)	mem 7585MB
[2024-07-13 14:36:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:33 lr 0.000031	 wd 0.0000	time 0.2154 (0.2333)	loss 1.4716 (1.3983)	grad_norm 0.3865 (inf)	loss_scale 4096.0000 (7763.0995)	mem 7585MB
[2024-07-13 14:36:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:10 lr 0.000031	 wd 0.0000	time 0.2011 (0.2322)	loss 1.5994 (1.3997)	grad_norm 2.1917 (inf)	loss_scale 4096.0000 (7596.4889)	mem 7585MB
[2024-07-13 14:36:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:46 lr 0.000031	 wd 0.0000	time 0.2355 (0.2313)	loss 1.4610 (1.3997)	grad_norm 0.3940 (inf)	loss_scale 4096.0000 (7444.3598)	mem 7585MB
[2024-07-13 14:37:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:23 lr 0.000031	 wd 0.0000	time 0.2031 (0.2320)	loss 1.5252 (1.3995)	grad_norm 0.4227 (inf)	loss_scale 4096.0000 (7304.9030)	mem 7585MB
[2024-07-13 14:37:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000031	 wd 0.0000	time 0.1567 (0.2298)	loss 1.1417 (1.3983)	grad_norm 0.3916 (inf)	loss_scale 4096.0000 (7176.5982)	mem 7585MB
[2024-07-13 14:37:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 12 training takes 0:09:40
[2024-07-13 14:38:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 18.983 (18.983)	Loss 0.4292 (0.4292)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 14:38:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.544 Acc@5 97.092
[2024-07-13 14:38:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.5%
[2024-07-13 14:38:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.56%
[2024-07-13 14:38:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][0/2502]	eta 13:29:54 lr 0.000031	 wd 0.0000	time 19.4222 (19.4222)	loss 1.3958 (1.3958)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:39:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:18:28 lr 0.000031	 wd 0.0000	time 0.1998 (0.4616)	loss 1.4605 (1.3829)	grad_norm 0.4026 (0.4245)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:39:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:12:50 lr 0.000031	 wd 0.0000	time 0.2088 (0.3346)	loss 1.7279 (1.3849)	grad_norm 0.3739 (0.4154)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:39:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:10:43 lr 0.000031	 wd 0.0000	time 0.2020 (0.2920)	loss 1.4612 (1.3941)	grad_norm 0.4054 (0.4114)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:40:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:09:26 lr 0.000030	 wd 0.0000	time 0.1832 (0.2696)	loss 1.3808 (1.3931)	grad_norm 0.3725 (0.4105)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:40:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:08:45 lr 0.000030	 wd 0.0000	time 0.2342 (0.2625)	loss 1.5396 (1.3876)	grad_norm 0.4833 (0.4102)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:40:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:11 lr 0.000030	 wd 0.0000	time 0.1936 (0.2582)	loss 1.5682 (1.3937)	grad_norm 0.4031 (0.4091)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:41:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:07:32 lr 0.000030	 wd 0.0000	time 0.2100 (0.2511)	loss 1.4786 (1.3889)	grad_norm 0.4016 (0.4094)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:41:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:06:58 lr 0.000030	 wd 0.0000	time 0.1886 (0.2458)	loss 1.5630 (1.3929)	grad_norm 0.3717 (0.4092)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:41:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:06:29 lr 0.000030	 wd 0.0000	time 0.2293 (0.2429)	loss 1.5656 (1.3897)	grad_norm 0.3965 (0.4093)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:42:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:10 lr 0.000030	 wd 0.0000	time 0.1968 (0.2468)	loss 1.6293 (1.3953)	grad_norm 0.3650 (0.4101)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:42:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:40 lr 0.000030	 wd 0.0000	time 0.1932 (0.2431)	loss 1.4195 (1.3969)	grad_norm 0.3834 (0.4100)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:43:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:12 lr 0.000030	 wd 0.0000	time 0.1804 (0.2404)	loss 1.5869 (1.3931)	grad_norm 0.3898 (0.4102)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:43:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:04:46 lr 0.000030	 wd 0.0000	time 0.2196 (0.2383)	loss 1.4739 (1.3918)	grad_norm 0.3878 (0.4105)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:43:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:24 lr 0.000030	 wd 0.0000	time 0.2028 (0.2401)	loss 1.6992 (1.3924)	grad_norm 0.4857 (0.4108)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:44:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:03:58 lr 0.000030	 wd 0.0000	time 0.1961 (0.2379)	loss 1.6753 (1.3912)	grad_norm 0.4085 (0.4107)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:44:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:32 lr 0.000029	 wd 0.0000	time 0.2137 (0.2360)	loss 1.5939 (1.3907)	grad_norm 0.4100 (0.4112)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:44:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:07 lr 0.000029	 wd 0.0000	time 0.2089 (0.2342)	loss 0.8799 (1.3884)	grad_norm 0.4088 (0.4128)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:45:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:44 lr 0.000029	 wd 0.0000	time 0.2363 (0.2337)	loss 1.4810 (1.3901)	grad_norm 0.3961 (0.4131)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:45:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:20 lr 0.000029	 wd 0.0000	time 0.1787 (0.2342)	loss 1.2378 (1.3905)	grad_norm 0.4341 (0.4128)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:46:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:56 lr 0.000029	 wd 0.0000	time 0.2200 (0.2330)	loss 1.4701 (1.3916)	grad_norm 0.3796 (0.4127)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:46:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:33 lr 0.000029	 wd 0.0000	time 0.2285 (0.2319)	loss 1.1534 (1.3912)	grad_norm 0.5843 (0.4131)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:46:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:09 lr 0.000029	 wd 0.0000	time 0.2252 (0.2313)	loss 1.5888 (1.3926)	grad_norm 0.5541 (0.4138)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:47:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:46 lr 0.000029	 wd 0.0000	time 0.1895 (0.2312)	loss 1.3369 (1.3922)	grad_norm 0.4282 (0.4145)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:47:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:23 lr 0.000029	 wd 0.0000	time 0.2085 (0.2305)	loss 1.7208 (1.3934)	grad_norm 0.3920 (0.4142)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:47:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000029	 wd 0.0000	time 0.1628 (0.2285)	loss 1.5744 (1.3927)	grad_norm 0.4011 (0.4139)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:47:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 13 training takes 0:09:35
[2024-07-13 14:48:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 20.512 (20.512)	Loss 0.4268 (0.4268)	Acc@1 91.992 (91.992)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 14:48:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.608 Acc@5 97.110
[2024-07-13 14:48:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.6%
[2024-07-13 14:48:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.61%
[2024-07-13 14:48:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 14:48:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 14:49:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][0/2502]	eta 23:44:33 lr 0.000029	 wd 0.0000	time 34.1621 (34.1621)	loss 1.5195 (1.5195)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:49:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:21:45 lr 0.000029	 wd 0.0000	time 0.1935 (0.5435)	loss 1.5863 (1.4013)	grad_norm 0.3895 (0.4067)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:49:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:14:20 lr 0.000028	 wd 0.0000	time 0.1776 (0.3738)	loss 1.3163 (1.4215)	grad_norm 0.3785 (0.4135)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:50:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:12:25 lr 0.000028	 wd 0.0000	time 0.3361 (0.3386)	loss 1.0265 (1.4094)	grad_norm 0.4021 (0.4177)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:50:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:11:16 lr 0.000028	 wd 0.0000	time 0.1960 (0.3218)	loss 1.2459 (1.3935)	grad_norm 0.3983 (0.4164)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:50:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:09:57 lr 0.000028	 wd 0.0000	time 0.2056 (0.2984)	loss 1.3289 (1.3965)	grad_norm 0.4590 (0.4156)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:51:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:08:58 lr 0.000028	 wd 0.0000	time 0.1796 (0.2829)	loss 1.6896 (1.4024)	grad_norm 2.1080 (0.4209)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:51:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:08:16 lr 0.000028	 wd 0.0000	time 0.2296 (0.2753)	loss 1.4749 (1.3984)	grad_norm 0.4143 (0.4199)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:52:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:41 lr 0.000028	 wd 0.0000	time 0.2300 (0.2710)	loss 1.3994 (1.3948)	grad_norm 0.4159 (0.4197)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:52:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:07:03 lr 0.000028	 wd 0.0000	time 0.1914 (0.2642)	loss 1.4651 (1.3908)	grad_norm 0.4126 (0.4176)	loss_scale 8192.0000 (4205.1054)	mem 7585MB
[2024-07-13 14:52:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:06:28 lr 0.000028	 wd 0.0000	time 0.1869 (0.2588)	loss 1.3470 (1.3891)	grad_norm 0.4012 (0.4169)	loss_scale 8192.0000 (4603.3966)	mem 7585MB
[2024-07-13 14:53:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:57 lr 0.000028	 wd 0.0000	time 0.2395 (0.2547)	loss 1.5242 (1.3867)	grad_norm 0.3868 (0.4157)	loss_scale 8192.0000 (4929.3370)	mem 7585MB
[2024-07-13 14:53:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:31 lr 0.000028	 wd 0.0000	time 0.2228 (0.2543)	loss 1.4388 (1.3870)	grad_norm 0.3819 (0.4150)	loss_scale 8192.0000 (5200.9992)	mem 7585MB
[2024-07-13 14:53:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:05:01 lr 0.000027	 wd 0.0000	time 0.2031 (0.2512)	loss 1.2194 (1.3872)	grad_norm 0.3829 (0.4150)	loss_scale 8192.0000 (5430.8993)	mem 7585MB
[2024-07-13 14:54:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:33 lr 0.000027	 wd 0.0000	time 0.2285 (0.2483)	loss 1.7081 (1.3861)	grad_norm 0.4103 (0.4149)	loss_scale 8192.0000 (5627.9800)	mem 7585MB
[2024-07-13 14:54:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:04:05 lr 0.000027	 wd 0.0000	time 0.2130 (0.2455)	loss 1.4040 (1.3870)	grad_norm 0.3867 (0.4144)	loss_scale 8192.0000 (5798.8008)	mem 7585MB
[2024-07-13 14:54:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:40 lr 0.000027	 wd 0.0000	time 0.2222 (0.2441)	loss 1.3422 (1.3868)	grad_norm 0.4153 (nan)	loss_scale 4096.0000 (5825.4791)	mem 7585MB
[2024-07-13 14:55:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:15 lr 0.000027	 wd 0.0000	time 0.2293 (0.2438)	loss 1.2307 (1.3861)	grad_norm 0.4742 (nan)	loss_scale 4096.0000 (5723.8048)	mem 7585MB
[2024-07-13 14:55:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:49 lr 0.000027	 wd 0.0000	time 0.2013 (0.2419)	loss 1.3363 (1.3858)	grad_norm 0.4452 (nan)	loss_scale 4096.0000 (5633.4214)	mem 7585MB
[2024-07-13 14:56:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:24 lr 0.000027	 wd 0.0000	time 0.1946 (0.2403)	loss 1.5910 (1.3860)	grad_norm 0.4050 (nan)	loss_scale 4096.0000 (5552.5471)	mem 7585MB
[2024-07-13 14:56:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:02:00 lr 0.000027	 wd 0.0000	time 0.1986 (0.2391)	loss 1.0978 (1.3879)	grad_norm 0.4787 (nan)	loss_scale 4096.0000 (5479.7561)	mem 7585MB
[2024-07-13 14:56:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:36 lr 0.000027	 wd 0.0000	time 0.1949 (0.2389)	loss 1.6053 (1.3876)	grad_norm 0.5555 (nan)	loss_scale 4096.0000 (5413.8943)	mem 7585MB
[2024-07-13 14:57:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:11 lr 0.000027	 wd 0.0000	time 0.2169 (0.2379)	loss 1.2176 (1.3877)	grad_norm 0.4049 (nan)	loss_scale 4096.0000 (5354.0173)	mem 7585MB
[2024-07-13 14:57:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:47 lr 0.000027	 wd 0.0000	time 0.2134 (0.2367)	loss 1.4245 (1.3886)	grad_norm 0.4179 (nan)	loss_scale 4096.0000 (5299.3446)	mem 7585MB
[2024-07-13 14:57:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:24 lr 0.000026	 wd 0.0000	time 0.2045 (0.2356)	loss 1.1399 (1.3896)	grad_norm 0.4725 (nan)	loss_scale 4096.0000 (5249.2262)	mem 7585MB
[2024-07-13 14:58:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1642 (0.2337)	loss 1.2751 (1.3887)	grad_norm 0.4323 (nan)	loss_scale 4096.0000 (5203.1156)	mem 7585MB
[2024-07-13 14:58:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 14 training takes 0:09:48
[2024-07-13 14:58:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 32.369 (32.369)	Loss 0.4231 (0.4231)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 14:59:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.614 Acc@5 97.114
[2024-07-13 14:59:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.6%
[2024-07-13 14:59:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.61%
[2024-07-13 14:59:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 14:59:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 14:59:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][0/2502]	eta 10:56:46 lr 0.000026	 wd 0.0000	time 15.7500 (15.7500)	loss 1.5001 (1.5001)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 14:59:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:15:07 lr 0.000026	 wd 0.0000	time 0.2285 (0.3779)	loss 1.0371 (1.3754)	grad_norm 0.3769 (0.4019)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:00:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:13:05 lr 0.000026	 wd 0.0000	time 0.1991 (0.3411)	loss 1.4919 (1.3901)	grad_norm 0.4568 (0.4056)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:00:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:10:52 lr 0.000026	 wd 0.0000	time 0.1912 (0.2965)	loss 1.4089 (1.3773)	grad_norm 0.3607 (0.4053)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:00:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:09:36 lr 0.000026	 wd 0.0000	time 0.2188 (0.2742)	loss 1.4377 (1.3809)	grad_norm 0.3972 (0.4039)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:01:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:08:45 lr 0.000026	 wd 0.0000	time 0.2441 (0.2625)	loss 0.8840 (1.3787)	grad_norm 0.3801 (0.4137)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:01:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:08:43 lr 0.000026	 wd 0.0000	time 0.2244 (0.2750)	loss 0.8558 (1.3826)	grad_norm 0.4209 (0.4135)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:02:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:58 lr 0.000026	 wd 0.0000	time 0.1902 (0.2657)	loss 1.1085 (1.3853)	grad_norm 0.5450 (0.4144)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:02:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:07:19 lr 0.000026	 wd 0.0000	time 0.1963 (0.2583)	loss 1.4519 (1.3857)	grad_norm 0.3722 (0.4144)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:02:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:45 lr 0.000025	 wd 0.0000	time 0.2192 (0.2534)	loss 1.2398 (1.3864)	grad_norm 0.3865 (0.4156)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:03:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:06:35 lr 0.000025	 wd 0.0000	time 0.2154 (0.2635)	loss 1.4698 (1.3877)	grad_norm 0.3759 (0.4149)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:03:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:06:02 lr 0.000025	 wd 0.0000	time 0.2221 (0.2583)	loss 1.2862 (1.3848)	grad_norm 0.4061 (0.4140)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:04:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:30 lr 0.000025	 wd 0.0000	time 0.2100 (0.2539)	loss 1.4363 (1.3855)	grad_norm 0.3751 (0.4153)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:04:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:05:01 lr 0.000025	 wd 0.0000	time 0.2534 (0.2511)	loss 1.4164 (1.3837)	grad_norm 0.3918 (0.4145)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:04:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:37 lr 0.000025	 wd 0.0000	time 0.2238 (0.2516)	loss 1.4746 (1.3839)	grad_norm 0.4563 (0.4147)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:05:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:04:09 lr 0.000025	 wd 0.0000	time 0.1819 (0.2492)	loss 1.5966 (1.3837)	grad_norm 0.4145 (0.4145)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:05:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:42 lr 0.000025	 wd 0.0000	time 0.2080 (0.2468)	loss 1.3030 (1.3859)	grad_norm 0.3971 (0.4138)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:05:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:16 lr 0.000025	 wd 0.0000	time 0.2373 (0.2446)	loss 1.4652 (1.3851)	grad_norm 0.5330 (0.4141)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:06:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:51 lr 0.000025	 wd 0.0000	time 0.2352 (0.2440)	loss 1.1124 (1.3847)	grad_norm 0.3916 (0.4139)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:06:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:27 lr 0.000024	 wd 0.0000	time 0.2268 (0.2443)	loss 1.6489 (1.3852)	grad_norm 0.3998 (0.4160)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:07:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:02:01 lr 0.000024	 wd 0.0000	time 0.1893 (0.2428)	loss 1.8966 (1.3873)	grad_norm 0.4148 (0.4160)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:07:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:36 lr 0.000024	 wd 0.0000	time 0.1876 (0.2412)	loss 1.5767 (1.3881)	grad_norm 0.4066 (0.4158)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:07:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:12 lr 0.000024	 wd 0.0000	time 0.2021 (0.2403)	loss 1.1093 (1.3893)	grad_norm 0.3649 (0.4157)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:08:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:48 lr 0.000024	 wd 0.0000	time 0.2442 (0.2408)	loss 1.6192 (1.3894)	grad_norm 0.3909 (0.4156)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:08:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:24 lr 0.000024	 wd 0.0000	time 0.1838 (0.2395)	loss 1.0920 (1.3882)	grad_norm 0.4073 (0.4151)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:08:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1627 (0.2371)	loss 1.2577 (1.3883)	grad_norm 0.3813 (0.4151)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:09:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 15 training takes 0:09:57
[2024-07-13 15:09:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_15.pth saving......
[2024-07-13 15:09:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_15.pth saved !!!
[2024-07-13 15:09:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 35.032 (35.032)	Loss 0.4224 (0.4224)	Acc@1 91.797 (91.797)	Acc@5 98.438 (98.438)	Mem 7585MB
[2024-07-13 15:09:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.676 Acc@5 97.102
[2024-07-13 15:09:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 15:09:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.68%
[2024-07-13 15:09:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 15:09:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 15:10:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][0/2502]	eta 12:17:01 lr 0.000024	 wd 0.0000	time 17.6743 (17.6743)	loss 1.3011 (1.3011)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:10:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:15:16 lr 0.000024	 wd 0.0000	time 0.2036 (0.3814)	loss 1.5020 (1.3819)	grad_norm 0.4085 (0.4398)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:10:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:11:24 lr 0.000024	 wd 0.0000	time 0.2500 (0.2972)	loss 1.3413 (1.3909)	grad_norm 0.4151 (0.4289)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:11:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:11:24 lr 0.000024	 wd 0.0000	time 0.1802 (0.3110)	loss 1.3986 (1.4033)	grad_norm 0.4105 (0.4217)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:11:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:09:59 lr 0.000024	 wd 0.0000	time 0.2073 (0.2852)	loss 1.2830 (1.3969)	grad_norm 0.3771 (0.4171)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:12:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:09:00 lr 0.000023	 wd 0.0000	time 0.2315 (0.2700)	loss 1.2916 (1.4074)	grad_norm 0.3940 (0.4150)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:12:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:17 lr 0.000023	 wd 0.0000	time 0.2426 (0.2616)	loss 1.0637 (1.3997)	grad_norm 0.4723 (0.4143)	loss_scale 8192.0000 (4450.3960)	mem 7585MB
[2024-07-13 15:13:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:08:02 lr 0.000023	 wd 0.0000	time 0.1820 (0.2679)	loss 1.3639 (1.4013)	grad_norm 0.3911 (0.4137)	loss_scale 8192.0000 (4984.1484)	mem 7585MB
[2024-07-13 15:13:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:07:23 lr 0.000023	 wd 0.0000	time 0.1876 (0.2606)	loss 1.4063 (1.3956)	grad_norm 0.3707 (0.4126)	loss_scale 8192.0000 (5384.6292)	mem 7585MB
[2024-07-13 15:13:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:48 lr 0.000023	 wd 0.0000	time 0.2120 (0.2549)	loss 1.5978 (1.3934)	grad_norm 0.4256 (inf)	loss_scale 4096.0000 (5387.0810)	mem 7585MB
[2024-07-13 15:14:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:06:15 lr 0.000023	 wd 0.0000	time 0.2137 (0.2503)	loss 1.5862 (1.3935)	grad_norm 0.4092 (inf)	loss_scale 4096.0000 (5258.1019)	mem 7585MB
[2024-07-13 15:14:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:51 lr 0.000023	 wd 0.0000	time 0.2205 (0.2510)	loss 1.3706 (1.3945)	grad_norm 0.3937 (inf)	loss_scale 4096.0000 (5152.5522)	mem 7585MB
[2024-07-13 15:14:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:22 lr 0.000023	 wd 0.0000	time 0.2008 (0.2481)	loss 1.4934 (1.3958)	grad_norm 0.4185 (inf)	loss_scale 4096.0000 (5064.5795)	mem 7585MB
[2024-07-13 15:15:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:04:54 lr 0.000023	 wd 0.0000	time 0.2476 (0.2452)	loss 1.1134 (1.3963)	grad_norm 0.3768 (inf)	loss_scale 4096.0000 (4990.1307)	mem 7585MB
[2024-07-13 15:15:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:27 lr 0.000023	 wd 0.0000	time 0.2002 (0.2425)	loss 1.2162 (1.3936)	grad_norm 0.5812 (inf)	loss_scale 4096.0000 (4926.3098)	mem 7585MB
[2024-07-13 15:15:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:04:01 lr 0.000022	 wd 0.0000	time 0.2197 (0.2413)	loss 1.4087 (1.3906)	grad_norm 0.3908 (inf)	loss_scale 4096.0000 (4870.9927)	mem 7585MB
[2024-07-13 15:16:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:37 lr 0.000022	 wd 0.0000	time 0.2278 (0.2416)	loss 1.4204 (1.3909)	grad_norm 0.4400 (inf)	loss_scale 4096.0000 (4822.5859)	mem 7585MB
[2024-07-13 15:16:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:12 lr 0.000022	 wd 0.0000	time 0.2000 (0.2401)	loss 1.1192 (1.3888)	grad_norm 0.4101 (inf)	loss_scale 4096.0000 (4779.8707)	mem 7585MB
[2024-07-13 15:17:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:47 lr 0.000022	 wd 0.0000	time 0.2071 (0.2386)	loss 1.2678 (1.3872)	grad_norm 0.4962 (inf)	loss_scale 4096.0000 (4741.8989)	mem 7585MB
[2024-07-13 15:17:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:22 lr 0.000022	 wd 0.0000	time 0.2322 (0.2373)	loss 1.2172 (1.3861)	grad_norm 0.3679 (inf)	loss_scale 4096.0000 (4707.9221)	mem 7585MB
[2024-07-13 15:17:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:01:59 lr 0.000022	 wd 0.0000	time 0.1908 (0.2375)	loss 1.5164 (1.3864)	grad_norm 0.4200 (inf)	loss_scale 4096.0000 (4677.3413)	mem 7585MB
[2024-07-13 15:18:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:35 lr 0.000022	 wd 0.0000	time 0.2024 (0.2364)	loss 1.3657 (1.3859)	grad_norm 0.3976 (inf)	loss_scale 4096.0000 (4649.6716)	mem 7585MB
[2024-07-13 15:18:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:11 lr 0.000022	 wd 0.0000	time 0.2344 (0.2351)	loss 1.4912 (1.3866)	grad_norm 0.6067 (inf)	loss_scale 4096.0000 (4624.5161)	mem 7585MB
[2024-07-13 15:18:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:47 lr 0.000022	 wd 0.0000	time 0.2886 (0.2340)	loss 1.2378 (1.3865)	grad_norm 0.4809 (inf)	loss_scale 4096.0000 (4601.5472)	mem 7585MB
[2024-07-13 15:19:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:23 lr 0.000022	 wd 0.0000	time 0.2168 (0.2335)	loss 1.5746 (1.3867)	grad_norm 0.4038 (inf)	loss_scale 4096.0000 (4580.4915)	mem 7585MB
[2024-07-13 15:19:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1631 (0.2322)	loss 1.4175 (1.3866)	grad_norm 0.4584 (inf)	loss_scale 4096.0000 (4561.1196)	mem 7585MB
[2024-07-13 15:19:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 16 training takes 0:09:46
[2024-07-13 15:19:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 17.932 (17.932)	Loss 0.4224 (0.4224)	Acc@1 91.797 (91.797)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 15:20:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.664 Acc@5 97.110
[2024-07-13 15:20:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 15:20:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.68%
[2024-07-13 15:20:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][0/2502]	eta 10:48:21 lr 0.000021	 wd 0.0000	time 15.5481 (15.5481)	loss 1.4846 (1.4846)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:21:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:21:31 lr 0.000021	 wd 0.0000	time 0.2397 (0.5376)	loss 1.5890 (1.3601)	grad_norm 0.4039 (0.4526)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:21:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:14:23 lr 0.000021	 wd 0.0000	time 0.1998 (0.3750)	loss 1.6091 (1.3756)	grad_norm 0.4293 (0.4320)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:21:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:11:41 lr 0.000021	 wd 0.0000	time 0.1852 (0.3186)	loss 1.3536 (1.3721)	grad_norm 0.4750 (0.4271)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:22:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:10:10 lr 0.000021	 wd 0.0000	time 0.2191 (0.2905)	loss 1.1608 (1.3663)	grad_norm 0.3735 (0.4227)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:22:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:09:32 lr 0.000021	 wd 0.0000	time 0.1739 (0.2861)	loss 1.3839 (1.3660)	grad_norm 0.3935 (0.4186)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:23:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:09:09 lr 0.000021	 wd 0.0000	time 0.1948 (0.2891)	loss 1.1915 (1.3731)	grad_norm 0.3999 (0.4164)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:23:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:08:20 lr 0.000021	 wd 0.0000	time 0.1864 (0.2776)	loss 1.3601 (1.3790)	grad_norm 0.3800 (0.4207)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:23:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:07:37 lr 0.000021	 wd 0.0000	time 0.2404 (0.2690)	loss 1.4286 (1.3832)	grad_norm 0.4011 (0.4199)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:24:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:07:04 lr 0.000021	 wd 0.0000	time 0.1943 (0.2652)	loss 1.6274 (1.3847)	grad_norm 0.3846 (0.4199)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:24:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:30 lr 0.000020	 wd 0.0000	time 0.2517 (0.2601)	loss 1.5723 (1.3831)	grad_norm 1.7158 (0.4211)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:24:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:58 lr 0.000020	 wd 0.0000	time 0.2015 (0.2557)	loss 1.1520 (1.3834)	grad_norm 0.3686 (0.4200)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:25:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:27 lr 0.000020	 wd 0.0000	time 0.2146 (0.2517)	loss 1.6470 (1.3851)	grad_norm 0.3949 (0.4197)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:25:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:05:00 lr 0.000020	 wd 0.0000	time 0.2750 (0.2496)	loss 1.2021 (1.3852)	grad_norm 0.4772 (0.4192)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:26:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:34 lr 0.000020	 wd 0.0000	time 0.2020 (0.2490)	loss 1.4991 (1.3860)	grad_norm 0.4226 (0.4192)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:26:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:04:07 lr 0.000020	 wd 0.0000	time 0.1934 (0.2466)	loss 1.4115 (1.3866)	grad_norm 0.3992 (nan)	loss_scale 2048.0000 (4000.4903)	mem 7585MB
[2024-07-13 15:26:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:40 lr 0.000020	 wd 0.0000	time 0.2090 (0.2445)	loss 1.5805 (1.3880)	grad_norm 0.4109 (nan)	loss_scale 2048.0000 (3878.5359)	mem 7585MB
[2024-07-13 15:27:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:14 lr 0.000020	 wd 0.0000	time 0.2080 (0.2427)	loss 1.5937 (1.3900)	grad_norm 0.4276 (nan)	loss_scale 2048.0000 (3770.9206)	mem 7585MB
[2024-07-13 15:27:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:50 lr 0.000020	 wd 0.0000	time 0.2377 (0.2430)	loss 1.3369 (1.3907)	grad_norm 0.4232 (nan)	loss_scale 2048.0000 (3675.2560)	mem 7585MB
[2024-07-13 15:27:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:25 lr 0.000020	 wd 0.0000	time 0.2398 (0.2418)	loss 1.1793 (1.3914)	grad_norm 0.4014 (nan)	loss_scale 2048.0000 (3589.6560)	mem 7585MB
[2024-07-13 15:28:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:02:00 lr 0.000019	 wd 0.0000	time 0.2083 (0.2404)	loss 1.5927 (1.3893)	grad_norm 0.4000 (nan)	loss_scale 2048.0000 (3512.6117)	mem 7585MB
[2024-07-13 15:28:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:36 lr 0.000019	 wd 0.0000	time 0.2080 (0.2390)	loss 1.4673 (1.3891)	grad_norm 0.3731 (nan)	loss_scale 2048.0000 (3442.9015)	mem 7585MB
[2024-07-13 15:28:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:11 lr 0.000019	 wd 0.0000	time 0.2255 (0.2382)	loss 1.3584 (1.3902)	grad_norm 0.3902 (nan)	loss_scale 2048.0000 (3379.5257)	mem 7585MB
[2024-07-13 15:29:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:48 lr 0.000019	 wd 0.0000	time 0.1913 (0.2381)	loss 1.4971 (1.3896)	grad_norm 0.4084 (nan)	loss_scale 2048.0000 (3321.6584)	mem 7585MB
[2024-07-13 15:29:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:24 lr 0.000019	 wd 0.0000	time 0.2259 (0.2370)	loss 1.4863 (1.3882)	grad_norm 0.3903 (nan)	loss_scale 2048.0000 (3268.6114)	mem 7585MB
[2024-07-13 15:30:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000019	 wd 0.0000	time 0.1534 (0.2347)	loss 1.5527 (1.3887)	grad_norm 0.4216 (nan)	loss_scale 2048.0000 (3219.8065)	mem 7585MB
[2024-07-13 15:30:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 17 training takes 0:09:51
[2024-07-13 15:30:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 41.033 (41.033)	Loss 0.4216 (0.4216)	Acc@1 91.992 (91.992)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 15:31:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.656 Acc@5 97.098
[2024-07-13 15:31:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 15:31:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.68%
[2024-07-13 15:31:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][0/2502]	eta 11:43:31 lr 0.000019	 wd 0.0000	time 16.8711 (16.8711)	loss 1.6118 (1.6118)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:31:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:14:55 lr 0.000019	 wd 0.0000	time 0.1847 (0.3727)	loss 1.5918 (1.4291)	grad_norm 0.4249 (0.4244)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:31:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:11:21 lr 0.000019	 wd 0.0000	time 0.2398 (0.2959)	loss 1.5109 (1.4093)	grad_norm 0.3895 (0.4223)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:32:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:11:14 lr 0.000019	 wd 0.0000	time 0.2189 (0.3064)	loss 1.7328 (1.4079)	grad_norm 0.3757 (0.4154)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:32:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:09:51 lr 0.000019	 wd 0.0000	time 0.2182 (0.2813)	loss 1.4679 (1.4010)	grad_norm 0.4000 (0.4162)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:33:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:08:53 lr 0.000018	 wd 0.0000	time 0.2207 (0.2665)	loss 1.3206 (1.3905)	grad_norm 0.4010 (0.4156)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:33:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:08:10 lr 0.000018	 wd 0.0000	time 0.2323 (0.2577)	loss 1.6702 (1.3913)	grad_norm 0.3788 (0.4158)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:34:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:07:55 lr 0.000018	 wd 0.0000	time 0.2336 (0.2638)	loss 1.4704 (1.3919)	grad_norm 0.3990 (0.4225)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:34:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:16 lr 0.000018	 wd 0.0000	time 0.1891 (0.2567)	loss 1.1263 (1.3894)	grad_norm 0.4147 (0.4210)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:34:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:06:42 lr 0.000018	 wd 0.0000	time 0.2147 (0.2511)	loss 1.1961 (1.3853)	grad_norm 0.4607 (0.4199)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:35:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:11 lr 0.000018	 wd 0.0000	time 0.2450 (0.2474)	loss 1.0576 (1.3888)	grad_norm 0.3939 (0.4196)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:35:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:48 lr 0.000018	 wd 0.0000	time 0.2083 (0.2485)	loss 1.3132 (1.3882)	grad_norm 0.3999 (0.4185)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:35:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:19 lr 0.000018	 wd 0.0000	time 0.1951 (0.2455)	loss 1.6882 (1.3886)	grad_norm 0.7911 (0.4210)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:36:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:04:51 lr 0.000018	 wd 0.0000	time 0.2253 (0.2429)	loss 1.4487 (1.3892)	grad_norm 0.3975 (0.4238)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:36:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:24 lr 0.000018	 wd 0.0000	time 0.2352 (0.2403)	loss 1.2459 (1.3890)	grad_norm 0.4448 (0.4226)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:36:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:03:59 lr 0.000017	 wd 0.0000	time 0.2091 (0.2392)	loss 1.6233 (1.3879)	grad_norm 0.4607 (0.4223)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:37:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:35 lr 0.000017	 wd 0.0000	time 0.2839 (0.2393)	loss 1.5068 (1.3873)	grad_norm 0.4096 (0.4215)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:37:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:10 lr 0.000017	 wd 0.0000	time 0.2051 (0.2377)	loss 1.5078 (1.3875)	grad_norm 0.4376 (0.4208)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:38:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:45 lr 0.000017	 wd 0.0000	time 0.1961 (0.2362)	loss 1.3662 (1.3883)	grad_norm 0.3948 (0.4206)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:38:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:21 lr 0.000017	 wd 0.0000	time 0.2449 (0.2354)	loss 1.5208 (1.3875)	grad_norm 0.4133 (0.4207)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:38:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:01:58 lr 0.000017	 wd 0.0000	time 0.2066 (0.2360)	loss 1.4165 (1.3897)	grad_norm 0.3759 (0.4204)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:39:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:34 lr 0.000017	 wd 0.0000	time 0.2072 (0.2355)	loss 1.4640 (1.3891)	grad_norm 0.3982 (0.4218)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:39:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:10 lr 0.000017	 wd 0.0000	time 0.2103 (0.2343)	loss 1.3793 (1.3891)	grad_norm 0.3804 (0.4217)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:39:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:47 lr 0.000017	 wd 0.0000	time 0.2350 (0.2332)	loss 1.5181 (1.3894)	grad_norm 0.3779 (0.4212)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:40:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:23 lr 0.000017	 wd 0.0000	time 0.2313 (0.2328)	loss 1.5723 (1.3908)	grad_norm 0.3927 (0.4207)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:40:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1530 (0.2315)	loss 1.5352 (1.3903)	grad_norm 0.4053 (0.4207)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:40:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 18 training takes 0:09:46
[2024-07-13 15:41:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 19.023 (19.023)	Loss 0.4226 (0.4226)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 15:41:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.668 Acc@5 97.098
[2024-07-13 15:41:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 15:41:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.68%
[2024-07-13 15:41:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][0/2502]	eta 12:31:59 lr 0.000016	 wd 0.0000	time 18.0333 (18.0333)	loss 1.4852 (1.4852)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:42:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:17:54 lr 0.000016	 wd 0.0000	time 0.1831 (0.4473)	loss 1.1106 (1.4010)	grad_norm 0.4127 (0.4265)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:42:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:12:35 lr 0.000016	 wd 0.0000	time 0.1813 (0.3280)	loss 1.4681 (1.3948)	grad_norm 0.4451 (0.4237)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:42:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:10:32 lr 0.000016	 wd 0.0000	time 0.2082 (0.2875)	loss 1.3153 (1.4084)	grad_norm 0.4075 (0.4212)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:43:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:09:20 lr 0.000016	 wd 0.0000	time 0.2028 (0.2666)	loss 1.5724 (1.4072)	grad_norm 0.5160 (0.4191)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 15:43:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:08:39 lr 0.000016	 wd 0.0000	time 0.2091 (0.2593)	loss 1.5702 (1.4025)	grad_norm 0.4041 (0.4202)	loss_scale 4096.0000 (2350.4990)	mem 7585MB
[2024-07-13 15:43:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:10 lr 0.000016	 wd 0.0000	time 0.2057 (0.2579)	loss 1.5154 (1.3974)	grad_norm 0.4060 (0.4216)	loss_scale 4096.0000 (2640.9318)	mem 7585MB
[2024-07-13 15:44:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:07:32 lr 0.000016	 wd 0.0000	time 0.1906 (0.2511)	loss 1.7040 (1.3995)	grad_norm 0.4166 (0.4212)	loss_scale 4096.0000 (2848.5021)	mem 7585MB
[2024-07-13 15:44:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:06:58 lr 0.000016	 wd 0.0000	time 0.1960 (0.2461)	loss 1.3810 (1.3983)	grad_norm 0.3923 (0.4210)	loss_scale 4096.0000 (3004.2447)	mem 7585MB
[2024-07-13 15:44:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:06:30 lr 0.000016	 wd 0.0000	time 0.2269 (0.2435)	loss 1.2734 (1.3980)	grad_norm 0.4264 (0.4208)	loss_scale 4096.0000 (3125.4162)	mem 7585MB
[2024-07-13 15:45:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:16 lr 0.000016	 wd 0.0000	time 0.2133 (0.2505)	loss 1.6115 (1.3989)	grad_norm 0.4397 (0.4186)	loss_scale 4096.0000 (3222.3776)	mem 7585MB
[2024-07-13 15:45:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:45 lr 0.000015	 wd 0.0000	time 0.2134 (0.2465)	loss 0.9400 (1.3974)	grad_norm 0.3898 (0.4188)	loss_scale 4096.0000 (3301.7257)	mem 7585MB
[2024-07-13 15:46:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:16 lr 0.000015	 wd 0.0000	time 0.2111 (0.2433)	loss 1.1440 (1.3955)	grad_norm 0.4158 (0.4179)	loss_scale 4096.0000 (3367.8601)	mem 7585MB
[2024-07-13 15:46:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:04:49 lr 0.000015	 wd 0.0000	time 0.2032 (0.2411)	loss 1.6246 (1.3961)	grad_norm 0.4198 (0.4180)	loss_scale 4096.0000 (3423.8278)	mem 7585MB
[2024-07-13 15:46:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:25 lr 0.000015	 wd 0.0000	time 0.1921 (0.2408)	loss 1.4991 (1.3971)	grad_norm 0.4077 (0.4172)	loss_scale 4096.0000 (3471.8059)	mem 7585MB
[2024-07-13 15:47:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:03:59 lr 0.000015	 wd 0.0000	time 0.2016 (0.2389)	loss 1.2424 (1.3969)	grad_norm 0.4482 (0.4170)	loss_scale 4096.0000 (3513.3911)	mem 7585MB
[2024-07-13 15:47:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:33 lr 0.000015	 wd 0.0000	time 0.2189 (0.2370)	loss 1.3540 (1.3971)	grad_norm 0.4021 (0.4160)	loss_scale 4096.0000 (3549.7814)	mem 7585MB
[2024-07-13 15:47:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:08 lr 0.000015	 wd 0.0000	time 0.2076 (0.2353)	loss 1.4218 (1.3979)	grad_norm 0.4519 (0.4161)	loss_scale 4096.0000 (3581.8930)	mem 7585MB
[2024-07-13 15:48:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:44 lr 0.000015	 wd 0.0000	time 0.1938 (0.2348)	loss 1.3543 (1.3974)	grad_norm 0.3875 (0.4155)	loss_scale 4096.0000 (3610.4386)	mem 7585MB
[2024-07-13 15:48:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:22 lr 0.000015	 wd 0.0000	time 0.2182 (0.2359)	loss 1.4407 (1.3978)	grad_norm 0.3664 (0.4153)	loss_scale 4096.0000 (3635.9811)	mem 7585MB
[2024-07-13 15:49:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:57 lr 0.000015	 wd 0.0000	time 0.2123 (0.2346)	loss 1.0915 (1.3973)	grad_norm 0.4555 (0.4167)	loss_scale 4096.0000 (3658.9705)	mem 7585MB
[2024-07-13 15:49:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:33 lr 0.000014	 wd 0.0000	time 0.1987 (0.2334)	loss 1.2245 (1.3962)	grad_norm 0.3806 (0.4173)	loss_scale 4096.0000 (3679.7715)	mem 7585MB
[2024-07-13 15:49:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:10 lr 0.000014	 wd 0.0000	time 0.2138 (0.2328)	loss 1.5017 (1.3940)	grad_norm 0.4093 (0.4169)	loss_scale 4096.0000 (3698.6824)	mem 7585MB
[2024-07-13 15:50:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:47 lr 0.000014	 wd 0.0000	time 0.1858 (0.2330)	loss 1.4396 (1.3935)	grad_norm 0.4065 (0.4170)	loss_scale 4096.0000 (3715.9496)	mem 7585MB
[2024-07-13 15:50:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:23 lr 0.000014	 wd 0.0000	time 0.2187 (0.2321)	loss 1.6007 (1.3949)	grad_norm 0.3805 (0.4174)	loss_scale 4096.0000 (3731.7784)	mem 7585MB
[2024-07-13 15:50:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1529 (0.2300)	loss 1.2606 (1.3948)	grad_norm 0.4953 (0.4175)	loss_scale 4096.0000 (3746.3415)	mem 7585MB
[2024-07-13 15:50:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 19 training takes 0:09:40
[2024-07-13 15:51:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 24.014 (24.014)	Loss 0.4219 (0.4219)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 15:51:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.650 Acc@5 97.104
[2024-07-13 15:51:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 15:51:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.68%
[2024-07-13 15:52:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][0/2502]	eta 12:28:47 lr 0.000014	 wd 0.0000	time 17.9568 (17.9568)	loss 1.0065 (1.0065)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:52:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:15:46 lr 0.000014	 wd 0.0000	time 0.2271 (0.3942)	loss 1.6135 (1.3908)	grad_norm 0.3909 (0.4086)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:52:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:11:29 lr 0.000014	 wd 0.0000	time 0.2078 (0.2994)	loss 1.4565 (1.3919)	grad_norm 0.4004 (0.4180)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:53:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:11:14 lr 0.000014	 wd 0.0000	time 0.2166 (0.3065)	loss 1.4985 (1.3886)	grad_norm 0.3973 (0.4263)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:53:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:09:55 lr 0.000014	 wd 0.0000	time 0.1885 (0.2833)	loss 1.4355 (1.3982)	grad_norm 0.3804 (0.4201)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 15:54:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:08:55 lr 0.000014	 wd 0.0000	time 0.2158 (0.2673)	loss 1.5684 (1.4002)	grad_norm 0.4041 (inf)	loss_scale 2048.0000 (3785.3253)	mem 7585MB
[2024-07-13 15:54:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:08:09 lr 0.000014	 wd 0.0000	time 0.1935 (0.2573)	loss 1.3586 (1.3964)	grad_norm 0.4026 (inf)	loss_scale 2048.0000 (3496.2529)	mem 7585MB
[2024-07-13 15:54:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:38 lr 0.000013	 wd 0.0000	time 0.2263 (0.2543)	loss 1.5087 (1.3984)	grad_norm 0.3978 (inf)	loss_scale 2048.0000 (3289.6548)	mem 7585MB
[2024-07-13 15:55:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:07:08 lr 0.000013	 wd 0.0000	time 0.2029 (0.2516)	loss 1.2904 (1.3957)	grad_norm 0.3599 (inf)	loss_scale 2048.0000 (3134.6417)	mem 7585MB
[2024-07-13 15:55:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:35 lr 0.000013	 wd 0.0000	time 0.1845 (0.2471)	loss 1.6283 (1.3985)	grad_norm 0.3698 (inf)	loss_scale 2048.0000 (3014.0377)	mem 7585MB
[2024-07-13 15:55:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:05 lr 0.000013	 wd 0.0000	time 0.1981 (0.2433)	loss 1.3262 (1.3974)	grad_norm 0.4005 (inf)	loss_scale 2048.0000 (2917.5305)	mem 7585MB
[2024-07-13 15:56:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:38 lr 0.000013	 wd 0.0000	time 0.2092 (0.2412)	loss 1.3769 (1.3949)	grad_norm 0.3978 (inf)	loss_scale 2048.0000 (2838.5540)	mem 7585MB
[2024-07-13 15:56:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:14 lr 0.000013	 wd 0.0000	time 0.2045 (0.2415)	loss 1.4681 (1.3917)	grad_norm 0.3775 (inf)	loss_scale 2048.0000 (2772.7294)	mem 7585MB
[2024-07-13 15:57:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:04:47 lr 0.000013	 wd 0.0000	time 0.2504 (0.2393)	loss 1.3463 (1.3903)	grad_norm 0.3813 (inf)	loss_scale 2048.0000 (2717.0238)	mem 7585MB
[2024-07-13 15:57:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:21 lr 0.000013	 wd 0.0000	time 0.2072 (0.2372)	loss 1.4330 (1.3922)	grad_norm 0.4125 (inf)	loss_scale 2048.0000 (2669.2705)	mem 7585MB
[2024-07-13 15:57:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:03:55 lr 0.000013	 wd 0.0000	time 0.2068 (0.2352)	loss 1.4611 (1.3928)	grad_norm 0.4142 (inf)	loss_scale 2048.0000 (2627.8801)	mem 7585MB
[2024-07-13 15:58:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:32 lr 0.000013	 wd 0.0000	time 0.2158 (0.2351)	loss 1.7294 (1.3932)	grad_norm 0.4067 (inf)	loss_scale 2048.0000 (2591.6602)	mem 7585MB
[2024-07-13 15:58:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:08 lr 0.000012	 wd 0.0000	time 0.2334 (0.2355)	loss 1.5535 (1.3926)	grad_norm 0.4128 (inf)	loss_scale 2048.0000 (2559.6990)	mem 7585MB
[2024-07-13 15:58:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:44 lr 0.000012	 wd 0.0000	time 0.2187 (0.2341)	loss 1.3331 (1.3919)	grad_norm 0.4472 (inf)	loss_scale 2048.0000 (2531.2871)	mem 7585MB
[2024-07-13 15:59:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:20 lr 0.000012	 wd 0.0000	time 0.1900 (0.2329)	loss 1.5728 (1.3938)	grad_norm 0.3650 (inf)	loss_scale 2048.0000 (2505.8643)	mem 7585MB
[2024-07-13 15:59:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:01:56 lr 0.000012	 wd 0.0000	time 0.1953 (0.2323)	loss 1.5325 (1.3934)	grad_norm 0.4104 (inf)	loss_scale 2048.0000 (2482.9825)	mem 7585MB
[2024-07-13 15:59:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:33 lr 0.000012	 wd 0.0000	time 0.2071 (0.2328)	loss 1.3580 (1.3940)	grad_norm 0.4248 (inf)	loss_scale 2048.0000 (2462.2789)	mem 7585MB
[2024-07-13 16:00:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:09 lr 0.000012	 wd 0.0000	time 0.1959 (0.2316)	loss 1.2864 (1.3955)	grad_norm 0.3942 (inf)	loss_scale 2048.0000 (2443.4566)	mem 7585MB
[2024-07-13 16:00:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:46 lr 0.000012	 wd 0.0000	time 0.2094 (0.2307)	loss 1.4186 (1.3955)	grad_norm 0.4702 (inf)	loss_scale 2048.0000 (2426.2703)	mem 7585MB
[2024-07-13 16:01:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:23 lr 0.000012	 wd 0.0000	time 0.2308 (0.2299)	loss 1.3744 (1.3958)	grad_norm 0.3768 (inf)	loss_scale 2048.0000 (2410.5156)	mem 7585MB
[2024-07-13 16:01:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000012	 wd 0.0000	time 0.1593 (0.2281)	loss 1.6661 (1.3965)	grad_norm 0.4087 (inf)	loss_scale 2048.0000 (2396.0208)	mem 7585MB
[2024-07-13 16:01:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 20 training takes 0:09:44
[2024-07-13 16:02:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 29.115 (29.115)	Loss 0.4216 (0.4216)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 16:02:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.634 Acc@5 97.106
[2024-07-13 16:02:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.6%
[2024-07-13 16:02:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.68%
[2024-07-13 16:02:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][0/2502]	eta 12:48:36 lr 0.000012	 wd 0.0000	time 18.4318 (18.4318)	loss 1.5991 (1.5991)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:03:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:17:06 lr 0.000012	 wd 0.0000	time 0.2252 (0.4276)	loss 1.5038 (1.4177)	grad_norm 0.4072 (0.4128)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:03:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:12:13 lr 0.000012	 wd 0.0000	time 0.2124 (0.3187)	loss 0.9258 (1.3966)	grad_norm 0.4028 (0.4081)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:03:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:10:19 lr 0.000012	 wd 0.0000	time 0.1896 (0.2813)	loss 1.4125 (1.3894)	grad_norm 0.3978 (0.4307)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:04:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:09:10 lr 0.000011	 wd 0.0000	time 0.2126 (0.2620)	loss 1.4738 (1.3908)	grad_norm 0.4127 (0.4257)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:04:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:08:34 lr 0.000011	 wd 0.0000	time 0.2803 (0.2568)	loss 1.3791 (1.3898)	grad_norm 0.4419 (0.4268)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:04:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:07 lr 0.000011	 wd 0.0000	time 0.1949 (0.2564)	loss 1.2260 (1.3902)	grad_norm 0.4096 (0.4243)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:05:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:07:30 lr 0.000011	 wd 0.0000	time 0.2039 (0.2497)	loss 1.3221 (1.3845)	grad_norm 0.3718 (0.4210)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:05:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:06:56 lr 0.000011	 wd 0.0000	time 0.2067 (0.2447)	loss 1.2358 (1.3839)	grad_norm 0.3708 (0.4208)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:06:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:28 lr 0.000011	 wd 0.0000	time 0.2385 (0.2427)	loss 1.5747 (1.3848)	grad_norm 0.3774 (0.4195)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:06:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:11 lr 0.000011	 wd 0.0000	time 0.1891 (0.2470)	loss 1.0772 (1.3840)	grad_norm 0.3951 (0.4196)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:06:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:05:40 lr 0.000011	 wd 0.0000	time 0.1939 (0.2431)	loss 1.4899 (1.3841)	grad_norm 0.3911 (0.4189)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:07:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:12 lr 0.000011	 wd 0.0000	time 0.2091 (0.2402)	loss 1.3717 (1.3852)	grad_norm 0.3991 (0.4202)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:07:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:46 lr 0.000011	 wd 0.0000	time 0.2386 (0.2382)	loss 1.5739 (1.3853)	grad_norm 0.4020 (0.4193)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:07:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:23 lr 0.000011	 wd 0.0000	time 0.2038 (0.2387)	loss 1.4605 (1.3859)	grad_norm 0.4089 (0.4194)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:08:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:03:57 lr 0.000010	 wd 0.0000	time 0.1728 (0.2370)	loss 1.6597 (1.3855)	grad_norm 0.4123 (0.4185)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:08:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:32 lr 0.000010	 wd 0.0000	time 0.2050 (0.2355)	loss 1.2354 (1.3850)	grad_norm 0.4300 (0.4209)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:08:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:07 lr 0.000010	 wd 0.0000	time 0.1917 (0.2338)	loss 1.4835 (1.3851)	grad_norm 0.3973 (0.4205)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:09:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:43 lr 0.000010	 wd 0.0000	time 0.2232 (0.2334)	loss 1.0333 (1.3855)	grad_norm 0.3878 (0.4200)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:09:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:21 lr 0.000010	 wd 0.0000	time 0.2311 (0.2342)	loss 1.0135 (1.3841)	grad_norm 0.4050 (0.4192)	loss_scale 2048.0000 (2048.0000)	mem 7585MB
[2024-07-13 16:10:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:56 lr 0.000010	 wd 0.0000	time 0.2176 (0.2330)	loss 1.4574 (1.3837)	grad_norm 0.3952 (0.4187)	loss_scale 4096.0000 (2127.8321)	mem 7585MB
[2024-07-13 16:10:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:33 lr 0.000010	 wd 0.0000	time 0.2142 (0.2319)	loss 1.2129 (1.3840)	grad_norm 0.3980 (0.4185)	loss_scale 4096.0000 (2221.5098)	mem 7585MB
[2024-07-13 16:10:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:09 lr 0.000010	 wd 0.0000	time 0.1962 (0.2313)	loss 1.5950 (1.3820)	grad_norm 0.4103 (0.4183)	loss_scale 4096.0000 (2306.6751)	mem 7585MB
[2024-07-13 16:11:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:46 lr 0.000010	 wd 0.0000	time 0.2171 (0.2315)	loss 1.5885 (1.3816)	grad_norm 0.3920 (0.4182)	loss_scale 4096.0000 (2384.4381)	mem 7585MB
[2024-07-13 16:11:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:23 lr 0.000010	 wd 0.0000	time 0.1892 (0.2307)	loss 1.3970 (1.3830)	grad_norm 0.4185 (0.4179)	loss_scale 4096.0000 (2455.7234)	mem 7585MB
[2024-07-13 16:11:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1525 (0.2286)	loss 1.3647 (1.3827)	grad_norm 0.4206 (0.4177)	loss_scale 4096.0000 (2521.3083)	mem 7585MB
[2024-07-13 16:12:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 21 training takes 0:09:40
[2024-07-13 16:12:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 32.646 (32.646)	Loss 0.4224 (0.4224)	Acc@1 91.992 (91.992)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 16:13:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.658 Acc@5 97.100
[2024-07-13 16:13:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 16:13:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.68%
[2024-07-13 16:13:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][0/2502]	eta 12:06:47 lr 0.000010	 wd 0.0000	time 17.4291 (17.4291)	loss 1.3392 (1.3392)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:13:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:15:02 lr 0.000010	 wd 0.0000	time 0.2142 (0.3756)	loss 1.3171 (1.3954)	grad_norm 0.3764 (0.4128)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:13:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:11:19 lr 0.000009	 wd 0.0000	time 0.2697 (0.2954)	loss 1.2009 (1.3913)	grad_norm 0.3827 (0.4148)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:14:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:11:30 lr 0.000009	 wd 0.0000	time 0.2193 (0.3137)	loss 1.5494 (1.3953)	grad_norm 0.5969 (0.4175)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:14:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:10:02 lr 0.000009	 wd 0.0000	time 0.2247 (0.2868)	loss 1.4586 (1.3986)	grad_norm 0.4081 (0.4152)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:15:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:09:02 lr 0.000009	 wd 0.0000	time 0.2048 (0.2707)	loss 0.9253 (1.3977)	grad_norm 0.4223 (0.4143)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:15:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:16 lr 0.000009	 wd 0.0000	time 0.2083 (0.2613)	loss 1.3787 (1.4009)	grad_norm 0.4233 (0.4143)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:16:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:08:10 lr 0.000009	 wd 0.0000	time 0.2110 (0.2720)	loss 0.9188 (1.3962)	grad_norm 0.4037 (0.4138)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:16:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:07:28 lr 0.000009	 wd 0.0000	time 0.1890 (0.2638)	loss 1.4164 (1.3918)	grad_norm 0.3922 (0.4127)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:16:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:52 lr 0.000009	 wd 0.0000	time 0.1830 (0.2574)	loss 1.3899 (1.3907)	grad_norm 0.4139 (0.4129)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:17:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:20 lr 0.000009	 wd 0.0000	time 0.2056 (0.2533)	loss 1.5702 (1.3929)	grad_norm 0.4403 (0.4142)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:17:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:54 lr 0.000009	 wd 0.0000	time 0.2177 (0.2528)	loss 1.4214 (1.3904)	grad_norm 0.4095 (0.4128)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:18:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:25 lr 0.000009	 wd 0.0000	time 0.2036 (0.2497)	loss 1.3504 (1.3891)	grad_norm 0.3809 (0.4123)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:18:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:04:56 lr 0.000009	 wd 0.0000	time 0.1770 (0.2467)	loss 0.9510 (1.3897)	grad_norm 0.3946 (0.4115)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:18:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:28 lr 0.000008	 wd 0.0000	time 0.2289 (0.2438)	loss 1.5811 (1.3917)	grad_norm 0.4106 (0.4136)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:19:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:04:03 lr 0.000008	 wd 0.0000	time 0.2206 (0.2428)	loss 1.3404 (1.3924)	grad_norm 0.4104 (0.4156)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:19:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:38 lr 0.000008	 wd 0.0000	time 0.2065 (0.2424)	loss 1.5789 (1.3927)	grad_norm 0.3867 (0.4149)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:19:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:12 lr 0.000008	 wd 0.0000	time 0.2178 (0.2405)	loss 1.3302 (1.3923)	grad_norm 0.3897 (0.4158)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:20:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:47 lr 0.000008	 wd 0.0000	time 0.2072 (0.2387)	loss 1.6300 (1.3916)	grad_norm 0.4198 (0.4153)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:20:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:23 lr 0.000008	 wd 0.0000	time 0.2123 (0.2378)	loss 1.5781 (1.3911)	grad_norm 0.5343 (0.4161)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:20:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:59 lr 0.000008	 wd 0.0000	time 0.1875 (0.2381)	loss 1.5377 (1.3900)	grad_norm 0.4441 (0.4161)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:21:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:35 lr 0.000008	 wd 0.0000	time 0.2113 (0.2372)	loss 1.4617 (1.3906)	grad_norm 0.4048 (0.4160)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:21:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:11 lr 0.000008	 wd 0.0000	time 0.2052 (0.2360)	loss 1.4656 (1.3887)	grad_norm 0.4071 (0.4155)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:22:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:47 lr 0.000008	 wd 0.0000	time 0.2403 (0.2349)	loss 1.5166 (1.3889)	grad_norm 0.4128 (0.4153)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:22:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:23 lr 0.000008	 wd 0.0000	time 0.1983 (0.2351)	loss 1.2351 (1.3882)	grad_norm 0.4144 (0.4153)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:22:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1510 (0.2330)	loss 1.0065 (1.3873)	grad_norm 0.4285 (0.4151)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:22:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 22 training takes 0:09:53
[2024-07-13 16:23:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 23.886 (23.886)	Loss 0.4219 (0.4219)	Acc@1 91.992 (91.992)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 16:23:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.672 Acc@5 97.116
[2024-07-13 16:23:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 16:23:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.68%
[2024-07-13 16:24:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][0/2502]	eta 23:49:06 lr 0.000008	 wd 0.0000	time 34.2710 (34.2710)	loss 1.1935 (1.1935)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:24:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:22:11 lr 0.000008	 wd 0.0000	time 0.1985 (0.5545)	loss 1.6095 (1.4266)	grad_norm 0.3813 (0.4118)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:24:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:14:34 lr 0.000007	 wd 0.0000	time 0.1867 (0.3798)	loss 1.5877 (1.4040)	grad_norm 0.4144 (0.4175)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:25:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:11:49 lr 0.000007	 wd 0.0000	time 0.2316 (0.3223)	loss 1.5530 (1.3972)	grad_norm 0.4024 (0.4136)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:25:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:11:58 lr 0.000007	 wd 0.0000	time 0.2263 (0.3418)	loss 1.5534 (1.3888)	grad_norm 0.3801 (0.4112)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:26:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:10:31 lr 0.000007	 wd 0.0000	time 0.2227 (0.3156)	loss 1.6902 (1.3936)	grad_norm 0.4033 (0.4110)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:26:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:09:25 lr 0.000007	 wd 0.0000	time 0.1924 (0.2974)	loss 1.1636 (1.3938)	grad_norm 0.3804 (0.4110)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:26:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:08:34 lr 0.000007	 wd 0.0000	time 0.2137 (0.2855)	loss 1.4309 (1.3913)	grad_norm 0.3925 (0.4103)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:27:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:07:57 lr 0.000007	 wd 0.0000	time 0.1890 (0.2807)	loss 1.7233 (1.3900)	grad_norm 0.3846 (0.4106)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:27:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:07:17 lr 0.000007	 wd 0.0000	time 0.2141 (0.2732)	loss 1.7318 (1.3864)	grad_norm 0.4004 (0.4141)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:28:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:40 lr 0.000007	 wd 0.0000	time 0.2169 (0.2669)	loss 1.1703 (1.3844)	grad_norm 0.3802 (0.4134)	loss_scale 8192.0000 (4431.5365)	mem 7585MB
[2024-07-13 16:28:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:06:06 lr 0.000007	 wd 0.0000	time 0.2282 (0.2617)	loss 0.8905 (1.3798)	grad_norm 0.5648 (0.4142)	loss_scale 8192.0000 (4773.0863)	mem 7585MB
[2024-07-13 16:28:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:37 lr 0.000007	 wd 0.0000	time 0.2052 (0.2589)	loss 1.5902 (1.3816)	grad_norm 0.4301 (0.4143)	loss_scale 8192.0000 (5057.7585)	mem 7585MB
[2024-07-13 16:29:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:05:09 lr 0.000007	 wd 0.0000	time 0.2051 (0.2574)	loss 1.4833 (1.3830)	grad_norm 0.4733 (0.4150)	loss_scale 8192.0000 (5298.6687)	mem 7585MB
[2024-07-13 16:29:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:39 lr 0.000007	 wd 0.0000	time 0.1979 (0.2540)	loss 1.6128 (1.3831)	grad_norm 0.3970 (0.4147)	loss_scale 8192.0000 (5505.1877)	mem 7585MB
[2024-07-13 16:29:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:04:11 lr 0.000006	 wd 0.0000	time 0.1938 (0.2508)	loss 1.3112 (1.3853)	grad_norm 0.6425 (0.4145)	loss_scale 8192.0000 (5684.1892)	mem 7585MB
[2024-07-13 16:30:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:44 lr 0.000006	 wd 0.0000	time 0.2026 (0.2487)	loss 1.1898 (1.3844)	grad_norm 0.3798 (0.4150)	loss_scale 8192.0000 (5840.8295)	mem 7585MB
[2024-07-13 16:30:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:19 lr 0.000006	 wd 0.0000	time 0.1843 (0.2489)	loss 1.3593 (1.3847)	grad_norm 0.4019 (0.4163)	loss_scale 8192.0000 (5979.0523)	mem 7585MB
[2024-07-13 16:31:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:53 lr 0.000006	 wd 0.0000	time 0.1982 (0.2469)	loss 1.4984 (1.3841)	grad_norm 0.4006 (0.4163)	loss_scale 8192.0000 (6101.9256)	mem 7585MB
[2024-07-13 16:31:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:27 lr 0.000006	 wd 0.0000	time 0.2092 (0.2450)	loss 1.2513 (1.3867)	grad_norm 0.4127 (0.4165)	loss_scale 8192.0000 (6211.8716)	mem 7585MB
[2024-07-13 16:31:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:02:02 lr 0.000006	 wd 0.0000	time 0.2453 (0.2434)	loss 1.4858 (1.3856)	grad_norm 0.4250 (0.4164)	loss_scale 8192.0000 (6310.8286)	mem 7585MB
[2024-07-13 16:32:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:37 lr 0.000006	 wd 0.0000	time 0.1877 (0.2435)	loss 1.7067 (1.3861)	grad_norm 0.4347 (0.4160)	loss_scale 8192.0000 (6400.3655)	mem 7585MB
[2024-07-13 16:32:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:13 lr 0.000006	 wd 0.0000	time 0.1936 (0.2430)	loss 1.5022 (1.3839)	grad_norm 0.3847 (0.4173)	loss_scale 8192.0000 (6481.7665)	mem 7585MB
[2024-07-13 16:32:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:48 lr 0.000006	 wd 0.0000	time 0.2216 (0.2416)	loss 1.6253 (1.3839)	grad_norm 0.3827 (0.4172)	loss_scale 8192.0000 (6556.0921)	mem 7585MB
[2024-07-13 16:33:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:24 lr 0.000006	 wd 0.0000	time 0.1913 (0.2402)	loss 1.5811 (1.3844)	grad_norm 0.3700 (0.4174)	loss_scale 8192.0000 (6624.2266)	mem 7585MB
[2024-07-13 16:33:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000006	 wd 0.0000	time 0.1566 (0.2381)	loss 1.4639 (1.3851)	grad_norm 0.3893 (0.4173)	loss_scale 8192.0000 (6686.9124)	mem 7585MB
[2024-07-13 16:33:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 23 training takes 0:10:03
[2024-07-13 16:34:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 31.816 (31.816)	Loss 0.4219 (0.4219)	Acc@1 91.992 (91.992)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 16:34:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.680 Acc@5 97.112
[2024-07-13 16:34:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 16:34:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.68%
[2024-07-13 16:34:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 16:34:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 16:34:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][0/2502]	eta 10:38:47 lr 0.000006	 wd 0.0000	time 15.3187 (15.3187)	loss 1.6236 (1.6236)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:35:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:16:45 lr 0.000006	 wd 0.0000	time 0.3831 (0.4188)	loss 1.1775 (1.4250)	grad_norm 0.4114 (0.4369)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:35:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:12:59 lr 0.000006	 wd 0.0000	time 0.1955 (0.3387)	loss 1.4582 (1.4073)	grad_norm 0.3894 (0.4188)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:36:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:10:48 lr 0.000006	 wd 0.0000	time 0.2044 (0.2945)	loss 1.6535 (1.4003)	grad_norm 0.4068 (0.4155)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:36:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:09:31 lr 0.000005	 wd 0.0000	time 0.2084 (0.2721)	loss 1.4529 (1.3966)	grad_norm 0.3931 (0.4165)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:36:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:08:43 lr 0.000005	 wd 0.0000	time 0.2187 (0.2616)	loss 1.7083 (1.3980)	grad_norm 0.3973 (0.4149)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:37:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:08:29 lr 0.000005	 wd 0.0000	time 0.1811 (0.2680)	loss 1.4346 (1.3948)	grad_norm 0.3953 (0.4173)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:37:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:07:47 lr 0.000005	 wd 0.0000	time 0.2220 (0.2594)	loss 1.3610 (1.3954)	grad_norm 0.4207 (0.4177)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:37:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:07:10 lr 0.000005	 wd 0.0000	time 0.1930 (0.2530)	loss 1.4691 (1.3964)	grad_norm 0.5098 (0.4173)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:38:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:06:39 lr 0.000005	 wd 0.0000	time 0.2436 (0.2491)	loss 1.5927 (1.3932)	grad_norm 0.4193 (0.4180)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:38:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:18 lr 0.000005	 wd 0.0000	time 0.2165 (0.2520)	loss 1.2260 (1.3936)	grad_norm 0.4115 (0.4170)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:39:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:05:47 lr 0.000005	 wd 0.0000	time 0.2206 (0.2479)	loss 1.5361 (1.3925)	grad_norm 0.3987 (0.4180)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:39:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:18 lr 0.000005	 wd 0.0000	time 0.1917 (0.2448)	loss 1.2609 (1.3906)	grad_norm 0.3807 (0.4169)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:39:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:04:50 lr 0.000005	 wd 0.0000	time 0.2123 (0.2420)	loss 1.4087 (1.3899)	grad_norm 0.4020 (0.4166)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:40:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:27 lr 0.000005	 wd 0.0000	time 0.2110 (0.2425)	loss 1.3606 (1.3882)	grad_norm 0.3908 (0.4158)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:40:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:01 lr 0.000005	 wd 0.0000	time 0.2065 (0.2408)	loss 0.9947 (1.3867)	grad_norm 0.3831 (0.4174)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:40:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:35 lr 0.000005	 wd 0.0000	time 0.2015 (0.2389)	loss 1.5581 (1.3863)	grad_norm 0.3738 (0.4166)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:41:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:10 lr 0.000005	 wd 0.0000	time 0.2057 (0.2370)	loss 1.6939 (1.3876)	grad_norm 0.4252 (0.4163)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:41:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:45 lr 0.000005	 wd 0.0000	time 0.2018 (0.2362)	loss 1.1737 (1.3854)	grad_norm 0.4070 (0.4163)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:42:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:22 lr 0.000005	 wd 0.0000	time 0.2231 (0.2367)	loss 1.4415 (1.3865)	grad_norm 0.3959 (0.4155)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:42:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:01:58 lr 0.000004	 wd 0.0000	time 0.2062 (0.2354)	loss 1.4190 (1.3870)	grad_norm 0.3883 (0.4147)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:42:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:34 lr 0.000004	 wd 0.0000	time 0.2015 (0.2342)	loss 1.5661 (1.3861)	grad_norm 0.4143 (0.4147)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:43:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:10 lr 0.000004	 wd 0.0000	time 0.2172 (0.2334)	loss 1.4581 (1.3860)	grad_norm 0.6690 (0.4152)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:43:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:47 lr 0.000004	 wd 0.0000	time 0.4437 (0.2339)	loss 1.7519 (1.3855)	grad_norm 0.3980 (0.4150)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:43:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:23 lr 0.000004	 wd 0.0000	time 0.2153 (0.2333)	loss 1.5444 (1.3854)	grad_norm 0.3903 (0.4149)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 16:44:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000004	 wd 0.0000	time 0.1517 (0.2312)	loss 1.2652 (1.3855)	grad_norm 0.3926 (0.4146)	loss_scale 16384.0000 (8467.1411)	mem 7585MB
[2024-07-13 16:44:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 24 training takes 0:09:46
[2024-07-13 16:44:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 22.265 (22.265)	Loss 0.4219 (0.4219)	Acc@1 91.992 (91.992)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 16:45:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.676 Acc@5 97.110
[2024-07-13 16:45:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 16:45:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.68%
[2024-07-13 16:45:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][0/2502]	eta 18:59:26 lr 0.000004	 wd 0.0000	time 27.3246 (27.3246)	loss 1.2693 (1.2693)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7585MB
[2024-07-13 16:45:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:19:04 lr 0.000004	 wd 0.0000	time 0.1978 (0.4763)	loss 1.4282 (1.3524)	grad_norm 0.3740 (0.4056)	loss_scale 16384.0000 (16384.0000)	mem 7585MB
[2024-07-13 16:46:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:13:03 lr 0.000004	 wd 0.0000	time 0.2021 (0.3403)	loss 1.5157 (1.3810)	grad_norm 0.3940 (0.4075)	loss_scale 16384.0000 (16384.0000)	mem 7585MB
[2024-07-13 16:46:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:12:40 lr 0.000004	 wd 0.0000	time 0.2530 (0.3452)	loss 1.1312 (1.3713)	grad_norm 0.3669 (0.4092)	loss_scale 16384.0000 (16384.0000)	mem 7585MB
[2024-07-13 16:47:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:11:12 lr 0.000004	 wd 0.0000	time 0.2244 (0.3198)	loss 1.2867 (1.3865)	grad_norm 0.4166 (0.4077)	loss_scale 16384.0000 (16384.0000)	mem 7585MB
[2024-07-13 16:47:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:09:54 lr 0.000004	 wd 0.0000	time 0.1884 (0.2970)	loss 1.5862 (1.3870)	grad_norm 0.3760 (0.4087)	loss_scale 16384.0000 (16384.0000)	mem 7585MB
[2024-07-13 16:47:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:56 lr 0.000004	 wd 0.0000	time 0.2214 (0.2819)	loss 1.2120 (1.3885)	grad_norm 0.3738 (0.4096)	loss_scale 16384.0000 (16384.0000)	mem 7585MB
[2024-07-13 16:48:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:08:38 lr 0.000004	 wd 0.0000	time 0.2798 (0.2875)	loss 1.2891 (1.3888)	grad_norm 0.3969 (nan)	loss_scale 8192.0000 (16126.9044)	mem 7585MB
[2024-07-13 16:48:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:07:53 lr 0.000004	 wd 0.0000	time 0.1933 (0.2779)	loss 1.0116 (1.3891)	grad_norm 0.4939 (nan)	loss_scale 8192.0000 (15136.2797)	mem 7585MB
[2024-07-13 16:49:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:07:12 lr 0.000004	 wd 0.0000	time 0.2068 (0.2700)	loss 1.5530 (1.3911)	grad_norm 0.4022 (nan)	loss_scale 8192.0000 (14365.5494)	mem 7585MB
[2024-07-13 16:49:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:35 lr 0.000004	 wd 0.0000	time 0.2255 (0.2636)	loss 1.2468 (1.3914)	grad_norm 0.4201 (nan)	loss_scale 4096.0000 (13593.3187)	mem 7585MB
[2024-07-13 16:49:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:06:18 lr 0.000004	 wd 0.0000	time 0.2394 (0.2700)	loss 1.3287 (1.3895)	grad_norm 0.3980 (nan)	loss_scale 4096.0000 (12730.7103)	mem 7585MB
[2024-07-13 16:50:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:45 lr 0.000004	 wd 0.0000	time 0.2105 (0.2652)	loss 1.3540 (1.3918)	grad_norm 0.4337 (nan)	loss_scale 4096.0000 (12011.7502)	mem 7585MB
[2024-07-13 16:50:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:05:13 lr 0.000003	 wd 0.0000	time 0.1900 (0.2607)	loss 1.4968 (1.3935)	grad_norm 0.4101 (nan)	loss_scale 4096.0000 (11403.3144)	mem 7585MB
[2024-07-13 16:51:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:42 lr 0.000003	 wd 0.0000	time 0.1860 (0.2566)	loss 1.1223 (1.3931)	grad_norm 0.3913 (nan)	loss_scale 4096.0000 (10881.7359)	mem 7585MB
[2024-07-13 16:51:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:04:15 lr 0.000003	 wd 0.0000	time 0.2349 (0.2550)	loss 1.2587 (1.3931)	grad_norm 0.4036 (nan)	loss_scale 4096.0000 (10429.6549)	mem 7585MB
[2024-07-13 16:51:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:49 lr 0.000003	 wd 0.0000	time 0.1985 (0.2545)	loss 1.5213 (1.3924)	grad_norm 0.3724 (nan)	loss_scale 4096.0000 (10034.0487)	mem 7585MB
[2024-07-13 16:52:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:21 lr 0.000003	 wd 0.0000	time 0.1936 (0.2517)	loss 1.4335 (1.3918)	grad_norm 0.3858 (nan)	loss_scale 4096.0000 (9684.9571)	mem 7585MB
[2024-07-13 16:52:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:55 lr 0.000003	 wd 0.0000	time 0.2019 (0.2493)	loss 1.5926 (1.3917)	grad_norm 0.3992 (nan)	loss_scale 4096.0000 (9374.6319)	mem 7585MB
[2024-07-13 16:52:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:29 lr 0.000003	 wd 0.0000	time 0.2327 (0.2478)	loss 1.9632 (1.3914)	grad_norm 0.3773 (nan)	loss_scale 4096.0000 (9096.9553)	mem 7585MB
[2024-07-13 16:53:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:02:04 lr 0.000003	 wd 0.0000	time 0.1905 (0.2477)	loss 1.3016 (1.3906)	grad_norm 0.3818 (nan)	loss_scale 4096.0000 (8847.0325)	mem 7585MB
[2024-07-13 16:53:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:38 lr 0.000003	 wd 0.0000	time 0.2123 (0.2462)	loss 0.8992 (1.3906)	grad_norm 0.4334 (nan)	loss_scale 4096.0000 (8620.9005)	mem 7585MB
[2024-07-13 16:53:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:13 lr 0.000003	 wd 0.0000	time 0.1940 (0.2445)	loss 1.4572 (1.3895)	grad_norm 0.3979 (nan)	loss_scale 4096.0000 (8415.3167)	mem 7585MB
[2024-07-13 16:54:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:49 lr 0.000003	 wd 0.0000	time 0.2375 (0.2431)	loss 1.2355 (1.3881)	grad_norm 0.3778 (nan)	loss_scale 4096.0000 (8227.6019)	mem 7585MB
[2024-07-13 16:54:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:24 lr 0.000003	 wd 0.0000	time 0.1619 (0.2425)	loss 1.4182 (1.3897)	grad_norm 0.3816 (nan)	loss_scale 4096.0000 (8055.5235)	mem 7585MB
[2024-07-13 16:55:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1537 (0.2404)	loss 1.5162 (1.3898)	grad_norm 0.4128 (nan)	loss_scale 4096.0000 (7897.2059)	mem 7585MB
[2024-07-13 16:55:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 25 training takes 0:10:12
[2024-07-13 16:55:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 23.811 (23.811)	Loss 0.4214 (0.4214)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 16:55:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.680 Acc@5 97.100
[2024-07-13 16:55:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 16:55:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.68%
[2024-07-13 16:55:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 16:55:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 16:56:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][0/2502]	eta 22:22:40 lr 0.000003	 wd 0.0000	time 32.1986 (32.1986)	loss 1.3484 (1.3484)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:56:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:21:07 lr 0.000003	 wd 0.0000	time 0.2003 (0.5277)	loss 1.5400 (1.3842)	grad_norm 0.3877 (0.4087)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:57:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:14:03 lr 0.000003	 wd 0.0000	time 0.2314 (0.3663)	loss 1.5076 (1.4047)	grad_norm 0.3941 (0.4126)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:57:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:11:27 lr 0.000003	 wd 0.0000	time 0.2353 (0.3123)	loss 1.5106 (1.3957)	grad_norm 0.4255 (0.4126)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:58:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:11:09 lr 0.000003	 wd 0.0000	time 0.2400 (0.3183)	loss 1.6788 (1.3975)	grad_norm 0.4005 (0.4113)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:58:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:09:55 lr 0.000003	 wd 0.0000	time 0.1840 (0.2973)	loss 1.6527 (1.4037)	grad_norm 0.4035 (0.4125)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:58:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:08:56 lr 0.000003	 wd 0.0000	time 0.2157 (0.2820)	loss 1.4235 (1.3984)	grad_norm 0.3931 (0.4165)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:59:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:08:09 lr 0.000003	 wd 0.0000	time 0.2185 (0.2715)	loss 1.5437 (1.3942)	grad_norm 0.4075 (0.4171)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:59:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:07:35 lr 0.000002	 wd 0.0000	time 0.2075 (0.2676)	loss 1.6096 (1.3927)	grad_norm 0.3713 (0.4153)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 16:59:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:07:01 lr 0.000002	 wd 0.0000	time 0.1947 (0.2631)	loss 1.3902 (1.3927)	grad_norm 0.3889 (0.4148)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:00:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:27 lr 0.000002	 wd 0.0000	time 0.2305 (0.2577)	loss 1.4565 (1.3932)	grad_norm 0.4015 (0.4169)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:00:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:55 lr 0.000002	 wd 0.0000	time 0.2063 (0.2533)	loss 1.6389 (1.3950)	grad_norm 0.4410 (0.4168)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:00:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:26 lr 0.000002	 wd 0.0000	time 0.2614 (0.2509)	loss 1.1031 (1.3956)	grad_norm 0.4290 (0.4157)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:01:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:05:01 lr 0.000002	 wd 0.0000	time 0.1755 (0.2506)	loss 0.9815 (1.3938)	grad_norm 0.4307 (0.4157)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:01:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:33 lr 0.000002	 wd 0.0000	time 0.2061 (0.2478)	loss 1.6301 (1.3933)	grad_norm 0.4131 (0.4153)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:02:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:04:05 lr 0.000002	 wd 0.0000	time 0.2115 (0.2452)	loss 1.4334 (1.3920)	grad_norm 0.3966 (0.4152)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:02:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:39 lr 0.000002	 wd 0.0000	time 0.2131 (0.2430)	loss 1.4919 (1.3909)	grad_norm 0.4092 (0.4144)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:02:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:15 lr 0.000002	 wd 0.0000	time 0.2051 (0.2435)	loss 1.3087 (1.3920)	grad_norm 0.3971 (0.4139)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:03:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:50 lr 0.000002	 wd 0.0000	time 0.2365 (0.2424)	loss 1.5451 (1.3949)	grad_norm 0.3933 (0.4137)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:03:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:24 lr 0.000002	 wd 0.0000	time 0.1716 (0.2408)	loss 1.0087 (1.3934)	grad_norm 0.3691 (0.4135)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:03:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:02:00 lr 0.000002	 wd 0.0000	time 0.1866 (0.2392)	loss 0.9565 (1.3924)	grad_norm 0.4423 (0.4135)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:04:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:35 lr 0.000002	 wd 0.0000	time 0.1838 (0.2387)	loss 1.1506 (1.3914)	grad_norm 0.3946 (0.4140)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:04:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:12 lr 0.000002	 wd 0.0000	time 0.2660 (0.2392)	loss 0.9816 (1.3910)	grad_norm 0.4367 (0.4141)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:05:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:48 lr 0.000002	 wd 0.0000	time 0.2263 (0.2378)	loss 1.2119 (1.3898)	grad_norm 0.3925 (0.4139)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:05:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:24 lr 0.000002	 wd 0.0000	time 0.2051 (0.2366)	loss 1.1485 (1.3898)	grad_norm 0.4084 (0.4142)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:05:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1649 (0.2343)	loss 0.9677 (1.3879)	grad_norm 0.4474 (0.4137)	loss_scale 8192.0000 (4161.5098)	mem 7585MB
[2024-07-13 17:05:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 26 training takes 0:09:53
[2024-07-13 17:06:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 39.944 (39.944)	Loss 0.4211 (0.4211)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 17:06:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.696 Acc@5 97.104
[2024-07-13 17:06:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 17:06:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.70%
[2024-07-13 17:06:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 17:06:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 17:07:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][0/2502]	eta 10:28:10 lr 0.000002	 wd 0.0000	time 15.0640 (15.0640)	loss 0.9579 (0.9579)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 17:07:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:15:53 lr 0.000002	 wd 0.0000	time 0.3097 (0.3968)	loss 1.5350 (1.3958)	grad_norm 0.3955 (0.4042)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 17:07:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:13:03 lr 0.000002	 wd 0.0000	time 0.1754 (0.3402)	loss 1.6063 (1.3897)	grad_norm 0.4043 (0.4073)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 17:08:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:10:51 lr 0.000002	 wd 0.0000	time 0.1928 (0.2957)	loss 1.3903 (1.3902)	grad_norm 0.4512 (0.4060)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 17:08:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:09:34 lr 0.000002	 wd 0.0000	time 0.2021 (0.2735)	loss 1.4745 (1.3881)	grad_norm 0.3744 (0.4106)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 17:09:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:08:46 lr 0.000002	 wd 0.0000	time 0.3064 (0.2632)	loss 0.9952 (1.3838)	grad_norm 0.5441 (0.4149)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 17:09:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:40 lr 0.000002	 wd 0.0000	time 0.2183 (0.2736)	loss 1.2864 (1.3869)	grad_norm 0.3814 (0.4135)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 17:09:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:56 lr 0.000002	 wd 0.0000	time 0.2104 (0.2643)	loss 1.4997 (1.3926)	grad_norm 0.3832 (0.4152)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 17:10:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:17 lr 0.000002	 wd 0.0000	time 0.2001 (0.2569)	loss 1.5779 (1.3961)	grad_norm 0.3857 (0.4144)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 17:10:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:45 lr 0.000001	 wd 0.0000	time 0.2222 (0.2534)	loss 1.3188 (1.4008)	grad_norm 0.3732 (0.4139)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 17:11:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:27 lr 0.000001	 wd 0.0000	time 0.2016 (0.2583)	loss 1.4812 (1.3990)	grad_norm 0.4248 (0.4132)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 17:11:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:55 lr 0.000001	 wd 0.0000	time 0.2205 (0.2535)	loss 1.5474 (1.3991)	grad_norm 0.3699 (0.4140)	loss_scale 8192.0000 (8192.0000)	mem 7585MB
[2024-07-13 17:11:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:25 lr 0.000001	 wd 0.0000	time 0.2051 (0.2497)	loss 1.5279 (1.3990)	grad_norm 0.4073 (nan)	loss_scale 4096.0000 (8096.5062)	mem 7585MB
[2024-07-13 17:12:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:56 lr 0.000001	 wd 0.0000	time 0.2078 (0.2469)	loss 1.5269 (1.3962)	grad_norm 0.3836 (nan)	loss_scale 4096.0000 (7789.0115)	mem 7585MB
[2024-07-13 17:12:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:31 lr 0.000001	 wd 0.0000	time 0.1957 (0.2465)	loss 1.3294 (1.3967)	grad_norm 0.6344 (nan)	loss_scale 4096.0000 (7525.4133)	mem 7585MB
[2024-07-13 17:12:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:04:04 lr 0.000001	 wd 0.0000	time 0.1864 (0.2444)	loss 1.6080 (1.3964)	grad_norm 0.3897 (nan)	loss_scale 4096.0000 (7296.9380)	mem 7585MB
[2024-07-13 17:13:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:38 lr 0.000001	 wd 0.0000	time 0.2354 (0.2422)	loss 1.5884 (1.3942)	grad_norm 0.4012 (nan)	loss_scale 4096.0000 (7097.0044)	mem 7585MB
[2024-07-13 17:13:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:12 lr 0.000001	 wd 0.0000	time 0.2121 (0.2402)	loss 1.4148 (1.3920)	grad_norm 0.3813 (nan)	loss_scale 4096.0000 (6920.5785)	mem 7585MB
[2024-07-13 17:14:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:48 lr 0.000001	 wd 0.0000	time 0.2421 (0.2394)	loss 1.5503 (1.3925)	grad_norm 0.3871 (nan)	loss_scale 4096.0000 (6763.7446)	mem 7585MB
[2024-07-13 17:14:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:24 lr 0.000001	 wd 0.0000	time 0.1980 (0.2398)	loss 1.1102 (1.3940)	grad_norm 0.4188 (nan)	loss_scale 4096.0000 (6623.4108)	mem 7585MB
[2024-07-13 17:14:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:59 lr 0.000001	 wd 0.0000	time 0.2040 (0.2383)	loss 1.0677 (1.3928)	grad_norm 0.3823 (nan)	loss_scale 4096.0000 (6497.1034)	mem 7585MB
[2024-07-13 17:15:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:35 lr 0.000001	 wd 0.0000	time 0.2096 (0.2369)	loss 1.7556 (1.3920)	grad_norm 0.4454 (nan)	loss_scale 4096.0000 (6382.8196)	mem 7585MB
[2024-07-13 17:15:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:11 lr 0.000001	 wd 0.0000	time 0.2240 (0.2361)	loss 1.0941 (1.3928)	grad_norm 0.3978 (nan)	loss_scale 4096.0000 (6278.9205)	mem 7585MB
[2024-07-13 17:15:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:47 lr 0.000001	 wd 0.0000	time 0.2749 (0.2362)	loss 1.4881 (1.3927)	grad_norm 0.4040 (nan)	loss_scale 4096.0000 (6184.0522)	mem 7585MB
[2024-07-13 17:16:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:24 lr 0.000001	 wd 0.0000	time 0.2232 (0.2354)	loss 1.3945 (1.3923)	grad_norm 0.3820 (nan)	loss_scale 4096.0000 (6097.0862)	mem 7585MB
[2024-07-13 17:16:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1529 (0.2330)	loss 1.5551 (1.3906)	grad_norm 0.3689 (nan)	loss_scale 4096.0000 (6017.0748)	mem 7585MB
[2024-07-13 17:16:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 27 training takes 0:09:51
[2024-07-13 17:17:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 27.711 (27.711)	Loss 0.4214 (0.4214)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 17:17:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.698 Acc@5 97.104
[2024-07-13 17:17:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 17:17:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.70%
[2024-07-13 17:17:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saving......
[2024-07-13 17:17:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_best.pth saved !!!
[2024-07-13 17:17:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][0/2502]	eta 11:19:53 lr 0.000001	 wd 0.0000	time 16.3042 (16.3042)	loss 1.3232 (1.3232)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:18:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:14:50 lr 0.000001	 wd 0.0000	time 0.1946 (0.3709)	loss 1.0779 (1.3711)	grad_norm 0.4242 (0.4099)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:18:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:11:09 lr 0.000001	 wd 0.0000	time 0.2666 (0.2910)	loss 1.0760 (1.3738)	grad_norm 0.4143 (0.4362)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:19:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:10:58 lr 0.000001	 wd 0.0000	time 0.2065 (0.2990)	loss 1.6596 (1.3843)	grad_norm 0.3982 (0.4298)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:19:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:09:40 lr 0.000001	 wd 0.0000	time 0.1931 (0.2761)	loss 1.4364 (1.3889)	grad_norm 0.3823 (0.4272)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:19:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:08:43 lr 0.000001	 wd 0.0000	time 0.2051 (0.2616)	loss 1.5922 (1.3908)	grad_norm 0.3847 (0.4257)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:20:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:00 lr 0.000001	 wd 0.0000	time 0.2087 (0.2528)	loss 1.4391 (1.3909)	grad_norm 0.3824 (0.4233)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:20:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:56 lr 0.000001	 wd 0.0000	time 0.2608 (0.2643)	loss 1.0453 (1.3930)	grad_norm 0.3807 (0.4218)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:21:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:18 lr 0.000001	 wd 0.0000	time 0.2147 (0.2574)	loss 1.6221 (1.3904)	grad_norm 0.3996 (0.4212)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:21:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:43 lr 0.000001	 wd 0.0000	time 0.1898 (0.2516)	loss 1.5720 (1.3910)	grad_norm 0.4044 (0.4206)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:21:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:11 lr 0.000001	 wd 0.0000	time 0.2258 (0.2475)	loss 1.5887 (1.3936)	grad_norm 0.4196 (0.4196)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:22:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:58 lr 0.000001	 wd 0.0000	time 0.2382 (0.2558)	loss 0.9686 (1.3899)	grad_norm 0.4057 (0.4186)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:22:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:27 lr 0.000001	 wd 0.0000	time 0.2145 (0.2518)	loss 1.2390 (1.3902)	grad_norm 0.4144 (0.4190)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:23:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:04:58 lr 0.000001	 wd 0.0000	time 0.2054 (0.2483)	loss 1.6230 (1.3869)	grad_norm 0.4156 (0.4198)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:23:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:30 lr 0.000001	 wd 0.0000	time 0.2108 (0.2455)	loss 0.9466 (1.3881)	grad_norm 0.3829 (0.4197)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:23:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:04:04 lr 0.000001	 wd 0.0000	time 0.2318 (0.2443)	loss 1.5186 (1.3866)	grad_norm 0.3893 (0.4202)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:24:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:39 lr 0.000001	 wd 0.0000	time 0.2071 (0.2437)	loss 1.1917 (1.3861)	grad_norm 0.4131 (0.4192)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:24:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:13 lr 0.000001	 wd 0.0000	time 0.2071 (0.2417)	loss 1.4416 (1.3876)	grad_norm 0.4161 (0.4187)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:24:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:48 lr 0.000001	 wd 0.0000	time 0.2082 (0.2399)	loss 1.4035 (1.3873)	grad_norm 0.5370 (0.4187)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:25:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:23 lr 0.000001	 wd 0.0000	time 0.2104 (0.2389)	loss 1.5585 (1.3863)	grad_norm 0.4098 (0.4185)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:25:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:02:00 lr 0.000001	 wd 0.0000	time 0.2236 (0.2394)	loss 0.9061 (1.3862)	grad_norm 0.4256 (0.4176)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:25:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:35 lr 0.000001	 wd 0.0000	time 0.2057 (0.2383)	loss 1.1037 (1.3864)	grad_norm 0.3930 (0.4170)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:26:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:11 lr 0.000001	 wd 0.0000	time 0.2208 (0.2371)	loss 1.5587 (1.3852)	grad_norm 0.3883 (0.4173)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:26:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:47 lr 0.000001	 wd 0.0000	time 0.2169 (0.2360)	loss 1.1144 (1.3853)	grad_norm 0.4338 (0.4168)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:27:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:24 lr 0.000001	 wd 0.0000	time 0.3051 (0.2359)	loss 1.6176 (1.3838)	grad_norm 0.4266 (0.4173)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:27:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1492 (0.2341)	loss 1.2054 (1.3829)	grad_norm 0.3927 (0.4171)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:27:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 28 training takes 0:09:56
[2024-07-13 17:27:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 20.006 (20.006)	Loss 0.4214 (0.4214)	Acc@1 91.992 (91.992)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 17:28:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.686 Acc@5 97.108
[2024-07-13 17:28:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 17:28:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.70%
[2024-07-13 17:28:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][0/2502]	eta 1 day, 1:07:07 lr 0.000001	 wd 0.0000	time 36.1420 (36.1420)	loss 1.4396 (1.4396)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:29:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:22:53 lr 0.000001	 wd 0.0000	time 0.1911 (0.5717)	loss 1.4957 (1.3651)	grad_norm 0.3805 (0.4049)	loss_scale 4096.0000 (4096.0000)	mem 7585MB
[2024-07-13 17:29:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:14:52 lr 0.000001	 wd 0.0000	time 0.1881 (0.3879)	loss 1.1478 (1.3801)	grad_norm 0.4200 (0.4085)	loss_scale 8192.0000 (4748.0995)	mem 7585MB
[2024-07-13 17:29:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:12:03 lr 0.000001	 wd 0.0000	time 0.2300 (0.3286)	loss 1.5253 (1.3779)	grad_norm 0.3907 (0.4075)	loss_scale 8192.0000 (5892.2525)	mem 7585MB
[2024-07-13 17:30:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:11:30 lr 0.000001	 wd 0.0000	time 0.2035 (0.3285)	loss 1.2102 (1.3867)	grad_norm 0.4922 (0.4071)	loss_scale 8192.0000 (6465.7556)	mem 7585MB
[2024-07-13 17:30:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:10:09 lr 0.000001	 wd 0.0000	time 0.1917 (0.3043)	loss 0.9548 (1.3889)	grad_norm 0.3990 (0.4078)	loss_scale 8192.0000 (6810.3154)	mem 7585MB
[2024-07-13 17:31:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:09:07 lr 0.000000	 wd 0.0000	time 0.1762 (0.2879)	loss 1.3711 (1.3900)	grad_norm 0.3577 (0.4069)	loss_scale 8192.0000 (7040.2130)	mem 7585MB
[2024-07-13 17:31:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:08:18 lr 0.000000	 wd 0.0000	time 0.2235 (0.2767)	loss 1.6140 (1.3906)	grad_norm 0.4432 (0.4061)	loss_scale 8192.0000 (7204.5193)	mem 7585MB
[2024-07-13 17:32:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:08:01 lr 0.000000	 wd 0.0000	time 0.2270 (0.2831)	loss 0.8243 (1.3919)	grad_norm 0.3834 (0.4064)	loss_scale 8192.0000 (7327.8002)	mem 7585MB
[2024-07-13 17:32:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:07:20 lr 0.000000	 wd 0.0000	time 0.2032 (0.2747)	loss 1.4411 (1.3917)	grad_norm 0.4218 (0.4066)	loss_scale 8192.0000 (7423.7159)	mem 7585MB
[2024-07-13 17:32:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:42 lr 0.000000	 wd 0.0000	time 0.2207 (0.2679)	loss 1.3577 (1.3913)	grad_norm 0.3974 (0.4083)	loss_scale 8192.0000 (7500.4675)	mem 7585MB
[2024-07-13 17:33:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:06:08 lr 0.000000	 wd 0.0000	time 0.2023 (0.2626)	loss 1.4878 (1.3918)	grad_norm 0.3604 (0.4100)	loss_scale 8192.0000 (7563.2770)	mem 7585MB
[2024-07-13 17:33:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:39 lr 0.000000	 wd 0.0000	time 0.2796 (0.2608)	loss 1.2964 (1.3887)	grad_norm 0.3779 (0.4095)	loss_scale 8192.0000 (7615.6270)	mem 7585MB
[2024-07-13 17:33:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:05:10 lr 0.000000	 wd 0.0000	time 0.1848 (0.2585)	loss 1.5779 (1.3895)	grad_norm 0.4137 (0.4100)	loss_scale 8192.0000 (7659.9293)	mem 7585MB
[2024-07-13 17:34:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:41 lr 0.000000	 wd 0.0000	time 0.2152 (0.2551)	loss 1.7894 (1.3884)	grad_norm 0.3792 (0.4112)	loss_scale 8192.0000 (7697.9072)	mem 7585MB
[2024-07-13 17:34:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:04:12 lr 0.000000	 wd 0.0000	time 0.2171 (0.2518)	loss 1.3061 (1.3895)	grad_norm 0.4264 (0.4109)	loss_scale 8192.0000 (7730.8248)	mem 7585MB
[2024-07-13 17:34:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:45 lr 0.000000	 wd 0.0000	time 0.2085 (0.2498)	loss 1.5007 (1.3910)	grad_norm 0.3933 (0.4126)	loss_scale 8192.0000 (7759.6302)	mem 7585MB
[2024-07-13 17:35:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:20 lr 0.000000	 wd 0.0000	time 0.2067 (0.2497)	loss 1.3213 (1.3878)	grad_norm 0.3975 (0.4141)	loss_scale 8192.0000 (7785.0488)	mem 7585MB
[2024-07-13 17:35:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:53 lr 0.000000	 wd 0.0000	time 0.1943 (0.2475)	loss 1.1982 (1.3894)	grad_norm 0.4186 (inf)	loss_scale 4096.0000 (7716.6730)	mem 7585MB
[2024-07-13 17:36:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:27 lr 0.000000	 wd 0.0000	time 0.2021 (0.2456)	loss 1.2546 (1.3891)	grad_norm 0.4237 (inf)	loss_scale 4096.0000 (7526.2115)	mem 7585MB
[2024-07-13 17:36:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:02:02 lr 0.000000	 wd 0.0000	time 0.2209 (0.2439)	loss 1.5429 (1.3892)	grad_norm 0.4292 (inf)	loss_scale 4096.0000 (7354.7866)	mem 7585MB
[2024-07-13 17:36:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:37 lr 0.000000	 wd 0.0000	time 0.1911 (0.2436)	loss 1.5318 (1.3898)	grad_norm 0.4336 (inf)	loss_scale 4096.0000 (7199.6802)	mem 7585MB
[2024-07-13 17:37:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:13 lr 0.000000	 wd 0.0000	time 0.2033 (0.2432)	loss 1.4791 (1.3915)	grad_norm 0.3935 (inf)	loss_scale 4096.0000 (7058.6679)	mem 7585MB
[2024-07-13 17:37:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:48 lr 0.000000	 wd 0.0000	time 0.2042 (0.2417)	loss 1.4604 (1.3927)	grad_norm 0.4149 (inf)	loss_scale 4096.0000 (6929.9122)	mem 7585MB
[2024-07-13 17:37:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.2052 (0.2403)	loss 1.4241 (1.3933)	grad_norm 0.4409 (inf)	loss_scale 4096.0000 (6811.8817)	mem 7585MB
[2024-07-13 17:38:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000000	 wd 0.0000	time 0.1577 (0.2380)	loss 1.6195 (1.3924)	grad_norm 0.3952 (inf)	loss_scale 4096.0000 (6703.2899)	mem 7585MB
[2024-07-13 17:38:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 29 training takes 0:10:04
[2024-07-13 17:38:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_29.pth saving......
[2024-07-13 17:38:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_swin_b_22kto1k_step_stag0/ckpt_epoch_29.pth saved !!!
[2024-07-13 17:38:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 35.439 (35.439)	Loss 0.4211 (0.4211)	Acc@1 91.992 (91.992)	Acc@5 98.242 (98.242)	Mem 7585MB
[2024-07-13 17:39:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.686 Acc@5 97.106
[2024-07-13 17:39:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-13 17:39:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.70%
[2024-07-13 17:39:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process0] (main.py 189): INFO Training time 5:19:53
