[2024-07-14 16:22:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft/config.json
[2024-07-14 16:22:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_swin_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 9
    - 3
    DIMS:
    - 96
    - 192
    - 384
    - 768
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: false
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: fullfinetune
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 4.0e-05
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.0e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 4.0e-08
  WEIGHT_DECAY: 1.0e-08

[2024-07-14 16:22:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/swin/diffusion_ft_adapter_swin_base_patch4_window7_224_22kto1k_step_stage_process4.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-14 16:22:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 108): INFO Creating model:adapter_swin_diffusion_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft
[2024-07-14 16:22:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 110): INFO Adapter_SwinTransformer_Diffusion_Finetune(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (uma): UMA(filter_strategy1=23, filter_strategy2=7,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-14 16:22:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 113): INFO number of params: 4531880
[2024-07-14 16:22:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 116): INFO number of GFLOPs: 15.438473216
[2024-07-14 16:22:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 150): INFO no checkpoint found in pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft, ignoring auto resume
[2024-07-14 16:22:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_best.pth for fine-tuning......
[2024-07-14 16:22:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])
[2024-07-14 16:22:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_swin_b_22kto1k_step_stag3/ckpt_epoch_best.pth'
[2024-07-14 16:23:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 71.872 (71.872)	Loss 0.4138 (0.4138)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 1490MB
[2024-07-14 16:24:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.184 Acc@5 97.284
[2024-07-14 16:24:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 162): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 16:24:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 168): INFO Start training
[2024-07-14 16:24:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][0/2502]	eta 16:42:49 lr 0.000000	 wd 0.0000	time 24.0484 (24.0484)	loss 1.6184 (1.6184)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 7938MB
[2024-07-14 16:25:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:19:11 lr 0.000000	 wd 0.0000	time 0.2319 (0.4795)	loss 1.3931 (1.3965)	grad_norm 0.4533 (nan)	loss_scale 16384.0000 (29199.2079)	mem 7984MB
[2024-07-14 16:25:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:15:05 lr 0.000001	 wd 0.0000	time 0.2083 (0.3932)	loss 1.4275 (1.3812)	grad_norm 0.4770 (nan)	loss_scale 16384.0000 (22823.4826)	mem 7984MB
[2024-07-14 16:25:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:27 lr 0.000001	 wd 0.0000	time 0.2171 (0.3394)	loss 1.4355 (1.3619)	grad_norm 0.4923 (nan)	loss_scale 16384.0000 (20684.1196)	mem 7984MB
[2024-07-14 16:26:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:56 lr 0.000001	 wd 0.0000	time 0.2487 (0.3124)	loss 1.8183 (1.3649)	grad_norm 0.4783 (nan)	loss_scale 16384.0000 (19611.7706)	mem 7984MB
[2024-07-14 16:26:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:09:56 lr 0.000002	 wd 0.0000	time 0.2603 (0.2980)	loss 1.4736 (1.3636)	grad_norm 0.6925 (nan)	loss_scale 8192.0000 (18673.1816)	mem 7984MB
[2024-07-14 16:27:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:13 lr 0.000002	 wd 0.0000	time 0.2907 (0.2912)	loss 1.1528 (1.3632)	grad_norm 0.4596 (nan)	loss_scale 8192.0000 (16929.2246)	mem 7984MB
[2024-07-14 16:27:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:30 lr 0.000002	 wd 0.0000	time 0.2115 (0.2831)	loss 1.4171 (1.3591)	grad_norm 0.6000 (nan)	loss_scale 8192.0000 (15682.8302)	mem 7984MB
[2024-07-14 16:27:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:51 lr 0.000003	 wd 0.0000	time 0.2352 (0.2773)	loss 1.5320 (1.3601)	grad_norm 0.4610 (nan)	loss_scale 8192.0000 (14747.6454)	mem 7984MB
[2024-07-14 16:28:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:17 lr 0.000003	 wd 0.0000	time 0.2706 (0.2733)	loss 1.5459 (1.3553)	grad_norm 0.5532 (nan)	loss_scale 8192.0000 (14020.0488)	mem 7984MB
[2024-07-14 16:28:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:06:49 lr 0.000003	 wd 0.0000	time 0.2579 (0.2729)	loss 1.3621 (1.3550)	grad_norm 0.5473 (nan)	loss_scale 8192.0000 (13437.8262)	mem 7984MB
[2024-07-14 16:29:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:18 lr 0.000004	 wd 0.0000	time 0.2370 (0.2698)	loss 1.5096 (1.3558)	grad_norm 0.4503 (nan)	loss_scale 8192.0000 (12961.3660)	mem 7984MB
[2024-07-14 16:29:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:47 lr 0.000004	 wd 0.0000	time 0.2133 (0.2671)	loss 1.4663 (1.3579)	grad_norm 0.4980 (nan)	loss_scale 4096.0000 (12250.4846)	mem 7984MB
[2024-07-14 16:29:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:18 lr 0.000004	 wd 0.0000	time 0.2433 (0.2652)	loss 1.4308 (1.3600)	grad_norm 0.4544 (nan)	loss_scale 4096.0000 (11623.6987)	mem 7984MB
[2024-07-14 16:30:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:52 lr 0.000005	 wd 0.0000	time 0.2355 (0.2651)	loss 1.5536 (1.3610)	grad_norm 0.5184 (nan)	loss_scale 4096.0000 (11086.3897)	mem 7984MB
[2024-07-14 16:30:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:23 lr 0.000005	 wd 0.0000	time 0.2226 (0.2633)	loss 1.4587 (1.3608)	grad_norm 0.6120 (nan)	loss_scale 4096.0000 (10620.6742)	mem 7984MB
[2024-07-14 16:31:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:55 lr 0.000005	 wd 0.0000	time 0.2219 (0.2616)	loss 1.5773 (1.3613)	grad_norm 0.5246 (nan)	loss_scale 4096.0000 (10213.1368)	mem 7984MB
[2024-07-14 16:31:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:28 lr 0.000005	 wd 0.0000	time 0.2124 (0.2606)	loss 1.4740 (1.3603)	grad_norm 0.5207 (nan)	loss_scale 4096.0000 (9853.5168)	mem 7984MB
[2024-07-14 16:32:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:03:03 lr 0.000006	 wd 0.0000	time 0.2256 (0.2616)	loss 1.2206 (1.3609)	grad_norm 3.2247 (nan)	loss_scale 4096.0000 (9533.8323)	mem 7984MB
[2024-07-14 16:32:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:36 lr 0.000006	 wd 0.0000	time 0.2467 (0.2604)	loss 1.6243 (1.3603)	grad_norm 0.5200 (nan)	loss_scale 4096.0000 (9247.7812)	mem 7984MB
[2024-07-14 16:32:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:10 lr 0.000006	 wd 0.0000	time 0.2195 (0.2594)	loss 1.4821 (1.3584)	grad_norm 0.4296 (nan)	loss_scale 4096.0000 (8990.3208)	mem 7984MB
[2024-07-14 16:33:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:43 lr 0.000007	 wd 0.0000	time 0.2747 (0.2586)	loss 1.3524 (1.3588)	grad_norm 0.4656 (nan)	loss_scale 4096.0000 (8757.3689)	mem 7984MB
[2024-07-14 16:33:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:17 lr 0.000007	 wd 0.0000	time 0.2238 (0.2583)	loss 1.6135 (1.3596)	grad_norm 0.4803 (nan)	loss_scale 4096.0000 (8545.5847)	mem 7984MB
[2024-07-14 16:34:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:51 lr 0.000007	 wd 0.0000	time 0.2304 (0.2572)	loss 1.5236 (1.3584)	grad_norm 0.5366 (nan)	loss_scale 4096.0000 (8352.2086)	mem 7984MB
[2024-07-14 16:34:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:26 lr 0.000008	 wd 0.0000	time 0.2313 (0.2562)	loss 1.3781 (1.3586)	grad_norm 1.0078 (nan)	loss_scale 4096.0000 (8174.9404)	mem 7984MB
[2024-07-14 16:34:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1785 (0.2542)	loss 1.6373 (1.3587)	grad_norm 0.6339 (nan)	loss_scale 4096.0000 (8011.8481)	mem 7984MB
[2024-07-14 16:34:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 0 training takes 0:10:40
[2024-07-14 16:34:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft/ckpt_epoch_0.pth saving......
[2024-07-14 16:34:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft/ckpt_epoch_0.pth saved !!!
[2024-07-14 16:36:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 101.421 (101.421)	Loss 0.4136 (0.4136)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 16:37:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.184 Acc@5 97.284
[2024-07-14 16:37:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 16:37:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-14 16:37:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft/ckpt_epoch_best.pth saving......
[2024-07-14 16:37:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft/ckpt_epoch_best.pth saved !!!
[2024-07-14 16:37:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][0/2502]	eta 14:26:44 lr 0.000008	 wd 0.0000	time 20.7852 (20.7852)	loss 1.2045 (1.2045)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:37:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:17:39 lr 0.000008	 wd 0.0000	time 0.2679 (0.4412)	loss 1.1543 (1.3962)	grad_norm 0.6514 (0.5167)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:38:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:14:19 lr 0.000009	 wd 0.0000	time 0.2051 (0.3732)	loss 1.3476 (1.3964)	grad_norm 0.5352 (0.5100)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:38:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:55 lr 0.000009	 wd 0.0000	time 0.2174 (0.3252)	loss 1.6774 (1.3755)	grad_norm 0.4555 (0.5136)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:39:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:10:32 lr 0.000009	 wd 0.0000	time 0.2203 (0.3010)	loss 0.9832 (1.3652)	grad_norm 0.4602 (0.5199)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:39:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:09:34 lr 0.000010	 wd 0.0000	time 0.2422 (0.2871)	loss 1.5162 (1.3639)	grad_norm 0.7556 (0.5267)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:39:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:08:53 lr 0.000010	 wd 0.0000	time 0.2130 (0.2805)	loss 1.4278 (1.3637)	grad_norm 0.5139 (0.5257)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:40:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:14 lr 0.000010	 wd 0.0000	time 0.2284 (0.2746)	loss 1.6141 (1.3623)	grad_norm 0.4803 (0.5234)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:40:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:38 lr 0.000011	 wd 0.0000	time 0.2161 (0.2696)	loss 1.5448 (1.3658)	grad_norm 0.4428 (0.5245)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:41:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:05 lr 0.000011	 wd 0.0000	time 0.2372 (0.2657)	loss 1.5913 (1.3630)	grad_norm 0.4905 (0.5244)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:41:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:41 lr 0.000011	 wd 0.0000	time 0.2160 (0.2674)	loss 1.6761 (1.3619)	grad_norm 0.5553 (0.5252)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:42:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:06:10 lr 0.000012	 wd 0.0000	time 0.2214 (0.2643)	loss 1.0832 (1.3610)	grad_norm 0.4917 (0.5265)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:42:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:41 lr 0.000012	 wd 0.0000	time 0.2080 (0.2619)	loss 1.3431 (1.3636)	grad_norm 0.4571 (0.5259)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:42:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:12 lr 0.000012	 wd 0.0000	time 0.2144 (0.2598)	loss 1.5515 (1.3669)	grad_norm 0.4931 (0.5242)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:43:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:46 lr 0.000012	 wd 0.0000	time 0.2432 (0.2600)	loss 1.4305 (1.3650)	grad_norm 0.4767 (0.5239)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:43:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:19 lr 0.000013	 wd 0.0000	time 0.2070 (0.2590)	loss 0.9730 (1.3633)	grad_norm 0.4930 (0.5230)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:44:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:52 lr 0.000013	 wd 0.0000	time 0.1949 (0.2575)	loss 0.9217 (1.3619)	grad_norm 0.4783 (0.5230)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:44:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:25 lr 0.000013	 wd 0.0000	time 0.2389 (0.2562)	loss 1.3365 (1.3612)	grad_norm 0.5013 (0.5216)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:44:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:03:00 lr 0.000014	 wd 0.0000	time 0.2174 (0.2575)	loss 1.4171 (1.3613)	grad_norm 0.4447 (0.5204)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:45:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:34 lr 0.000014	 wd 0.0000	time 0.2354 (0.2565)	loss 1.4459 (1.3624)	grad_norm 0.5345 (0.5204)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:45:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:08 lr 0.000014	 wd 0.0000	time 0.2257 (0.2553)	loss 1.3169 (1.3616)	grad_norm 0.4901 (0.5193)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:46:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:42 lr 0.000015	 wd 0.0000	time 0.2326 (0.2545)	loss 1.3910 (1.3626)	grad_norm 0.4892 (0.5201)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:46:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:16 lr 0.000015	 wd 0.0000	time 0.2397 (0.2546)	loss 1.1944 (1.3638)	grad_norm 0.4788 (0.5193)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:46:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:51 lr 0.000015	 wd 0.0000	time 0.2365 (0.2539)	loss 1.6148 (1.3642)	grad_norm 0.5235 (0.5181)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:47:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:25 lr 0.000016	 wd 0.0000	time 0.2120 (0.2531)	loss 1.4528 (1.3624)	grad_norm 0.5502 (0.5191)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:47:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1769 (0.2512)	loss 1.1102 (1.3636)	grad_norm 0.4880 (0.5197)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:47:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 1 training takes 0:10:33
[2024-07-14 16:48:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 37.631 (37.631)	Loss 0.4158 (0.4158)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 16:48:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.160 Acc@5 97.272
[2024-07-14 16:48:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 16:48:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-14 16:48:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][0/2502]	eta 11:47:07 lr 0.000016	 wd 0.0000	time 16.9575 (16.9575)	loss 1.6379 (1.6379)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:49:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:15:51 lr 0.000016	 wd 0.0000	time 0.2294 (0.3962)	loss 1.4085 (1.3346)	grad_norm 0.5952 (0.5455)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 16:49:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:12:44 lr 0.000017	 wd 0.0000	time 0.1967 (0.3323)	loss 1.4324 (1.3547)	grad_norm 0.4532 (0.5528)	loss_scale 8192.0000 (6052.2985)	mem 7984MB
[2024-07-14 16:50:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:10:57 lr 0.000017	 wd 0.0000	time 0.2103 (0.2985)	loss 1.2964 (1.3657)	grad_norm 0.5820 (inf)	loss_scale 4096.0000 (6273.2757)	mem 7984MB
[2024-07-14 16:50:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:09:50 lr 0.000017	 wd 0.0000	time 0.2263 (0.2809)	loss 1.5179 (1.3636)	grad_norm 0.4907 (inf)	loss_scale 4096.0000 (5730.3142)	mem 7984MB
[2024-07-14 16:50:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:09:00 lr 0.000018	 wd 0.0000	time 0.2409 (0.2702)	loss 1.5333 (1.3621)	grad_norm 0.4650 (inf)	loss_scale 4096.0000 (5404.1038)	mem 7984MB
[2024-07-14 16:51:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:29 lr 0.000018	 wd 0.0000	time 0.3078 (0.2678)	loss 1.2675 (1.3567)	grad_norm 0.5125 (inf)	loss_scale 4096.0000 (5186.4493)	mem 7984MB
[2024-07-14 16:51:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:07:54 lr 0.000018	 wd 0.0000	time 0.2074 (0.2635)	loss 1.2557 (1.3589)	grad_norm 0.4741 (inf)	loss_scale 4096.0000 (5030.8930)	mem 7984MB
[2024-07-14 16:52:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:21 lr 0.000019	 wd 0.0000	time 0.2184 (0.2594)	loss 1.4456 (1.3571)	grad_norm 0.4955 (inf)	loss_scale 4096.0000 (4914.1773)	mem 7984MB
[2024-07-14 16:52:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:50 lr 0.000019	 wd 0.0000	time 0.2199 (0.2561)	loss 1.5191 (1.3616)	grad_norm 0.4851 (inf)	loss_scale 4096.0000 (4823.3696)	mem 7984MB
[2024-07-14 16:52:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:25 lr 0.000019	 wd 0.0000	time 0.2212 (0.2565)	loss 1.4520 (1.3625)	grad_norm 0.7126 (inf)	loss_scale 4096.0000 (4750.7053)	mem 7984MB
[2024-07-14 16:53:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:57 lr 0.000020	 wd 0.0000	time 0.2254 (0.2551)	loss 1.1636 (1.3620)	grad_norm 0.4820 (inf)	loss_scale 4096.0000 (4691.2407)	mem 7984MB
[2024-07-14 16:53:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:29 lr 0.000020	 wd 0.0000	time 0.2113 (0.2532)	loss 1.2598 (1.3611)	grad_norm 0.5063 (inf)	loss_scale 4096.0000 (4641.6786)	mem 7984MB
[2024-07-14 16:54:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:05:02 lr 0.000020	 wd 0.0000	time 0.2301 (0.2520)	loss 1.6874 (1.3638)	grad_norm 0.5424 (inf)	loss_scale 4096.0000 (4599.7356)	mem 7984MB
[2024-07-14 16:54:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:37 lr 0.000020	 wd 0.0000	time 0.2330 (0.2520)	loss 1.4220 (1.3636)	grad_norm 0.4932 (inf)	loss_scale 4096.0000 (4563.7802)	mem 7984MB
[2024-07-14 16:54:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:12 lr 0.000021	 wd 0.0000	time 0.2043 (0.2518)	loss 1.4874 (1.3617)	grad_norm 0.4756 (inf)	loss_scale 4096.0000 (4532.6156)	mem 7984MB
[2024-07-14 16:55:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:46 lr 0.000021	 wd 0.0000	time 0.2349 (0.2508)	loss 1.2725 (1.3620)	grad_norm 0.7318 (inf)	loss_scale 4096.0000 (4505.3442)	mem 7984MB
[2024-07-14 16:55:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:20 lr 0.000021	 wd 0.0000	time 0.2267 (0.2497)	loss 1.4515 (1.3617)	grad_norm 0.5675 (inf)	loss_scale 4096.0000 (4481.2792)	mem 7984MB
[2024-07-14 16:56:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:57 lr 0.000022	 wd 0.0000	time 2.9948 (0.2531)	loss 1.3452 (1.3617)	grad_norm 0.5191 (inf)	loss_scale 4096.0000 (4459.8867)	mem 7984MB
[2024-07-14 16:56:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:34 lr 0.000022	 wd 0.0000	time 0.2439 (0.2571)	loss 1.0744 (1.3602)	grad_norm 0.4817 (inf)	loss_scale 4096.0000 (4440.7449)	mem 7984MB
[2024-07-14 16:57:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:02:10 lr 0.000022	 wd 0.0000	time 0.3271 (0.2600)	loss 1.1112 (1.3583)	grad_norm 0.5179 (inf)	loss_scale 4096.0000 (4423.5162)	mem 7984MB
[2024-07-14 16:58:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:52 lr 0.000023	 wd 0.0000	time 0.5081 (0.2789)	loss 1.4401 (1.3585)	grad_norm 0.5749 (inf)	loss_scale 4096.0000 (4407.9277)	mem 7984MB
[2024-07-14 16:59:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:29 lr 0.000023	 wd 0.0000	time 0.2878 (0.2959)	loss 1.4929 (1.3585)	grad_norm 0.4880 (inf)	loss_scale 4096.0000 (4393.7556)	mem 7984MB
[2024-07-14 16:59:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:59 lr 0.000023	 wd 0.0000	time 0.2287 (0.2935)	loss 1.5779 (1.3585)	grad_norm 0.4738 (inf)	loss_scale 4096.0000 (4380.8153)	mem 7984MB
[2024-07-14 17:00:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:29 lr 0.000024	 wd 0.0000	time 0.2189 (0.2910)	loss 1.4099 (1.3574)	grad_norm 0.4588 (inf)	loss_scale 4096.0000 (4368.9529)	mem 7984MB
[2024-07-14 17:00:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1892 (0.2875)	loss 1.4459 (1.3573)	grad_norm 0.4728 (inf)	loss_scale 4096.0000 (4358.0392)	mem 7984MB
[2024-07-14 17:00:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 2 training takes 0:12:03
[2024-07-14 17:01:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 40.623 (40.623)	Loss 0.4116 (0.4116)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 17:01:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.172 Acc@5 97.288
[2024-07-14 17:01:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 17:01:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.18%
[2024-07-14 17:01:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][0/2502]	eta 12:05:55 lr 0.000024	 wd 0.0000	time 17.4084 (17.4084)	loss 1.0812 (1.0812)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:02:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:16:07 lr 0.000024	 wd 0.0000	time 0.2194 (0.4027)	loss 1.6777 (1.3441)	grad_norm 0.5156 (0.5386)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:02:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:12:53 lr 0.000025	 wd 0.0000	time 0.2118 (0.3361)	loss 1.4811 (1.3554)	grad_norm 0.4627 (0.5458)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:03:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:11:02 lr 0.000025	 wd 0.0000	time 0.2246 (0.3009)	loss 1.4068 (1.3444)	grad_norm 0.4344 (0.5347)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:03:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:09:53 lr 0.000025	 wd 0.0000	time 0.2204 (0.2825)	loss 1.5318 (1.3508)	grad_norm 0.4490 (0.5296)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:03:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:09:03 lr 0.000026	 wd 0.0000	time 0.2533 (0.2714)	loss 1.3765 (1.3481)	grad_norm 0.5134 (nan)	loss_scale 2048.0000 (3850.7305)	mem 7984MB
[2024-07-14 17:04:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:08:35 lr 0.000026	 wd 0.0000	time 0.2194 (0.2709)	loss 1.4451 (1.3476)	grad_norm 0.4918 (nan)	loss_scale 2048.0000 (3550.7754)	mem 7984MB
[2024-07-14 17:04:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:07:59 lr 0.000026	 wd 0.0000	time 0.2219 (0.2658)	loss 1.4861 (1.3495)	grad_norm 0.5040 (nan)	loss_scale 2048.0000 (3336.3994)	mem 7984MB
[2024-07-14 17:05:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:24 lr 0.000027	 wd 0.0000	time 0.2294 (0.2614)	loss 1.1330 (1.3500)	grad_norm 0.4867 (nan)	loss_scale 2048.0000 (3175.5506)	mem 7984MB
[2024-07-14 17:05:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:06:53 lr 0.000027	 wd 0.0000	time 0.2364 (0.2580)	loss 1.3420 (1.3513)	grad_norm 0.8476 (nan)	loss_scale 2048.0000 (3050.4062)	mem 7984MB
[2024-07-14 17:05:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:29 lr 0.000027	 wd 0.0000	time 0.2317 (0.2592)	loss 1.5954 (1.3546)	grad_norm 0.4606 (nan)	loss_scale 2048.0000 (2950.2657)	mem 7984MB
[2024-07-14 17:06:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:06:00 lr 0.000028	 wd 0.0000	time 0.2362 (0.2572)	loss 1.3849 (1.3568)	grad_norm 0.4997 (nan)	loss_scale 2048.0000 (2868.3161)	mem 7984MB
[2024-07-14 17:06:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:32 lr 0.000028	 wd 0.0000	time 0.2480 (0.2552)	loss 1.3052 (1.3557)	grad_norm 0.4129 (nan)	loss_scale 2048.0000 (2800.0133)	mem 7984MB
[2024-07-14 17:07:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:05:04 lr 0.000028	 wd 0.0000	time 0.2687 (0.2535)	loss 1.2186 (1.3586)	grad_norm 0.5211 (nan)	loss_scale 2048.0000 (2742.2106)	mem 7984MB
[2024-07-14 17:07:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:39 lr 0.000028	 wd 0.0000	time 0.3640 (0.2535)	loss 1.2258 (1.3594)	grad_norm 0.5291 (nan)	loss_scale 2048.0000 (2692.6595)	mem 7984MB
[2024-07-14 17:07:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:13 lr 0.000029	 wd 0.0000	time 0.2170 (0.2527)	loss 1.3660 (1.3597)	grad_norm 0.4615 (nan)	loss_scale 2048.0000 (2649.7109)	mem 7984MB
[2024-07-14 17:08:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:46 lr 0.000029	 wd 0.0000	time 0.2155 (0.2515)	loss 1.4086 (1.3585)	grad_norm 0.4635 (nan)	loss_scale 2048.0000 (2612.1274)	mem 7984MB
[2024-07-14 17:08:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:20 lr 0.000029	 wd 0.0000	time 0.2229 (0.2505)	loss 1.0691 (1.3576)	grad_norm 0.4864 (nan)	loss_scale 2048.0000 (2578.9630)	mem 7984MB
[2024-07-14 17:09:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:56 lr 0.000030	 wd 0.0000	time 0.4411 (0.2517)	loss 1.6162 (1.3592)	grad_norm 0.4995 (nan)	loss_scale 2048.0000 (2549.4814)	mem 7984MB
[2024-07-14 17:09:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:31 lr 0.000030	 wd 0.0000	time 0.2259 (0.2511)	loss 1.5248 (1.3590)	grad_norm 0.4910 (nan)	loss_scale 2048.0000 (2523.1015)	mem 7984MB
[2024-07-14 17:09:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:05 lr 0.000030	 wd 0.0000	time 0.2293 (0.2503)	loss 1.1623 (1.3597)	grad_norm 0.4902 (nan)	loss_scale 2048.0000 (2499.3583)	mem 7984MB
[2024-07-14 17:10:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:40 lr 0.000031	 wd 0.0000	time 0.2364 (0.2496)	loss 1.2103 (1.3581)	grad_norm 0.4598 (nan)	loss_scale 2048.0000 (2477.8753)	mem 7984MB
[2024-07-14 17:10:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:16 lr 0.000031	 wd 0.0000	time 0.3064 (0.2520)	loss 1.3536 (1.3592)	grad_norm 0.6635 (nan)	loss_scale 2048.0000 (2458.3444)	mem 7984MB
[2024-07-14 17:11:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:51 lr 0.000031	 wd 0.0000	time 0.3093 (0.2554)	loss 1.5237 (1.3599)	grad_norm 0.4645 (nan)	loss_scale 2048.0000 (2440.5111)	mem 7984MB
[2024-07-14 17:11:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:26 lr 0.000032	 wd 0.0000	time 0.2481 (0.2579)	loss 0.9787 (1.3592)	grad_norm 0.4788 (nan)	loss_scale 2048.0000 (2424.1633)	mem 7984MB
[2024-07-14 17:12:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000032	 wd 0.0000	time 0.1943 (0.2565)	loss 1.5435 (1.3596)	grad_norm 0.5023 (nan)	loss_scale 2048.0000 (2409.1228)	mem 7984MB
[2024-07-14 17:12:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 3 training takes 0:11:01
[2024-07-14 17:13:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 62.909 (62.909)	Loss 0.4158 (0.4158)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 17:13:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.206 Acc@5 97.270
[2024-07-14 17:13:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 17:13:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.21%
[2024-07-14 17:13:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft/ckpt_epoch_best.pth saving......
[2024-07-14 17:14:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft/ckpt_epoch_best.pth saved !!!
[2024-07-14 17:14:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][0/2502]	eta 14:20:11 lr 0.000032	 wd 0.0000	time 20.6280 (20.6280)	loss 1.4249 (1.4249)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:14:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:17:19 lr 0.000032	 wd 0.0000	time 0.2158 (0.4329)	loss 1.1425 (1.3697)	grad_norm 0.4631 (0.5185)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:15:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:12:46 lr 0.000033	 wd 0.0000	time 0.2769 (0.3329)	loss 1.1296 (1.3710)	grad_norm 0.5059 (0.5078)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:15:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:11:19 lr 0.000033	 wd 0.0000	time 0.2530 (0.3085)	loss 1.1029 (1.3707)	grad_norm 0.5005 (0.5145)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:15:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:10:07 lr 0.000033	 wd 0.0000	time 0.2152 (0.2890)	loss 1.5870 (1.3664)	grad_norm 0.4717 (0.5221)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:16:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:09:14 lr 0.000034	 wd 0.0000	time 0.2400 (0.2769)	loss 1.3364 (1.3596)	grad_norm 0.4894 (0.5220)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:16:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:08:32 lr 0.000034	 wd 0.0000	time 0.2376 (0.2693)	loss 1.4777 (1.3555)	grad_norm 0.4649 (0.5218)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:17:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:08:03 lr 0.000034	 wd 0.0000	time 0.2294 (0.2682)	loss 1.2697 (1.3554)	grad_norm 0.4818 (0.5266)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:17:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:29 lr 0.000035	 wd 0.0000	time 0.1913 (0.2640)	loss 1.4656 (1.3548)	grad_norm 0.5089 (0.5242)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:17:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:06:57 lr 0.000035	 wd 0.0000	time 0.2449 (0.2604)	loss 1.4728 (1.3559)	grad_norm 0.4425 (0.5223)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:18:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:26 lr 0.000035	 wd 0.0000	time 0.2080 (0.2574)	loss 1.5214 (1.3566)	grad_norm 0.4640 (0.5206)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:18:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:06:00 lr 0.000036	 wd 0.0000	time 0.4298 (0.2573)	loss 1.5254 (1.3575)	grad_norm 0.5611 (0.5199)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:19:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:33 lr 0.000036	 wd 0.0000	time 0.2336 (0.2559)	loss 1.0738 (1.3561)	grad_norm 0.5145 (0.5203)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:19:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:05:05 lr 0.000036	 wd 0.0000	time 0.2038 (0.2540)	loss 1.5685 (1.3554)	grad_norm 0.5138 (0.5217)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:19:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:38 lr 0.000036	 wd 0.0000	time 0.2494 (0.2525)	loss 1.4966 (1.3555)	grad_norm 0.5298 (0.5220)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:20:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:12 lr 0.000037	 wd 0.0000	time 0.2549 (0.2523)	loss 1.2552 (1.3580)	grad_norm 0.4613 (0.5215)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:20:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:47 lr 0.000037	 wd 0.0000	time 0.2508 (0.2524)	loss 1.0633 (1.3576)	grad_norm 0.4595 (0.5201)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:21:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:21 lr 0.000037	 wd 0.0000	time 0.2060 (0.2514)	loss 1.5388 (1.3570)	grad_norm 0.4830 (0.5196)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:21:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:55 lr 0.000038	 wd 0.0000	time 0.2460 (0.2505)	loss 1.3674 (1.3569)	grad_norm 0.5181 (0.5194)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:21:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:30 lr 0.000038	 wd 0.0000	time 0.3830 (0.2506)	loss 1.6523 (1.3567)	grad_norm 0.4976 (0.5194)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 17:22:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:02:05 lr 0.000038	 wd 0.0000	time 0.2123 (0.2508)	loss 1.4553 (1.3561)	grad_norm 0.5475 (0.5205)	loss_scale 4096.0000 (2111.4563)	mem 7984MB
[2024-07-14 17:22:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:40 lr 0.000039	 wd 0.0000	time 0.2113 (0.2502)	loss 1.4309 (1.3566)	grad_norm 0.5348 (0.5195)	loss_scale 4096.0000 (2205.9134)	mem 7984MB
[2024-07-14 17:23:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:15 lr 0.000039	 wd 0.0000	time 0.2343 (0.2494)	loss 0.9831 (1.3542)	grad_norm 0.4403 (0.5193)	loss_scale 4096.0000 (2291.7874)	mem 7984MB
[2024-07-14 17:23:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:50 lr 0.000039	 wd 0.0000	time 0.3146 (0.2493)	loss 1.3025 (1.3544)	grad_norm 0.4766 (0.5184)	loss_scale 4096.0000 (2370.1973)	mem 7984MB
[2024-07-14 17:24:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:26 lr 0.000040	 wd 0.0000	time 0.5222 (0.2574)	loss 1.5691 (1.3543)	grad_norm 0.6569 (0.5181)	loss_scale 4096.0000 (2442.0758)	mem 7984MB
[2024-07-14 17:24:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1832 (0.2573)	loss 0.9211 (1.3542)	grad_norm 0.4460 (0.5176)	loss_scale 4096.0000 (2508.2063)	mem 7984MB
[2024-07-14 17:24:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 4 training takes 0:10:49
[2024-07-14 17:26:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 99.388 (99.388)	Loss 0.4143 (0.4143)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 17:26:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.138 Acc@5 97.294
[2024-07-14 17:26:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 17:26:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.21%
[2024-07-14 17:27:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][0/2502]	eta 18:10:54 lr 0.000040	 wd 0.0000	time 26.1610 (26.1610)	loss 1.5977 (1.5977)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:27:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:19:40 lr 0.000040	 wd 0.0000	time 0.2262 (0.4914)	loss 1.2855 (1.3746)	grad_norm 0.5442 (0.5117)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:28:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:13:44 lr 0.000040	 wd 0.0000	time 0.2048 (0.3583)	loss 1.4582 (1.3782)	grad_norm 0.5104 (0.5187)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:28:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:11:57 lr 0.000040	 wd 0.0000	time 0.2535 (0.3259)	loss 1.6167 (1.3673)	grad_norm 0.6620 (0.5319)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:28:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:10:35 lr 0.000040	 wd 0.0000	time 0.2442 (0.3023)	loss 0.9967 (1.3688)	grad_norm 0.5061 (0.5239)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:29:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:09:34 lr 0.000040	 wd 0.0000	time 0.2023 (0.2868)	loss 1.5059 (1.3641)	grad_norm 0.4491 (0.5252)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:29:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:47 lr 0.000040	 wd 0.0000	time 0.2286 (0.2773)	loss 1.4239 (1.3651)	grad_norm 0.4949 (0.5231)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:30:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:08:11 lr 0.000040	 wd 0.0000	time 0.2314 (0.2726)	loss 1.4543 (1.3629)	grad_norm 0.5167 (0.5205)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:30:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:38 lr 0.000040	 wd 0.0000	time 0.2217 (0.2692)	loss 0.9217 (1.3567)	grad_norm 0.4575 (0.5204)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:30:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:07:04 lr 0.000040	 wd 0.0000	time 0.2320 (0.2649)	loss 0.9072 (1.3560)	grad_norm 0.5130 (0.5241)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:31:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:32 lr 0.000040	 wd 0.0000	time 0.2467 (0.2613)	loss 1.5019 (1.3589)	grad_norm 0.4578 (0.5243)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:31:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:06:03 lr 0.000040	 wd 0.0000	time 0.2562 (0.2595)	loss 1.5373 (1.3550)	grad_norm 0.5488 (0.5264)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:32:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:37 lr 0.000040	 wd 0.0000	time 0.2075 (0.2591)	loss 1.5406 (1.3530)	grad_norm 0.6964 (0.5248)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:32:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:05:08 lr 0.000040	 wd 0.0000	time 0.2394 (0.2570)	loss 1.4836 (1.3535)	grad_norm 0.4740 (0.5258)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:32:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:41 lr 0.000040	 wd 0.0000	time 0.2326 (0.2551)	loss 1.5292 (1.3530)	grad_norm 0.4984 (0.5240)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:33:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:04:14 lr 0.000040	 wd 0.0000	time 0.2278 (0.2542)	loss 1.3840 (1.3531)	grad_norm 0.5025 (0.5241)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:33:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:49 lr 0.000040	 wd 0.0000	time 0.2551 (0.2546)	loss 1.4321 (1.3551)	grad_norm 0.4820 (0.5235)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:34:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:23 lr 0.000040	 wd 0.0000	time 0.2095 (0.2533)	loss 1.3341 (1.3547)	grad_norm 0.4500 (0.5224)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:34:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:57 lr 0.000040	 wd 0.0000	time 0.1972 (0.2524)	loss 0.9779 (1.3541)	grad_norm 0.5202 (0.5225)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:34:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:31 lr 0.000040	 wd 0.0000	time 0.2578 (0.2519)	loss 1.4617 (1.3562)	grad_norm 0.5163 (0.5250)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:35:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:02:06 lr 0.000040	 wd 0.0000	time 0.2066 (0.2525)	loss 1.5090 (1.3571)	grad_norm 0.5816 (0.5260)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:35:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:41 lr 0.000040	 wd 0.0000	time 0.2259 (0.2516)	loss 1.5055 (1.3576)	grad_norm 0.4590 (0.5273)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:36:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:15 lr 0.000040	 wd 0.0000	time 0.2342 (0.2508)	loss 1.2285 (1.3556)	grad_norm 0.4650 (0.5268)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:36:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:50 lr 0.000040	 wd 0.0000	time 0.2408 (0.2505)	loss 0.8942 (1.3547)	grad_norm 0.4368 (0.5258)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:37:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:26 lr 0.000040	 wd 0.0000	time 0.2717 (0.2566)	loss 1.4980 (1.3549)	grad_norm 0.5384 (0.5266)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:37:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1813 (0.2552)	loss 1.5092 (1.3548)	grad_norm 0.4700 (0.5271)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:37:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 5 training takes 0:10:44
[2024-07-14 17:39:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 89.754 (89.754)	Loss 0.4084 (0.4084)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 17:39:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.158 Acc@5 97.288
[2024-07-14 17:39:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 17:39:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.21%
[2024-07-14 17:40:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][0/2502]	eta 1 day, 5:30:16 lr 0.000040	 wd 0.0000	time 42.4526 (42.4526)	loss 1.5599 (1.5599)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:40:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:26:01 lr 0.000040	 wd 0.0000	time 0.1967 (0.6503)	loss 1.2114 (1.3259)	grad_norm 0.5096 (0.5031)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:40:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:16:51 lr 0.000040	 wd 0.0000	time 0.2150 (0.4396)	loss 1.5761 (1.3473)	grad_norm 0.4631 (0.5110)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:41:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:13:43 lr 0.000040	 wd 0.0000	time 0.2215 (0.3739)	loss 1.4564 (1.3578)	grad_norm 0.5560 (0.5154)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:41:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:12:00 lr 0.000040	 wd 0.0000	time 0.2012 (0.3426)	loss 1.3657 (1.3513)	grad_norm 0.5864 (0.5144)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:42:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:10:38 lr 0.000040	 wd 0.0000	time 0.2153 (0.3190)	loss 1.3547 (1.3458)	grad_norm 0.4967 (0.5171)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:42:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:09:38 lr 0.000040	 wd 0.0000	time 0.1923 (0.3041)	loss 1.5832 (1.3498)	grad_norm 0.4641 (0.5233)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:42:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:08:50 lr 0.000040	 wd 0.0000	time 0.2353 (0.2945)	loss 1.4036 (1.3522)	grad_norm 0.4989 (0.5208)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:43:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:08:15 lr 0.000040	 wd 0.0000	time 0.2149 (0.2912)	loss 1.0009 (1.3514)	grad_norm 0.6481 (0.5191)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:43:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:07:35 lr 0.000040	 wd 0.0000	time 0.2027 (0.2843)	loss 1.6447 (1.3553)	grad_norm 0.4318 (0.5183)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 17:44:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:58 lr 0.000040	 wd 0.0000	time 0.2296 (0.2789)	loss 1.3008 (1.3508)	grad_norm 0.4644 (0.5181)	loss_scale 8192.0000 (4366.0659)	mem 7984MB
[2024-07-14 17:44:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:06:25 lr 0.000040	 wd 0.0000	time 0.2383 (0.2750)	loss 1.1943 (1.3500)	grad_norm 0.5279 (0.5164)	loss_scale 8192.0000 (4713.5622)	mem 7984MB
[2024-07-14 17:44:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:55 lr 0.000040	 wd 0.0000	time 0.2355 (0.2734)	loss 1.0477 (1.3516)	grad_norm 0.4647 (0.5164)	loss_scale 8192.0000 (5003.1907)	mem 7984MB
[2024-07-14 17:45:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:05:25 lr 0.000040	 wd 0.0000	time 0.2234 (0.2704)	loss 1.3971 (1.3508)	grad_norm 0.6316 (0.5164)	loss_scale 8192.0000 (5248.2952)	mem 7984MB
[2024-07-14 17:45:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:55 lr 0.000040	 wd 0.0000	time 0.2261 (0.2677)	loss 1.6451 (1.3494)	grad_norm 0.5054 (0.5183)	loss_scale 8192.0000 (5458.4097)	mem 7984MB
[2024-07-14 17:46:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:26 lr 0.000040	 wd 0.0000	time 0.2331 (0.2656)	loss 1.4584 (1.3510)	grad_norm 0.4453 (0.5177)	loss_scale 8192.0000 (5640.5276)	mem 7984MB
[2024-07-14 17:46:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:59 lr 0.000040	 wd 0.0000	time 0.2622 (0.2652)	loss 1.5433 (1.3498)	grad_norm 0.5425 (0.5175)	loss_scale 8192.0000 (5799.8951)	mem 7984MB
[2024-07-14 17:46:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:31 lr 0.000040	 wd 0.0000	time 0.2097 (0.2635)	loss 1.5032 (1.3491)	grad_norm 0.6171 (0.5170)	loss_scale 8192.0000 (5940.5244)	mem 7984MB
[2024-07-14 17:47:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:03:03 lr 0.000040	 wd 0.0000	time 0.2479 (0.2620)	loss 1.1516 (1.3489)	grad_norm 0.4983 (0.5176)	loss_scale 8192.0000 (6065.5369)	mem 7984MB
[2024-07-14 17:47:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:36 lr 0.000040	 wd 0.0000	time 0.2353 (0.2606)	loss 1.2833 (1.3483)	grad_norm 0.5114 (0.5185)	loss_scale 8192.0000 (6177.3972)	mem 7984MB
[2024-07-14 17:48:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:02:11 lr 0.000039	 wd 0.0000	time 0.2122 (0.2610)	loss 0.9837 (1.3482)	grad_norm 0.4869 (0.5192)	loss_scale 8192.0000 (6278.0770)	mem 7984MB
[2024-07-14 17:48:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:44 lr 0.000039	 wd 0.0000	time 0.2142 (0.2603)	loss 1.5556 (1.3479)	grad_norm 0.5548 (0.5199)	loss_scale 8192.0000 (6369.1728)	mem 7984MB
[2024-07-14 17:48:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:18 lr 0.000039	 wd 0.0000	time 0.2168 (0.2591)	loss 1.2481 (1.3483)	grad_norm 0.4983 (0.5199)	loss_scale 8192.0000 (6451.9909)	mem 7984MB
[2024-07-14 17:49:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:52 lr 0.000039	 wd 0.0000	time 0.2448 (0.2581)	loss 1.4393 (1.3490)	grad_norm 0.5055 (0.5198)	loss_scale 8192.0000 (6527.6106)	mem 7984MB
[2024-07-14 17:49:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:26 lr 0.000039	 wd 0.0000	time 0.2950 (0.2611)	loss 1.1838 (1.3483)	grad_norm 0.4316 (0.5196)	loss_scale 8192.0000 (6596.9313)	mem 7984MB
[2024-07-14 17:50:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1699 (0.2601)	loss 1.0230 (1.3490)	grad_norm 0.5015 (0.5209)	loss_scale 8192.0000 (6660.7085)	mem 7984MB
[2024-07-14 17:50:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 6 training takes 0:10:58
[2024-07-14 17:51:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 72.332 (72.332)	Loss 0.4153 (0.4153)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 17:51:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.114 Acc@5 97.298
[2024-07-14 17:51:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-14 17:51:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.21%
[2024-07-14 17:52:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][0/2502]	eta 22:35:49 lr 0.000039	 wd 0.0000	time 32.5136 (32.5136)	loss 1.5957 (1.5957)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 17:52:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:25:39 lr 0.000039	 wd 0.0000	time 0.2378 (0.6410)	loss 1.2245 (1.3745)	grad_norm 0.4911 (0.5242)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 17:53:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:16:43 lr 0.000039	 wd 0.0000	time 0.1936 (0.4360)	loss 1.4313 (1.3489)	grad_norm 0.5880 (0.5214)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 17:53:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:13:26 lr 0.000039	 wd 0.0000	time 0.2432 (0.3663)	loss 1.3100 (1.3463)	grad_norm 0.4761 (0.5140)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 17:54:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:11:35 lr 0.000039	 wd 0.0000	time 0.2429 (0.3309)	loss 1.3350 (1.3483)	grad_norm 0.5489 (0.5143)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 17:54:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:10:29 lr 0.000039	 wd 0.0000	time 0.2052 (0.3146)	loss 1.4364 (1.3436)	grad_norm 0.5407 (0.5147)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 17:54:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:09:32 lr 0.000039	 wd 0.0000	time 0.1985 (0.3011)	loss 1.3166 (1.3474)	grad_norm 0.4413 (0.5162)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 17:55:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:08:44 lr 0.000039	 wd 0.0000	time 0.2590 (0.2912)	loss 1.4800 (1.3511)	grad_norm 0.6364 (0.5177)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 17:55:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:08:01 lr 0.000039	 wd 0.0000	time 0.2251 (0.2832)	loss 0.8865 (1.3535)	grad_norm 0.4910 (0.5183)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 17:56:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:07:28 lr 0.000039	 wd 0.0000	time 0.2276 (0.2798)	loss 1.0866 (1.3554)	grad_norm 0.4694 (0.5176)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 17:56:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:54 lr 0.000039	 wd 0.0000	time 0.2462 (0.2762)	loss 1.1694 (1.3514)	grad_norm 0.4468 (0.5189)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 17:56:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:06:21 lr 0.000039	 wd 0.0000	time 0.2140 (0.2721)	loss 1.2282 (1.3498)	grad_norm 0.4467 (0.5192)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 17:57:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:49 lr 0.000039	 wd 0.0000	time 0.2117 (0.2684)	loss 1.4081 (1.3486)	grad_norm 0.4740 (0.5216)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 17:57:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:05:20 lr 0.000039	 wd 0.0000	time 0.2349 (0.2668)	loss 1.4643 (1.3487)	grad_norm 0.5485 (0.5203)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 17:58:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:52 lr 0.000039	 wd 0.0000	time 0.2272 (0.2653)	loss 1.4050 (1.3495)	grad_norm 0.4630 (0.5209)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 17:58:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:23 lr 0.000039	 wd 0.0000	time 0.2242 (0.2631)	loss 1.6420 (1.3489)	grad_norm 0.5516 (0.5223)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 17:58:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:55 lr 0.000039	 wd 0.0000	time 0.2094 (0.2611)	loss 1.5194 (1.3507)	grad_norm 0.5148 (0.5209)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 17:59:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:28 lr 0.000039	 wd 0.0000	time 0.2396 (0.2602)	loss 1.5645 (1.3510)	grad_norm 0.5334 (0.5205)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 17:59:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:03:02 lr 0.000039	 wd 0.0000	time 0.2504 (0.2605)	loss 1.1217 (1.3505)	grad_norm 0.6052 (0.5207)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:00:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:36 lr 0.000039	 wd 0.0000	time 0.2121 (0.2592)	loss 1.2996 (1.3500)	grad_norm 0.5283 (0.5215)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:00:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:02:09 lr 0.000039	 wd 0.0000	time 0.2258 (0.2579)	loss 1.4161 (1.3510)	grad_norm 0.8557 (0.5218)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:00:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:43 lr 0.000039	 wd 0.0000	time 0.2408 (0.2573)	loss 1.5023 (1.3521)	grad_norm 0.6990 (0.5210)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:01:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:17 lr 0.000039	 wd 0.0000	time 0.2338 (0.2569)	loss 1.1032 (1.3502)	grad_norm 0.4948 (inf)	loss_scale 4096.0000 (8009.6247)	mem 7984MB
[2024-07-14 18:01:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:51 lr 0.000039	 wd 0.0000	time 0.2328 (0.2558)	loss 1.5507 (1.3506)	grad_norm 0.4655 (inf)	loss_scale 4096.0000 (7839.5411)	mem 7984MB
[2024-07-14 18:02:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:25 lr 0.000039	 wd 0.0000	time 0.2214 (0.2548)	loss 1.4467 (1.3501)	grad_norm 0.5022 (inf)	loss_scale 4096.0000 (7683.6252)	mem 7984MB
[2024-07-14 18:02:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1715 (0.2530)	loss 1.2693 (1.3504)	grad_norm 0.4841 (inf)	loss_scale 4096.0000 (7540.1775)	mem 7984MB
[2024-07-14 18:02:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 7 training takes 0:10:37
[2024-07-14 18:03:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 33.679 (33.679)	Loss 0.4177 (0.4177)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 7984MB
[2024-07-14 18:03:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.222 Acc@5 97.304
[2024-07-14 18:03:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 18:03:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.22%
[2024-07-14 18:03:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft/ckpt_epoch_best.pth saving......
[2024-07-14 18:03:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft/ckpt_epoch_best.pth saved !!!
[2024-07-14 18:03:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][0/2502]	eta 10:42:56 lr 0.000039	 wd 0.0000	time 15.4184 (15.4184)	loss 1.4084 (1.4084)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:03:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:15:40 lr 0.000039	 wd 0.0000	time 0.2499 (0.3917)	loss 1.4405 (1.3884)	grad_norm 0.4722 (0.5438)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:04:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:12:28 lr 0.000039	 wd 0.0000	time 0.2273 (0.3251)	loss 1.5265 (1.3639)	grad_norm 0.4772 (0.5443)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:04:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:10:44 lr 0.000038	 wd 0.0000	time 0.2102 (0.2927)	loss 1.3472 (1.3611)	grad_norm 0.5418 (0.5343)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:05:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:09:40 lr 0.000038	 wd 0.0000	time 0.2171 (0.2760)	loss 1.6177 (1.3573)	grad_norm 0.5001 (0.5307)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:05:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:08:53 lr 0.000038	 wd 0.0000	time 0.2408 (0.2665)	loss 1.4340 (1.3601)	grad_norm 0.4743 (0.5269)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:05:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:22 lr 0.000038	 wd 0.0000	time 0.2369 (0.2641)	loss 1.5108 (1.3643)	grad_norm 0.4688 (0.5345)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:06:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:47 lr 0.000038	 wd 0.0000	time 0.2003 (0.2592)	loss 1.6319 (1.3625)	grad_norm 0.4974 (0.5360)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:06:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:14 lr 0.000038	 wd 0.0000	time 0.2106 (0.2554)	loss 1.4684 (1.3601)	grad_norm 0.4427 (0.5343)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:07:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:44 lr 0.000038	 wd 0.0000	time 0.2361 (0.2527)	loss 1.6480 (1.3601)	grad_norm 0.5246 (0.5348)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:07:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:19 lr 0.000038	 wd 0.0000	time 0.3298 (0.2528)	loss 1.4966 (1.3565)	grad_norm 0.4519 (0.5341)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:07:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:52 lr 0.000038	 wd 0.0000	time 0.2301 (0.2514)	loss 1.3286 (1.3534)	grad_norm 0.5229 (0.5329)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:08:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:25 lr 0.000038	 wd 0.0000	time 0.2260 (0.2497)	loss 1.4468 (1.3537)	grad_norm 1.5535 (0.5346)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:08:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:58 lr 0.000038	 wd 0.0000	time 0.2368 (0.2481)	loss 1.1679 (1.3523)	grad_norm 0.4907 (0.5338)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:09:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:34 lr 0.000038	 wd 0.0000	time 0.2182 (0.2491)	loss 0.9653 (1.3540)	grad_norm 0.5762 (0.5349)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:09:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:04:08 lr 0.000038	 wd 0.0000	time 0.2225 (0.2484)	loss 0.8243 (1.3517)	grad_norm 0.5812 (0.5336)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:09:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:43 lr 0.000038	 wd 0.0000	time 0.2158 (0.2475)	loss 1.2157 (1.3489)	grad_norm 0.6464 (0.5322)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:10:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:17 lr 0.000038	 wd 0.0000	time 0.2402 (0.2466)	loss 1.1714 (1.3507)	grad_norm 0.4818 (0.5316)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:10:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:53 lr 0.000038	 wd 0.0000	time 0.2139 (0.2478)	loss 1.5327 (1.3517)	grad_norm 0.4939 (0.5315)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:11:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:29 lr 0.000038	 wd 0.0000	time 0.1958 (0.2478)	loss 1.2923 (1.3509)	grad_norm 0.4856 (0.5299)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:11:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:02:04 lr 0.000038	 wd 0.0000	time 0.2185 (0.2471)	loss 1.6719 (1.3529)	grad_norm 0.4839 (0.5291)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:11:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:39 lr 0.000038	 wd 0.0000	time 0.2052 (0.2464)	loss 1.4046 (1.3520)	grad_norm 0.4734 (0.5285)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:12:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:14 lr 0.000038	 wd 0.0000	time 0.3411 (0.2467)	loss 1.5460 (1.3506)	grad_norm 0.4825 (0.5289)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:12:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:49 lr 0.000038	 wd 0.0000	time 0.2197 (0.2464)	loss 1.4765 (1.3513)	grad_norm 0.5861 (0.5287)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:13:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:25 lr 0.000038	 wd 0.0000	time 0.2326 (0.2459)	loss 1.3018 (1.3528)	grad_norm 0.5034 (0.5282)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:13:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000038	 wd 0.0000	time 0.1792 (0.2442)	loss 1.7372 (1.3542)	grad_norm 0.4715 (0.5282)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:13:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 8 training takes 0:10:15
[2024-07-14 18:14:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 35.880 (35.880)	Loss 0.4187 (0.4187)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 18:14:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.172 Acc@5 97.286
[2024-07-14 18:14:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 18:14:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.22%
[2024-07-14 18:14:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][0/2502]	eta 11:47:50 lr 0.000038	 wd 0.0000	time 16.9746 (16.9746)	loss 1.3462 (1.3462)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:14:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:15:38 lr 0.000038	 wd 0.0000	time 0.2294 (0.3909)	loss 1.2296 (1.3178)	grad_norm 0.5021 (0.5934)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:15:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:12:23 lr 0.000037	 wd 0.0000	time 0.2831 (0.3228)	loss 1.4791 (1.3312)	grad_norm 0.5173 (0.5727)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:15:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:53 lr 0.000037	 wd 0.0000	time 0.2175 (0.2967)	loss 1.4309 (1.3433)	grad_norm 0.4654 (0.5525)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:16:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:46 lr 0.000037	 wd 0.0000	time 0.1980 (0.2792)	loss 1.5744 (1.3383)	grad_norm 0.4404 (0.5441)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:16:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:08:56 lr 0.000037	 wd 0.0000	time 0.2060 (0.2682)	loss 1.3752 (1.3450)	grad_norm 0.4788 (0.5396)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:16:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:21 lr 0.000037	 wd 0.0000	time 0.2703 (0.2638)	loss 1.4926 (1.3396)	grad_norm 0.4589 (0.5355)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:17:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:51 lr 0.000037	 wd 0.0000	time 0.2028 (0.2617)	loss 1.5110 (1.3412)	grad_norm 0.4577 (0.5371)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:17:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:18 lr 0.000037	 wd 0.0000	time 0.2562 (0.2578)	loss 1.3813 (1.3441)	grad_norm 0.4771 (0.5339)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:18:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:47 lr 0.000037	 wd 0.0000	time 0.2168 (0.2546)	loss 1.5788 (1.3412)	grad_norm 0.5747 (0.5308)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:18:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:20 lr 0.000037	 wd 0.0000	time 0.2277 (0.2532)	loss 1.4576 (1.3439)	grad_norm 0.5944 (0.5291)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 18:18:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:55 lr 0.000037	 wd 0.0000	time 0.2750 (0.2534)	loss 1.3775 (1.3469)	grad_norm 0.7011 (0.5291)	loss_scale 8192.0000 (4103.4405)	mem 7984MB
[2024-07-14 18:19:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:27 lr 0.000037	 wd 0.0000	time 0.2227 (0.2515)	loss 1.5431 (1.3480)	grad_norm 0.4491 (0.5285)	loss_scale 8192.0000 (4443.8701)	mem 7984MB
[2024-07-14 18:19:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:05:00 lr 0.000037	 wd 0.0000	time 0.2077 (0.2500)	loss 0.9546 (1.3460)	grad_norm 0.5557 (0.5278)	loss_scale 8192.0000 (4731.9662)	mem 7984MB
[2024-07-14 18:20:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:34 lr 0.000037	 wd 0.0000	time 0.2211 (0.2489)	loss 1.3354 (1.3474)	grad_norm 0.4649 (0.5272)	loss_scale 8192.0000 (4978.9350)	mem 7984MB
[2024-07-14 18:20:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:04:10 lr 0.000037	 wd 0.0000	time 0.2715 (0.2496)	loss 1.4553 (1.3493)	grad_norm 0.5079 (0.5267)	loss_scale 8192.0000 (5192.9967)	mem 7984MB
[2024-07-14 18:20:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:44 lr 0.000037	 wd 0.0000	time 0.2139 (0.2486)	loss 0.9164 (1.3484)	grad_norm 0.4917 (0.5272)	loss_scale 8192.0000 (5380.3173)	mem 7984MB
[2024-07-14 18:21:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:18 lr 0.000037	 wd 0.0000	time 0.2253 (0.2476)	loss 1.1025 (1.3496)	grad_norm 0.5202 (0.5278)	loss_scale 8192.0000 (5545.6132)	mem 7984MB
[2024-07-14 18:21:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:53 lr 0.000037	 wd 0.0000	time 0.2573 (0.2470)	loss 1.5224 (1.3501)	grad_norm 0.5003 (0.5265)	loss_scale 8192.0000 (5692.5530)	mem 7984MB
[2024-07-14 18:22:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:29 lr 0.000037	 wd 0.0000	time 0.2583 (0.2481)	loss 1.3122 (1.3488)	grad_norm 0.4981 (0.5269)	loss_scale 8192.0000 (5824.0337)	mem 7984MB
[2024-07-14 18:22:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:02:04 lr 0.000037	 wd 0.0000	time 0.1968 (0.2476)	loss 1.4721 (1.3490)	grad_norm 0.5516 (0.5282)	loss_scale 8192.0000 (5942.3728)	mem 7984MB
[2024-07-14 18:22:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:39 lr 0.000036	 wd 0.0000	time 0.2358 (0.2470)	loss 1.0739 (1.3491)	grad_norm 0.5134 (0.5279)	loss_scale 8192.0000 (6049.4469)	mem 7984MB
[2024-07-14 18:23:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:14 lr 0.000036	 wd 0.0000	time 0.2137 (0.2465)	loss 1.4824 (1.3501)	grad_norm 0.5076 (0.5300)	loss_scale 8192.0000 (6146.7915)	mem 7984MB
[2024-07-14 18:23:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:49 lr 0.000036	 wd 0.0000	time 0.2052 (0.2470)	loss 1.4275 (1.3507)	grad_norm 0.5212 (0.5295)	loss_scale 8192.0000 (6235.6749)	mem 7984MB
[2024-07-14 18:24:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:25 lr 0.000036	 wd 0.0000	time 0.2180 (0.2465)	loss 1.2580 (1.3504)	grad_norm 0.4941 (0.5289)	loss_scale 8192.0000 (6317.1545)	mem 7984MB
[2024-07-14 18:24:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000036	 wd 0.0000	time 0.1719 (0.2447)	loss 1.1210 (1.3515)	grad_norm 0.5623 (0.5287)	loss_scale 8192.0000 (6392.1184)	mem 7984MB
[2024-07-14 18:24:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 9 training takes 0:10:16
[2024-07-14 18:25:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 26.345 (26.345)	Loss 0.4099 (0.4099)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 18:25:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.152 Acc@5 97.284
[2024-07-14 18:25:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 18:25:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.22%
[2024-07-14 18:25:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][0/2502]	eta 12:18:45 lr 0.000036	 wd 0.0000	time 17.7162 (17.7162)	loss 1.2831 (1.2831)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:26:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:16:06 lr 0.000036	 wd 0.0000	time 0.2436 (0.4023)	loss 1.3411 (1.3326)	grad_norm 0.4531 (0.5279)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:26:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:12:02 lr 0.000036	 wd 0.0000	time 0.2554 (0.3140)	loss 1.2880 (1.3532)	grad_norm 0.8054 (0.5170)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:26:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:53 lr 0.000036	 wd 0.0000	time 0.2446 (0.2966)	loss 0.8730 (1.3502)	grad_norm 0.5084 (0.5286)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:27:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:48 lr 0.000036	 wd 0.0000	time 0.2142 (0.2800)	loss 1.5108 (1.3535)	grad_norm 0.5119 (0.5196)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:27:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:08:58 lr 0.000036	 wd 0.0000	time 0.2160 (0.2690)	loss 1.3987 (1.3495)	grad_norm 0.4659 (0.5216)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:28:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:18 lr 0.000036	 wd 0.0000	time 0.2378 (0.2620)	loss 1.5132 (1.3497)	grad_norm 0.6074 (0.5239)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:28:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:49 lr 0.000036	 wd 0.0000	time 0.2412 (0.2603)	loss 1.4747 (1.3458)	grad_norm 0.4749 (0.5241)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:28:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:07:19 lr 0.000036	 wd 0.0000	time 0.2151 (0.2583)	loss 1.2368 (1.3451)	grad_norm 0.6455 (0.5245)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:29:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:49 lr 0.000036	 wd 0.0000	time 0.2243 (0.2554)	loss 1.5202 (1.3452)	grad_norm 0.6278 (0.5327)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:29:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:19 lr 0.000036	 wd 0.0000	time 0.2145 (0.2528)	loss 1.5000 (1.3438)	grad_norm 0.4838 (0.5309)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:30:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:53 lr 0.000036	 wd 0.0000	time 0.2534 (0.2523)	loss 1.2972 (1.3413)	grad_norm 0.5751 (0.5313)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:30:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:28 lr 0.000035	 wd 0.0000	time 0.2226 (0.2522)	loss 1.3384 (1.3420)	grad_norm 1.1431 (0.5317)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:30:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:05:01 lr 0.000035	 wd 0.0000	time 0.2482 (0.2505)	loss 1.5641 (1.3446)	grad_norm 0.4928 (0.5300)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:31:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:34 lr 0.000035	 wd 0.0000	time 0.2009 (0.2491)	loss 1.3416 (1.3450)	grad_norm 0.6495 (0.5292)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:31:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:04:08 lr 0.000035	 wd 0.0000	time 0.2295 (0.2484)	loss 1.2454 (1.3449)	grad_norm 0.4507 (0.5291)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:32:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:44 lr 0.000035	 wd 0.0000	time 0.2565 (0.2488)	loss 1.2173 (1.3464)	grad_norm 0.5810 (0.5291)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:32:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:18 lr 0.000035	 wd 0.0000	time 0.2165 (0.2478)	loss 1.3103 (1.3473)	grad_norm 0.4744 (0.5293)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:32:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:53 lr 0.000035	 wd 0.0000	time 0.2289 (0.2469)	loss 1.4030 (1.3481)	grad_norm 1.4935 (0.5301)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:33:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:28 lr 0.000035	 wd 0.0000	time 0.2536 (0.2466)	loss 1.4975 (1.3496)	grad_norm 0.5081 (0.5304)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:33:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:02:04 lr 0.000035	 wd 0.0000	time 0.2195 (0.2477)	loss 1.2499 (1.3507)	grad_norm 0.4882 (0.5306)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:34:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:39 lr 0.000035	 wd 0.0000	time 0.2500 (0.2471)	loss 1.5421 (1.3524)	grad_norm 0.7942 (0.5304)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:34:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:14 lr 0.000035	 wd 0.0000	time 0.1695 (0.2464)	loss 0.9511 (1.3522)	grad_norm 0.4728 (0.5300)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:34:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:49 lr 0.000035	 wd 0.0000	time 0.2814 (0.2462)	loss 1.4644 (1.3517)	grad_norm 0.5330 (0.5297)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:35:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:25 lr 0.000035	 wd 0.0000	time 0.2117 (0.2467)	loss 1.5105 (1.3516)	grad_norm 0.4932 (0.5297)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:35:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1750 (0.2449)	loss 1.3335 (1.3507)	grad_norm 0.5043 (0.5300)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:35:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 10 training takes 0:10:17
[2024-07-14 18:35:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 18.983 (18.983)	Loss 0.4158 (0.4158)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 18:36:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.172 Acc@5 97.298
[2024-07-14 18:36:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 18:36:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.22%
[2024-07-14 18:36:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][0/2502]	eta 1 day, 8:37:10 lr 0.000035	 wd 0.0000	time 46.9346 (46.9346)	loss 1.4956 (1.4956)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:37:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:30:34 lr 0.000035	 wd 0.0000	time 0.3433 (0.7638)	loss 1.3878 (1.3420)	grad_norm 0.7040 (0.5282)	loss_scale 16384.0000 (8678.6535)	mem 7984MB
[2024-07-14 18:37:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:20:05 lr 0.000034	 wd 0.0000	time 0.2426 (0.5235)	loss 1.4565 (1.3456)	grad_norm 0.4733 (0.5148)	loss_scale 16384.0000 (12512.1592)	mem 7984MB
[2024-07-14 18:38:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:19:36 lr 0.000034	 wd 0.0000	time 0.2573 (0.5345)	loss 1.3282 (1.3482)	grad_norm 0.5055 (0.5186)	loss_scale 16384.0000 (13798.4850)	mem 7984MB
[2024-07-14 18:39:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:17:04 lr 0.000034	 wd 0.0000	time 0.2409 (0.4876)	loss 1.5298 (1.3480)	grad_norm 0.4808 (0.5176)	loss_scale 16384.0000 (14443.2519)	mem 7984MB
[2024-07-14 18:40:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:15:20 lr 0.000034	 wd 0.0000	time 0.2418 (0.4599)	loss 1.3690 (1.3450)	grad_norm 0.4409 (0.5160)	loss_scale 16384.0000 (14830.6267)	mem 7984MB
[2024-07-14 18:40:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:13:21 lr 0.000034	 wd 0.0000	time 0.2163 (0.4212)	loss 1.4748 (1.3427)	grad_norm 0.7639 (0.5199)	loss_scale 16384.0000 (15089.0915)	mem 7984MB
[2024-07-14 18:40:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:11:50 lr 0.000034	 wd 0.0000	time 0.2273 (0.3942)	loss 1.4667 (1.3434)	grad_norm 0.4962 (0.5205)	loss_scale 16384.0000 (15273.8146)	mem 7984MB
[2024-07-14 18:41:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:10:37 lr 0.000034	 wd 0.0000	time 0.2344 (0.3744)	loss 1.6033 (1.3459)	grad_norm 0.4866 (0.5189)	loss_scale 16384.0000 (15412.4145)	mem 7984MB
[2024-07-14 18:41:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:09:38 lr 0.000034	 wd 0.0000	time 0.2152 (0.3613)	loss 1.4912 (1.3459)	grad_norm 0.4824 (0.5180)	loss_scale 16384.0000 (15520.2486)	mem 7984MB
[2024-07-14 18:42:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:08:43 lr 0.000034	 wd 0.0000	time 0.2205 (0.3486)	loss 1.4427 (1.3480)	grad_norm 0.5634 (0.5171)	loss_scale 16384.0000 (15606.5375)	mem 7984MB
[2024-07-14 18:42:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:07:53 lr 0.000034	 wd 0.0000	time 0.2257 (0.3378)	loss 1.5348 (1.3494)	grad_norm 0.5059 (0.5176)	loss_scale 16384.0000 (15677.1517)	mem 7984MB
[2024-07-14 18:42:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:07:08 lr 0.000034	 wd 0.0000	time 0.2470 (0.3290)	loss 1.6835 (1.3492)	grad_norm 0.5064 (0.5188)	loss_scale 16384.0000 (15736.0067)	mem 7984MB
[2024-07-14 18:43:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:06:29 lr 0.000034	 wd 0.0000	time 0.2212 (0.3238)	loss 0.9037 (1.3481)	grad_norm 0.4355 (0.5195)	loss_scale 16384.0000 (15785.8140)	mem 7984MB
[2024-07-14 18:43:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:05:50 lr 0.000034	 wd 0.0000	time 0.2163 (0.3179)	loss 0.8738 (1.3477)	grad_norm 0.4719 (0.5192)	loss_scale 16384.0000 (15828.5111)	mem 7984MB
[2024-07-14 18:44:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:05:12 lr 0.000034	 wd 0.0000	time 0.2197 (0.3122)	loss 1.4282 (1.3468)	grad_norm 0.4556 (0.5204)	loss_scale 16384.0000 (15865.5190)	mem 7984MB
[2024-07-14 18:44:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:04:37 lr 0.000034	 wd 0.0000	time 0.2392 (0.3072)	loss 1.2498 (1.3479)	grad_norm 0.7073 (0.5207)	loss_scale 16384.0000 (15897.9038)	mem 7984MB
[2024-07-14 18:44:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:04:04 lr 0.000033	 wd 0.0000	time 0.2104 (0.3043)	loss 1.4547 (1.3472)	grad_norm 0.4754 (nan)	loss_scale 8192.0000 (15695.3133)	mem 7984MB
[2024-07-14 18:45:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:03:31 lr 0.000033	 wd 0.0000	time 0.2207 (0.3007)	loss 1.2817 (1.3489)	grad_norm 0.4665 (nan)	loss_scale 8192.0000 (15278.6941)	mem 7984MB
[2024-07-14 18:45:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:58 lr 0.000033	 wd 0.0000	time 0.2350 (0.2973)	loss 1.4912 (1.3491)	grad_norm 0.4697 (nan)	loss_scale 8192.0000 (14905.9064)	mem 7984MB
[2024-07-14 18:46:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:02:27 lr 0.000033	 wd 0.0000	time 0.2404 (0.2942)	loss 1.1083 (1.3485)	grad_norm 0.4512 (nan)	loss_scale 8192.0000 (14570.3788)	mem 7984MB
[2024-07-14 18:46:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:57 lr 0.000033	 wd 0.0000	time 0.2988 (0.2925)	loss 1.5464 (1.3483)	grad_norm 0.5379 (nan)	loss_scale 8192.0000 (14266.7911)	mem 7984MB
[2024-07-14 18:46:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:27 lr 0.000033	 wd 0.0000	time 0.1790 (0.2901)	loss 1.2632 (1.3492)	grad_norm 0.4547 (nan)	loss_scale 8192.0000 (13990.7896)	mem 7984MB
[2024-07-14 18:47:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:58 lr 0.000033	 wd 0.0000	time 0.2115 (0.2877)	loss 1.5103 (1.3489)	grad_norm 0.4893 (nan)	loss_scale 8192.0000 (13738.7779)	mem 7984MB
[2024-07-14 18:47:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:29 lr 0.000033	 wd 0.0000	time 0.2554 (0.2855)	loss 1.2534 (1.3481)	grad_norm 0.5353 (nan)	loss_scale 8192.0000 (13507.7584)	mem 7984MB
[2024-07-14 18:47:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000033	 wd 0.0000	time 0.1780 (0.2825)	loss 1.3830 (1.3477)	grad_norm 0.5340 (nan)	loss_scale 8192.0000 (13295.2131)	mem 7984MB
[2024-07-14 18:48:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 11 training takes 0:12:06
[2024-07-14 18:49:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 67.238 (67.238)	Loss 0.4141 (0.4141)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 18:49:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.264 Acc@5 97.276
[2024-07-14 18:49:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-14 18:49:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 18:49:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft/ckpt_epoch_best.pth saving......
[2024-07-14 18:49:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft/ckpt_epoch_best.pth saved !!!
[2024-07-14 18:50:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][0/2502]	eta 12:01:00 lr 0.000033	 wd 0.0000	time 17.2903 (17.2903)	loss 1.6089 (1.6089)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 18:50:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:15:52 lr 0.000033	 wd 0.0000	time 0.2226 (0.3965)	loss 1.4902 (1.3528)	grad_norm 0.4868 (inf)	loss_scale 4096.0000 (6975.3663)	mem 7984MB
[2024-07-14 18:51:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:12:32 lr 0.000033	 wd 0.0000	time 0.3017 (0.3269)	loss 0.9764 (1.3593)	grad_norm 0.4504 (inf)	loss_scale 4096.0000 (5542.8458)	mem 7984MB
[2024-07-14 18:51:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:11:05 lr 0.000033	 wd 0.0000	time 0.2103 (0.3021)	loss 1.2899 (1.3594)	grad_norm 0.5237 (inf)	loss_scale 4096.0000 (5062.1661)	mem 7984MB
[2024-07-14 18:51:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:56 lr 0.000033	 wd 0.0000	time 0.2033 (0.2837)	loss 1.2241 (1.3520)	grad_norm 0.4335 (inf)	loss_scale 4096.0000 (4821.2269)	mem 7984MB
[2024-07-14 18:52:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:09:04 lr 0.000032	 wd 0.0000	time 0.2168 (0.2720)	loss 1.0044 (1.3527)	grad_norm 0.4491 (inf)	loss_scale 4096.0000 (4676.4711)	mem 7984MB
[2024-07-14 18:52:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:08:27 lr 0.000032	 wd 0.0000	time 0.2994 (0.2666)	loss 1.3455 (1.3500)	grad_norm 0.5197 (inf)	loss_scale 4096.0000 (4579.8869)	mem 7984MB
[2024-07-14 18:53:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:56 lr 0.000032	 wd 0.0000	time 0.2316 (0.2645)	loss 1.4481 (1.3478)	grad_norm 0.5350 (inf)	loss_scale 4096.0000 (4510.8588)	mem 7984MB
[2024-07-14 18:53:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:07:22 lr 0.000032	 wd 0.0000	time 0.2081 (0.2602)	loss 1.4405 (1.3558)	grad_norm 0.5314 (inf)	loss_scale 4096.0000 (4459.0662)	mem 7984MB
[2024-07-14 18:53:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:51 lr 0.000032	 wd 0.0000	time 0.2520 (0.2568)	loss 1.0347 (1.3561)	grad_norm 0.5903 (inf)	loss_scale 4096.0000 (4418.7703)	mem 7984MB
[2024-07-14 18:54:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:22 lr 0.000032	 wd 0.0000	time 0.2369 (0.2549)	loss 1.6297 (1.3537)	grad_norm 0.4755 (inf)	loss_scale 4096.0000 (4386.5255)	mem 7984MB
[2024-07-14 18:54:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:57 lr 0.000032	 wd 0.0000	time 0.2045 (0.2550)	loss 1.4701 (1.3577)	grad_norm 0.4901 (inf)	loss_scale 4096.0000 (4360.1381)	mem 7984MB
[2024-07-14 18:55:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:29 lr 0.000032	 wd 0.0000	time 0.2197 (0.2529)	loss 1.4987 (1.3567)	grad_norm 0.5126 (inf)	loss_scale 4096.0000 (4338.1449)	mem 7984MB
[2024-07-14 18:55:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:05:01 lr 0.000032	 wd 0.0000	time 0.2310 (0.2511)	loss 1.4357 (1.3571)	grad_norm 0.5649 (inf)	loss_scale 4096.0000 (4319.5327)	mem 7984MB
[2024-07-14 18:55:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:35 lr 0.000032	 wd 0.0000	time 0.2296 (0.2498)	loss 1.5817 (1.3571)	grad_norm 0.4590 (inf)	loss_scale 4096.0000 (4303.5774)	mem 7984MB
[2024-07-14 18:56:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:04:10 lr 0.000032	 wd 0.0000	time 0.2073 (0.2499)	loss 1.4157 (1.3577)	grad_norm 0.4578 (inf)	loss_scale 4096.0000 (4289.7482)	mem 7984MB
[2024-07-14 18:56:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:44 lr 0.000032	 wd 0.0000	time 0.2120 (0.2492)	loss 1.4123 (1.3566)	grad_norm 0.4790 (inf)	loss_scale 4096.0000 (4277.6465)	mem 7984MB
[2024-07-14 18:56:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:19 lr 0.000031	 wd 0.0000	time 0.2176 (0.2483)	loss 1.5612 (1.3576)	grad_norm 0.4719 (inf)	loss_scale 4096.0000 (4266.9677)	mem 7984MB
[2024-07-14 18:57:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:53 lr 0.000031	 wd 0.0000	time 0.2506 (0.2475)	loss 1.2667 (1.3584)	grad_norm 0.5447 (inf)	loss_scale 4096.0000 (4257.4747)	mem 7984MB
[2024-07-14 18:57:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:29 lr 0.000031	 wd 0.0000	time 0.2421 (0.2486)	loss 1.4099 (1.3579)	grad_norm 0.5627 (inf)	loss_scale 4096.0000 (4248.9805)	mem 7984MB
[2024-07-14 18:58:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:02:04 lr 0.000031	 wd 0.0000	time 0.2091 (0.2481)	loss 1.3994 (1.3570)	grad_norm 0.4559 (inf)	loss_scale 4096.0000 (4241.3353)	mem 7984MB
[2024-07-14 18:58:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:39 lr 0.000031	 wd 0.0000	time 0.2147 (0.2474)	loss 1.4260 (1.3582)	grad_norm 0.5166 (inf)	loss_scale 4096.0000 (4234.4179)	mem 7984MB
[2024-07-14 18:59:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:14 lr 0.000031	 wd 0.0000	time 0.2300 (0.2469)	loss 1.5644 (1.3597)	grad_norm 0.4952 (inf)	loss_scale 4096.0000 (4228.1290)	mem 7984MB
[2024-07-14 18:59:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:49 lr 0.000031	 wd 0.0000	time 0.2267 (0.2473)	loss 1.4231 (1.3597)	grad_norm 0.4875 (inf)	loss_scale 4096.0000 (4222.3868)	mem 7984MB
[2024-07-14 18:59:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:25 lr 0.000031	 wd 0.0000	time 0.2061 (0.2469)	loss 1.4967 (1.3593)	grad_norm 0.5838 (inf)	loss_scale 4096.0000 (4217.1229)	mem 7984MB
[2024-07-14 19:00:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000031	 wd 0.0000	time 0.1672 (0.2452)	loss 1.1132 (1.3582)	grad_norm 0.7730 (inf)	loss_scale 4096.0000 (4212.2799)	mem 7984MB
[2024-07-14 19:00:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 12 training takes 0:10:17
[2024-07-14 19:00:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 26.890 (26.890)	Loss 0.4146 (0.4146)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 19:01:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.188 Acc@5 97.318
[2024-07-14 19:01:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 19:01:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 19:01:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][0/2502]	eta 12:55:19 lr 0.000031	 wd 0.0000	time 18.5930 (18.5930)	loss 1.3554 (1.3554)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:01:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:16:16 lr 0.000031	 wd 0.0000	time 0.2114 (0.4066)	loss 1.3793 (1.3453)	grad_norm 0.4852 (0.5354)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:02:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:12:09 lr 0.000031	 wd 0.0000	time 0.2207 (0.3171)	loss 1.6780 (1.3471)	grad_norm 0.4677 (0.5234)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:02:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:12:07 lr 0.000031	 wd 0.0000	time 0.2887 (0.3305)	loss 1.4421 (1.3553)	grad_norm 0.4961 (0.5196)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:03:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:10:47 lr 0.000030	 wd 0.0000	time 0.2159 (0.3082)	loss 1.3234 (1.3540)	grad_norm 0.6053 (0.5181)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:03:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:09:44 lr 0.000030	 wd 0.0000	time 0.2043 (0.2919)	loss 1.5211 (1.3483)	grad_norm 0.5913 (0.5211)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:03:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:56 lr 0.000030	 wd 0.0000	time 0.2938 (0.2823)	loss 1.5241 (1.3546)	grad_norm 0.5912 (0.5194)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:04:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:08:21 lr 0.000030	 wd 0.0000	time 0.2047 (0.2786)	loss 1.4186 (1.3501)	grad_norm 0.4901 (0.5201)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:04:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:44 lr 0.000030	 wd 0.0000	time 0.2468 (0.2729)	loss 1.5485 (1.3538)	grad_norm 0.4781 (0.5221)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:05:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:07:10 lr 0.000030	 wd 0.0000	time 0.2251 (0.2685)	loss 1.5263 (1.3509)	grad_norm 0.5373 (0.5218)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:05:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:37 lr 0.000030	 wd 0.0000	time 0.2877 (0.2649)	loss 1.5921 (1.3564)	grad_norm 0.4519 (0.5245)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:05:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:06:10 lr 0.000030	 wd 0.0000	time 0.1930 (0.2640)	loss 1.3852 (1.3580)	grad_norm 0.6144 (0.5262)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:06:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:40 lr 0.000030	 wd 0.0000	time 0.2194 (0.2618)	loss 1.5498 (1.3543)	grad_norm 0.5137 (0.5266)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:06:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:05:11 lr 0.000030	 wd 0.0000	time 0.2218 (0.2595)	loss 1.4203 (1.3530)	grad_norm 0.4607 (0.5288)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:07:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:44 lr 0.000030	 wd 0.0000	time 0.2548 (0.2577)	loss 1.6261 (1.3536)	grad_norm 0.4808 (0.5283)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:07:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:04:17 lr 0.000030	 wd 0.0000	time 0.2729 (0.2575)	loss 1.6157 (1.3524)	grad_norm 0.4826 (0.5289)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:07:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:51 lr 0.000029	 wd 0.0000	time 0.2424 (0.2563)	loss 1.5658 (1.3520)	grad_norm 0.6906 (0.5302)	loss_scale 8192.0000 (4177.8688)	mem 7984MB
[2024-07-14 19:08:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:24 lr 0.000029	 wd 0.0000	time 0.2151 (0.2549)	loss 0.8574 (1.3496)	grad_norm 0.6296 (0.5294)	loss_scale 8192.0000 (4413.8554)	mem 7984MB
[2024-07-14 19:08:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:58 lr 0.000029	 wd 0.0000	time 0.2328 (0.2537)	loss 1.4124 (1.3512)	grad_norm 0.5485 (0.5292)	loss_scale 8192.0000 (4623.6358)	mem 7984MB
[2024-07-14 19:09:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:33 lr 0.000029	 wd 0.0000	time 0.2266 (0.2543)	loss 1.2107 (1.3517)	grad_norm 0.4890 (0.5297)	loss_scale 8192.0000 (4811.3456)	mem 7984MB
[2024-07-14 19:09:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:02:07 lr 0.000029	 wd 0.0000	time 0.2357 (0.2540)	loss 1.4234 (1.3527)	grad_norm 0.5366 (0.5292)	loss_scale 8192.0000 (4980.2939)	mem 7984MB
[2024-07-14 19:09:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:41 lr 0.000029	 wd 0.0000	time 0.2279 (0.2530)	loss 1.0957 (1.3524)	grad_norm 0.4816 (0.5287)	loss_scale 8192.0000 (5133.1594)	mem 7984MB
[2024-07-14 19:10:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:16 lr 0.000029	 wd 0.0000	time 0.2506 (0.2522)	loss 1.5193 (1.3539)	grad_norm 0.4817 (0.5279)	loss_scale 8192.0000 (5272.1345)	mem 7984MB
[2024-07-14 19:10:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:50 lr 0.000029	 wd 0.0000	time 0.3871 (0.2522)	loss 1.2983 (1.3533)	grad_norm 0.5084 (nan)	loss_scale 4096.0000 (5345.6271)	mem 7984MB
[2024-07-14 19:11:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:25 lr 0.000029	 wd 0.0000	time 0.2130 (0.2518)	loss 1.6588 (1.3545)	grad_norm 0.4608 (nan)	loss_scale 4096.0000 (5293.5810)	mem 7984MB
[2024-07-14 19:11:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000029	 wd 0.0000	time 0.1906 (0.2499)	loss 1.5216 (1.3539)	grad_norm 0.4644 (nan)	loss_scale 4096.0000 (5245.6969)	mem 7984MB
[2024-07-14 19:11:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 13 training takes 0:10:29
[2024-07-14 19:12:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 27.772 (27.772)	Loss 0.4104 (0.4104)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 19:12:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.204 Acc@5 97.282
[2024-07-14 19:12:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 19:12:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 19:12:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][0/2502]	eta 12:56:30 lr 0.000029	 wd 0.0000	time 18.6213 (18.6213)	loss 1.4757 (1.4757)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:13:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:16:29 lr 0.000029	 wd 0.0000	time 0.2186 (0.4118)	loss 1.5182 (1.3631)	grad_norm 0.4523 (0.5286)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:13:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:12:16 lr 0.000028	 wd 0.0000	time 0.2147 (0.3199)	loss 1.3041 (1.3828)	grad_norm 0.4881 (0.5208)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:13:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:11:03 lr 0.000028	 wd 0.0000	time 0.2082 (0.3013)	loss 1.0149 (1.3705)	grad_norm 0.4709 (0.5214)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:14:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:09:55 lr 0.000028	 wd 0.0000	time 0.2176 (0.2835)	loss 1.1906 (1.3557)	grad_norm 0.5242 (0.5291)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:14:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:09:05 lr 0.000028	 wd 0.0000	time 0.2407 (0.2724)	loss 1.2795 (1.3585)	grad_norm 0.5040 (0.5298)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:15:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:08:24 lr 0.000028	 wd 0.0000	time 0.2491 (0.2653)	loss 1.6504 (1.3640)	grad_norm 0.5239 (0.5274)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:15:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:55 lr 0.000028	 wd 0.0000	time 0.2186 (0.2638)	loss 1.4262 (1.3600)	grad_norm 0.5734 (0.5294)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:15:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:24 lr 0.000028	 wd 0.0000	time 0.2541 (0.2613)	loss 1.3809 (1.3563)	grad_norm 0.5090 (0.5295)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:16:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:53 lr 0.000028	 wd 0.0000	time 0.2063 (0.2579)	loss 1.4265 (1.3524)	grad_norm 0.5106 (0.5276)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:16:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:06:22 lr 0.000028	 wd 0.0000	time 0.2228 (0.2549)	loss 1.3113 (1.3509)	grad_norm 0.4821 (0.5258)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:17:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:57 lr 0.000028	 wd 0.0000	time 0.2322 (0.2546)	loss 1.4732 (1.3485)	grad_norm 0.4950 (0.5270)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:17:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:30 lr 0.000028	 wd 0.0000	time 0.2052 (0.2540)	loss 1.4101 (1.3487)	grad_norm 0.4634 (0.5274)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:17:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:05:03 lr 0.000027	 wd 0.0000	time 0.1992 (0.2523)	loss 1.1639 (1.3489)	grad_norm 0.6785 (0.5285)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:18:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:36 lr 0.000027	 wd 0.0000	time 0.2389 (0.2507)	loss 1.6298 (1.3480)	grad_norm 0.5464 (0.5292)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:18:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:04:10 lr 0.000027	 wd 0.0000	time 0.2205 (0.2502)	loss 1.3549 (1.3488)	grad_norm 0.4710 (0.5320)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:19:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:45 lr 0.000027	 wd 0.0000	time 0.2189 (0.2505)	loss 1.3146 (1.3487)	grad_norm 0.5005 (0.5334)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:19:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:20 lr 0.000027	 wd 0.0000	time 0.2219 (0.2494)	loss 1.1758 (1.3481)	grad_norm 0.4895 (0.5318)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:19:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:54 lr 0.000027	 wd 0.0000	time 0.2073 (0.2485)	loss 1.3046 (1.3480)	grad_norm 0.5899 (0.5316)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:20:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:29 lr 0.000027	 wd 0.0000	time 0.2476 (0.2483)	loss 1.5355 (1.3481)	grad_norm 0.5109 (0.5319)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:20:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:02:04 lr 0.000027	 wd 0.0000	time 0.2069 (0.2486)	loss 1.0596 (1.3500)	grad_norm 0.5034 (0.5310)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:21:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:39 lr 0.000027	 wd 0.0000	time 0.2308 (0.2479)	loss 1.5504 (1.3498)	grad_norm 3.5762 (0.5329)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:21:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:14 lr 0.000027	 wd 0.0000	time 0.2290 (0.2471)	loss 1.2130 (1.3500)	grad_norm 0.4777 (0.5326)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:21:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:49 lr 0.000027	 wd 0.0000	time 0.2286 (0.2470)	loss 1.3851 (1.3508)	grad_norm 0.5690 (0.5322)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:22:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:26 lr 0.000026	 wd 0.0000	time 0.3495 (0.2589)	loss 1.1280 (1.3519)	grad_norm 0.5243 (0.5316)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:23:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1780 (0.2583)	loss 1.2475 (1.3510)	grad_norm 0.5248 (0.5326)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:23:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 14 training takes 0:10:52
[2024-07-14 19:24:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 81.456 (81.456)	Loss 0.4099 (0.4099)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 19:24:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.222 Acc@5 97.296
[2024-07-14 19:24:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 19:24:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 19:25:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][0/2502]	eta 1 day, 7:17:48 lr 0.000026	 wd 0.0000	time 45.0313 (45.0313)	loss 1.4418 (1.4418)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:26:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:27:12 lr 0.000026	 wd 0.0000	time 0.2253 (0.6797)	loss 1.0078 (1.3379)	grad_norm 0.4863 (0.5286)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:26:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:17:21 lr 0.000026	 wd 0.0000	time 0.2070 (0.4526)	loss 1.4376 (1.3530)	grad_norm 0.4896 (0.5200)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:26:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:14:12 lr 0.000026	 wd 0.0000	time 0.2420 (0.3872)	loss 1.3893 (1.3403)	grad_norm 0.4381 (0.5153)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:27:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:12:14 lr 0.000026	 wd 0.0000	time 0.2175 (0.3492)	loss 1.3919 (1.3442)	grad_norm 0.5491 (0.5273)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:27:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:10:49 lr 0.000026	 wd 0.0000	time 0.2373 (0.3247)	loss 0.8649 (1.3419)	grad_norm 0.4647 (0.5270)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:28:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:09:48 lr 0.000026	 wd 0.0000	time 0.2494 (0.3093)	loss 0.8396 (1.3454)	grad_norm 0.4837 (0.5416)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:28:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:09:02 lr 0.000026	 wd 0.0000	time 0.2355 (0.3009)	loss 1.1049 (1.3479)	grad_norm 0.6076 (0.5389)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:28:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:08:19 lr 0.000026	 wd 0.0000	time 0.2233 (0.2937)	loss 1.4028 (1.3482)	grad_norm 0.4630 (0.5383)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:29:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:07:39 lr 0.000025	 wd 0.0000	time 0.2557 (0.2866)	loss 1.2206 (1.3490)	grad_norm 0.4712 (0.5350)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:29:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:07:02 lr 0.000025	 wd 0.0000	time 0.2075 (0.2810)	loss 1.4203 (1.3504)	grad_norm 0.4606 (0.5346)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:29:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:06:29 lr 0.000025	 wd 0.0000	time 0.2414 (0.2777)	loss 1.2425 (1.3476)	grad_norm 2.0459 (0.5387)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:30:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:58 lr 0.000025	 wd 0.0000	time 0.2337 (0.2757)	loss 1.3858 (1.3482)	grad_norm 0.4699 (0.5406)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:30:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:05:27 lr 0.000025	 wd 0.0000	time 0.2274 (0.2722)	loss 1.3469 (1.3466)	grad_norm 0.5266 (0.5389)	loss_scale 8192.0000 (4203.0438)	mem 7984MB
[2024-07-14 19:31:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:56 lr 0.000025	 wd 0.0000	time 0.1944 (0.2692)	loss 1.4433 (1.3468)	grad_norm 1.0000 (0.5384)	loss_scale 8192.0000 (4487.7659)	mem 7984MB
[2024-07-14 19:31:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:04:27 lr 0.000025	 wd 0.0000	time 0.2424 (0.2675)	loss 1.5645 (1.3466)	grad_norm 1.3911 (0.5391)	loss_scale 8192.0000 (4734.5503)	mem 7984MB
[2024-07-14 19:32:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:04:00 lr 0.000025	 wd 0.0000	time 0.2100 (0.2665)	loss 1.2769 (1.3489)	grad_norm 0.4778 (0.5376)	loss_scale 8192.0000 (4950.5059)	mem 7984MB
[2024-07-14 19:32:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:32 lr 0.000025	 wd 0.0000	time 0.2408 (0.2646)	loss 1.4197 (1.3479)	grad_norm 1.1310 (0.5376)	loss_scale 8192.0000 (5141.0700)	mem 7984MB
[2024-07-14 19:32:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:03:04 lr 0.000025	 wd 0.0000	time 0.1999 (0.2630)	loss 1.0583 (1.3477)	grad_norm 0.5377 (0.5368)	loss_scale 8192.0000 (5310.4720)	mem 7984MB
[2024-07-14 19:33:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:37 lr 0.000024	 wd 0.0000	time 0.2183 (0.2620)	loss 1.5881 (1.3481)	grad_norm 0.4948 (0.5360)	loss_scale 8192.0000 (5462.0516)	mem 7984MB
[2024-07-14 19:33:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:02:11 lr 0.000024	 wd 0.0000	time 0.2102 (0.2617)	loss 1.8218 (1.3503)	grad_norm 0.5422 (0.5368)	loss_scale 8192.0000 (5598.4808)	mem 7984MB
[2024-07-14 19:34:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:44 lr 0.000024	 wd 0.0000	time 0.2077 (0.2604)	loss 1.4892 (1.3511)	grad_norm 0.4888 (0.5362)	loss_scale 8192.0000 (5721.9229)	mem 7984MB
[2024-07-14 19:34:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:18 lr 0.000024	 wd 0.0000	time 0.2061 (0.2593)	loss 1.0570 (1.3523)	grad_norm 0.5005 (0.5354)	loss_scale 8192.0000 (5834.1481)	mem 7984MB
[2024-07-14 19:34:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:52 lr 0.000024	 wd 0.0000	time 0.2544 (0.2585)	loss 1.5725 (1.3524)	grad_norm 0.5379 (0.5348)	loss_scale 8192.0000 (5936.6189)	mem 7984MB
[2024-07-14 19:35:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:26 lr 0.000024	 wd 0.0000	time 0.2028 (0.2581)	loss 1.0616 (1.3512)	grad_norm 0.5214 (0.5344)	loss_scale 8192.0000 (6030.5539)	mem 7984MB
[2024-07-14 19:35:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1920 (0.2562)	loss 1.2032 (1.3513)	grad_norm 0.4580 (0.5341)	loss_scale 8192.0000 (6116.9772)	mem 7984MB
[2024-07-14 19:35:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 15 training takes 0:10:45
[2024-07-14 19:35:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft/ckpt_epoch_15.pth saving......
[2024-07-14 19:35:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft/ckpt_epoch_15.pth saved !!!
[2024-07-14 19:35:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 18.513 (18.513)	Loss 0.4094 (0.4094)	Acc@1 93.164 (93.164)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 19:36:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.178 Acc@5 97.296
[2024-07-14 19:36:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 19:36:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 19:36:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][0/2502]	eta 20:52:15 lr 0.000024	 wd 0.0000	time 30.0304 (30.0304)	loss 1.2690 (1.2690)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 19:37:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:21:00 lr 0.000024	 wd 0.0000	time 0.2120 (0.5248)	loss 1.4627 (1.3448)	grad_norm 0.5287 (0.5090)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 19:37:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:14:23 lr 0.000024	 wd 0.0000	time 0.2151 (0.3753)	loss 1.3103 (1.3544)	grad_norm 0.5174 (0.5105)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 19:37:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:11:58 lr 0.000024	 wd 0.0000	time 0.2418 (0.3263)	loss 1.3475 (1.3666)	grad_norm 0.4731 (0.5135)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 19:38:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:10:49 lr 0.000024	 wd 0.0000	time 0.2311 (0.3090)	loss 1.2641 (1.3606)	grad_norm 0.4966 (0.5146)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 19:38:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:09:46 lr 0.000023	 wd 0.0000	time 0.2197 (0.2928)	loss 1.2472 (1.3705)	grad_norm 0.5099 (0.5225)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 19:39:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:56 lr 0.000023	 wd 0.0000	time 0.2590 (0.2823)	loss 1.0401 (1.3630)	grad_norm 0.5528 (0.5210)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 19:39:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:08:14 lr 0.000023	 wd 0.0000	time 0.2339 (0.2745)	loss 1.3155 (1.3646)	grad_norm 0.5059 (0.5238)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 19:39:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:07:42 lr 0.000023	 wd 0.0000	time 0.2346 (0.2717)	loss 1.3865 (1.3591)	grad_norm 0.4998 (nan)	loss_scale 4096.0000 (7885.1835)	mem 7984MB
[2024-07-14 19:40:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:07:10 lr 0.000023	 wd 0.0000	time 0.2189 (0.2685)	loss 1.5511 (1.3571)	grad_norm 0.4983 (nan)	loss_scale 4096.0000 (7464.6304)	mem 7984MB
[2024-07-14 19:40:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:06:37 lr 0.000023	 wd 0.0000	time 0.2482 (0.2646)	loss 1.5416 (1.3573)	grad_norm 0.7083 (nan)	loss_scale 4096.0000 (7128.1039)	mem 7984MB
[2024-07-14 19:41:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:06:06 lr 0.000023	 wd 0.0000	time 0.2156 (0.2614)	loss 1.3204 (1.3583)	grad_norm 0.5138 (nan)	loss_scale 4096.0000 (6852.7084)	mem 7984MB
[2024-07-14 19:41:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:38 lr 0.000023	 wd 0.0000	time 0.2438 (0.2601)	loss 1.4085 (1.3595)	grad_norm 0.5583 (nan)	loss_scale 4096.0000 (6623.1740)	mem 7984MB
[2024-07-14 19:41:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:05:11 lr 0.000023	 wd 0.0000	time 0.2067 (0.2591)	loss 1.0887 (1.3600)	grad_norm 0.4560 (nan)	loss_scale 4096.0000 (6428.9254)	mem 7984MB
[2024-07-14 19:42:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:43 lr 0.000023	 wd 0.0000	time 0.2502 (0.2570)	loss 1.2043 (1.3574)	grad_norm 0.5078 (nan)	loss_scale 4096.0000 (6262.4069)	mem 7984MB
[2024-07-14 19:42:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:04:15 lr 0.000022	 wd 0.0000	time 0.2332 (0.2552)	loss 1.3978 (1.3544)	grad_norm 0.4892 (nan)	loss_scale 4096.0000 (6118.0759)	mem 7984MB
[2024-07-14 19:43:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:49 lr 0.000022	 wd 0.0000	time 0.2261 (0.2546)	loss 1.3769 (1.3548)	grad_norm 0.5066 (nan)	loss_scale 4096.0000 (5991.7751)	mem 7984MB
[2024-07-14 19:43:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:24 lr 0.000022	 wd 0.0000	time 0.1978 (0.2550)	loss 1.1079 (1.3528)	grad_norm 0.5251 (nan)	loss_scale 4096.0000 (5880.3245)	mem 7984MB
[2024-07-14 19:43:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:58 lr 0.000022	 wd 0.0000	time 0.2396 (0.2541)	loss 1.2458 (1.3512)	grad_norm 0.4867 (nan)	loss_scale 4096.0000 (5781.2504)	mem 7984MB
[2024-07-14 19:44:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:32 lr 0.000022	 wd 0.0000	time 0.2214 (0.2529)	loss 1.1796 (1.3500)	grad_norm 0.4545 (nan)	loss_scale 4096.0000 (5692.5997)	mem 7984MB
[2024-07-14 19:44:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:02:06 lr 0.000022	 wd 0.0000	time 0.2294 (0.2525)	loss 1.4625 (1.3502)	grad_norm 0.4841 (nan)	loss_scale 4096.0000 (5612.8096)	mem 7984MB
[2024-07-14 19:45:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:41 lr 0.000022	 wd 0.0000	time 0.2279 (0.2526)	loss 1.3452 (1.3498)	grad_norm 0.5071 (nan)	loss_scale 4096.0000 (5540.6149)	mem 7984MB
[2024-07-14 19:45:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:16 lr 0.000022	 wd 0.0000	time 0.2299 (0.2518)	loss 1.4683 (1.3504)	grad_norm 0.4819 (nan)	loss_scale 4096.0000 (5474.9805)	mem 7984MB
[2024-07-14 19:45:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:50 lr 0.000022	 wd 0.0000	time 0.2034 (0.2509)	loss 1.2108 (1.3505)	grad_norm 0.5364 (nan)	loss_scale 4096.0000 (5415.0508)	mem 7984MB
[2024-07-14 19:46:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:25 lr 0.000022	 wd 0.0000	time 0.2145 (0.2508)	loss 1.5293 (1.3507)	grad_norm 0.5211 (nan)	loss_scale 4096.0000 (5360.1133)	mem 7984MB
[2024-07-14 19:46:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1685 (0.2536)	loss 1.3675 (1.3506)	grad_norm 0.4707 (nan)	loss_scale 4096.0000 (5309.5690)	mem 7984MB
[2024-07-14 19:46:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 16 training takes 0:10:42
[2024-07-14 19:48:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 67.401 (67.401)	Loss 0.4097 (0.4097)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 19:48:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.262 Acc@5 97.296
[2024-07-14 19:48:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-14 19:48:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 19:48:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][0/2502]	eta 12:02:00 lr 0.000021	 wd 0.0000	time 17.3144 (17.3144)	loss 1.4413 (1.4413)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:49:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:16:00 lr 0.000021	 wd 0.0000	time 0.2032 (0.3999)	loss 1.5533 (1.3242)	grad_norm 0.4738 (0.5451)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:49:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:12:35 lr 0.000021	 wd 0.0000	time 0.2608 (0.3284)	loss 1.5801 (1.3397)	grad_norm 0.5031 (0.5388)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:49:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:11:01 lr 0.000021	 wd 0.0000	time 0.2338 (0.3004)	loss 1.3223 (1.3359)	grad_norm 0.5219 (0.5629)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:50:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:09:52 lr 0.000021	 wd 0.0000	time 0.2149 (0.2821)	loss 1.1144 (1.3301)	grad_norm 0.5632 (0.5549)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:50:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:09:01 lr 0.000021	 wd 0.0000	time 0.2208 (0.2707)	loss 1.3576 (1.3302)	grad_norm 0.4790 (0.5514)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:50:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:25 lr 0.000021	 wd 0.0000	time 0.2543 (0.2656)	loss 1.1834 (1.3371)	grad_norm 0.4801 (0.5479)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:51:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:55 lr 0.000021	 wd 0.0000	time 0.2327 (0.2637)	loss 1.3289 (1.3429)	grad_norm 0.4703 (0.5444)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:51:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:07:21 lr 0.000021	 wd 0.0000	time 0.2077 (0.2597)	loss 1.3521 (1.3465)	grad_norm 0.5461 (0.5414)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:52:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:50 lr 0.000021	 wd 0.0000	time 0.2146 (0.2564)	loss 1.5896 (1.3480)	grad_norm 0.4973 (0.5420)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:52:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:22 lr 0.000020	 wd 0.0000	time 0.2712 (0.2548)	loss 1.5193 (1.3466)	grad_norm 0.5062 (0.5384)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:53:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:57 lr 0.000020	 wd 0.0000	time 0.2524 (0.2548)	loss 1.1029 (1.3471)	grad_norm 0.4790 (0.5385)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:53:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:29 lr 0.000020	 wd 0.0000	time 0.2410 (0.2528)	loss 1.5717 (1.3489)	grad_norm 0.4682 (0.5389)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:53:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:05:01 lr 0.000020	 wd 0.0000	time 0.1988 (0.2512)	loss 1.1692 (1.3490)	grad_norm 0.5038 (0.5373)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:54:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:35 lr 0.000020	 wd 0.0000	time 0.2397 (0.2502)	loss 1.4771 (1.3498)	grad_norm 0.4998 (0.5359)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:54:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:04:10 lr 0.000020	 wd 0.0000	time 0.2350 (0.2504)	loss 1.3941 (1.3506)	grad_norm 0.5348 (0.5351)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:54:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:44 lr 0.000020	 wd 0.0000	time 0.2235 (0.2493)	loss 1.5484 (1.3520)	grad_norm 0.5170 (0.5346)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:55:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:19 lr 0.000020	 wd 0.0000	time 0.2297 (0.2485)	loss 1.5675 (1.3539)	grad_norm 0.4703 (0.5334)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:55:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:54 lr 0.000020	 wd 0.0000	time 0.2430 (0.2479)	loss 1.2915 (1.3547)	grad_norm 0.6072 (0.5334)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:56:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:29 lr 0.000020	 wd 0.0000	time 0.2656 (0.2490)	loss 1.1467 (1.3555)	grad_norm 0.4907 (0.5337)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 19:56:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:02:04 lr 0.000019	 wd 0.0000	time 0.2122 (0.2482)	loss 1.5465 (1.3534)	grad_norm 0.5049 (nan)	loss_scale 2048.0000 (4010.0270)	mem 7984MB
[2024-07-14 19:56:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:39 lr 0.000019	 wd 0.0000	time 0.2123 (0.2476)	loss 1.4290 (1.3531)	grad_norm 0.4586 (nan)	loss_scale 2048.0000 (3916.6416)	mem 7984MB
[2024-07-14 19:57:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:14 lr 0.000019	 wd 0.0000	time 0.2548 (0.2471)	loss 1.3373 (1.3543)	grad_norm 0.5767 (nan)	loss_scale 2048.0000 (3831.7419)	mem 7984MB
[2024-07-14 19:57:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:49 lr 0.000019	 wd 0.0000	time 0.2032 (0.2473)	loss 1.4561 (1.3536)	grad_norm 0.5281 (nan)	loss_scale 2048.0000 (3754.2216)	mem 7984MB
[2024-07-14 19:58:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:25 lr 0.000019	 wd 0.0000	time 0.2375 (0.2468)	loss 1.4452 (1.3523)	grad_norm 0.5213 (nan)	loss_scale 2048.0000 (3683.1587)	mem 7984MB
[2024-07-14 19:58:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000019	 wd 0.0000	time 0.1686 (0.2451)	loss 1.4866 (1.3528)	grad_norm 0.5401 (nan)	loss_scale 2048.0000 (3617.7785)	mem 7984MB
[2024-07-14 19:58:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 17 training takes 0:10:17
[2024-07-14 19:59:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 27.423 (27.423)	Loss 0.4106 (0.4106)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 19:59:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.254 Acc@5 97.296
[2024-07-14 19:59:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-14 19:59:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 19:59:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][0/2502]	eta 11:55:31 lr 0.000019	 wd 0.0000	time 17.1587 (17.1587)	loss 1.6010 (1.6010)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:00:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:16:19 lr 0.000019	 wd 0.0000	time 0.2050 (0.4079)	loss 1.5552 (1.3943)	grad_norm 0.4643 (0.5485)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:00:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:12:10 lr 0.000019	 wd 0.0000	time 0.2415 (0.3173)	loss 1.4809 (1.3754)	grad_norm 0.4794 (0.5341)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:00:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:11:00 lr 0.000019	 wd 0.0000	time 0.2003 (0.3001)	loss 1.7095 (1.3748)	grad_norm 0.4740 (0.5267)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:01:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:09:54 lr 0.000019	 wd 0.0000	time 0.2139 (0.2828)	loss 1.4437 (1.3677)	grad_norm 0.5512 (0.5252)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:01:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:09:03 lr 0.000018	 wd 0.0000	time 0.2208 (0.2714)	loss 1.3072 (1.3571)	grad_norm 0.4965 (0.5232)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:02:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:08:22 lr 0.000018	 wd 0.0000	time 0.2046 (0.2640)	loss 1.6277 (1.3578)	grad_norm 0.4651 (0.5216)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:02:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:07:52 lr 0.000018	 wd 0.0000	time 0.2485 (0.2621)	loss 1.4294 (1.3582)	grad_norm 0.4414 (0.5213)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:02:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:22 lr 0.000018	 wd 0.0000	time 0.2441 (0.2597)	loss 1.0831 (1.3556)	grad_norm 0.5622 (0.5219)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:03:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:06:50 lr 0.000018	 wd 0.0000	time 0.2258 (0.2564)	loss 1.1739 (1.3519)	grad_norm 0.5222 (0.5207)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:03:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:21 lr 0.000018	 wd 0.0000	time 0.2350 (0.2538)	loss 1.0273 (1.3553)	grad_norm 0.4664 (0.5249)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:04:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:54 lr 0.000018	 wd 0.0000	time 0.2380 (0.2531)	loss 1.2486 (1.3549)	grad_norm 0.4658 (0.5256)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:04:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:29 lr 0.000018	 wd 0.0000	time 0.2055 (0.2529)	loss 1.6433 (1.3552)	grad_norm 0.4990 (0.5311)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:04:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:05:01 lr 0.000018	 wd 0.0000	time 0.2396 (0.2512)	loss 1.3914 (1.3558)	grad_norm 0.4888 (0.5312)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:05:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:35 lr 0.000018	 wd 0.0000	time 0.2308 (0.2497)	loss 1.2167 (1.3556)	grad_norm 0.4996 (0.5313)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:05:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:04:09 lr 0.000017	 wd 0.0000	time 0.2041 (0.2493)	loss 1.5948 (1.3548)	grad_norm 0.4771 (0.5307)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:06:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:44 lr 0.000017	 wd 0.0000	time 0.2048 (0.2494)	loss 1.4712 (1.3542)	grad_norm 0.5036 (0.5311)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:06:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:19 lr 0.000017	 wd 0.0000	time 0.2403 (0.2484)	loss 1.4595 (1.3545)	grad_norm 0.5313 (0.5317)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:06:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:53 lr 0.000017	 wd 0.0000	time 0.2232 (0.2476)	loss 1.3101 (1.3553)	grad_norm 0.7745 (0.5345)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:07:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:28 lr 0.000017	 wd 0.0000	time 0.2763 (0.2475)	loss 1.4601 (1.3544)	grad_norm 0.4857 (0.5346)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:07:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:02:04 lr 0.000017	 wd 0.0000	time 0.2121 (0.2479)	loss 1.3754 (1.3565)	grad_norm 0.4740 (0.5343)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:08:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:39 lr 0.000017	 wd 0.0000	time 0.2340 (0.2473)	loss 1.4390 (1.3558)	grad_norm 0.4786 (0.5333)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:08:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:14 lr 0.000017	 wd 0.0000	time 0.2094 (0.2467)	loss 1.3420 (1.3559)	grad_norm 0.4432 (0.5328)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:08:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:49 lr 0.000017	 wd 0.0000	time 0.2172 (0.2466)	loss 1.4952 (1.3562)	grad_norm 0.5059 (0.5329)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:09:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:25 lr 0.000017	 wd 0.0000	time 0.2423 (0.2468)	loss 1.5061 (1.3576)	grad_norm 0.7269 (0.5351)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:09:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1733 (0.2450)	loss 1.4915 (1.3571)	grad_norm 0.4660 (0.5370)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:09:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 18 training takes 0:10:17
[2024-07-14 20:10:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 17.831 (17.831)	Loss 0.4106 (0.4106)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 20:10:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.216 Acc@5 97.310
[2024-07-14 20:10:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 20:10:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 20:10:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][0/2502]	eta 21:53:47 lr 0.000016	 wd 0.0000	time 31.5057 (31.5057)	loss 1.4218 (1.4218)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:11:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:21:59 lr 0.000016	 wd 0.0000	time 0.2357 (0.5492)	loss 1.0925 (1.3687)	grad_norm 0.5165 (0.5351)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:11:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:14:52 lr 0.000016	 wd 0.0000	time 0.2034 (0.3875)	loss 1.4255 (1.3620)	grad_norm 0.5037 (0.5279)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:11:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:12:18 lr 0.000016	 wd 0.0000	time 0.2383 (0.3353)	loss 1.3063 (1.3746)	grad_norm 0.7217 (0.5327)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:12:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:11:02 lr 0.000016	 wd 0.0000	time 0.2313 (0.3153)	loss 1.4932 (1.3741)	grad_norm 0.4755 (0.5298)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:12:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:09:55 lr 0.000016	 wd 0.0000	time 0.2115 (0.2975)	loss 1.5050 (1.3693)	grad_norm 0.5793 (0.5290)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:13:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:09:04 lr 0.000016	 wd 0.0000	time 0.2407 (0.2863)	loss 1.4810 (1.3644)	grad_norm 0.4828 (0.5314)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:13:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:08:21 lr 0.000016	 wd 0.0000	time 0.2356 (0.2782)	loss 1.6328 (1.3662)	grad_norm 0.7060 (0.5311)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:13:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:07:47 lr 0.000016	 wd 0.0000	time 0.2446 (0.2746)	loss 1.3550 (1.3651)	grad_norm 0.7333 (0.5300)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:14:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:07:13 lr 0.000016	 wd 0.0000	time 0.2535 (0.2705)	loss 1.2294 (1.3646)	grad_norm 0.4781 (0.5304)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:14:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:40 lr 0.000016	 wd 0.0000	time 0.2081 (0.2666)	loss 1.5767 (1.3654)	grad_norm 0.5201 (0.5301)	loss_scale 4096.0000 (2228.0440)	mem 7984MB
[2024-07-14 20:15:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:06:09 lr 0.000015	 wd 0.0000	time 0.2415 (0.2634)	loss 0.9176 (1.3640)	grad_norm 0.4666 (0.5314)	loss_scale 4096.0000 (2397.7039)	mem 7984MB
[2024-07-14 20:15:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:41 lr 0.000015	 wd 0.0000	time 0.2226 (0.2621)	loss 1.1166 (1.3623)	grad_norm 0.6263 (0.5301)	loss_scale 4096.0000 (2539.1107)	mem 7984MB
[2024-07-14 20:15:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:05:13 lr 0.000015	 wd 0.0000	time 0.2165 (0.2608)	loss 1.5828 (1.3627)	grad_norm 0.5056 (0.5338)	loss_scale 4096.0000 (2658.7794)	mem 7984MB
[2024-07-14 20:16:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:45 lr 0.000015	 wd 0.0000	time 0.1970 (0.2586)	loss 1.4445 (1.3636)	grad_norm 0.4978 (0.5330)	loss_scale 4096.0000 (2761.3647)	mem 7984MB
[2024-07-14 20:16:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:04:17 lr 0.000015	 wd 0.0000	time 0.2271 (0.2567)	loss 1.2027 (1.3633)	grad_norm 0.4657 (0.5320)	loss_scale 4096.0000 (2850.2811)	mem 7984MB
[2024-07-14 20:17:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:50 lr 0.000015	 wd 0.0000	time 0.3358 (0.2561)	loss 1.2884 (1.3635)	grad_norm 0.9142 (0.5322)	loss_scale 4096.0000 (2928.0899)	mem 7984MB
[2024-07-14 20:17:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:25 lr 0.000015	 wd 0.0000	time 0.2097 (0.2561)	loss 1.3927 (1.3643)	grad_norm 0.4892 (0.5309)	loss_scale 4096.0000 (2996.7501)	mem 7984MB
[2024-07-14 20:17:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:58 lr 0.000015	 wd 0.0000	time 0.2523 (0.2548)	loss 1.3297 (1.3638)	grad_norm 0.5163 (0.5304)	loss_scale 4096.0000 (3057.7857)	mem 7984MB
[2024-07-14 20:18:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:32 lr 0.000015	 wd 0.0000	time 0.2010 (0.2536)	loss 1.4078 (1.3641)	grad_norm 0.4499 (0.5301)	loss_scale 4096.0000 (3112.3998)	mem 7984MB
[2024-07-14 20:18:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:02:07 lr 0.000015	 wd 0.0000	time 0.2455 (0.2531)	loss 1.0511 (1.3637)	grad_norm 0.5020 (0.5298)	loss_scale 4096.0000 (3161.5552)	mem 7984MB
[2024-07-14 20:19:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:41 lr 0.000014	 wd 0.0000	time 0.2114 (0.2535)	loss 1.1783 (1.3626)	grad_norm 0.6198 (0.5322)	loss_scale 4096.0000 (3206.0314)	mem 7984MB
[2024-07-14 20:19:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:16 lr 0.000014	 wd 0.0000	time 0.2436 (0.2526)	loss 1.4814 (1.3605)	grad_norm 0.5067 (nan)	loss_scale 2048.0000 (3159.0005)	mem 7984MB
[2024-07-14 20:19:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:50 lr 0.000014	 wd 0.0000	time 0.2185 (0.2516)	loss 1.4024 (1.3602)	grad_norm 0.5283 (nan)	loss_scale 2048.0000 (3110.7171)	mem 7984MB
[2024-07-14 20:20:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:25 lr 0.000014	 wd 0.0000	time 0.2246 (0.2514)	loss 1.5324 (1.3616)	grad_norm 0.5524 (nan)	loss_scale 2048.0000 (3066.4556)	mem 7984MB
[2024-07-14 20:20:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1810 (0.2502)	loss 1.2201 (1.3614)	grad_norm 0.5782 (nan)	loss_scale 2048.0000 (3025.7337)	mem 7984MB
[2024-07-14 20:20:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 19 training takes 0:10:31
[2024-07-14 20:21:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 19.047 (19.047)	Loss 0.4092 (0.4092)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 20:21:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.250 Acc@5 97.306
[2024-07-14 20:21:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 20:21:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 20:21:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][0/2502]	eta 11:05:49 lr 0.000014	 wd 0.0000	time 15.9670 (15.9670)	loss 0.9807 (0.9807)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:22:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:17:41 lr 0.000014	 wd 0.0000	time 0.2158 (0.4418)	loss 1.5662 (1.3567)	grad_norm 0.4642 (0.5205)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:22:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:12:55 lr 0.000014	 wd 0.0000	time 0.2304 (0.3369)	loss 1.4174 (1.3583)	grad_norm 0.5284 (0.5214)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:22:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:11:01 lr 0.000014	 wd 0.0000	time 0.1962 (0.3004)	loss 1.4681 (1.3544)	grad_norm 0.4973 (0.5199)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:23:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:09:51 lr 0.000014	 wd 0.0000	time 0.2168 (0.2816)	loss 1.4063 (1.3638)	grad_norm 0.5147 (0.5232)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:23:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:09:08 lr 0.000014	 wd 0.0000	time 0.2557 (0.2741)	loss 1.5462 (1.3660)	grad_norm 0.4913 (0.5330)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:23:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:08:30 lr 0.000014	 wd 0.0000	time 0.1806 (0.2682)	loss 1.3223 (1.3625)	grad_norm 0.5080 (0.5310)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:24:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:53 lr 0.000013	 wd 0.0000	time 0.2060 (0.2628)	loss 1.4677 (1.3649)	grad_norm 0.4822 (0.5282)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:24:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:07:20 lr 0.000013	 wd 0.0000	time 0.2235 (0.2586)	loss 1.2552 (1.3621)	grad_norm 0.4785 (0.5259)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:25:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:52 lr 0.000013	 wd 0.0000	time 0.2281 (0.2573)	loss 1.5905 (1.3648)	grad_norm 0.4787 (0.5240)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:25:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:25 lr 0.000013	 wd 0.0000	time 0.2193 (0.2569)	loss 1.2852 (1.3638)	grad_norm 0.4740 (0.5234)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:25:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:56 lr 0.000013	 wd 0.0000	time 0.2060 (0.2545)	loss 1.3475 (1.3615)	grad_norm 0.6110 (0.5228)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:26:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:28 lr 0.000013	 wd 0.0000	time 0.2075 (0.2525)	loss 1.4133 (1.3584)	grad_norm 0.4932 (0.5246)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:26:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:05:03 lr 0.000013	 wd 0.0000	time 0.2617 (0.2521)	loss 1.3053 (1.3571)	grad_norm 0.5305 (0.5245)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:27:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:37 lr 0.000013	 wd 0.0000	time 0.2062 (0.2515)	loss 1.3903 (1.3588)	grad_norm 0.5082 (0.5276)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:27:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:04:10 lr 0.000013	 wd 0.0000	time 0.2359 (0.2503)	loss 1.4299 (1.3593)	grad_norm 0.5028 (0.5268)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:27:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:44 lr 0.000013	 wd 0.0000	time 0.2131 (0.2491)	loss 1.6751 (1.3596)	grad_norm 0.5772 (0.5265)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:28:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:19 lr 0.000012	 wd 0.0000	time 0.2052 (0.2487)	loss 1.5263 (1.3589)	grad_norm 0.4620 (0.5269)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:28:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:55 lr 0.000012	 wd 0.0000	time 0.2221 (0.2495)	loss 1.3034 (1.3582)	grad_norm 0.5126 (0.5274)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:29:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:29 lr 0.000012	 wd 0.0000	time 0.2126 (0.2488)	loss 1.5245 (1.3601)	grad_norm 0.4495 (0.5299)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:29:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:02:04 lr 0.000012	 wd 0.0000	time 0.2167 (0.2478)	loss 1.4959 (1.3597)	grad_norm 0.5824 (0.5288)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:29:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:39 lr 0.000012	 wd 0.0000	time 0.2359 (0.2478)	loss 1.2994 (1.3603)	grad_norm 0.4783 (0.5305)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:30:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:14 lr 0.000012	 wd 0.0000	time 0.1991 (0.2482)	loss 1.2523 (1.3619)	grad_norm 0.4921 (0.5305)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:30:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:50 lr 0.000012	 wd 0.0000	time 0.2226 (0.2476)	loss 1.4023 (1.3618)	grad_norm 1.0165 (0.5310)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:31:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:25 lr 0.000012	 wd 0.0000	time 0.2110 (0.2469)	loss 1.3500 (1.3621)	grad_norm 0.4805 (0.5314)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:31:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000012	 wd 0.0000	time 0.1761 (0.2453)	loss 1.6035 (1.3628)	grad_norm 0.4997 (0.5321)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:31:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 20 training takes 0:10:18
[2024-07-14 20:32:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 34.306 (34.306)	Loss 0.4119 (0.4119)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 20:32:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.260 Acc@5 97.292
[2024-07-14 20:32:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-14 20:32:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 20:32:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][0/2502]	eta 11:35:34 lr 0.000012	 wd 0.0000	time 16.6806 (16.6806)	loss 1.5565 (1.5565)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:33:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:16:03 lr 0.000012	 wd 0.0000	time 0.2356 (0.4011)	loss 1.4593 (1.3819)	grad_norm 0.7294 (0.5196)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:33:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:12:40 lr 0.000012	 wd 0.0000	time 0.2361 (0.3305)	loss 0.8902 (1.3633)	grad_norm 0.4959 (0.5171)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:33:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:10:52 lr 0.000012	 wd 0.0000	time 0.2196 (0.2962)	loss 1.3911 (1.3562)	grad_norm 0.5308 (0.5162)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:34:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:09:45 lr 0.000011	 wd 0.0000	time 0.2108 (0.2783)	loss 1.4402 (1.3574)	grad_norm 0.5247 (0.5161)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:34:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:08:57 lr 0.000011	 wd 0.0000	time 0.2283 (0.2686)	loss 1.3558 (1.3567)	grad_norm 0.5057 (0.5169)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:35:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:25 lr 0.000011	 wd 0.0000	time 0.2175 (0.2660)	loss 1.1987 (1.3572)	grad_norm 0.5191 (0.5207)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:35:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:07:50 lr 0.000011	 wd 0.0000	time 0.1986 (0.2611)	loss 1.2803 (1.3519)	grad_norm 0.4673 (0.5212)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:35:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:17 lr 0.000011	 wd 0.0000	time 0.2282 (0.2573)	loss 1.2162 (1.3514)	grad_norm 0.4674 (0.5210)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:36:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:47 lr 0.000011	 wd 0.0000	time 0.2338 (0.2544)	loss 1.5306 (1.3520)	grad_norm 0.4691 (0.5221)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:36:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:22 lr 0.000011	 wd 0.0000	time 0.2256 (0.2544)	loss 1.0491 (1.3510)	grad_norm 0.5684 (0.5222)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:36:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:05:54 lr 0.000011	 wd 0.0000	time 0.2354 (0.2527)	loss 1.4609 (1.3511)	grad_norm 0.4643 (0.5226)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 20:37:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:26 lr 0.000011	 wd 0.0000	time 0.2493 (0.2510)	loss 1.3177 (1.3522)	grad_norm 0.4762 (0.5227)	loss_scale 4096.0000 (2215.1141)	mem 7984MB
[2024-07-14 20:37:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:59 lr 0.000011	 wd 0.0000	time 0.2607 (0.2493)	loss 1.5008 (1.3523)	grad_norm 0.5111 (0.5215)	loss_scale 4096.0000 (2359.6864)	mem 7984MB
[2024-07-14 20:38:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:34 lr 0.000011	 wd 0.0000	time 0.3422 (0.2492)	loss 1.4271 (1.3527)	grad_norm 0.6166 (0.5224)	loss_scale 4096.0000 (2483.6203)	mem 7984MB
[2024-07-14 20:38:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:04:09 lr 0.000010	 wd 0.0000	time 0.2288 (0.2488)	loss 1.6394 (1.3524)	grad_norm 0.5122 (0.5216)	loss_scale 4096.0000 (2591.0406)	mem 7984MB
[2024-07-14 20:38:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:43 lr 0.000010	 wd 0.0000	time 0.2087 (0.2478)	loss 1.2218 (1.3519)	grad_norm 0.5331 (0.5217)	loss_scale 4096.0000 (2685.0418)	mem 7984MB
[2024-07-14 20:39:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:18 lr 0.000010	 wd 0.0000	time 0.2480 (0.2469)	loss 1.4795 (1.3520)	grad_norm 0.5550 (0.5232)	loss_scale 4096.0000 (2767.9906)	mem 7984MB
[2024-07-14 20:39:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:53 lr 0.000010	 wd 0.0000	time 0.8947 (0.2473)	loss 1.0191 (1.3525)	grad_norm 0.4996 (0.5240)	loss_scale 4096.0000 (2841.7279)	mem 7984MB
[2024-07-14 20:40:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:29 lr 0.000010	 wd 0.0000	time 0.2297 (0.2476)	loss 0.9982 (1.3512)	grad_norm 0.5478 (0.5248)	loss_scale 4096.0000 (2907.7075)	mem 7984MB
[2024-07-14 20:40:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:02:03 lr 0.000010	 wd 0.0000	time 0.2246 (0.2470)	loss 1.3879 (1.3507)	grad_norm 0.5483 (0.5256)	loss_scale 4096.0000 (2967.0925)	mem 7984MB
[2024-07-14 20:40:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:39 lr 0.000010	 wd 0.0000	time 0.2563 (0.2463)	loss 1.1836 (1.3509)	grad_norm 0.5476 (0.5262)	loss_scale 4096.0000 (3020.8244)	mem 7984MB
[2024-07-14 20:41:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:14 lr 0.000010	 wd 0.0000	time 0.2448 (0.2468)	loss 1.5558 (1.3489)	grad_norm 0.5728 (0.5258)	loss_scale 4096.0000 (3069.6738)	mem 7984MB
[2024-07-14 20:41:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:49 lr 0.000010	 wd 0.0000	time 0.2181 (0.2465)	loss 1.5623 (1.3486)	grad_norm 0.5097 (0.5255)	loss_scale 4096.0000 (3114.2773)	mem 7984MB
[2024-07-14 20:42:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:25 lr 0.000010	 wd 0.0000	time 0.2081 (0.2461)	loss 1.3803 (1.3499)	grad_norm 0.5647 (0.5261)	loss_scale 4096.0000 (3155.1653)	mem 7984MB
[2024-07-14 20:42:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1903 (0.2445)	loss 1.3137 (1.3496)	grad_norm 0.5464 (0.5267)	loss_scale 4096.0000 (3192.7837)	mem 7984MB
[2024-07-14 20:42:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 21 training takes 0:10:17
[2024-07-14 20:43:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 38.561 (38.561)	Loss 0.4106 (0.4106)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 20:43:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.214 Acc@5 97.294
[2024-07-14 20:43:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 20:43:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 20:43:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][0/2502]	eta 11:23:26 lr 0.000010	 wd 0.0000	time 16.3894 (16.3894)	loss 1.3121 (1.3121)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:44:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:15:25 lr 0.000010	 wd 0.0000	time 0.2065 (0.3852)	loss 1.2641 (1.3606)	grad_norm 0.4741 (0.5434)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:44:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:12:21 lr 0.000009	 wd 0.0000	time 0.2616 (0.3222)	loss 1.1692 (1.3572)	grad_norm 0.6478 (0.5423)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:44:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:10:44 lr 0.000009	 wd 0.0000	time 0.2185 (0.2927)	loss 1.5124 (1.3610)	grad_norm 0.5157 (0.5410)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:45:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:09:40 lr 0.000009	 wd 0.0000	time 0.2310 (0.2760)	loss 1.4213 (1.3650)	grad_norm 0.5090 (0.5382)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:45:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:08:51 lr 0.000009	 wd 0.0000	time 0.2148 (0.2655)	loss 0.9014 (1.3644)	grad_norm 0.4916 (0.5401)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:46:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:18 lr 0.000009	 wd 0.0000	time 0.2466 (0.2622)	loss 1.3609 (1.3673)	grad_norm 0.5059 (0.5476)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:46:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:48 lr 0.000009	 wd 0.0000	time 0.2242 (0.2599)	loss 0.8942 (1.3628)	grad_norm 0.5017 (0.5448)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:46:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:07:16 lr 0.000009	 wd 0.0000	time 0.2281 (0.2565)	loss 1.3654 (1.3587)	grad_norm 0.4832 (0.5437)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:47:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:46 lr 0.000009	 wd 0.0000	time 0.2402 (0.2539)	loss 1.3368 (1.3578)	grad_norm 0.5061 (0.5407)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:47:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:20 lr 0.000009	 wd 0.0000	time 0.2311 (0.2532)	loss 1.5513 (1.3599)	grad_norm 0.5836 (0.5387)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:48:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:54 lr 0.000009	 wd 0.0000	time 0.2388 (0.2528)	loss 1.4034 (1.3574)	grad_norm 0.4979 (0.5365)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:48:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:26 lr 0.000009	 wd 0.0000	time 0.2175 (0.2507)	loss 1.3408 (1.3562)	grad_norm 0.5172 (0.5345)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:48:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:04:59 lr 0.000009	 wd 0.0000	time 0.2240 (0.2493)	loss 0.9412 (1.3568)	grad_norm 0.5063 (0.5334)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:49:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:34 lr 0.000008	 wd 0.0000	time 0.2541 (0.2487)	loss 1.5615 (1.3588)	grad_norm 0.4715 (0.5326)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:49:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:04:09 lr 0.000008	 wd 0.0000	time 0.1872 (0.2491)	loss 1.3240 (1.3595)	grad_norm 0.4800 (0.5338)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:50:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:43 lr 0.000008	 wd 0.0000	time 0.2338 (0.2482)	loss 1.5411 (1.3598)	grad_norm 0.5469 (0.5332)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:50:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:18 lr 0.000008	 wd 0.0000	time 0.2173 (0.2473)	loss 1.3059 (1.3594)	grad_norm 0.4969 (0.5324)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:50:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:53 lr 0.000008	 wd 0.0000	time 0.2430 (0.2468)	loss 1.5813 (1.3588)	grad_norm 0.5146 (0.5353)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:51:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:28 lr 0.000008	 wd 0.0000	time 0.2776 (0.2474)	loss 1.5368 (1.3583)	grad_norm 0.5458 (0.5349)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:51:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:02:03 lr 0.000008	 wd 0.0000	time 0.2839 (0.2468)	loss 1.5147 (1.3574)	grad_norm 0.4426 (0.5355)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:52:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:38 lr 0.000008	 wd 0.0000	time 0.2216 (0.2462)	loss 1.4299 (1.3579)	grad_norm 0.5414 (0.5347)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:52:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:14 lr 0.000008	 wd 0.0000	time 0.2374 (0.2459)	loss 1.4311 (1.3561)	grad_norm 0.5249 (0.5334)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:52:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:49 lr 0.000008	 wd 0.0000	time 0.1993 (0.2464)	loss 1.5033 (1.3562)	grad_norm 0.5275 (0.5333)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:53:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:25 lr 0.000008	 wd 0.0000	time 0.2268 (0.2460)	loss 1.2084 (1.3555)	grad_norm 0.4823 (0.5345)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:53:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1718 (0.2442)	loss 0.9854 (1.3546)	grad_norm 0.5499 (0.5342)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:53:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 22 training takes 0:10:15
[2024-07-14 20:54:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 31.970 (31.970)	Loss 0.4116 (0.4116)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 20:54:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.252 Acc@5 97.314
[2024-07-14 20:54:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-14 20:54:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 20:54:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][0/2502]	eta 11:00:13 lr 0.000008	 wd 0.0000	time 15.8326 (15.8326)	loss 1.1636 (1.1636)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 20:55:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:15:43 lr 0.000008	 wd 0.0000	time 0.2125 (0.3930)	loss 1.5709 (1.3908)	grad_norm 0.4615 (0.5249)	loss_scale 8192.0000 (4177.1089)	mem 7984MB
[2024-07-14 20:55:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:12:06 lr 0.000007	 wd 0.0000	time 0.2467 (0.3156)	loss 1.5463 (1.3705)	grad_norm 0.4910 (0.5215)	loss_scale 8192.0000 (6174.5672)	mem 7984MB
[2024-07-14 20:56:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:10:52 lr 0.000007	 wd 0.0000	time 0.2194 (0.2964)	loss 1.5101 (1.3638)	grad_norm 0.5764 (0.5174)	loss_scale 8192.0000 (6844.8106)	mem 7984MB
[2024-07-14 20:56:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:09:46 lr 0.000007	 wd 0.0000	time 0.2346 (0.2791)	loss 1.5256 (1.3554)	grad_norm 0.4760 (0.5201)	loss_scale 8192.0000 (7180.7681)	mem 7984MB
[2024-07-14 20:56:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:08:56 lr 0.000007	 wd 0.0000	time 0.1880 (0.2681)	loss 1.6801 (1.3602)	grad_norm 0.5108 (0.5188)	loss_scale 8192.0000 (7382.6108)	mem 7984MB
[2024-07-14 20:57:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:08:18 lr 0.000007	 wd 0.0000	time 0.2075 (0.2621)	loss 1.1243 (1.3600)	grad_norm 0.4770 (0.5210)	loss_scale 8192.0000 (7517.2845)	mem 7984MB
[2024-07-14 20:57:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:50 lr 0.000007	 wd 0.0000	time 0.2387 (0.2612)	loss 1.4177 (1.3573)	grad_norm 0.6033 (0.5242)	loss_scale 8192.0000 (7613.5350)	mem 7984MB
[2024-07-14 20:58:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:07:18 lr 0.000007	 wd 0.0000	time 0.2236 (0.2577)	loss 1.6831 (1.3561)	grad_norm 0.4424 (0.5241)	loss_scale 8192.0000 (7685.7528)	mem 7984MB
[2024-07-14 20:58:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:06:48 lr 0.000007	 wd 0.0000	time 0.2375 (0.2547)	loss 1.7049 (1.3527)	grad_norm 0.5544 (0.5321)	loss_scale 8192.0000 (7741.9401)	mem 7984MB
[2024-07-14 20:58:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:19 lr 0.000007	 wd 0.0000	time 0.2236 (0.2524)	loss 1.1466 (1.3507)	grad_norm 0.5018 (inf)	loss_scale 4096.0000 (7631.4086)	mem 7984MB
[2024-07-14 20:59:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:55 lr 0.000007	 wd 0.0000	time 0.2219 (0.2533)	loss 0.8743 (1.3464)	grad_norm 0.5110 (inf)	loss_scale 4096.0000 (7310.2997)	mem 7984MB
[2024-07-14 20:59:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:27 lr 0.000007	 wd 0.0000	time 0.2015 (0.2516)	loss 1.5558 (1.3483)	grad_norm 0.4989 (inf)	loss_scale 4096.0000 (7042.6644)	mem 7984MB
[2024-07-14 21:00:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:05:00 lr 0.000007	 wd 0.0000	time 0.2347 (0.2501)	loss 1.4409 (1.3497)	grad_norm 0.4722 (inf)	loss_scale 4096.0000 (6816.1722)	mem 7984MB
[2024-07-14 21:00:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:33 lr 0.000007	 wd 0.0000	time 0.2221 (0.2486)	loss 1.5870 (1.3496)	grad_norm 0.4737 (inf)	loss_scale 4096.0000 (6622.0128)	mem 7984MB
[2024-07-14 21:00:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:04:09 lr 0.000006	 wd 0.0000	time 0.2185 (0.2488)	loss 1.2741 (1.3519)	grad_norm 0.5269 (inf)	loss_scale 4096.0000 (6453.7242)	mem 7984MB
[2024-07-14 21:01:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:44 lr 0.000006	 wd 0.0000	time 0.2569 (0.2487)	loss 1.1667 (1.3512)	grad_norm 0.4850 (inf)	loss_scale 4096.0000 (6306.4585)	mem 7984MB
[2024-07-14 21:01:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:18 lr 0.000006	 wd 0.0000	time 0.2220 (0.2476)	loss 1.3173 (1.3515)	grad_norm 0.4970 (inf)	loss_scale 4096.0000 (6176.5079)	mem 7984MB
[2024-07-14 21:02:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:53 lr 0.000006	 wd 0.0000	time 0.2687 (0.2468)	loss 1.4292 (1.3510)	grad_norm 0.6526 (inf)	loss_scale 4096.0000 (6060.9883)	mem 7984MB
[2024-07-14 21:02:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:29 lr 0.000006	 wd 0.0000	time 0.2146 (0.2475)	loss 1.2280 (1.3537)	grad_norm 0.5741 (inf)	loss_scale 4096.0000 (5957.6223)	mem 7984MB
[2024-07-14 21:02:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:02:04 lr 0.000006	 wd 0.0000	time 0.2275 (0.2476)	loss 1.4543 (1.3525)	grad_norm 0.5410 (inf)	loss_scale 4096.0000 (5864.5877)	mem 7984MB
[2024-07-14 21:03:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:39 lr 0.000006	 wd 0.0000	time 0.1953 (0.2471)	loss 1.6968 (1.3530)	grad_norm 0.4869 (inf)	loss_scale 4096.0000 (5780.4093)	mem 7984MB
[2024-07-14 21:03:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:14 lr 0.000006	 wd 0.0000	time 0.2382 (0.2464)	loss 1.4651 (1.3508)	grad_norm 0.5051 (inf)	loss_scale 4096.0000 (5703.8801)	mem 7984MB
[2024-07-14 21:04:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:49 lr 0.000006	 wd 0.0000	time 0.9519 (0.2469)	loss 1.5860 (1.3510)	grad_norm 0.5138 (inf)	loss_scale 4096.0000 (5634.0026)	mem 7984MB
[2024-07-14 21:04:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:25 lr 0.000006	 wd 0.0000	time 0.2087 (0.2465)	loss 1.5363 (1.3515)	grad_norm 0.4628 (inf)	loss_scale 4096.0000 (5569.9459)	mem 7984MB
[2024-07-14 21:04:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000006	 wd 0.0000	time 0.1855 (0.2449)	loss 1.4293 (1.3522)	grad_norm 0.5531 (inf)	loss_scale 4096.0000 (5511.0116)	mem 7984MB
[2024-07-14 21:04:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 23 training takes 0:10:17
[2024-07-14 21:05:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 18.141 (18.141)	Loss 0.4111 (0.4111)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 21:05:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.248 Acc@5 97.304
[2024-07-14 21:05:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 21:05:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 21:06:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][0/2502]	eta 1 day, 21:53:40 lr 0.000006	 wd 0.0000	time 66.0354 (66.0354)	loss 1.5813 (1.5813)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:07:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:37:50 lr 0.000006	 wd 0.0000	time 0.2302 (0.9451)	loss 1.1455 (1.3916)	grad_norm 0.5044 (0.5340)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:07:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:24:16 lr 0.000006	 wd 0.0000	time 0.2245 (0.6326)	loss 1.4073 (1.3733)	grad_norm 0.5700 (0.5273)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:08:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:18:15 lr 0.000006	 wd 0.0000	time 0.2022 (0.4977)	loss 1.6264 (1.3665)	grad_norm 0.5295 (0.5262)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:08:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:15:04 lr 0.000005	 wd 0.0000	time 0.2013 (0.4305)	loss 1.3964 (1.3631)	grad_norm 0.5357 (0.5304)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:08:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:13:05 lr 0.000005	 wd 0.0000	time 0.3339 (0.3923)	loss 1.6599 (1.3644)	grad_norm 0.5706 (0.5282)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:09:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:11:41 lr 0.000005	 wd 0.0000	time 0.2230 (0.3687)	loss 1.3962 (1.3614)	grad_norm 1.1646 (0.5307)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:09:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:10:28 lr 0.000005	 wd 0.0000	time 0.2584 (0.3491)	loss 1.3389 (1.3625)	grad_norm 0.4950 (0.5349)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:09:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:09:28 lr 0.000005	 wd 0.0000	time 0.2163 (0.3341)	loss 1.4038 (1.3636)	grad_norm 0.5094 (0.5351)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:10:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:08:38 lr 0.000005	 wd 0.0000	time 0.2536 (0.3238)	loss 1.5494 (1.3605)	grad_norm 0.5249 (0.5348)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:10:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:07:56 lr 0.000005	 wd 0.0000	time 0.1919 (0.3170)	loss 1.2185 (1.3609)	grad_norm 0.4916 (0.5354)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:11:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:07:13 lr 0.000005	 wd 0.0000	time 0.2078 (0.3092)	loss 1.4922 (1.3598)	grad_norm 0.5196 (0.5340)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:11:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:06:34 lr 0.000005	 wd 0.0000	time 0.2151 (0.3027)	loss 1.2517 (1.3580)	grad_norm 0.5803 (0.5340)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:11:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:05:57 lr 0.000005	 wd 0.0000	time 0.2337 (0.2978)	loss 1.3899 (1.3574)	grad_norm 1.0213 (0.5343)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:12:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:05:24 lr 0.000005	 wd 0.0000	time 0.2008 (0.2946)	loss 1.3458 (1.3558)	grad_norm 0.5097 (0.5335)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:12:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:51 lr 0.000005	 wd 0.0000	time 0.2648 (0.2906)	loss 0.9718 (1.3542)	grad_norm 0.4700 (0.5345)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:13:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:04:18 lr 0.000005	 wd 0.0000	time 0.2306 (0.2870)	loss 1.5063 (1.3539)	grad_norm 0.5972 (0.5342)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:13:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:47 lr 0.000005	 wd 0.0000	time 0.2323 (0.2842)	loss 1.6882 (1.3551)	grad_norm 0.4937 (0.5360)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:14:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:03:18 lr 0.000005	 wd 0.0000	time 0.2580 (0.2832)	loss 1.1303 (1.3530)	grad_norm 0.5168 (inf)	loss_scale 2048.0000 (4032.3198)	mem 7984MB
[2024-07-14 21:14:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:49 lr 0.000005	 wd 0.0000	time 0.2108 (0.2811)	loss 1.4106 (1.3541)	grad_norm 0.4710 (inf)	loss_scale 2048.0000 (3927.9369)	mem 7984MB
[2024-07-14 21:14:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:02:19 lr 0.000004	 wd 0.0000	time 0.2007 (0.2788)	loss 1.3846 (1.3548)	grad_norm 0.5127 (inf)	loss_scale 2048.0000 (3833.9870)	mem 7984MB
[2024-07-14 21:15:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:51 lr 0.000004	 wd 0.0000	time 0.2370 (0.2769)	loss 1.5358 (1.3539)	grad_norm 0.5004 (inf)	loss_scale 2048.0000 (3748.9805)	mem 7984MB
[2024-07-14 21:15:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:23 lr 0.000004	 wd 0.0000	time 0.2059 (0.2759)	loss 1.3985 (1.3537)	grad_norm 0.5296 (inf)	loss_scale 2048.0000 (3671.6983)	mem 7984MB
[2024-07-14 21:16:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:55 lr 0.000004	 wd 0.0000	time 0.2111 (0.2741)	loss 1.7350 (1.3534)	grad_norm 0.5059 (inf)	loss_scale 2048.0000 (3601.1334)	mem 7984MB
[2024-07-14 21:16:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:27 lr 0.000004	 wd 0.0000	time 0.1886 (0.2724)	loss 1.4867 (1.3533)	grad_norm 0.5071 (inf)	loss_scale 2048.0000 (3536.4465)	mem 7984MB
[2024-07-14 21:16:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000004	 wd 0.0000	time 0.1729 (0.2697)	loss 1.2606 (1.3534)	grad_norm 0.6118 (inf)	loss_scale 2048.0000 (3476.9324)	mem 7984MB
[2024-07-14 21:16:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 24 training takes 0:11:22
[2024-07-14 21:17:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 35.836 (35.836)	Loss 0.4114 (0.4114)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 21:17:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.264 Acc@5 97.304
[2024-07-14 21:17:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-14 21:17:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 21:18:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][0/2502]	eta 10:59:49 lr 0.000004	 wd 0.0000	time 15.8231 (15.8231)	loss 1.2487 (1.2487)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:18:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:16:14 lr 0.000004	 wd 0.0000	time 0.2621 (0.4056)	loss 1.3887 (1.3223)	grad_norm 0.5097 (0.5283)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:18:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:12:37 lr 0.000004	 wd 0.0000	time 0.2159 (0.3292)	loss 1.4746 (1.3495)	grad_norm 0.4555 (0.5289)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:19:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:10:51 lr 0.000004	 wd 0.0000	time 0.2055 (0.2958)	loss 1.1139 (1.3391)	grad_norm 0.4337 (0.5317)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:19:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:09:46 lr 0.000004	 wd 0.0000	time 0.2011 (0.2790)	loss 1.2416 (1.3542)	grad_norm 0.4902 (0.5370)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:20:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:09:02 lr 0.000004	 wd 0.0000	time 0.2276 (0.2711)	loss 1.5549 (1.3543)	grad_norm 0.4931 (0.5366)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:20:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:29 lr 0.000004	 wd 0.0000	time 0.2152 (0.2679)	loss 1.1396 (1.3559)	grad_norm 0.4648 (0.5359)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:20:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:07:52 lr 0.000004	 wd 0.0000	time 0.2042 (0.2622)	loss 1.2268 (1.3563)	grad_norm 0.5724 (0.5359)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:21:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:07:19 lr 0.000004	 wd 0.0000	time 0.2244 (0.2580)	loss 0.9957 (1.3565)	grad_norm 0.5023 (0.5411)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:21:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:06:48 lr 0.000004	 wd 0.0000	time 0.2443 (0.2551)	loss 1.4989 (1.3583)	grad_norm 0.7165 (0.5392)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:22:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:23 lr 0.000004	 wd 0.0000	time 0.2222 (0.2553)	loss 1.2238 (1.3589)	grad_norm 0.4958 (0.5388)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:22:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:55 lr 0.000004	 wd 0.0000	time 0.2222 (0.2534)	loss 1.2873 (1.3570)	grad_norm 0.5674 (0.5369)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:22:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:27 lr 0.000004	 wd 0.0000	time 0.2402 (0.2514)	loss 1.3487 (1.3594)	grad_norm 0.5562 (0.5356)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:23:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:05:00 lr 0.000003	 wd 0.0000	time 0.2310 (0.2500)	loss 1.4826 (1.3611)	grad_norm 0.5241 (0.5370)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:23:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:35 lr 0.000003	 wd 0.0000	time 0.2426 (0.2504)	loss 1.1217 (1.3606)	grad_norm 1.1570 (0.5363)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:24:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:04:10 lr 0.000003	 wd 0.0000	time 0.2118 (0.2495)	loss 1.2366 (1.3607)	grad_norm 0.4964 (0.5360)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:24:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:44 lr 0.000003	 wd 0.0000	time 0.2415 (0.2485)	loss 1.4907 (1.3600)	grad_norm 0.4960 (0.5346)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:24:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:18 lr 0.000003	 wd 0.0000	time 0.2357 (0.2476)	loss 1.3813 (1.3593)	grad_norm 0.4919 (0.5351)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:25:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:54 lr 0.000003	 wd 0.0000	time 0.2188 (0.2490)	loss 1.5397 (1.3591)	grad_norm 0.5458 (0.5359)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:25:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:29 lr 0.000003	 wd 0.0000	time 0.2438 (0.2488)	loss 1.9489 (1.3590)	grad_norm 0.8343 (0.5351)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:26:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:02:04 lr 0.000003	 wd 0.0000	time 0.2189 (0.2480)	loss 1.2675 (1.3583)	grad_norm 0.4841 (0.5345)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:26:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:39 lr 0.000003	 wd 0.0000	time 0.2391 (0.2474)	loss 0.8754 (1.3583)	grad_norm 0.5653 (0.5358)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:26:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:14 lr 0.000003	 wd 0.0000	time 0.2482 (0.2478)	loss 1.4300 (1.3571)	grad_norm 0.5577 (0.5356)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:27:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:49 lr 0.000003	 wd 0.0000	time 0.2301 (0.2474)	loss 1.1998 (1.3557)	grad_norm 0.4472 (0.5361)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:27:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:25 lr 0.000003	 wd 0.0000	time 0.1991 (0.2468)	loss 1.3932 (1.3572)	grad_norm 0.4797 (0.5384)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:28:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1728 (0.2450)	loss 1.4822 (1.3573)	grad_norm 0.5435 (0.5390)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:28:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 25 training takes 0:10:20
[2024-07-14 21:28:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 35.236 (35.236)	Loss 0.4116 (0.4116)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 21:29:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.242 Acc@5 97.308
[2024-07-14 21:29:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 21:29:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 21:29:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][0/2502]	eta 11:27:06 lr 0.000003	 wd 0.0000	time 16.4776 (16.4776)	loss 1.3224 (1.3224)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:29:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:16:00 lr 0.000003	 wd 0.0000	time 0.2569 (0.3999)	loss 1.5147 (1.3498)	grad_norm 0.4720 (0.5376)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:30:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:12:41 lr 0.000003	 wd 0.0000	time 0.2156 (0.3307)	loss 1.4764 (1.3704)	grad_norm 0.5369 (0.5269)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:30:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:10:52 lr 0.000003	 wd 0.0000	time 0.2280 (0.2962)	loss 1.4848 (1.3618)	grad_norm 0.5345 (0.5229)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:30:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:09:45 lr 0.000003	 wd 0.0000	time 0.2068 (0.2784)	loss 1.6298 (1.3635)	grad_norm 0.6312 (0.5232)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:31:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:08:56 lr 0.000003	 wd 0.0000	time 0.2347 (0.2680)	loss 1.6169 (1.3701)	grad_norm 0.4990 (0.5348)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:31:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:08:24 lr 0.000003	 wd 0.0000	time 0.2958 (0.2654)	loss 1.4060 (1.3653)	grad_norm 0.4871 (0.5393)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:32:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:50 lr 0.000003	 wd 0.0000	time 0.2186 (0.2610)	loss 1.5384 (1.3614)	grad_norm 0.4744 (0.5349)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-14 21:32:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:07:17 lr 0.000002	 wd 0.0000	time 0.2255 (0.2572)	loss 1.6056 (1.3601)	grad_norm 0.4656 (0.5342)	loss_scale 4096.0000 (2201.4082)	mem 7984MB
[2024-07-14 21:32:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:06:46 lr 0.000002	 wd 0.0000	time 0.2082 (0.2540)	loss 1.3834 (1.3602)	grad_norm 0.6312 (0.5325)	loss_scale 4096.0000 (2411.6848)	mem 7984MB
[2024-07-14 21:33:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:23 lr 0.000002	 wd 0.0000	time 0.5017 (0.2555)	loss 1.4165 (1.3608)	grad_norm 0.5161 (0.5308)	loss_scale 4096.0000 (2579.9481)	mem 7984MB
[2024-07-14 21:33:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:55 lr 0.000002	 wd 0.0000	time 0.2317 (0.2534)	loss 1.5807 (1.3622)	grad_norm 0.4479 (0.5300)	loss_scale 4096.0000 (2717.6458)	mem 7984MB
[2024-07-14 21:34:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:27 lr 0.000002	 wd 0.0000	time 0.2108 (0.2516)	loss 1.0771 (1.3626)	grad_norm 0.5389 (0.5298)	loss_scale 4096.0000 (2832.4130)	mem 7984MB
[2024-07-14 21:34:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:05:00 lr 0.000002	 wd 0.0000	time 0.3019 (0.2502)	loss 0.9470 (1.3609)	grad_norm 0.5592 (0.5301)	loss_scale 4096.0000 (2929.5373)	mem 7984MB
[2024-07-14 21:34:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:36 lr 0.000002	 wd 0.0000	time 0.1877 (0.2508)	loss 1.5917 (1.3603)	grad_norm 0.5260 (0.5308)	loss_scale 4096.0000 (3012.7966)	mem 7984MB
[2024-07-14 21:35:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:04:10 lr 0.000002	 wd 0.0000	time 0.2589 (0.2501)	loss 1.3976 (1.3591)	grad_norm 0.5037 (0.5298)	loss_scale 4096.0000 (3084.9620)	mem 7984MB
[2024-07-14 21:35:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:44 lr 0.000002	 wd 0.0000	time 0.2332 (0.2491)	loss 1.4471 (1.3580)	grad_norm 0.5652 (0.5307)	loss_scale 4096.0000 (3148.1124)	mem 7984MB
[2024-07-14 21:36:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:18 lr 0.000002	 wd 0.0000	time 0.2392 (0.2481)	loss 1.2803 (1.3590)	grad_norm 0.5539 (0.5302)	loss_scale 4096.0000 (3203.8377)	mem 7984MB
[2024-07-14 21:36:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:54 lr 0.000002	 wd 0.0000	time 0.5950 (0.2482)	loss 1.5219 (1.3619)	grad_norm 0.6574 (0.5298)	loss_scale 4096.0000 (3253.3748)	mem 7984MB
[2024-07-14 21:36:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:29 lr 0.000002	 wd 0.0000	time 0.2274 (0.2487)	loss 0.9668 (1.3604)	grad_norm 0.4659 (0.5290)	loss_scale 4096.0000 (3297.7002)	mem 7984MB
[2024-07-14 21:37:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:02:04 lr 0.000002	 wd 0.0000	time 0.2134 (0.2480)	loss 0.9043 (1.3594)	grad_norm 0.6338 (0.5322)	loss_scale 4096.0000 (3337.5952)	mem 7984MB
[2024-07-14 21:37:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:39 lr 0.000002	 wd 0.0000	time 0.2523 (0.2473)	loss 1.1262 (1.3583)	grad_norm 0.5080 (0.5316)	loss_scale 4096.0000 (3373.6925)	mem 7984MB
[2024-07-14 21:38:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:14 lr 0.000002	 wd 0.0000	time 0.2269 (0.2478)	loss 0.9590 (1.3581)	grad_norm 0.5108 (0.5319)	loss_scale 4096.0000 (3406.5098)	mem 7984MB
[2024-07-14 21:38:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:50 lr 0.000002	 wd 0.0000	time 0.2341 (0.2477)	loss 1.2001 (1.3569)	grad_norm 0.5011 (0.5318)	loss_scale 4096.0000 (3436.4746)	mem 7984MB
[2024-07-14 21:38:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:25 lr 0.000002	 wd 0.0000	time 0.2130 (0.2472)	loss 1.1113 (1.3570)	grad_norm 0.6200 (0.5321)	loss_scale 4096.0000 (3463.9434)	mem 7984MB
[2024-07-14 21:39:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1842 (0.2453)	loss 0.9491 (1.3552)	grad_norm 0.5044 (0.5324)	loss_scale 4096.0000 (3489.2155)	mem 7984MB
[2024-07-14 21:39:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 26 training takes 0:10:21
[2024-07-14 21:40:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 37.434 (37.434)	Loss 0.4114 (0.4114)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 21:40:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.232 Acc@5 97.302
[2024-07-14 21:40:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-14 21:40:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 21:40:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][0/2502]	eta 10:50:52 lr 0.000002	 wd 0.0000	time 15.6084 (15.6084)	loss 0.9319 (0.9319)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:41:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:15:34 lr 0.000002	 wd 0.0000	time 0.2160 (0.3889)	loss 1.4869 (1.3619)	grad_norm 0.5746 (0.6010)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:41:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:12:31 lr 0.000002	 wd 0.0000	time 0.2141 (0.3264)	loss 1.5764 (1.3569)	grad_norm 0.6655 (0.5633)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:41:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:10:48 lr 0.000002	 wd 0.0000	time 0.2232 (0.2944)	loss 1.3576 (1.3571)	grad_norm 0.5034 (0.5514)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:42:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:09:42 lr 0.000002	 wd 0.0000	time 0.2070 (0.2774)	loss 1.4465 (1.3549)	grad_norm 0.4837 (0.5456)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:42:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:08:54 lr 0.000002	 wd 0.0000	time 0.2282 (0.2671)	loss 0.9784 (1.3508)	grad_norm 0.6125 (0.5443)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:43:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:23 lr 0.000002	 wd 0.0000	time 0.2286 (0.2647)	loss 1.2697 (1.3539)	grad_norm 0.5051 (0.5414)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:43:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:49 lr 0.000002	 wd 0.0000	time 0.2214 (0.2604)	loss 1.4783 (1.3596)	grad_norm 0.4896 (0.5387)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:43:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:16 lr 0.000002	 wd 0.0000	time 0.2466 (0.2564)	loss 1.5181 (1.3630)	grad_norm 0.4828 (0.5378)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:44:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:46 lr 0.000001	 wd 0.0000	time 0.2210 (0.2534)	loss 1.2803 (1.3677)	grad_norm 0.4669 (0.5366)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:44:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:20 lr 0.000001	 wd 0.0000	time 0.3345 (0.2530)	loss 1.4125 (1.3659)	grad_norm 1.1228 (0.5359)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:45:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:54 lr 0.000001	 wd 0.0000	time 0.2150 (0.2528)	loss 1.5116 (1.3657)	grad_norm 0.4739 (0.5361)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:45:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:26 lr 0.000001	 wd 0.0000	time 0.2219 (0.2511)	loss 1.4791 (1.3656)	grad_norm 0.7685 (0.5355)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:45:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:59 lr 0.000001	 wd 0.0000	time 0.2167 (0.2495)	loss 1.4784 (1.3629)	grad_norm 0.4615 (0.5339)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:46:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:35 lr 0.000001	 wd 0.0000	time 0.2119 (0.2496)	loss 1.2680 (1.3633)	grad_norm 0.4927 (0.5359)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:46:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:04:10 lr 0.000001	 wd 0.0000	time 0.2426 (0.2496)	loss 1.5198 (1.3630)	grad_norm 0.4826 (0.5373)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:47:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:44 lr 0.000001	 wd 0.0000	time 0.2322 (0.2485)	loss 1.5536 (1.3610)	grad_norm 0.5255 (0.5381)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:47:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:18 lr 0.000001	 wd 0.0000	time 0.2122 (0.2475)	loss 1.3944 (1.3588)	grad_norm 0.4843 (0.5380)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:47:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:53 lr 0.000001	 wd 0.0000	time 0.2258 (0.2474)	loss 1.5056 (1.3593)	grad_norm 0.4922 (0.5372)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:48:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:29 lr 0.000001	 wd 0.0000	time 0.2665 (0.2478)	loss 1.0843 (1.3608)	grad_norm 0.5246 (0.5360)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:48:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:02:04 lr 0.000001	 wd 0.0000	time 0.2092 (0.2472)	loss 1.0582 (1.3596)	grad_norm 0.4681 (0.5356)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:49:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:39 lr 0.000001	 wd 0.0000	time 0.2253 (0.2464)	loss 1.6899 (1.3589)	grad_norm 0.4765 (0.5349)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:49:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:14 lr 0.000001	 wd 0.0000	time 0.2378 (0.2464)	loss 1.0920 (1.3596)	grad_norm 0.5763 (0.5353)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 21:49:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:49 lr 0.000001	 wd 0.0000	time 0.2242 (0.2466)	loss 1.4453 (1.3597)	grad_norm 0.4875 (0.5350)	loss_scale 8192.0000 (4206.3659)	mem 7984MB
[2024-07-14 21:50:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:25 lr 0.000001	 wd 0.0000	time 0.2056 (0.2461)	loss 1.3680 (1.3593)	grad_norm 0.4781 (0.5355)	loss_scale 8192.0000 (4372.3648)	mem 7984MB
[2024-07-14 21:50:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1743 (0.2443)	loss 1.4970 (1.3577)	grad_norm 0.6000 (0.5355)	loss_scale 8192.0000 (4525.0892)	mem 7984MB
[2024-07-14 21:50:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 27 training takes 0:10:19
[2024-07-14 21:51:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 38.342 (38.342)	Loss 0.4119 (0.4119)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 21:51:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.254 Acc@5 97.310
[2024-07-14 21:51:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-14 21:51:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 21:51:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][0/2502]	eta 11:01:26 lr 0.000001	 wd 0.0000	time 15.8620 (15.8620)	loss 1.2862 (1.2862)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 21:52:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:15:38 lr 0.000001	 wd 0.0000	time 0.2163 (0.3909)	loss 1.0630 (1.3387)	grad_norm 0.4910 (0.5167)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 21:52:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:13:47 lr 0.000001	 wd 0.0000	time 0.2412 (0.3597)	loss 1.0655 (1.3425)	grad_norm 0.4928 (0.5260)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 21:53:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:11:35 lr 0.000001	 wd 0.0000	time 0.1943 (0.3158)	loss 1.6323 (1.3526)	grad_norm 0.4661 (0.5282)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 21:53:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:10:18 lr 0.000001	 wd 0.0000	time 0.1978 (0.2941)	loss 1.3826 (1.3572)	grad_norm 0.4636 (0.5356)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 21:54:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:09:22 lr 0.000001	 wd 0.0000	time 0.2563 (0.2810)	loss 1.5575 (1.3592)	grad_norm 0.4716 (0.5354)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 21:54:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:46 lr 0.000001	 wd 0.0000	time 0.2210 (0.2766)	loss 1.3794 (1.3591)	grad_norm 0.5390 (0.5418)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-14 21:54:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:08:07 lr 0.000001	 wd 0.0000	time 0.2405 (0.2707)	loss 1.0278 (1.3610)	grad_norm 0.4738 (inf)	loss_scale 4096.0000 (7923.2183)	mem 7984MB
[2024-07-14 21:55:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:32 lr 0.000001	 wd 0.0000	time 0.2310 (0.2656)	loss 1.6131 (1.3581)	grad_norm 0.4830 (inf)	loss_scale 4096.0000 (7445.4132)	mem 7984MB
[2024-07-14 21:55:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:59 lr 0.000001	 wd 0.0000	time 0.2324 (0.2617)	loss 1.5244 (1.3587)	grad_norm 0.5072 (inf)	loss_scale 4096.0000 (7073.6693)	mem 7984MB
[2024-07-14 21:56:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:32 lr 0.000001	 wd 0.0000	time 0.3312 (0.2613)	loss 1.5498 (1.3613)	grad_norm 0.5171 (inf)	loss_scale 4096.0000 (6776.1998)	mem 7984MB
[2024-07-14 21:56:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:06:03 lr 0.000001	 wd 0.0000	time 0.2313 (0.2593)	loss 0.9377 (1.3579)	grad_norm 0.5332 (inf)	loss_scale 4096.0000 (6532.7666)	mem 7984MB
[2024-07-14 21:56:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:34 lr 0.000001	 wd 0.0000	time 0.2132 (0.2569)	loss 1.2119 (1.3581)	grad_norm 1.5218 (inf)	loss_scale 4096.0000 (6329.8718)	mem 7984MB
[2024-07-14 21:57:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:05:06 lr 0.000001	 wd 0.0000	time 0.2566 (0.2550)	loss 1.5545 (1.3549)	grad_norm 0.5038 (inf)	loss_scale 4096.0000 (6158.1676)	mem 7984MB
[2024-07-14 21:57:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:41 lr 0.000001	 wd 0.0000	time 0.2108 (0.2557)	loss 0.9227 (1.3559)	grad_norm 0.4965 (inf)	loss_scale 4096.0000 (6010.9750)	mem 7984MB
[2024-07-14 21:58:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:04:15 lr 0.000001	 wd 0.0000	time 0.2320 (0.2546)	loss 1.4800 (1.3545)	grad_norm 0.5795 (inf)	loss_scale 4096.0000 (5883.3951)	mem 7984MB
[2024-07-14 21:58:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:48 lr 0.000001	 wd 0.0000	time 0.2338 (0.2532)	loss 1.1873 (1.3541)	grad_norm 0.5475 (inf)	loss_scale 4096.0000 (5771.7527)	mem 7984MB
[2024-07-14 21:58:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:22 lr 0.000001	 wd 0.0000	time 0.2159 (0.2521)	loss 1.4121 (1.3555)	grad_norm 0.5447 (inf)	loss_scale 4096.0000 (5673.2369)	mem 7984MB
[2024-07-14 21:59:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:57 lr 0.000001	 wd 0.0000	time 0.2426 (0.2522)	loss 1.3747 (1.3552)	grad_norm 0.5986 (inf)	loss_scale 4096.0000 (5585.6613)	mem 7984MB
[2024-07-14 21:59:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:31 lr 0.000001	 wd 0.0000	time 0.2457 (0.2519)	loss 1.5391 (1.3542)	grad_norm 0.5797 (inf)	loss_scale 4096.0000 (5507.2993)	mem 7984MB
[2024-07-14 22:00:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:02:05 lr 0.000001	 wd 0.0000	time 0.2271 (0.2509)	loss 0.8793 (1.3541)	grad_norm 0.5259 (inf)	loss_scale 4096.0000 (5436.7696)	mem 7984MB
[2024-07-14 22:00:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:40 lr 0.000001	 wd 0.0000	time 0.1997 (0.2500)	loss 1.0880 (1.3543)	grad_norm 0.4829 (inf)	loss_scale 4096.0000 (5372.9538)	mem 7984MB
[2024-07-14 22:00:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:15 lr 0.000001	 wd 0.0000	time 0.2047 (0.2502)	loss 1.5277 (1.3532)	grad_norm 0.5276 (inf)	loss_scale 4096.0000 (5314.9368)	mem 7984MB
[2024-07-14 22:01:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:50 lr 0.000001	 wd 0.0000	time 0.2252 (0.2500)	loss 1.0881 (1.3533)	grad_norm 0.4935 (inf)	loss_scale 4096.0000 (5261.9626)	mem 7984MB
[2024-07-14 22:01:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:25 lr 0.000001	 wd 0.0000	time 0.2318 (0.2494)	loss 1.5586 (1.3518)	grad_norm 0.4921 (inf)	loss_scale 4096.0000 (5213.4011)	mem 7984MB
[2024-07-14 22:01:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1809 (0.2475)	loss 1.1905 (1.3510)	grad_norm 0.5642 (inf)	loss_scale 4096.0000 (5168.7229)	mem 7984MB
[2024-07-14 22:02:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 28 training takes 0:10:27
[2024-07-14 22:02:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 36.333 (36.333)	Loss 0.4119 (0.4119)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 22:03:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.256 Acc@5 97.306
[2024-07-14 22:03:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-14 22:03:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 22:03:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][0/2502]	eta 11:30:18 lr 0.000001	 wd 0.0000	time 16.5543 (16.5543)	loss 1.4048 (1.4048)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:03:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:15:36 lr 0.000001	 wd 0.0000	time 0.2613 (0.3898)	loss 1.4598 (1.3324)	grad_norm 0.4659 (0.5144)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:04:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:12:40 lr 0.000001	 wd 0.0000	time 0.1728 (0.3303)	loss 1.1456 (1.3472)	grad_norm 0.4939 (0.5236)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:04:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:10:54 lr 0.000001	 wd 0.0000	time 0.2146 (0.2973)	loss 1.4853 (1.3461)	grad_norm 0.4926 (0.5252)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:04:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:09:46 lr 0.000001	 wd 0.0000	time 0.1887 (0.2789)	loss 1.1750 (1.3548)	grad_norm 0.5308 (0.5223)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:05:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:08:56 lr 0.000001	 wd 0.0000	time 0.2300 (0.2682)	loss 0.9433 (1.3564)	grad_norm 0.5046 (0.5250)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:05:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:25 lr 0.000000	 wd 0.0000	time 0.3031 (0.2656)	loss 1.3431 (1.3573)	grad_norm 0.4691 (0.5279)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:06:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:52 lr 0.000000	 wd 0.0000	time 0.2258 (0.2621)	loss 1.5669 (1.3582)	grad_norm 0.5603 (0.5274)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:06:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:07:19 lr 0.000000	 wd 0.0000	time 0.2037 (0.2581)	loss 0.7927 (1.3592)	grad_norm 0.4625 (0.5281)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:06:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:06:48 lr 0.000000	 wd 0.0000	time 0.2583 (0.2548)	loss 1.4158 (1.3590)	grad_norm 0.5157 (0.5315)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:07:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:22 lr 0.000000	 wd 0.0000	time 0.2039 (0.2545)	loss 1.3202 (1.3587)	grad_norm 0.4765 (0.5318)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:07:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:56 lr 0.000000	 wd 0.0000	time 0.2211 (0.2546)	loss 1.4585 (1.3592)	grad_norm 0.4890 (0.5329)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:08:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:28 lr 0.000000	 wd 0.0000	time 0.2227 (0.2527)	loss 1.2618 (1.3562)	grad_norm 0.5190 (0.5324)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:08:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:05:01 lr 0.000000	 wd 0.0000	time 0.2399 (0.2510)	loss 1.5369 (1.3570)	grad_norm 0.5980 (0.5344)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:08:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:36 lr 0.000000	 wd 0.0000	time 0.2734 (0.2508)	loss 1.7611 (1.3559)	grad_norm 0.4901 (0.5337)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:09:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:04:11 lr 0.000000	 wd 0.0000	time 0.1983 (0.2510)	loss 1.2952 (1.3572)	grad_norm 0.7967 (0.5334)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:09:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:45 lr 0.000000	 wd 0.0000	time 0.1957 (0.2500)	loss 1.4677 (1.3586)	grad_norm 0.4914 (0.5317)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:10:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:19 lr 0.000000	 wd 0.0000	time 0.2352 (0.2487)	loss 1.2885 (1.3555)	grad_norm 0.4938 (0.5309)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:10:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:54 lr 0.000000	 wd 0.0000	time 0.2359 (0.2487)	loss 1.1567 (1.3571)	grad_norm 0.5237 (0.5307)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:10:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:30 lr 0.000000	 wd 0.0000	time 0.2220 (0.2493)	loss 1.2242 (1.3569)	grad_norm 0.5037 (0.5295)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:11:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:02:04 lr 0.000000	 wd 0.0000	time 0.2103 (0.2485)	loss 1.4818 (1.3570)	grad_norm 0.5773 (0.5297)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:11:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:39 lr 0.000000	 wd 0.0000	time 0.2410 (0.2477)	loss 1.4999 (1.3575)	grad_norm 0.8405 (0.5327)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-14 22:12:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:14 lr 0.000000	 wd 0.0000	time 0.2207 (0.2476)	loss 1.3953 (1.3591)	grad_norm 0.5164 (0.5316)	loss_scale 8192.0000 (4185.3267)	mem 7984MB
[2024-07-14 22:12:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:50 lr 0.000000	 wd 0.0000	time 0.2271 (0.2478)	loss 1.4187 (1.3604)	grad_norm 0.5287 (0.5318)	loss_scale 8192.0000 (4359.4542)	mem 7984MB
[2024-07-14 22:12:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.2495 (0.2472)	loss 1.4048 (1.3611)	grad_norm 0.5252 (0.5322)	loss_scale 8192.0000 (4519.0771)	mem 7984MB
[2024-07-14 22:13:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000000	 wd 0.0000	time 0.1837 (0.2455)	loss 1.5604 (1.3602)	grad_norm 0.4940 (0.5320)	loss_scale 8192.0000 (4665.9352)	mem 7984MB
[2024-07-14 22:13:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 249): INFO EPOCH 29 training takes 0:10:22
[2024-07-14 22:13:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft/ckpt_epoch_29.pth saving......
[2024-07-14 22:13:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_stag4-full-ft/ckpt_epoch_29.pth saved !!!
[2024-07-14 22:14:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 87.318 (87.318)	Loss 0.4121 (0.4121)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-14 22:15:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 296): INFO  * Acc@1 84.258 Acc@5 97.306
[2024-07-14 22:15:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-14 22:15:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 182): INFO Max accuracy: 84.26%
[2024-07-14 22:15:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_stage_process4-efficient-ft] (main.py 189): INFO Training time 5:51:00
