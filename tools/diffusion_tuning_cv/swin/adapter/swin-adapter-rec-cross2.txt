[2024-07-12 22:23:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/config.json
[2024-07-12 22:23:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer1/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_swin_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    DEPTHS:
    - 3
    - 3
    - 9
    - 3
    DIMS:
    - 96
    - 192
    - 384
    - 768
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: false
    AB_NORM_LTM: false
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: fullfinetune
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 4.0e-05
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.0e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 4.0e-08
  WEIGHT_DECAY: 1.0e-08

[2024-07-12 22:23:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/swin/diffusion_ft_adapter_swin_base_patch4_window7_224_22kto1k_step_cross_process2.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer1/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-12 22:23:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 108): INFO Creating model:adapter_swin_diffusion_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft
[2024-07-12 22:23:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 110): INFO Adapter_SwinTransformer_Diffusion_Finetune(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (uma): UMA(filter_strategy1=23, filter_strategy2=7,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=128, emb_dim=32, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=128, out_features=32, bias=True)
            (up): Linear(in_features=32, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=256, emb_dim=64, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=256, out_features=64, bias=True)
            (up): Linear(in_features=64, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): VCNU_SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=512, emb_dim=128, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=512, out_features=128, bias=True)
            (up): Linear(in_features=128, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VCNU_SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0, training_mode=tfs
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (adapter): Adapter(
            dim=1024, emb_dim=256, model_style=trans, 
            (activation): GELU()
            (down): Linear(in_features=1024, out_features=256, bias=True)
            (up): Linear(in_features=256, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-12 22:23:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 113): INFO number of params: 4531880
[2024-07-12 22:23:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 116): INFO number of GFLOPs: 15.438473216
[2024-07-12 22:23:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 150): INFO no checkpoint found in pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft, ignoring auto resume
[2024-07-12 22:23:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer1/ckpt_epoch_best.pth for fine-tuning......
[2024-07-12 22:23:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])
[2024-07-12 22:23:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer1/ckpt_epoch_best.pth'
[2024-07-12 22:24:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 63.101 (63.101)	Loss 0.4146 (0.4146)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 1490MB
[2024-07-12 22:24:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.148 Acc@5 97.258
[2024-07-12 22:24:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 162): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-12 22:24:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 168): INFO Start training
[2024-07-12 22:25:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][0/2502]	eta 14:16:03 lr 0.000000	 wd 0.0000	time 20.5292 (20.5292)	loss 1.6050 (1.6050)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 7938MB
[2024-07-12 22:25:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:20:48 lr 0.000000	 wd 0.0000	time 0.2221 (0.5199)	loss 1.4149 (1.3993)	grad_norm 0.5584 (nan)	loss_scale 16384.0000 (31145.8218)	mem 7984MB
[2024-07-12 22:26:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:14:28 lr 0.000001	 wd 0.0000	time 0.2136 (0.3772)	loss 1.4280 (1.3845)	grad_norm 0.5156 (nan)	loss_scale 16384.0000 (23801.6318)	mem 7984MB
[2024-07-12 22:26:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:05 lr 0.000001	 wd 0.0000	time 0.2182 (0.3293)	loss 1.4373 (1.3650)	grad_norm 0.4685 (nan)	loss_scale 8192.0000 (20466.3920)	mem 7984MB
[2024-07-12 22:26:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:43 lr 0.000001	 wd 0.0000	time 0.2375 (0.3060)	loss 1.8322 (1.3677)	grad_norm 0.4609 (nan)	loss_scale 8192.0000 (17405.4464)	mem 7984MB
[2024-07-12 22:27:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:10:22 lr 0.000002	 wd 0.0000	time 0.2555 (0.3108)	loss 1.4874 (1.3663)	grad_norm 0.4579 (nan)	loss_scale 8192.0000 (15566.4351)	mem 7984MB
[2024-07-12 22:27:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:26 lr 0.000002	 wd 0.0000	time 0.2192 (0.2977)	loss 1.1546 (1.3658)	grad_norm 0.4771 (nan)	loss_scale 8192.0000 (14339.4077)	mem 7984MB
[2024-07-12 22:28:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:40 lr 0.000002	 wd 0.0000	time 0.2357 (0.2889)	loss 1.4158 (1.3617)	grad_norm 0.4915 (nan)	loss_scale 8192.0000 (13462.4593)	mem 7984MB
[2024-07-12 22:28:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:08:02 lr 0.000003	 wd 0.0000	time 0.2450 (0.2834)	loss 1.5317 (1.3628)	grad_norm 0.5467 (nan)	loss_scale 8192.0000 (12804.4744)	mem 7984MB
[2024-07-12 22:28:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:31 lr 0.000003	 wd 0.0000	time 0.2207 (0.2816)	loss 1.5524 (1.3578)	grad_norm 0.4518 (nan)	loss_scale 4096.0000 (12183.4406)	mem 7984MB
[2024-07-12 22:29:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:06:55 lr 0.000003	 wd 0.0000	time 0.2542 (0.2769)	loss 1.3642 (1.3575)	grad_norm 0.6054 (nan)	loss_scale 4096.0000 (11375.5045)	mem 7984MB
[2024-07-12 22:29:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:23 lr 0.000004	 wd 0.0000	time 0.2162 (0.2733)	loss 1.5154 (1.3583)	grad_norm 0.4585 (nan)	loss_scale 4096.0000 (10714.3324)	mem 7984MB
[2024-07-12 22:30:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:52 lr 0.000004	 wd 0.0000	time 0.2600 (0.2707)	loss 1.4663 (1.3604)	grad_norm 0.4522 (nan)	loss_scale 4096.0000 (10163.2639)	mem 7984MB
[2024-07-12 22:30:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:24 lr 0.000004	 wd 0.0000	time 0.2149 (0.2699)	loss 1.4373 (1.3624)	grad_norm 0.4880 (nan)	loss_scale 4096.0000 (9696.9101)	mem 7984MB
[2024-07-12 22:30:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:54 lr 0.000005	 wd 0.0000	time 0.2203 (0.2675)	loss 1.5499 (1.3635)	grad_norm 0.4605 (nan)	loss_scale 4096.0000 (9297.1306)	mem 7984MB
[2024-07-12 22:31:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:25 lr 0.000005	 wd 0.0000	time 0.2125 (0.2652)	loss 1.4679 (1.3633)	grad_norm 0.4859 (nan)	loss_scale 4096.0000 (8950.6196)	mem 7984MB
[2024-07-12 22:31:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:57 lr 0.000005	 wd 0.0000	time 0.2877 (0.2637)	loss 1.5872 (1.3639)	grad_norm 0.6102 (nan)	loss_scale 4096.0000 (8647.3954)	mem 7984MB
[2024-07-12 22:32:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:31 lr 0.000005	 wd 0.0000	time 0.2392 (0.2643)	loss 1.4808 (1.3629)	grad_norm 0.4829 (nan)	loss_scale 4096.0000 (8379.8236)	mem 7984MB
[2024-07-12 22:32:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:03:04 lr 0.000006	 wd 0.0000	time 0.2130 (0.2628)	loss 1.2197 (1.3635)	grad_norm 0.5232 (nan)	loss_scale 4096.0000 (8141.9656)	mem 7984MB
[2024-07-12 22:33:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:37 lr 0.000006	 wd 0.0000	time 0.2271 (0.2613)	loss 1.6255 (1.3629)	grad_norm 0.4777 (nan)	loss_scale 4096.0000 (7929.1320)	mem 7984MB
[2024-07-12 22:33:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:10 lr 0.000006	 wd 0.0000	time 0.2356 (0.2604)	loss 1.4932 (1.3610)	grad_norm 0.4482 (nan)	loss_scale 4096.0000 (7737.5712)	mem 7984MB
[2024-07-12 22:33:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:44 lr 0.000007	 wd 0.0000	time 0.2384 (0.2602)	loss 1.3531 (1.3615)	grad_norm 0.4704 (nan)	loss_scale 4096.0000 (7564.2456)	mem 7984MB
[2024-07-12 22:34:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:18 lr 0.000007	 wd 0.0000	time 0.2240 (0.2590)	loss 1.6126 (1.3623)	grad_norm 0.4423 (nan)	loss_scale 4096.0000 (7406.6697)	mem 7984MB
[2024-07-12 22:34:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:52 lr 0.000007	 wd 0.0000	time 0.2443 (0.2580)	loss 1.5267 (1.3611)	grad_norm 0.5550 (nan)	loss_scale 4096.0000 (7262.7901)	mem 7984MB
[2024-07-12 22:35:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:26 lr 0.000008	 wd 0.0000	time 0.2597 (0.2575)	loss 1.3904 (1.3613)	grad_norm 0.4826 (nan)	loss_scale 4096.0000 (7130.8955)	mem 7984MB
[2024-07-12 22:35:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1793 (0.2558)	loss 1.6354 (1.3614)	grad_norm 0.4379 (nan)	loss_scale 4096.0000 (7009.5482)	mem 7984MB
[2024-07-12 22:35:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 0 training takes 0:10:49
[2024-07-12 22:35:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/ckpt_epoch_0.pth saving......
[2024-07-12 22:35:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/ckpt_epoch_0.pth saved !!!
[2024-07-12 22:36:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 39.046 (39.046)	Loss 0.4143 (0.4143)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-12 22:36:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.150 Acc@5 97.266
[2024-07-12 22:36:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-12 22:36:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-12 22:36:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/ckpt_epoch_best.pth saving......
[2024-07-12 22:36:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/ckpt_epoch_best.pth saved !!!
[2024-07-12 22:37:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][0/2502]	eta 1 day, 1:51:21 lr 0.000008	 wd 0.0000	time 37.2029 (37.2029)	loss 1.2167 (1.2167)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:37:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:23:57 lr 0.000008	 wd 0.0000	time 0.2006 (0.5985)	loss 1.1566 (1.3991)	grad_norm 0.4626 (0.5138)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:37:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:15:51 lr 0.000009	 wd 0.0000	time 0.2261 (0.4132)	loss 1.3503 (1.3992)	grad_norm 0.4825 (0.5108)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:38:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:13:03 lr 0.000009	 wd 0.0000	time 0.2829 (0.3558)	loss 1.6914 (1.3784)	grad_norm 0.4727 (0.5183)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:38:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:11:31 lr 0.000009	 wd 0.0000	time 0.2653 (0.3289)	loss 0.9777 (1.3680)	grad_norm 0.4715 (0.5161)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:39:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:10:18 lr 0.000010	 wd 0.0000	time 0.2310 (0.3091)	loss 1.5189 (1.3666)	grad_norm 0.5221 (0.5107)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:39:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:09:22 lr 0.000010	 wd 0.0000	time 0.2166 (0.2955)	loss 1.4291 (1.3662)	grad_norm 0.5140 (0.5096)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:39:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:37 lr 0.000010	 wd 0.0000	time 0.2462 (0.2874)	loss 1.6170 (1.3648)	grad_norm 0.4504 (0.5081)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:40:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:08:03 lr 0.000011	 wd 0.0000	time 0.2545 (0.2842)	loss 1.5434 (1.3682)	grad_norm 0.4377 (0.5074)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:40:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:26 lr 0.000011	 wd 0.0000	time 0.2200 (0.2786)	loss 1.5917 (1.3655)	grad_norm 0.5022 (0.5076)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:41:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:51 lr 0.000011	 wd 0.0000	time 0.2058 (0.2740)	loss 1.6764 (1.3644)	grad_norm 0.7826 (0.5126)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:41:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:06:19 lr 0.000012	 wd 0.0000	time 0.2331 (0.2709)	loss 1.0861 (1.3635)	grad_norm 0.4978 (0.5138)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:41:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:52 lr 0.000012	 wd 0.0000	time 0.2441 (0.2705)	loss 1.3427 (1.3661)	grad_norm 0.4617 (0.5132)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:42:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:21 lr 0.000012	 wd 0.0000	time 0.2006 (0.2677)	loss 1.5447 (1.3694)	grad_norm 0.4592 (0.5144)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:42:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:52 lr 0.000012	 wd 0.0000	time 0.2176 (0.2653)	loss 1.4280 (1.3675)	grad_norm 0.4702 (0.5146)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:43:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:23 lr 0.000013	 wd 0.0000	time 0.2368 (0.2634)	loss 0.9805 (1.3659)	grad_norm 0.5205 (0.5139)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:43:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:57 lr 0.000013	 wd 0.0000	time 0.2791 (0.2638)	loss 0.9249 (1.3644)	grad_norm 0.4823 (0.5139)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:43:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:30 lr 0.000013	 wd 0.0000	time 0.2311 (0.2622)	loss 1.3418 (1.3638)	grad_norm 0.4830 (0.5134)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:44:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:03:03 lr 0.000014	 wd 0.0000	time 0.2308 (0.2607)	loss 1.4287 (1.3638)	grad_norm 0.4824 (0.5123)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:44:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:36 lr 0.000014	 wd 0.0000	time 0.2192 (0.2596)	loss 1.4428 (1.3650)	grad_norm 0.5025 (0.5108)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:45:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:10 lr 0.000014	 wd 0.0000	time 0.2597 (0.2601)	loss 1.3220 (1.3642)	grad_norm 0.4541 (0.5108)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:45:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:44 lr 0.000015	 wd 0.0000	time 0.2492 (0.2590)	loss 1.4004 (1.3652)	grad_norm 0.4648 (0.5125)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:45:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:17 lr 0.000015	 wd 0.0000	time 0.1917 (0.2579)	loss 1.2048 (1.3664)	grad_norm 0.7860 (0.5126)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:46:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:51 lr 0.000015	 wd 0.0000	time 0.2194 (0.2571)	loss 1.6225 (1.3668)	grad_norm 0.5065 (0.5120)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 22:46:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:26 lr 0.000016	 wd 0.0000	time 0.2231 (0.2571)	loss 1.4501 (1.3649)	grad_norm 0.4583 (0.5118)	loss_scale 8192.0000 (4140.3549)	mem 7984MB
[2024-07-12 22:47:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1714 (0.2551)	loss 1.1121 (1.3662)	grad_norm 0.4417 (0.5111)	loss_scale 8192.0000 (4302.3559)	mem 7984MB
[2024-07-12 22:47:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 1 training takes 0:10:43
[2024-07-12 22:47:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 25.026 (25.026)	Loss 0.4158 (0.4158)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-12 22:47:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.148 Acc@5 97.254
[2024-07-12 22:47:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-12 22:47:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-12 22:48:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][0/2502]	eta 1 day, 0:39:54 lr 0.000016	 wd 0.0000	time 35.4895 (35.4895)	loss 1.6410 (1.6410)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:48:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:23:11 lr 0.000016	 wd 0.0000	time 0.1904 (0.5794)	loss 1.4067 (1.3379)	grad_norm 0.5473 (0.5065)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:49:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:15:28 lr 0.000017	 wd 0.0000	time 0.2104 (0.4035)	loss 1.4348 (1.3577)	grad_norm 0.4303 (0.5044)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:49:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:12:47 lr 0.000017	 wd 0.0000	time 0.2497 (0.3484)	loss 1.2978 (1.3687)	grad_norm 0.5108 (0.5094)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:49:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:11:21 lr 0.000017	 wd 0.0000	time 0.2176 (0.3240)	loss 1.5246 (1.3666)	grad_norm 0.4657 (0.5108)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:50:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:10:09 lr 0.000018	 wd 0.0000	time 0.2197 (0.3046)	loss 1.5269 (1.3649)	grad_norm 0.4919 (0.5098)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:50:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:09:15 lr 0.000018	 wd 0.0000	time 0.2185 (0.2922)	loss 1.2681 (1.3595)	grad_norm 0.5026 (0.5126)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:51:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:08:32 lr 0.000018	 wd 0.0000	time 0.2428 (0.2841)	loss 1.2487 (1.3617)	grad_norm 1.4894 (0.5144)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:51:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:57 lr 0.000019	 wd 0.0000	time 0.2576 (0.2807)	loss 1.4397 (1.3600)	grad_norm 0.4702 (0.5111)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:51:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:07:21 lr 0.000019	 wd 0.0000	time 0.2386 (0.2757)	loss 1.5180 (1.3644)	grad_norm 0.4842 (0.5096)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:52:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:47 lr 0.000019	 wd 0.0000	time 0.2559 (0.2713)	loss 1.4491 (1.3655)	grad_norm 0.4982 (0.5095)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:52:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:06:15 lr 0.000020	 wd 0.0000	time 0.2036 (0.2679)	loss 1.1717 (1.3650)	grad_norm 0.4644 (0.5104)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:53:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:49 lr 0.000020	 wd 0.0000	time 0.2173 (0.2681)	loss 1.2565 (1.3641)	grad_norm 0.5292 (0.5115)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:53:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:05:19 lr 0.000020	 wd 0.0000	time 0.2044 (0.2657)	loss 1.6975 (1.3668)	grad_norm 0.5166 (0.5115)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:53:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:50 lr 0.000020	 wd 0.0000	time 0.2287 (0.2633)	loss 1.4330 (1.3668)	grad_norm 0.4706 (0.5110)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:54:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:21 lr 0.000021	 wd 0.0000	time 0.2397 (0.2613)	loss 1.4918 (1.3649)	grad_norm 0.4643 (0.5092)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:54:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:55 lr 0.000021	 wd 0.0000	time 0.2079 (0.2615)	loss 1.2766 (1.3651)	grad_norm 0.4837 (0.5129)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:55:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:28 lr 0.000021	 wd 0.0000	time 0.2217 (0.2604)	loss 1.4479 (1.3648)	grad_norm 0.4975 (0.5115)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:55:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:03:01 lr 0.000022	 wd 0.0000	time 0.2197 (0.2591)	loss 1.3520 (1.3649)	grad_norm 0.4607 (0.5123)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:55:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:35 lr 0.000022	 wd 0.0000	time 0.2410 (0.2580)	loss 1.0781 (1.3633)	grad_norm 0.4823 (0.5125)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:56:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:02:09 lr 0.000022	 wd 0.0000	time 0.1781 (0.2583)	loss 1.1038 (1.3615)	grad_norm 0.5025 (0.5133)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:56:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:43 lr 0.000023	 wd 0.0000	time 0.2091 (0.2574)	loss 1.4461 (1.3617)	grad_norm 0.4919 (0.5134)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:57:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:17 lr 0.000023	 wd 0.0000	time 0.2019 (0.2564)	loss 1.5041 (1.3617)	grad_norm 0.5019 (0.5140)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:57:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:51 lr 0.000023	 wd 0.0000	time 0.2305 (0.2554)	loss 1.5758 (1.3617)	grad_norm 0.4814 (0.5149)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:58:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:26 lr 0.000024	 wd 0.0000	time 0.3007 (0.2554)	loss 1.4127 (1.3606)	grad_norm 0.4537 (0.5147)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:58:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1752 (0.2538)	loss 1.4419 (1.3605)	grad_norm 0.4728 (0.5143)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 22:58:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 2 training takes 0:10:40
[2024-07-12 22:58:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 24.191 (24.191)	Loss 0.4119 (0.4119)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-12 22:59:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.084 Acc@5 97.254
[2024-07-12 22:59:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-12 22:59:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-12 22:59:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][0/2502]	eta 23:08:45 lr 0.000024	 wd 0.0000	time 33.3038 (33.3038)	loss 1.0907 (1.0907)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 23:00:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:22:27 lr 0.000024	 wd 0.0000	time 0.2335 (0.5609)	loss 1.6734 (1.3466)	grad_norm 0.5125 (0.5182)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 23:00:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:15:08 lr 0.000025	 wd 0.0000	time 0.2501 (0.3946)	loss 1.4906 (1.3584)	grad_norm 0.4616 (0.5200)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 23:00:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:12:28 lr 0.000025	 wd 0.0000	time 0.2335 (0.3401)	loss 1.4111 (1.3474)	grad_norm 0.4727 (0.5208)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 23:01:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:11:12 lr 0.000025	 wd 0.0000	time 0.2599 (0.3200)	loss 1.5184 (1.3537)	grad_norm 0.4908 (0.5152)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 23:01:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:10:04 lr 0.000026	 wd 0.0000	time 0.2336 (0.3018)	loss 1.3851 (1.3512)	grad_norm 0.5158 (0.5161)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 23:01:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:09:12 lr 0.000026	 wd 0.0000	time 0.2149 (0.2902)	loss 1.4579 (1.3507)	grad_norm 0.5603 (0.5142)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 23:02:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:08:28 lr 0.000026	 wd 0.0000	time 0.2516 (0.2819)	loss 1.4842 (1.3527)	grad_norm 0.5602 (0.5149)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 23:02:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:57 lr 0.000027	 wd 0.0000	time 0.1775 (0.2808)	loss 1.1306 (1.3533)	grad_norm 0.4486 (0.5171)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 23:03:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:07:21 lr 0.000027	 wd 0.0000	time 0.2888 (0.2756)	loss 1.3410 (1.3548)	grad_norm 0.4612 (0.5186)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 23:03:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:46 lr 0.000027	 wd 0.0000	time 0.2431 (0.2709)	loss 1.5989 (1.3580)	grad_norm 0.4683 (0.5152)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 23:03:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:06:14 lr 0.000028	 wd 0.0000	time 0.2202 (0.2673)	loss 1.3869 (1.3603)	grad_norm 0.4648 (0.5133)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 23:04:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:46 lr 0.000028	 wd 0.0000	time 0.2054 (0.2664)	loss 1.2976 (1.3592)	grad_norm 0.4111 (0.5131)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 23:04:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:05:18 lr 0.000028	 wd 0.0000	time 0.2264 (0.2654)	loss 1.2187 (1.3620)	grad_norm 0.4636 (0.5147)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-12 23:05:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:49 lr 0.000028	 wd 0.0000	time 0.2168 (0.2629)	loss 1.2220 (1.3627)	grad_norm 0.4954 (0.5159)	loss_scale 16384.0000 (8367.4176)	mem 7984MB
[2024-07-12 23:05:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:21 lr 0.000029	 wd 0.0000	time 0.2466 (0.2607)	loss 1.3804 (1.3630)	grad_norm 0.5844 (0.5149)	loss_scale 16384.0000 (8901.5003)	mem 7984MB
[2024-07-12 23:06:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:55 lr 0.000029	 wd 0.0000	time 1.4324 (0.2610)	loss 1.4128 (1.3618)	grad_norm 0.4537 (0.5153)	loss_scale 16384.0000 (9368.8645)	mem 7984MB
[2024-07-12 23:06:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:28 lr 0.000029	 wd 0.0000	time 0.2145 (0.2599)	loss 1.0612 (1.3609)	grad_norm 0.4824 (nan)	loss_scale 8192.0000 (9473.0535)	mem 7984MB
[2024-07-12 23:06:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:03:01 lr 0.000030	 wd 0.0000	time 0.2231 (0.2586)	loss 1.6184 (1.3625)	grad_norm 0.5012 (nan)	loss_scale 8192.0000 (9401.9234)	mem 7984MB
[2024-07-12 23:07:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:34 lr 0.000030	 wd 0.0000	time 0.1938 (0.2573)	loss 1.5314 (1.3623)	grad_norm 0.4754 (nan)	loss_scale 8192.0000 (9338.2767)	mem 7984MB
[2024-07-12 23:07:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:09 lr 0.000030	 wd 0.0000	time 0.2143 (0.2571)	loss 1.1638 (1.3630)	grad_norm 0.4879 (nan)	loss_scale 8192.0000 (9280.9915)	mem 7984MB
[2024-07-12 23:08:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:43 lr 0.000031	 wd 0.0000	time 0.2169 (0.2567)	loss 1.2147 (1.3614)	grad_norm 0.4589 (nan)	loss_scale 4096.0000 (9197.9667)	mem 7984MB
[2024-07-12 23:08:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:17 lr 0.000031	 wd 0.0000	time 0.2466 (0.2558)	loss 1.3511 (1.3625)	grad_norm 0.6035 (nan)	loss_scale 4096.0000 (8966.1645)	mem 7984MB
[2024-07-12 23:08:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:51 lr 0.000031	 wd 0.0000	time 0.2214 (0.2548)	loss 1.5274 (1.3632)	grad_norm 0.4821 (nan)	loss_scale 4096.0000 (8754.5102)	mem 7984MB
[2024-07-12 23:09:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:25 lr 0.000032	 wd 0.0000	time 0.2025 (0.2547)	loss 0.9788 (1.3625)	grad_norm 0.4767 (nan)	loss_scale 4096.0000 (8560.4865)	mem 7984MB
[2024-07-12 23:09:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000032	 wd 0.0000	time 0.1786 (0.2530)	loss 1.5502 (1.3630)	grad_norm 0.4904 (nan)	loss_scale 4096.0000 (8381.9784)	mem 7984MB
[2024-07-12 23:09:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 3 training takes 0:10:38
[2024-07-12 23:10:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 23.300 (23.300)	Loss 0.4155 (0.4155)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-12 23:10:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.090 Acc@5 97.268
[2024-07-12 23:10:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-12 23:10:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-12 23:10:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][0/2502]	eta 17:39:07 lr 0.000032	 wd 0.0000	time 25.3987 (25.3987)	loss 1.4261 (1.4261)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:11:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:20:04 lr 0.000032	 wd 0.0000	time 0.2257 (0.5014)	loss 1.1451 (1.3725)	grad_norm 0.5422 (0.5005)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:11:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:14:00 lr 0.000033	 wd 0.0000	time 0.2175 (0.3651)	loss 1.1271 (1.3739)	grad_norm 0.4685 (0.4926)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:11:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:11:42 lr 0.000033	 wd 0.0000	time 0.2054 (0.3191)	loss 1.1098 (1.3738)	grad_norm 0.4787 (0.4991)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:12:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:10:31 lr 0.000033	 wd 0.0000	time 0.2596 (0.3006)	loss 1.5841 (1.3696)	grad_norm 0.4298 (0.4998)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:12:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:09:37 lr 0.000034	 wd 0.0000	time 0.2459 (0.2884)	loss 1.3438 (1.3631)	grad_norm 0.6639 (0.5007)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:13:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:08:50 lr 0.000034	 wd 0.0000	time 0.2125 (0.2789)	loss 1.4860 (1.3590)	grad_norm 0.5241 (0.5104)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:13:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:08:09 lr 0.000034	 wd 0.0000	time 0.2234 (0.2716)	loss 1.2755 (1.3590)	grad_norm 0.4549 (nan)	loss_scale 2048.0000 (4084.3138)	mem 7984MB
[2024-07-12 23:13:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:35 lr 0.000035	 wd 0.0000	time 0.2547 (0.2675)	loss 1.4648 (1.3584)	grad_norm 0.4625 (nan)	loss_scale 2048.0000 (3830.0924)	mem 7984MB
[2024-07-12 23:14:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:07:06 lr 0.000035	 wd 0.0000	time 0.2665 (0.2664)	loss 1.4865 (1.3596)	grad_norm 0.4444 (nan)	loss_scale 2048.0000 (3632.3019)	mem 7984MB
[2024-07-12 23:14:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:35 lr 0.000035	 wd 0.0000	time 0.2343 (0.2631)	loss 1.5246 (1.3603)	grad_norm 0.4231 (nan)	loss_scale 2048.0000 (3474.0300)	mem 7984MB
[2024-07-12 23:15:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:06:04 lr 0.000036	 wd 0.0000	time 0.2045 (0.2602)	loss 1.5265 (1.3612)	grad_norm 0.5792 (nan)	loss_scale 2048.0000 (3344.5086)	mem 7984MB
[2024-07-12 23:15:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:36 lr 0.000036	 wd 0.0000	time 0.2296 (0.2583)	loss 1.0904 (1.3598)	grad_norm 0.5031 (nan)	loss_scale 2048.0000 (3236.5562)	mem 7984MB
[2024-07-12 23:15:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:05:09 lr 0.000036	 wd 0.0000	time 0.2105 (0.2579)	loss 1.5703 (1.3591)	grad_norm 0.4874 (nan)	loss_scale 2048.0000 (3145.1991)	mem 7984MB
[2024-07-12 23:16:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:42 lr 0.000036	 wd 0.0000	time 0.2189 (0.2563)	loss 1.5065 (1.3592)	grad_norm 0.4766 (nan)	loss_scale 2048.0000 (3066.8837)	mem 7984MB
[2024-07-12 23:16:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:15 lr 0.000037	 wd 0.0000	time 0.2341 (0.2547)	loss 1.2542 (1.3616)	grad_norm 0.4648 (nan)	loss_scale 2048.0000 (2999.0033)	mem 7984MB
[2024-07-12 23:17:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:48 lr 0.000037	 wd 0.0000	time 0.2379 (0.2536)	loss 1.0594 (1.3612)	grad_norm 0.6624 (nan)	loss_scale 2048.0000 (2939.6027)	mem 7984MB
[2024-07-12 23:17:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:24 lr 0.000037	 wd 0.0000	time 0.3678 (0.2545)	loss 1.5477 (1.3606)	grad_norm 0.5170 (nan)	loss_scale 2048.0000 (2887.1864)	mem 7984MB
[2024-07-12 23:17:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:58 lr 0.000038	 wd 0.0000	time 0.2399 (0.2538)	loss 1.3735 (1.3605)	grad_norm 0.4687 (nan)	loss_scale 2048.0000 (2840.5908)	mem 7984MB
[2024-07-12 23:18:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:32 lr 0.000038	 wd 0.0000	time 0.2289 (0.2528)	loss 1.6455 (1.3604)	grad_norm 0.4859 (nan)	loss_scale 2048.0000 (2798.8974)	mem 7984MB
[2024-07-12 23:18:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:02:06 lr 0.000038	 wd 0.0000	time 0.2370 (0.2520)	loss 1.4619 (1.3598)	grad_norm 0.4937 (nan)	loss_scale 2048.0000 (2761.3713)	mem 7984MB
[2024-07-12 23:19:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:41 lr 0.000039	 wd 0.0000	time 0.2113 (0.2522)	loss 1.4334 (1.3602)	grad_norm 0.4975 (nan)	loss_scale 2048.0000 (2727.4174)	mem 7984MB
[2024-07-12 23:19:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:15 lr 0.000039	 wd 0.0000	time 0.2121 (0.2513)	loss 0.9874 (1.3579)	grad_norm 0.4229 (nan)	loss_scale 2048.0000 (2696.5488)	mem 7984MB
[2024-07-12 23:19:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:50 lr 0.000039	 wd 0.0000	time 0.2096 (0.2506)	loss 1.2940 (1.3581)	grad_norm 0.4950 (nan)	loss_scale 2048.0000 (2668.3633)	mem 7984MB
[2024-07-12 23:20:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:25 lr 0.000040	 wd 0.0000	time 0.2704 (0.2501)	loss 1.5774 (1.3580)	grad_norm 0.4211 (nan)	loss_scale 2048.0000 (2642.5256)	mem 7984MB
[2024-07-12 23:20:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1901 (0.2485)	loss 0.9291 (1.3578)	grad_norm 0.4516 (nan)	loss_scale 2048.0000 (2618.7541)	mem 7984MB
[2024-07-12 23:20:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 4 training takes 0:10:31
[2024-07-12 23:21:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 23.107 (23.107)	Loss 0.4141 (0.4141)	Acc@1 92.969 (92.969)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-12 23:21:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.128 Acc@5 97.268
[2024-07-12 23:21:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-12 23:21:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-12 23:21:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][0/2502]	eta 11:33:02 lr 0.000040	 wd 0.0000	time 16.6198 (16.6198)	loss 1.6010 (1.6010)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:22:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:16:28 lr 0.000040	 wd 0.0000	time 0.2486 (0.4115)	loss 1.2896 (1.3782)	grad_norm 0.6268 (0.5304)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:22:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:12:29 lr 0.000040	 wd 0.0000	time 0.2298 (0.3255)	loss 1.4654 (1.3815)	grad_norm 0.5485 (0.5149)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:22:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:43 lr 0.000040	 wd 0.0000	time 0.2310 (0.2922)	loss 1.6110 (1.3710)	grad_norm 0.4911 (0.5236)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:23:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:40 lr 0.000040	 wd 0.0000	time 0.2194 (0.2761)	loss 0.9982 (1.3723)	grad_norm 0.6110 (0.5176)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:23:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:08:59 lr 0.000040	 wd 0.0000	time 0.2199 (0.2695)	loss 1.5138 (1.3678)	grad_norm 0.4436 (0.5146)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:24:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:25 lr 0.000040	 wd 0.0000	time 0.2305 (0.2657)	loss 1.4276 (1.3685)	grad_norm 0.5065 (0.5129)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:24:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:49 lr 0.000040	 wd 0.0000	time 0.2025 (0.2605)	loss 1.4521 (1.3662)	grad_norm 0.5007 (0.5113)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:24:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:16 lr 0.000040	 wd 0.0000	time 0.2080 (0.2566)	loss 0.9296 (1.3601)	grad_norm 0.4741 (0.5171)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:25:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:48 lr 0.000040	 wd 0.0000	time 0.2299 (0.2551)	loss 0.9028 (1.3594)	grad_norm 0.5888 (0.5150)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:25:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:22 lr 0.000040	 wd 0.0000	time 0.2248 (0.2549)	loss 1.5165 (1.3625)	grad_norm 0.4410 (0.5181)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:26:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:54 lr 0.000040	 wd 0.0000	time 0.2429 (0.2527)	loss 1.5397 (1.3586)	grad_norm 0.4693 (0.5160)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:26:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:26 lr 0.000040	 wd 0.0000	time 0.2173 (0.2510)	loss 1.5399 (1.3566)	grad_norm 0.4719 (0.5146)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:26:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:05:00 lr 0.000040	 wd 0.0000	time 0.2319 (0.2502)	loss 1.4906 (1.3572)	grad_norm 0.4685 (0.5155)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:27:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:36 lr 0.000040	 wd 0.0000	time 0.2271 (0.2508)	loss 1.5276 (1.3567)	grad_norm 0.4783 (0.5132)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:27:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:04:10 lr 0.000040	 wd 0.0000	time 0.2352 (0.2498)	loss 1.3804 (1.3567)	grad_norm 0.5090 (0.5127)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:28:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:44 lr 0.000040	 wd 0.0000	time 0.2312 (0.2488)	loss 1.4431 (1.3587)	grad_norm 0.5377 (0.5140)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:28:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:19 lr 0.000040	 wd 0.0000	time 0.2284 (0.2482)	loss 1.3443 (1.3584)	grad_norm 0.4504 (0.5137)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:28:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:54 lr 0.000040	 wd 0.0000	time 0.2728 (0.2491)	loss 0.9890 (1.3577)	grad_norm 0.8604 (0.5141)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:29:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:29 lr 0.000040	 wd 0.0000	time 0.2298 (0.2483)	loss 1.4679 (1.3598)	grad_norm 0.7625 (0.5130)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:29:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:02:04 lr 0.000040	 wd 0.0000	time 0.2440 (0.2476)	loss 1.5093 (1.3607)	grad_norm 0.4616 (0.5119)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:30:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:39 lr 0.000040	 wd 0.0000	time 0.2486 (0.2473)	loss 1.4983 (1.3612)	grad_norm 0.5390 (0.5120)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:30:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:14 lr 0.000040	 wd 0.0000	time 0.2244 (0.2474)	loss 1.2334 (1.3592)	grad_norm 0.4884 (0.5118)	loss_scale 4096.0000 (2053.5829)	mem 7984MB
[2024-07-12 23:30:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:49 lr 0.000040	 wd 0.0000	time 0.2248 (0.2468)	loss 0.8951 (1.3584)	grad_norm 0.4293 (0.5122)	loss_scale 4096.0000 (2142.3451)	mem 7984MB
[2024-07-12 23:31:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:25 lr 0.000040	 wd 0.0000	time 0.2026 (0.2463)	loss 1.4999 (1.3585)	grad_norm 0.4999 (0.5119)	loss_scale 4096.0000 (2223.7135)	mem 7984MB
[2024-07-12 23:31:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1725 (0.2446)	loss 1.5108 (1.3584)	grad_norm 0.4778 (0.5125)	loss_scale 4096.0000 (2298.5750)	mem 7984MB
[2024-07-12 23:31:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 5 training takes 0:10:16
[2024-07-12 23:32:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 34.923 (34.923)	Loss 0.4077 (0.4077)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-12 23:32:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.104 Acc@5 97.272
[2024-07-12 23:32:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-12 23:32:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-12 23:32:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][0/2502]	eta 11:33:26 lr 0.000040	 wd 0.0000	time 16.6291 (16.6291)	loss 1.5634 (1.5634)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:33:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:15:37 lr 0.000040	 wd 0.0000	time 0.2470 (0.3905)	loss 1.2119 (1.3299)	grad_norm 0.4614 (0.5137)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:33:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:14:00 lr 0.000040	 wd 0.0000	time 0.2259 (0.3652)	loss 1.5834 (1.3509)	grad_norm 0.4603 (0.5320)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:34:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:11:44 lr 0.000040	 wd 0.0000	time 0.2166 (0.3197)	loss 1.4634 (1.3613)	grad_norm 0.6482 (0.5349)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:34:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:10:25 lr 0.000040	 wd 0.0000	time 0.2440 (0.2977)	loss 1.3731 (1.3549)	grad_norm 0.4960 (0.5267)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:34:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:09:29 lr 0.000040	 wd 0.0000	time 0.2422 (0.2844)	loss 1.3523 (1.3492)	grad_norm 0.4448 (0.5248)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:35:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:08:51 lr 0.000040	 wd 0.0000	time 0.2071 (0.2797)	loss 1.5903 (1.3534)	grad_norm 0.4418 (0.5234)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:35:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:08:12 lr 0.000040	 wd 0.0000	time 0.2180 (0.2732)	loss 1.4146 (1.3557)	grad_norm 0.5259 (0.5215)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:36:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:35 lr 0.000040	 wd 0.0000	time 0.2135 (0.2678)	loss 0.9974 (1.3547)	grad_norm 0.5395 (0.5199)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:36:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:07:03 lr 0.000040	 wd 0.0000	time 0.1987 (0.2643)	loss 1.6404 (1.3587)	grad_norm 0.4232 (0.5188)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:36:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:36 lr 0.000040	 wd 0.0000	time 0.2001 (0.2642)	loss 1.2988 (1.3541)	grad_norm 0.4720 (0.5177)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:37:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:06:06 lr 0.000040	 wd 0.0000	time 0.2191 (0.2616)	loss 1.1963 (1.3533)	grad_norm 0.4732 (0.5183)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:37:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:37 lr 0.000040	 wd 0.0000	time 0.2119 (0.2589)	loss 1.0510 (1.3549)	grad_norm 0.4672 (0.5171)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:38:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:05:09 lr 0.000040	 wd 0.0000	time 0.2390 (0.2571)	loss 1.3992 (1.3541)	grad_norm 0.4907 (0.5169)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:38:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:43 lr 0.000040	 wd 0.0000	time 0.2315 (0.2577)	loss 1.6524 (1.3528)	grad_norm 0.4791 (0.5165)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:38:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:16 lr 0.000040	 wd 0.0000	time 0.2324 (0.2563)	loss 1.4578 (1.3544)	grad_norm 0.4771 (0.5153)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:39:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:49 lr 0.000040	 wd 0.0000	time 0.2215 (0.2549)	loss 1.5343 (1.3531)	grad_norm 0.4776 (0.5144)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:39:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:23 lr 0.000040	 wd 0.0000	time 0.2410 (0.2537)	loss 1.5036 (1.3525)	grad_norm 0.4585 (0.5133)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:40:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:58 lr 0.000040	 wd 0.0000	time 0.3836 (0.2546)	loss 1.1589 (1.3522)	grad_norm 0.4597 (0.5126)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:40:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:32 lr 0.000040	 wd 0.0000	time 0.2435 (0.2539)	loss 1.2772 (1.3517)	grad_norm 0.4983 (0.5119)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:40:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:02:06 lr 0.000039	 wd 0.0000	time 0.2371 (0.2529)	loss 0.9820 (1.3516)	grad_norm 0.4821 (0.5162)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:41:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:41 lr 0.000039	 wd 0.0000	time 0.2393 (0.2520)	loss 1.5589 (1.3512)	grad_norm 0.5292 (0.5167)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:41:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:16 lr 0.000039	 wd 0.0000	time 0.3782 (0.2522)	loss 1.2516 (1.3517)	grad_norm 0.5296 (0.5157)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:42:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:50 lr 0.000039	 wd 0.0000	time 0.2242 (0.2517)	loss 1.4447 (1.3525)	grad_norm 0.4711 (0.5146)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:42:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:25 lr 0.000039	 wd 0.0000	time 0.2440 (0.2510)	loss 1.1850 (1.3517)	grad_norm 0.5770 (0.5154)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:42:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1942 (0.2492)	loss 1.0296 (1.3523)	grad_norm 0.4598 (0.5145)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:42:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 6 training takes 0:10:27
[2024-07-12 23:43:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 38.666 (38.666)	Loss 0.4136 (0.4136)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-12 23:43:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.084 Acc@5 97.282
[2024-07-12 23:43:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-12 23:43:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-12 23:44:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][0/2502]	eta 11:16:30 lr 0.000039	 wd 0.0000	time 16.2233 (16.2233)	loss 1.5891 (1.5891)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:44:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:15:43 lr 0.000039	 wd 0.0000	time 0.2274 (0.3930)	loss 1.2273 (1.3778)	grad_norm 0.5105 (0.4888)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:44:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:12:49 lr 0.000039	 wd 0.0000	time 0.2221 (0.3341)	loss 1.4406 (1.3520)	grad_norm 0.6669 (0.5164)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:45:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:10:59 lr 0.000039	 wd 0.0000	time 0.2115 (0.2996)	loss 1.3115 (1.3497)	grad_norm 0.4628 (0.5196)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:45:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:09:51 lr 0.000039	 wd 0.0000	time 0.1982 (0.2814)	loss 1.3343 (1.3517)	grad_norm 0.7226 (0.5165)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:46:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:08:59 lr 0.000039	 wd 0.0000	time 0.2316 (0.2696)	loss 1.4290 (1.3470)	grad_norm 0.5298 (0.5138)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:46:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:27 lr 0.000039	 wd 0.0000	time 0.2702 (0.2669)	loss 1.3239 (1.3508)	grad_norm 0.4719 (0.5149)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:46:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:07:55 lr 0.000039	 wd 0.0000	time 0.2077 (0.2637)	loss 1.4790 (1.3546)	grad_norm 0.4702 (0.5147)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-12 23:47:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:07:21 lr 0.000039	 wd 0.0000	time 0.2215 (0.2594)	loss 0.8966 (1.3568)	grad_norm 0.5019 (inf)	loss_scale 2048.0000 (3845.4332)	mem 7984MB
[2024-07-12 23:47:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:06:50 lr 0.000039	 wd 0.0000	time 0.2366 (0.2561)	loss 1.0873 (1.3587)	grad_norm 0.5020 (inf)	loss_scale 2048.0000 (3645.9401)	mem 7984MB
[2024-07-12 23:48:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:24 lr 0.000039	 wd 0.0000	time 0.2481 (0.2558)	loss 1.1672 (1.3547)	grad_norm 0.6334 (inf)	loss_scale 2048.0000 (3486.3057)	mem 7984MB
[2024-07-12 23:48:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:57 lr 0.000039	 wd 0.0000	time 0.2188 (0.2547)	loss 1.2349 (1.3532)	grad_norm 0.5060 (inf)	loss_scale 2048.0000 (3355.6694)	mem 7984MB
[2024-07-12 23:48:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:29 lr 0.000039	 wd 0.0000	time 0.2070 (0.2528)	loss 1.4140 (1.3520)	grad_norm 0.5200 (inf)	loss_scale 2048.0000 (3246.7877)	mem 7984MB
[2024-07-12 23:49:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:05:01 lr 0.000039	 wd 0.0000	time 0.1978 (0.2511)	loss 1.4748 (1.3521)	grad_norm 0.4420 (inf)	loss_scale 2048.0000 (3154.6441)	mem 7984MB
[2024-07-12 23:49:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:36 lr 0.000039	 wd 0.0000	time 0.2341 (0.2508)	loss 1.4099 (1.3530)	grad_norm 0.4603 (inf)	loss_scale 2048.0000 (3075.6545)	mem 7984MB
[2024-07-12 23:50:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:11 lr 0.000039	 wd 0.0000	time 0.2522 (0.2511)	loss 1.6356 (1.3523)	grad_norm 0.5794 (inf)	loss_scale 2048.0000 (3007.1899)	mem 7984MB
[2024-07-12 23:50:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:45 lr 0.000039	 wd 0.0000	time 0.2243 (0.2501)	loss 1.5150 (1.3542)	grad_norm 0.5132 (inf)	loss_scale 2048.0000 (2947.2780)	mem 7984MB
[2024-07-12 23:50:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:19 lr 0.000039	 wd 0.0000	time 0.2181 (0.2489)	loss 1.5660 (1.3544)	grad_norm 0.4839 (inf)	loss_scale 2048.0000 (2894.4103)	mem 7984MB
[2024-07-12 23:51:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:54 lr 0.000039	 wd 0.0000	time 0.2442 (0.2488)	loss 1.1235 (1.3539)	grad_norm 0.5122 (inf)	loss_scale 2048.0000 (2847.4137)	mem 7984MB
[2024-07-12 23:51:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:30 lr 0.000039	 wd 0.0000	time 0.2487 (0.2492)	loss 1.3128 (1.3534)	grad_norm 0.5347 (inf)	loss_scale 2048.0000 (2805.3614)	mem 7984MB
[2024-07-12 23:52:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:02:04 lr 0.000039	 wd 0.0000	time 0.2153 (0.2486)	loss 1.4227 (1.3544)	grad_norm 0.4585 (inf)	loss_scale 2048.0000 (2767.5122)	mem 7984MB
[2024-07-12 23:52:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:39 lr 0.000039	 wd 0.0000	time 0.2095 (0.2477)	loss 1.5066 (1.3555)	grad_norm 0.6810 (inf)	loss_scale 2048.0000 (2733.2661)	mem 7984MB
[2024-07-12 23:52:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:14 lr 0.000039	 wd 0.0000	time 0.2292 (0.2476)	loss 1.1009 (1.3536)	grad_norm 0.6845 (inf)	loss_scale 2048.0000 (2702.1318)	mem 7984MB
[2024-07-12 23:53:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:49 lr 0.000039	 wd 0.0000	time 0.2051 (0.2475)	loss 1.5616 (1.3540)	grad_norm 0.4767 (inf)	loss_scale 2048.0000 (2673.7036)	mem 7984MB
[2024-07-12 23:53:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:25 lr 0.000039	 wd 0.0000	time 0.2344 (0.2470)	loss 1.4586 (1.3535)	grad_norm 0.4602 (inf)	loss_scale 2048.0000 (2647.6435)	mem 7984MB
[2024-07-12 23:54:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1639 (0.2452)	loss 1.2706 (1.3538)	grad_norm 0.5467 (inf)	loss_scale 2048.0000 (2623.6673)	mem 7984MB
[2024-07-12 23:54:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 7 training takes 0:10:17
[2024-07-12 23:54:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 35.233 (35.233)	Loss 0.4221 (0.4221)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 7984MB
[2024-07-12 23:54:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.126 Acc@5 97.288
[2024-07-12 23:54:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-12 23:54:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-12 23:55:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][0/2502]	eta 11:52:44 lr 0.000039	 wd 0.0000	time 17.0920 (17.0920)	loss 1.4182 (1.4182)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:55:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:15:46 lr 0.000039	 wd 0.0000	time 0.1874 (0.3942)	loss 1.4472 (1.3910)	grad_norm 0.4403 (0.5084)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:55:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:12:09 lr 0.000039	 wd 0.0000	time 0.2975 (0.3168)	loss 1.5289 (1.3664)	grad_norm 0.4779 (0.5120)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:56:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:11:28 lr 0.000038	 wd 0.0000	time 0.2618 (0.3126)	loss 1.3582 (1.3634)	grad_norm 0.4771 (0.5148)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:56:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:10:12 lr 0.000038	 wd 0.0000	time 0.2232 (0.2913)	loss 1.6243 (1.3599)	grad_norm 0.6113 (0.5132)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:57:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:09:18 lr 0.000038	 wd 0.0000	time 0.2435 (0.2789)	loss 1.4349 (1.3631)	grad_norm 0.5067 (0.5136)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:57:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:38 lr 0.000038	 wd 0.0000	time 0.2853 (0.2727)	loss 1.5227 (1.3674)	grad_norm 0.5149 (0.5174)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:58:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:08:05 lr 0.000038	 wd 0.0000	time 0.2039 (0.2696)	loss 1.6280 (1.3655)	grad_norm 0.4672 (0.5178)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:58:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:30 lr 0.000038	 wd 0.0000	time 0.1958 (0.2648)	loss 1.4778 (1.3632)	grad_norm 0.4395 (0.5157)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:58:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:58 lr 0.000038	 wd 0.0000	time 0.2262 (0.2610)	loss 1.6481 (1.3633)	grad_norm 0.4479 (0.5204)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:59:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:28 lr 0.000038	 wd 0.0000	time 0.2451 (0.2589)	loss 1.4942 (1.3596)	grad_norm 0.5397 (0.5190)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-12 23:59:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:06:03 lr 0.000038	 wd 0.0000	time 0.2601 (0.2596)	loss 1.3327 (1.3565)	grad_norm 0.4789 (0.5179)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 00:00:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:34 lr 0.000038	 wd 0.0000	time 0.2270 (0.2572)	loss 1.4517 (1.3568)	grad_norm 0.4524 (0.5162)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 00:00:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:05:06 lr 0.000038	 wd 0.0000	time 0.2175 (0.2551)	loss 1.1786 (1.3553)	grad_norm 0.5532 (0.5172)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 00:00:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:39 lr 0.000038	 wd 0.0000	time 0.2342 (0.2538)	loss 0.9624 (1.3571)	grad_norm 0.6176 (0.5178)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 00:01:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:04:14 lr 0.000038	 wd 0.0000	time 0.2185 (0.2540)	loss 0.8240 (1.3547)	grad_norm 0.6773 (0.5174)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 00:01:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:48 lr 0.000038	 wd 0.0000	time 0.2208 (0.2529)	loss 1.2199 (1.3520)	grad_norm 0.4615 (0.5162)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 00:02:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:21 lr 0.000038	 wd 0.0000	time 0.2079 (0.2518)	loss 1.1748 (1.3537)	grad_norm 0.5111 (0.5162)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 00:02:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:56 lr 0.000038	 wd 0.0000	time 0.2378 (0.2511)	loss 1.5333 (1.3548)	grad_norm 0.4560 (0.5150)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 00:02:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:31 lr 0.000038	 wd 0.0000	time 0.2313 (0.2516)	loss 1.2947 (1.3540)	grad_norm 0.4636 (0.5163)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 00:03:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:02:05 lr 0.000038	 wd 0.0000	time 0.2252 (0.2509)	loss 1.6849 (1.3560)	grad_norm 0.4951 (0.5158)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 00:03:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:40 lr 0.000038	 wd 0.0000	time 0.2106 (0.2501)	loss 1.4077 (1.3551)	grad_norm 0.4869 (0.5159)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 00:04:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:15 lr 0.000038	 wd 0.0000	time 0.2211 (0.2495)	loss 1.5527 (1.3537)	grad_norm 0.5545 (0.5169)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 00:04:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:50 lr 0.000038	 wd 0.0000	time 0.2135 (0.2500)	loss 1.4797 (1.3544)	grad_norm 0.5765 (0.5162)	loss_scale 4096.0000 (2137.0048)	mem 7984MB
[2024-07-13 00:04:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:25 lr 0.000038	 wd 0.0000	time 0.2148 (0.2495)	loss 1.3086 (1.3560)	grad_norm 0.5069 (0.5155)	loss_scale 4096.0000 (2218.5956)	mem 7984MB
[2024-07-13 00:05:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000038	 wd 0.0000	time 0.1880 (0.2479)	loss 1.7331 (1.3574)	grad_norm 0.4429 (0.5155)	loss_scale 4096.0000 (2293.6617)	mem 7984MB
[2024-07-13 00:05:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 8 training takes 0:10:24
[2024-07-13 00:05:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 29.119 (29.119)	Loss 0.4211 (0.4211)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 00:06:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.160 Acc@5 97.302
[2024-07-13 00:06:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-13 00:06:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.16%
[2024-07-13 00:06:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/ckpt_epoch_best.pth saving......
[2024-07-13 00:06:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/ckpt_epoch_best.pth saved !!!
[2024-07-13 00:06:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][0/2502]	eta 11:11:05 lr 0.000038	 wd 0.0000	time 16.0934 (16.0934)	loss 1.3551 (1.3551)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:06:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:15:32 lr 0.000038	 wd 0.0000	time 0.2150 (0.3881)	loss 1.2314 (1.3218)	grad_norm 0.5170 (0.5176)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:07:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:11:49 lr 0.000037	 wd 0.0000	time 0.2214 (0.3084)	loss 1.4868 (1.3348)	grad_norm 0.4903 (0.5105)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:07:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:11:15 lr 0.000037	 wd 0.0000	time 0.2375 (0.3067)	loss 1.4340 (1.3466)	grad_norm 0.4836 (0.5080)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:08:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:10:05 lr 0.000037	 wd 0.0000	time 0.2000 (0.2882)	loss 1.5779 (1.3416)	grad_norm 0.4969 (0.5043)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:08:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:09:13 lr 0.000037	 wd 0.0000	time 0.2299 (0.2765)	loss 1.3771 (1.3482)	grad_norm 0.4910 (0.5055)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:08:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:32 lr 0.000037	 wd 0.0000	time 0.2307 (0.2693)	loss 1.4901 (1.3428)	grad_norm 0.4610 (0.5086)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:09:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:08:05 lr 0.000037	 wd 0.0000	time 0.2001 (0.2695)	loss 1.5165 (1.3444)	grad_norm 0.4744 (0.5124)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:09:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:31 lr 0.000037	 wd 0.0000	time 0.2176 (0.2654)	loss 1.3747 (1.3472)	grad_norm 0.4637 (0.5108)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:10:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:59 lr 0.000037	 wd 0.0000	time 0.2207 (0.2618)	loss 1.5873 (1.3443)	grad_norm 0.6597 (0.5139)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:10:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:28 lr 0.000037	 wd 0.0000	time 0.2315 (0.2587)	loss 1.4587 (1.3470)	grad_norm 0.4546 (0.5129)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:10:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:06:03 lr 0.000037	 wd 0.0000	time 0.2600 (0.2592)	loss 1.3857 (1.3500)	grad_norm 0.4711 (0.5129)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:11:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:35 lr 0.000037	 wd 0.0000	time 0.2083 (0.2577)	loss 1.5399 (1.3511)	grad_norm 0.5101 (0.5124)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:11:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:05:07 lr 0.000037	 wd 0.0000	time 0.2123 (0.2558)	loss 0.9632 (1.3491)	grad_norm 0.4632 (0.5126)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:12:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:39 lr 0.000037	 wd 0.0000	time 0.2368 (0.2540)	loss 1.3366 (1.3504)	grad_norm 0.4734 (0.5131)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:12:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:04:14 lr 0.000037	 wd 0.0000	time 0.2040 (0.2542)	loss 1.4610 (1.3524)	grad_norm 0.5013 (0.5116)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:12:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:48 lr 0.000037	 wd 0.0000	time 0.2173 (0.2537)	loss 0.9252 (1.3514)	grad_norm 0.4687 (0.5109)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:13:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:22 lr 0.000037	 wd 0.0000	time 0.2298 (0.2526)	loss 1.1040 (1.3526)	grad_norm 0.4722 (0.5119)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:13:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:56 lr 0.000037	 wd 0.0000	time 0.2239 (0.2514)	loss 1.5247 (1.3530)	grad_norm 0.5733 (0.5111)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:14:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:31 lr 0.000037	 wd 0.0000	time 0.2238 (0.2514)	loss 1.3144 (1.3517)	grad_norm 0.5138 (0.5109)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:14:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:02:06 lr 0.000037	 wd 0.0000	time 0.2077 (0.2512)	loss 1.4878 (1.3519)	grad_norm 0.5248 (0.5100)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:14:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:40 lr 0.000036	 wd 0.0000	time 0.1986 (0.2504)	loss 1.0729 (1.3520)	grad_norm 0.4797 (0.5097)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:15:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:15 lr 0.000036	 wd 0.0000	time 0.2372 (0.2497)	loss 1.4825 (1.3530)	grad_norm 0.4674 (0.5103)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:15:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:50 lr 0.000036	 wd 0.0000	time 0.2517 (0.2500)	loss 1.4199 (1.3537)	grad_norm 0.4920 (0.5097)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:16:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:25 lr 0.000036	 wd 0.0000	time 0.2452 (0.2498)	loss 1.2664 (1.3534)	grad_norm 0.7385 (0.5098)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:16:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000036	 wd 0.0000	time 0.1821 (0.2481)	loss 1.1187 (1.3545)	grad_norm 0.4547 (0.5097)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:16:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 9 training takes 0:10:25
[2024-07-13 00:16:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 22.392 (22.392)	Loss 0.4097 (0.4097)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 00:17:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.076 Acc@5 97.266
[2024-07-13 00:17:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-13 00:17:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.16%
[2024-07-13 00:17:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][0/2502]	eta 21:41:16 lr 0.000036	 wd 0.0000	time 31.2057 (31.2057)	loss 1.2825 (1.2825)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:18:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:21:20 lr 0.000036	 wd 0.0000	time 0.2160 (0.5330)	loss 1.3475 (1.3351)	grad_norm 0.4447 (0.5043)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:18:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:14:35 lr 0.000036	 wd 0.0000	time 0.2345 (0.3801)	loss 1.2911 (1.3558)	grad_norm 0.4977 (0.5161)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:18:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:12:27 lr 0.000036	 wd 0.0000	time 0.2458 (0.3393)	loss 0.8782 (1.3530)	grad_norm 0.4658 (0.5108)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:19:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:11:02 lr 0.000036	 wd 0.0000	time 0.2153 (0.3153)	loss 1.5130 (1.3563)	grad_norm 0.5038 (0.5101)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:19:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:09:55 lr 0.000036	 wd 0.0000	time 0.2132 (0.2974)	loss 1.4066 (1.3522)	grad_norm 0.4792 (0.5139)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:20:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:09:04 lr 0.000036	 wd 0.0000	time 0.2214 (0.2864)	loss 1.5107 (1.3525)	grad_norm 0.5463 (0.5206)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:20:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:08:26 lr 0.000036	 wd 0.0000	time 0.2588 (0.2810)	loss 1.4544 (1.3484)	grad_norm 0.5095 (0.5287)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:20:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:07:52 lr 0.000036	 wd 0.0000	time 0.2266 (0.2778)	loss 1.2403 (1.3476)	grad_norm 0.4720 (0.5311)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:21:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:07:16 lr 0.000036	 wd 0.0000	time 0.2165 (0.2725)	loss 1.5266 (1.3478)	grad_norm 0.5537 (0.5294)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:21:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:42 lr 0.000036	 wd 0.0000	time 0.2125 (0.2683)	loss 1.4984 (1.3464)	grad_norm 0.4815 (0.5268)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:22:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:06:13 lr 0.000036	 wd 0.0000	time 0.2447 (0.2662)	loss 1.2959 (1.3439)	grad_norm 0.5331 (0.5270)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:22:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:45 lr 0.000035	 wd 0.0000	time 0.2994 (0.2655)	loss 1.3463 (1.3446)	grad_norm 0.6019 (0.5246)	loss_scale 8192.0000 (4109.6420)	mem 7984MB
[2024-07-13 00:22:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:05:15 lr 0.000035	 wd 0.0000	time 0.2341 (0.2629)	loss 1.5728 (1.3472)	grad_norm 0.4919 (0.5236)	loss_scale 8192.0000 (4423.4281)	mem 7984MB
[2024-07-13 00:23:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:47 lr 0.000035	 wd 0.0000	time 0.2384 (0.2606)	loss 1.3341 (1.3477)	grad_norm 0.4837 (0.5222)	loss_scale 8192.0000 (4692.4197)	mem 7984MB
[2024-07-13 00:23:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:04:19 lr 0.000035	 wd 0.0000	time 0.2520 (0.2595)	loss 1.2504 (1.3477)	grad_norm 0.4589 (0.5204)	loss_scale 8192.0000 (4925.5696)	mem 7984MB
[2024-07-13 00:24:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:54 lr 0.000035	 wd 0.0000	time 0.2651 (0.2597)	loss 1.2230 (1.3491)	grad_norm 0.5274 (0.5191)	loss_scale 8192.0000 (5129.5940)	mem 7984MB
[2024-07-13 00:24:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:27 lr 0.000035	 wd 0.0000	time 0.2340 (0.2583)	loss 1.3098 (1.3501)	grad_norm 0.4330 (0.5198)	loss_scale 8192.0000 (5309.6296)	mem 7984MB
[2024-07-13 00:24:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:03:00 lr 0.000035	 wd 0.0000	time 0.2113 (0.2568)	loss 1.3990 (1.3509)	grad_norm 0.5499 (0.5191)	loss_scale 8192.0000 (5469.6724)	mem 7984MB
[2024-07-13 00:25:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:34 lr 0.000035	 wd 0.0000	time 0.2224 (0.2559)	loss 1.4963 (1.3523)	grad_norm 0.5108 (0.5188)	loss_scale 8192.0000 (5612.8774)	mem 7984MB
[2024-07-13 00:25:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:02:08 lr 0.000035	 wd 0.0000	time 0.2620 (0.2556)	loss 1.2453 (1.3534)	grad_norm 0.5760 (0.5189)	loss_scale 8192.0000 (5741.7691)	mem 7984MB
[2024-07-13 00:26:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:42 lr 0.000035	 wd 0.0000	time 0.2149 (0.2546)	loss 1.5433 (1.3551)	grad_norm 0.5447 (0.5183)	loss_scale 8192.0000 (5858.3912)	mem 7984MB
[2024-07-13 00:26:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:16 lr 0.000035	 wd 0.0000	time 0.2302 (0.2536)	loss 0.9560 (1.3550)	grad_norm 0.4687 (0.5180)	loss_scale 8192.0000 (5964.4162)	mem 7984MB
[2024-07-13 00:26:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:51 lr 0.000035	 wd 0.0000	time 0.2227 (0.2531)	loss 1.4759 (1.3545)	grad_norm 0.4829 (0.5177)	loss_scale 8192.0000 (6061.2256)	mem 7984MB
[2024-07-13 00:27:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:25 lr 0.000035	 wd 0.0000	time 0.2173 (0.2529)	loss 1.5163 (1.3544)	grad_norm 0.4570 (0.5174)	loss_scale 8192.0000 (6149.9708)	mem 7984MB
[2024-07-13 00:27:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1884 (0.2512)	loss 1.3335 (1.3535)	grad_norm 0.5094 (0.5170)	loss_scale 8192.0000 (6231.6194)	mem 7984MB
[2024-07-13 00:27:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 10 training takes 0:10:32
[2024-07-13 00:28:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 20.057 (20.057)	Loss 0.4172 (0.4172)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 00:28:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.062 Acc@5 97.268
[2024-07-13 00:28:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-13 00:28:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.16%
[2024-07-13 00:28:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][0/2502]	eta 22:16:05 lr 0.000035	 wd 0.0000	time 32.0406 (32.0406)	loss 1.4891 (1.4891)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:29:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:21:59 lr 0.000035	 wd 0.0000	time 0.2053 (0.5494)	loss 1.3919 (1.3454)	grad_norm 0.5539 (0.5208)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:29:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:14:54 lr 0.000034	 wd 0.0000	time 0.2136 (0.3885)	loss 1.4625 (1.3491)	grad_norm 0.5552 (0.5182)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:29:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:12:16 lr 0.000034	 wd 0.0000	time 0.2379 (0.3343)	loss 1.3283 (1.3517)	grad_norm 0.5363 (0.5256)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:30:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:11:02 lr 0.000034	 wd 0.0000	time 0.2253 (0.3153)	loss 1.5320 (1.3513)	grad_norm 0.4954 (0.5191)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:30:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:09:56 lr 0.000034	 wd 0.0000	time 0.2173 (0.2982)	loss 1.3823 (1.3482)	grad_norm 0.4236 (0.5156)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:31:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:09:05 lr 0.000034	 wd 0.0000	time 0.2071 (0.2868)	loss 1.4682 (1.3459)	grad_norm 0.4787 (0.5147)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:31:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:08:22 lr 0.000034	 wd 0.0000	time 0.2192 (0.2788)	loss 1.4713 (1.3464)	grad_norm 0.4739 (0.5130)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:31:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:07:49 lr 0.000034	 wd 0.0000	time 0.2083 (0.2756)	loss 1.5949 (1.3489)	grad_norm 0.5359 (0.5132)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:32:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:07:15 lr 0.000034	 wd 0.0000	time 0.2338 (0.2719)	loss 1.5013 (1.3489)	grad_norm 0.4656 (0.5124)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:32:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:42 lr 0.000034	 wd 0.0000	time 0.2027 (0.2677)	loss 1.4433 (1.3510)	grad_norm 0.4913 (0.5129)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:33:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:06:10 lr 0.000034	 wd 0.0000	time 0.2494 (0.2642)	loss 1.5475 (1.3524)	grad_norm 0.5778 (0.5127)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:33:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:42 lr 0.000034	 wd 0.0000	time 0.2339 (0.2630)	loss 1.6946 (1.3522)	grad_norm 0.5178 (0.5159)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:33:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:05:15 lr 0.000034	 wd 0.0000	time 0.2561 (0.2622)	loss 0.8975 (1.3511)	grad_norm 0.4305 (0.5152)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:34:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:46 lr 0.000034	 wd 0.0000	time 0.2245 (0.2601)	loss 0.8796 (1.3507)	grad_norm 0.4460 (0.5155)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:34:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:04:18 lr 0.000034	 wd 0.0000	time 0.2196 (0.2580)	loss 1.4284 (1.3497)	grad_norm 0.4686 (0.5178)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:35:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:52 lr 0.000034	 wd 0.0000	time 0.2425 (0.2573)	loss 1.2574 (1.3507)	grad_norm 0.5004 (0.5181)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:35:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:26 lr 0.000033	 wd 0.0000	time 0.2416 (0.2574)	loss 1.4471 (1.3499)	grad_norm 0.4520 (0.5174)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:35:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:59 lr 0.000033	 wd 0.0000	time 0.2133 (0.2563)	loss 1.2807 (1.3516)	grad_norm 0.4806 (0.5176)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:36:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:33 lr 0.000033	 wd 0.0000	time 0.2397 (0.2551)	loss 1.4924 (1.3518)	grad_norm 0.4768 (0.5168)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:36:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:02:07 lr 0.000033	 wd 0.0000	time 0.2567 (0.2546)	loss 1.1131 (1.3512)	grad_norm 0.4479 (0.5182)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:37:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:42 lr 0.000033	 wd 0.0000	time 0.2225 (0.2547)	loss 1.5344 (1.3509)	grad_norm 0.5334 (0.5174)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:37:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:16 lr 0.000033	 wd 0.0000	time 0.2120 (0.2539)	loss 1.2656 (1.3518)	grad_norm 0.4559 (0.5178)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:37:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:51 lr 0.000033	 wd 0.0000	time 0.2533 (0.2529)	loss 1.5110 (1.3515)	grad_norm 0.5366 (0.5178)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:38:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:25 lr 0.000033	 wd 0.0000	time 0.2472 (0.2526)	loss 1.2570 (1.3507)	grad_norm 0.4917 (0.5173)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:38:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000033	 wd 0.0000	time 0.1934 (0.2509)	loss 1.3881 (1.3503)	grad_norm 0.5898 (0.5168)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:38:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 11 training takes 0:10:33
[2024-07-13 00:39:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 20.807 (20.807)	Loss 0.4160 (0.4160)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 7984MB
[2024-07-13 00:39:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.190 Acc@5 97.266
[2024-07-13 00:39:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-13 00:39:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.19%
[2024-07-13 00:39:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/ckpt_epoch_best.pth saving......
[2024-07-13 00:39:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/ckpt_epoch_best.pth saved !!!
[2024-07-13 00:39:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][0/2502]	eta 10:55:30 lr 0.000033	 wd 0.0000	time 15.7198 (15.7198)	loss 1.6072 (1.6072)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:40:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:16:52 lr 0.000033	 wd 0.0000	time 0.2459 (0.4213)	loss 1.4914 (1.3562)	grad_norm 0.5090 (0.5345)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 00:40:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:12:31 lr 0.000033	 wd 0.0000	time 0.2198 (0.3265)	loss 0.9758 (1.3623)	grad_norm 0.4705 (0.5291)	loss_scale 16384.0000 (8518.0498)	mem 7984MB
[2024-07-13 00:40:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:47 lr 0.000033	 wd 0.0000	time 0.2481 (0.2939)	loss 1.3000 (1.3623)	grad_norm 0.5510 (0.5219)	loss_scale 16384.0000 (11131.3223)	mem 7984MB
[2024-07-13 00:41:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:41 lr 0.000033	 wd 0.0000	time 0.2469 (0.2767)	loss 1.2272 (1.3549)	grad_norm 0.4426 (0.5235)	loss_scale 16384.0000 (12441.2170)	mem 7984MB
[2024-07-13 00:41:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:09:02 lr 0.000032	 wd 0.0000	time 0.2712 (0.2711)	loss 1.0110 (1.3556)	grad_norm 0.4442 (0.5249)	loss_scale 16384.0000 (13228.1996)	mem 7984MB
[2024-07-13 00:42:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:08:27 lr 0.000032	 wd 0.0000	time 0.2052 (0.2671)	loss 1.3445 (1.3528)	grad_norm 0.4991 (0.5210)	loss_scale 16384.0000 (13753.2912)	mem 7984MB
[2024-07-13 00:42:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:51 lr 0.000032	 wd 0.0000	time 0.2485 (0.2618)	loss 1.4470 (1.3506)	grad_norm 0.5294 (nan)	loss_scale 4096.0000 (13205.3638)	mem 7984MB
[2024-07-13 00:42:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:07:18 lr 0.000032	 wd 0.0000	time 0.2043 (0.2575)	loss 1.4379 (1.3584)	grad_norm 1.4088 (nan)	loss_scale 4096.0000 (12068.1149)	mem 7984MB
[2024-07-13 00:43:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:51 lr 0.000032	 wd 0.0000	time 0.2296 (0.2567)	loss 1.0454 (1.3588)	grad_norm 0.4883 (nan)	loss_scale 4096.0000 (11183.3074)	mem 7984MB
[2024-07-13 00:43:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:23 lr 0.000032	 wd 0.0000	time 0.2187 (0.2553)	loss 1.6298 (1.3564)	grad_norm 0.4835 (nan)	loss_scale 4096.0000 (10475.2847)	mem 7984MB
[2024-07-13 00:43:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:54 lr 0.000032	 wd 0.0000	time 0.2608 (0.2531)	loss 1.4704 (1.3603)	grad_norm 0.4542 (nan)	loss_scale 4096.0000 (9895.8765)	mem 7984MB
[2024-07-13 00:44:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:26 lr 0.000032	 wd 0.0000	time 0.2359 (0.2511)	loss 1.4969 (1.3594)	grad_norm 0.5189 (nan)	loss_scale 4096.0000 (9412.9559)	mem 7984MB
[2024-07-13 00:44:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:05:01 lr 0.000032	 wd 0.0000	time 0.2259 (0.2508)	loss 1.4397 (1.3598)	grad_norm 0.4930 (nan)	loss_scale 4096.0000 (9004.2736)	mem 7984MB
[2024-07-13 00:45:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:36 lr 0.000032	 wd 0.0000	time 0.2246 (0.2512)	loss 1.5877 (1.3597)	grad_norm 0.5467 (nan)	loss_scale 4096.0000 (8653.9329)	mem 7984MB
[2024-07-13 00:45:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:04:10 lr 0.000032	 wd 0.0000	time 0.2365 (0.2500)	loss 1.4285 (1.3603)	grad_norm 0.4635 (nan)	loss_scale 4096.0000 (8350.2732)	mem 7984MB
[2024-07-13 00:45:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:44 lr 0.000032	 wd 0.0000	time 0.2143 (0.2488)	loss 1.4142 (1.3591)	grad_norm 0.4956 (nan)	loss_scale 4096.0000 (8084.5472)	mem 7984MB
[2024-07-13 00:46:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:19 lr 0.000031	 wd 0.0000	time 0.2350 (0.2485)	loss 1.5588 (1.3602)	grad_norm 0.4653 (nan)	loss_scale 4096.0000 (7850.0647)	mem 7984MB
[2024-07-13 00:46:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:54 lr 0.000031	 wd 0.0000	time 0.2535 (0.2492)	loss 1.2688 (1.3610)	grad_norm 0.4930 (nan)	loss_scale 4096.0000 (7641.6213)	mem 7984MB
[2024-07-13 00:47:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:29 lr 0.000031	 wd 0.0000	time 0.2174 (0.2484)	loss 1.4066 (1.3605)	grad_norm 0.5295 (nan)	loss_scale 4096.0000 (7455.1078)	mem 7984MB
[2024-07-13 00:47:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:02:04 lr 0.000031	 wd 0.0000	time 0.2348 (0.2476)	loss 1.3895 (1.3595)	grad_norm 0.4649 (nan)	loss_scale 4096.0000 (7287.2364)	mem 7984MB
[2024-07-13 00:48:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:39 lr 0.000031	 wd 0.0000	time 0.2453 (0.2475)	loss 1.4232 (1.3608)	grad_norm 0.4781 (nan)	loss_scale 4096.0000 (7135.3451)	mem 7984MB
[2024-07-13 00:48:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:14 lr 0.000031	 wd 0.0000	time 0.2817 (0.2476)	loss 1.5607 (1.3622)	grad_norm 1.1038 (nan)	loss_scale 4096.0000 (6997.2558)	mem 7984MB
[2024-07-13 00:48:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:49 lr 0.000031	 wd 0.0000	time 0.2219 (0.2471)	loss 1.4259 (1.3622)	grad_norm 0.4893 (nan)	loss_scale 4096.0000 (6871.1691)	mem 7984MB
[2024-07-13 00:49:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:25 lr 0.000031	 wd 0.0000	time 0.2085 (0.2465)	loss 1.4963 (1.3619)	grad_norm 0.5460 (nan)	loss_scale 4096.0000 (6755.5852)	mem 7984MB
[2024-07-13 00:49:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000031	 wd 0.0000	time 0.1797 (0.2449)	loss 1.1184 (1.3607)	grad_norm 0.5783 (nan)	loss_scale 4096.0000 (6649.2443)	mem 7984MB
[2024-07-13 00:49:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 12 training takes 0:10:17
[2024-07-13 00:50:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 37.475 (37.475)	Loss 0.4143 (0.4143)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 00:50:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.162 Acc@5 97.290
[2024-07-13 00:50:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-13 00:50:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.19%
[2024-07-13 00:50:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][0/2502]	eta 11:03:47 lr 0.000031	 wd 0.0000	time 15.9184 (15.9184)	loss 1.3583 (1.3583)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:51:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:16:22 lr 0.000031	 wd 0.0000	time 0.2922 (0.4089)	loss 1.3781 (1.3477)	grad_norm 0.6128 (0.5301)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:51:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:12:57 lr 0.000031	 wd 0.0000	time 0.2171 (0.3376)	loss 1.6815 (1.3493)	grad_norm 0.4557 (0.5101)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:51:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:11:04 lr 0.000031	 wd 0.0000	time 0.1923 (0.3020)	loss 1.4350 (1.3573)	grad_norm 0.4942 (0.5159)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:52:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:09:54 lr 0.000030	 wd 0.0000	time 0.1989 (0.2830)	loss 1.3251 (1.3561)	grad_norm 0.5042 (0.5159)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:52:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:09:09 lr 0.000030	 wd 0.0000	time 0.2506 (0.2746)	loss 1.5302 (1.3509)	grad_norm 0.5197 (0.5119)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:53:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:35 lr 0.000030	 wd 0.0000	time 0.2147 (0.2711)	loss 1.5281 (1.3572)	grad_norm 0.4896 (0.5151)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:53:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:07:57 lr 0.000030	 wd 0.0000	time 0.2086 (0.2653)	loss 1.4262 (1.3527)	grad_norm 0.4887 (0.5182)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:53:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:24 lr 0.000030	 wd 0.0000	time 0.1870 (0.2610)	loss 1.5322 (1.3565)	grad_norm 0.6196 (0.5237)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:54:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:06:53 lr 0.000030	 wd 0.0000	time 0.2320 (0.2583)	loss 1.5195 (1.3536)	grad_norm 0.5188 (0.5228)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:54:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:28 lr 0.000030	 wd 0.0000	time 0.2513 (0.2588)	loss 1.5962 (1.3592)	grad_norm 0.4526 (0.5216)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:55:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:59 lr 0.000030	 wd 0.0000	time 0.2074 (0.2564)	loss 1.3853 (1.3606)	grad_norm 0.4999 (0.5207)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:55:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:31 lr 0.000030	 wd 0.0000	time 0.2542 (0.2546)	loss 1.5454 (1.3570)	grad_norm 0.4581 (0.5201)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:55:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:05:04 lr 0.000030	 wd 0.0000	time 0.2315 (0.2537)	loss 1.4163 (1.3556)	grad_norm 0.4925 (0.5212)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:56:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:40 lr 0.000030	 wd 0.0000	time 0.2300 (0.2541)	loss 1.6371 (1.3561)	grad_norm 0.5298 (0.5218)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:56:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:04:13 lr 0.000030	 wd 0.0000	time 0.2390 (0.2529)	loss 1.6236 (1.3549)	grad_norm 0.4700 (0.5220)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:57:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:47 lr 0.000029	 wd 0.0000	time 0.2239 (0.2518)	loss 1.5663 (1.3546)	grad_norm 0.5079 (0.5216)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:57:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:21 lr 0.000029	 wd 0.0000	time 0.2857 (0.2511)	loss 0.8627 (1.3522)	grad_norm 0.4745 (0.5214)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:58:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:57 lr 0.000029	 wd 0.0000	time 0.2039 (0.2526)	loss 1.4187 (1.3539)	grad_norm 0.4502 (0.5212)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:58:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:31 lr 0.000029	 wd 0.0000	time 0.2161 (0.2517)	loss 1.2012 (1.3543)	grad_norm 0.6376 (0.5214)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:58:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:02:05 lr 0.000029	 wd 0.0000	time 0.2593 (0.2509)	loss 1.4261 (1.3553)	grad_norm 0.5308 (0.5207)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:59:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:40 lr 0.000029	 wd 0.0000	time 0.2385 (0.2505)	loss 1.1003 (1.3550)	grad_norm 0.4776 (0.5201)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 00:59:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:15 lr 0.000029	 wd 0.0000	time 0.2268 (0.2506)	loss 1.5297 (1.3565)	grad_norm 0.4854 (0.5202)	loss_scale 8192.0000 (4148.1072)	mem 7984MB
[2024-07-13 01:00:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:50 lr 0.000029	 wd 0.0000	time 0.2350 (0.2498)	loss 1.3028 (1.3559)	grad_norm 0.5096 (0.5207)	loss_scale 8192.0000 (4323.8522)	mem 7984MB
[2024-07-13 01:00:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:25 lr 0.000029	 wd 0.0000	time 0.2145 (0.2492)	loss 1.6740 (1.3571)	grad_norm 0.4619 (0.5206)	loss_scale 8192.0000 (4484.9579)	mem 7984MB
[2024-07-13 01:00:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000029	 wd 0.0000	time 0.1790 (0.2473)	loss 1.5176 (1.3565)	grad_norm 0.4436 (0.5201)	loss_scale 8192.0000 (4633.1803)	mem 7984MB
[2024-07-13 01:00:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 13 training takes 0:10:23
[2024-07-13 01:01:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 39.812 (39.812)	Loss 0.4104 (0.4104)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 01:01:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.148 Acc@5 97.300
[2024-07-13 01:01:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-13 01:01:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.19%
[2024-07-13 01:02:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][0/2502]	eta 11:21:10 lr 0.000029	 wd 0.0000	time 16.3350 (16.3350)	loss 1.4800 (1.4800)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 01:02:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:16:17 lr 0.000029	 wd 0.0000	time 0.2599 (0.4070)	loss 1.5309 (1.3657)	grad_norm 0.4703 (0.5115)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 01:02:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:13:38 lr 0.000028	 wd 0.0000	time 0.1976 (0.3557)	loss 1.3122 (1.3853)	grad_norm 0.5032 (inf)	loss_scale 4096.0000 (7580.6567)	mem 7984MB
[2024-07-13 01:03:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:11:28 lr 0.000028	 wd 0.0000	time 0.2152 (0.3127)	loss 1.0120 (1.3733)	grad_norm 0.4610 (inf)	loss_scale 4096.0000 (6422.9635)	mem 7984MB
[2024-07-13 01:03:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:10:12 lr 0.000028	 wd 0.0000	time 0.2273 (0.2912)	loss 1.1976 (1.3585)	grad_norm 0.4733 (inf)	loss_scale 4096.0000 (5842.6733)	mem 7984MB
[2024-07-13 01:04:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:09:22 lr 0.000028	 wd 0.0000	time 0.2307 (0.2808)	loss 1.2790 (1.3612)	grad_norm 0.4791 (inf)	loss_scale 4096.0000 (5494.0359)	mem 7984MB
[2024-07-13 01:04:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:08:41 lr 0.000028	 wd 0.0000	time 0.2079 (0.2742)	loss 1.6487 (1.3667)	grad_norm 0.6855 (inf)	loss_scale 4096.0000 (5261.4176)	mem 7984MB
[2024-07-13 01:04:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:08:03 lr 0.000028	 wd 0.0000	time 0.2069 (0.2680)	loss 1.4314 (1.3626)	grad_norm 0.4770 (inf)	loss_scale 4096.0000 (5095.1669)	mem 7984MB
[2024-07-13 01:05:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:27 lr 0.000028	 wd 0.0000	time 0.1802 (0.2631)	loss 1.3812 (1.3589)	grad_norm 0.4619 (inf)	loss_scale 2048.0000 (4929.5181)	mem 7984MB
[2024-07-13 01:05:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:56 lr 0.000028	 wd 0.0000	time 0.3299 (0.2603)	loss 1.4331 (1.3550)	grad_norm 0.4794 (inf)	loss_scale 2048.0000 (4609.7048)	mem 7984MB
[2024-07-13 01:06:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:06:30 lr 0.000028	 wd 0.0000	time 0.2027 (0.2597)	loss 1.3119 (1.3535)	grad_norm 0.4549 (inf)	loss_scale 2048.0000 (4353.7902)	mem 7984MB
[2024-07-13 01:06:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:06:00 lr 0.000028	 wd 0.0000	time 0.2351 (0.2572)	loss 1.4814 (1.3511)	grad_norm 0.4605 (inf)	loss_scale 2048.0000 (4144.3633)	mem 7984MB
[2024-07-13 01:06:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:32 lr 0.000028	 wd 0.0000	time 0.2339 (0.2550)	loss 1.4103 (1.3513)	grad_norm 0.4560 (inf)	loss_scale 2048.0000 (3969.8118)	mem 7984MB
[2024-07-13 01:07:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:05:05 lr 0.000027	 wd 0.0000	time 0.2393 (0.2538)	loss 1.1725 (1.3515)	grad_norm 0.5122 (inf)	loss_scale 2048.0000 (3822.0938)	mem 7984MB
[2024-07-13 01:07:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:40 lr 0.000027	 wd 0.0000	time 0.2477 (0.2541)	loss 1.6439 (1.3505)	grad_norm 0.4645 (inf)	loss_scale 2048.0000 (3695.4632)	mem 7984MB
[2024-07-13 01:08:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:04:13 lr 0.000027	 wd 0.0000	time 0.2183 (0.2529)	loss 1.3705 (1.3513)	grad_norm 0.4397 (inf)	loss_scale 2048.0000 (3585.7055)	mem 7984MB
[2024-07-13 01:08:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:46 lr 0.000027	 wd 0.0000	time 0.2299 (0.2516)	loss 1.3139 (1.3512)	grad_norm 0.4979 (inf)	loss_scale 2048.0000 (3489.6590)	mem 7984MB
[2024-07-13 01:08:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:21 lr 0.000027	 wd 0.0000	time 0.2422 (0.2507)	loss 1.1783 (1.3505)	grad_norm 0.4965 (inf)	loss_scale 2048.0000 (3404.9053)	mem 7984MB
[2024-07-13 01:09:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:56 lr 0.000027	 wd 0.0000	time 0.2040 (0.2515)	loss 1.3058 (1.3504)	grad_norm 0.5326 (inf)	loss_scale 2048.0000 (3329.5636)	mem 7984MB
[2024-07-13 01:09:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:30 lr 0.000027	 wd 0.0000	time 0.2108 (0.2507)	loss 1.5249 (1.3504)	grad_norm 0.4903 (inf)	loss_scale 2048.0000 (3262.1483)	mem 7984MB
[2024-07-13 01:10:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:02:05 lr 0.000027	 wd 0.0000	time 0.2101 (0.2497)	loss 1.0649 (1.3523)	grad_norm 0.4825 (inf)	loss_scale 2048.0000 (3201.4713)	mem 7984MB
[2024-07-13 01:10:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:40 lr 0.000027	 wd 0.0000	time 0.2996 (0.2491)	loss 1.5486 (1.3521)	grad_norm 0.5144 (inf)	loss_scale 2048.0000 (3146.5702)	mem 7984MB
[2024-07-13 01:10:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:15 lr 0.000027	 wd 0.0000	time 0.2261 (0.2492)	loss 1.2142 (1.3523)	grad_norm 0.4595 (inf)	loss_scale 2048.0000 (3096.6579)	mem 7984MB
[2024-07-13 01:11:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:50 lr 0.000027	 wd 0.0000	time 0.2342 (0.2487)	loss 1.3771 (1.3531)	grad_norm 0.4984 (inf)	loss_scale 2048.0000 (3051.0839)	mem 7984MB
[2024-07-13 01:11:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:25 lr 0.000026	 wd 0.0000	time 0.2091 (0.2481)	loss 1.1220 (1.3542)	grad_norm 0.5674 (inf)	loss_scale 2048.0000 (3009.3061)	mem 7984MB
[2024-07-13 01:12:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1996 (0.2463)	loss 1.2479 (1.3533)	grad_norm 0.4993 (inf)	loss_scale 2048.0000 (2970.8693)	mem 7984MB
[2024-07-13 01:12:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 14 training takes 0:10:20
[2024-07-13 01:12:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 36.589 (36.589)	Loss 0.4114 (0.4114)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 01:12:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.112 Acc@5 97.304
[2024-07-13 01:12:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-13 01:12:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.19%
[2024-07-13 01:13:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][0/2502]	eta 11:06:37 lr 0.000026	 wd 0.0000	time 15.9861 (15.9861)	loss 1.4490 (1.4490)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:13:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:15:30 lr 0.000026	 wd 0.0000	time 0.2540 (0.3872)	loss 1.0148 (1.3399)	grad_norm 0.4787 (0.5202)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:14:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:12:32 lr 0.000026	 wd 0.0000	time 0.2253 (0.3268)	loss 1.4414 (1.3550)	grad_norm 0.5187 (0.5088)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:14:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:10:54 lr 0.000026	 wd 0.0000	time 0.2190 (0.2971)	loss 1.3918 (1.3421)	grad_norm 0.4802 (0.5141)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:14:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:09:47 lr 0.000026	 wd 0.0000	time 0.2230 (0.2793)	loss 1.3837 (1.3459)	grad_norm 0.5160 (0.5076)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:15:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:08:56 lr 0.000026	 wd 0.0000	time 0.2043 (0.2679)	loss 0.8662 (1.3436)	grad_norm 0.4664 (0.5095)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:15:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:08:23 lr 0.000026	 wd 0.0000	time 0.2239 (0.2646)	loss 0.8393 (1.3472)	grad_norm 0.5064 (0.5103)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:15:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:52 lr 0.000026	 wd 0.0000	time 0.2201 (0.2623)	loss 1.1020 (1.3497)	grad_norm 0.9829 (0.5116)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:16:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:07:19 lr 0.000026	 wd 0.0000	time 0.2270 (0.2582)	loss 1.4079 (1.3500)	grad_norm 0.5329 (0.5121)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:16:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:48 lr 0.000025	 wd 0.0000	time 0.2259 (0.2549)	loss 1.2223 (1.3509)	grad_norm 0.4750 (0.5125)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:17:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:06:22 lr 0.000025	 wd 0.0000	time 0.2461 (0.2548)	loss 1.4210 (1.3523)	grad_norm 0.4937 (0.5121)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:17:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:56 lr 0.000025	 wd 0.0000	time 0.2256 (0.2542)	loss 1.2439 (1.3495)	grad_norm 0.5180 (0.5119)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:17:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:28 lr 0.000025	 wd 0.0000	time 0.2325 (0.2521)	loss 1.3878 (1.3501)	grad_norm 0.4793 (0.5120)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:18:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:05:00 lr 0.000025	 wd 0.0000	time 0.2131 (0.2504)	loss 1.3537 (1.3485)	grad_norm 0.4951 (0.5134)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:18:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:35 lr 0.000025	 wd 0.0000	time 0.2634 (0.2501)	loss 1.4425 (1.3486)	grad_norm 0.7312 (0.5147)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:19:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:04:10 lr 0.000025	 wd 0.0000	time 0.2356 (0.2502)	loss 1.5616 (1.3484)	grad_norm 0.4892 (0.5141)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:19:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:44 lr 0.000025	 wd 0.0000	time 0.2570 (0.2491)	loss 1.2717 (1.3508)	grad_norm 0.4709 (0.5164)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:19:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:18 lr 0.000025	 wd 0.0000	time 0.2046 (0.2481)	loss 1.4199 (1.3498)	grad_norm 0.4874 (0.5169)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:20:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:53 lr 0.000025	 wd 0.0000	time 0.2497 (0.2477)	loss 1.0639 (1.3496)	grad_norm 0.5559 (0.5184)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:20:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:29 lr 0.000024	 wd 0.0000	time 0.2461 (0.2484)	loss 1.5975 (1.3501)	grad_norm 0.5444 (0.5184)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:21:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:02:04 lr 0.000024	 wd 0.0000	time 0.2360 (0.2476)	loss 1.8275 (1.3523)	grad_norm 1.2666 (0.5231)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:21:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:39 lr 0.000024	 wd 0.0000	time 0.2409 (0.2470)	loss 1.4957 (1.3530)	grad_norm 0.5131 (0.5220)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:21:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:14 lr 0.000024	 wd 0.0000	time 0.2577 (0.2467)	loss 1.0601 (1.3542)	grad_norm 0.4765 (0.5220)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:22:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:49 lr 0.000024	 wd 0.0000	time 0.2183 (0.2469)	loss 1.5722 (1.3544)	grad_norm 0.5306 (0.5226)	loss_scale 4096.0000 (2064.0209)	mem 7984MB
[2024-07-13 01:22:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:25 lr 0.000024	 wd 0.0000	time 0.2033 (0.2465)	loss 1.0635 (1.3532)	grad_norm 0.4650 (0.5294)	loss_scale 4096.0000 (2148.6514)	mem 7984MB
[2024-07-13 01:23:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1717 (0.2448)	loss 1.2091 (1.3533)	grad_norm 0.4502 (0.5283)	loss_scale 4096.0000 (2226.5142)	mem 7984MB
[2024-07-13 01:23:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 15 training takes 0:10:16
[2024-07-13 01:23:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/ckpt_epoch_15.pth saving......
[2024-07-13 01:23:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/ckpt_epoch_15.pth saved !!!
[2024-07-13 01:23:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 35.292 (35.292)	Loss 0.4116 (0.4116)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 01:24:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.182 Acc@5 97.288
[2024-07-13 01:24:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-13 01:24:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.19%
[2024-07-13 01:24:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][0/2502]	eta 11:50:57 lr 0.000024	 wd 0.0000	time 17.0495 (17.0495)	loss 1.2679 (1.2679)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:24:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:15:51 lr 0.000024	 wd 0.0000	time 0.2327 (0.3962)	loss 1.4669 (1.3476)	grad_norm 0.5089 (0.5101)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:25:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:12:12 lr 0.000024	 wd 0.0000	time 0.3160 (0.3181)	loss 1.3092 (1.3566)	grad_norm 0.4737 (0.5249)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:25:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:11:33 lr 0.000024	 wd 0.0000	time 0.2378 (0.3149)	loss 1.3469 (1.3687)	grad_norm 0.4818 (0.5177)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:25:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:10:15 lr 0.000024	 wd 0.0000	time 0.2313 (0.2928)	loss 1.2724 (1.3625)	grad_norm 0.4810 (0.5169)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:26:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:09:21 lr 0.000023	 wd 0.0000	time 0.2131 (0.2803)	loss 1.2457 (1.3724)	grad_norm 0.4582 (0.5168)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:26:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:40 lr 0.000023	 wd 0.0000	time 0.2478 (0.2734)	loss 1.0381 (1.3648)	grad_norm 0.5304 (nan)	loss_scale 2048.0000 (3946.0632)	mem 7984MB
[2024-07-13 01:27:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:08:08 lr 0.000023	 wd 0.0000	time 0.2136 (0.2710)	loss 1.3197 (1.3665)	grad_norm 0.4814 (nan)	loss_scale 2048.0000 (3675.2981)	mem 7984MB
[2024-07-13 01:27:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:07:32 lr 0.000023	 wd 0.0000	time 0.2192 (0.2661)	loss 1.3854 (1.3611)	grad_norm 0.4654 (nan)	loss_scale 2048.0000 (3472.1398)	mem 7984MB
[2024-07-13 01:27:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:59 lr 0.000023	 wd 0.0000	time 0.2060 (0.2620)	loss 1.5515 (1.3589)	grad_norm 0.4744 (nan)	loss_scale 2048.0000 (3314.0777)	mem 7984MB
[2024-07-13 01:28:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:06:30 lr 0.000023	 wd 0.0000	time 0.2406 (0.2600)	loss 1.5459 (1.3592)	grad_norm 0.4669 (nan)	loss_scale 2048.0000 (3187.5964)	mem 7984MB
[2024-07-13 01:28:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:06:04 lr 0.000023	 wd 0.0000	time 0.2006 (0.2597)	loss 1.3218 (1.3602)	grad_norm 1.3017 (nan)	loss_scale 2048.0000 (3084.0908)	mem 7984MB
[2024-07-13 01:29:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:34 lr 0.000023	 wd 0.0000	time 0.2101 (0.2572)	loss 1.3952 (1.3614)	grad_norm 0.4963 (nan)	loss_scale 2048.0000 (2997.8218)	mem 7984MB
[2024-07-13 01:29:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:05:06 lr 0.000023	 wd 0.0000	time 0.2304 (0.2553)	loss 1.0895 (1.3619)	grad_norm 0.4595 (nan)	loss_scale 2048.0000 (2924.8148)	mem 7984MB
[2024-07-13 01:29:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:39 lr 0.000023	 wd 0.0000	time 0.2493 (0.2539)	loss 1.2029 (1.3592)	grad_norm 0.4809 (nan)	loss_scale 2048.0000 (2862.2298)	mem 7984MB
[2024-07-13 01:30:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:04:14 lr 0.000022	 wd 0.0000	time 0.1917 (0.2544)	loss 1.4031 (1.3562)	grad_norm 0.4731 (nan)	loss_scale 2048.0000 (2807.9840)	mem 7984MB
[2024-07-13 01:30:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:48 lr 0.000022	 wd 0.0000	time 0.2362 (0.2532)	loss 1.3800 (1.3566)	grad_norm 0.5531 (nan)	loss_scale 2048.0000 (2760.5147)	mem 7984MB
[2024-07-13 01:31:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:22 lr 0.000022	 wd 0.0000	time 0.2218 (0.2521)	loss 1.1074 (1.3546)	grad_norm 0.6897 (nan)	loss_scale 2048.0000 (2718.6267)	mem 7984MB
[2024-07-13 01:31:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:56 lr 0.000022	 wd 0.0000	time 0.2165 (0.2514)	loss 1.2415 (1.3530)	grad_norm 0.5703 (nan)	loss_scale 2048.0000 (2681.3903)	mem 7984MB
[2024-07-13 01:32:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:31 lr 0.000022	 wd 0.0000	time 0.2302 (0.2517)	loss 1.1879 (1.3519)	grad_norm 0.4512 (nan)	loss_scale 2048.0000 (2648.0715)	mem 7984MB
[2024-07-13 01:32:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:02:06 lr 0.000022	 wd 0.0000	time 0.2164 (0.2511)	loss 1.4663 (1.3521)	grad_norm 0.4864 (nan)	loss_scale 2048.0000 (2618.0830)	mem 7984MB
[2024-07-13 01:32:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:40 lr 0.000022	 wd 0.0000	time 0.2466 (0.2503)	loss 1.3400 (1.3517)	grad_norm 0.5482 (nan)	loss_scale 2048.0000 (2590.9491)	mem 7984MB
[2024-07-13 01:33:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:15 lr 0.000022	 wd 0.0000	time 0.2436 (0.2497)	loss 1.4651 (1.3523)	grad_norm 0.8507 (nan)	loss_scale 2048.0000 (2566.2808)	mem 7984MB
[2024-07-13 01:33:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:50 lr 0.000022	 wd 0.0000	time 0.2116 (0.2498)	loss 1.2103 (1.3524)	grad_norm 0.4815 (nan)	loss_scale 2048.0000 (2543.7566)	mem 7984MB
[2024-07-13 01:34:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:25 lr 0.000022	 wd 0.0000	time 0.2037 (0.2493)	loss 1.5316 (1.3525)	grad_norm 0.5683 (nan)	loss_scale 2048.0000 (2523.1087)	mem 7984MB
[2024-07-13 01:34:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1660 (0.2478)	loss 1.3616 (1.3525)	grad_norm 0.4701 (nan)	loss_scale 2048.0000 (2504.1120)	mem 7984MB
[2024-07-13 01:34:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 16 training takes 0:10:23
[2024-07-13 01:34:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 28.288 (28.288)	Loss 0.4131 (0.4131)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 01:35:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.196 Acc@5 97.282
[2024-07-13 01:35:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-13 01:35:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.20%
[2024-07-13 01:35:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/ckpt_epoch_best.pth saving......
[2024-07-13 01:35:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/ckpt_epoch_best.pth saved !!!
[2024-07-13 01:35:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][0/2502]	eta 11:31:17 lr 0.000021	 wd 0.0000	time 16.5779 (16.5779)	loss 1.4494 (1.4494)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:35:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:15:42 lr 0.000021	 wd 0.0000	time 0.2372 (0.3924)	loss 1.5541 (1.3277)	grad_norm 0.4930 (0.5510)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:36:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:11:51 lr 0.000021	 wd 0.0000	time 0.2200 (0.3093)	loss 1.5889 (1.3434)	grad_norm 0.6165 (0.5388)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:36:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:49 lr 0.000021	 wd 0.0000	time 0.2263 (0.2951)	loss 1.3256 (1.3399)	grad_norm 0.7938 (0.5347)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:37:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:09:47 lr 0.000021	 wd 0.0000	time 0.2312 (0.2795)	loss 1.1181 (1.3342)	grad_norm 0.5390 (0.5256)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:37:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:08:58 lr 0.000021	 wd 0.0000	time 0.2123 (0.2688)	loss 1.3603 (1.3342)	grad_norm 0.4706 (0.5282)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:37:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:18 lr 0.000021	 wd 0.0000	time 0.2481 (0.2622)	loss 1.1830 (1.3410)	grad_norm 0.4841 (0.5278)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:38:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:50 lr 0.000021	 wd 0.0000	time 0.2490 (0.2609)	loss 1.3266 (1.3467)	grad_norm 0.8467 (0.5262)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:38:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:07:19 lr 0.000021	 wd 0.0000	time 0.2089 (0.2584)	loss 1.3648 (1.3504)	grad_norm 0.4583 (0.5281)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:39:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:48 lr 0.000021	 wd 0.0000	time 0.2439 (0.2552)	loss 1.5967 (1.3518)	grad_norm 0.5404 (0.5266)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:39:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:19 lr 0.000020	 wd 0.0000	time 0.2003 (0.2527)	loss 1.5266 (1.3503)	grad_norm 0.4928 (0.5246)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:39:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:53 lr 0.000020	 wd 0.0000	time 0.2042 (0.2520)	loss 1.1034 (1.3508)	grad_norm 0.4399 (0.5240)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:40:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:28 lr 0.000020	 wd 0.0000	time 0.2029 (0.2522)	loss 1.5860 (1.3527)	grad_norm 0.4509 (0.5227)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:40:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:05:01 lr 0.000020	 wd 0.0000	time 0.2473 (0.2507)	loss 1.1633 (1.3527)	grad_norm 0.5348 (0.5212)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:41:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:34 lr 0.000020	 wd 0.0000	time 0.2228 (0.2492)	loss 1.4827 (1.3535)	grad_norm 0.5191 (0.5212)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:41:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:04:09 lr 0.000020	 wd 0.0000	time 0.2554 (0.2489)	loss 1.3936 (1.3543)	grad_norm 0.5043 (0.5212)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:41:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:45 lr 0.000020	 wd 0.0000	time 0.2394 (0.2496)	loss 1.5461 (1.3555)	grad_norm 0.4400 (0.5210)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:42:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:19 lr 0.000020	 wd 0.0000	time 0.2189 (0.2487)	loss 1.5724 (1.3574)	grad_norm 0.5469 (0.5207)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:42:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:54 lr 0.000020	 wd 0.0000	time 0.2421 (0.2479)	loss 1.2939 (1.3582)	grad_norm 0.6104 (0.5206)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:43:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:29 lr 0.000020	 wd 0.0000	time 0.2326 (0.2479)	loss 1.1506 (1.3590)	grad_norm 0.4792 (0.5201)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:43:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:02:04 lr 0.000019	 wd 0.0000	time 0.2191 (0.2484)	loss 1.5513 (1.3569)	grad_norm 0.5094 (0.5191)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 01:43:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:39 lr 0.000019	 wd 0.0000	time 0.2421 (0.2477)	loss 1.4349 (1.3566)	grad_norm 0.4893 (0.5185)	loss_scale 4096.0000 (2092.8396)	mem 7984MB
[2024-07-13 01:44:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:14 lr 0.000019	 wd 0.0000	time 0.2326 (0.2471)	loss 1.3324 (1.3578)	grad_norm 0.4732 (0.5180)	loss_scale 4096.0000 (2183.8510)	mem 7984MB
[2024-07-13 01:44:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:49 lr 0.000019	 wd 0.0000	time 0.2135 (0.2470)	loss 1.4554 (1.3571)	grad_norm 0.5968 (0.5200)	loss_scale 4096.0000 (2266.9518)	mem 7984MB
[2024-07-13 01:45:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:25 lr 0.000019	 wd 0.0000	time 0.2304 (0.2472)	loss 1.4512 (1.3558)	grad_norm 0.6697 (0.5194)	loss_scale 4096.0000 (2343.1304)	mem 7984MB
[2024-07-13 01:45:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000019	 wd 0.0000	time 0.1941 (0.2456)	loss 1.4923 (1.3564)	grad_norm 0.4670 (0.5193)	loss_scale 4096.0000 (2413.2171)	mem 7984MB
[2024-07-13 01:45:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 17 training takes 0:10:18
[2024-07-13 01:45:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 18.577 (18.577)	Loss 0.4138 (0.4138)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 01:46:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.204 Acc@5 97.262
[2024-07-13 01:46:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-13 01:46:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.20%
[2024-07-13 01:46:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/ckpt_epoch_best.pth saving......
[2024-07-13 01:46:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/ckpt_epoch_best.pth saved !!!
[2024-07-13 01:46:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][0/2502]	eta 22:23:34 lr 0.000019	 wd 0.0000	time 32.2202 (32.2202)	loss 1.5988 (1.5988)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:47:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:21:50 lr 0.000019	 wd 0.0000	time 0.2293 (0.5455)	loss 1.5529 (1.3959)	grad_norm 0.4977 (0.5057)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:47:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:14:47 lr 0.000019	 wd 0.0000	time 0.2001 (0.3855)	loss 1.4696 (1.3768)	grad_norm 0.4735 (0.5115)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:47:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:12:20 lr 0.000019	 wd 0.0000	time 0.2820 (0.3361)	loss 1.7061 (1.3762)	grad_norm 0.6966 (0.5133)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:48:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:11:03 lr 0.000019	 wd 0.0000	time 0.2355 (0.3155)	loss 1.4516 (1.3693)	grad_norm 0.4963 (0.5146)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:48:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:09:56 lr 0.000018	 wd 0.0000	time 0.2169 (0.2981)	loss 1.3088 (1.3588)	grad_norm 0.5506 (0.5175)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:48:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:09:05 lr 0.000018	 wd 0.0000	time 0.2302 (0.2867)	loss 1.6276 (1.3595)	grad_norm 0.4272 (0.5169)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:49:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:08:23 lr 0.000018	 wd 0.0000	time 0.2273 (0.2793)	loss 1.4374 (1.3598)	grad_norm 0.4981 (0.5205)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:49:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:50 lr 0.000018	 wd 0.0000	time 0.2283 (0.2764)	loss 1.0911 (1.3572)	grad_norm 0.4916 (0.5286)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:50:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:07:15 lr 0.000018	 wd 0.0000	time 0.2312 (0.2716)	loss 1.1728 (1.3535)	grad_norm 0.5238 (0.5257)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:50:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:41 lr 0.000018	 wd 0.0000	time 0.2207 (0.2676)	loss 1.0333 (1.3570)	grad_norm 0.5474 (0.5247)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:50:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:06:10 lr 0.000018	 wd 0.0000	time 0.2414 (0.2645)	loss 1.2518 (1.3566)	grad_norm 0.4743 (0.5239)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:51:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:44 lr 0.000018	 wd 0.0000	time 0.2530 (0.2645)	loss 1.6520 (1.3569)	grad_norm 0.5140 (0.5227)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:51:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:05:15 lr 0.000018	 wd 0.0000	time 0.2208 (0.2625)	loss 1.4020 (1.3575)	grad_norm 0.4817 (0.5289)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:52:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:46 lr 0.000018	 wd 0.0000	time 0.2468 (0.2602)	loss 1.2111 (1.3573)	grad_norm 0.8027 (0.5287)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:52:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:04:18 lr 0.000017	 wd 0.0000	time 0.2223 (0.2582)	loss 1.5958 (1.3565)	grad_norm 0.4694 (0.5280)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:52:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:52 lr 0.000017	 wd 0.0000	time 0.3150 (0.2581)	loss 1.4781 (1.3559)	grad_norm 0.7740 (0.5266)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:53:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:26 lr 0.000017	 wd 0.0000	time 0.2106 (0.2573)	loss 1.4749 (1.3562)	grad_norm 0.5481 (0.5257)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:53:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:59 lr 0.000017	 wd 0.0000	time 0.2144 (0.2561)	loss 1.3104 (1.3570)	grad_norm 0.4794 (0.5251)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:54:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:33 lr 0.000017	 wd 0.0000	time 0.2562 (0.2551)	loss 1.4673 (1.3562)	grad_norm 0.4604 (0.5244)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:54:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:02:08 lr 0.000017	 wd 0.0000	time 0.1964 (0.2555)	loss 1.3732 (1.3584)	grad_norm 0.4466 (0.5238)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:55:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:42 lr 0.000017	 wd 0.0000	time 0.2081 (0.2544)	loss 1.4427 (1.3577)	grad_norm 0.5089 (0.5232)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:55:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:16 lr 0.000017	 wd 0.0000	time 0.2335 (0.2535)	loss 1.3461 (1.3578)	grad_norm 0.4566 (0.5228)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:55:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:51 lr 0.000017	 wd 0.0000	time 0.2256 (0.2527)	loss 1.4981 (1.3581)	grad_norm 0.5158 (0.5230)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:56:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:25 lr 0.000017	 wd 0.0000	time 0.2235 (0.2528)	loss 1.4998 (1.3595)	grad_norm 0.5386 (0.5231)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:56:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1797 (0.2510)	loss 1.4926 (1.3590)	grad_norm 0.4594 (0.5253)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:56:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 18 training takes 0:10:33
[2024-07-13 01:56:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 19.785 (19.785)	Loss 0.4131 (0.4131)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 01:57:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.204 Acc@5 97.284
[2024-07-13 01:57:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-13 01:57:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.20%
[2024-07-13 01:57:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][0/2502]	eta 14:36:58 lr 0.000016	 wd 0.0000	time 21.0304 (21.0304)	loss 1.4268 (1.4268)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:57:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:18:39 lr 0.000016	 wd 0.0000	time 0.2077 (0.4660)	loss 1.0934 (1.3708)	grad_norm 0.4842 (0.5020)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:58:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:13:19 lr 0.000016	 wd 0.0000	time 0.2333 (0.3474)	loss 1.4321 (1.3642)	grad_norm 0.5174 (0.5198)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:58:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:11:16 lr 0.000016	 wd 0.0000	time 0.2210 (0.3072)	loss 1.3076 (1.3767)	grad_norm 0.4640 (0.5151)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:59:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:10:06 lr 0.000016	 wd 0.0000	time 0.2270 (0.2887)	loss 1.5085 (1.3761)	grad_norm 0.4778 (0.5231)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:59:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:09:20 lr 0.000016	 wd 0.0000	time 0.2286 (0.2800)	loss 1.5053 (1.3713)	grad_norm 0.5236 (0.5219)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 01:59:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:37 lr 0.000016	 wd 0.0000	time 0.2275 (0.2722)	loss 1.4753 (1.3662)	grad_norm 0.5194 (0.5258)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:00:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:07:59 lr 0.000016	 wd 0.0000	time 0.2065 (0.2660)	loss 1.6301 (1.3681)	grad_norm 0.6413 (0.5264)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:00:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:07:25 lr 0.000016	 wd 0.0000	time 0.2403 (0.2616)	loss 1.3544 (1.3670)	grad_norm 0.4979 (0.5245)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:01:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:06:58 lr 0.000016	 wd 0.0000	time 0.3329 (0.2613)	loss 1.2307 (1.3665)	grad_norm 0.4553 (0.5261)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:01:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:28 lr 0.000016	 wd 0.0000	time 0.2070 (0.2587)	loss 1.5785 (1.3673)	grad_norm 0.5190 (0.5237)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:01:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:59 lr 0.000015	 wd 0.0000	time 0.2106 (0.2561)	loss 0.9157 (1.3658)	grad_norm 0.4689 (0.5219)	loss_scale 8192.0000 (4282.0127)	mem 7984MB
[2024-07-13 02:02:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:30 lr 0.000015	 wd 0.0000	time 0.2124 (0.2541)	loss 1.1189 (1.3641)	grad_norm 0.5287 (0.5200)	loss_scale 8192.0000 (4607.5737)	mem 7984MB
[2024-07-13 02:02:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:05:05 lr 0.000015	 wd 0.0000	time 0.2183 (0.2541)	loss 1.5709 (1.3645)	grad_norm 0.5687 (0.5185)	loss_scale 8192.0000 (4883.0869)	mem 7984MB
[2024-07-13 02:03:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:38 lr 0.000015	 wd 0.0000	time 0.2117 (0.2527)	loss 1.4573 (1.3654)	grad_norm 0.5097 (0.5186)	loss_scale 8192.0000 (5119.2691)	mem 7984MB
[2024-07-13 02:03:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:04:11 lr 0.000015	 wd 0.0000	time 0.2103 (0.2513)	loss 1.2099 (1.3651)	grad_norm 0.4323 (0.5188)	loss_scale 8192.0000 (5323.9813)	mem 7984MB
[2024-07-13 02:03:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:45 lr 0.000015	 wd 0.0000	time 0.1920 (0.2501)	loss 1.2984 (1.3653)	grad_norm 0.5568 (0.5202)	loss_scale 8192.0000 (5503.1205)	mem 7984MB
[2024-07-13 02:04:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:20 lr 0.000015	 wd 0.0000	time 0.4335 (0.2505)	loss 1.3973 (1.3661)	grad_norm 1.1144 (0.5225)	loss_scale 8192.0000 (5661.1969)	mem 7984MB
[2024-07-13 02:04:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:56 lr 0.000015	 wd 0.0000	time 0.2076 (0.2509)	loss 1.3285 (1.3655)	grad_norm 0.5575 (0.5226)	loss_scale 8192.0000 (5801.7190)	mem 7984MB
[2024-07-13 02:05:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:30 lr 0.000015	 wd 0.0000	time 0.2059 (0.2501)	loss 1.4105 (1.3659)	grad_norm 0.4430 (0.5228)	loss_scale 8192.0000 (5927.4571)	mem 7984MB
[2024-07-13 02:05:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:02:05 lr 0.000015	 wd 0.0000	time 0.2108 (0.2493)	loss 1.0601 (1.3654)	grad_norm 0.5040 (0.5219)	loss_scale 8192.0000 (6040.6277)	mem 7984MB
[2024-07-13 02:05:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:40 lr 0.000014	 wd 0.0000	time 0.2561 (0.2497)	loss 1.1775 (1.3643)	grad_norm 0.5085 (0.5215)	loss_scale 8192.0000 (6143.0252)	mem 7984MB
[2024-07-13 02:06:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:15 lr 0.000014	 wd 0.0000	time 0.1925 (0.2491)	loss 1.4856 (1.3622)	grad_norm 0.5008 (0.5217)	loss_scale 8192.0000 (6236.1181)	mem 7984MB
[2024-07-13 02:06:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:50 lr 0.000014	 wd 0.0000	time 0.2370 (0.2486)	loss 1.3989 (1.3619)	grad_norm 0.5204 (0.5228)	loss_scale 8192.0000 (6321.1195)	mem 7984MB
[2024-07-13 02:07:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:25 lr 0.000014	 wd 0.0000	time 0.2305 (0.2479)	loss 1.5346 (1.3633)	grad_norm 0.5142 (0.5230)	loss_scale 8192.0000 (6399.0404)	mem 7984MB
[2024-07-13 02:07:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1770 (0.2463)	loss 1.2254 (1.3631)	grad_norm 0.4871 (0.5230)	loss_scale 8192.0000 (6470.7301)	mem 7984MB
[2024-07-13 02:07:49 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 19 training takes 0:10:37
[2024-07-13 02:08:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 69.109 (69.109)	Loss 0.4126 (0.4126)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 02:09:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.242 Acc@5 97.328
[2024-07-13 02:09:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-13 02:09:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.24%
[2024-07-13 02:09:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 160): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/ckpt_epoch_best.pth saving......
[2024-07-13 02:09:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 162): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/ckpt_epoch_best.pth saved !!!
[2024-07-13 02:09:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][0/2502]	eta 10:50:47 lr 0.000014	 wd 0.0000	time 15.6064 (15.6064)	loss 0.9880 (0.9880)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:10:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:15:31 lr 0.000014	 wd 0.0000	time 0.2057 (0.3880)	loss 1.5671 (1.3581)	grad_norm 0.4554 (0.5068)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:10:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:12:08 lr 0.000014	 wd 0.0000	time 0.2431 (0.3166)	loss 1.4227 (1.3597)	grad_norm 0.5062 (0.5049)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:10:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:10:55 lr 0.000014	 wd 0.0000	time 0.2290 (0.2976)	loss 1.4648 (1.3559)	grad_norm 0.5028 (0.5091)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:11:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:09:49 lr 0.000014	 wd 0.0000	time 0.2285 (0.2805)	loss 1.4025 (1.3652)	grad_norm 0.4700 (0.5145)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:11:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:08:59 lr 0.000014	 wd 0.0000	time 0.2070 (0.2694)	loss 1.5390 (1.3675)	grad_norm 0.4801 (0.5161)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:12:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:08:21 lr 0.000014	 wd 0.0000	time 0.2217 (0.2638)	loss 1.3282 (1.3641)	grad_norm 0.4752 (0.5167)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:12:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:56 lr 0.000013	 wd 0.0000	time 0.2160 (0.2647)	loss 1.4752 (1.3664)	grad_norm 0.4938 (0.5177)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:12:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:07:23 lr 0.000013	 wd 0.0000	time 0.2052 (0.2604)	loss 1.2621 (1.3635)	grad_norm 0.4747 (nan)	loss_scale 4096.0000 (7701.0936)	mem 7984MB
[2024-07-13 02:13:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:51 lr 0.000013	 wd 0.0000	time 0.2067 (0.2570)	loss 1.5967 (1.3662)	grad_norm 0.4473 (nan)	loss_scale 4096.0000 (7300.9723)	mem 7984MB
[2024-07-13 02:13:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:22 lr 0.000013	 wd 0.0000	time 0.2476 (0.2549)	loss 1.2920 (1.3653)	grad_norm 0.4457 (nan)	loss_scale 4096.0000 (6980.7952)	mem 7984MB
[2024-07-13 02:14:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:57 lr 0.000013	 wd 0.0000	time 0.2700 (0.2550)	loss 1.3493 (1.3630)	grad_norm 0.4766 (nan)	loss_scale 4096.0000 (6718.7793)	mem 7984MB
[2024-07-13 02:14:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:29 lr 0.000013	 wd 0.0000	time 0.2100 (0.2534)	loss 1.4109 (1.3599)	grad_norm 0.4866 (nan)	loss_scale 4096.0000 (6500.3963)	mem 7984MB
[2024-07-13 02:14:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:05:02 lr 0.000013	 wd 0.0000	time 0.1859 (0.2518)	loss 1.3048 (1.3586)	grad_norm 0.4837 (nan)	loss_scale 4096.0000 (6315.5849)	mem 7984MB
[2024-07-13 02:15:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:36 lr 0.000013	 wd 0.0000	time 0.2552 (0.2505)	loss 1.3882 (1.3602)	grad_norm 0.5069 (nan)	loss_scale 4096.0000 (6157.1563)	mem 7984MB
[2024-07-13 02:15:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:04:11 lr 0.000013	 wd 0.0000	time 0.2157 (0.2511)	loss 1.4371 (1.3607)	grad_norm 0.4818 (nan)	loss_scale 4096.0000 (6019.8374)	mem 7984MB
[2024-07-13 02:16:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:45 lr 0.000013	 wd 0.0000	time 0.2322 (0.2505)	loss 1.6796 (1.3610)	grad_norm 0.5739 (nan)	loss_scale 4096.0000 (5899.6727)	mem 7984MB
[2024-07-13 02:16:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:20 lr 0.000012	 wd 0.0000	time 0.2130 (0.2494)	loss 1.5245 (1.3604)	grad_norm 0.4690 (nan)	loss_scale 4096.0000 (5793.6367)	mem 7984MB
[2024-07-13 02:16:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:54 lr 0.000012	 wd 0.0000	time 0.2028 (0.2486)	loss 1.2988 (1.3596)	grad_norm 0.4627 (nan)	loss_scale 4096.0000 (5699.3759)	mem 7984MB
[2024-07-13 02:17:18 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:30 lr 0.000012	 wd 0.0000	time 0.2308 (0.2492)	loss 1.5291 (1.3616)	grad_norm 0.4407 (nan)	loss_scale 4096.0000 (5615.0321)	mem 7984MB
[2024-07-13 02:17:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:02:04 lr 0.000012	 wd 0.0000	time 0.2161 (0.2487)	loss 1.4903 (1.3612)	grad_norm 0.4889 (nan)	loss_scale 4096.0000 (5539.1184)	mem 7984MB
[2024-07-13 02:18:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:39 lr 0.000012	 wd 0.0000	time 0.2162 (0.2480)	loss 1.3018 (1.3618)	grad_norm 0.4518 (nan)	loss_scale 4096.0000 (5470.4312)	mem 7984MB
[2024-07-13 02:18:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:14 lr 0.000012	 wd 0.0000	time 0.2091 (0.2473)	loss 1.2433 (1.3633)	grad_norm 0.4944 (nan)	loss_scale 4096.0000 (5407.9855)	mem 7984MB
[2024-07-13 02:18:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:49 lr 0.000012	 wd 0.0000	time 0.2318 (0.2475)	loss 1.4035 (1.3633)	grad_norm 0.6202 (nan)	loss_scale 4096.0000 (5350.9674)	mem 7984MB
[2024-07-13 02:19:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:25 lr 0.000012	 wd 0.0000	time 0.2130 (0.2470)	loss 1.3524 (1.3636)	grad_norm 0.5081 (nan)	loss_scale 4096.0000 (5298.6989)	mem 7984MB
[2024-07-13 02:19:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000012	 wd 0.0000	time 0.1699 (0.2454)	loss 1.6112 (1.3643)	grad_norm 0.5062 (nan)	loss_scale 4096.0000 (5250.6102)	mem 7984MB
[2024-07-13 02:19:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 20 training takes 0:10:18
[2024-07-13 02:20:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 19.176 (19.176)	Loss 0.4141 (0.4141)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 02:20:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.172 Acc@5 97.296
[2024-07-13 02:20:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-13 02:20:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.24%
[2024-07-13 02:20:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][0/2502]	eta 21:04:07 lr 0.000012	 wd 0.0000	time 30.3147 (30.3147)	loss 1.5542 (1.5542)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:21:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:20:59 lr 0.000012	 wd 0.0000	time 0.2055 (0.5243)	loss 1.4462 (1.3833)	grad_norm 0.4947 (0.5116)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:21:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:14:25 lr 0.000012	 wd 0.0000	time 0.2199 (0.3760)	loss 0.8879 (1.3644)	grad_norm 0.4909 (0.5441)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:21:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:12:17 lr 0.000012	 wd 0.0000	time 0.2296 (0.3347)	loss 1.4031 (1.3576)	grad_norm 0.5340 (0.5351)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:22:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:10:57 lr 0.000011	 wd 0.0000	time 0.2136 (0.3126)	loss 1.4428 (1.3590)	grad_norm 0.4926 (0.5272)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:22:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:09:51 lr 0.000011	 wd 0.0000	time 0.2161 (0.2954)	loss 1.3512 (1.3583)	grad_norm 0.9226 (0.5261)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:23:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:09:01 lr 0.000011	 wd 0.0000	time 0.1953 (0.2848)	loss 1.1954 (1.3588)	grad_norm 0.4786 (0.5269)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:23:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:08:22 lr 0.000011	 wd 0.0000	time 0.2932 (0.2791)	loss 1.2814 (1.3534)	grad_norm 0.4758 (0.5270)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:23:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:49 lr 0.000011	 wd 0.0000	time 0.2155 (0.2756)	loss 1.2224 (1.3529)	grad_norm 0.4605 (0.5239)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:24:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:07:13 lr 0.000011	 wd 0.0000	time 0.2450 (0.2707)	loss 1.5317 (1.3536)	grad_norm 0.4679 (0.5228)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:24:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:40 lr 0.000011	 wd 0.0000	time 0.2052 (0.2668)	loss 1.0478 (1.3526)	grad_norm 0.4706 (0.5232)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:25:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:06:10 lr 0.000011	 wd 0.0000	time 0.2397 (0.2646)	loss 1.4593 (1.3527)	grad_norm 0.4655 (0.5226)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:25:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:43 lr 0.000011	 wd 0.0000	time 0.2409 (0.2638)	loss 1.3264 (1.3537)	grad_norm 0.4669 (0.5209)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:25:55 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:05:14 lr 0.000011	 wd 0.0000	time 0.2204 (0.2614)	loss 1.5150 (1.3539)	grad_norm 0.4785 (0.5201)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:26:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:45 lr 0.000011	 wd 0.0000	time 0.2074 (0.2593)	loss 1.4292 (1.3543)	grad_norm 0.5583 (0.5199)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:26:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:04:18 lr 0.000010	 wd 0.0000	time 0.2156 (0.2578)	loss 1.6451 (1.3539)	grad_norm 0.4717 (0.5211)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:27:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:52 lr 0.000010	 wd 0.0000	time 0.2269 (0.2579)	loss 1.2145 (1.3534)	grad_norm 0.5377 (0.5225)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:27:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:25 lr 0.000010	 wd 0.0000	time 0.2519 (0.2568)	loss 1.4821 (1.3535)	grad_norm 0.6197 (0.5232)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:27:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:59 lr 0.000010	 wd 0.0000	time 0.2154 (0.2556)	loss 1.0219 (1.3540)	grad_norm 0.5953 (0.5237)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:28:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:33 lr 0.000010	 wd 0.0000	time 0.2164 (0.2548)	loss 0.9982 (1.3527)	grad_norm 0.5036 (0.5243)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:28:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:02:07 lr 0.000010	 wd 0.0000	time 0.2501 (0.2549)	loss 1.3837 (1.3522)	grad_norm 0.5058 (0.5256)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:29:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:42 lr 0.000010	 wd 0.0000	time 0.2203 (0.2540)	loss 1.1891 (1.3524)	grad_norm 0.5707 (0.5257)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:29:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:16 lr 0.000010	 wd 0.0000	time 0.1889 (0.2531)	loss 1.5560 (1.3504)	grad_norm 0.4380 (0.5258)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 02:29:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:50 lr 0.000010	 wd 0.0000	time 0.2527 (0.2525)	loss 1.5668 (1.3501)	grad_norm 0.5166 (0.5257)	loss_scale 8192.0000 (4270.4494)	mem 7984MB
[2024-07-13 02:30:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:25 lr 0.000010	 wd 0.0000	time 0.2252 (0.2528)	loss 1.3815 (1.3515)	grad_norm 0.4701 (0.5253)	loss_scale 8192.0000 (4433.7793)	mem 7984MB
[2024-07-13 02:30:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1903 (0.2509)	loss 1.3138 (1.3512)	grad_norm 0.5473 (0.5247)	loss_scale 8192.0000 (4584.0480)	mem 7984MB
[2024-07-13 02:30:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 21 training takes 0:10:32
[2024-07-13 02:31:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 19.335 (19.335)	Loss 0.4116 (0.4116)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 02:31:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.204 Acc@5 97.306
[2024-07-13 02:31:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-13 02:31:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.24%
[2024-07-13 02:32:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][0/2502]	eta 1 day, 10:54:15 lr 0.000010	 wd 0.0000	time 50.2222 (50.2222)	loss 1.3086 (1.3086)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:32:41 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:31:40 lr 0.000010	 wd 0.0000	time 0.3006 (0.7913)	loss 1.2588 (1.3615)	grad_norm 0.5306 (0.5261)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:33:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:20:29 lr 0.000009	 wd 0.0000	time 0.2333 (0.5340)	loss 1.1812 (1.3583)	grad_norm 0.6417 (0.5150)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:34:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:20:22 lr 0.000009	 wd 0.0000	time 0.3094 (0.5553)	loss 1.5110 (1.3626)	grad_norm 0.6148 (0.5205)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:34:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:17:31 lr 0.000009	 wd 0.0000	time 0.2199 (0.5004)	loss 1.4301 (1.3665)	grad_norm 0.7837 (0.5287)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:35:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:15:37 lr 0.000009	 wd 0.0000	time 0.1990 (0.4684)	loss 0.8974 (1.3658)	grad_norm 0.5008 (0.5311)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:35:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:13:35 lr 0.000009	 wd 0.0000	time 0.2147 (0.4288)	loss 1.3656 (1.3688)	grad_norm 0.5778 (0.5304)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:36:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:12:02 lr 0.000009	 wd 0.0000	time 0.2159 (0.4007)	loss 0.8984 (1.3643)	grad_norm 0.5166 (0.5280)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:36:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:10:48 lr 0.000009	 wd 0.0000	time 0.2580 (0.3808)	loss 1.3713 (1.3602)	grad_norm 0.4924 (0.5365)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:36:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:09:48 lr 0.000009	 wd 0.0000	time 0.2145 (0.3671)	loss 1.3407 (1.3593)	grad_norm 0.5133 (0.5360)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:37:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:08:51 lr 0.000009	 wd 0.0000	time 0.2004 (0.3538)	loss 1.5515 (1.3614)	grad_norm 0.5002 (0.5362)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:37:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:08:00 lr 0.000009	 wd 0.0000	time 0.2076 (0.3426)	loss 1.4059 (1.3589)	grad_norm 0.4909 (0.5380)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:38:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:07:14 lr 0.000009	 wd 0.0000	time 0.2169 (0.3338)	loss 1.3393 (1.3577)	grad_norm 0.4800 (0.5354)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:38:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:06:33 lr 0.000009	 wd 0.0000	time 0.2419 (0.3277)	loss 0.9348 (1.3583)	grad_norm 0.4890 (0.5343)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:38:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:05:53 lr 0.000008	 wd 0.0000	time 0.2046 (0.3210)	loss 1.5620 (1.3603)	grad_norm 0.5316 (0.5348)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:39:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:05:15 lr 0.000008	 wd 0.0000	time 0.1896 (0.3151)	loss 1.3193 (1.3610)	grad_norm 0.5205 (0.5345)	loss_scale 8192.0000 (8192.0000)	mem 7984MB
[2024-07-13 02:39:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:04:39 lr 0.000008	 wd 0.0000	time 0.2501 (0.3102)	loss 1.5426 (1.3613)	grad_norm 0.5137 (inf)	loss_scale 4096.0000 (8018.0287)	mem 7984MB
[2024-07-13 02:40:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:04:06 lr 0.000008	 wd 0.0000	time 0.2133 (0.3076)	loss 1.3094 (1.3609)	grad_norm 0.5096 (inf)	loss_scale 4096.0000 (7787.4568)	mem 7984MB
[2024-07-13 02:40:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:03:33 lr 0.000008	 wd 0.0000	time 0.2437 (0.3037)	loss 1.5852 (1.3603)	grad_norm 0.5684 (inf)	loss_scale 4096.0000 (7582.4897)	mem 7984MB
[2024-07-13 02:40:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:03:00 lr 0.000008	 wd 0.0000	time 0.2261 (0.3001)	loss 1.5381 (1.3597)	grad_norm 0.5421 (inf)	loss_scale 4096.0000 (7399.0868)	mem 7984MB
[2024-07-13 02:41:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:02:29 lr 0.000008	 wd 0.0000	time 0.2197 (0.2970)	loss 1.5103 (1.3588)	grad_norm 0.4382 (inf)	loss_scale 4096.0000 (7234.0150)	mem 7984MB
[2024-07-13 02:41:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:58 lr 0.000008	 wd 0.0000	time 0.1990 (0.2948)	loss 1.4253 (1.3594)	grad_norm 0.5330 (inf)	loss_scale 4096.0000 (7084.6568)	mem 7984MB
[2024-07-13 02:42:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:28 lr 0.000008	 wd 0.0000	time 0.2353 (0.2921)	loss 1.4353 (1.3576)	grad_norm 0.5257 (inf)	loss_scale 4096.0000 (6948.8705)	mem 7984MB
[2024-07-13 02:42:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:58 lr 0.000008	 wd 0.0000	time 0.2223 (0.2897)	loss 1.4997 (1.3577)	grad_norm 0.6450 (inf)	loss_scale 4096.0000 (6824.8866)	mem 7984MB
[2024-07-13 02:42:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:29 lr 0.000008	 wd 0.0000	time 0.2407 (0.2875)	loss 1.2037 (1.3570)	grad_norm 0.4727 (nan)	loss_scale 2048.0000 (6668.5814)	mem 7984MB
[2024-07-13 02:43:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1703 (0.2846)	loss 0.9882 (1.3561)	grad_norm 0.4576 (nan)	loss_scale 2048.0000 (6483.8321)	mem 7984MB
[2024-07-13 02:43:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 22 training takes 0:12:04
[2024-07-13 02:43:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 24.382 (24.382)	Loss 0.4119 (0.4119)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 02:44:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.210 Acc@5 97.310
[2024-07-13 02:44:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-13 02:44:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.24%
[2024-07-13 02:44:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][0/2502]	eta 10:52:09 lr 0.000008	 wd 0.0000	time 15.6394 (15.6394)	loss 1.1628 (1.1628)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:44:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:16:41 lr 0.000008	 wd 0.0000	time 0.2171 (0.4168)	loss 1.5648 (1.3933)	grad_norm 0.4777 (0.5397)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:45:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:12:28 lr 0.000007	 wd 0.0000	time 0.2040 (0.3254)	loss 1.5405 (1.3725)	grad_norm 0.4971 (0.5387)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:45:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:10:45 lr 0.000007	 wd 0.0000	time 0.2164 (0.2931)	loss 1.5091 (1.3657)	grad_norm 0.5054 (0.5280)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:45:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:09:40 lr 0.000007	 wd 0.0000	time 0.2152 (0.2760)	loss 1.5255 (1.3571)	grad_norm 0.6218 (0.5354)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:46:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:09:01 lr 0.000007	 wd 0.0000	time 0.2546 (0.2706)	loss 1.6881 (1.3619)	grad_norm 0.5457 (0.5316)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:46:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:08:26 lr 0.000007	 wd 0.0000	time 0.2117 (0.2663)	loss 1.1325 (1.3617)	grad_norm 0.8504 (0.5327)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:47:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:50 lr 0.000007	 wd 0.0000	time 0.2441 (0.2609)	loss 1.4157 (1.3589)	grad_norm 0.4869 (0.5308)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:47:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:07:16 lr 0.000007	 wd 0.0000	time 0.2132 (0.2567)	loss 1.6890 (1.3578)	grad_norm 0.4505 (0.5291)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:47:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:06:50 lr 0.000007	 wd 0.0000	time 0.2463 (0.2560)	loss 1.7058 (1.3544)	grad_norm 0.8963 (0.5284)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:48:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:24 lr 0.000007	 wd 0.0000	time 0.2440 (0.2560)	loss 1.1523 (1.3524)	grad_norm 0.4837 (0.5277)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:48:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:55 lr 0.000007	 wd 0.0000	time 0.1941 (0.2537)	loss 0.8807 (1.3481)	grad_norm 0.5061 (0.5296)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:49:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:27 lr 0.000007	 wd 0.0000	time 0.2241 (0.2518)	loss 1.5632 (1.3499)	grad_norm 0.4939 (0.5278)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:49:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:05:02 lr 0.000007	 wd 0.0000	time 0.2880 (0.2517)	loss 1.4451 (1.3513)	grad_norm 0.4800 (0.5299)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:49:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:37 lr 0.000007	 wd 0.0000	time 0.1987 (0.2519)	loss 1.5823 (1.3512)	grad_norm 0.5009 (0.5282)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:50:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:04:11 lr 0.000006	 wd 0.0000	time 0.2271 (0.2507)	loss 1.2713 (1.3535)	grad_norm 0.5059 (0.5293)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:50:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:45 lr 0.000006	 wd 0.0000	time 0.2298 (0.2495)	loss 1.1749 (1.3528)	grad_norm 0.4982 (0.5296)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:51:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:20 lr 0.000006	 wd 0.0000	time 0.2390 (0.2494)	loss 1.3117 (1.3531)	grad_norm 0.4827 (0.5305)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:51:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:55 lr 0.000006	 wd 0.0000	time 0.2683 (0.2504)	loss 1.4291 (1.3526)	grad_norm 0.5169 (0.5304)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:52:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:30 lr 0.000006	 wd 0.0000	time 0.2287 (0.2496)	loss 1.2361 (1.3552)	grad_norm 0.5292 (0.5302)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:52:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:02:04 lr 0.000006	 wd 0.0000	time 0.2354 (0.2487)	loss 1.4503 (1.3540)	grad_norm 0.5265 (0.5306)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:52:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:39 lr 0.000006	 wd 0.0000	time 0.2454 (0.2486)	loss 1.7006 (1.3544)	grad_norm 0.4662 (0.5292)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:53:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:15 lr 0.000006	 wd 0.0000	time 0.2397 (0.2486)	loss 1.4637 (1.3523)	grad_norm 0.5004 (0.5292)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:53:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:50 lr 0.000006	 wd 0.0000	time 0.2384 (0.2480)	loss 1.5860 (1.3524)	grad_norm 0.5566 (0.5290)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:53:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:25 lr 0.000006	 wd 0.0000	time 0.2362 (0.2473)	loss 1.5376 (1.3530)	grad_norm 0.5919 (0.5290)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:54:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000006	 wd 0.0000	time 0.1855 (0.2456)	loss 1.4324 (1.3537)	grad_norm 0.4780 (0.5281)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:54:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 23 training takes 0:10:20
[2024-07-13 02:54:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 33.392 (33.392)	Loss 0.4121 (0.4121)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 02:55:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.204 Acc@5 97.310
[2024-07-13 02:55:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-13 02:55:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.24%
[2024-07-13 02:55:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][0/2502]	eta 11:22:10 lr 0.000006	 wd 0.0000	time 16.3593 (16.3593)	loss 1.5824 (1.5824)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:55:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:16:21 lr 0.000006	 wd 0.0000	time 0.2467 (0.4087)	loss 1.1464 (1.3929)	grad_norm 0.5410 (0.5208)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:56:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:12:34 lr 0.000006	 wd 0.0000	time 0.2095 (0.3279)	loss 1.4063 (1.3748)	grad_norm 0.5039 (0.5361)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:56:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:10:48 lr 0.000006	 wd 0.0000	time 0.2091 (0.2944)	loss 1.6215 (1.3681)	grad_norm 0.5652 (0.5375)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 02:57:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:09:43 lr 0.000005	 wd 0.0000	time 0.1908 (0.2774)	loss 1.4035 (1.3646)	grad_norm 0.5116 (nan)	loss_scale 1024.0000 (1869.2469)	mem 7984MB
[2024-07-13 02:57:31 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:08:58 lr 0.000005	 wd 0.0000	time 0.2336 (0.2688)	loss 1.6583 (1.3659)	grad_norm 0.4794 (nan)	loss_scale 1024.0000 (1700.5349)	mem 7984MB
[2024-07-13 02:57:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:08:26 lr 0.000005	 wd 0.0000	time 0.2266 (0.2665)	loss 1.3938 (1.3630)	grad_norm 0.5215 (nan)	loss_scale 1024.0000 (1587.9667)	mem 7984MB
[2024-07-13 02:58:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:07:50 lr 0.000005	 wd 0.0000	time 0.2263 (0.2611)	loss 1.3472 (1.3640)	grad_norm 0.5644 (nan)	loss_scale 1024.0000 (1507.5150)	mem 7984MB
[2024-07-13 02:58:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:07:17 lr 0.000005	 wd 0.0000	time 0.1936 (0.2572)	loss 1.4086 (1.3650)	grad_norm 0.5360 (nan)	loss_scale 1024.0000 (1447.1511)	mem 7984MB
[2024-07-13 02:59:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:06:48 lr 0.000005	 wd 0.0000	time 0.2485 (0.2552)	loss 1.5524 (1.3620)	grad_norm 0.5082 (nan)	loss_scale 1024.0000 (1400.1865)	mem 7984MB
[2024-07-13 02:59:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:24 lr 0.000005	 wd 0.0000	time 0.1905 (0.2560)	loss 1.2168 (1.3623)	grad_norm 0.8639 (nan)	loss_scale 1024.0000 (1362.6054)	mem 7984MB
[2024-07-13 02:59:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:05:56 lr 0.000005	 wd 0.0000	time 0.1752 (0.2540)	loss 1.4961 (1.3612)	grad_norm 0.5174 (nan)	loss_scale 1024.0000 (1331.8510)	mem 7984MB
[2024-07-13 03:00:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:28 lr 0.000005	 wd 0.0000	time 0.2110 (0.2522)	loss 1.2528 (1.3594)	grad_norm 0.5650 (nan)	loss_scale 1024.0000 (1306.2182)	mem 7984MB
[2024-07-13 03:00:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:05:01 lr 0.000005	 wd 0.0000	time 0.2404 (0.2510)	loss 1.3948 (1.3587)	grad_norm 0.5111 (nan)	loss_scale 1024.0000 (1284.5257)	mem 7984MB
[2024-07-13 03:01:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:37 lr 0.000005	 wd 0.0000	time 0.2324 (0.2516)	loss 1.3465 (1.3572)	grad_norm 0.5108 (nan)	loss_scale 1024.0000 (1265.9300)	mem 7984MB
[2024-07-13 03:01:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:10 lr 0.000005	 wd 0.0000	time 0.2279 (0.2503)	loss 0.9712 (1.3555)	grad_norm 0.4842 (nan)	loss_scale 1024.0000 (1249.8121)	mem 7984MB
[2024-07-13 03:01:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:44 lr 0.000005	 wd 0.0000	time 0.2144 (0.2492)	loss 1.5057 (1.3552)	grad_norm 0.5405 (nan)	loss_scale 1024.0000 (1235.7077)	mem 7984MB
[2024-07-13 03:02:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:19 lr 0.000005	 wd 0.0000	time 0.2592 (0.2484)	loss 1.6850 (1.3564)	grad_norm 0.4707 (nan)	loss_scale 1024.0000 (1223.2616)	mem 7984MB
[2024-07-13 03:02:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:55 lr 0.000005	 wd 0.0000	time 0.2125 (0.2498)	loss 1.1316 (1.3543)	grad_norm 0.4716 (nan)	loss_scale 1024.0000 (1212.1977)	mem 7984MB
[2024-07-13 03:03:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:30 lr 0.000005	 wd 0.0000	time 0.2125 (0.2493)	loss 1.4078 (1.3554)	grad_norm 0.4597 (nan)	loss_scale 1024.0000 (1202.2977)	mem 7984MB
[2024-07-13 03:03:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:02:04 lr 0.000004	 wd 0.0000	time 0.2063 (0.2484)	loss 1.3786 (1.3560)	grad_norm 0.4988 (nan)	loss_scale 1024.0000 (1193.3873)	mem 7984MB
[2024-07-13 03:03:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:39 lr 0.000004	 wd 0.0000	time 0.2197 (0.2480)	loss 1.5361 (1.3552)	grad_norm 0.5581 (nan)	loss_scale 1024.0000 (1185.3251)	mem 7984MB
[2024-07-13 03:04:24 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:15 lr 0.000004	 wd 0.0000	time 0.2689 (0.2486)	loss 1.4019 (1.3550)	grad_norm 0.5854 (nan)	loss_scale 1024.0000 (1177.9955)	mem 7984MB
[2024-07-13 03:04:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:50 lr 0.000004	 wd 0.0000	time 0.2465 (0.2481)	loss 1.7348 (1.3546)	grad_norm 0.5582 (nan)	loss_scale 1024.0000 (1171.3029)	mem 7984MB
[2024-07-13 03:05:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:25 lr 0.000004	 wd 0.0000	time 0.2290 (0.2475)	loss 1.5009 (1.3545)	grad_norm 0.4500 (nan)	loss_scale 1024.0000 (1165.1678)	mem 7984MB
[2024-07-13 03:05:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000004	 wd 0.0000	time 0.1799 (0.2460)	loss 1.2622 (1.3547)	grad_norm 0.5059 (nan)	loss_scale 1024.0000 (1159.5234)	mem 7984MB
[2024-07-13 03:05:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 24 training takes 0:10:23
[2024-07-13 03:06:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 39.174 (39.174)	Loss 0.4121 (0.4121)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 03:06:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.194 Acc@5 97.306
[2024-07-13 03:06:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-13 03:06:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.24%
[2024-07-13 03:06:54 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][0/2502]	eta 11:07:22 lr 0.000004	 wd 0.0000	time 16.0041 (16.0041)	loss 1.2539 (1.2539)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:07:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:16:47 lr 0.000004	 wd 0.0000	time 0.2379 (0.4196)	loss 1.3863 (1.3232)	grad_norm 0.4602 (0.4967)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:07:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:13:23 lr 0.000004	 wd 0.0000	time 0.2125 (0.3490)	loss 1.4841 (1.3505)	grad_norm 0.6150 (0.5052)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:08:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:11:19 lr 0.000004	 wd 0.0000	time 0.1976 (0.3085)	loss 1.1167 (1.3403)	grad_norm 0.4492 (0.5171)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:08:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:10:04 lr 0.000004	 wd 0.0000	time 0.2004 (0.2877)	loss 1.2491 (1.3555)	grad_norm 0.5284 (0.5185)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:08:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:09:17 lr 0.000004	 wd 0.0000	time 0.2298 (0.2786)	loss 1.5473 (1.3556)	grad_norm 0.5334 (0.5198)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:09:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:39 lr 0.000004	 wd 0.0000	time 0.2216 (0.2731)	loss 1.1411 (1.3572)	grad_norm 0.4823 (0.5189)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:09:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:08:00 lr 0.000004	 wd 0.0000	time 0.2101 (0.2669)	loss 1.2350 (1.3577)	grad_norm 0.4895 (0.5219)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:10:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:07:25 lr 0.000004	 wd 0.0000	time 0.2285 (0.2620)	loss 0.9961 (1.3578)	grad_norm 0.4861 (0.5253)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:10:32 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:06:56 lr 0.000004	 wd 0.0000	time 0.2671 (0.2599)	loss 1.5061 (1.3596)	grad_norm 0.5460 (0.5265)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:10:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:29 lr 0.000004	 wd 0.0000	time 0.2016 (0.2591)	loss 1.2332 (1.3602)	grad_norm 0.4697 (0.5290)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:11:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:59 lr 0.000004	 wd 0.0000	time 0.2351 (0.2565)	loss 1.3026 (1.3584)	grad_norm 0.7206 (0.5267)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:11:44 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:31 lr 0.000004	 wd 0.0000	time 0.2289 (0.2543)	loss 1.3508 (1.3608)	grad_norm 0.5250 (0.5258)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:12:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:05:04 lr 0.000003	 wd 0.0000	time 0.2275 (0.2532)	loss 1.4766 (1.3625)	grad_norm 0.4870 (0.5242)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:12:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:38 lr 0.000003	 wd 0.0000	time 0.2164 (0.2531)	loss 1.1208 (1.3620)	grad_norm 0.5867 (0.5245)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:12:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:04:12 lr 0.000003	 wd 0.0000	time 0.2493 (0.2517)	loss 1.2358 (1.3621)	grad_norm 0.4746 (0.5248)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:13:19 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:46 lr 0.000003	 wd 0.0000	time 0.2397 (0.2506)	loss 1.4901 (1.3614)	grad_norm 0.4659 (0.5249)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:13:43 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:20 lr 0.000003	 wd 0.0000	time 0.2314 (0.2499)	loss 1.3755 (1.3607)	grad_norm 0.5227 (0.5248)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:14:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:56 lr 0.000003	 wd 0.0000	time 0.2128 (0.2514)	loss 1.5578 (1.3606)	grad_norm 0.5368 (0.5236)	loss_scale 1024.0000 (1024.0000)	mem 7984MB
[2024-07-13 03:14:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:30 lr 0.000003	 wd 0.0000	time 0.2225 (0.2506)	loss 1.9534 (1.3604)	grad_norm 0.4634 (0.5234)	loss_scale 2048.0000 (1062.7838)	mem 7984MB
[2024-07-13 03:14:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:02:05 lr 0.000003	 wd 0.0000	time 0.2163 (0.2497)	loss 1.2698 (1.3598)	grad_norm 0.4917 (0.5243)	loss_scale 2048.0000 (1112.0200)	mem 7984MB
[2024-07-13 03:15:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:40 lr 0.000003	 wd 0.0000	time 0.2557 (0.2494)	loss 0.8747 (1.3597)	grad_norm 0.5440 (0.5253)	loss_scale 2048.0000 (1156.5693)	mem 7984MB
[2024-07-13 03:15:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:15 lr 0.000003	 wd 0.0000	time 0.2098 (0.2499)	loss 1.4328 (1.3585)	grad_norm 1.5458 (0.5260)	loss_scale 2048.0000 (1197.0704)	mem 7984MB
[2024-07-13 03:16:11 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:50 lr 0.000003	 wd 0.0000	time 0.2351 (0.2492)	loss 1.2006 (1.3572)	grad_norm 0.4888 (0.5276)	loss_scale 2048.0000 (1234.0513)	mem 7984MB
[2024-07-13 03:16:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:25 lr 0.000003	 wd 0.0000	time 0.2120 (0.2485)	loss 1.3965 (1.3587)	grad_norm 0.4893 (0.5285)	loss_scale 2048.0000 (1267.9517)	mem 7984MB
[2024-07-13 03:16:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1862 (0.2470)	loss 1.4815 (1.3588)	grad_norm 0.4925 (0.5271)	loss_scale 2048.0000 (1299.1411)	mem 7984MB
[2024-07-13 03:17:04 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 25 training takes 0:10:26
[2024-07-13 03:17:38 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 33.899 (33.899)	Loss 0.4126 (0.4126)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 03:17:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.202 Acc@5 97.322
[2024-07-13 03:17:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-13 03:17:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.24%
[2024-07-13 03:18:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][0/2502]	eta 10:50:47 lr 0.000003	 wd 0.0000	time 15.6066 (15.6066)	loss 1.3221 (1.3221)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:18:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:17:18 lr 0.000003	 wd 0.0000	time 0.4086 (0.4324)	loss 1.5034 (1.3512)	grad_norm 0.4660 (0.5156)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:19:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:14:02 lr 0.000003	 wd 0.0000	time 0.2206 (0.3659)	loss 1.4759 (1.3718)	grad_norm 0.5008 (0.5172)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:19:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:11:44 lr 0.000003	 wd 0.0000	time 0.2235 (0.3201)	loss 1.4899 (1.3634)	grad_norm 0.4968 (0.5154)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:19:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:10:22 lr 0.000003	 wd 0.0000	time 0.1919 (0.2962)	loss 1.6413 (1.3649)	grad_norm 0.4876 (0.5184)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:20:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:09:34 lr 0.000003	 wd 0.0000	time 0.2196 (0.2870)	loss 1.6198 (1.3716)	grad_norm 0.5177 (0.5178)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:20:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:08:53 lr 0.000003	 wd 0.0000	time 0.2517 (0.2805)	loss 1.4085 (1.3667)	grad_norm 0.5644 (0.5181)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:21:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:08:12 lr 0.000003	 wd 0.0000	time 0.2208 (0.2735)	loss 1.5328 (1.3626)	grad_norm 0.4538 (0.5263)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:21:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:07:36 lr 0.000002	 wd 0.0000	time 0.2062 (0.2679)	loss 1.5992 (1.3614)	grad_norm 0.5407 (0.5263)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:21:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:07:06 lr 0.000002	 wd 0.0000	time 0.2732 (0.2660)	loss 1.3840 (1.3614)	grad_norm 0.4894 (0.5266)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:22:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:37 lr 0.000002	 wd 0.0000	time 0.2231 (0.2644)	loss 1.4100 (1.3619)	grad_norm 0.4932 (0.5244)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:22:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:06:06 lr 0.000002	 wd 0.0000	time 0.2208 (0.2611)	loss 1.5748 (1.3634)	grad_norm 0.4773 (0.5244)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:23:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:36 lr 0.000002	 wd 0.0000	time 0.2187 (0.2587)	loss 1.0812 (1.3638)	grad_norm 0.5211 (0.5234)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:23:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:05:09 lr 0.000002	 wd 0.0000	time 0.2247 (0.2577)	loss 0.9506 (1.3621)	grad_norm 0.5017 (0.5232)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:23:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:43 lr 0.000002	 wd 0.0000	time 0.2254 (0.2573)	loss 1.5980 (1.3615)	grad_norm 0.5399 (0.5235)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:24:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:04:16 lr 0.000002	 wd 0.0000	time 0.2509 (0.2557)	loss 1.3993 (1.3602)	grad_norm 0.4813 (0.5253)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:24:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:49 lr 0.000002	 wd 0.0000	time 0.2065 (0.2540)	loss 1.4490 (1.3592)	grad_norm 0.5697 (0.5241)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:25:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:23 lr 0.000002	 wd 0.0000	time 0.2390 (0.2535)	loss 1.2762 (1.3602)	grad_norm 0.4951 (0.5241)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:25:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:58 lr 0.000002	 wd 0.0000	time 0.2221 (0.2540)	loss 1.5174 (1.3631)	grad_norm 0.4981 (0.5236)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:25:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:32 lr 0.000002	 wd 0.0000	time 0.1901 (0.2530)	loss 0.9756 (1.3616)	grad_norm 0.4897 (0.5230)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:26:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:02:06 lr 0.000002	 wd 0.0000	time 0.2214 (0.2521)	loss 0.9105 (1.3606)	grad_norm 0.6008 (0.5233)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:26:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:41 lr 0.000002	 wd 0.0000	time 0.2378 (0.2519)	loss 1.1269 (1.3595)	grad_norm 0.4868 (0.5235)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:27:14 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:16 lr 0.000002	 wd 0.0000	time 0.2244 (0.2525)	loss 0.9553 (1.3593)	grad_norm 0.5445 (0.5251)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:27:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:50 lr 0.000002	 wd 0.0000	time 0.2405 (0.2517)	loss 1.2033 (1.3581)	grad_norm 0.4776 (0.5245)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:28:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:25 lr 0.000002	 wd 0.0000	time 0.2007 (0.2509)	loss 1.1146 (1.3583)	grad_norm 0.5054 (0.5244)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:28:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1975 (0.2494)	loss 0.9448 (1.3564)	grad_norm 0.4912 (0.5252)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:28:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 26 training takes 0:10:31
[2024-07-13 03:29:01 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 31.261 (31.261)	Loss 0.4124 (0.4124)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 03:29:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.174 Acc@5 97.336
[2024-07-13 03:29:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-13 03:29:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.24%
[2024-07-13 03:29:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][0/2502]	eta 11:21:41 lr 0.000002	 wd 0.0000	time 16.3477 (16.3477)	loss 0.9310 (0.9310)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:30:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:16:39 lr 0.000002	 wd 0.0000	time 0.2627 (0.4160)	loss 1.4909 (1.3626)	grad_norm 0.5659 (0.5343)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:30:27 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:12:41 lr 0.000002	 wd 0.0000	time 0.2052 (0.3309)	loss 1.5743 (1.3576)	grad_norm 0.5055 (0.5299)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:30:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:10:53 lr 0.000002	 wd 0.0000	time 0.2316 (0.2966)	loss 1.3581 (1.3580)	grad_norm 0.4665 (0.5208)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:31:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:09:46 lr 0.000002	 wd 0.0000	time 0.1859 (0.2790)	loss 1.4452 (1.3558)	grad_norm 0.4825 (0.5171)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:31:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:09:03 lr 0.000002	 wd 0.0000	time 0.2741 (0.2717)	loss 0.9802 (1.3516)	grad_norm 0.5714 (0.5139)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:32:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:30 lr 0.000002	 wd 0.0000	time 0.2485 (0.2683)	loss 1.2709 (1.3548)	grad_norm 0.4661 (0.5131)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:32:25 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:53 lr 0.000002	 wd 0.0000	time 0.2019 (0.2626)	loss 1.4747 (1.3606)	grad_norm 0.4979 (0.5166)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:32:48 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:20 lr 0.000002	 wd 0.0000	time 0.2072 (0.2586)	loss 1.5209 (1.3641)	grad_norm 0.4758 (0.5176)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:33:12 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:51 lr 0.000001	 wd 0.0000	time 0.2867 (0.2567)	loss 1.2801 (1.3688)	grad_norm 0.5113 (0.5240)	loss_scale 4096.0000 (2220.7503)	mem 7984MB
[2024-07-13 03:33:37 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:24 lr 0.000001	 wd 0.0000	time 0.2048 (0.2563)	loss 1.4059 (1.3669)	grad_norm 0.5346 (0.5231)	loss_scale 4096.0000 (2408.0879)	mem 7984MB
[2024-07-13 03:34:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:55 lr 0.000001	 wd 0.0000	time 0.2276 (0.2539)	loss 1.5176 (1.3667)	grad_norm 0.4836 (0.5259)	loss_scale 4096.0000 (2561.3951)	mem 7984MB
[2024-07-13 03:34:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:28 lr 0.000001	 wd 0.0000	time 0.2190 (0.2522)	loss 1.4883 (1.3666)	grad_norm 0.5043 (0.5290)	loss_scale 4096.0000 (2689.1724)	mem 7984MB
[2024-07-13 03:34:47 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:05:01 lr 0.000001	 wd 0.0000	time 0.2843 (0.2510)	loss 1.4828 (1.3639)	grad_norm 0.5458 (0.5288)	loss_scale 4096.0000 (2797.3067)	mem 7984MB
[2024-07-13 03:35:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:37 lr 0.000001	 wd 0.0000	time 0.2160 (0.2514)	loss 1.2604 (1.3643)	grad_norm 0.5097 (0.5275)	loss_scale 4096.0000 (2890.0043)	mem 7984MB
[2024-07-13 03:35:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:04:10 lr 0.000001	 wd 0.0000	time 0.2256 (0.2501)	loss 1.5260 (1.3640)	grad_norm 0.4659 (0.5275)	loss_scale 4096.0000 (2970.3504)	mem 7984MB
[2024-07-13 03:35:59 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:44 lr 0.000001	 wd 0.0000	time 0.2138 (0.2489)	loss 1.5568 (1.3619)	grad_norm 0.5569 (0.5260)	loss_scale 4096.0000 (3040.6596)	mem 7984MB
[2024-07-13 03:36:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:19 lr 0.000001	 wd 0.0000	time 0.2220 (0.2483)	loss 1.3907 (1.3598)	grad_norm 0.4821 (0.5270)	loss_scale 4096.0000 (3102.7019)	mem 7984MB
[2024-07-13 03:36:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:55 lr 0.000001	 wd 0.0000	time 0.2345 (0.2493)	loss 1.5069 (1.3603)	grad_norm 0.4763 (0.5266)	loss_scale 4096.0000 (3157.8545)	mem 7984MB
[2024-07-13 03:37:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:29 lr 0.000001	 wd 0.0000	time 0.2049 (0.2485)	loss 1.0869 (1.3618)	grad_norm 0.5837 (0.5254)	loss_scale 4096.0000 (3207.2046)	mem 7984MB
[2024-07-13 03:37:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:02:04 lr 0.000001	 wd 0.0000	time 0.2199 (0.2477)	loss 1.0518 (1.3607)	grad_norm 0.4699 (0.5245)	loss_scale 4096.0000 (3251.6222)	mem 7984MB
[2024-07-13 03:38:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:39 lr 0.000001	 wd 0.0000	time 0.2432 (0.2473)	loss 1.6965 (1.3600)	grad_norm 0.5053 (0.5247)	loss_scale 4096.0000 (3291.8115)	mem 7984MB
[2024-07-13 03:38:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:14 lr 0.000001	 wd 0.0000	time 0.2216 (0.2480)	loss 1.0838 (1.3607)	grad_norm 0.5032 (0.5245)	loss_scale 4096.0000 (3328.3489)	mem 7984MB
[2024-07-13 03:38:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:49 lr 0.000001	 wd 0.0000	time 0.2223 (0.2474)	loss 1.4492 (1.3607)	grad_norm 0.4743 (0.5245)	loss_scale 4096.0000 (3361.7106)	mem 7984MB
[2024-07-13 03:39:13 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:25 lr 0.000001	 wd 0.0000	time 0.2194 (0.2468)	loss 1.3678 (1.3603)	grad_norm 0.4887 (0.5248)	loss_scale 4096.0000 (3392.2932)	mem 7984MB
[2024-07-13 03:39:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1686 (0.2451)	loss 1.4985 (1.3587)	grad_norm 0.4465 (0.5245)	loss_scale 4096.0000 (3420.4302)	mem 7984MB
[2024-07-13 03:39:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 27 training takes 0:10:19
[2024-07-13 03:40:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 37.770 (37.770)	Loss 0.4131 (0.4131)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 03:40:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.168 Acc@5 97.324
[2024-07-13 03:40:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-13 03:40:36 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.24%
[2024-07-13 03:40:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][0/2502]	eta 11:16:00 lr 0.000001	 wd 0.0000	time 16.2114 (16.2114)	loss 1.2764 (1.2764)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 03:41:17 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:16:19 lr 0.000001	 wd 0.0000	time 0.2290 (0.4077)	loss 1.0660 (1.3393)	grad_norm 0.5642 (0.5738)	loss_scale 4096.0000 (4096.0000)	mem 7984MB
[2024-07-13 03:41:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:12:45 lr 0.000001	 wd 0.0000	time 0.2143 (0.3327)	loss 1.0721 (1.3433)	grad_norm 0.4688 (nan)	loss_scale 2048.0000 (3871.8408)	mem 7984MB
[2024-07-13 03:42:05 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:10:57 lr 0.000001	 wd 0.0000	time 0.2411 (0.2985)	loss 1.6402 (1.3533)	grad_norm 0.4637 (nan)	loss_scale 2048.0000 (3265.9136)	mem 7984MB
[2024-07-13 03:42:28 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:09:49 lr 0.000001	 wd 0.0000	time 0.2229 (0.2803)	loss 1.3768 (1.3579)	grad_norm 0.4580 (nan)	loss_scale 2048.0000 (2962.1945)	mem 7984MB
[2024-07-13 03:42:51 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:09:01 lr 0.000001	 wd 0.0000	time 0.2324 (0.2706)	loss 1.5610 (1.3601)	grad_norm 0.4758 (nan)	loss_scale 2048.0000 (2779.7206)	mem 7984MB
[2024-07-13 03:43:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:29 lr 0.000001	 wd 0.0000	time 0.2717 (0.2677)	loss 1.3746 (1.3601)	grad_norm 0.4754 (nan)	loss_scale 2048.0000 (2657.9700)	mem 7984MB
[2024-07-13 03:43:40 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:52 lr 0.000001	 wd 0.0000	time 0.2522 (0.2624)	loss 1.0285 (1.3619)	grad_norm 0.4838 (nan)	loss_scale 2048.0000 (2570.9558)	mem 7984MB
[2024-07-13 03:44:02 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:19 lr 0.000001	 wd 0.0000	time 0.2130 (0.2583)	loss 1.6095 (1.3591)	grad_norm 0.4898 (nan)	loss_scale 2048.0000 (2505.6679)	mem 7984MB
[2024-07-13 03:44:26 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:49 lr 0.000001	 wd 0.0000	time 0.2221 (0.2557)	loss 1.5260 (1.3597)	grad_norm 0.5426 (nan)	loss_scale 2048.0000 (2454.8724)	mem 7984MB
[2024-07-13 03:44:52 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:25 lr 0.000001	 wd 0.0000	time 0.2348 (0.2564)	loss 1.5558 (1.3623)	grad_norm 0.5039 (nan)	loss_scale 2048.0000 (2414.2258)	mem 7984MB
[2024-07-13 03:45:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:57 lr 0.000001	 wd 0.0000	time 0.2319 (0.2548)	loss 0.9402 (1.3588)	grad_norm 0.5132 (nan)	loss_scale 2048.0000 (2380.9628)	mem 7984MB
[2024-07-13 03:45:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:29 lr 0.000001	 wd 0.0000	time 0.2203 (0.2529)	loss 1.2101 (1.3591)	grad_norm 0.5474 (nan)	loss_scale 2048.0000 (2353.2390)	mem 7984MB
[2024-07-13 03:46:03 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:05:02 lr 0.000001	 wd 0.0000	time 0.2378 (0.2514)	loss 1.5559 (1.3560)	grad_norm 0.5124 (nan)	loss_scale 2048.0000 (2329.7771)	mem 7984MB
[2024-07-13 03:46:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:38 lr 0.000001	 wd 0.0000	time 0.2427 (0.2524)	loss 0.9272 (1.3570)	grad_norm 0.4581 (nan)	loss_scale 2048.0000 (2309.6645)	mem 7984MB
[2024-07-13 03:46:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:04:11 lr 0.000001	 wd 0.0000	time 0.2090 (0.2513)	loss 1.4850 (1.3555)	grad_norm 0.5144 (nan)	loss_scale 2048.0000 (2292.2318)	mem 7984MB
[2024-07-13 03:47:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:45 lr 0.000001	 wd 0.0000	time 0.1997 (0.2500)	loss 1.1851 (1.3550)	grad_norm 0.4714 (nan)	loss_scale 2048.0000 (2276.9769)	mem 7984MB
[2024-07-13 03:47:39 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:19 lr 0.000001	 wd 0.0000	time 0.2746 (0.2491)	loss 1.4150 (1.3565)	grad_norm 0.5669 (nan)	loss_scale 2048.0000 (2263.5156)	mem 7984MB
[2024-07-13 03:48:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:55 lr 0.000001	 wd 0.0000	time 0.3365 (0.2499)	loss 1.3751 (1.3562)	grad_norm 0.5704 (nan)	loss_scale 2048.0000 (2251.5491)	mem 7984MB
[2024-07-13 03:48:29 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:30 lr 0.000001	 wd 0.0000	time 0.2204 (0.2492)	loss 1.5401 (1.3551)	grad_norm 0.5975 (nan)	loss_scale 2048.0000 (2240.8417)	mem 7984MB
[2024-07-13 03:48:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:02:04 lr 0.000001	 wd 0.0000	time 0.2616 (0.2484)	loss 0.8843 (1.3551)	grad_norm 0.5545 (nan)	loss_scale 2048.0000 (2231.2044)	mem 7984MB
[2024-07-13 03:49:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:39 lr 0.000001	 wd 0.0000	time 0.2631 (0.2479)	loss 1.0860 (1.3553)	grad_norm 0.4695 (nan)	loss_scale 2048.0000 (2222.4845)	mem 7984MB
[2024-07-13 03:49:42 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:14 lr 0.000001	 wd 0.0000	time 0.3341 (0.2483)	loss 1.5259 (1.3541)	grad_norm 0.4909 (nan)	loss_scale 2048.0000 (2214.5570)	mem 7984MB
[2024-07-13 03:50:06 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:50 lr 0.000001	 wd 0.0000	time 0.1998 (0.2480)	loss 1.0843 (1.3543)	grad_norm 0.5451 (nan)	loss_scale 2048.0000 (2207.3186)	mem 7984MB
[2024-07-13 03:50:30 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:25 lr 0.000001	 wd 0.0000	time 0.2236 (0.2474)	loss 1.5679 (1.3528)	grad_norm 0.6005 (nan)	loss_scale 2048.0000 (2200.6830)	mem 7984MB
[2024-07-13 03:50:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1909 (0.2457)	loss 1.1936 (1.3520)	grad_norm 0.5144 (nan)	loss_scale 2048.0000 (2194.5782)	mem 7984MB
[2024-07-13 03:50:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 28 training takes 0:10:21
[2024-07-13 03:51:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 36.937 (36.937)	Loss 0.4126 (0.4126)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 03:51:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.174 Acc@5 97.316
[2024-07-13 03:51:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-13 03:51:53 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.24%
[2024-07-13 03:52:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][0/2502]	eta 11:24:54 lr 0.000001	 wd 0.0000	time 16.4248 (16.4248)	loss 1.4082 (1.4082)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:52:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:16:01 lr 0.000001	 wd 0.0000	time 0.2673 (0.4003)	loss 1.4546 (1.3339)	grad_norm 0.5092 (0.5138)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:53:00 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:12:40 lr 0.000001	 wd 0.0000	time 0.2134 (0.3305)	loss 1.1517 (1.3484)	grad_norm 0.4959 (0.5180)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:53:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:10:52 lr 0.000001	 wd 0.0000	time 0.2140 (0.2963)	loss 1.4860 (1.3476)	grad_norm 0.5092 (0.5138)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:53:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:09:46 lr 0.000001	 wd 0.0000	time 0.2209 (0.2788)	loss 1.1740 (1.3562)	grad_norm 0.4945 (0.5141)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:54:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:08:58 lr 0.000001	 wd 0.0000	time 0.2270 (0.2689)	loss 0.9445 (1.3577)	grad_norm 0.4987 (0.5298)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:54:35 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:32 lr 0.000000	 wd 0.0000	time 0.1990 (0.2692)	loss 1.3408 (1.3586)	grad_norm 0.4469 (0.5302)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:54:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:55 lr 0.000000	 wd 0.0000	time 0.1975 (0.2639)	loss 1.5718 (1.3593)	grad_norm 0.5980 (0.5281)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:55:21 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:07:21 lr 0.000000	 wd 0.0000	time 0.2452 (0.2597)	loss 0.7901 (1.3603)	grad_norm 0.4682 (0.5302)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:55:45 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:06:50 lr 0.000000	 wd 0.0000	time 0.2430 (0.2565)	loss 1.4175 (1.3601)	grad_norm 0.5505 (0.5293)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:56:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:25 lr 0.000000	 wd 0.0000	time 0.2046 (0.2567)	loss 1.3189 (1.3599)	grad_norm 0.4803 (0.5313)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:56:34 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:57 lr 0.000000	 wd 0.0000	time 0.2056 (0.2548)	loss 1.4593 (1.3604)	grad_norm 0.4505 (0.5301)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:56:57 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:29 lr 0.000000	 wd 0.0000	time 0.2411 (0.2528)	loss 1.2666 (1.3573)	grad_norm 0.5051 (0.5309)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:57:20 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:05:02 lr 0.000000	 wd 0.0000	time 0.2482 (0.2512)	loss 1.5419 (1.3582)	grad_norm 0.6333 (0.5314)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:57:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:36 lr 0.000000	 wd 0.0000	time 0.1993 (0.2513)	loss 1.7615 (1.3570)	grad_norm 0.5354 (0.5302)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:58:09 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:04:10 lr 0.000000	 wd 0.0000	time 0.2087 (0.2505)	loss 1.2916 (1.3584)	grad_norm 0.4880 (0.5302)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:58:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:44 lr 0.000000	 wd 0.0000	time 0.2066 (0.2493)	loss 1.4707 (1.3597)	grad_norm 0.5239 (0.5299)	loss_scale 2048.0000 (2048.0000)	mem 7984MB
[2024-07-13 03:58:56 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:19 lr 0.000000	 wd 0.0000	time 0.2259 (0.2483)	loss 1.2904 (1.3567)	grad_norm 0.4886 (0.5300)	loss_scale 4096.0000 (2076.8959)	mem 7984MB
[2024-07-13 03:59:22 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:54 lr 0.000000	 wd 0.0000	time 0.1903 (0.2491)	loss 1.1584 (1.3582)	grad_norm 0.4929 (0.5294)	loss_scale 4096.0000 (2189.0061)	mem 7984MB
[2024-07-13 03:59:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:29 lr 0.000000	 wd 0.0000	time 0.1902 (0.2486)	loss 1.2276 (1.3580)	grad_norm 0.6188 (0.5285)	loss_scale 4096.0000 (2289.3214)	mem 7984MB
[2024-07-13 04:00:10 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:02:04 lr 0.000000	 wd 0.0000	time 0.2301 (0.2479)	loss 1.4867 (1.3581)	grad_norm 0.5712 (0.5281)	loss_scale 4096.0000 (2379.6102)	mem 7984MB
[2024-07-13 04:00:33 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:39 lr 0.000000	 wd 0.0000	time 0.2342 (0.2472)	loss 1.4951 (1.3586)	grad_norm 0.5304 (0.5278)	loss_scale 4096.0000 (2461.3041)	mem 7984MB
[2024-07-13 04:00:58 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:14 lr 0.000000	 wd 0.0000	time 0.2307 (0.2475)	loss 1.4001 (1.3602)	grad_norm 0.4605 (0.5277)	loss_scale 4096.0000 (2535.5747)	mem 7984MB
[2024-07-13 04:01:23 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:50 lr 0.000000	 wd 0.0000	time 0.2428 (0.2476)	loss 1.4132 (1.3615)	grad_norm 0.5458 (0.5291)	loss_scale 4096.0000 (2603.3898)	mem 7984MB
[2024-07-13 04:01:46 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.2404 (0.2470)	loss 1.4039 (1.3621)	grad_norm 0.5703 (0.5288)	loss_scale 4096.0000 (2665.5560)	mem 7984MB
[2024-07-13 04:02:07 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000000	 wd 0.0000	time 0.1762 (0.2452)	loss 1.5560 (1.3613)	grad_norm 0.5528 (0.5287)	loss_scale 4096.0000 (2722.7509)	mem 7984MB
[2024-07-13 04:02:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 29 training takes 0:10:21
[2024-07-13 04:02:15 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 145): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/ckpt_epoch_29.pth saving......
[2024-07-13 04:02:16 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 147): INFO pretrain/vcnu_finetune/adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_swin_b_22kto1k_step_crosslayer2-full-ft/ckpt_epoch_29.pth saved !!!
[2024-07-13 04:02:50 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 33.562 (33.562)	Loss 0.4126 (0.4126)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7984MB
[2024-07-13 04:03:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 84.186 Acc@5 97.320
[2024-07-13 04:03:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-13 04:03:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 84.24%
[2024-07-13 04:03:08 adapter_swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 189): INFO Training time 5:38:23
