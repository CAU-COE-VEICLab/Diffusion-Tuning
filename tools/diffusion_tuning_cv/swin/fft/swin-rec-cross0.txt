[2024-07-02 10:01:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/config.json
[2024-07-02 10:01:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/swin-b/swin_base_patch4_window7_224_22k.pth
  RESUME: ''
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    FINETUNE_MODE: part0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: swin_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    DEPTHS:
    - 3
    - 3
    - 9
    - 3
    DIMS:
    - 96
    - 192
    - 384
    - 768
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 4.0e-05
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.0e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 4.0e-08
  WEIGHT_DECAY: 1.0e-08

[2024-07-02 10:01:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/swin/diffusion_ft_swin_base_patch4_window7_224_22kto1k_finetune_crosslayer_proces0.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/swin-b/swin_base_patch4_window7_224_22k.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-02 10:01:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 108): INFO Creating model:swin_diffusion_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0
[2024-07-02 10:01:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 110): INFO SwinTransformer_Diffusion_Finetune(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-02 10:01:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 113): INFO number of params: 45780740
[2024-07-02 10:01:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 116): INFO number of GFLOPs: 15.438473216
[2024-07-02 10:01:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 150): INFO no checkpoint found in pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0, ignoring auto resume
[2024-07-02 10:01:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/swin-b/swin_base_patch4_window7_224_22k.pth for fine-tuning......
[2024-07-02 10:01:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 112): INFO loading ImageNet-22K weight to ImageNet-1K ......
[2024-07-02 10:01:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])
[2024-07-02 10:01:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/swin-b/swin_base_patch4_window7_224_22k.pth'
[2024-07-02 10:01:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 18.092 (18.092)	Loss 0.3547 (0.3547)	Acc@1 91.406 (91.406)	Acc@5 98.242 (98.242)	Mem 1569MB
[2024-07-02 10:01:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 82.584 Acc@5 96.560
[2024-07-02 10:01:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 162): INFO Accuracy of the network on the 50000 test images: 82.6%
[2024-07-02 10:01:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 168): INFO Start training
[2024-07-02 10:02:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][0/2502]	eta 15:00:15 lr 0.000000	 wd 0.0000	time 21.5890 (21.5890)	loss 1.8071 (1.8071)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 9671MB
[2024-07-02 10:02:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:18:39 lr 0.000000	 wd 0.0000	time 0.2332 (0.4659)	loss 1.6275 (1.5305)	grad_norm 3.6528 (nan)	loss_scale 2048.0000 (5393.7426)	mem 10200MB
[2024-07-02 10:03:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:13:45 lr 0.000001	 wd 0.0000	time 0.2425 (0.3588)	loss 1.4439 (1.5126)	grad_norm 6.3043 (nan)	loss_scale 2048.0000 (3729.1940)	mem 10200MB
[2024-07-02 10:03:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:11:54 lr 0.000001	 wd 0.0000	time 0.2392 (0.3247)	loss 1.3839 (1.4896)	grad_norm 4.5344 (nan)	loss_scale 2048.0000 (3170.6578)	mem 10200MB
[2024-07-02 10:03:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:52 lr 0.000001	 wd 0.0000	time 0.2451 (0.3104)	loss 1.9930 (1.4883)	grad_norm 5.6335 (nan)	loss_scale 2048.0000 (2890.6933)	mem 10200MB
[2024-07-02 10:04:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:09:58 lr 0.000002	 wd 0.0000	time 0.2424 (0.2991)	loss 1.6715 (1.4852)	grad_norm 8.9753 (nan)	loss_scale 2048.0000 (2722.4910)	mem 10200MB
[2024-07-02 10:04:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:14 lr 0.000002	 wd 0.0000	time 0.2418 (0.2917)	loss 1.0389 (1.4853)	grad_norm 9.9254 (nan)	loss_scale 2048.0000 (2610.2629)	mem 10200MB
[2024-07-02 10:05:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:38 lr 0.000002	 wd 0.0000	time 0.2253 (0.2875)	loss 1.5372 (1.4789)	grad_norm 4.4923 (nan)	loss_scale 2048.0000 (2530.0542)	mem 10200MB
[2024-07-02 10:05:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:08:06 lr 0.000003	 wd 0.0000	time 0.2314 (0.2861)	loss 1.6408 (1.4749)	grad_norm 5.3410 (nan)	loss_scale 1024.0000 (2390.6117)	mem 10200MB
[2024-07-02 10:06:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:32 lr 0.000003	 wd 0.0000	time 0.2585 (0.2825)	loss 1.6676 (1.4656)	grad_norm 3.8585 (nan)	loss_scale 1024.0000 (2238.9345)	mem 10200MB
[2024-07-02 10:06:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:06:59 lr 0.000003	 wd 0.0000	time 0.2319 (0.2793)	loss 1.4292 (1.4615)	grad_norm 5.5082 (nan)	loss_scale 1024.0000 (2117.5624)	mem 10200MB
[2024-07-02 10:06:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:32 lr 0.000004	 wd 0.0000	time 0.2671 (0.2797)	loss 1.5567 (1.4587)	grad_norm 7.9883 (nan)	loss_scale 1024.0000 (2018.2380)	mem 10200MB
[2024-07-02 10:07:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:06:02 lr 0.000004	 wd 0.0000	time 0.2360 (0.2788)	loss 1.3823 (1.4595)	grad_norm 4.2170 (nan)	loss_scale 1024.0000 (1935.4538)	mem 10200MB
[2024-07-02 10:07:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:33 lr 0.000004	 wd 0.0000	time 0.2183 (0.2771)	loss 1.5694 (1.4582)	grad_norm 4.1007 (nan)	loss_scale 1024.0000 (1865.3958)	mem 10200MB
[2024-07-02 10:08:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:05:05 lr 0.000005	 wd 0.0000	time 0.2270 (0.2770)	loss 1.6277 (1.4572)	grad_norm 4.0891 (nan)	loss_scale 1024.0000 (1805.3390)	mem 10200MB
[2024-07-02 10:08:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:39 lr 0.000005	 wd 0.0000	time 0.2353 (0.2794)	loss 1.4434 (1.4543)	grad_norm 3.9157 (nan)	loss_scale 1024.0000 (1753.2845)	mem 10200MB
[2024-07-02 10:09:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:04:10 lr 0.000005	 wd 0.0000	time 0.2358 (0.2781)	loss 1.7785 (1.4532)	grad_norm 4.1643 (nan)	loss_scale 1024.0000 (1707.7327)	mem 10200MB
[2024-07-02 10:09:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:43 lr 0.000005	 wd 0.0000	time 0.2414 (0.2781)	loss 1.6267 (1.4507)	grad_norm 8.5537 (nan)	loss_scale 1024.0000 (1667.5367)	mem 10200MB
[2024-07-02 10:10:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:03:15 lr 0.000006	 wd 0.0000	time 0.2209 (0.2783)	loss 1.2327 (1.4489)	grad_norm 6.7481 (nan)	loss_scale 1024.0000 (1631.8046)	mem 10200MB
[2024-07-02 10:10:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:47 lr 0.000006	 wd 0.0000	time 0.2248 (0.2788)	loss 1.4754 (1.4461)	grad_norm 4.4934 (nan)	loss_scale 1024.0000 (1599.8317)	mem 10200MB
[2024-07-02 10:11:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:19 lr 0.000006	 wd 0.0000	time 0.2451 (0.2774)	loss 1.5913 (1.4422)	grad_norm 4.3323 (nan)	loss_scale 1024.0000 (1571.0545)	mem 10200MB
[2024-07-02 10:11:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:50 lr 0.000007	 wd 0.0000	time 0.2287 (0.2760)	loss 1.4576 (1.4420)	grad_norm 5.4914 (nan)	loss_scale 1024.0000 (1545.0167)	mem 10200MB
[2024-07-02 10:11:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:23 lr 0.000007	 wd 0.0000	time 0.2317 (0.2767)	loss 1.5495 (1.4405)	grad_norm 6.1935 (nan)	loss_scale 1024.0000 (1521.3448)	mem 10200MB
[2024-07-02 10:12:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:55 lr 0.000007	 wd 0.0000	time 0.2494 (0.2769)	loss 1.4524 (1.4380)	grad_norm 5.3419 (nan)	loss_scale 1024.0000 (1499.7306)	mem 10200MB
[2024-07-02 10:12:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:28 lr 0.000008	 wd 0.0000	time 0.2264 (0.2757)	loss 1.5249 (1.4372)	grad_norm 4.5795 (nan)	loss_scale 1024.0000 (1479.9167)	mem 10200MB
[2024-07-02 10:13:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.2212 (0.2744)	loss 1.6154 (1.4364)	grad_norm 3.3922 (nan)	loss_scale 1024.0000 (1461.6873)	mem 10200MB
[2024-07-02 10:13:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 0 training takes 0:11:29
[2024-07-02 10:13:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_0.pth saving......
[2024-07-02 10:13:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_0.pth saved !!!
[2024-07-02 10:13:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 19.691 (19.691)	Loss 0.4404 (0.4404)	Acc@1 91.602 (91.602)	Acc@5 98.242 (98.242)	Mem 10200MB
[2024-07-02 10:13:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 83.302 Acc@5 96.856
[2024-07-02 10:13:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.3%
[2024-07-02 10:13:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 83.30%
[2024-07-02 10:13:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 10:13:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 10:14:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][0/2502]	eta 10:29:29 lr 0.000008	 wd 0.0000	time 15.0957 (15.0957)	loss 1.2547 (1.2547)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 10:14:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:16:35 lr 0.000008	 wd 0.0000	time 0.2894 (0.4144)	loss 1.1966 (1.4352)	grad_norm 5.3791 (5.4440)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 10:14:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:12:44 lr 0.000009	 wd 0.0000	time 0.2194 (0.3322)	loss 1.4581 (1.4390)	grad_norm 4.8606 (5.1834)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 10:15:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:21 lr 0.000009	 wd 0.0000	time 0.2248 (0.3096)	loss 1.7880 (1.4252)	grad_norm 4.4022 (5.0486)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 10:15:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:10:22 lr 0.000009	 wd 0.0000	time 0.2168 (0.2961)	loss 0.9238 (1.4111)	grad_norm 4.1348 (inf)	loss_scale 512.0000 (995.9102)	mem 10200MB
[2024-07-02 10:16:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:09:38 lr 0.000010	 wd 0.0000	time 0.2482 (0.2892)	loss 1.7113 (1.4085)	grad_norm 4.9957 (inf)	loss_scale 512.0000 (899.3214)	mem 10200MB
[2024-07-02 10:16:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:09:01 lr 0.000010	 wd 0.0000	time 0.2934 (0.2849)	loss 1.3876 (1.4046)	grad_norm 8.0102 (inf)	loss_scale 512.0000 (834.8752)	mem 10200MB
[2024-07-02 10:17:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:28 lr 0.000010	 wd 0.0000	time 0.2415 (0.2821)	loss 1.5393 (1.4022)	grad_norm 7.1443 (inf)	loss_scale 512.0000 (788.8160)	mem 10200MB
[2024-07-02 10:17:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:53 lr 0.000011	 wd 0.0000	time 0.2476 (0.2785)	loss 1.5636 (1.4058)	grad_norm 3.7462 (inf)	loss_scale 512.0000 (754.2572)	mem 10200MB
[2024-07-02 10:18:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:21 lr 0.000011	 wd 0.0000	time 0.2294 (0.2757)	loss 1.5729 (1.4038)	grad_norm 5.9541 (inf)	loss_scale 512.0000 (727.3696)	mem 10200MB
[2024-07-02 10:18:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:52 lr 0.000011	 wd 0.0000	time 0.2344 (0.2747)	loss 1.4627 (1.4019)	grad_norm 5.7911 (inf)	loss_scale 512.0000 (705.8541)	mem 10200MB
[2024-07-02 10:18:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:06:22 lr 0.000012	 wd 0.0000	time 0.2174 (0.2731)	loss 1.1497 (1.4022)	grad_norm 3.3090 (inf)	loss_scale 512.0000 (688.2470)	mem 10200MB
[2024-07-02 10:19:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:53 lr 0.000012	 wd 0.0000	time 0.2602 (0.2714)	loss 1.4592 (1.4050)	grad_norm 7.6960 (inf)	loss_scale 512.0000 (673.5720)	mem 10200MB
[2024-07-02 10:19:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:25 lr 0.000012	 wd 0.0000	time 0.2606 (0.2708)	loss 1.5160 (1.4060)	grad_norm 4.4079 (inf)	loss_scale 512.0000 (661.1530)	mem 10200MB
[2024-07-02 10:20:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:57 lr 0.000012	 wd 0.0000	time 0.2332 (0.2704)	loss 1.4848 (1.4037)	grad_norm 3.7337 (inf)	loss_scale 512.0000 (650.5068)	mem 10200MB
[2024-07-02 10:20:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:30 lr 0.000013	 wd 0.0000	time 0.2389 (0.2701)	loss 0.9604 (1.4017)	grad_norm 4.0151 (inf)	loss_scale 512.0000 (641.2791)	mem 10200MB
[2024-07-02 10:21:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:04:02 lr 0.000013	 wd 0.0000	time 0.2264 (0.2691)	loss 1.0039 (1.4005)	grad_norm 8.4493 (inf)	loss_scale 512.0000 (633.2042)	mem 10200MB
[2024-07-02 10:21:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:34 lr 0.000013	 wd 0.0000	time 0.2372 (0.2680)	loss 1.4413 (1.4002)	grad_norm 9.8751 (inf)	loss_scale 512.0000 (626.0788)	mem 10200MB
[2024-07-02 10:21:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:03:08 lr 0.000014	 wd 0.0000	time 0.2258 (0.2682)	loss 1.3871 (1.3994)	grad_norm 4.9478 (inf)	loss_scale 512.0000 (619.7446)	mem 10200MB
[2024-07-02 10:22:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:40 lr 0.000014	 wd 0.0000	time 0.2647 (0.2673)	loss 1.4318 (1.4003)	grad_norm 5.7636 (inf)	loss_scale 512.0000 (614.0768)	mem 10200MB
[2024-07-02 10:22:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:13 lr 0.000014	 wd 0.0000	time 0.2238 (0.2664)	loss 1.4772 (1.3998)	grad_norm 6.3365 (inf)	loss_scale 512.0000 (608.9755)	mem 10200MB
[2024-07-02 10:23:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:46 lr 0.000015	 wd 0.0000	time 0.2254 (0.2654)	loss 1.5705 (1.4007)	grad_norm 3.9045 (inf)	loss_scale 512.0000 (604.3598)	mem 10200MB
[2024-07-02 10:23:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:20 lr 0.000015	 wd 0.0000	time 0.2544 (0.2656)	loss 1.0945 (1.4012)	grad_norm 4.2884 (inf)	loss_scale 512.0000 (600.1636)	mem 10200MB
[2024-07-02 10:24:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:53 lr 0.000015	 wd 0.0000	time 0.2472 (0.2649)	loss 1.3947 (1.4013)	grad_norm 5.1946 (inf)	loss_scale 512.0000 (596.3320)	mem 10200MB
[2024-07-02 10:24:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:26 lr 0.000016	 wd 0.0000	time 0.2380 (0.2643)	loss 1.5699 (1.3994)	grad_norm 3.4607 (inf)	loss_scale 512.0000 (592.8197)	mem 10200MB
[2024-07-02 10:24:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.2276 (0.2635)	loss 1.1281 (1.4008)	grad_norm 4.8395 (inf)	loss_scale 512.0000 (589.5882)	mem 10200MB
[2024-07-02 10:25:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 1 training takes 0:11:13
[2024-07-02 10:25:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 17.066 (17.066)	Loss 0.4380 (0.4380)	Acc@1 91.406 (91.406)	Acc@5 98.242 (98.242)	Mem 10200MB
[2024-07-02 10:25:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 83.566 Acc@5 97.052
[2024-07-02 10:25:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.6%
[2024-07-02 10:25:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 83.57%
[2024-07-02 10:25:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 10:25:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 10:25:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][0/2502]	eta 10:43:46 lr 0.000016	 wd 0.0000	time 15.4382 (15.4382)	loss 1.4682 (1.4682)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:26:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:16:05 lr 0.000016	 wd 0.0000	time 0.2248 (0.4018)	loss 1.5525 (1.3729)	grad_norm 6.2940 (5.5293)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:26:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:12:55 lr 0.000017	 wd 0.0000	time 0.2396 (0.3371)	loss 1.5185 (1.3907)	grad_norm 4.1537 (5.3745)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:27:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:11:20 lr 0.000017	 wd 0.0000	time 0.2372 (0.3091)	loss 1.1672 (1.3930)	grad_norm 3.5046 (5.2894)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:27:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:10:19 lr 0.000017	 wd 0.0000	time 0.2497 (0.2947)	loss 1.5823 (1.3883)	grad_norm 5.6521 (5.1407)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:27:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:09:31 lr 0.000018	 wd 0.0000	time 0.2413 (0.2857)	loss 1.4427 (1.3905)	grad_norm 3.4804 (5.1133)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:28:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:09:09 lr 0.000018	 wd 0.0000	time 0.2837 (0.2887)	loss 1.3019 (1.3844)	grad_norm 5.8365 (5.2956)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:28:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:08:32 lr 0.000018	 wd 0.0000	time 0.2508 (0.2847)	loss 1.2476 (1.3878)	grad_norm 4.8060 (5.3561)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:29:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:57 lr 0.000019	 wd 0.0000	time 0.2299 (0.2808)	loss 1.5975 (1.3859)	grad_norm 4.3234 (5.3069)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:29:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:07:27 lr 0.000019	 wd 0.0000	time 0.2307 (0.2793)	loss 1.5153 (1.3912)	grad_norm 4.5184 (5.2598)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:30:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:58 lr 0.000019	 wd 0.0000	time 0.2375 (0.2784)	loss 1.4872 (1.3929)	grad_norm 4.1594 (5.2395)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:30:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:06:27 lr 0.000020	 wd 0.0000	time 0.2169 (0.2764)	loss 1.2276 (1.3935)	grad_norm 5.3432 (5.4362)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:31:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:57 lr 0.000020	 wd 0.0000	time 0.2428 (0.2745)	loss 1.3200 (1.3924)	grad_norm 5.3967 (5.4083)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:31:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:05:31 lr 0.000020	 wd 0.0000	time 0.2460 (0.2756)	loss 1.6569 (1.3948)	grad_norm 4.4537 (5.4219)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:31:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:05:02 lr 0.000020	 wd 0.0000	time 0.2148 (0.2744)	loss 1.4274 (1.3951)	grad_norm 6.3733 (5.4127)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:32:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:33 lr 0.000021	 wd 0.0000	time 0.2348 (0.2728)	loss 1.5550 (1.3931)	grad_norm 6.5545 (5.4265)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:32:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:04:05 lr 0.000021	 wd 0.0000	time 0.2361 (0.2723)	loss 1.2841 (1.3933)	grad_norm 7.2401 (5.3975)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:33:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:38 lr 0.000021	 wd 0.0000	time 0.2353 (0.2727)	loss 1.3349 (1.3920)	grad_norm 4.1793 (5.4198)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:33:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:03:10 lr 0.000022	 wd 0.0000	time 0.2275 (0.2717)	loss 1.3345 (1.3917)	grad_norm 4.1692 (5.4686)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:34:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:42 lr 0.000022	 wd 0.0000	time 0.2550 (0.2706)	loss 0.9928 (1.3899)	grad_norm 20.9052 (5.4752)	loss_scale 1024.0000 (518.4640)	mem 10200MB
[2024-07-02 10:34:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:02:15 lr 0.000022	 wd 0.0000	time 0.2416 (0.2694)	loss 1.1999 (1.3876)	grad_norm 3.8205 (5.4854)	loss_scale 1024.0000 (543.7281)	mem 10200MB
[2024-07-02 10:35:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:48 lr 0.000023	 wd 0.0000	time 0.2423 (0.2703)	loss 1.4386 (1.3878)	grad_norm 5.2741 (5.4637)	loss_scale 1024.0000 (566.5873)	mem 10200MB
[2024-07-02 10:35:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:21 lr 0.000023	 wd 0.0000	time 0.2342 (0.2694)	loss 1.6330 (1.3874)	grad_norm 4.5363 (5.4564)	loss_scale 1024.0000 (587.3694)	mem 10200MB
[2024-07-02 10:35:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:54 lr 0.000023	 wd 0.0000	time 0.2549 (0.2692)	loss 1.6850 (1.3876)	grad_norm 7.9063 (5.4485)	loss_scale 1024.0000 (606.3451)	mem 10200MB
[2024-07-02 10:36:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:27 lr 0.000024	 wd 0.0000	time 0.2199 (0.2686)	loss 1.5000 (1.3865)	grad_norm 10.5301 (5.4348)	loss_scale 1024.0000 (623.7401)	mem 10200MB
[2024-07-02 10:36:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.2184 (0.2687)	loss 1.5532 (1.3867)	grad_norm 3.6983 (5.4297)	loss_scale 1024.0000 (639.7441)	mem 10200MB
[2024-07-02 10:36:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 2 training takes 0:11:18
[2024-07-02 10:37:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 17.823 (17.823)	Loss 0.4272 (0.4272)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 10200MB
[2024-07-02 10:37:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 83.698 Acc@5 97.094
[2024-07-02 10:37:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-02 10:37:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 83.70%
[2024-07-02 10:37:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 10:37:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 10:37:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][0/2502]	eta 9:59:47 lr 0.000024	 wd 0.0000	time 14.3833 (14.3833)	loss 0.9855 (0.9855)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 10:38:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:16:58 lr 0.000024	 wd 0.0000	time 0.2342 (0.4241)	loss 1.5019 (1.3549)	grad_norm 7.4540 (5.5727)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 10:38:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:13:01 lr 0.000025	 wd 0.0000	time 0.2261 (0.3396)	loss 1.4293 (1.3723)	grad_norm 4.9521 (5.3321)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 10:38:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:11:27 lr 0.000025	 wd 0.0000	time 0.2428 (0.3120)	loss 1.5891 (1.3663)	grad_norm 4.0899 (5.3518)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 10:39:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:10:23 lr 0.000025	 wd 0.0000	time 0.2589 (0.2966)	loss 1.5576 (1.3694)	grad_norm 4.3662 (5.2086)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 10:39:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:09:40 lr 0.000026	 wd 0.0000	time 0.2672 (0.2900)	loss 1.4359 (1.3677)	grad_norm 4.3514 (5.2360)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 10:40:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:09:00 lr 0.000026	 wd 0.0000	time 0.2334 (0.2840)	loss 1.3960 (1.3687)	grad_norm 5.7914 (inf)	loss_scale 512.0000 (966.0699)	mem 10200MB
[2024-07-02 10:40:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:08:28 lr 0.000026	 wd 0.0000	time 0.2313 (0.2822)	loss 1.7225 (1.3702)	grad_norm 5.2138 (inf)	loss_scale 512.0000 (901.2953)	mem 10200MB
[2024-07-02 10:41:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:53 lr 0.000027	 wd 0.0000	time 0.2312 (0.2782)	loss 1.1118 (1.3705)	grad_norm 4.2992 (inf)	loss_scale 512.0000 (852.6941)	mem 10200MB
[2024-07-02 10:41:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:07:23 lr 0.000027	 wd 0.0000	time 0.2246 (0.2767)	loss 1.5159 (1.3718)	grad_norm 5.6786 (inf)	loss_scale 512.0000 (814.8812)	mem 10200MB
[2024-07-02 10:42:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:55 lr 0.000027	 wd 0.0000	time 0.2528 (0.2765)	loss 1.4923 (1.3747)	grad_norm 5.7711 (inf)	loss_scale 512.0000 (784.6234)	mem 10200MB
[2024-07-02 10:42:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:06:24 lr 0.000028	 wd 0.0000	time 0.2361 (0.2746)	loss 1.3823 (1.3771)	grad_norm 3.7001 (inf)	loss_scale 512.0000 (759.8619)	mem 10200MB
[2024-07-02 10:42:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:55 lr 0.000028	 wd 0.0000	time 0.2380 (0.2732)	loss 1.2484 (1.3753)	grad_norm 2.7926 (inf)	loss_scale 512.0000 (739.2240)	mem 10200MB
[2024-07-02 10:43:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:05:29 lr 0.000028	 wd 0.0000	time 0.2273 (0.2737)	loss 1.3101 (1.3779)	grad_norm 6.8393 (inf)	loss_scale 512.0000 (721.7586)	mem 10200MB
[2024-07-02 10:43:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:05:00 lr 0.000028	 wd 0.0000	time 0.2696 (0.2728)	loss 1.2519 (1.3784)	grad_norm 4.5441 (inf)	loss_scale 512.0000 (706.7866)	mem 10200MB
[2024-07-02 10:44:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:32 lr 0.000029	 wd 0.0000	time 0.2341 (0.2716)	loss 1.4899 (1.3801)	grad_norm 4.6342 (inf)	loss_scale 512.0000 (693.8095)	mem 10200MB
[2024-07-02 10:44:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:04:05 lr 0.000029	 wd 0.0000	time 1.4548 (0.2718)	loss 1.5645 (1.3789)	grad_norm 7.0002 (inf)	loss_scale 512.0000 (682.4535)	mem 10200MB
[2024-07-02 10:45:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:37 lr 0.000029	 wd 0.0000	time 0.2398 (0.2714)	loss 1.1093 (1.3781)	grad_norm 8.7412 (inf)	loss_scale 512.0000 (672.4327)	mem 10200MB
[2024-07-02 10:45:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:03:09 lr 0.000030	 wd 0.0000	time 0.2556 (0.2704)	loss 1.4917 (1.3784)	grad_norm 3.7341 (inf)	loss_scale 512.0000 (663.5247)	mem 10200MB
[2024-07-02 10:45:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:42 lr 0.000030	 wd 0.0000	time 0.2282 (0.2693)	loss 1.4885 (1.3776)	grad_norm 4.2381 (inf)	loss_scale 512.0000 (655.5539)	mem 10200MB
[2024-07-02 10:46:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:15 lr 0.000030	 wd 0.0000	time 0.2246 (0.2704)	loss 1.1577 (1.3781)	grad_norm 7.9587 (inf)	loss_scale 512.0000 (648.3798)	mem 10200MB
[2024-07-02 10:46:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:48 lr 0.000031	 wd 0.0000	time 0.2340 (0.2696)	loss 1.1800 (1.3770)	grad_norm 3.6440 (inf)	loss_scale 512.0000 (641.8886)	mem 10200MB
[2024-07-02 10:47:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:21 lr 0.000031	 wd 0.0000	time 0.2435 (0.2697)	loss 1.3604 (1.3778)	grad_norm 4.9317 (inf)	loss_scale 512.0000 (635.9873)	mem 10200MB
[2024-07-02 10:47:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:54 lr 0.000031	 wd 0.0000	time 0.2563 (0.2688)	loss 1.4815 (1.3787)	grad_norm 4.6866 (inf)	loss_scale 512.0000 (630.5989)	mem 10200MB
[2024-07-02 10:48:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:27 lr 0.000032	 wd 0.0000	time 0.2379 (0.2692)	loss 1.0106 (1.3779)	grad_norm 2.9983 (inf)	loss_scale 512.0000 (625.6593)	mem 10200MB
[2024-07-02 10:48:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000032	 wd 0.0000	time 0.2460 (0.2683)	loss 1.4394 (1.3782)	grad_norm 4.2203 (inf)	loss_scale 512.0000 (621.1148)	mem 10200MB
[2024-07-02 10:48:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 3 training takes 0:11:15
[2024-07-02 10:48:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 16.919 (16.919)	Loss 0.4290 (0.4290)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 10200MB
[2024-07-02 10:49:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 83.878 Acc@5 97.178
[2024-07-02 10:49:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-02 10:49:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 83.88%
[2024-07-02 10:49:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 10:49:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 10:49:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][0/2502]	eta 14:20:18 lr 0.000032	 wd 0.0000	time 20.6310 (20.6310)	loss 1.4223 (1.4223)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:49:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:18:14 lr 0.000032	 wd 0.0000	time 0.2331 (0.4555)	loss 1.2596 (1.4063)	grad_norm 3.9527 (5.1410)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:50:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:13:37 lr 0.000033	 wd 0.0000	time 0.2188 (0.3552)	loss 1.1603 (1.3933)	grad_norm 4.0628 (5.0886)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:50:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:11:45 lr 0.000033	 wd 0.0000	time 0.2327 (0.3204)	loss 1.1198 (1.3938)	grad_norm 5.7507 (5.2135)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:51:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:10:48 lr 0.000033	 wd 0.0000	time 0.2922 (0.3083)	loss 1.4160 (1.3825)	grad_norm 5.0205 (5.3864)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:51:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:09:58 lr 0.000034	 wd 0.0000	time 0.3684 (0.2992)	loss 1.4286 (1.3784)	grad_norm 4.3354 (5.4824)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:52:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:09:15 lr 0.000034	 wd 0.0000	time 0.2566 (0.2923)	loss 1.4345 (1.3735)	grad_norm 4.5444 (5.4510)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:52:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:08:36 lr 0.000034	 wd 0.0000	time 0.2280 (0.2866)	loss 1.2867 (1.3736)	grad_norm 3.1992 (5.4704)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:52:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:08:06 lr 0.000035	 wd 0.0000	time 0.2458 (0.2860)	loss 1.3323 (1.3744)	grad_norm 2.7704 (5.4367)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:53:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:07:33 lr 0.000035	 wd 0.0000	time 0.2562 (0.2829)	loss 1.4935 (1.3751)	grad_norm 3.3132 (5.3594)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:53:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:07:04 lr 0.000035	 wd 0.0000	time 0.2361 (0.2829)	loss 1.5272 (1.3759)	grad_norm 10.7027 (5.3096)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:54:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:06:32 lr 0.000036	 wd 0.0000	time 0.2433 (0.2803)	loss 1.5938 (1.3762)	grad_norm 4.8148 (5.2365)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:54:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:06:04 lr 0.000036	 wd 0.0000	time 0.3498 (0.2799)	loss 1.0468 (1.3755)	grad_norm 4.5161 (5.2549)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:55:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:05:34 lr 0.000036	 wd 0.0000	time 0.2503 (0.2780)	loss 1.5555 (1.3742)	grad_norm 4.3588 (5.2152)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:55:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:05:04 lr 0.000036	 wd 0.0000	time 0.2406 (0.2764)	loss 1.4538 (1.3743)	grad_norm 4.6305 (5.1683)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:56:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:35 lr 0.000037	 wd 0.0000	time 0.2316 (0.2750)	loss 1.3032 (1.3772)	grad_norm 8.6735 (5.2216)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:56:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:04:07 lr 0.000037	 wd 0.0000	time 0.2398 (0.2741)	loss 1.2337 (1.3766)	grad_norm 5.1365 (5.2165)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:56:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:38 lr 0.000037	 wd 0.0000	time 0.2504 (0.2727)	loss 1.5380 (1.3761)	grad_norm 4.6373 (5.2126)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:57:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:03:10 lr 0.000038	 wd 0.0000	time 0.2491 (0.2714)	loss 1.5702 (1.3759)	grad_norm 3.8408 (5.2023)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:57:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:44 lr 0.000038	 wd 0.0000	time 0.5322 (0.2729)	loss 1.5482 (1.3759)	grad_norm 4.4064 (5.2337)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:58:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:02:16 lr 0.000038	 wd 0.0000	time 0.2228 (0.2722)	loss 1.5862 (1.3760)	grad_norm 3.8445 (5.2358)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 10:58:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:49 lr 0.000039	 wd 0.0000	time 0.2445 (0.2712)	loss 1.3707 (1.3760)	grad_norm 15.1360 (5.2342)	loss_scale 1024.0000 (529.0585)	mem 10200MB
[2024-07-02 10:59:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:21 lr 0.000039	 wd 0.0000	time 0.2553 (0.2701)	loss 0.9968 (1.3734)	grad_norm 3.6699 (5.2252)	loss_scale 1024.0000 (551.5457)	mem 10200MB
[2024-07-02 10:59:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:54 lr 0.000039	 wd 0.0000	time 0.2459 (0.2715)	loss 1.3118 (1.3744)	grad_norm 3.7811 (5.2015)	loss_scale 1024.0000 (572.0782)	mem 10200MB
[2024-07-02 10:59:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:27 lr 0.000040	 wd 0.0000	time 0.2691 (0.2709)	loss 1.4880 (1.3740)	grad_norm 3.1186 (5.2157)	loss_scale 1024.0000 (590.9005)	mem 10200MB
[2024-07-02 11:00:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.2294 (0.2699)	loss 0.9318 (1.3736)	grad_norm 3.0788 (5.2027)	loss_scale 1024.0000 (608.2175)	mem 10200MB
[2024-07-02 11:00:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 4 training takes 0:11:18
[2024-07-02 11:00:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 18.051 (18.051)	Loss 0.4353 (0.4353)	Acc@1 91.211 (91.211)	Acc@5 98.242 (98.242)	Mem 10200MB
[2024-07-02 11:01:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 83.938 Acc@5 97.256
[2024-07-02 11:01:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-02 11:01:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 83.94%
[2024-07-02 11:01:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 11:01:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 11:01:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][0/2502]	eta 10:30:05 lr 0.000040	 wd 0.0000	time 15.1102 (15.1102)	loss 1.5623 (1.5623)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:01:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:16:10 lr 0.000040	 wd 0.0000	time 0.2202 (0.4042)	loss 1.3072 (1.3885)	grad_norm 5.4297 (4.9192)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:02:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:12:38 lr 0.000040	 wd 0.0000	time 0.2319 (0.3296)	loss 1.4514 (1.4020)	grad_norm 4.4788 (5.0369)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:02:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:11:26 lr 0.000040	 wd 0.0000	time 0.2746 (0.3117)	loss 1.6279 (1.3882)	grad_norm 6.2374 (4.9614)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:03:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:10:24 lr 0.000040	 wd 0.0000	time 0.2301 (0.2969)	loss 1.1430 (1.3890)	grad_norm 4.0704 (4.8365)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:03:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:09:37 lr 0.000040	 wd 0.0000	time 0.2351 (0.2886)	loss 1.6868 (1.3842)	grad_norm 3.2671 (4.7862)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:04:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:57 lr 0.000040	 wd 0.0000	time 0.2454 (0.2826)	loss 1.5323 (1.3870)	grad_norm 16.1712 (inf)	loss_scale 512.0000 (1000.1464)	mem 10200MB
[2024-07-02 11:04:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:08:29 lr 0.000040	 wd 0.0000	time 0.2281 (0.2830)	loss 1.5175 (1.3842)	grad_norm 4.5422 (inf)	loss_scale 512.0000 (930.5107)	mem 10200MB
[2024-07-02 11:04:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:55 lr 0.000040	 wd 0.0000	time 0.2613 (0.2795)	loss 1.1196 (1.3778)	grad_norm 3.4930 (inf)	loss_scale 512.0000 (878.2622)	mem 10200MB
[2024-07-02 11:05:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:07:23 lr 0.000040	 wd 0.0000	time 0.2202 (0.2768)	loss 0.8400 (1.3762)	grad_norm 3.7198 (inf)	loss_scale 512.0000 (837.6115)	mem 10200MB
[2024-07-02 11:05:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:57 lr 0.000040	 wd 0.0000	time 0.2729 (0.2778)	loss 1.3967 (1.3788)	grad_norm 5.8945 (inf)	loss_scale 512.0000 (805.0829)	mem 10200MB
[2024-07-02 11:06:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:06:27 lr 0.000040	 wd 0.0000	time 0.2522 (0.2762)	loss 1.5601 (1.3745)	grad_norm 6.6197 (inf)	loss_scale 512.0000 (778.4632)	mem 10200MB
[2024-07-02 11:06:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:57 lr 0.000040	 wd 0.0000	time 0.2604 (0.2743)	loss 1.5007 (1.3740)	grad_norm 3.5879 (inf)	loss_scale 512.0000 (756.2764)	mem 10200MB
[2024-07-02 11:07:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:05:28 lr 0.000040	 wd 0.0000	time 0.2231 (0.2730)	loss 1.5470 (1.3738)	grad_norm 4.3736 (inf)	loss_scale 512.0000 (737.5004)	mem 10200MB
[2024-07-02 11:07:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:05:01 lr 0.000040	 wd 0.0000	time 0.2584 (0.2740)	loss 1.5091 (1.3734)	grad_norm 4.0121 (inf)	loss_scale 512.0000 (721.4047)	mem 10200MB
[2024-07-02 11:07:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:04:33 lr 0.000040	 wd 0.0000	time 0.2330 (0.2728)	loss 1.3204 (1.3734)	grad_norm 4.2732 (inf)	loss_scale 512.0000 (707.4537)	mem 10200MB
[2024-07-02 11:08:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:04:04 lr 0.000040	 wd 0.0000	time 0.2335 (0.2715)	loss 1.4339 (1.3743)	grad_norm 5.0898 (inf)	loss_scale 512.0000 (695.2455)	mem 10200MB
[2024-07-02 11:08:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:36 lr 0.000040	 wd 0.0000	time 0.2251 (0.2702)	loss 1.4906 (1.3744)	grad_norm 5.7693 (inf)	loss_scale 512.0000 (684.4727)	mem 10200MB
[2024-07-02 11:09:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:03:11 lr 0.000040	 wd 0.0000	time 0.2257 (0.2734)	loss 1.0788 (1.3731)	grad_norm 5.2720 (inf)	loss_scale 512.0000 (674.8962)	mem 10200MB
[2024-07-02 11:09:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:43 lr 0.000040	 wd 0.0000	time 0.2489 (0.2723)	loss 1.5267 (1.3751)	grad_norm 3.7335 (inf)	loss_scale 512.0000 (666.3272)	mem 10200MB
[2024-07-02 11:10:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:02:16 lr 0.000040	 wd 0.0000	time 0.2273 (0.2712)	loss 1.3996 (1.3763)	grad_norm 6.6780 (inf)	loss_scale 512.0000 (658.6147)	mem 10200MB
[2024-07-02 11:10:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:49 lr 0.000040	 wd 0.0000	time 0.2536 (0.2712)	loss 1.6020 (1.3773)	grad_norm 4.0928 (inf)	loss_scale 512.0000 (651.6364)	mem 10200MB
[2024-07-02 11:11:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:21 lr 0.000040	 wd 0.0000	time 0.2404 (0.2706)	loss 1.3443 (1.3752)	grad_norm 4.4890 (inf)	loss_scale 512.0000 (645.2921)	mem 10200MB
[2024-07-02 11:11:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:54 lr 0.000040	 wd 0.0000	time 0.2238 (0.2709)	loss 0.9762 (1.3746)	grad_norm 8.6939 (inf)	loss_scale 512.0000 (639.4993)	mem 10200MB
[2024-07-02 11:11:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:27 lr 0.000040	 wd 0.0000	time 0.2313 (0.2699)	loss 1.6113 (1.3746)	grad_norm 3.7870 (inf)	loss_scale 512.0000 (634.1891)	mem 10200MB
[2024-07-02 11:12:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.2171 (0.2701)	loss 1.4449 (1.3744)	grad_norm 3.6797 (inf)	loss_scale 512.0000 (629.3035)	mem 10200MB
[2024-07-02 11:12:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 5 training takes 0:11:29
[2024-07-02 11:12:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 17.823 (17.823)	Loss 0.4314 (0.4314)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 10200MB
[2024-07-02 11:13:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 83.996 Acc@5 97.308
[2024-07-02 11:13:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-02 11:13:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.00%
[2024-07-02 11:13:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 11:13:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 11:13:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][0/2502]	eta 10:59:55 lr 0.000040	 wd 0.0000	time 15.8253 (15.8253)	loss 1.7673 (1.7673)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:13:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:16:24 lr 0.000040	 wd 0.0000	time 0.6337 (0.4100)	loss 1.2238 (1.3580)	grad_norm 4.3190 (4.7728)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:14:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:13:24 lr 0.000040	 wd 0.0000	time 0.2484 (0.3493)	loss 1.4668 (1.3723)	grad_norm 4.5951 (4.8167)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:14:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:11:38 lr 0.000040	 wd 0.0000	time 0.2351 (0.3172)	loss 1.5483 (1.3781)	grad_norm 5.2409 (4.8442)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:15:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:10:32 lr 0.000040	 wd 0.0000	time 0.2525 (0.3010)	loss 1.4090 (1.3713)	grad_norm 4.5007 (5.0152)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:15:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:09:43 lr 0.000040	 wd 0.0000	time 0.3041 (0.2915)	loss 1.5241 (1.3688)	grad_norm 4.4912 (4.9133)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:16:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:09:07 lr 0.000040	 wd 0.0000	time 0.2323 (0.2879)	loss 1.5311 (1.3704)	grad_norm 3.5616 (4.9656)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:16:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:08:30 lr 0.000040	 wd 0.0000	time 0.2848 (0.2831)	loss 1.3782 (1.3705)	grad_norm 7.2545 (5.2061)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:16:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:58 lr 0.000040	 wd 0.0000	time 0.2438 (0.2811)	loss 1.1597 (1.3708)	grad_norm 5.1499 (5.1666)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:17:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:07:27 lr 0.000040	 wd 0.0000	time 0.2300 (0.2792)	loss 1.5462 (1.3726)	grad_norm 4.3317 (5.1832)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:17:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:55 lr 0.000040	 wd 0.0000	time 0.2321 (0.2765)	loss 1.2957 (1.3692)	grad_norm 4.0910 (5.1432)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:18:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:06:24 lr 0.000040	 wd 0.0000	time 0.2282 (0.2743)	loss 1.3030 (1.3668)	grad_norm 4.1842 (5.1404)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:18:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:54 lr 0.000040	 wd 0.0000	time 0.2397 (0.2723)	loss 1.1037 (1.3680)	grad_norm 4.8530 (5.1703)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:19:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:05:27 lr 0.000040	 wd 0.0000	time 0.2600 (0.2724)	loss 1.5454 (1.3669)	grad_norm 4.1556 (5.1199)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:19:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:05:00 lr 0.000040	 wd 0.0000	time 0.2388 (0.2726)	loss 1.7687 (1.3647)	grad_norm 4.7869 (5.1181)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:19:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:31 lr 0.000040	 wd 0.0000	time 0.2337 (0.2711)	loss 1.4412 (1.3670)	grad_norm 4.6060 (5.1340)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:20:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:04:03 lr 0.000040	 wd 0.0000	time 0.2488 (0.2698)	loss 1.4386 (1.3651)	grad_norm 4.2848 (5.1603)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:21:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:42 lr 0.000040	 wd 0.0000	time 0.2399 (0.2776)	loss 1.5515 (1.3650)	grad_norm 4.9946 (5.1482)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:21:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:03:13 lr 0.000040	 wd 0.0000	time 0.2303 (0.2762)	loss 1.1221 (1.3648)	grad_norm 3.4626 (5.1535)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:21:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:45 lr 0.000040	 wd 0.0000	time 0.2415 (0.2749)	loss 1.2691 (1.3647)	grad_norm 4.1846 (5.1639)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:22:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:02:18 lr 0.000039	 wd 0.0000	time 0.6613 (0.2756)	loss 1.0715 (1.3651)	grad_norm 5.3791 (5.1732)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:22:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:50 lr 0.000039	 wd 0.0000	time 0.2240 (0.2745)	loss 1.5196 (1.3642)	grad_norm 4.9567 (5.1856)	loss_scale 1024.0000 (519.3108)	mem 10200MB
[2024-07-02 11:23:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:22 lr 0.000039	 wd 0.0000	time 0.2340 (0.2741)	loss 1.2740 (1.3643)	grad_norm 4.0355 (5.1702)	loss_scale 1024.0000 (542.2408)	mem 10200MB
[2024-07-02 11:23:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:55 lr 0.000039	 wd 0.0000	time 0.2518 (0.2742)	loss 1.4897 (1.3649)	grad_norm 9.8486 (5.1691)	loss_scale 1024.0000 (563.1777)	mem 10200MB
[2024-07-02 11:24:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:28 lr 0.000039	 wd 0.0000	time 0.2325 (0.2753)	loss 1.1385 (1.3643)	grad_norm 4.9319 (5.1450)	loss_scale 1024.0000 (582.3707)	mem 10200MB
[2024-07-02 11:24:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.2395 (0.2744)	loss 0.9840 (1.3647)	grad_norm 5.1901 (5.1497)	loss_scale 1024.0000 (600.0288)	mem 10200MB
[2024-07-02 11:24:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 6 training takes 0:11:30
[2024-07-02 11:24:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 17.690 (17.690)	Loss 0.4397 (0.4397)	Acc@1 91.602 (91.602)	Acc@5 98.438 (98.438)	Mem 10200MB
[2024-07-02 11:25:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 83.998 Acc@5 97.302
[2024-07-02 11:25:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-02 11:25:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.00%
[2024-07-02 11:25:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 11:25:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 11:25:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][0/2502]	eta 18:35:01 lr 0.000039	 wd 0.0000	time 26.7391 (26.7391)	loss 1.6963 (1.6963)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:26:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:20:35 lr 0.000039	 wd 0.0000	time 0.2438 (0.5144)	loss 1.3660 (1.3769)	grad_norm 4.3590 (5.5802)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:26:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:14:47 lr 0.000039	 wd 0.0000	time 0.2238 (0.3855)	loss 1.5426 (1.3553)	grad_norm 4.0283 (5.0782)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:26:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:12:32 lr 0.000039	 wd 0.0000	time 0.2657 (0.3419)	loss 1.3356 (1.3558)	grad_norm 4.8498 (4.9903)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:27:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:11:28 lr 0.000039	 wd 0.0000	time 0.2356 (0.3276)	loss 1.4225 (1.3592)	grad_norm 5.0290 (4.9837)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:27:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:10:27 lr 0.000039	 wd 0.0000	time 0.2518 (0.3132)	loss 1.5051 (1.3555)	grad_norm 5.3472 (4.9679)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:28:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:09:37 lr 0.000039	 wd 0.0000	time 0.2315 (0.3034)	loss 1.3797 (1.3590)	grad_norm 5.5549 (5.0641)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:28:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:08:53 lr 0.000039	 wd 0.0000	time 0.2406 (0.2961)	loss 1.3834 (1.3608)	grad_norm 3.5283 (5.0531)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:29:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:08:18 lr 0.000039	 wd 0.0000	time 0.2366 (0.2928)	loss 1.0316 (1.3626)	grad_norm 4.2873 (5.1006)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:29:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:07:42 lr 0.000039	 wd 0.0000	time 0.2268 (0.2890)	loss 1.1983 (1.3653)	grad_norm 4.9003 (5.0722)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:29:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:07:12 lr 0.000039	 wd 0.0000	time 0.2291 (0.2880)	loss 1.2743 (1.3621)	grad_norm 6.0373 (5.1022)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:30:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:06:40 lr 0.000039	 wd 0.0000	time 0.2382 (0.2857)	loss 1.3274 (1.3605)	grad_norm 4.4822 (5.0630)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:30:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:06:09 lr 0.000039	 wd 0.0000	time 0.2364 (0.2835)	loss 1.3282 (1.3576)	grad_norm 3.9570 (5.0938)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:31:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:05:37 lr 0.000039	 wd 0.0000	time 0.2245 (0.2811)	loss 1.4474 (1.3585)	grad_norm 3.6129 (5.0905)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:31:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:05:07 lr 0.000039	 wd 0.0000	time 0.2441 (0.2789)	loss 1.5704 (1.3588)	grad_norm 10.3627 (5.0997)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:32:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:38 lr 0.000039	 wd 0.0000	time 0.2466 (0.2781)	loss 1.4580 (1.3579)	grad_norm 5.9518 (5.1629)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:32:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:04:10 lr 0.000039	 wd 0.0000	time 0.2267 (0.2781)	loss 1.4949 (1.3591)	grad_norm 9.3945 (5.1444)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:33:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:41 lr 0.000039	 wd 0.0000	time 0.2341 (0.2767)	loss 1.5465 (1.3592)	grad_norm 4.7018 (5.1381)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:33:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:03:13 lr 0.000039	 wd 0.0000	time 0.2297 (0.2752)	loss 1.3349 (1.3588)	grad_norm 8.2579 (5.1580)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 11:33:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:46 lr 0.000039	 wd 0.0000	time 0.2537 (0.2762)	loss 1.3226 (1.3580)	grad_norm 3.5839 (inf)	loss_scale 512.0000 (997.6055)	mem 10200MB
[2024-07-02 11:34:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:02:18 lr 0.000039	 wd 0.0000	time 0.2286 (0.2758)	loss 1.4842 (1.3587)	grad_norm 5.0158 (inf)	loss_scale 512.0000 (973.3373)	mem 10200MB
[2024-07-02 11:34:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:50 lr 0.000039	 wd 0.0000	time 0.2369 (0.2746)	loss 1.6065 (1.3603)	grad_norm 5.6573 (inf)	loss_scale 512.0000 (951.3793)	mem 10200MB
[2024-07-02 11:35:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:22 lr 0.000039	 wd 0.0000	time 0.2136 (0.2736)	loss 1.2572 (1.3589)	grad_norm 4.0612 (inf)	loss_scale 512.0000 (931.4166)	mem 10200MB
[2024-07-02 11:35:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:55 lr 0.000039	 wd 0.0000	time 0.2516 (0.2734)	loss 1.4975 (1.3593)	grad_norm 2.8042 (inf)	loss_scale 512.0000 (913.1890)	mem 10200MB
[2024-07-02 11:36:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:27 lr 0.000039	 wd 0.0000	time 0.2466 (0.2726)	loss 1.3505 (1.3590)	grad_norm 4.0966 (inf)	loss_scale 512.0000 (896.4798)	mem 10200MB
[2024-07-02 11:36:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.2317 (0.2714)	loss 1.2714 (1.3592)	grad_norm 4.5114 (inf)	loss_scale 512.0000 (881.1068)	mem 10200MB
[2024-07-02 11:36:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 7 training takes 0:11:22
[2024-07-02 11:36:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 23.034 (23.034)	Loss 0.4341 (0.4341)	Acc@1 90.820 (90.820)	Acc@5 98.438 (98.438)	Mem 10200MB
[2024-07-02 11:37:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.044 Acc@5 97.340
[2024-07-02 11:37:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-02 11:37:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.04%
[2024-07-02 11:37:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 11:37:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 11:37:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][0/2502]	eta 10:03:05 lr 0.000039	 wd 0.0000	time 14.4625 (14.4625)	loss 1.5411 (1.5411)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:37:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:15:51 lr 0.000039	 wd 0.0000	time 0.2363 (0.3959)	loss 1.4732 (1.3858)	grad_norm 7.5535 (4.9256)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:38:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:12:25 lr 0.000039	 wd 0.0000	time 0.2600 (0.3237)	loss 1.4047 (1.3614)	grad_norm 5.5019 (5.4296)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:38:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:11:27 lr 0.000038	 wd 0.0000	time 0.2370 (0.3121)	loss 1.3454 (1.3562)	grad_norm 4.2700 (5.5602)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:39:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:10:27 lr 0.000038	 wd 0.0000	time 0.2411 (0.2983)	loss 1.4495 (1.3534)	grad_norm 3.9864 (5.3219)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:39:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:09:38 lr 0.000038	 wd 0.0000	time 0.2457 (0.2892)	loss 1.5116 (1.3598)	grad_norm 3.5481 (5.2357)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:40:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:09:00 lr 0.000038	 wd 0.0000	time 0.2417 (0.2840)	loss 1.5681 (1.3639)	grad_norm 4.3306 (5.2117)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:40:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:08:35 lr 0.000038	 wd 0.0000	time 0.2561 (0.2862)	loss 1.5251 (1.3643)	grad_norm 4.5924 (5.1868)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:40:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:08:00 lr 0.000038	 wd 0.0000	time 0.2530 (0.2823)	loss 1.4163 (1.3635)	grad_norm 4.2261 (5.1264)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:41:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:07:27 lr 0.000038	 wd 0.0000	time 0.2300 (0.2795)	loss 1.5390 (1.3641)	grad_norm 3.6646 (5.1550)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:41:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:56 lr 0.000038	 wd 0.0000	time 0.2375 (0.2774)	loss 1.3926 (1.3615)	grad_norm 4.2413 (5.1579)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:42:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:06:28 lr 0.000038	 wd 0.0000	time 0.2458 (0.2770)	loss 1.4801 (1.3580)	grad_norm 5.1540 (5.1970)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:42:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:58 lr 0.000038	 wd 0.0000	time 0.2306 (0.2753)	loss 1.4185 (1.3570)	grad_norm 5.6046 (5.1731)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:43:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:05:30 lr 0.000038	 wd 0.0000	time 0.2399 (0.2750)	loss 1.0839 (1.3550)	grad_norm 7.0393 (5.2536)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:43:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:05:05 lr 0.000038	 wd 0.0000	time 0.2392 (0.2770)	loss 0.9533 (1.3560)	grad_norm 4.1106 (5.2932)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:44:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:04:36 lr 0.000038	 wd 0.0000	time 0.2433 (0.2755)	loss 0.9194 (1.3525)	grad_norm 6.4437 (5.3136)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:44:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:04:07 lr 0.000038	 wd 0.0000	time 0.2448 (0.2740)	loss 1.2795 (1.3495)	grad_norm 4.6497 (5.2781)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:44:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:39 lr 0.000038	 wd 0.0000	time 0.2307 (0.2740)	loss 1.2523 (1.3510)	grad_norm 3.7438 (5.2662)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:45:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:03:14 lr 0.000038	 wd 0.0000	time 0.2379 (0.2770)	loss 1.4727 (1.3527)	grad_norm 5.2806 (5.2438)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:45:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:46 lr 0.000038	 wd 0.0000	time 0.2192 (0.2769)	loss 1.2878 (1.3532)	grad_norm 4.1746 (5.2211)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:46:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:02:18 lr 0.000038	 wd 0.0000	time 0.2291 (0.2756)	loss 1.7234 (1.3550)	grad_norm 3.6715 (5.1774)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:46:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:51 lr 0.000038	 wd 0.0000	time 0.2806 (0.2766)	loss 1.3684 (1.3549)	grad_norm 6.1489 (5.1925)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:47:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:23 lr 0.000038	 wd 0.0000	time 0.2386 (0.2769)	loss 1.4751 (1.3538)	grad_norm 4.1577 (5.1882)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:47:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:55 lr 0.000038	 wd 0.0000	time 0.2207 (0.2758)	loss 1.3583 (1.3544)	grad_norm 4.7504 (5.1914)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:48:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:28 lr 0.000038	 wd 0.0000	time 0.2283 (0.2746)	loss 1.4444 (1.3562)	grad_norm 4.5436 (5.1772)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:48:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000038	 wd 0.0000	time 0.2219 (0.2741)	loss 1.5649 (1.3573)	grad_norm 3.0144 (5.1567)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:48:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 8 training takes 0:11:35
[2024-07-02 11:49:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 16.771 (16.771)	Loss 0.4324 (0.4324)	Acc@1 92.188 (92.188)	Acc@5 98.047 (98.047)	Mem 10200MB
[2024-07-02 11:49:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.122 Acc@5 97.342
[2024-07-02 11:49:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-02 11:49:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.12%
[2024-07-02 11:49:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 11:49:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 11:49:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][0/2502]	eta 10:08:43 lr 0.000038	 wd 0.0000	time 14.5978 (14.5978)	loss 1.3689 (1.3689)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:49:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:15:53 lr 0.000038	 wd 0.0000	time 0.2750 (0.3968)	loss 1.2874 (1.3297)	grad_norm 4.2410 (5.5593)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:50:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:13:40 lr 0.000037	 wd 0.0000	time 0.2480 (0.3564)	loss 1.5015 (1.3340)	grad_norm 4.8874 (5.1689)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:50:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:11:50 lr 0.000037	 wd 0.0000	time 0.2361 (0.3226)	loss 1.3964 (1.3446)	grad_norm 5.4342 (5.3220)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:51:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:10:40 lr 0.000037	 wd 0.0000	time 0.2636 (0.3047)	loss 1.5738 (1.3407)	grad_norm 4.5420 (5.1735)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:51:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:09:52 lr 0.000037	 wd 0.0000	time 0.2248 (0.2961)	loss 1.3174 (1.3453)	grad_norm 4.0334 (5.1692)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:52:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:09:12 lr 0.000037	 wd 0.0000	time 0.2467 (0.2907)	loss 1.3959 (1.3394)	grad_norm 7.6470 (5.1223)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:52:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:08:34 lr 0.000037	 wd 0.0000	time 0.2645 (0.2855)	loss 1.5124 (1.3401)	grad_norm 3.2667 (5.0861)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 11:53:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:58 lr 0.000037	 wd 0.0000	time 0.2272 (0.2811)	loss 1.3779 (1.3449)	grad_norm 3.8029 (5.0311)	loss_scale 1024.0000 (513.2784)	mem 10200MB
[2024-07-02 11:53:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:07:27 lr 0.000037	 wd 0.0000	time 0.2281 (0.2795)	loss 1.5510 (1.3420)	grad_norm 4.1449 (5.1021)	loss_scale 1024.0000 (569.9623)	mem 10200MB
[2024-07-02 11:53:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:56 lr 0.000037	 wd 0.0000	time 0.2452 (0.2770)	loss 1.4999 (1.3442)	grad_norm 7.0351 (5.1121)	loss_scale 1024.0000 (615.3207)	mem 10200MB
[2024-07-02 11:54:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:06:25 lr 0.000037	 wd 0.0000	time 0.2339 (0.2750)	loss 1.3367 (1.3479)	grad_norm 5.1498 (5.0939)	loss_scale 1024.0000 (652.4396)	mem 10200MB
[2024-07-02 11:54:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:55 lr 0.000037	 wd 0.0000	time 0.2356 (0.2730)	loss 1.6469 (1.3507)	grad_norm 3.1813 (5.0998)	loss_scale 1024.0000 (683.3772)	mem 10200MB
[2024-07-02 11:55:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:05:29 lr 0.000037	 wd 0.0000	time 0.2267 (0.2738)	loss 0.9588 (1.3479)	grad_norm 3.5520 (5.0760)	loss_scale 1024.0000 (709.5588)	mem 10200MB
[2024-07-02 11:55:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:05:00 lr 0.000037	 wd 0.0000	time 0.2346 (0.2723)	loss 1.3720 (1.3499)	grad_norm 8.4553 (5.0877)	loss_scale 1024.0000 (732.0029)	mem 10200MB
[2024-07-02 11:56:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:04:31 lr 0.000037	 wd 0.0000	time 0.2426 (0.2708)	loss 1.5342 (1.3521)	grad_norm 4.3029 (5.0455)	loss_scale 1024.0000 (751.4564)	mem 10200MB
[2024-07-02 11:56:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:04:03 lr 0.000037	 wd 0.0000	time 0.2713 (0.2698)	loss 0.9991 (1.3516)	grad_norm 6.8333 (5.0164)	loss_scale 1024.0000 (768.4797)	mem 10200MB
[2024-07-02 11:57:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:39 lr 0.000037	 wd 0.0000	time 0.2353 (0.2736)	loss 1.0716 (1.3531)	grad_norm 5.6757 (5.0745)	loss_scale 1024.0000 (783.5015)	mem 10200MB
[2024-07-02 11:57:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:03:11 lr 0.000037	 wd 0.0000	time 0.2386 (0.2725)	loss 1.5213 (1.3537)	grad_norm 3.5902 (5.1017)	loss_scale 1024.0000 (796.8551)	mem 10200MB
[2024-07-02 11:57:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:43 lr 0.000037	 wd 0.0000	time 0.2358 (0.2720)	loss 1.3779 (1.3527)	grad_norm 4.6635 (5.0931)	loss_scale 1024.0000 (808.8038)	mem 10200MB
[2024-07-02 11:58:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:02:17 lr 0.000037	 wd 0.0000	time 0.2594 (0.2732)	loss 1.5380 (1.3519)	grad_norm 4.5240 (5.0788)	loss_scale 1024.0000 (819.5582)	mem 10200MB
[2024-07-02 11:58:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:49 lr 0.000036	 wd 0.0000	time 0.2446 (0.2725)	loss 1.1543 (1.3525)	grad_norm 5.6277 (5.0560)	loss_scale 1024.0000 (829.2889)	mem 10200MB
[2024-07-02 11:59:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:22 lr 0.000036	 wd 0.0000	time 0.2427 (0.2717)	loss 1.4425 (1.3539)	grad_norm 4.3326 (5.0385)	loss_scale 1024.0000 (838.1354)	mem 10200MB
[2024-07-02 11:59:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:54 lr 0.000036	 wd 0.0000	time 0.2386 (0.2707)	loss 1.3978 (1.3544)	grad_norm 4.3655 (5.0297)	loss_scale 1024.0000 (846.2130)	mem 10200MB
[2024-07-02 12:00:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:27 lr 0.000036	 wd 0.0000	time 0.2360 (0.2712)	loss 1.2519 (1.3541)	grad_norm 7.8484 (5.0156)	loss_scale 1024.0000 (853.6177)	mem 10200MB
[2024-07-02 12:00:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000036	 wd 0.0000	time 0.2475 (0.2703)	loss 0.9182 (1.3550)	grad_norm 4.1026 (5.0035)	loss_scale 1024.0000 (860.4302)	mem 10200MB
[2024-07-02 12:00:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 9 training takes 0:11:20
[2024-07-02 12:00:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 17.421 (17.421)	Loss 0.4143 (0.4143)	Acc@1 92.188 (92.188)	Acc@5 98.047 (98.047)	Mem 10200MB
[2024-07-02 12:01:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.250 Acc@5 97.342
[2024-07-02 12:01:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-02 12:01:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.25%
[2024-07-02 12:01:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 12:01:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 12:01:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][0/2502]	eta 10:09:10 lr 0.000036	 wd 0.0000	time 14.6083 (14.6083)	loss 1.2869 (1.2869)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:01:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:16:59 lr 0.000036	 wd 0.0000	time 0.2372 (0.4246)	loss 1.1935 (1.3175)	grad_norm 4.7424 (4.8707)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:02:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:12:58 lr 0.000036	 wd 0.0000	time 0.2443 (0.3380)	loss 1.3820 (1.3435)	grad_norm 5.3976 (5.0302)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:02:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:11:28 lr 0.000036	 wd 0.0000	time 0.2469 (0.3127)	loss 0.9341 (1.3457)	grad_norm 3.9635 (5.1431)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:03:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:10:32 lr 0.000036	 wd 0.0000	time 0.2773 (0.3008)	loss 1.5223 (1.3506)	grad_norm 4.3849 (5.0456)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:03:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:09:44 lr 0.000036	 wd 0.0000	time 0.2333 (0.2918)	loss 1.4830 (1.3478)	grad_norm 8.9986 (5.0041)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:04:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:09:04 lr 0.000036	 wd 0.0000	time 0.2723 (0.2863)	loss 1.5955 (1.3470)	grad_norm 4.7764 (5.0144)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:04:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:08:28 lr 0.000036	 wd 0.0000	time 0.2415 (0.2823)	loss 1.4281 (1.3442)	grad_norm 4.4145 (4.9927)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:04:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:08:00 lr 0.000036	 wd 0.0000	time 0.2322 (0.2821)	loss 1.3362 (1.3458)	grad_norm 5.2676 (4.9990)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:05:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:07:28 lr 0.000036	 wd 0.0000	time 0.2419 (0.2798)	loss 1.4923 (1.3456)	grad_norm 5.6483 (4.9581)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:05:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:56 lr 0.000036	 wd 0.0000	time 0.2444 (0.2771)	loss 1.5884 (1.3439)	grad_norm 4.3263 (4.9938)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:06:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:06:25 lr 0.000036	 wd 0.0000	time 0.2406 (0.2747)	loss 1.3714 (1.3416)	grad_norm 4.2881 (4.9655)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:06:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:56 lr 0.000035	 wd 0.0000	time 0.2567 (0.2739)	loss 1.2505 (1.3420)	grad_norm 4.9474 (4.9676)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:07:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:05:29 lr 0.000035	 wd 0.0000	time 0.2393 (0.2739)	loss 1.5848 (1.3446)	grad_norm 3.1734 (4.9506)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:07:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:05:00 lr 0.000035	 wd 0.0000	time 0.2583 (0.2724)	loss 1.4298 (1.3469)	grad_norm 6.2696 (4.9520)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:07:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:04:31 lr 0.000035	 wd 0.0000	time 0.2490 (0.2708)	loss 1.2351 (1.3470)	grad_norm 5.4373 (4.9573)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:08:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:04:05 lr 0.000035	 wd 0.0000	time 0.2286 (0.2724)	loss 1.2072 (1.3481)	grad_norm 3.4209 (4.9356)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:08:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:37 lr 0.000035	 wd 0.0000	time 0.2329 (0.2712)	loss 1.3815 (1.3488)	grad_norm 5.4489 (4.9114)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:09:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:03:10 lr 0.000035	 wd 0.0000	time 0.2361 (0.2711)	loss 1.3399 (1.3488)	grad_norm 5.5297 (4.8890)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:09:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:44 lr 0.000035	 wd 0.0000	time 0.2427 (0.2739)	loss 1.4265 (1.3497)	grad_norm 4.2132 (4.9049)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:10:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:02:17 lr 0.000035	 wd 0.0000	time 0.2358 (0.2742)	loss 1.2892 (1.3497)	grad_norm 7.2285 (4.8858)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:10:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:49 lr 0.000035	 wd 0.0000	time 0.2346 (0.2732)	loss 1.4742 (1.3512)	grad_norm 6.5781 (4.8973)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:11:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:22 lr 0.000035	 wd 0.0000	time 0.2306 (0.2721)	loss 0.9761 (1.3517)	grad_norm 5.3133 (4.8759)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:11:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:55 lr 0.000035	 wd 0.0000	time 0.2332 (0.2734)	loss 1.4629 (1.3510)	grad_norm 12.9268 (4.8891)	loss_scale 2048.0000 (1025.7801)	mem 10200MB
[2024-07-02 12:12:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:27 lr 0.000035	 wd 0.0000	time 0.2358 (0.2724)	loss 1.4294 (1.3512)	grad_norm 5.0512 (nan)	loss_scale 1024.0000 (1052.1483)	mem 10200MB
[2024-07-02 12:12:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.2201 (0.2714)	loss 1.5081 (1.3506)	grad_norm 5.9142 (nan)	loss_scale 1024.0000 (1051.0228)	mem 10200MB
[2024-07-02 12:12:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 10 training takes 0:11:22
[2024-07-02 12:12:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 16.568 (16.568)	Loss 0.4302 (0.4302)	Acc@1 91.602 (91.602)	Acc@5 98.438 (98.438)	Mem 10200MB
[2024-07-02 12:13:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.328 Acc@5 97.338
[2024-07-02 12:13:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-02 12:13:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.33%
[2024-07-02 12:13:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 12:13:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 12:13:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][0/2502]	eta 10:55:41 lr 0.000035	 wd 0.0000	time 15.7242 (15.7242)	loss 1.5086 (1.5086)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:13:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:16:32 lr 0.000035	 wd 0.0000	time 0.2252 (0.4132)	loss 1.3256 (1.3431)	grad_norm 5.9730 (5.3702)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:14:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:12:53 lr 0.000034	 wd 0.0000	time 0.2391 (0.3361)	loss 1.5241 (1.3467)	grad_norm 6.0993 (5.1491)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:14:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:11:52 lr 0.000034	 wd 0.0000	time 0.2401 (0.3237)	loss 1.2462 (1.3478)	grad_norm 3.9582 (4.9881)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:15:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:10:47 lr 0.000034	 wd 0.0000	time 0.2229 (0.3079)	loss 1.4612 (1.3523)	grad_norm 4.7936 (4.9437)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:15:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:09:57 lr 0.000034	 wd 0.0000	time 0.2562 (0.2984)	loss 1.3075 (1.3452)	grad_norm 3.4458 (5.0039)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:16:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:09:13 lr 0.000034	 wd 0.0000	time 0.2270 (0.2909)	loss 1.4322 (1.3433)	grad_norm 3.8155 (4.9351)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:16:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:08:48 lr 0.000034	 wd 0.0000	time 0.2172 (0.2934)	loss 1.3772 (1.3433)	grad_norm 3.9084 (4.9014)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:16:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:08:11 lr 0.000034	 wd 0.0000	time 0.2288 (0.2888)	loss 1.6256 (1.3466)	grad_norm 3.9438 (4.8929)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:17:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:07:36 lr 0.000034	 wd 0.0000	time 0.2388 (0.2851)	loss 1.4859 (1.3469)	grad_norm 5.7523 (4.8663)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:17:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:07:04 lr 0.000034	 wd 0.0000	time 0.2570 (0.2826)	loss 1.4461 (1.3468)	grad_norm 4.0330 (4.8271)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:18:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:06:35 lr 0.000034	 wd 0.0000	time 0.5291 (0.2822)	loss 1.3916 (1.3487)	grad_norm 4.2365 (4.8291)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:18:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:06:05 lr 0.000034	 wd 0.0000	time 0.2286 (0.2810)	loss 1.5894 (1.3494)	grad_norm 3.8163 (4.8115)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:19:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:05:35 lr 0.000034	 wd 0.0000	time 0.2276 (0.2787)	loss 1.0705 (1.3480)	grad_norm 3.2917 (4.8531)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:19:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:05:07 lr 0.000034	 wd 0.0000	time 0.2422 (0.2791)	loss 0.9888 (1.3479)	grad_norm 4.2957 (4.8467)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:20:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:04:38 lr 0.000034	 wd 0.0000	time 0.2270 (0.2775)	loss 1.4146 (1.3472)	grad_norm 2.9113 (4.8460)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:20:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:04:08 lr 0.000034	 wd 0.0000	time 0.2285 (0.2758)	loss 1.2591 (1.3482)	grad_norm 13.2678 (4.8874)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:20:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:40 lr 0.000033	 wd 0.0000	time 0.2393 (0.2747)	loss 1.3792 (1.3470)	grad_norm 8.2666 (4.8814)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:21:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:03:16 lr 0.000033	 wd 0.0000	time 0.2503 (0.2792)	loss 1.3209 (1.3485)	grad_norm 3.5414 (4.9328)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:21:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:47 lr 0.000033	 wd 0.0000	time 0.2522 (0.2779)	loss 1.5173 (1.3481)	grad_norm 7.4799 (4.9136)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:22:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:02:18 lr 0.000033	 wd 0.0000	time 0.2383 (0.2767)	loss 1.2068 (1.3480)	grad_norm 2.8743 (4.9316)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:22:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:51 lr 0.000033	 wd 0.0000	time 0.2351 (0.2769)	loss 1.4059 (1.3472)	grad_norm 19.1113 (4.9490)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:23:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:23 lr 0.000033	 wd 0.0000	time 0.2272 (0.2764)	loss 1.3797 (1.3488)	grad_norm 7.1114 (4.9646)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:23:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:55 lr 0.000033	 wd 0.0000	time 0.2416 (0.2752)	loss 1.4983 (1.3481)	grad_norm 5.4794 (4.9991)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:24:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:27 lr 0.000033	 wd 0.0000	time 0.2259 (0.2740)	loss 1.3761 (1.3475)	grad_norm 3.9394 (4.9813)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:24:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000033	 wd 0.0000	time 0.2224 (0.2728)	loss 1.4024 (1.3476)	grad_norm 10.6919 (4.9953)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:24:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 11 training takes 0:11:36
[2024-07-02 12:25:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 17.375 (17.375)	Loss 0.4202 (0.4202)	Acc@1 91.797 (91.797)	Acc@5 98.242 (98.242)	Mem 10200MB
[2024-07-02 12:25:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.398 Acc@5 97.368
[2024-07-02 12:25:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.4%
[2024-07-02 12:25:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.40%
[2024-07-02 12:25:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 12:25:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 12:25:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][0/2502]	eta 10:39:55 lr 0.000033	 wd 0.0000	time 15.3457 (15.3457)	loss 1.6312 (1.6312)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:25:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:16:01 lr 0.000033	 wd 0.0000	time 0.2595 (0.4005)	loss 1.5010 (1.3426)	grad_norm 3.0425 (5.3067)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:26:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:13:14 lr 0.000033	 wd 0.0000	time 0.2374 (0.3451)	loss 0.9100 (1.3480)	grad_norm 3.1337 (5.3549)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:26:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:11:41 lr 0.000033	 wd 0.0000	time 0.2163 (0.3188)	loss 1.3051 (1.3482)	grad_norm 3.8416 (5.2655)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:27:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:10:36 lr 0.000033	 wd 0.0000	time 0.2338 (0.3030)	loss 1.3074 (1.3423)	grad_norm 3.0294 (5.1954)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:27:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:09:47 lr 0.000032	 wd 0.0000	time 0.2399 (0.2935)	loss 1.0832 (1.3441)	grad_norm 3.2900 (5.1176)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:28:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:09:10 lr 0.000032	 wd 0.0000	time 0.2154 (0.2895)	loss 1.3574 (1.3411)	grad_norm 3.4517 (5.0784)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:28:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:08:36 lr 0.000032	 wd 0.0000	time 0.2452 (0.2866)	loss 1.4075 (1.3409)	grad_norm 3.4265 (5.0647)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:29:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:08:00 lr 0.000032	 wd 0.0000	time 0.2357 (0.2823)	loss 1.6409 (1.3505)	grad_norm 4.9477 (5.0713)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:29:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:07:31 lr 0.000032	 wd 0.0000	time 0.2358 (0.2816)	loss 1.0506 (1.3522)	grad_norm 14.7833 (5.0292)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:29:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:59 lr 0.000032	 wd 0.0000	time 0.2497 (0.2790)	loss 1.3816 (1.3507)	grad_norm 3.8857 (5.0152)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:30:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:06:28 lr 0.000032	 wd 0.0000	time 0.2389 (0.2768)	loss 1.4622 (1.3559)	grad_norm 4.4126 (5.0789)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:30:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:57 lr 0.000032	 wd 0.0000	time 0.2547 (0.2746)	loss 1.5932 (1.3543)	grad_norm 7.4978 (5.0254)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:31:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:05:32 lr 0.000032	 wd 0.0000	time 0.2209 (0.2765)	loss 1.5370 (1.3544)	grad_norm 4.0370 (5.0170)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:31:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:05:03 lr 0.000032	 wd 0.0000	time 0.2415 (0.2750)	loss 1.5369 (1.3542)	grad_norm 3.7019 (5.0013)	loss_scale 2048.0000 (1054.6981)	mem 10200MB
[2024-07-02 12:32:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:04:34 lr 0.000032	 wd 0.0000	time 0.2881 (0.2736)	loss 1.4497 (1.3550)	grad_norm 3.4315 (4.9970)	loss_scale 2048.0000 (1120.8741)	mem 10200MB
[2024-07-02 12:32:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:04:08 lr 0.000032	 wd 0.0000	time 0.2455 (0.2755)	loss 1.4821 (1.3530)	grad_norm 3.1599 (5.0028)	loss_scale 2048.0000 (1178.7833)	mem 10200MB
[2024-07-02 12:33:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:42 lr 0.000031	 wd 0.0000	time 0.2404 (0.2776)	loss 1.4098 (1.3542)	grad_norm 3.4508 (5.0143)	loss_scale 2048.0000 (1229.8836)	mem 10200MB
[2024-07-02 12:33:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:03:13 lr 0.000031	 wd 0.0000	time 0.2457 (0.2763)	loss 1.3434 (1.3550)	grad_norm 9.8764 (5.0247)	loss_scale 2048.0000 (1275.3093)	mem 10200MB
[2024-07-02 12:33:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:45 lr 0.000031	 wd 0.0000	time 0.2341 (0.2750)	loss 1.2875 (1.3547)	grad_norm 6.4257 (5.0152)	loss_scale 2048.0000 (1315.9558)	mem 10200MB
[2024-07-02 12:34:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:02:19 lr 0.000031	 wd 0.0000	time 0.2276 (0.2775)	loss 1.3843 (1.3541)	grad_norm 4.6731 (5.0340)	loss_scale 2048.0000 (1352.5397)	mem 10200MB
[2024-07-02 12:34:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:51 lr 0.000031	 wd 0.0000	time 0.2310 (0.2774)	loss 1.4990 (1.3547)	grad_norm 4.3371 (nan)	loss_scale 1024.0000 (1373.9438)	mem 10200MB
[2024-07-02 12:35:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:23 lr 0.000031	 wd 0.0000	time 0.2442 (0.2762)	loss 1.4703 (1.3552)	grad_norm 6.0198 (nan)	loss_scale 1024.0000 (1358.0445)	mem 10200MB
[2024-07-02 12:35:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:55 lr 0.000031	 wd 0.0000	time 0.2721 (0.2762)	loss 1.3314 (1.3547)	grad_norm 4.2865 (nan)	loss_scale 1024.0000 (1343.5272)	mem 10200MB
[2024-07-02 12:36:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:28 lr 0.000031	 wd 0.0000	time 0.2325 (0.2771)	loss 1.5575 (1.3544)	grad_norm 3.3015 (nan)	loss_scale 1024.0000 (1330.2191)	mem 10200MB
[2024-07-02 12:36:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000031	 wd 0.0000	time 0.2182 (0.2759)	loss 1.1011 (1.3529)	grad_norm 4.2868 (nan)	loss_scale 1024.0000 (1317.9752)	mem 10200MB
[2024-07-02 12:36:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 12 training takes 0:11:33
[2024-07-02 12:37:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 17.567 (17.567)	Loss 0.4204 (0.4204)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 10200MB
[2024-07-02 12:37:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.386 Acc@5 97.372
[2024-07-02 12:37:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.4%
[2024-07-02 12:37:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.40%
[2024-07-02 12:37:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][0/2502]	eta 13:22:20 lr 0.000031	 wd 0.0000	time 19.2409 (19.2409)	loss 1.3052 (1.3052)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:38:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:17:53 lr 0.000031	 wd 0.0000	time 0.2381 (0.4470)	loss 1.4849 (1.3424)	grad_norm 4.6944 (5.1221)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:38:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:13:45 lr 0.000031	 wd 0.0000	time 0.2423 (0.3587)	loss 1.5933 (1.3442)	grad_norm 3.4900 (5.1030)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:38:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:11:53 lr 0.000031	 wd 0.0000	time 0.2318 (0.3242)	loss 1.5318 (1.3504)	grad_norm 6.7267 (4.9372)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:39:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:10:54 lr 0.000030	 wd 0.0000	time 0.2502 (0.3116)	loss 1.4347 (1.3485)	grad_norm 3.9758 (4.9050)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:39:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:10:02 lr 0.000030	 wd 0.0000	time 0.2448 (0.3008)	loss 1.4480 (1.3430)	grad_norm 4.7432 (4.9858)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:40:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:09:22 lr 0.000030	 wd 0.0000	time 0.2489 (0.2960)	loss 1.4714 (1.3477)	grad_norm 3.9286 (5.0454)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:40:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:08:44 lr 0.000030	 wd 0.0000	time 0.6840 (0.2911)	loss 1.6577 (1.3439)	grad_norm 6.0873 (5.0385)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:41:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:08:13 lr 0.000030	 wd 0.0000	time 0.2217 (0.2899)	loss 1.4943 (1.3470)	grad_norm 4.3785 (4.9910)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:41:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:07:37 lr 0.000030	 wd 0.0000	time 0.2420 (0.2858)	loss 1.5733 (1.3431)	grad_norm 4.4993 (4.9567)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:41:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:07:03 lr 0.000030	 wd 0.0000	time 0.2478 (0.2823)	loss 1.4870 (1.3457)	grad_norm 3.2268 (4.9159)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:42:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:06:35 lr 0.000030	 wd 0.0000	time 0.2691 (0.2821)	loss 1.4489 (1.3475)	grad_norm 4.1733 (4.8970)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:42:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:06:05 lr 0.000030	 wd 0.0000	time 0.2364 (0.2805)	loss 1.6563 (1.3447)	grad_norm 4.0672 (4.9012)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:43:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:05:34 lr 0.000030	 wd 0.0000	time 0.2238 (0.2785)	loss 1.5168 (1.3440)	grad_norm 3.4116 (4.9030)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:43:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:05:04 lr 0.000030	 wd 0.0000	time 0.2471 (0.2765)	loss 1.6427 (1.3447)	grad_norm 11.3626 (4.9001)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:44:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:04:40 lr 0.000030	 wd 0.0000	time 0.2230 (0.2798)	loss 1.5199 (1.3441)	grad_norm 7.9380 (4.8991)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 12:44:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:04:11 lr 0.000029	 wd 0.0000	time 0.2470 (0.2784)	loss 1.4756 (1.3438)	grad_norm 3.9072 (nan)	loss_scale 512.0000 (1002.2536)	mem 10200MB
[2024-07-02 12:45:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:42 lr 0.000029	 wd 0.0000	time 0.2284 (0.2770)	loss 0.8788 (1.3413)	grad_norm 4.3286 (nan)	loss_scale 512.0000 (973.4321)	mem 10200MB
[2024-07-02 12:45:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:03:14 lr 0.000029	 wd 0.0000	time 0.2134 (0.2771)	loss 1.3161 (1.3427)	grad_norm 3.5345 (nan)	loss_scale 512.0000 (947.8112)	mem 10200MB
[2024-07-02 12:46:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:49 lr 0.000029	 wd 0.0000	time 0.2455 (0.2813)	loss 1.1449 (1.3428)	grad_norm 7.7120 (nan)	loss_scale 512.0000 (924.8858)	mem 10200MB
[2024-07-02 12:46:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:02:20 lr 0.000029	 wd 0.0000	time 0.2409 (0.2801)	loss 1.3992 (1.3434)	grad_norm 3.4003 (nan)	loss_scale 512.0000 (904.2519)	mem 10200MB
[2024-07-02 12:47:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:51 lr 0.000029	 wd 0.0000	time 0.2273 (0.2785)	loss 1.1306 (1.3429)	grad_norm 4.4023 (nan)	loss_scale 512.0000 (885.5821)	mem 10200MB
[2024-07-02 12:47:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:24 lr 0.000029	 wd 0.0000	time 0.3278 (0.2793)	loss 1.5184 (1.3447)	grad_norm 4.5336 (nan)	loss_scale 512.0000 (868.6088)	mem 10200MB
[2024-07-02 12:47:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:56 lr 0.000029	 wd 0.0000	time 0.2291 (0.2786)	loss 1.3408 (1.3437)	grad_norm 5.0276 (nan)	loss_scale 512.0000 (853.1108)	mem 10200MB
[2024-07-02 12:48:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:28 lr 0.000029	 wd 0.0000	time 0.2403 (0.2779)	loss 1.4726 (1.3444)	grad_norm 7.3892 (nan)	loss_scale 512.0000 (838.9038)	mem 10200MB
[2024-07-02 12:48:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000029	 wd 0.0000	time 0.2213 (0.2764)	loss 1.4401 (1.3439)	grad_norm 3.7217 (nan)	loss_scale 512.0000 (825.8329)	mem 10200MB
[2024-07-02 12:49:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 13 training takes 0:11:45
[2024-07-02 12:49:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 17.120 (17.120)	Loss 0.4143 (0.4143)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 10200MB
[2024-07-02 12:49:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.446 Acc@5 97.454
[2024-07-02 12:49:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.4%
[2024-07-02 12:49:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.45%
[2024-07-02 12:49:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 12:49:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 12:49:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][0/2502]	eta 10:57:15 lr 0.000029	 wd 0.0000	time 15.7616 (15.7616)	loss 1.5469 (1.5469)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:50:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:16:16 lr 0.000029	 wd 0.0000	time 0.2294 (0.4064)	loss 1.4871 (1.3392)	grad_norm 3.2665 (4.2655)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:50:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:13:15 lr 0.000028	 wd 0.0000	time 0.2632 (0.3456)	loss 1.2414 (1.3635)	grad_norm 3.0771 (4.4157)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:51:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:11:34 lr 0.000028	 wd 0.0000	time 0.2424 (0.3154)	loss 1.1258 (1.3516)	grad_norm 7.7354 (4.6328)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:51:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:10:30 lr 0.000028	 wd 0.0000	time 0.2445 (0.3002)	loss 1.1969 (1.3397)	grad_norm 4.2797 (4.6948)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:51:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:09:43 lr 0.000028	 wd 0.0000	time 0.2397 (0.2913)	loss 1.4195 (1.3408)	grad_norm 9.2034 (4.8286)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:52:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:09:11 lr 0.000028	 wd 0.0000	time 0.2463 (0.2898)	loss 1.5977 (1.3444)	grad_norm 5.8154 (4.8447)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:52:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:08:33 lr 0.000028	 wd 0.0000	time 0.2328 (0.2849)	loss 1.3250 (1.3409)	grad_norm 3.4545 (4.8995)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:53:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:57 lr 0.000028	 wd 0.0000	time 0.2408 (0.2808)	loss 1.3151 (1.3380)	grad_norm 2.9653 (4.9778)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:53:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:07:25 lr 0.000028	 wd 0.0000	time 0.2140 (0.2780)	loss 1.5754 (1.3362)	grad_norm 3.8554 (4.9382)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:54:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:07:03 lr 0.000028	 wd 0.0000	time 0.2227 (0.2822)	loss 1.1331 (1.3346)	grad_norm 3.4659 (4.9093)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:54:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:06:32 lr 0.000028	 wd 0.0000	time 0.2303 (0.2800)	loss 1.3936 (1.3320)	grad_norm 4.4273 (4.9141)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:55:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:06:01 lr 0.000028	 wd 0.0000	time 0.2309 (0.2776)	loss 1.5150 (1.3322)	grad_norm 3.5515 (4.9531)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:55:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:05:34 lr 0.000027	 wd 0.0000	time 0.2452 (0.2785)	loss 1.2112 (1.3335)	grad_norm 3.8221 (4.9453)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:56:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:05:05 lr 0.000027	 wd 0.0000	time 0.2365 (0.2775)	loss 1.4444 (1.3328)	grad_norm 5.2399 (4.9562)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:56:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:04:36 lr 0.000027	 wd 0.0000	time 0.2298 (0.2760)	loss 1.3538 (1.3336)	grad_norm 3.0912 (4.9833)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:56:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:04:08 lr 0.000027	 wd 0.0000	time 0.2357 (0.2758)	loss 1.3434 (1.3346)	grad_norm 5.5294 (4.9799)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:57:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:40 lr 0.000027	 wd 0.0000	time 0.2381 (0.2754)	loss 1.2086 (1.3350)	grad_norm 5.0881 (4.9468)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:57:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:03:12 lr 0.000027	 wd 0.0000	time 0.2137 (0.2741)	loss 1.2622 (1.3344)	grad_norm 3.8794 (4.9296)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:58:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:44 lr 0.000027	 wd 0.0000	time 0.2465 (0.2730)	loss 1.4285 (1.3343)	grad_norm 3.9411 (4.9286)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:58:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:02:16 lr 0.000027	 wd 0.0000	time 0.2464 (0.2718)	loss 1.0156 (1.3358)	grad_norm 4.7892 (4.9228)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:59:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:49 lr 0.000027	 wd 0.0000	time 0.2441 (0.2735)	loss 1.6194 (1.3349)	grad_norm 9.6246 (4.9320)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:59:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:22 lr 0.000027	 wd 0.0000	time 0.2570 (0.2732)	loss 1.2633 (1.3352)	grad_norm 2.8594 (4.9491)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 12:59:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:54 lr 0.000027	 wd 0.0000	time 0.2330 (0.2721)	loss 1.3364 (1.3361)	grad_norm 4.3068 (4.9620)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:00:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:27 lr 0.000026	 wd 0.0000	time 0.2445 (0.2714)	loss 1.2554 (1.3372)	grad_norm 5.0900 (4.9409)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:00:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.2443 (0.2708)	loss 1.3628 (1.3362)	grad_norm 9.0463 (4.9620)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:00:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 14 training takes 0:11:23
[2024-07-02 13:01:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 19.202 (19.202)	Loss 0.4141 (0.4141)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 10200MB
[2024-07-02 13:01:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.522 Acc@5 97.444
[2024-07-02 13:01:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.5%
[2024-07-02 13:01:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.52%
[2024-07-02 13:01:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 13:01:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 13:01:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][0/2502]	eta 9:53:14 lr 0.000026	 wd 0.0000	time 14.2263 (14.2263)	loss 1.3420 (1.3420)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:02:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:16:36 lr 0.000026	 wd 0.0000	time 0.2390 (0.4148)	loss 1.0771 (1.3248)	grad_norm 3.8806 (4.7468)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:02:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:12:48 lr 0.000026	 wd 0.0000	time 0.2194 (0.3340)	loss 1.4344 (1.3374)	grad_norm 3.4444 (5.0515)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:03:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:11:19 lr 0.000026	 wd 0.0000	time 0.2416 (0.3087)	loss 1.3644 (1.3236)	grad_norm 3.2498 (5.1872)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:03:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:10:19 lr 0.000026	 wd 0.0000	time 0.2233 (0.2945)	loss 1.3321 (1.3266)	grad_norm 5.0190 (5.1779)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:03:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:09:41 lr 0.000026	 wd 0.0000	time 0.2384 (0.2907)	loss 0.8894 (1.3215)	grad_norm 3.8095 (5.0602)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:04:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:09:03 lr 0.000026	 wd 0.0000	time 0.2448 (0.2860)	loss 0.8778 (1.3251)	grad_norm 5.1460 (5.1900)	loss_scale 1024.0000 (573.3378)	mem 10200MB
[2024-07-02 13:04:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:08:27 lr 0.000026	 wd 0.0000	time 0.2689 (0.2815)	loss 1.1291 (1.3285)	grad_norm 5.1453 (5.2187)	loss_scale 1024.0000 (637.6262)	mem 10200MB
[2024-07-02 13:05:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:07:52 lr 0.000026	 wd 0.0000	time 0.2491 (0.2775)	loss 1.5106 (1.3296)	grad_norm 3.5589 (5.2443)	loss_scale 1024.0000 (685.8627)	mem 10200MB
[2024-07-02 13:05:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:07:28 lr 0.000025	 wd 0.0000	time 0.2327 (0.2800)	loss 1.1588 (1.3291)	grad_norm 5.2885 (5.5468)	loss_scale 1024.0000 (723.3918)	mem 10200MB
[2024-07-02 13:06:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:06:57 lr 0.000025	 wd 0.0000	time 0.2294 (0.2778)	loss 1.3227 (1.3294)	grad_norm 3.4259 (5.4750)	loss_scale 1024.0000 (753.4226)	mem 10200MB
[2024-07-02 13:06:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:06:26 lr 0.000025	 wd 0.0000	time 0.2344 (0.2755)	loss 1.3324 (1.3265)	grad_norm 4.3930 (5.5203)	loss_scale 1024.0000 (777.9982)	mem 10200MB
[2024-07-02 13:07:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:06:01 lr 0.000025	 wd 0.0000	time 0.2152 (0.2774)	loss 1.5494 (1.3267)	grad_norm 3.5620 (5.5845)	loss_scale 1024.0000 (798.4813)	mem 10200MB
[2024-07-02 13:07:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:05:31 lr 0.000025	 wd 0.0000	time 0.2431 (0.2759)	loss 1.3834 (1.3253)	grad_norm 4.7458 (5.4951)	loss_scale 1024.0000 (815.8155)	mem 10200MB
[2024-07-02 13:07:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:05:02 lr 0.000025	 wd 0.0000	time 0.2598 (0.2746)	loss 1.3151 (1.3260)	grad_norm 4.0546 (5.4261)	loss_scale 1024.0000 (830.6752)	mem 10200MB
[2024-07-02 13:08:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:04:33 lr 0.000025	 wd 0.0000	time 0.2372 (0.2729)	loss 1.5974 (1.3254)	grad_norm 5.4075 (5.3597)	loss_scale 1024.0000 (843.5550)	mem 10200MB
[2024-07-02 13:08:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:04:06 lr 0.000025	 wd 0.0000	time 0.2315 (0.2730)	loss 1.1961 (1.3279)	grad_norm 4.1531 (5.3025)	loss_scale 1024.0000 (854.8257)	mem 10200MB
[2024-07-02 13:09:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:37 lr 0.000025	 wd 0.0000	time 0.2286 (0.2718)	loss 1.5362 (1.3284)	grad_norm 4.6915 (5.3086)	loss_scale 1024.0000 (864.7713)	mem 10200MB
[2024-07-02 13:09:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:03:10 lr 0.000025	 wd 0.0000	time 0.2221 (0.2707)	loss 1.0708 (1.3282)	grad_norm 3.8360 (5.3151)	loss_scale 1024.0000 (873.6124)	mem 10200MB
[2024-07-02 13:10:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:42 lr 0.000024	 wd 0.0000	time 0.2406 (0.2695)	loss 1.5876 (1.3292)	grad_norm 6.4641 (5.2912)	loss_scale 1024.0000 (881.5234)	mem 10200MB
[2024-07-02 13:10:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:02:15 lr 0.000024	 wd 0.0000	time 0.2419 (0.2693)	loss 1.7446 (1.3320)	grad_norm 3.4864 (5.2567)	loss_scale 1024.0000 (888.6437)	mem 10200MB
[2024-07-02 13:10:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:47 lr 0.000024	 wd 0.0000	time 0.2278 (0.2684)	loss 1.6168 (1.3327)	grad_norm 5.4746 (5.2602)	loss_scale 1024.0000 (895.0861)	mem 10200MB
[2024-07-02 13:11:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:20 lr 0.000024	 wd 0.0000	time 0.2459 (0.2675)	loss 0.9081 (1.3338)	grad_norm 4.0899 (5.2504)	loss_scale 1024.0000 (900.9432)	mem 10200MB
[2024-07-02 13:11:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:53 lr 0.000024	 wd 0.0000	time 0.2371 (0.2666)	loss 1.5016 (1.3342)	grad_norm 8.1264 (5.2615)	loss_scale 1024.0000 (906.2912)	mem 10200MB
[2024-07-02 13:12:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:27 lr 0.000024	 wd 0.0000	time 0.2420 (0.2667)	loss 1.1674 (1.3332)	grad_norm 6.6380 (5.2420)	loss_scale 1024.0000 (911.1937)	mem 10200MB
[2024-07-02 13:12:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.2251 (0.2658)	loss 1.3868 (1.3334)	grad_norm 3.0274 (5.2159)	loss_scale 1024.0000 (915.7041)	mem 10200MB
[2024-07-02 13:12:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 15 training takes 0:11:09
[2024-07-02 13:12:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_15.pth saving......
[2024-07-02 13:12:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_15.pth saved !!!
[2024-07-02 13:12:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 16.078 (16.078)	Loss 0.4058 (0.4058)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 10200MB
[2024-07-02 13:13:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.498 Acc@5 97.442
[2024-07-02 13:13:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.5%
[2024-07-02 13:13:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.52%
[2024-07-02 13:13:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][0/2502]	eta 11:06:09 lr 0.000024	 wd 0.0000	time 15.9750 (15.9750)	loss 1.1982 (1.1982)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:13:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:18:53 lr 0.000024	 wd 0.0000	time 0.2136 (0.4717)	loss 1.4588 (1.3383)	grad_norm 4.1646 (4.9185)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:14:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:13:55 lr 0.000024	 wd 0.0000	time 0.2538 (0.3631)	loss 1.2882 (1.3439)	grad_norm 3.8664 (4.8032)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:14:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:12:12 lr 0.000024	 wd 0.0000	time 0.2394 (0.3325)	loss 1.3223 (1.3526)	grad_norm 3.7652 (4.9762)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:15:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:11:00 lr 0.000024	 wd 0.0000	time 0.2406 (0.3143)	loss 1.2205 (1.3474)	grad_norm 4.2344 (5.1299)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:15:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:10:04 lr 0.000023	 wd 0.0000	time 0.2566 (0.3021)	loss 1.3488 (1.3552)	grad_norm 7.2017 (5.1636)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:16:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:09:19 lr 0.000023	 wd 0.0000	time 0.2304 (0.2944)	loss 1.0685 (1.3463)	grad_norm 3.3806 (5.2801)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:16:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:08:40 lr 0.000023	 wd 0.0000	time 0.2384 (0.2886)	loss 1.3064 (1.3481)	grad_norm 3.5151 (5.2403)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:16:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:08:14 lr 0.000023	 wd 0.0000	time 0.2440 (0.2906)	loss 1.3081 (1.3419)	grad_norm 4.0608 (5.1684)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:17:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:07:39 lr 0.000023	 wd 0.0000	time 0.2424 (0.2869)	loss 1.3202 (1.3409)	grad_norm 4.5188 (5.1488)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:17:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:07:05 lr 0.000023	 wd 0.0000	time 0.2231 (0.2834)	loss 1.4633 (1.3410)	grad_norm 4.5062 (5.1693)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:18:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:06:33 lr 0.000023	 wd 0.0000	time 0.2358 (0.2805)	loss 1.3336 (1.3430)	grad_norm 4.0244 (5.1590)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:18:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:06:13 lr 0.000023	 wd 0.0000	time 0.2430 (0.2869)	loss 1.4900 (1.3424)	grad_norm 3.4276 (5.1242)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:19:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:05:41 lr 0.000023	 wd 0.0000	time 0.2390 (0.2843)	loss 1.0601 (1.3425)	grad_norm 5.0542 (5.1638)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:19:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:05:10 lr 0.000023	 wd 0.0000	time 0.2366 (0.2821)	loss 1.2744 (1.3401)	grad_norm 3.9895 (5.1836)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:20:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:04:44 lr 0.000022	 wd 0.0000	time 0.2137 (0.2844)	loss 1.3799 (1.3375)	grad_norm 5.9929 (5.2087)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:20:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:04:14 lr 0.000022	 wd 0.0000	time 0.2369 (0.2824)	loss 1.3982 (1.3368)	grad_norm 4.8799 (5.2249)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:21:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:45 lr 0.000022	 wd 0.0000	time 0.2353 (0.2807)	loss 1.0541 (1.3350)	grad_norm 5.4185 (5.1887)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:21:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:03:15 lr 0.000022	 wd 0.0000	time 0.2263 (0.2788)	loss 1.0945 (1.3339)	grad_norm 3.2703 (5.1996)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:21:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:48 lr 0.000022	 wd 0.0000	time 0.2414 (0.2802)	loss 1.3049 (1.3333)	grad_norm 4.4364 (5.1640)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:22:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:02:19 lr 0.000022	 wd 0.0000	time 0.2413 (0.2787)	loss 1.5348 (1.3332)	grad_norm 2.8139 (5.1639)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 13:22:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:51 lr 0.000022	 wd 0.0000	time 0.2375 (0.2777)	loss 1.4119 (1.3326)	grad_norm 4.1769 (5.1675)	loss_scale 2048.0000 (1060.0666)	mem 10200MB
[2024-07-02 13:23:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:23 lr 0.000022	 wd 0.0000	time 0.2267 (0.2767)	loss 1.3313 (1.3333)	grad_norm 3.4469 (5.1529)	loss_scale 2048.0000 (1104.9523)	mem 10200MB
[2024-07-02 13:23:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:55 lr 0.000022	 wd 0.0000	time 0.2391 (0.2759)	loss 1.2590 (1.3335)	grad_norm 3.9489 (5.1489)	loss_scale 2048.0000 (1145.9365)	mem 10200MB
[2024-07-02 13:24:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:28 lr 0.000022	 wd 0.0000	time 0.2304 (0.2749)	loss 1.2887 (1.3333)	grad_norm 4.5856 (5.1404)	loss_scale 2048.0000 (1183.5069)	mem 10200MB
[2024-07-02 13:24:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.2168 (0.2736)	loss 1.4034 (1.3331)	grad_norm 3.7051 (5.1251)	loss_scale 2048.0000 (1218.0728)	mem 10200MB
[2024-07-02 13:24:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 16 training takes 0:11:27
[2024-07-02 13:25:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 27.580 (27.580)	Loss 0.4182 (0.4182)	Acc@1 91.797 (91.797)	Acc@5 98.242 (98.242)	Mem 10200MB
[2024-07-02 13:25:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.530 Acc@5 97.418
[2024-07-02 13:25:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.5%
[2024-07-02 13:25:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.53%
[2024-07-02 13:25:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 13:25:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 13:25:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][0/2502]	eta 10:05:44 lr 0.000021	 wd 0.0000	time 14.5260 (14.5260)	loss 1.4060 (1.4060)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:25:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:15:53 lr 0.000021	 wd 0.0000	time 0.2628 (0.3969)	loss 1.5406 (1.3118)	grad_norm 4.4841 (5.4072)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:26:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:12:32 lr 0.000021	 wd 0.0000	time 0.2342 (0.3270)	loss 1.5162 (1.3257)	grad_norm 6.1790 (5.1067)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:26:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:11:36 lr 0.000021	 wd 0.0000	time 0.2254 (0.3161)	loss 1.3818 (1.3231)	grad_norm 4.9479 (5.0816)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:27:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:10:31 lr 0.000021	 wd 0.0000	time 0.2377 (0.3006)	loss 1.0964 (1.3223)	grad_norm 4.7372 (5.0396)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:27:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:09:46 lr 0.000021	 wd 0.0000	time 0.2225 (0.2931)	loss 1.3200 (1.3201)	grad_norm 3.7737 (5.0419)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:28:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:09:04 lr 0.000021	 wd 0.0000	time 0.2937 (0.2863)	loss 1.1490 (1.3254)	grad_norm 3.5175 (5.0261)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:28:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:08:35 lr 0.000021	 wd 0.0000	time 0.2212 (0.2863)	loss 1.3245 (1.3295)	grad_norm 4.6855 (5.0736)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:29:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:08:02 lr 0.000021	 wd 0.0000	time 0.2395 (0.2836)	loss 1.2976 (1.3327)	grad_norm 6.0213 (5.1323)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:29:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:07:28 lr 0.000021	 wd 0.0000	time 0.2334 (0.2800)	loss 1.4317 (1.3349)	grad_norm 5.2326 (5.0921)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:29:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:59 lr 0.000020	 wd 0.0000	time 0.2643 (0.2790)	loss 1.5036 (1.3331)	grad_norm 5.0036 (5.0469)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:30:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:06:28 lr 0.000020	 wd 0.0000	time 0.2359 (0.2772)	loss 1.1328 (1.3314)	grad_norm 3.0293 (4.9964)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:30:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:58 lr 0.000020	 wd 0.0000	time 0.2299 (0.2753)	loss 1.3990 (1.3336)	grad_norm 5.0390 (5.0345)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:31:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:05:28 lr 0.000020	 wd 0.0000	time 0.2389 (0.2736)	loss 1.2295 (1.3334)	grad_norm 4.8508 (5.0303)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:31:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:05:00 lr 0.000020	 wd 0.0000	time 0.2203 (0.2728)	loss 1.4617 (1.3337)	grad_norm 4.1776 (5.0246)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:32:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:04:32 lr 0.000020	 wd 0.0000	time 0.2590 (0.2715)	loss 1.5095 (1.3343)	grad_norm 3.2407 (4.9998)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:32:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:04:03 lr 0.000020	 wd 0.0000	time 0.2195 (0.2705)	loss 1.4027 (1.3353)	grad_norm 10.1907 (4.9875)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:32:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:35 lr 0.000020	 wd 0.0000	time 0.2534 (0.2692)	loss 1.5587 (1.3367)	grad_norm 4.8301 (4.9666)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:33:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:03:09 lr 0.000020	 wd 0.0000	time 0.2154 (0.2706)	loss 1.4040 (1.3371)	grad_norm 4.5347 (4.9498)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:33:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:42 lr 0.000020	 wd 0.0000	time 0.2291 (0.2703)	loss 1.2296 (1.3376)	grad_norm 3.7989 (4.9521)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:34:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:02:15 lr 0.000019	 wd 0.0000	time 0.2519 (0.2693)	loss 1.4085 (1.3353)	grad_norm 5.2449 (4.9349)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:34:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:47 lr 0.000019	 wd 0.0000	time 0.2317 (0.2683)	loss 1.4958 (1.3351)	grad_norm 3.3358 (4.9209)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:35:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:21 lr 0.000019	 wd 0.0000	time 0.2234 (0.2684)	loss 1.3068 (1.3357)	grad_norm 3.5463 (4.9139)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:35:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:54 lr 0.000019	 wd 0.0000	time 0.2395 (0.2677)	loss 1.5521 (1.3348)	grad_norm 3.8334 (4.9200)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:35:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:27 lr 0.000019	 wd 0.0000	time 0.2185 (0.2669)	loss 1.3844 (1.3330)	grad_norm 3.4661 (4.9161)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:36:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000019	 wd 0.0000	time 0.2229 (0.2660)	loss 1.3218 (1.3339)	grad_norm 3.8115 (4.8943)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:36:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 17 training takes 0:11:17
[2024-07-02 13:36:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 17.030 (17.030)	Loss 0.4102 (0.4102)	Acc@1 91.992 (91.992)	Acc@5 98.242 (98.242)	Mem 10200MB
[2024-07-02 13:36:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.506 Acc@5 97.432
[2024-07-02 13:36:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.5%
[2024-07-02 13:36:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.53%
[2024-07-02 13:37:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][0/2502]	eta 11:35:15 lr 0.000019	 wd 0.0000	time 16.6731 (16.6731)	loss 1.5608 (1.5608)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:37:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:16:45 lr 0.000019	 wd 0.0000	time 0.2378 (0.4186)	loss 1.5560 (1.3689)	grad_norm 5.6069 (5.0215)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:38:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:13:17 lr 0.000019	 wd 0.0000	time 0.2328 (0.3465)	loss 1.5634 (1.3448)	grad_norm 4.6798 (4.7717)	loss_scale 2048.0000 (2048.0000)	mem 10200MB
[2024-07-02 13:38:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:11:36 lr 0.000019	 wd 0.0000	time 0.2276 (0.3161)	loss 1.5327 (1.3421)	grad_norm 3.6486 (nan)	loss_scale 1024.0000 (1809.8605)	mem 10200MB
[2024-07-02 13:39:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:10:31 lr 0.000019	 wd 0.0000	time 0.2370 (0.3004)	loss 1.3608 (1.3396)	grad_norm 6.0868 (nan)	loss_scale 1024.0000 (1613.8853)	mem 10200MB
[2024-07-02 13:39:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:09:41 lr 0.000018	 wd 0.0000	time 0.2656 (0.2906)	loss 1.2224 (1.3331)	grad_norm 4.1609 (nan)	loss_scale 1024.0000 (1496.1437)	mem 10200MB
[2024-07-02 13:39:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:09:05 lr 0.000018	 wd 0.0000	time 0.2251 (0.2867)	loss 1.5742 (1.3322)	grad_norm 3.2693 (nan)	loss_scale 1024.0000 (1417.5840)	mem 10200MB
[2024-07-02 13:40:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:08:28 lr 0.000018	 wd 0.0000	time 0.2288 (0.2820)	loss 1.5535 (1.3339)	grad_norm 3.9987 (nan)	loss_scale 1024.0000 (1361.4379)	mem 10200MB
[2024-07-02 13:40:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:54 lr 0.000018	 wd 0.0000	time 0.2494 (0.2787)	loss 1.0865 (1.3305)	grad_norm 4.4423 (nan)	loss_scale 1024.0000 (1319.3109)	mem 10200MB
[2024-07-02 13:41:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:07:21 lr 0.000018	 wd 0.0000	time 0.2344 (0.2755)	loss 1.3737 (1.3275)	grad_norm 6.2916 (nan)	loss_scale 1024.0000 (1286.5350)	mem 10200MB
[2024-07-02 13:41:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:56 lr 0.000018	 wd 0.0000	time 0.3140 (0.2773)	loss 1.0996 (1.3314)	grad_norm 5.0246 (nan)	loss_scale 512.0000 (1240.8711)	mem 10200MB
[2024-07-02 13:42:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:06:25 lr 0.000018	 wd 0.0000	time 0.2350 (0.2752)	loss 1.3164 (1.3305)	grad_norm 9.1978 (nan)	loss_scale 512.0000 (1174.6703)	mem 10200MB
[2024-07-02 13:42:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:55 lr 0.000018	 wd 0.0000	time 0.2192 (0.2733)	loss 1.4924 (1.3307)	grad_norm 3.7065 (nan)	loss_scale 512.0000 (1119.4938)	mem 10200MB
[2024-07-02 13:42:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:05:26 lr 0.000018	 wd 0.0000	time 0.2346 (0.2720)	loss 1.5544 (1.3315)	grad_norm 3.8228 (nan)	loss_scale 512.0000 (1072.7994)	mem 10200MB
[2024-07-02 13:43:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:05:00 lr 0.000018	 wd 0.0000	time 0.2322 (0.2724)	loss 1.1773 (1.3308)	grad_norm 3.8585 (nan)	loss_scale 512.0000 (1032.7709)	mem 10200MB
[2024-07-02 13:43:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:04:31 lr 0.000017	 wd 0.0000	time 0.2430 (0.2710)	loss 1.4950 (1.3291)	grad_norm 5.7457 (nan)	loss_scale 512.0000 (998.0759)	mem 10200MB
[2024-07-02 13:44:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:04:03 lr 0.000017	 wd 0.0000	time 0.2388 (0.2700)	loss 1.5754 (1.3290)	grad_norm 4.7657 (nan)	loss_scale 512.0000 (967.7152)	mem 10200MB
[2024-07-02 13:44:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:37 lr 0.000017	 wd 0.0000	time 0.2256 (0.2716)	loss 1.4398 (1.3278)	grad_norm 4.4308 (nan)	loss_scale 512.0000 (940.9242)	mem 10200MB
[2024-07-02 13:45:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:03:09 lr 0.000017	 wd 0.0000	time 0.2432 (0.2706)	loss 1.3384 (1.3293)	grad_norm 3.4467 (nan)	loss_scale 512.0000 (917.1083)	mem 10200MB
[2024-07-02 13:45:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:42 lr 0.000017	 wd 0.0000	time 0.6373 (0.2699)	loss 1.5267 (1.3294)	grad_norm 3.1436 (nan)	loss_scale 512.0000 (895.7980)	mem 10200MB
[2024-07-02 13:45:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:02:14 lr 0.000017	 wd 0.0000	time 0.2347 (0.2687)	loss 1.4161 (1.3312)	grad_norm 3.4631 (nan)	loss_scale 512.0000 (876.6177)	mem 10200MB
[2024-07-02 13:46:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:48 lr 0.000017	 wd 0.0000	time 0.2570 (0.2705)	loss 1.3553 (1.3306)	grad_norm 4.0109 (nan)	loss_scale 512.0000 (859.2632)	mem 10200MB
[2024-07-02 13:46:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:21 lr 0.000017	 wd 0.0000	time 0.2215 (0.2696)	loss 1.3807 (1.3304)	grad_norm 3.7900 (nan)	loss_scale 512.0000 (843.4857)	mem 10200MB
[2024-07-02 13:47:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:54 lr 0.000017	 wd 0.0000	time 0.2270 (0.2688)	loss 1.4262 (1.3305)	grad_norm 3.9709 (nan)	loss_scale 512.0000 (829.0795)	mem 10200MB
[2024-07-02 13:47:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:27 lr 0.000017	 wd 0.0000	time 0.2714 (0.2685)	loss 1.4860 (1.3320)	grad_norm 3.2533 (nan)	loss_scale 512.0000 (815.8734)	mem 10200MB
[2024-07-02 13:48:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.2170 (0.2684)	loss 1.5017 (1.3317)	grad_norm 4.0787 (nan)	loss_scale 512.0000 (803.7233)	mem 10200MB
[2024-07-02 13:48:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 18 training takes 0:11:17
[2024-07-02 13:48:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 16.928 (16.928)	Loss 0.4023 (0.4023)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 10200MB
[2024-07-02 13:48:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.528 Acc@5 97.444
[2024-07-02 13:48:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.5%
[2024-07-02 13:48:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.53%
[2024-07-02 13:49:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][0/2502]	eta 11:10:34 lr 0.000016	 wd 0.0000	time 16.0811 (16.0811)	loss 1.4706 (1.4706)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:49:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:17:17 lr 0.000016	 wd 0.0000	time 0.2414 (0.4319)	loss 1.1067 (1.3391)	grad_norm 3.6523 (4.7266)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:49:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:13:12 lr 0.000016	 wd 0.0000	time 0.2399 (0.3443)	loss 1.5216 (1.3360)	grad_norm 9.1145 (4.7376)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:50:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:11:31 lr 0.000016	 wd 0.0000	time 0.2344 (0.3139)	loss 1.3351 (1.3454)	grad_norm 3.7528 (5.0364)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:50:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:10:26 lr 0.000016	 wd 0.0000	time 0.2335 (0.2981)	loss 1.4784 (1.3448)	grad_norm 3.6925 (5.2210)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:51:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:09:47 lr 0.000016	 wd 0.0000	time 0.2578 (0.2934)	loss 1.5901 (1.3426)	grad_norm 4.3689 (5.1573)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:51:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:09:14 lr 0.000016	 wd 0.0000	time 0.2328 (0.2913)	loss 1.5432 (1.3379)	grad_norm 4.0125 (5.1387)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:52:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:08:35 lr 0.000016	 wd 0.0000	time 0.2579 (0.2860)	loss 1.6161 (1.3396)	grad_norm 3.8547 (5.1374)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:52:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:07:59 lr 0.000016	 wd 0.0000	time 0.2406 (0.2816)	loss 1.2822 (1.3363)	grad_norm 4.8963 (5.1936)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:53:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:07:34 lr 0.000016	 wd 0.0000	time 0.2682 (0.2835)	loss 1.4159 (1.3376)	grad_norm 3.9910 (5.1837)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:53:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:07:02 lr 0.000016	 wd 0.0000	time 0.2403 (0.2813)	loss 1.4940 (1.3397)	grad_norm 24.2813 (5.2304)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:53:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:06:30 lr 0.000015	 wd 0.0000	time 0.2569 (0.2787)	loss 0.8807 (1.3380)	grad_norm 3.6284 (5.1708)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:54:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:06:00 lr 0.000015	 wd 0.0000	time 0.2394 (0.2767)	loss 1.0856 (1.3355)	grad_norm 6.6366 (5.1685)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:54:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:05:34 lr 0.000015	 wd 0.0000	time 0.2258 (0.2787)	loss 1.4022 (1.3355)	grad_norm 3.8944 (5.1098)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:55:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:05:05 lr 0.000015	 wd 0.0000	time 0.2278 (0.2774)	loss 1.3708 (1.3368)	grad_norm 3.5194 (5.0975)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:55:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:04:35 lr 0.000015	 wd 0.0000	time 0.2368 (0.2754)	loss 1.2155 (1.3366)	grad_norm 4.8538 (5.1088)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:56:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:04:11 lr 0.000015	 wd 0.0000	time 0.2321 (0.2791)	loss 1.3375 (1.3373)	grad_norm 4.0196 (5.0773)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:56:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:42 lr 0.000015	 wd 0.0000	time 0.2174 (0.2776)	loss 1.4874 (1.3379)	grad_norm 3.7536 (5.0966)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:57:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:03:13 lr 0.000015	 wd 0.0000	time 0.2203 (0.2761)	loss 1.3034 (1.3378)	grad_norm 3.9070 (5.0544)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:57:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:45 lr 0.000015	 wd 0.0000	time 0.2281 (0.2747)	loss 1.3125 (1.3381)	grad_norm 5.0713 (5.0481)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:57:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:02:18 lr 0.000015	 wd 0.0000	time 0.2394 (0.2758)	loss 0.9880 (1.3374)	grad_norm 7.1263 (5.0322)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:58:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:50 lr 0.000014	 wd 0.0000	time 0.2190 (0.2746)	loss 1.1559 (1.3367)	grad_norm 4.7018 (5.0205)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:58:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:22 lr 0.000014	 wd 0.0000	time 0.2398 (0.2736)	loss 1.4498 (1.3349)	grad_norm 7.0348 (5.0273)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:59:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:55 lr 0.000014	 wd 0.0000	time 0.2662 (0.2731)	loss 1.3834 (1.3341)	grad_norm 4.2121 (5.0531)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 13:59:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:27 lr 0.000014	 wd 0.0000	time 0.2339 (0.2732)	loss 1.5043 (1.3351)	grad_norm 3.5875 (5.0393)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:00:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.2240 (0.2725)	loss 1.2434 (1.3351)	grad_norm 3.5887 (5.0280)	loss_scale 1024.0000 (520.1887)	mem 10200MB
[2024-07-02 14:00:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 19 training takes 0:11:25
[2024-07-02 14:00:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 18.184 (18.184)	Loss 0.4053 (0.4053)	Acc@1 92.383 (92.383)	Acc@5 98.242 (98.242)	Mem 10200MB
[2024-07-02 14:00:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.582 Acc@5 97.410
[2024-07-02 14:00:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-02 14:00:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.58%
[2024-07-02 14:00:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 14:00:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 14:01:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][0/2502]	eta 18:56:29 lr 0.000014	 wd 0.0000	time 27.2539 (27.2539)	loss 1.0762 (1.0762)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:01:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:21:11 lr 0.000014	 wd 0.0000	time 0.2599 (0.5295)	loss 1.6929 (1.3282)	grad_norm 4.1790 (4.6328)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:01:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:14:59 lr 0.000014	 wd 0.0000	time 0.2411 (0.3909)	loss 1.3907 (1.3343)	grad_norm 6.0003 (4.7495)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:02:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:12:37 lr 0.000014	 wd 0.0000	time 0.2255 (0.3441)	loss 1.4188 (1.3330)	grad_norm 2.9857 (4.8294)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:02:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:11:32 lr 0.000014	 wd 0.0000	time 0.2252 (0.3292)	loss 1.5009 (1.3397)	grad_norm 11.3519 (5.1189)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:03:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:10:28 lr 0.000014	 wd 0.0000	time 0.2549 (0.3138)	loss 1.3460 (1.3382)	grad_norm 3.8478 (5.0940)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:03:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:09:37 lr 0.000014	 wd 0.0000	time 0.2238 (0.3038)	loss 1.4306 (1.3339)	grad_norm 3.4218 (5.0108)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:04:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:09:04 lr 0.000013	 wd 0.0000	time 0.2499 (0.3021)	loss 1.4395 (1.3393)	grad_norm 4.2273 (5.0341)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:04:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:08:27 lr 0.000013	 wd 0.0000	time 0.2545 (0.2981)	loss 1.2519 (1.3366)	grad_norm 3.8245 (5.0461)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:05:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:07:50 lr 0.000013	 wd 0.0000	time 0.2533 (0.2935)	loss 1.5922 (1.3394)	grad_norm 6.4368 (5.1281)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:05:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:07:14 lr 0.000013	 wd 0.0000	time 0.2348 (0.2894)	loss 1.3298 (1.3389)	grad_norm 4.0870 (5.1511)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:05:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:06:42 lr 0.000013	 wd 0.0000	time 0.2365 (0.2870)	loss 1.4182 (1.3361)	grad_norm 8.7448 (5.1347)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:06:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:06:10 lr 0.000013	 wd 0.0000	time 0.2372 (0.2848)	loss 1.3708 (1.3332)	grad_norm 6.2449 (5.1323)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:06:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:05:39 lr 0.000013	 wd 0.0000	time 0.2501 (0.2825)	loss 1.1600 (1.3298)	grad_norm 3.9105 (5.0856)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:07:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:05:08 lr 0.000013	 wd 0.0000	time 0.2290 (0.2803)	loss 1.3415 (1.3314)	grad_norm 4.4505 (5.0869)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:07:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:04:40 lr 0.000013	 wd 0.0000	time 0.2333 (0.2801)	loss 1.2371 (1.3328)	grad_norm 4.0969 (5.0877)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:08:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:04:11 lr 0.000013	 wd 0.0000	time 0.2246 (0.2788)	loss 1.5280 (1.3334)	grad_norm 4.5836 (5.1378)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:08:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:42 lr 0.000012	 wd 0.0000	time 0.2258 (0.2776)	loss 1.5491 (1.3331)	grad_norm 3.4881 (inf)	loss_scale 512.0000 (1000.5220)	mem 10200MB
[2024-07-02 14:08:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:03:13 lr 0.000012	 wd 0.0000	time 0.2698 (0.2759)	loss 1.3062 (1.3321)	grad_norm 3.4839 (inf)	loss_scale 512.0000 (973.3970)	mem 10200MB
[2024-07-02 14:09:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:47 lr 0.000012	 wd 0.0000	time 0.2175 (0.2778)	loss 1.5994 (1.3327)	grad_norm 3.0046 (inf)	loss_scale 512.0000 (949.1257)	mem 10200MB
[2024-07-02 14:09:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:02:18 lr 0.000012	 wd 0.0000	time 0.2335 (0.2766)	loss 1.4500 (1.3320)	grad_norm 4.9118 (inf)	loss_scale 512.0000 (927.2804)	mem 10200MB
[2024-07-02 14:10:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:50 lr 0.000012	 wd 0.0000	time 0.2334 (0.2753)	loss 1.3974 (1.3327)	grad_norm 9.3000 (inf)	loss_scale 512.0000 (907.5145)	mem 10200MB
[2024-07-02 14:10:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:23 lr 0.000012	 wd 0.0000	time 0.2984 (0.2777)	loss 1.2594 (1.3340)	grad_norm 5.1806 (inf)	loss_scale 512.0000 (889.5448)	mem 10200MB
[2024-07-02 14:11:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:55 lr 0.000012	 wd 0.0000	time 0.2492 (0.2767)	loss 1.2962 (1.3343)	grad_norm 3.9763 (inf)	loss_scale 512.0000 (873.1369)	mem 10200MB
[2024-07-02 14:11:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:28 lr 0.000012	 wd 0.0000	time 0.2443 (0.2757)	loss 1.2263 (1.3346)	grad_norm 4.3454 (inf)	loss_scale 512.0000 (858.0958)	mem 10200MB
[2024-07-02 14:12:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000012	 wd 0.0000	time 0.2197 (0.2744)	loss 1.4416 (1.3353)	grad_norm 4.3305 (inf)	loss_scale 512.0000 (844.2575)	mem 10200MB
[2024-07-02 14:12:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 20 training takes 0:11:30
[2024-07-02 14:12:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 19.305 (19.305)	Loss 0.4114 (0.4114)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 10200MB
[2024-07-02 14:12:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.582 Acc@5 97.486
[2024-07-02 14:12:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-02 14:12:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.58%
[2024-07-02 14:12:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 14:12:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 14:12:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][0/2502]	eta 10:15:55 lr 0.000012	 wd 0.0000	time 14.7702 (14.7702)	loss 1.5366 (1.5366)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:13:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:15:55 lr 0.000012	 wd 0.0000	time 0.2284 (0.3979)	loss 1.5528 (1.3657)	grad_norm 8.5584 (4.9082)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:13:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:12:39 lr 0.000012	 wd 0.0000	time 0.2375 (0.3299)	loss 0.9516 (1.3369)	grad_norm 7.8950 (4.9535)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:14:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:11:12 lr 0.000012	 wd 0.0000	time 0.2440 (0.3055)	loss 1.4003 (1.3292)	grad_norm 5.2131 (5.0231)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:14:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:10:13 lr 0.000011	 wd 0.0000	time 0.2198 (0.2916)	loss 1.3239 (1.3314)	grad_norm 4.3295 (5.0749)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:15:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:09:30 lr 0.000011	 wd 0.0000	time 0.2647 (0.2851)	loss 1.2973 (1.3305)	grad_norm 5.3722 (5.0073)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:15:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:56 lr 0.000011	 wd 0.0000	time 0.6503 (0.2822)	loss 1.2065 (1.3322)	grad_norm 4.7780 (5.2091)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:16:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:08:23 lr 0.000011	 wd 0.0000	time 0.2531 (0.2793)	loss 1.2681 (1.3265)	grad_norm 4.2356 (5.1704)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:16:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:50 lr 0.000011	 wd 0.0000	time 0.2365 (0.2763)	loss 1.2370 (1.3247)	grad_norm 5.4239 (5.1219)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:16:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:07:18 lr 0.000011	 wd 0.0000	time 0.2561 (0.2736)	loss 1.5501 (1.3240)	grad_norm 4.9462 (5.1092)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:17:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:48 lr 0.000011	 wd 0.0000	time 0.2634 (0.2721)	loss 1.0738 (1.3230)	grad_norm 3.0558 (5.0931)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:17:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:06:19 lr 0.000011	 wd 0.0000	time 0.2278 (0.2706)	loss 1.4077 (1.3232)	grad_norm 3.8490 (5.0817)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:18:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:50 lr 0.000011	 wd 0.0000	time 0.2363 (0.2690)	loss 1.3697 (1.3234)	grad_norm 3.3329 (5.0772)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:18:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:05:21 lr 0.000011	 wd 0.0000	time 0.2282 (0.2676)	loss 1.5085 (1.3227)	grad_norm 2.8935 (5.0634)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:18:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:54 lr 0.000011	 wd 0.0000	time 0.2303 (0.2674)	loss 1.3012 (1.3233)	grad_norm 5.1295 (5.0855)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:19:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:04:27 lr 0.000010	 wd 0.0000	time 0.2509 (0.2665)	loss 1.6280 (1.3228)	grad_norm 5.8304 (5.0961)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:19:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:59 lr 0.000010	 wd 0.0000	time 0.2177 (0.2657)	loss 1.2528 (1.3222)	grad_norm 4.5907 (5.1005)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:20:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:32 lr 0.000010	 wd 0.0000	time 0.2311 (0.2646)	loss 1.4641 (1.3230)	grad_norm 4.7355 (5.1030)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:20:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:03:05 lr 0.000010	 wd 0.0000	time 0.2295 (0.2649)	loss 1.0852 (1.3238)	grad_norm 5.1110 (5.1163)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:21:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:39 lr 0.000010	 wd 0.0000	time 0.2413 (0.2644)	loss 1.0638 (1.3222)	grad_norm 3.4780 (5.0909)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:21:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:02:12 lr 0.000010	 wd 0.0000	time 0.2486 (0.2637)	loss 1.3652 (1.3219)	grad_norm 5.3812 (5.0928)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:21:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:45 lr 0.000010	 wd 0.0000	time 0.2434 (0.2629)	loss 1.1651 (1.3235)	grad_norm 4.1388 (5.0863)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:22:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:19 lr 0.000010	 wd 0.0000	time 0.2277 (0.2643)	loss 1.5871 (1.3218)	grad_norm 5.1635 (5.0809)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:22:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:53 lr 0.000010	 wd 0.0000	time 0.2245 (0.2637)	loss 1.5932 (1.3209)	grad_norm 6.5301 (5.0622)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:23:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:26 lr 0.000010	 wd 0.0000	time 0.2351 (0.2633)	loss 1.3470 (1.3224)	grad_norm 2.9178 (5.0475)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:23:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.2243 (0.2625)	loss 1.4044 (1.3218)	grad_norm 6.7796 (5.0451)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:23:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 21 training takes 0:11:12
[2024-07-02 14:24:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 16.714 (16.714)	Loss 0.4048 (0.4048)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 10200MB
[2024-07-02 14:24:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.626 Acc@5 97.440
[2024-07-02 14:24:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-02 14:24:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.63%
[2024-07-02 14:24:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 14:24:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 14:24:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][0/2502]	eta 10:43:38 lr 0.000010	 wd 0.0000	time 15.4349 (15.4349)	loss 1.2402 (1.2402)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:25:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:17:23 lr 0.000010	 wd 0.0000	time 0.2489 (0.4345)	loss 1.3410 (1.3429)	grad_norm 3.8741 (5.2226)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:25:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:13:50 lr 0.000009	 wd 0.0000	time 0.2576 (0.3606)	loss 1.0105 (1.3291)	grad_norm 4.4497 (5.0539)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:26:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:11:56 lr 0.000009	 wd 0.0000	time 0.2650 (0.3252)	loss 1.4684 (1.3341)	grad_norm 5.8695 (4.9729)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:26:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:10:51 lr 0.000009	 wd 0.0000	time 0.2459 (0.3097)	loss 1.3143 (1.3377)	grad_norm 6.5181 (4.9082)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:26:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:09:55 lr 0.000009	 wd 0.0000	time 0.2517 (0.2976)	loss 1.0093 (1.3367)	grad_norm 3.7448 (4.9536)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:27:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:09:17 lr 0.000009	 wd 0.0000	time 0.2579 (0.2933)	loss 1.4417 (1.3370)	grad_norm 4.4326 (4.9214)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 14:27:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:08:39 lr 0.000009	 wd 0.0000	time 0.2501 (0.2881)	loss 0.9002 (1.3308)	grad_norm 5.0726 (4.8802)	loss_scale 1024.0000 (571.8916)	mem 10200MB
[2024-07-02 14:28:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:08:02 lr 0.000009	 wd 0.0000	time 0.2269 (0.2836)	loss 1.2755 (1.3264)	grad_norm 3.9966 (4.8586)	loss_scale 1024.0000 (628.3346)	mem 10200MB
[2024-07-02 14:28:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:07:30 lr 0.000009	 wd 0.0000	time 0.2330 (0.2811)	loss 1.3018 (1.3245)	grad_norm 6.6409 (5.0242)	loss_scale 1024.0000 (672.2486)	mem 10200MB
[2024-07-02 14:29:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:07:00 lr 0.000009	 wd 0.0000	time 0.2300 (0.2800)	loss 1.4840 (1.3264)	grad_norm 5.2525 (4.9899)	loss_scale 1024.0000 (707.3886)	mem 10200MB
[2024-07-02 14:29:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:06:29 lr 0.000009	 wd 0.0000	time 0.2413 (0.2776)	loss 1.3426 (1.3250)	grad_norm 5.4754 (4.9873)	loss_scale 1024.0000 (736.1453)	mem 10200MB
[2024-07-02 14:29:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:59 lr 0.000009	 wd 0.0000	time 0.2341 (0.2758)	loss 1.2939 (1.3238)	grad_norm 4.5699 (5.0353)	loss_scale 1024.0000 (760.1132)	mem 10200MB
[2024-07-02 14:30:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:05:33 lr 0.000009	 wd 0.0000	time 0.2333 (0.2776)	loss 0.9768 (1.3247)	grad_norm 4.4747 (5.0487)	loss_scale 1024.0000 (780.3966)	mem 10200MB
[2024-07-02 14:30:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:05:04 lr 0.000008	 wd 0.0000	time 0.2478 (0.2765)	loss 1.4848 (1.3264)	grad_norm 8.1286 (5.0258)	loss_scale 1024.0000 (797.7844)	mem 10200MB
[2024-07-02 14:31:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:04:35 lr 0.000008	 wd 0.0000	time 0.2480 (0.2748)	loss 1.1642 (1.3269)	grad_norm 3.1034 (4.9948)	loss_scale 1024.0000 (812.8554)	mem 10200MB
[2024-07-02 14:31:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:04:06 lr 0.000008	 wd 0.0000	time 0.2156 (0.2732)	loss 1.5178 (1.3267)	grad_norm 4.3759 (5.0105)	loss_scale 1024.0000 (826.0437)	mem 10200MB
[2024-07-02 14:32:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:39 lr 0.000008	 wd 0.0000	time 0.3304 (0.2737)	loss 1.2786 (1.3259)	grad_norm 12.7200 (5.0738)	loss_scale 1024.0000 (837.6814)	mem 10200MB
[2024-07-02 14:32:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:03:11 lr 0.000008	 wd 0.0000	time 0.2785 (0.2731)	loss 1.5792 (1.3257)	grad_norm 9.1570 (5.0532)	loss_scale 1024.0000 (848.0267)	mem 10200MB
[2024-07-02 14:33:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:43 lr 0.000008	 wd 0.0000	time 0.2320 (0.2720)	loss 1.5202 (1.3250)	grad_norm 5.3784 (5.0468)	loss_scale 1024.0000 (857.2835)	mem 10200MB
[2024-07-02 14:33:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:02:16 lr 0.000008	 wd 0.0000	time 0.2663 (0.2719)	loss 1.4111 (1.3240)	grad_norm 2.6925 (5.0820)	loss_scale 1024.0000 (865.6152)	mem 10200MB
[2024-07-02 14:33:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:49 lr 0.000008	 wd 0.0000	time 0.2265 (0.2723)	loss 1.4558 (1.3245)	grad_norm 6.6793 (5.0656)	loss_scale 1024.0000 (873.1537)	mem 10200MB
[2024-07-02 14:34:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:21 lr 0.000008	 wd 0.0000	time 0.2379 (0.2714)	loss 1.4528 (1.3236)	grad_norm 4.2624 (5.0508)	loss_scale 1024.0000 (880.0073)	mem 10200MB
[2024-07-02 14:34:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:54 lr 0.000008	 wd 0.0000	time 0.2364 (0.2705)	loss 1.5387 (1.3236)	grad_norm 6.0582 (5.0558)	loss_scale 1024.0000 (886.2651)	mem 10200MB
[2024-07-02 14:35:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:27 lr 0.000008	 wd 0.0000	time 0.2357 (0.2701)	loss 1.0558 (1.3231)	grad_norm 3.2124 (5.0520)	loss_scale 1024.0000 (892.0017)	mem 10200MB
[2024-07-02 14:35:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.2147 (0.2695)	loss 1.0524 (1.3222)	grad_norm 4.6335 (5.0445)	loss_scale 1024.0000 (897.2795)	mem 10200MB
[2024-07-02 14:35:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 22 training takes 0:11:23
[2024-07-02 14:36:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 16.709 (16.709)	Loss 0.4060 (0.4060)	Acc@1 92.383 (92.383)	Acc@5 98.242 (98.242)	Mem 10200MB
[2024-07-02 14:36:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.640 Acc@5 97.458
[2024-07-02 14:36:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-02 14:36:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.64%
[2024-07-02 14:36:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 14:36:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 14:36:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][0/2502]	eta 9:49:02 lr 0.000008	 wd 0.0000	time 14.1257 (14.1257)	loss 1.0809 (1.0809)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:37:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:17:53 lr 0.000008	 wd 0.0000	time 0.2329 (0.4468)	loss 1.4447 (1.3608)	grad_norm 10.0566 (5.5958)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:37:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:13:39 lr 0.000007	 wd 0.0000	time 0.2363 (0.3561)	loss 1.4922 (1.3402)	grad_norm 3.7352 (5.4162)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:38:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:11:50 lr 0.000007	 wd 0.0000	time 0.2292 (0.3224)	loss 1.3356 (1.3354)	grad_norm 4.5951 (5.1836)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:38:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:10:41 lr 0.000007	 wd 0.0000	time 0.2332 (0.3053)	loss 1.6824 (1.3306)	grad_norm 4.2893 (5.3784)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:38:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:09:51 lr 0.000007	 wd 0.0000	time 0.2309 (0.2957)	loss 1.5607 (1.3343)	grad_norm 3.9146 (5.3159)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:39:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:09:10 lr 0.000007	 wd 0.0000	time 0.2292 (0.2897)	loss 1.1775 (1.3343)	grad_norm 3.0636 (5.1685)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:39:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:08:33 lr 0.000007	 wd 0.0000	time 0.2443 (0.2851)	loss 1.4834 (1.3313)	grad_norm 4.0169 (5.0867)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:40:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:08:01 lr 0.000007	 wd 0.0000	time 0.3987 (0.2827)	loss 1.6647 (1.3290)	grad_norm 6.8205 (5.1116)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:40:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:07:28 lr 0.000007	 wd 0.0000	time 0.2579 (0.2800)	loss 1.6263 (1.3260)	grad_norm 6.3695 (5.0422)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:41:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:56 lr 0.000007	 wd 0.0000	time 0.2382 (0.2773)	loss 1.0634 (1.3254)	grad_norm 6.2145 (5.0473)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:41:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:06:25 lr 0.000007	 wd 0.0000	time 0.2267 (0.2748)	loss 0.8175 (1.3202)	grad_norm 3.9331 (5.0624)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:41:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:06:00 lr 0.000007	 wd 0.0000	time 0.2444 (0.2765)	loss 1.5160 (1.3218)	grad_norm 4.2820 (5.0946)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:42:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:05:31 lr 0.000007	 wd 0.0000	time 0.2202 (0.2756)	loss 1.4960 (1.3230)	grad_norm 4.7613 (5.1455)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:42:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:05:01 lr 0.000007	 wd 0.0000	time 0.2280 (0.2739)	loss 1.3308 (1.3224)	grad_norm 5.2827 (5.1223)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:43:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:04:34 lr 0.000006	 wd 0.0000	time 0.2284 (0.2742)	loss 1.1913 (1.3240)	grad_norm 16.1951 (5.2131)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:43:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:04:08 lr 0.000006	 wd 0.0000	time 0.2358 (0.2759)	loss 1.2072 (1.3239)	grad_norm 3.6186 (5.1962)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:44:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:40 lr 0.000006	 wd 0.0000	time 0.2413 (0.2748)	loss 1.3296 (1.3243)	grad_norm 3.8836 (5.1799)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:44:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:03:11 lr 0.000006	 wd 0.0000	time 0.2347 (0.2734)	loss 1.3479 (1.3237)	grad_norm 3.4838 (5.1879)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:45:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:46 lr 0.000006	 wd 0.0000	time 0.2357 (0.2763)	loss 1.1770 (1.3259)	grad_norm 6.8710 (5.1839)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:45:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:02:18 lr 0.000006	 wd 0.0000	time 0.2360 (0.2760)	loss 1.3402 (1.3246)	grad_norm 6.0334 (5.1894)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:46:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:50 lr 0.000006	 wd 0.0000	time 0.2359 (0.2749)	loss 1.6202 (1.3246)	grad_norm 4.7403 (5.1694)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:46:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:22 lr 0.000006	 wd 0.0000	time 0.2323 (0.2736)	loss 1.4609 (1.3221)	grad_norm 3.4753 (5.1732)	loss_scale 2048.0000 (1063.0804)	mem 10200MB
[2024-07-02 14:46:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:55 lr 0.000006	 wd 0.0000	time 0.2287 (0.2753)	loss 1.4811 (1.3218)	grad_norm 4.8595 (inf)	loss_scale 1024.0000 (1091.6436)	mem 10200MB
[2024-07-02 14:47:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:28 lr 0.000006	 wd 0.0000	time 0.2724 (0.2748)	loss 1.5287 (1.3225)	grad_norm 2.7359 (inf)	loss_scale 1024.0000 (1088.8263)	mem 10200MB
[2024-07-02 14:47:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000006	 wd 0.0000	time 0.2229 (0.2735)	loss 1.4076 (1.3232)	grad_norm 5.3320 (inf)	loss_scale 1024.0000 (1086.2343)	mem 10200MB
[2024-07-02 14:47:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 23 training takes 0:11:31
[2024-07-02 14:48:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 33.096 (33.096)	Loss 0.4077 (0.4077)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 10200MB
[2024-07-02 14:48:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.670 Acc@5 97.464
[2024-07-02 14:48:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 14:48:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.67%
[2024-07-02 14:48:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 14:48:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 14:49:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][0/2502]	eta 10:37:01 lr 0.000006	 wd 0.0000	time 15.2766 (15.2766)	loss 1.5434 (1.5434)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:49:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:16:06 lr 0.000006	 wd 0.0000	time 0.2213 (0.4023)	loss 1.2047 (1.3567)	grad_norm 3.8458 (5.4196)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:49:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:13:05 lr 0.000006	 wd 0.0000	time 0.2531 (0.3412)	loss 1.6003 (1.3443)	grad_norm 4.3636 (5.1976)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:50:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:11:38 lr 0.000006	 wd 0.0000	time 0.2621 (0.3170)	loss 1.5797 (1.3339)	grad_norm 4.0629 (5.3091)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:50:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:10:31 lr 0.000005	 wd 0.0000	time 0.2244 (0.3006)	loss 1.4190 (1.3279)	grad_norm 6.7296 (5.1973)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:51:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:09:41 lr 0.000005	 wd 0.0000	time 0.2312 (0.2907)	loss 1.5240 (1.3297)	grad_norm 5.3754 (5.1198)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:51:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:09:14 lr 0.000005	 wd 0.0000	time 0.2381 (0.2916)	loss 1.3193 (1.3252)	grad_norm 3.9938 (5.0023)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:52:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:08:44 lr 0.000005	 wd 0.0000	time 0.2373 (0.2913)	loss 1.2918 (1.3269)	grad_norm 3.0250 (4.9611)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:52:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:08:07 lr 0.000005	 wd 0.0000	time 0.2208 (0.2863)	loss 1.3848 (1.3280)	grad_norm 5.4023 (4.9973)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:53:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:07:32 lr 0.000005	 wd 0.0000	time 0.2401 (0.2824)	loss 1.4284 (1.3261)	grad_norm 3.8735 (4.9538)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:53:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:07:02 lr 0.000005	 wd 0.0000	time 0.2370 (0.2810)	loss 1.3115 (1.3262)	grad_norm 5.0612 (4.9119)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:53:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:06:32 lr 0.000005	 wd 0.0000	time 0.2321 (0.2798)	loss 1.4678 (1.3246)	grad_norm 5.8492 (4.9132)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:54:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:06:01 lr 0.000005	 wd 0.0000	time 0.2337 (0.2778)	loss 1.1406 (1.3232)	grad_norm 3.7091 (4.9368)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:54:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:05:33 lr 0.000005	 wd 0.0000	time 0.3156 (0.2775)	loss 1.2482 (1.3241)	grad_norm 4.4106 (4.9683)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:55:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:05:03 lr 0.000005	 wd 0.0000	time 0.2266 (0.2758)	loss 1.2282 (1.3227)	grad_norm 6.5813 (4.9639)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:55:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:34 lr 0.000005	 wd 0.0000	time 0.2385 (0.2741)	loss 0.9843 (1.3215)	grad_norm 4.2717 (4.9629)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:56:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:04:06 lr 0.000005	 wd 0.0000	time 0.2196 (0.2728)	loss 1.3805 (1.3209)	grad_norm 6.7224 (4.9739)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:56:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:38 lr 0.000005	 wd 0.0000	time 0.2457 (0.2722)	loss 1.6941 (1.3231)	grad_norm 5.4472 (4.9675)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:56:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:03:10 lr 0.000005	 wd 0.0000	time 0.2202 (0.2712)	loss 1.1547 (1.3224)	grad_norm 4.7814 (4.9664)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:57:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:42 lr 0.000005	 wd 0.0000	time 0.2237 (0.2703)	loss 1.4331 (1.3235)	grad_norm 3.3002 (4.9539)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:57:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:02:15 lr 0.000004	 wd 0.0000	time 0.2432 (0.2693)	loss 1.4910 (1.3235)	grad_norm 15.2727 (4.9644)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:58:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:48 lr 0.000004	 wd 0.0000	time 0.2645 (0.2704)	loss 1.4721 (1.3220)	grad_norm 4.8514 (4.9779)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:58:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:21 lr 0.000004	 wd 0.0000	time 0.2364 (0.2696)	loss 1.2344 (1.3216)	grad_norm 3.9906 (4.9604)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:59:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:54 lr 0.000004	 wd 0.0000	time 0.2291 (0.2688)	loss 1.6727 (1.3211)	grad_norm 4.6710 (4.9578)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:59:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:27 lr 0.000004	 wd 0.0000	time 0.2660 (0.2680)	loss 1.5271 (1.3212)	grad_norm 3.3536 (4.9610)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 14:59:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000004	 wd 0.0000	time 0.2193 (0.2673)	loss 1.2104 (1.3216)	grad_norm 7.5095 (4.9406)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:00:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 24 training takes 0:11:24
[2024-07-02 15:00:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 16.957 (16.957)	Loss 0.4070 (0.4070)	Acc@1 92.578 (92.578)	Acc@5 98.242 (98.242)	Mem 10200MB
[2024-07-02 15:00:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.662 Acc@5 97.472
[2024-07-02 15:00:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 15:00:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.67%
[2024-07-02 15:01:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][0/2502]	eta 10:59:01 lr 0.000004	 wd 0.0000	time 15.8038 (15.8038)	loss 1.0528 (1.0528)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:01:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:17:44 lr 0.000004	 wd 0.0000	time 0.2381 (0.4432)	loss 1.2943 (1.2901)	grad_norm 5.5885 (4.5860)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:01:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:13:22 lr 0.000004	 wd 0.0000	time 0.2419 (0.3485)	loss 1.4021 (1.3124)	grad_norm 3.7509 (5.0696)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:02:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:11:39 lr 0.000004	 wd 0.0000	time 0.2219 (0.3176)	loss 1.0302 (1.3065)	grad_norm 3.8709 (4.9031)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:02:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:10:31 lr 0.000004	 wd 0.0000	time 0.2413 (0.3004)	loss 1.2283 (1.3197)	grad_norm 3.4805 (5.2796)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:03:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:09:43 lr 0.000004	 wd 0.0000	time 0.2292 (0.2914)	loss 1.3967 (1.3208)	grad_norm 24.5203 (5.2835)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:03:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:09:02 lr 0.000004	 wd 0.0000	time 0.2292 (0.2852)	loss 1.1543 (1.3230)	grad_norm 3.3510 (5.2016)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:04:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:08:29 lr 0.000004	 wd 0.0000	time 0.2433 (0.2828)	loss 1.1963 (1.3225)	grad_norm 4.5194 (5.2578)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:04:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:07:54 lr 0.000004	 wd 0.0000	time 0.2330 (0.2790)	loss 1.0805 (1.3228)	grad_norm 4.9911 (5.2326)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:04:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:07:27 lr 0.000004	 wd 0.0000	time 0.2621 (0.2794)	loss 1.3974 (1.3251)	grad_norm 3.3905 (5.1846)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:05:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:55 lr 0.000004	 wd 0.0000	time 0.2313 (0.2768)	loss 1.3155 (1.3260)	grad_norm 4.5487 (5.1111)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:05:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:06:25 lr 0.000004	 wd 0.0000	time 0.2333 (0.2749)	loss 1.3279 (1.3237)	grad_norm 3.3467 (5.1555)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:06:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:55 lr 0.000004	 wd 0.0000	time 0.2261 (0.2732)	loss 1.2711 (1.3252)	grad_norm 4.2377 (5.1437)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:06:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:05:28 lr 0.000003	 wd 0.0000	time 0.2899 (0.2732)	loss 1.5014 (1.3254)	grad_norm 3.4332 (nan)	loss_scale 1024.0000 (1039.7417)	mem 10200MB
[2024-07-02 15:07:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:59 lr 0.000003	 wd 0.0000	time 0.2435 (0.2716)	loss 1.1792 (1.3263)	grad_norm 3.5259 (nan)	loss_scale 1024.0000 (1038.6181)	mem 10200MB
[2024-07-02 15:07:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:04:30 lr 0.000003	 wd 0.0000	time 0.2209 (0.2703)	loss 1.2349 (1.3255)	grad_norm 3.9513 (nan)	loss_scale 1024.0000 (1037.6442)	mem 10200MB
[2024-07-02 15:08:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:04:04 lr 0.000003	 wd 0.0000	time 0.2142 (0.2715)	loss 1.4838 (1.3256)	grad_norm 7.5852 (nan)	loss_scale 1024.0000 (1036.7920)	mem 10200MB
[2024-07-02 15:08:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:36 lr 0.000003	 wd 0.0000	time 0.2379 (0.2703)	loss 1.2857 (1.3256)	grad_norm 4.1806 (nan)	loss_scale 1024.0000 (1036.0400)	mem 10200MB
[2024-07-02 15:08:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:03:08 lr 0.000003	 wd 0.0000	time 0.2187 (0.2691)	loss 1.3568 (1.3248)	grad_norm 8.0028 (nan)	loss_scale 1024.0000 (1035.3715)	mem 10200MB
[2024-07-02 15:09:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:41 lr 0.000003	 wd 0.0000	time 0.2331 (0.2688)	loss 1.5760 (1.3251)	grad_norm 6.1800 (nan)	loss_scale 1024.0000 (1034.7733)	mem 10200MB
[2024-07-02 15:09:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:02:15 lr 0.000003	 wd 0.0000	time 0.2459 (0.2697)	loss 1.2668 (1.3247)	grad_norm 3.8784 (nan)	loss_scale 1024.0000 (1034.2349)	mem 10200MB
[2024-07-02 15:10:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:48 lr 0.000003	 wd 0.0000	time 0.2426 (0.2688)	loss 0.8858 (1.3250)	grad_norm 7.6289 (nan)	loss_scale 1024.0000 (1033.7477)	mem 10200MB
[2024-07-02 15:10:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:20 lr 0.000003	 wd 0.0000	time 0.2227 (0.2679)	loss 1.3804 (1.3238)	grad_norm 6.3647 (nan)	loss_scale 1024.0000 (1033.3049)	mem 10200MB
[2024-07-02 15:11:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:53 lr 0.000003	 wd 0.0000	time 0.2315 (0.2670)	loss 1.4163 (1.3224)	grad_norm 5.0159 (nan)	loss_scale 1024.0000 (1032.9005)	mem 10200MB
[2024-07-02 15:11:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:27 lr 0.000003	 wd 0.0000	time 0.2437 (0.2677)	loss 1.3881 (1.3237)	grad_norm 3.0791 (nan)	loss_scale 1024.0000 (1032.5298)	mem 10200MB
[2024-07-02 15:11:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.2240 (0.2672)	loss 1.4604 (1.3238)	grad_norm 5.2459 (nan)	loss_scale 1024.0000 (1032.1887)	mem 10200MB
[2024-07-02 15:12:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 25 training takes 0:11:18
[2024-07-02 15:12:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 16.367 (16.367)	Loss 0.4077 (0.4077)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 10200MB
[2024-07-02 15:12:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.720 Acc@5 97.490
[2024-07-02 15:12:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 15:12:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.72%
[2024-07-02 15:12:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 15:12:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 15:12:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][0/2502]	eta 10:58:25 lr 0.000003	 wd 0.0000	time 15.7896 (15.7896)	loss 1.1747 (1.1747)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:13:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:16:28 lr 0.000003	 wd 0.0000	time 0.2438 (0.4116)	loss 1.4599 (1.3158)	grad_norm 4.5548 (4.9910)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:13:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:13:13 lr 0.000003	 wd 0.0000	time 0.2225 (0.3447)	loss 1.4080 (1.3420)	grad_norm 3.9184 (4.7041)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:14:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:11:31 lr 0.000003	 wd 0.0000	time 0.2535 (0.3142)	loss 1.3133 (1.3339)	grad_norm 3.4095 (4.8606)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:14:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:10:30 lr 0.000003	 wd 0.0000	time 0.2179 (0.3000)	loss 1.6548 (1.3358)	grad_norm 3.5261 (4.9218)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:15:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:09:40 lr 0.000003	 wd 0.0000	time 0.2348 (0.2898)	loss 1.6672 (1.3425)	grad_norm 5.1461 (4.9867)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:15:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:09:00 lr 0.000003	 wd 0.0000	time 0.2308 (0.2840)	loss 1.2551 (1.3380)	grad_norm 4.6196 (4.9567)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:15:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:08:24 lr 0.000003	 wd 0.0000	time 0.2324 (0.2797)	loss 1.3770 (1.3319)	grad_norm 5.2363 (4.9845)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:16:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:07:54 lr 0.000002	 wd 0.0000	time 0.2373 (0.2786)	loss 1.4030 (1.3287)	grad_norm 5.3831 (4.9241)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:16:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:07:22 lr 0.000002	 wd 0.0000	time 0.2581 (0.2761)	loss 1.3421 (1.3302)	grad_norm 6.3913 (4.9172)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:17:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:51 lr 0.000002	 wd 0.0000	time 0.2619 (0.2737)	loss 1.4483 (1.3301)	grad_norm 3.9574 (4.9401)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:17:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:06:24 lr 0.000002	 wd 0.0000	time 0.3463 (0.2744)	loss 1.4659 (1.3319)	grad_norm 4.5645 (5.0211)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:18:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:56 lr 0.000002	 wd 0.0000	time 0.2469 (0.2740)	loss 1.0500 (1.3326)	grad_norm 5.6587 (5.0044)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:18:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:05:27 lr 0.000002	 wd 0.0000	time 0.2389 (0.2725)	loss 0.9481 (1.3304)	grad_norm 4.5552 (4.9820)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:19:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:58 lr 0.000002	 wd 0.0000	time 0.2536 (0.2710)	loss 1.7829 (1.3302)	grad_norm 3.8926 (5.0622)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:19:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:04:32 lr 0.000002	 wd 0.0000	time 0.2431 (0.2722)	loss 1.5081 (1.3289)	grad_norm 5.4936 (5.0387)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:19:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:04:05 lr 0.000002	 wd 0.0000	time 0.2518 (0.2717)	loss 1.4125 (1.3276)	grad_norm 5.1250 (5.0223)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:20:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:37 lr 0.000002	 wd 0.0000	time 0.2206 (0.2707)	loss 1.3220 (1.3281)	grad_norm 4.3067 (5.0416)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:20:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:03:09 lr 0.000002	 wd 0.0000	time 0.2248 (0.2696)	loss 1.4157 (1.3296)	grad_norm 4.1943 (5.0357)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:21:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:43 lr 0.000002	 wd 0.0000	time 0.2331 (0.2718)	loss 1.0682 (1.3277)	grad_norm 3.9777 (5.0434)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:21:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:02:15 lr 0.000002	 wd 0.0000	time 0.2277 (0.2708)	loss 1.1632 (1.3276)	grad_norm 5.8508 (5.0379)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:22:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:48 lr 0.000002	 wd 0.0000	time 0.2329 (0.2697)	loss 0.9507 (1.3261)	grad_norm 5.0597 (5.0630)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:22:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:21 lr 0.000002	 wd 0.0000	time 0.2262 (0.2691)	loss 0.8860 (1.3258)	grad_norm 3.9803 (5.0783)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:23:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:54 lr 0.000002	 wd 0.0000	time 0.2536 (0.2692)	loss 1.0859 (1.3249)	grad_norm 5.4218 (5.0579)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:23:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:27 lr 0.000002	 wd 0.0000	time 0.2382 (0.2685)	loss 1.0964 (1.3246)	grad_norm 5.2867 (5.0431)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:23:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.2251 (0.2679)	loss 1.0555 (1.3231)	grad_norm 8.0211 (5.0526)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:23:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 26 training takes 0:11:19
[2024-07-02 15:24:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 24.935 (24.935)	Loss 0.4033 (0.4033)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 10200MB
[2024-07-02 15:24:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.704 Acc@5 97.470
[2024-07-02 15:24:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 15:24:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.72%
[2024-07-02 15:24:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][0/2502]	eta 10:35:31 lr 0.000002	 wd 0.0000	time 15.2405 (15.2405)	loss 0.9185 (0.9185)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:25:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:16:30 lr 0.000002	 wd 0.0000	time 0.2442 (0.4123)	loss 1.4295 (1.3398)	grad_norm 5.1958 (5.1360)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:25:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:13:10 lr 0.000002	 wd 0.0000	time 0.2715 (0.3432)	loss 1.4876 (1.3295)	grad_norm 5.1943 (4.9422)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:26:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:11:38 lr 0.000002	 wd 0.0000	time 0.2321 (0.3172)	loss 1.2637 (1.3219)	grad_norm 6.5742 (4.9226)	loss_scale 2048.0000 (1092.0399)	mem 10200MB
[2024-07-02 15:26:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:10:34 lr 0.000002	 wd 0.0000	time 0.2498 (0.3020)	loss 1.3214 (1.3217)	grad_norm 3.9988 (4.9636)	loss_scale 2048.0000 (1330.4339)	mem 10200MB
[2024-07-02 15:27:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:09:43 lr 0.000002	 wd 0.0000	time 0.2395 (0.2914)	loss 0.8300 (1.3151)	grad_norm 3.6884 (4.8866)	loss_scale 2048.0000 (1473.6607)	mem 10200MB
[2024-07-02 15:27:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:09:04 lr 0.000002	 wd 0.0000	time 0.2377 (0.2865)	loss 1.3319 (1.3160)	grad_norm 3.6775 (4.8693)	loss_scale 2048.0000 (1569.2246)	mem 10200MB
[2024-07-02 15:28:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:08:28 lr 0.000002	 wd 0.0000	time 0.2258 (0.2821)	loss 1.4151 (1.3209)	grad_norm 4.1839 (4.9059)	loss_scale 2048.0000 (1637.5235)	mem 10200MB
[2024-07-02 15:28:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:54 lr 0.000002	 wd 0.0000	time 0.2338 (0.2786)	loss 1.5527 (1.3238)	grad_norm 4.4952 (4.9235)	loss_scale 2048.0000 (1688.7690)	mem 10200MB
[2024-07-02 15:28:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:07:21 lr 0.000001	 wd 0.0000	time 0.2371 (0.2754)	loss 1.3835 (1.3286)	grad_norm 2.8340 (4.9006)	loss_scale 2048.0000 (1728.6393)	mem 10200MB
[2024-07-02 15:29:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:51 lr 0.000001	 wd 0.0000	time 0.2790 (0.2743)	loss 1.3758 (1.3276)	grad_norm 4.0958 (4.8621)	loss_scale 2048.0000 (1760.5435)	mem 10200MB
[2024-07-02 15:29:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:06:22 lr 0.000001	 wd 0.0000	time 0.2436 (0.2725)	loss 1.3407 (1.3284)	grad_norm 4.4146 (4.8574)	loss_scale 2048.0000 (1786.6521)	mem 10200MB
[2024-07-02 15:30:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:54 lr 0.000001	 wd 0.0000	time 0.2282 (0.2723)	loss 1.5212 (1.3285)	grad_norm 3.8330 (4.8956)	loss_scale 2048.0000 (1808.4130)	mem 10200MB
[2024-07-02 15:30:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:05:25 lr 0.000001	 wd 0.0000	time 0.2384 (0.2705)	loss 1.4335 (1.3268)	grad_norm 4.4819 (4.9079)	loss_scale 2048.0000 (1826.8286)	mem 10200MB
[2024-07-02 15:31:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:57 lr 0.000001	 wd 0.0000	time 0.2442 (0.2698)	loss 1.3173 (1.3281)	grad_norm 4.4320 (4.9051)	loss_scale 2048.0000 (1842.6153)	mem 10200MB
[2024-07-02 15:31:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:04:29 lr 0.000001	 wd 0.0000	time 0.2437 (0.2686)	loss 1.4925 (1.3281)	grad_norm 4.6961 (4.9463)	loss_scale 2048.0000 (1856.2985)	mem 10200MB
[2024-07-02 15:31:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:04:01 lr 0.000001	 wd 0.0000	time 0.2351 (0.2674)	loss 1.4766 (1.3264)	grad_norm 4.7930 (4.9611)	loss_scale 2048.0000 (1868.2723)	mem 10200MB
[2024-07-02 15:32:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:33 lr 0.000001	 wd 0.0000	time 0.2340 (0.2665)	loss 1.3871 (1.3245)	grad_norm 4.0840 (4.9301)	loss_scale 2048.0000 (1878.8383)	mem 10200MB
[2024-07-02 15:32:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:03:07 lr 0.000001	 wd 0.0000	time 0.2311 (0.2668)	loss 1.3933 (1.3250)	grad_norm 8.0074 (4.9565)	loss_scale 2048.0000 (1888.2310)	mem 10200MB
[2024-07-02 15:33:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:40 lr 0.000001	 wd 0.0000	time 0.2277 (0.2670)	loss 0.9325 (1.3261)	grad_norm 5.8651 (4.9613)	loss_scale 2048.0000 (1896.6355)	mem 10200MB
[2024-07-02 15:33:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:02:13 lr 0.000001	 wd 0.0000	time 0.2280 (0.2660)	loss 0.8835 (1.3246)	grad_norm 4.7353 (4.9707)	loss_scale 2048.0000 (1904.1999)	mem 10200MB
[2024-07-02 15:34:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:47 lr 0.000001	 wd 0.0000	time 0.2484 (0.2671)	loss 1.7149 (1.3234)	grad_norm 3.3124 (4.9512)	loss_scale 2048.0000 (1911.0443)	mem 10200MB
[2024-07-02 15:34:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:20 lr 0.000001	 wd 0.0000	time 0.2474 (0.2670)	loss 0.9841 (1.3245)	grad_norm 6.7372 (4.9414)	loss_scale 2048.0000 (1917.2667)	mem 10200MB
[2024-07-02 15:34:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:53 lr 0.000001	 wd 0.0000	time 0.2547 (0.2663)	loss 1.4436 (1.3247)	grad_norm 3.4750 (nan)	loss_scale 1024.0000 (1907.8175)	mem 10200MB
[2024-07-02 15:35:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:27 lr 0.000001	 wd 0.0000	time 0.2376 (0.2661)	loss 1.1847 (1.3244)	grad_norm 4.6382 (nan)	loss_scale 1024.0000 (1871.0071)	mem 10200MB
[2024-07-02 15:35:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.2264 (0.2652)	loss 1.4479 (1.3229)	grad_norm 4.4583 (nan)	loss_scale 1024.0000 (1837.1403)	mem 10200MB
[2024-07-02 15:36:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 27 training takes 0:11:21
[2024-07-02 15:36:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 17.627 (17.627)	Loss 0.4038 (0.4038)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 10200MB
[2024-07-02 15:36:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.740 Acc@5 97.476
[2024-07-02 15:36:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 15:36:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.74%
[2024-07-02 15:36:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 15:36:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 15:36:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][0/2502]	eta 9:46:14 lr 0.000001	 wd 0.0000	time 14.0584 (14.0584)	loss 1.2337 (1.2337)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:37:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:17:03 lr 0.000001	 wd 0.0000	time 0.2361 (0.4263)	loss 0.9983 (1.3046)	grad_norm 5.8551 (6.0977)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:37:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:13:05 lr 0.000001	 wd 0.0000	time 0.2227 (0.3412)	loss 1.0834 (1.3093)	grad_norm 5.8331 (5.6681)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:38:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:11:25 lr 0.000001	 wd 0.0000	time 0.2335 (0.3111)	loss 1.5518 (1.3235)	grad_norm 9.9283 (5.5389)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:38:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:10:21 lr 0.000001	 wd 0.0000	time 0.2220 (0.2957)	loss 1.4893 (1.3286)	grad_norm 3.1727 (5.3419)	loss_scale 1024.0000 (1024.0000)	mem 10200MB
[2024-07-02 15:39:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:09:39 lr 0.000001	 wd 0.0000	time 0.2375 (0.2896)	loss 1.5592 (1.3283)	grad_norm 5.6967 (nan)	loss_scale 512.0000 (958.5948)	mem 10200MB
[2024-07-02 15:39:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:09:02 lr 0.000001	 wd 0.0000	time 0.2999 (0.2854)	loss 1.3669 (1.3287)	grad_norm 5.5329 (nan)	loss_scale 512.0000 (884.2862)	mem 10200MB
[2024-07-02 15:39:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:08:27 lr 0.000001	 wd 0.0000	time 0.2420 (0.2814)	loss 1.0096 (1.3311)	grad_norm 3.9205 (nan)	loss_scale 512.0000 (831.1783)	mem 10200MB
[2024-07-02 15:40:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:52 lr 0.000001	 wd 0.0000	time 0.2368 (0.2777)	loss 1.5847 (1.3285)	grad_norm 3.0255 (nan)	loss_scale 512.0000 (791.3308)	mem 10200MB
[2024-07-02 15:40:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:07:25 lr 0.000001	 wd 0.0000	time 0.2176 (0.2784)	loss 1.4476 (1.3286)	grad_norm 4.2218 (nan)	loss_scale 512.0000 (760.3285)	mem 10200MB
[2024-07-02 15:41:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:54 lr 0.000001	 wd 0.0000	time 0.2303 (0.2758)	loss 1.4212 (1.3292)	grad_norm 3.8041 (nan)	loss_scale 512.0000 (735.5205)	mem 10200MB
[2024-07-02 15:41:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:06:23 lr 0.000001	 wd 0.0000	time 0.2210 (0.2737)	loss 1.0400 (1.3277)	grad_norm 3.9779 (nan)	loss_scale 512.0000 (715.2189)	mem 10200MB
[2024-07-02 15:42:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:54 lr 0.000001	 wd 0.0000	time 0.2351 (0.2727)	loss 1.1176 (1.3262)	grad_norm 3.1967 (nan)	loss_scale 512.0000 (698.2981)	mem 10200MB
[2024-07-02 15:42:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:05:26 lr 0.000001	 wd 0.0000	time 0.2269 (0.2719)	loss 1.3819 (1.3234)	grad_norm 5.7590 (nan)	loss_scale 512.0000 (683.9785)	mem 10200MB
[2024-07-02 15:43:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:58 lr 0.000001	 wd 0.0000	time 0.2271 (0.2707)	loss 0.9666 (1.3242)	grad_norm 5.6974 (nan)	loss_scale 512.0000 (671.7031)	mem 10200MB
[2024-07-02 15:43:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:04:29 lr 0.000001	 wd 0.0000	time 0.2301 (0.2694)	loss 1.4624 (1.3213)	grad_norm 3.8081 (nan)	loss_scale 512.0000 (661.0633)	mem 10200MB
[2024-07-02 15:43:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:04:02 lr 0.000001	 wd 0.0000	time 0.2234 (0.2688)	loss 1.1878 (1.3214)	grad_norm 6.3588 (nan)	loss_scale 512.0000 (651.7527)	mem 10200MB
[2024-07-02 15:44:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:35 lr 0.000001	 wd 0.0000	time 0.2306 (0.2688)	loss 1.4699 (1.3224)	grad_norm 3.2621 (nan)	loss_scale 512.0000 (643.5367)	mem 10200MB
[2024-07-02 15:44:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:03:07 lr 0.000001	 wd 0.0000	time 0.2468 (0.2678)	loss 1.3399 (1.3214)	grad_norm 4.0193 (nan)	loss_scale 512.0000 (636.2332)	mem 10200MB
[2024-07-02 15:45:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:40 lr 0.000001	 wd 0.0000	time 0.2397 (0.2668)	loss 1.5948 (1.3203)	grad_norm 4.6928 (nan)	loss_scale 512.0000 (629.6981)	mem 10200MB
[2024-07-02 15:45:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:02:14 lr 0.000001	 wd 0.0000	time 0.2842 (0.2687)	loss 0.8713 (1.3197)	grad_norm 4.4135 (nan)	loss_scale 512.0000 (623.8161)	mem 10200MB
[2024-07-02 15:46:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:47 lr 0.000001	 wd 0.0000	time 0.2289 (0.2680)	loss 1.1481 (1.3198)	grad_norm 2.8481 (nan)	loss_scale 512.0000 (618.4941)	mem 10200MB
[2024-07-02 15:46:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:20 lr 0.000001	 wd 0.0000	time 0.2238 (0.2672)	loss 1.4671 (1.3187)	grad_norm 5.0640 (nan)	loss_scale 512.0000 (613.6556)	mem 10200MB
[2024-07-02 15:46:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:53 lr 0.000001	 wd 0.0000	time 0.2496 (0.2664)	loss 1.2026 (1.3191)	grad_norm 3.9212 (nan)	loss_scale 512.0000 (609.2377)	mem 10200MB
[2024-07-02 15:47:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:27 lr 0.000001	 wd 0.0000	time 0.2456 (0.2670)	loss 1.5445 (1.3180)	grad_norm 8.0660 (nan)	loss_scale 512.0000 (605.1878)	mem 10200MB
[2024-07-02 15:47:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.2228 (0.2660)	loss 1.1380 (1.3165)	grad_norm 4.1826 (nan)	loss_scale 512.0000 (601.4618)	mem 10200MB
[2024-07-02 15:47:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 28 training takes 0:11:16
[2024-07-02 15:48:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 16.774 (16.774)	Loss 0.4041 (0.4041)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 10200MB
[2024-07-02 15:48:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.748 Acc@5 97.480
[2024-07-02 15:48:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 15:48:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.75%
[2024-07-02 15:48:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 15:48:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 15:48:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][0/2502]	eta 15:26:27 lr 0.000001	 wd 0.0000	time 22.2172 (22.2172)	loss 1.4447 (1.4447)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:49:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:18:45 lr 0.000001	 wd 0.0000	time 0.2488 (0.4684)	loss 1.4829 (1.2965)	grad_norm 3.9518 (4.9435)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:49:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:13:51 lr 0.000001	 wd 0.0000	time 0.2322 (0.3613)	loss 1.1568 (1.3134)	grad_norm 4.3922 (5.0178)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:50:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:11:54 lr 0.000001	 wd 0.0000	time 0.2390 (0.3247)	loss 1.4882 (1.3121)	grad_norm 3.8953 (4.9086)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:50:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:10:59 lr 0.000001	 wd 0.0000	time 0.2405 (0.3139)	loss 1.1974 (1.3170)	grad_norm 3.8680 (4.8768)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:51:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:10:03 lr 0.000001	 wd 0.0000	time 0.2256 (0.3014)	loss 0.9035 (1.3216)	grad_norm 5.0466 (4.8153)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:51:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:09:18 lr 0.000000	 wd 0.0000	time 0.2843 (0.2937)	loss 1.3148 (1.3257)	grad_norm 5.5992 (4.8314)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:51:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:08:38 lr 0.000000	 wd 0.0000	time 0.2805 (0.2878)	loss 1.6142 (1.3253)	grad_norm 11.0190 (4.8505)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:52:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:08:11 lr 0.000000	 wd 0.0000	time 0.2298 (0.2890)	loss 0.8288 (1.3244)	grad_norm 3.3563 (4.8423)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:52:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:07:37 lr 0.000000	 wd 0.0000	time 0.2211 (0.2859)	loss 1.3066 (1.3246)	grad_norm 5.0957 (4.8538)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:53:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:07:03 lr 0.000000	 wd 0.0000	time 0.2475 (0.2821)	loss 1.3021 (1.3232)	grad_norm 3.1070 (4.8547)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:53:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:06:36 lr 0.000000	 wd 0.0000	time 0.2348 (0.2831)	loss 1.2947 (1.3232)	grad_norm 5.4773 (4.8312)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:54:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:06:06 lr 0.000000	 wd 0.0000	time 0.2323 (0.2817)	loss 1.3442 (1.3204)	grad_norm 4.4061 (4.8654)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:54:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:05:36 lr 0.000000	 wd 0.0000	time 0.2371 (0.2797)	loss 1.4817 (1.3210)	grad_norm 5.3487 (4.8672)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:55:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:05:07 lr 0.000000	 wd 0.0000	time 0.2453 (0.2786)	loss 1.5492 (1.3183)	grad_norm 4.3061 (4.8821)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:55:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:04:38 lr 0.000000	 wd 0.0000	time 0.2810 (0.2777)	loss 1.3414 (1.3192)	grad_norm 4.5967 (4.8751)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:55:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:04:09 lr 0.000000	 wd 0.0000	time 0.2512 (0.2763)	loss 1.3046 (1.3209)	grad_norm 3.5012 (4.9093)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:56:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:40 lr 0.000000	 wd 0.0000	time 0.2241 (0.2748)	loss 1.1342 (1.3187)	grad_norm 3.3564 (4.9328)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:56:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:03:11 lr 0.000000	 wd 0.0000	time 0.2408 (0.2733)	loss 1.1356 (1.3203)	grad_norm 4.5844 (4.9246)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:57:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:44 lr 0.000000	 wd 0.0000	time 0.2274 (0.2734)	loss 1.2482 (1.3195)	grad_norm 4.2413 (4.9618)	loss_scale 512.0000 (512.0000)	mem 10200MB
[2024-07-02 15:57:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:02:16 lr 0.000000	 wd 0.0000	time 0.2446 (0.2722)	loss 1.5309 (1.3193)	grad_norm 5.9020 (4.9582)	loss_scale 1024.0000 (528.8876)	mem 10200MB
[2024-07-02 15:58:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:48 lr 0.000000	 wd 0.0000	time 0.2356 (0.2711)	loss 1.3982 (1.3200)	grad_norm 4.1789 (nan)	loss_scale 512.0000 (543.6802)	mem 10200MB
[2024-07-02 15:58:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:21 lr 0.000000	 wd 0.0000	time 0.4201 (0.2702)	loss 1.4212 (1.3217)	grad_norm 7.0980 (nan)	loss_scale 512.0000 (542.2408)	mem 10200MB
[2024-07-02 15:58:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:54 lr 0.000000	 wd 0.0000	time 0.2277 (0.2698)	loss 1.4573 (1.3226)	grad_norm 6.6018 (nan)	loss_scale 512.0000 (540.9266)	mem 10200MB
[2024-07-02 15:59:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.2352 (0.2708)	loss 1.4985 (1.3234)	grad_norm 4.0035 (nan)	loss_scale 512.0000 (539.7218)	mem 10200MB
[2024-07-02 15:59:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000000	 wd 0.0000	time 0.2197 (0.2698)	loss 1.3957 (1.3228)	grad_norm 3.1300 (nan)	loss_scale 512.0000 (538.6134)	mem 10200MB
[2024-07-02 15:59:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 249): INFO EPOCH 29 training takes 0:11:23
[2024-07-02 15:59:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_29.pth saving......
[2024-07-02 15:59:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_29.pth saved !!!
[2024-07-02 16:00:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 289): INFO Test: [0/98]	Time 30.807 (30.807)	Loss 0.4043 (0.4043)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 10200MB
[2024-07-02 16:00:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 296): INFO  * Acc@1 84.760 Acc@5 97.500
[2024-07-02 16:00:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-02 16:00:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 182): INFO Max accuracy: 84.76%
[2024-07-02 16:00:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saving......
[2024-07-02 16:00:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth saved !!!
[2024-07-02 16:00:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0] (main.py 189): INFO Training time 5:58:55
