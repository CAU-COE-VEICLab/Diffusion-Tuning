[2024-07-04 09:03:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/config.json
[2024-07-04 09:03:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    FINETUNE_MODE: sequence_stage2
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: swin_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    DEPTHS:
    - 3
    - 3
    - 9
    - 3
    DIMS:
    - 96
    - 192
    - 384
    - 768
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 4.0e-05
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.0e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 4.0e-08
  WEIGHT_DECAY: 1.0e-08

[2024-07-04 09:03:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility/configs/swin/diffusion_ft_swin_base_patch4_window7_224_22kto1k_sequence_stage_process2.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-04 09:03:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 108): INFO Creating model:swin_diffusion_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2
[2024-07-04 09:03:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 110): INFO SwinTransformer_Diffusion_Finetune(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-04 09:03:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 113): INFO number of params: 62564960
[2024-07-04 09:03:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 116): INFO number of GFLOPs: 15.438473216
[2024-07-04 09:03:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 150): INFO no checkpoint found in pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2, ignoring auto resume
[2024-07-04 09:03:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth for fine-tuning......
[2024-07-04 09:03:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])
[2024-07-04 09:03:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth'
[2024-07-04 09:03:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 12.312 (12.312)	Loss 0.4055 (0.4055)	Acc@1 93.164 (93.164)	Acc@5 98.438 (98.438)	Mem 1633MB
[2024-07-04 09:03:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 83.868 Acc@5 97.170
[2024-07-04 09:03:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 162): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-04 09:03:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 168): INFO Start training
[2024-07-04 09:03:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][0/2502]	eta 8:05:05 lr 0.000000	 wd 0.0000	time 11.6330 (11.6330)	loss 1.6251 (1.6251)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 10986MB
[2024-07-04 09:04:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:22:25 lr 0.000000	 wd 0.0000	time 0.4314 (0.5601)	loss 1.4439 (1.4133)	grad_norm 3.3557 (nan)	loss_scale 4096.0000 (7137.5842)	mem 11711MB
[2024-07-04 09:05:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:19:18 lr 0.000001	 wd 0.0000	time 0.4275 (0.5033)	loss 1.3122 (1.3958)	grad_norm 7.3046 (nan)	loss_scale 4096.0000 (5624.3582)	mem 11711MB
[2024-07-04 09:06:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:17:47 lr 0.000001	 wd 0.0000	time 0.4310 (0.4846)	loss 1.3216 (1.3768)	grad_norm 6.7365 (nan)	loss_scale 2048.0000 (4926.0864)	mem 11711MB
[2024-07-04 09:06:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:16:38 lr 0.000001	 wd 0.0000	time 0.4141 (0.4749)	loss 1.8662 (1.3785)	grad_norm 5.2946 (nan)	loss_scale 2048.0000 (4208.3591)	mem 11711MB
[2024-07-04 09:07:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:15:38 lr 0.000002	 wd 0.0000	time 0.4331 (0.4690)	loss 1.5774 (1.3791)	grad_norm inf (nan)	loss_scale 1024.0000 (3773.0619)	mem 11711MB
[2024-07-04 09:08:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:14:44 lr 0.000002	 wd 0.0000	time 0.4374 (0.4653)	loss 0.9820 (1.3835)	grad_norm 7.8368 (nan)	loss_scale 1024.0000 (3315.6473)	mem 11711MB
[2024-07-04 09:08:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:13:53 lr 0.000002	 wd 0.0000	time 0.4320 (0.4625)	loss 1.4699 (1.3812)	grad_norm 4.4082 (nan)	loss_scale 1024.0000 (2988.7361)	mem 11711MB
[2024-07-04 09:09:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:13:03 lr 0.000003	 wd 0.0000	time 0.4317 (0.4604)	loss 1.6009 (1.3811)	grad_norm 4.2735 (nan)	loss_scale 1024.0000 (2743.4507)	mem 11711MB
[2024-07-04 09:10:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:12:15 lr 0.000003	 wd 0.0000	time 0.4197 (0.4588)	loss 1.5669 (1.3764)	grad_norm 6.5129 (nan)	loss_scale 1024.0000 (2552.6127)	mem 11711MB
[2024-07-04 09:11:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:11:27 lr 0.000003	 wd 0.0000	time 0.4376 (0.4576)	loss 1.3741 (1.3756)	grad_norm 6.1543 (nan)	loss_scale 1024.0000 (2399.9041)	mem 11711MB
[2024-07-04 09:11:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:10:39 lr 0.000004	 wd 0.0000	time 0.4235 (0.4565)	loss 1.5198 (1.3760)	grad_norm 2.9015 (nan)	loss_scale 1024.0000 (2274.9355)	mem 11711MB
[2024-07-04 09:12:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:09:53 lr 0.000004	 wd 0.0000	time 0.4313 (0.4556)	loss 1.3614 (1.3792)	grad_norm 4.6527 (nan)	loss_scale 1024.0000 (2170.7777)	mem 11711MB
[2024-07-04 09:13:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:09:06 lr 0.000004	 wd 0.0000	time 0.4319 (0.4548)	loss 1.5154 (1.3810)	grad_norm 5.5589 (nan)	loss_scale 1024.0000 (2082.6318)	mem 11711MB
[2024-07-04 09:14:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:08:20 lr 0.000005	 wd 0.0000	time 0.4360 (0.4542)	loss 1.5854 (1.3816)	grad_norm 4.5807 (nan)	loss_scale 1024.0000 (2007.0692)	mem 11711MB
[2024-07-04 09:14:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:07:34 lr 0.000005	 wd 0.0000	time 0.4274 (0.4536)	loss 1.3677 (1.3809)	grad_norm 4.9224 (nan)	loss_scale 1024.0000 (1941.5750)	mem 11711MB
[2024-07-04 09:15:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:06:48 lr 0.000005	 wd 0.0000	time 0.4287 (0.4531)	loss 1.7299 (1.3816)	grad_norm 3.5834 (nan)	loss_scale 1024.0000 (1884.2623)	mem 11711MB
[2024-07-04 09:16:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:06:03 lr 0.000005	 wd 0.0000	time 0.4332 (0.4528)	loss 1.5914 (1.3810)	grad_norm 3.6681 (nan)	loss_scale 1024.0000 (1833.6884)	mem 11711MB
[2024-07-04 09:17:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:05:17 lr 0.000006	 wd 0.0000	time 0.4383 (0.4524)	loss 1.2268 (1.3808)	grad_norm 3.8859 (nan)	loss_scale 1024.0000 (1788.7307)	mem 11711MB
[2024-07-04 09:17:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:04:32 lr 0.000006	 wd 0.0000	time 0.4331 (0.4520)	loss 1.4521 (1.3799)	grad_norm 5.9915 (nan)	loss_scale 1024.0000 (1748.5029)	mem 11711MB
[2024-07-04 09:18:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:03:46 lr 0.000006	 wd 0.0000	time 0.4296 (0.4518)	loss 1.5249 (1.3775)	grad_norm 4.3288 (nan)	loss_scale 1024.0000 (1712.2959)	mem 11711MB
[2024-07-04 09:19:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:03:01 lr 0.000007	 wd 0.0000	time 0.4311 (0.4515)	loss 1.3907 (1.3785)	grad_norm 4.3828 (nan)	loss_scale 1024.0000 (1679.5355)	mem 11711MB
[2024-07-04 09:20:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:02:16 lr 0.000007	 wd 0.0000	time 0.4203 (0.4512)	loss 1.5386 (1.3784)	grad_norm 7.8992 (nan)	loss_scale 1024.0000 (1649.7519)	mem 11711MB
[2024-07-04 09:20:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:01:31 lr 0.000007	 wd 0.0000	time 0.4354 (0.4510)	loss 1.4117 (1.3770)	grad_norm 10.6601 (nan)	loss_scale 1024.0000 (1622.5571)	mem 11711MB
[2024-07-04 09:21:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:45 lr 0.000008	 wd 0.0000	time 0.4284 (0.4508)	loss 1.4726 (1.3774)	grad_norm 4.9660 (nan)	loss_scale 1024.0000 (1597.6277)	mem 11711MB
[2024-07-04 09:22:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.4315 (0.4506)	loss 1.6119 (1.3777)	grad_norm 4.4335 (nan)	loss_scale 1024.0000 (1574.6917)	mem 11711MB
[2024-07-04 09:22:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 0 training takes 0:18:50
[2024-07-04 09:22:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_0.pth saving......
[2024-07-04 09:22:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_0.pth saved !!!
[2024-07-04 09:22:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 10.007 (10.007)	Loss 0.4004 (0.4004)	Acc@1 93.359 (93.359)	Acc@5 98.438 (98.438)	Mem 11711MB
[2024-07-04 09:22:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.070 Acc@5 97.246
[2024-07-04 09:22:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-04 09:22:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.07%
[2024-07-04 09:22:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saving......
[2024-07-04 09:22:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saved !!!
[2024-07-04 09:23:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][0/2502]	eta 7:14:55 lr 0.000008	 wd 0.0000	time 10.4299 (10.4299)	loss 1.2438 (1.2438)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 09:23:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:21:50 lr 0.000008	 wd 0.0000	time 0.4317 (0.5455)	loss 1.1698 (1.4013)	grad_norm 6.7287 (5.9046)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 09:24:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:19:01 lr 0.000009	 wd 0.0000	time 0.4267 (0.4960)	loss 1.4043 (1.4086)	grad_norm 7.4584 (5.7356)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 09:25:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:17:36 lr 0.000009	 wd 0.0000	time 0.4196 (0.4796)	loss 1.7103 (1.3950)	grad_norm 4.5170 (5.6016)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 09:25:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:16:31 lr 0.000009	 wd 0.0000	time 0.4245 (0.4715)	loss 0.9161 (1.3811)	grad_norm 4.6494 (5.4433)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 09:26:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:15:34 lr 0.000010	 wd 0.0000	time 0.4394 (0.4667)	loss 1.6707 (1.3787)	grad_norm 4.0303 (5.5133)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 09:27:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:14:41 lr 0.000010	 wd 0.0000	time 0.4253 (0.4634)	loss 1.3772 (1.3754)	grad_norm 10.5636 (5.4707)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 09:28:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:13:50 lr 0.000010	 wd 0.0000	time 0.4380 (0.4609)	loss 1.5045 (1.3740)	grad_norm 4.1914 (5.4996)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 09:28:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:13:01 lr 0.000011	 wd 0.0000	time 0.4331 (0.4591)	loss 1.5313 (1.3773)	grad_norm 3.7822 (5.4352)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 09:29:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:12:13 lr 0.000011	 wd 0.0000	time 0.4252 (0.4577)	loss 1.5397 (1.3757)	grad_norm 7.6546 (5.4188)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 09:30:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:11:25 lr 0.000011	 wd 0.0000	time 0.4346 (0.4566)	loss 1.4718 (1.3739)	grad_norm 6.7469 (5.3898)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 09:31:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:10:38 lr 0.000012	 wd 0.0000	time 0.4360 (0.4557)	loss 1.1516 (1.3742)	grad_norm 3.7345 (5.3890)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 09:31:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:09:52 lr 0.000012	 wd 0.0000	time 0.4288 (0.4550)	loss 1.4085 (1.3772)	grad_norm 4.3845 (5.3790)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 09:32:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:09:06 lr 0.000012	 wd 0.0000	time 0.4200 (0.4543)	loss 1.5300 (1.3787)	grad_norm 5.6079 (5.4061)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 09:33:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:08:20 lr 0.000012	 wd 0.0000	time 0.4324 (0.4537)	loss 1.4859 (1.3766)	grad_norm 4.0489 (5.3933)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 09:34:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:07:34 lr 0.000013	 wd 0.0000	time 0.4301 (0.4532)	loss 0.9543 (1.3749)	grad_norm 5.0706 (nan)	loss_scale 512.0000 (1001.4870)	mem 11711MB
[2024-07-04 09:34:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:06:48 lr 0.000013	 wd 0.0000	time 0.4333 (0.4528)	loss 0.9720 (1.3740)	grad_norm 4.2936 (nan)	loss_scale 512.0000 (970.9132)	mem 11711MB
[2024-07-04 09:35:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:06:02 lr 0.000013	 wd 0.0000	time 0.4344 (0.4524)	loss 1.4009 (1.3739)	grad_norm 3.6550 (nan)	loss_scale 512.0000 (943.9342)	mem 11711MB
[2024-07-04 09:36:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:05:17 lr 0.000014	 wd 0.0000	time 0.4317 (0.4521)	loss 1.3640 (1.3732)	grad_norm 7.8164 (nan)	loss_scale 512.0000 (919.9511)	mem 11711MB
[2024-07-04 09:37:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:04:31 lr 0.000014	 wd 0.0000	time 0.4227 (0.4518)	loss 1.3877 (1.3741)	grad_norm 3.7517 (nan)	loss_scale 512.0000 (898.4913)	mem 11711MB
[2024-07-04 09:37:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:03:46 lr 0.000014	 wd 0.0000	time 0.4325 (0.4516)	loss 1.4349 (1.3740)	grad_norm 5.7077 (nan)	loss_scale 512.0000 (879.1764)	mem 11711MB
[2024-07-04 09:38:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:03:01 lr 0.000015	 wd 0.0000	time 0.4351 (0.4514)	loss 1.5516 (1.3751)	grad_norm 4.7643 (nan)	loss_scale 512.0000 (861.7001)	mem 11711MB
[2024-07-04 09:39:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:02:16 lr 0.000015	 wd 0.0000	time 0.4235 (0.4511)	loss 1.0720 (1.3757)	grad_norm 5.4322 (nan)	loss_scale 512.0000 (845.8119)	mem 11711MB
[2024-07-04 09:40:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:01:31 lr 0.000015	 wd 0.0000	time 0.4303 (0.4509)	loss 1.3894 (1.3759)	grad_norm 4.1061 (nan)	loss_scale 512.0000 (831.3047)	mem 11711MB
[2024-07-04 09:40:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:45 lr 0.000016	 wd 0.0000	time 0.4236 (0.4508)	loss 1.5530 (1.3743)	grad_norm 5.4274 (nan)	loss_scale 512.0000 (818.0058)	mem 11711MB
[2024-07-04 09:41:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.4235 (0.4505)	loss 1.1231 (1.3757)	grad_norm 4.2828 (nan)	loss_scale 512.0000 (805.7705)	mem 11711MB
[2024-07-04 09:41:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 1 training takes 0:18:49
[2024-07-04 09:41:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.460 (11.460)	Loss 0.4116 (0.4116)	Acc@1 92.773 (92.773)	Acc@5 98.242 (98.242)	Mem 11711MB
[2024-07-04 09:42:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.150 Acc@5 97.280
[2024-07-04 09:42:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-04 09:42:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-04 09:42:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saving......
[2024-07-04 09:42:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saved !!!
[2024-07-04 09:42:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][0/2502]	eta 6:52:53 lr 0.000016	 wd 0.0000	time 9.9015 (9.9015)	loss 1.4448 (1.4448)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:42:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:21:41 lr 0.000016	 wd 0.0000	time 0.4358 (0.5417)	loss 1.5145 (1.3506)	grad_norm 4.7815 (6.1162)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:43:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:18:58 lr 0.000017	 wd 0.0000	time 0.4308 (0.4946)	loss 1.4890 (1.3696)	grad_norm 4.0321 (5.9225)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:44:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:17:34 lr 0.000017	 wd 0.0000	time 0.4409 (0.4788)	loss 1.1742 (1.3732)	grad_norm 5.5615 (5.8278)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:45:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:16:29 lr 0.000017	 wd 0.0000	time 0.4341 (0.4709)	loss 1.5461 (1.3686)	grad_norm 5.9869 (5.6171)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:45:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:15:32 lr 0.000018	 wd 0.0000	time 0.4184 (0.4660)	loss 1.4193 (1.3711)	grad_norm 4.6150 (5.6674)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:46:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:14:40 lr 0.000018	 wd 0.0000	time 0.4253 (0.4627)	loss 1.2655 (1.3648)	grad_norm 4.8275 (5.5792)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:47:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:13:49 lr 0.000018	 wd 0.0000	time 0.4283 (0.4602)	loss 1.2426 (1.3686)	grad_norm 3.6455 (5.5164)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:48:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:13:00 lr 0.000019	 wd 0.0000	time 0.4324 (0.4586)	loss 1.5938 (1.3669)	grad_norm 3.3881 (5.6230)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:48:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:12:12 lr 0.000019	 wd 0.0000	time 0.4309 (0.4573)	loss 1.5110 (1.3723)	grad_norm 4.2495 (5.5478)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:49:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:11:25 lr 0.000019	 wd 0.0000	time 0.4300 (0.4561)	loss 1.4748 (1.3739)	grad_norm 6.4735 (5.5353)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:50:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:10:38 lr 0.000020	 wd 0.0000	time 0.4384 (0.4553)	loss 1.1787 (1.3747)	grad_norm 5.6757 (5.5409)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:51:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:09:51 lr 0.000020	 wd 0.0000	time 0.4218 (0.4547)	loss 1.3288 (1.3738)	grad_norm 4.8369 (5.5607)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:51:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:09:05 lr 0.000020	 wd 0.0000	time 0.4329 (0.4541)	loss 1.6468 (1.3766)	grad_norm 5.7304 (5.5746)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:52:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:08:19 lr 0.000020	 wd 0.0000	time 0.4275 (0.4536)	loss 1.4033 (1.3771)	grad_norm 5.1931 (5.6172)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:53:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:07:34 lr 0.000021	 wd 0.0000	time 0.4260 (0.4532)	loss 1.5183 (1.3752)	grad_norm 5.3738 (5.6120)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:54:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:06:48 lr 0.000021	 wd 0.0000	time 0.4343 (0.4528)	loss 1.2624 (1.3756)	grad_norm 5.5048 (5.6243)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:54:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:06:02 lr 0.000021	 wd 0.0000	time 0.4338 (0.4525)	loss 1.3403 (1.3745)	grad_norm 6.3866 (5.6121)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:55:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:05:17 lr 0.000022	 wd 0.0000	time 0.4395 (0.4522)	loss 1.3160 (1.3743)	grad_norm 5.4895 (5.6039)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:56:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:04:32 lr 0.000022	 wd 0.0000	time 0.4295 (0.4519)	loss 0.9574 (1.3727)	grad_norm 4.2622 (5.6097)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:57:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:03:46 lr 0.000022	 wd 0.0000	time 0.4344 (0.4517)	loss 1.1819 (1.3706)	grad_norm 5.0854 (5.6064)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:57:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:03:01 lr 0.000023	 wd 0.0000	time 0.4365 (0.4515)	loss 1.4285 (1.3708)	grad_norm 10.2803 (5.6031)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:58:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:02:16 lr 0.000023	 wd 0.0000	time 0.4320 (0.4513)	loss 1.6284 (1.3705)	grad_norm 12.3445 (5.6259)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 09:59:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:01:31 lr 0.000023	 wd 0.0000	time 0.4359 (0.4511)	loss 1.6511 (1.3708)	grad_norm 5.5342 (5.6202)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 10:00:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:46 lr 0.000024	 wd 0.0000	time 0.4434 (0.4510)	loss 1.5014 (1.3699)	grad_norm 6.6030 (5.5917)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 10:00:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.4397 (0.4508)	loss 1.5281 (1.3702)	grad_norm 6.0393 (5.5691)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 10:00:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 2 training takes 0:18:50
[2024-07-04 10:01:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.234 (11.234)	Loss 0.4023 (0.4023)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 11711MB
[2024-07-04 10:01:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.066 Acc@5 97.326
[2024-07-04 10:01:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-04 10:01:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-04 10:01:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][0/2502]	eta 7:56:18 lr 0.000024	 wd 0.0000	time 11.4222 (11.4222)	loss 0.9783 (0.9783)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 10:02:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:22:14 lr 0.000024	 wd 0.0000	time 0.4352 (0.5555)	loss 1.4876 (1.3420)	grad_norm 9.6688 (6.1164)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 10:02:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:19:15 lr 0.000025	 wd 0.0000	time 0.4435 (0.5018)	loss 1.4090 (1.3587)	grad_norm 3.9482 (5.5914)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 10:03:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:17:44 lr 0.000025	 wd 0.0000	time 0.4270 (0.4833)	loss 1.5598 (1.3530)	grad_norm 6.2217 (5.3666)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 10:04:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:16:36 lr 0.000025	 wd 0.0000	time 0.4142 (0.4742)	loss 1.5242 (1.3562)	grad_norm 4.4683 (5.3756)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 10:05:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:15:38 lr 0.000026	 wd 0.0000	time 0.4346 (0.4687)	loss 1.3999 (1.3546)	grad_norm 4.7210 (5.2554)	loss_scale 1024.0000 (583.5369)	mem 11711MB
[2024-07-04 10:05:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:14:44 lr 0.000026	 wd 0.0000	time 0.4282 (0.4650)	loss 1.4054 (1.3556)	grad_norm 4.7261 (5.2470)	loss_scale 1024.0000 (656.8253)	mem 11711MB
[2024-07-04 10:06:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:13:53 lr 0.000026	 wd 0.0000	time 0.4218 (0.4623)	loss 1.7005 (1.3578)	grad_norm 4.6951 (5.2436)	loss_scale 1024.0000 (709.2040)	mem 11711MB
[2024-07-04 10:07:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:13:03 lr 0.000027	 wd 0.0000	time 0.4307 (0.4603)	loss 1.1100 (1.3581)	grad_norm 3.3193 (5.2507)	loss_scale 1024.0000 (748.5044)	mem 11711MB
[2024-07-04 10:08:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:12:14 lr 0.000027	 wd 0.0000	time 0.4352 (0.4588)	loss 1.4922 (1.3593)	grad_norm 6.2982 (5.2396)	loss_scale 1024.0000 (779.0810)	mem 11711MB
[2024-07-04 10:08:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:11:27 lr 0.000027	 wd 0.0000	time 0.4192 (0.4575)	loss 1.5152 (1.3621)	grad_norm 9.9136 (5.2855)	loss_scale 1024.0000 (803.5485)	mem 11711MB
[2024-07-04 10:09:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:10:39 lr 0.000028	 wd 0.0000	time 0.4337 (0.4565)	loss 1.3903 (1.3646)	grad_norm 4.3297 (5.2658)	loss_scale 1024.0000 (823.5713)	mem 11711MB
[2024-07-04 10:10:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:09:53 lr 0.000028	 wd 0.0000	time 0.4347 (0.4557)	loss 1.2360 (1.3629)	grad_norm 4.5080 (5.2595)	loss_scale 1024.0000 (840.2598)	mem 11711MB
[2024-07-04 10:11:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:09:06 lr 0.000028	 wd 0.0000	time 0.4299 (0.4550)	loss 1.2840 (1.3653)	grad_norm 4.0043 (5.2585)	loss_scale 1024.0000 (854.3828)	mem 11711MB
[2024-07-04 10:11:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:08:20 lr 0.000028	 wd 0.0000	time 0.4293 (0.4544)	loss 1.2572 (1.3658)	grad_norm 4.7600 (5.2824)	loss_scale 1024.0000 (866.4897)	mem 11711MB
[2024-07-04 10:12:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:07:34 lr 0.000029	 wd 0.0000	time 0.4366 (0.4539)	loss 1.4630 (1.3677)	grad_norm 4.1894 (5.2594)	loss_scale 1024.0000 (876.9833)	mem 11711MB
[2024-07-04 10:13:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:06:49 lr 0.000029	 wd 0.0000	time 0.4334 (0.4535)	loss 1.5568 (1.3667)	grad_norm 6.5542 (5.2704)	loss_scale 1024.0000 (886.1661)	mem 11711MB
[2024-07-04 10:14:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:06:03 lr 0.000029	 wd 0.0000	time 0.4296 (0.4532)	loss 1.1204 (1.3658)	grad_norm 4.3690 (5.2612)	loss_scale 1024.0000 (894.2693)	mem 11711MB
[2024-07-04 10:14:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:05:17 lr 0.000030	 wd 0.0000	time 0.4324 (0.4528)	loss 1.5180 (1.3660)	grad_norm 3.9640 (5.2421)	loss_scale 1024.0000 (901.4725)	mem 11711MB
[2024-07-04 10:15:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:04:32 lr 0.000030	 wd 0.0000	time 0.4281 (0.4525)	loss 1.4994 (1.3654)	grad_norm 4.5549 (5.2471)	loss_scale 1024.0000 (907.9179)	mem 11711MB
[2024-07-04 10:16:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:03:47 lr 0.000030	 wd 0.0000	time 0.4318 (0.4523)	loss 1.1690 (1.3660)	grad_norm 5.3977 (5.2267)	loss_scale 1024.0000 (913.7191)	mem 11711MB
[2024-07-04 10:17:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:03:01 lr 0.000031	 wd 0.0000	time 0.4234 (0.4520)	loss 1.1668 (1.3650)	grad_norm 7.1148 (5.2179)	loss_scale 1024.0000 (918.9681)	mem 11711MB
[2024-07-04 10:17:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:02:16 lr 0.000031	 wd 0.0000	time 0.4265 (0.4517)	loss 1.3939 (1.3659)	grad_norm 5.4401 (5.1806)	loss_scale 1024.0000 (923.7401)	mem 11711MB
[2024-07-04 10:18:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:01:31 lr 0.000031	 wd 0.0000	time 0.4309 (0.4515)	loss 1.4921 (1.3668)	grad_norm 3.8481 (5.1641)	loss_scale 1024.0000 (928.0973)	mem 11711MB
[2024-07-04 10:19:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:46 lr 0.000032	 wd 0.0000	time 0.4295 (0.4513)	loss 1.0075 (1.3660)	grad_norm 3.2916 (5.1389)	loss_scale 1024.0000 (932.0916)	mem 11711MB
[2024-07-04 10:20:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000032	 wd 0.0000	time 0.4269 (0.4511)	loss 1.4445 (1.3665)	grad_norm 5.9315 (5.1338)	loss_scale 1024.0000 (935.7665)	mem 11711MB
[2024-07-04 10:20:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 3 training takes 0:18:51
[2024-07-04 10:20:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.291 (11.291)	Loss 0.4119 (0.4119)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 11711MB
[2024-07-04 10:20:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.102 Acc@5 97.304
[2024-07-04 10:20:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-04 10:20:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-04 10:20:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][0/2502]	eta 7:30:19 lr 0.000032	 wd 0.0000	time 10.7992 (10.7992)	loss 1.4234 (1.4234)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:21:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:22:11 lr 0.000032	 wd 0.0000	time 0.4174 (0.5542)	loss 1.2473 (1.3943)	grad_norm 4.2633 (4.4295)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:22:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:19:11 lr 0.000033	 wd 0.0000	time 0.4290 (0.5003)	loss 1.1693 (1.3837)	grad_norm 5.3345 (4.6531)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:22:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:17:41 lr 0.000033	 wd 0.0000	time 0.4332 (0.4822)	loss 1.1053 (1.3847)	grad_norm 8.5326 (4.6013)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:23:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:16:35 lr 0.000033	 wd 0.0000	time 0.4239 (0.4735)	loss 1.4063 (1.3747)	grad_norm 6.7097 (4.9354)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:24:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:15:37 lr 0.000034	 wd 0.0000	time 0.4331 (0.4682)	loss 1.4415 (1.3703)	grad_norm 4.5822 (4.9463)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:25:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:14:43 lr 0.000034	 wd 0.0000	time 0.4230 (0.4647)	loss 1.4208 (1.3655)	grad_norm 3.9277 (4.9457)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:25:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:13:52 lr 0.000034	 wd 0.0000	time 0.4308 (0.4620)	loss 1.2634 (1.3655)	grad_norm 5.0958 (4.9742)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:26:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:13:03 lr 0.000035	 wd 0.0000	time 0.4291 (0.4601)	loss 1.3411 (1.3664)	grad_norm 3.6246 (4.9867)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:27:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:12:14 lr 0.000035	 wd 0.0000	time 0.4286 (0.4586)	loss 1.4750 (1.3672)	grad_norm 5.9419 (4.9662)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:28:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:11:26 lr 0.000035	 wd 0.0000	time 0.4217 (0.4573)	loss 1.5380 (1.3684)	grad_norm 4.9178 (4.9961)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:28:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:10:39 lr 0.000036	 wd 0.0000	time 0.4304 (0.4564)	loss 1.5516 (1.3688)	grad_norm 4.1030 (5.0375)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:29:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:09:53 lr 0.000036	 wd 0.0000	time 0.4301 (0.4557)	loss 1.0222 (1.3680)	grad_norm 3.9857 (5.0544)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:30:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:09:06 lr 0.000036	 wd 0.0000	time 0.4323 (0.4550)	loss 1.5435 (1.3668)	grad_norm 3.9438 (5.0799)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:31:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:08:20 lr 0.000036	 wd 0.0000	time 0.4287 (0.4544)	loss 1.4347 (1.3669)	grad_norm 4.8254 (5.0624)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:31:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:07:34 lr 0.000037	 wd 0.0000	time 0.4276 (0.4539)	loss 1.2987 (1.3699)	grad_norm 3.5160 (5.0647)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:32:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:06:49 lr 0.000037	 wd 0.0000	time 0.4277 (0.4535)	loss 1.2114 (1.3694)	grad_norm 3.1814 (5.0380)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:33:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:06:03 lr 0.000037	 wd 0.0000	time 0.4301 (0.4531)	loss 1.5543 (1.3690)	grad_norm 5.1316 (5.0466)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:34:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:05:17 lr 0.000038	 wd 0.0000	time 0.4310 (0.4527)	loss 1.5514 (1.3688)	grad_norm 3.4220 (5.0659)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:34:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:04:32 lr 0.000038	 wd 0.0000	time 0.4355 (0.4524)	loss 1.5352 (1.3687)	grad_norm 8.6399 (5.0821)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:35:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:03:46 lr 0.000038	 wd 0.0000	time 0.4308 (0.4521)	loss 1.5965 (1.3688)	grad_norm 6.8319 (5.0714)	loss_scale 2048.0000 (1060.8456)	mem 11711MB
[2024-07-04 10:36:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:03:01 lr 0.000039	 wd 0.0000	time 0.4311 (0.4519)	loss 1.3842 (1.3689)	grad_norm 4.9975 (5.0697)	loss_scale 2048.0000 (1107.8306)	mem 11711MB
[2024-07-04 10:37:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:02:16 lr 0.000039	 wd 0.0000	time 0.4252 (0.4517)	loss 0.9868 (1.3663)	grad_norm 4.2135 (5.0761)	loss_scale 2048.0000 (1150.5461)	mem 11711MB
[2024-07-04 10:37:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:01:31 lr 0.000039	 wd 0.0000	time 0.4362 (0.4515)	loss 1.2881 (1.3673)	grad_norm 4.9445 (5.0418)	loss_scale 2048.0000 (1189.5489)	mem 11711MB
[2024-07-04 10:38:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:46 lr 0.000040	 wd 0.0000	time 0.4338 (0.4513)	loss 1.4779 (1.3668)	grad_norm 3.3238 (5.0443)	loss_scale 2048.0000 (1225.3028)	mem 11711MB
[2024-07-04 10:39:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.4269 (0.4511)	loss 0.9152 (1.3666)	grad_norm 4.2231 (5.0366)	loss_scale 2048.0000 (1258.1975)	mem 11711MB
[2024-07-04 10:39:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 4 training takes 0:18:51
[2024-07-04 10:39:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.919 (11.919)	Loss 0.4248 (0.4248)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 11711MB
[2024-07-04 10:39:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.044 Acc@5 97.264
[2024-07-04 10:39:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-04 10:39:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-04 10:39:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][0/2502]	eta 7:45:36 lr 0.000040	 wd 0.0000	time 11.1655 (11.1655)	loss 1.5871 (1.5871)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 11711MB
[2024-07-04 10:40:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:22:09 lr 0.000040	 wd 0.0000	time 0.4345 (0.5534)	loss 1.3007 (1.3809)	grad_norm 7.5569 (4.7398)	loss_scale 2048.0000 (2048.0000)	mem 11711MB
[2024-07-04 10:41:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:19:11 lr 0.000040	 wd 0.0000	time 0.4425 (0.5004)	loss 1.4332 (1.3943)	grad_norm 3.9450 (4.7060)	loss_scale 2048.0000 (2048.0000)	mem 11711MB
[2024-07-04 10:42:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:17:42 lr 0.000040	 wd 0.0000	time 0.4259 (0.4823)	loss 1.6444 (1.3814)	grad_norm 3.9972 (4.7436)	loss_scale 2048.0000 (2048.0000)	mem 11711MB
[2024-07-04 10:42:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:16:35 lr 0.000040	 wd 0.0000	time 0.4340 (0.4735)	loss 1.1544 (1.3828)	grad_norm 4.7862 (4.6187)	loss_scale 2048.0000 (2048.0000)	mem 11711MB
[2024-07-04 10:43:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:15:36 lr 0.000040	 wd 0.0000	time 0.4405 (0.4680)	loss 1.6858 (1.3784)	grad_norm 3.6935 (4.7008)	loss_scale 2048.0000 (2048.0000)	mem 11711MB
[2024-07-04 10:44:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:14:42 lr 0.000040	 wd 0.0000	time 0.4315 (0.4642)	loss 1.5259 (1.3815)	grad_norm 6.2722 (4.6950)	loss_scale 2048.0000 (2048.0000)	mem 11711MB
[2024-07-04 10:45:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:13:51 lr 0.000040	 wd 0.0000	time 0.4334 (0.4616)	loss 1.5172 (1.3787)	grad_norm 4.9498 (4.7250)	loss_scale 2048.0000 (2048.0000)	mem 11711MB
[2024-07-04 10:45:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:13:02 lr 0.000040	 wd 0.0000	time 0.4300 (0.4596)	loss 1.1080 (1.3726)	grad_norm 3.1431 (4.7536)	loss_scale 2048.0000 (2048.0000)	mem 11711MB
[2024-07-04 10:46:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:12:13 lr 0.000040	 wd 0.0000	time 0.4455 (0.4580)	loss 0.8407 (1.3711)	grad_norm 3.6801 (4.7896)	loss_scale 2048.0000 (2048.0000)	mem 11711MB
[2024-07-04 10:47:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:11:26 lr 0.000040	 wd 0.0000	time 0.4260 (0.4567)	loss 1.4112 (1.3739)	grad_norm 4.4917 (4.8154)	loss_scale 2048.0000 (2048.0000)	mem 11711MB
[2024-07-04 10:48:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:10:38 lr 0.000040	 wd 0.0000	time 0.4295 (0.4557)	loss 1.5531 (1.3698)	grad_norm 5.8099 (4.7839)	loss_scale 2048.0000 (2048.0000)	mem 11711MB
[2024-07-04 10:48:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:09:52 lr 0.000040	 wd 0.0000	time 0.4288 (0.4549)	loss 1.4910 (1.3691)	grad_norm 3.6322 (4.7686)	loss_scale 2048.0000 (2048.0000)	mem 11711MB
[2024-07-04 10:49:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:09:05 lr 0.000040	 wd 0.0000	time 0.4309 (0.4541)	loss 1.5111 (1.3689)	grad_norm 3.7772 (4.7958)	loss_scale 2048.0000 (2048.0000)	mem 11711MB
[2024-07-04 10:50:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:08:19 lr 0.000040	 wd 0.0000	time 0.4354 (0.4535)	loss 1.4998 (1.3686)	grad_norm 3.2579 (4.7770)	loss_scale 2048.0000 (2048.0000)	mem 11711MB
[2024-07-04 10:51:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:07:33 lr 0.000040	 wd 0.0000	time 0.4251 (0.4530)	loss 1.3175 (1.3686)	grad_norm 3.1740 (inf)	loss_scale 1024.0000 (2012.5250)	mem 11711MB
[2024-07-04 10:51:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:06:48 lr 0.000040	 wd 0.0000	time 0.4280 (0.4525)	loss 1.4435 (1.3699)	grad_norm 3.0153 (inf)	loss_scale 1024.0000 (1950.7808)	mem 11711MB
[2024-07-04 10:52:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:06:02 lr 0.000040	 wd 0.0000	time 0.4261 (0.4521)	loss 1.4612 (1.3702)	grad_norm 6.8565 (inf)	loss_scale 1024.0000 (1896.2963)	mem 11711MB
[2024-07-04 10:53:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:05:17 lr 0.000040	 wd 0.0000	time 0.4289 (0.4518)	loss 1.0495 (1.3690)	grad_norm 6.3107 (inf)	loss_scale 1024.0000 (1847.8623)	mem 11711MB
[2024-07-04 10:54:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:04:31 lr 0.000040	 wd 0.0000	time 0.4325 (0.4515)	loss 1.5284 (1.3709)	grad_norm 3.7888 (inf)	loss_scale 1024.0000 (1804.5239)	mem 11711MB
[2024-07-04 10:54:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:03:46 lr 0.000040	 wd 0.0000	time 0.4345 (0.4513)	loss 1.4299 (1.3721)	grad_norm 6.0163 (inf)	loss_scale 1024.0000 (1765.5172)	mem 11711MB
[2024-07-04 10:55:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:03:01 lr 0.000040	 wd 0.0000	time 0.4399 (0.4511)	loss 1.6225 (1.3730)	grad_norm 3.9223 (inf)	loss_scale 1024.0000 (1730.2237)	mem 11711MB
[2024-07-04 10:56:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:02:16 lr 0.000040	 wd 0.0000	time 0.4393 (0.4509)	loss 1.3473 (1.3710)	grad_norm 5.0457 (inf)	loss_scale 1024.0000 (1698.1372)	mem 11711MB
[2024-07-04 10:57:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:01:31 lr 0.000040	 wd 0.0000	time 0.4359 (0.4507)	loss 0.9557 (1.3704)	grad_norm 4.6998 (inf)	loss_scale 1024.0000 (1668.8396)	mem 11711MB
[2024-07-04 10:57:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:45 lr 0.000040	 wd 0.0000	time 0.4235 (0.4506)	loss 1.6413 (1.3706)	grad_norm 3.7907 (inf)	loss_scale 1024.0000 (1641.9825)	mem 11711MB
[2024-07-04 10:58:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.4315 (0.4506)	loss 1.4636 (1.3705)	grad_norm 4.7621 (inf)	loss_scale 1024.0000 (1617.2731)	mem 11711MB
[2024-07-04 10:58:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 5 training takes 0:18:49
[2024-07-04 10:58:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.307 (11.307)	Loss 0.4224 (0.4224)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 11711MB
[2024-07-04 10:59:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.058 Acc@5 97.250
[2024-07-04 10:59:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-04 10:59:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-04 10:59:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][0/2502]	eta 8:08:23 lr 0.000040	 wd 0.0000	time 11.7119 (11.7119)	loss 1.7622 (1.7622)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 10:59:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:22:19 lr 0.000040	 wd 0.0000	time 0.4327 (0.5576)	loss 1.2344 (1.3556)	grad_norm 6.4373 (5.8368)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 11:00:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:19:16 lr 0.000040	 wd 0.0000	time 0.4166 (0.5023)	loss 1.4452 (1.3701)	grad_norm 3.5429 (5.3402)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 11:01:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:17:45 lr 0.000040	 wd 0.0000	time 0.4415 (0.4839)	loss 1.5394 (1.3767)	grad_norm 5.5902 (5.2519)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 11:02:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:16:37 lr 0.000040	 wd 0.0000	time 0.4334 (0.4746)	loss 1.4256 (1.3700)	grad_norm 4.4675 (5.1600)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 11:02:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:15:38 lr 0.000040	 wd 0.0000	time 0.4182 (0.4687)	loss 1.5083 (1.3674)	grad_norm 8.2985 (5.2827)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 11:03:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:14:44 lr 0.000040	 wd 0.0000	time 0.4352 (0.4651)	loss 1.5167 (1.3688)	grad_norm 4.5839 (5.2021)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 11:04:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:13:53 lr 0.000040	 wd 0.0000	time 0.4238 (0.4624)	loss 1.3994 (1.3693)	grad_norm 4.3452 (5.3293)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 11:05:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:13:03 lr 0.000040	 wd 0.0000	time 0.4283 (0.4605)	loss 1.1374 (1.3696)	grad_norm 4.6014 (5.2452)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 11:05:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:12:15 lr 0.000040	 wd 0.0000	time 0.4427 (0.4590)	loss 1.5545 (1.3714)	grad_norm 4.3625 (5.2004)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 11:06:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:11:27 lr 0.000040	 wd 0.0000	time 0.4406 (0.4578)	loss 1.2986 (1.3677)	grad_norm 7.0058 (5.1945)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 11:07:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:10:40 lr 0.000040	 wd 0.0000	time 0.4216 (0.4568)	loss 1.2989 (1.3654)	grad_norm 7.9176 (5.1893)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 11:08:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:09:53 lr 0.000040	 wd 0.0000	time 0.4277 (0.4559)	loss 1.0958 (1.3664)	grad_norm 4.7318 (5.1609)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 11:08:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:09:07 lr 0.000040	 wd 0.0000	time 0.4252 (0.4552)	loss 1.5011 (1.3652)	grad_norm 3.6705 (5.1237)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 11:09:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:08:20 lr 0.000040	 wd 0.0000	time 0.4308 (0.4546)	loss 1.7465 (1.3631)	grad_norm 5.3912 (5.1026)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 11:10:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:07:34 lr 0.000040	 wd 0.0000	time 0.4417 (0.4541)	loss 1.4689 (1.3654)	grad_norm 4.8972 (5.0784)	loss_scale 1024.0000 (1024.0000)	mem 11711MB
[2024-07-04 11:11:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:06:49 lr 0.000040	 wd 0.0000	time 0.4050 (0.4536)	loss 1.4249 (1.3637)	grad_norm 4.5753 (nan)	loss_scale 512.0000 (1006.7308)	mem 11711MB
[2024-07-04 11:11:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:06:03 lr 0.000040	 wd 0.0000	time 0.4253 (0.4532)	loss 1.5670 (1.3636)	grad_norm 4.0966 (nan)	loss_scale 512.0000 (977.6461)	mem 11711MB
[2024-07-04 11:12:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:05:17 lr 0.000040	 wd 0.0000	time 0.4242 (0.4529)	loss 1.0871 (1.3634)	grad_norm 4.4052 (nan)	loss_scale 512.0000 (951.7912)	mem 11711MB
[2024-07-04 11:13:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:04:32 lr 0.000040	 wd 0.0000	time 0.4339 (0.4526)	loss 1.2579 (1.3633)	grad_norm 3.5087 (nan)	loss_scale 512.0000 (928.6565)	mem 11711MB
[2024-07-04 11:14:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:03:47 lr 0.000039	 wd 0.0000	time 0.4366 (0.4523)	loss 1.0912 (1.3636)	grad_norm 4.9806 (nan)	loss_scale 512.0000 (907.8341)	mem 11711MB
[2024-07-04 11:14:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:03:01 lr 0.000039	 wd 0.0000	time 0.4296 (0.4520)	loss 1.4994 (1.3629)	grad_norm 5.0391 (nan)	loss_scale 512.0000 (888.9938)	mem 11711MB
[2024-07-04 11:15:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:02:16 lr 0.000039	 wd 0.0000	time 0.4232 (0.4518)	loss 1.2681 (1.3629)	grad_norm 4.2121 (nan)	loss_scale 512.0000 (871.8655)	mem 11711MB
[2024-07-04 11:16:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:01:31 lr 0.000039	 wd 0.0000	time 0.4340 (0.4516)	loss 1.5026 (1.3635)	grad_norm 5.8817 (nan)	loss_scale 512.0000 (856.2260)	mem 11711MB
[2024-07-04 11:17:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:46 lr 0.000039	 wd 0.0000	time 0.4308 (0.4514)	loss 1.1544 (1.3629)	grad_norm 2.9967 (nan)	loss_scale 512.0000 (841.8892)	mem 11711MB
[2024-07-04 11:17:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.4356 (0.4513)	loss 0.9859 (1.3633)	grad_norm 5.7624 (nan)	loss_scale 512.0000 (828.6989)	mem 11711MB
[2024-07-04 11:17:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 6 training takes 0:18:52
[2024-07-04 11:18:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 10.864 (10.864)	Loss 0.4280 (0.4280)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 11711MB
[2024-07-04 11:18:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.094 Acc@5 97.324
[2024-07-04 11:18:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-04 11:18:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-04 11:18:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][0/2502]	eta 8:12:58 lr 0.000039	 wd 0.0000	time 11.8221 (11.8221)	loss 1.6738 (1.6738)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:19:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:22:24 lr 0.000039	 wd 0.0000	time 0.4313 (0.5597)	loss 1.3715 (1.3737)	grad_norm 4.1264 (5.1213)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:19:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:19:18 lr 0.000039	 wd 0.0000	time 0.4326 (0.5034)	loss 1.5873 (1.3556)	grad_norm 4.0447 (4.9217)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:20:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:17:47 lr 0.000039	 wd 0.0000	time 0.4274 (0.4846)	loss 1.3242 (1.3562)	grad_norm 6.9524 (4.7902)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:21:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:16:38 lr 0.000039	 wd 0.0000	time 0.4243 (0.4751)	loss 1.3952 (1.3598)	grad_norm 3.7459 (4.6945)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:22:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:15:39 lr 0.000039	 wd 0.0000	time 0.4079 (0.4693)	loss 1.5022 (1.3561)	grad_norm 4.7561 (4.7309)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:22:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:14:45 lr 0.000039	 wd 0.0000	time 0.4266 (0.4655)	loss 1.3706 (1.3592)	grad_norm 4.2036 (4.8190)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:23:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:13:53 lr 0.000039	 wd 0.0000	time 0.4263 (0.4627)	loss 1.4225 (1.3610)	grad_norm 4.6262 (4.8965)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:24:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:13:04 lr 0.000039	 wd 0.0000	time 0.4305 (0.4607)	loss 1.0509 (1.3630)	grad_norm 6.1560 (4.9245)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:25:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:12:15 lr 0.000039	 wd 0.0000	time 0.4299 (0.4591)	loss 1.1648 (1.3656)	grad_norm 4.2761 (5.0556)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:25:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:11:27 lr 0.000039	 wd 0.0000	time 0.4311 (0.4578)	loss 1.2466 (1.3628)	grad_norm 4.6677 (5.0416)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:26:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:10:40 lr 0.000039	 wd 0.0000	time 0.4169 (0.4568)	loss 1.3662 (1.3614)	grad_norm 4.5560 (4.9970)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:27:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:09:53 lr 0.000039	 wd 0.0000	time 0.4281 (0.4560)	loss 1.2986 (1.3585)	grad_norm 3.4915 (5.0012)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:28:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:09:07 lr 0.000039	 wd 0.0000	time 0.4302 (0.4553)	loss 1.4387 (1.3593)	grad_norm 3.6595 (4.9687)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:28:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:08:21 lr 0.000039	 wd 0.0000	time 0.4320 (0.4546)	loss 1.5587 (1.3597)	grad_norm 5.6845 (4.9627)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:29:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:07:35 lr 0.000039	 wd 0.0000	time 0.4291 (0.4542)	loss 1.4480 (1.3589)	grad_norm 4.7008 (4.9686)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:30:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:06:49 lr 0.000039	 wd 0.0000	time 0.4392 (0.4537)	loss 1.5189 (1.3602)	grad_norm 4.7316 (4.9729)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:31:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:06:03 lr 0.000039	 wd 0.0000	time 0.4271 (0.4533)	loss 1.5522 (1.3602)	grad_norm 4.8503 (4.9909)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:31:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:05:17 lr 0.000039	 wd 0.0000	time 0.4335 (0.4530)	loss 1.3204 (1.3596)	grad_norm 5.2250 (4.9910)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:32:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:04:32 lr 0.000039	 wd 0.0000	time 0.4204 (0.4526)	loss 1.3302 (1.3589)	grad_norm 3.7376 (4.9644)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 11:33:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:03:47 lr 0.000039	 wd 0.0000	time 0.4282 (0.4524)	loss 1.5019 (1.3595)	grad_norm 4.7104 (4.9358)	loss_scale 512.0000 (512.0000)	mem 11711MB
[2024-07-04 13:13:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/config.json
[2024-07-04 13:13:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    FINETUNE_MODE: sequence_stage2
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: swin_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    DEPTHS:
    - 3
    - 3
    - 9
    - 3
    DIMS:
    - 96
    - 192
    - 384
    - 768
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 4.0e-05
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.0e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 4.0e-08
  WEIGHT_DECAY: 1.0e-08

[2024-07-04 13:13:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility/configs/swin/diffusion_ft_swin_base_patch4_window7_224_22kto1k_sequence_stage_process2.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-04 13:13:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 108): INFO Creating model:swin_diffusion_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2
[2024-07-04 13:13:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 110): INFO SwinTransformer_Diffusion_Finetune(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-04 13:13:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 113): INFO number of params: 62564960
[2024-07-04 13:13:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 116): INFO number of GFLOPs: 15.438473216
[2024-07-04 13:13:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 148): INFO auto resuming from pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth
[2024-07-04 13:13:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 19): INFO ==============> Resuming form pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth....................
[2024-07-04 13:13:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 26): INFO <All keys matched successfully>
[2024-07-04 13:13:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 36): INFO => loaded successfully 'pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth' (epoch 1)
[2024-07-04 13:14:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 12.865 (12.865)	Loss 0.4116 (0.4116)	Acc@1 92.773 (92.773)	Acc@5 98.242 (98.242)	Mem 2110MB
[2024-07-04 13:14:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.150 Acc@5 97.280
[2024-07-04 13:14:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 155): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-04 13:14:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 168): INFO Start training
[2024-07-04 13:14:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][0/2502]	eta 8:01:38 lr 0.000016	 wd 0.0000	time 11.5500 (11.5500)	loss 1.5398 (1.5398)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 11464MB
[2024-07-04 13:15:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:22:21 lr 0.000016	 wd 0.0000	time 0.4272 (0.5584)	loss 1.4709 (1.3998)	grad_norm 3.6444 (5.7466)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:16:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:19:15 lr 0.000017	 wd 0.0000	time 0.4260 (0.5017)	loss 1.3392 (1.3743)	grad_norm 5.3775 (5.5036)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:16:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:17:43 lr 0.000017	 wd 0.0000	time 0.4300 (0.4830)	loss 1.2835 (1.3581)	grad_norm 4.2685 (5.3690)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:17:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:16:35 lr 0.000017	 wd 0.0000	time 0.4289 (0.4736)	loss 1.5578 (1.3643)	grad_norm 6.5299 (5.3922)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:18:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:15:37 lr 0.000018	 wd 0.0000	time 0.4343 (0.4681)	loss 1.4002 (1.3638)	grad_norm 7.0777 (5.3741)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:19:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:14:43 lr 0.000018	 wd 0.0000	time 0.4187 (0.4645)	loss 0.9915 (1.3674)	grad_norm 5.2398 (5.3628)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:19:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:13:51 lr 0.000018	 wd 0.0000	time 0.4241 (0.4617)	loss 1.6131 (1.3669)	grad_norm 7.9084 (5.3670)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:20:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:13:01 lr 0.000019	 wd 0.0000	time 0.4333 (0.4594)	loss 1.5412 (1.3682)	grad_norm 3.8761 (5.4481)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:21:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:12:13 lr 0.000019	 wd 0.0000	time 0.4268 (0.4579)	loss 1.5475 (1.3635)	grad_norm 5.4960 (5.4603)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:22:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:11:25 lr 0.000019	 wd 0.0000	time 0.4360 (0.4566)	loss 1.3676 (1.3636)	grad_norm 5.6856 (5.5298)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:22:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:10:38 lr 0.000020	 wd 0.0000	time 0.4252 (0.4556)	loss 1.5199 (1.3640)	grad_norm 2.6013 (5.5008)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:23:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:09:52 lr 0.000020	 wd 0.0000	time 0.4311 (0.4547)	loss 1.5284 (1.3665)	grad_norm 4.5058 (5.4588)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:24:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:09:05 lr 0.000020	 wd 0.0000	time 0.4292 (0.4541)	loss 1.5778 (1.3697)	grad_norm 3.7356 (5.4428)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:24:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:08:19 lr 0.000020	 wd 0.0000	time 0.4357 (0.4535)	loss 1.4517 (1.3709)	grad_norm 8.1837 (5.4340)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:25:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:07:33 lr 0.000021	 wd 0.0000	time 0.4231 (0.4530)	loss 1.3478 (1.3695)	grad_norm 6.6317 (5.3970)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:26:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:06:48 lr 0.000021	 wd 0.0000	time 0.4363 (0.4525)	loss 1.5015 (1.3697)	grad_norm 5.5473 (5.3924)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:27:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:06:02 lr 0.000021	 wd 0.0000	time 0.4337 (0.4522)	loss 1.4464 (1.3689)	grad_norm 4.8028 (5.3694)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:27:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:05:17 lr 0.000022	 wd 0.0000	time 0.4405 (0.4518)	loss 1.2862 (1.3695)	grad_norm 5.7241 (5.3600)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:28:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:04:31 lr 0.000022	 wd 0.0000	time 0.4318 (0.4515)	loss 1.5011 (1.3690)	grad_norm 4.8477 (5.4015)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:29:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:03:46 lr 0.000022	 wd 0.0000	time 0.4277 (0.4513)	loss 1.4411 (1.3667)	grad_norm 4.9771 (5.4402)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:30:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:03:01 lr 0.000023	 wd 0.0000	time 0.4314 (0.4510)	loss 1.2378 (1.3676)	grad_norm 12.1077 (5.4354)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:30:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:02:16 lr 0.000023	 wd 0.0000	time 0.4267 (0.4508)	loss 1.5994 (1.3684)	grad_norm 13.4487 (5.4740)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:31:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:01:31 lr 0.000023	 wd 0.0000	time 0.4322 (0.4506)	loss 1.2602 (1.3671)	grad_norm 8.5035 (5.4961)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:32:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:45 lr 0.000024	 wd 0.0000	time 0.4327 (0.4504)	loss 1.6270 (1.3667)	grad_norm 6.1906 (5.4668)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:33:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.4233 (0.4501)	loss 1.5473 (1.3674)	grad_norm 3.2747 (5.4607)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:33:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 2 training takes 0:18:48
[2024-07-04 13:33:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 10.497 (10.497)	Loss 0.4155 (0.4155)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 11714MB
[2024-07-04 13:33:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.038 Acc@5 97.306
[2024-07-04 13:33:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-04 13:33:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-04 13:33:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][0/2502]	eta 7:45:32 lr 0.000024	 wd 0.0000	time 11.1640 (11.1640)	loss 1.1158 (1.1158)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:34:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:22:13 lr 0.000024	 wd 0.0000	time 0.4316 (0.5553)	loss 1.3673 (1.4013)	grad_norm 4.2247 (5.7478)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:35:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:19:13 lr 0.000025	 wd 0.0000	time 0.4246 (0.5010)	loss 1.5538 (1.3972)	grad_norm 3.2063 (5.6667)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:36:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:17:43 lr 0.000025	 wd 0.0000	time 0.4377 (0.4830)	loss 1.6194 (1.3863)	grad_norm 28.8772 (5.8344)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:36:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:16:35 lr 0.000025	 wd 0.0000	time 0.4314 (0.4737)	loss 1.0143 (1.3730)	grad_norm 26.2652 (5.7536)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 13:37:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:15:37 lr 0.000026	 wd 0.0000	time 0.4320 (0.4681)	loss 1.4588 (1.3733)	grad_norm 4.3189 (5.6321)	loss_scale 1024.0000 (583.5369)	mem 11714MB
[2024-07-04 13:38:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:14:43 lr 0.000026	 wd 0.0000	time 0.4265 (0.4643)	loss 1.3384 (1.3701)	grad_norm 4.7444 (5.6439)	loss_scale 1024.0000 (656.8253)	mem 11714MB
[2024-07-04 13:38:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:13:51 lr 0.000026	 wd 0.0000	time 0.4065 (0.4617)	loss 1.5952 (1.3709)	grad_norm 3.9208 (5.5403)	loss_scale 1024.0000 (709.2040)	mem 11714MB
[2024-07-04 13:39:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:13:02 lr 0.000027	 wd 0.0000	time 0.4173 (0.4596)	loss 1.5117 (1.3721)	grad_norm 3.8197 (5.5752)	loss_scale 1024.0000 (748.5044)	mem 11714MB
[2024-07-04 13:40:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:12:13 lr 0.000027	 wd 0.0000	time 0.4234 (0.4581)	loss 1.6887 (1.3710)	grad_norm 4.4414 (5.5070)	loss_scale 1024.0000 (779.0810)	mem 11714MB
[2024-07-04 13:41:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:11:26 lr 0.000027	 wd 0.0000	time 0.4251 (0.4568)	loss 1.5769 (1.3718)	grad_norm 4.4400 (5.4474)	loss_scale 1024.0000 (803.5485)	mem 11714MB
[2024-07-04 13:41:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:10:38 lr 0.000028	 wd 0.0000	time 0.4361 (0.4557)	loss 0.8546 (1.3722)	grad_norm 4.1348 (5.4454)	loss_scale 1024.0000 (823.5713)	mem 11714MB
[2024-07-04 13:42:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:09:52 lr 0.000028	 wd 0.0000	time 0.4313 (0.4548)	loss 1.3397 (1.3760)	grad_norm 8.0206 (5.4518)	loss_scale 1024.0000 (840.2598)	mem 11714MB
[2024-07-04 13:43:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:09:05 lr 0.000028	 wd 0.0000	time 0.4254 (0.4541)	loss 1.5824 (1.3784)	grad_norm 5.8228 (5.4189)	loss_scale 1024.0000 (854.3828)	mem 11714MB
[2024-07-04 13:44:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:08:19 lr 0.000028	 wd 0.0000	time 0.4309 (0.4535)	loss 1.4449 (1.3759)	grad_norm 4.5065 (5.4304)	loss_scale 1024.0000 (866.4897)	mem 11714MB
[2024-07-04 13:44:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:07:33 lr 0.000029	 wd 0.0000	time 0.4329 (0.4530)	loss 0.9599 (1.3747)	grad_norm 4.7036 (5.4447)	loss_scale 1024.0000 (876.9833)	mem 11714MB
[2024-07-04 13:45:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:06:48 lr 0.000029	 wd 0.0000	time 0.4329 (0.4525)	loss 1.0325 (1.3726)	grad_norm 5.8447 (5.4489)	loss_scale 1024.0000 (886.1661)	mem 11714MB
[2024-07-04 13:46:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:06:02 lr 0.000029	 wd 0.0000	time 0.4349 (0.4521)	loss 1.5673 (1.3717)	grad_norm 8.2636 (5.4402)	loss_scale 1024.0000 (894.2693)	mem 11714MB
[2024-07-04 13:47:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:05:17 lr 0.000030	 wd 0.0000	time 0.4473 (0.4517)	loss 1.2543 (1.3701)	grad_norm 4.9059 (5.4105)	loss_scale 1024.0000 (901.4725)	mem 11714MB
[2024-07-04 13:47:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:04:31 lr 0.000030	 wd 0.0000	time 0.4234 (0.4514)	loss 1.4373 (1.3706)	grad_norm 3.5065 (5.4092)	loss_scale 1024.0000 (907.9179)	mem 11714MB
[2024-07-04 13:48:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:03:46 lr 0.000030	 wd 0.0000	time 0.4281 (0.4510)	loss 1.5710 (1.3704)	grad_norm 3.7620 (5.3952)	loss_scale 1024.0000 (913.7191)	mem 11714MB
[2024-07-04 13:49:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:03:01 lr 0.000031	 wd 0.0000	time 0.4311 (0.4508)	loss 1.5360 (1.3711)	grad_norm 5.0891 (5.4053)	loss_scale 1024.0000 (918.9681)	mem 11714MB
[2024-07-04 13:50:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:02:16 lr 0.000031	 wd 0.0000	time 0.4165 (0.4505)	loss 1.1892 (1.3716)	grad_norm 6.0515 (5.3940)	loss_scale 1024.0000 (923.7401)	mem 11714MB
[2024-07-04 13:50:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:01:30 lr 0.000031	 wd 0.0000	time 0.4335 (0.4503)	loss 1.4122 (1.3715)	grad_norm 4.2855 (5.3884)	loss_scale 1024.0000 (928.0973)	mem 11714MB
[2024-07-04 13:51:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:45 lr 0.000032	 wd 0.0000	time 0.4239 (0.4501)	loss 1.4742 (1.3704)	grad_norm 8.4710 (5.4028)	loss_scale 1024.0000 (932.0916)	mem 11714MB
[2024-07-04 13:52:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000032	 wd 0.0000	time 0.4216 (0.4499)	loss 0.9967 (1.3719)	grad_norm 4.1884 (5.4251)	loss_scale 1024.0000 (935.7665)	mem 11714MB
[2024-07-04 13:52:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 3 training takes 0:18:48
[2024-07-04 13:52:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 10.995 (10.995)	Loss 0.4141 (0.4141)	Acc@1 92.969 (92.969)	Acc@5 98.633 (98.633)	Mem 11714MB
[2024-07-04 13:52:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.120 Acc@5 97.294
[2024-07-04 13:52:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-04 13:52:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-04 13:52:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][0/2502]	eta 7:58:03 lr 0.000032	 wd 0.0000	time 11.4641 (11.4641)	loss 1.5134 (1.5134)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 13:53:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:22:12 lr 0.000032	 wd 0.0000	time 0.4278 (0.5545)	loss 1.3813 (1.3375)	grad_norm 4.4477 (5.1716)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 13:54:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:19:11 lr 0.000033	 wd 0.0000	time 0.4333 (0.5000)	loss 1.5289 (1.3667)	grad_norm 3.9667 (5.1089)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 13:55:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:17:40 lr 0.000033	 wd 0.0000	time 0.4348 (0.4815)	loss 1.2794 (1.3751)	grad_norm 4.3907 (5.3174)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 13:55:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:16:32 lr 0.000033	 wd 0.0000	time 0.4377 (0.4723)	loss 1.4045 (1.3710)	grad_norm 4.6087 (5.2375)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 13:56:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:15:34 lr 0.000034	 wd 0.0000	time 0.4319 (0.4667)	loss 1.5541 (1.3739)	grad_norm 7.0095 (5.1637)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 13:57:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:14:40 lr 0.000034	 wd 0.0000	time 0.4272 (0.4631)	loss 1.2721 (1.3675)	grad_norm 4.4364 (5.1109)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 13:58:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:13:49 lr 0.000034	 wd 0.0000	time 0.4331 (0.4605)	loss 1.3409 (1.3686)	grad_norm 4.2893 (5.1493)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 13:58:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:13:00 lr 0.000035	 wd 0.0000	time 0.4267 (0.4584)	loss 1.4570 (1.3664)	grad_norm 4.4866 (5.1094)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 13:59:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:12:11 lr 0.000035	 wd 0.0000	time 0.4323 (0.4568)	loss 1.7274 (1.3713)	grad_norm 4.8385 (5.2562)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:00:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:11:24 lr 0.000035	 wd 0.0000	time 0.4211 (0.4555)	loss 1.6058 (1.3750)	grad_norm 5.0951 (5.2430)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:01:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:10:37 lr 0.000036	 wd 0.0000	time 0.4341 (0.4545)	loss 1.2259 (1.3763)	grad_norm 5.6218 (5.2173)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:01:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:09:50 lr 0.000036	 wd 0.0000	time 0.4316 (0.4536)	loss 1.1500 (1.3765)	grad_norm 5.8592 (5.2402)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:02:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:09:04 lr 0.000036	 wd 0.0000	time 0.4221 (0.4529)	loss 1.5098 (1.3779)	grad_norm 4.0969 (5.2405)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:03:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:08:18 lr 0.000036	 wd 0.0000	time 0.4061 (0.4523)	loss 1.2966 (1.3774)	grad_norm 5.3790 (5.2311)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:04:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:07:32 lr 0.000037	 wd 0.0000	time 0.4229 (0.4517)	loss 1.3521 (1.3760)	grad_norm 7.4572 (5.2114)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:04:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:06:47 lr 0.000037	 wd 0.0000	time 0.4271 (0.4513)	loss 1.2139 (1.3766)	grad_norm 4.4861 (5.1826)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:05:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:06:01 lr 0.000037	 wd 0.0000	time 0.4269 (0.4510)	loss 1.4720 (1.3754)	grad_norm 6.6793 (5.1767)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:06:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:05:16 lr 0.000038	 wd 0.0000	time 0.4332 (0.4506)	loss 1.4612 (1.3755)	grad_norm 6.4792 (5.1582)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:07:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:04:31 lr 0.000038	 wd 0.0000	time 0.4319 (0.4503)	loss 1.1669 (1.3736)	grad_norm 4.0539 (5.2130)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:07:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:03:45 lr 0.000038	 wd 0.0000	time 0.4279 (0.4500)	loss 1.1634 (1.3713)	grad_norm 3.1325 (5.1801)	loss_scale 2048.0000 (1060.8456)	mem 11714MB
[2024-07-04 14:08:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:03:00 lr 0.000039	 wd 0.0000	time 0.4325 (0.4498)	loss 1.2831 (1.3715)	grad_norm 4.7545 (inf)	loss_scale 1024.0000 (1078.5873)	mem 11714MB
[2024-07-04 14:09:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:02:15 lr 0.000039	 wd 0.0000	time 0.4323 (0.4496)	loss 1.5622 (1.3717)	grad_norm 5.1301 (inf)	loss_scale 1024.0000 (1076.1072)	mem 11714MB
[2024-07-04 14:10:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:01:30 lr 0.000039	 wd 0.0000	time 0.4170 (0.4494)	loss 1.5859 (1.3724)	grad_norm 6.4692 (inf)	loss_scale 1024.0000 (1073.8427)	mem 11714MB
[2024-07-04 14:10:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:45 lr 0.000040	 wd 0.0000	time 0.4312 (0.4492)	loss 1.3197 (1.3720)	grad_norm 4.9958 (inf)	loss_scale 1024.0000 (1071.7668)	mem 11714MB
[2024-07-04 14:11:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.4285 (0.4490)	loss 1.3661 (1.3724)	grad_norm 3.7735 (inf)	loss_scale 1024.0000 (1069.8569)	mem 11714MB
[2024-07-04 14:11:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 4 training takes 0:18:46
[2024-07-04 14:11:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.275 (11.275)	Loss 0.4089 (0.4089)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 11714MB
[2024-07-04 14:11:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.026 Acc@5 97.308
[2024-07-04 14:11:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-04 14:11:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-04 14:12:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][0/2502]	eta 7:06:38 lr 0.000040	 wd 0.0000	time 10.2313 (10.2313)	loss 1.2051 (1.2051)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:12:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:21:58 lr 0.000040	 wd 0.0000	time 0.4319 (0.5487)	loss 1.3774 (1.3585)	grad_norm 6.2689 (5.2292)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:13:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:19:03 lr 0.000040	 wd 0.0000	time 0.4348 (0.4966)	loss 1.2469 (1.3691)	grad_norm 17.3633 (5.1931)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:14:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:17:34 lr 0.000040	 wd 0.0000	time 0.4257 (0.4791)	loss 1.6413 (1.3591)	grad_norm 3.6132 (5.1765)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:15:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:16:28 lr 0.000040	 wd 0.0000	time 0.4206 (0.4703)	loss 1.5039 (1.3635)	grad_norm 4.4414 (5.1606)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:15:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:15:31 lr 0.000040	 wd 0.0000	time 0.4329 (0.4652)	loss 1.4493 (1.3595)	grad_norm 5.4865 (5.0986)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:16:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:14:38 lr 0.000040	 wd 0.0000	time 0.4249 (0.4617)	loss 1.6586 (1.3611)	grad_norm 6.3229 (5.0991)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:17:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:13:47 lr 0.000040	 wd 0.0000	time 0.4266 (0.4593)	loss 1.5322 (1.3599)	grad_norm 5.0982 (5.0938)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:18:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:12:58 lr 0.000040	 wd 0.0000	time 0.4253 (0.4573)	loss 1.1411 (1.3614)	grad_norm 4.0019 (5.1186)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:18:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:12:10 lr 0.000040	 wd 0.0000	time 0.4203 (0.4560)	loss 1.2549 (1.3630)	grad_norm 11.3132 (5.2150)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:19:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:11:23 lr 0.000040	 wd 0.0000	time 0.4192 (0.4548)	loss 1.5027 (1.3649)	grad_norm 4.9247 (5.2460)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:20:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:10:36 lr 0.000040	 wd 0.0000	time 0.4276 (0.4539)	loss 1.4866 (1.3673)	grad_norm 4.3448 (5.3102)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:21:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:09:50 lr 0.000040	 wd 0.0000	time 0.4392 (0.4532)	loss 1.3115 (1.3673)	grad_norm 2.5763 (5.3498)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:21:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:09:03 lr 0.000040	 wd 0.0000	time 0.4287 (0.4526)	loss 1.3527 (1.3696)	grad_norm 6.9555 (5.3108)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:22:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:08:18 lr 0.000040	 wd 0.0000	time 0.4197 (0.4520)	loss 1.2634 (1.3688)	grad_norm 6.0104 (5.2762)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:23:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:07:32 lr 0.000040	 wd 0.0000	time 0.4273 (0.4516)	loss 1.4175 (1.3699)	grad_norm 5.7384 (5.2764)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 14:23:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:06:46 lr 0.000040	 wd 0.0000	time 0.4338 (0.4512)	loss 1.5067 (1.3701)	grad_norm 6.5169 (inf)	loss_scale 512.0000 (1016.3248)	mem 11714MB
[2024-07-04 14:24:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:06:01 lr 0.000040	 wd 0.0000	time 0.4444 (0.4509)	loss 1.0584 (1.3695)	grad_norm 4.8454 (inf)	loss_scale 512.0000 (986.6761)	mem 11714MB
[2024-07-04 14:25:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:05:16 lr 0.000040	 wd 0.0000	time 0.4312 (0.4506)	loss 1.5017 (1.3701)	grad_norm 4.0227 (inf)	loss_scale 512.0000 (960.3198)	mem 11714MB
[2024-07-04 14:26:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:04:31 lr 0.000040	 wd 0.0000	time 0.4292 (0.4503)	loss 1.5846 (1.3694)	grad_norm 3.3166 (inf)	loss_scale 512.0000 (936.7365)	mem 11714MB
[2024-07-04 14:26:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:03:45 lr 0.000040	 wd 0.0000	time 0.4333 (0.4501)	loss 1.2285 (1.3705)	grad_norm 13.7041 (inf)	loss_scale 512.0000 (915.5102)	mem 11714MB
[2024-07-04 14:27:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:03:00 lr 0.000040	 wd 0.0000	time 0.4296 (0.4498)	loss 1.5482 (1.3692)	grad_norm 3.5083 (inf)	loss_scale 512.0000 (896.3046)	mem 11714MB
[2024-07-04 14:28:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:02:15 lr 0.000040	 wd 0.0000	time 0.4169 (0.4496)	loss 1.4610 (1.3703)	grad_norm 5.0188 (inf)	loss_scale 512.0000 (878.8442)	mem 11714MB
[2024-07-04 14:29:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:01:30 lr 0.000040	 wd 0.0000	time 0.4255 (0.4494)	loss 1.4076 (1.3704)	grad_norm 3.7726 (inf)	loss_scale 512.0000 (862.9013)	mem 11714MB
[2024-07-04 14:29:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:45 lr 0.000040	 wd 0.0000	time 0.4266 (0.4492)	loss 0.9386 (1.3696)	grad_norm 3.4217 (inf)	loss_scale 512.0000 (848.2865)	mem 11714MB
[2024-07-04 14:30:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.4324 (0.4489)	loss 1.5844 (1.3696)	grad_norm 4.4606 (inf)	loss_scale 512.0000 (834.8405)	mem 11714MB
[2024-07-04 14:30:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 5 training takes 0:18:45
[2024-07-04 14:30:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.010 (11.010)	Loss 0.4055 (0.4055)	Acc@1 93.164 (93.164)	Acc@5 98.633 (98.633)	Mem 11714MB
[2024-07-04 14:31:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.164 Acc@5 97.278
[2024-07-04 14:31:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-04 14:31:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.16%
[2024-07-04 14:31:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saving......
[2024-07-04 14:31:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saved !!!
[2024-07-04 14:31:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][0/2502]	eta 7:22:17 lr 0.000040	 wd 0.0000	time 10.6067 (10.6067)	loss 1.5153 (1.5153)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:32:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:21:54 lr 0.000040	 wd 0.0000	time 0.4321 (0.5471)	loss 1.1178 (1.4048)	grad_norm 3.9462 (5.4280)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:32:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:19:02 lr 0.000040	 wd 0.0000	time 0.4298 (0.4965)	loss 1.0704 (1.3838)	grad_norm 12.1010 (5.3236)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:33:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:17:35 lr 0.000040	 wd 0.0000	time 0.4244 (0.4792)	loss 1.0354 (1.3827)	grad_norm 8.2024 (5.4485)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:34:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:16:29 lr 0.000040	 wd 0.0000	time 0.4312 (0.4706)	loss 1.4393 (1.3742)	grad_norm 4.1849 (5.2133)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:35:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:15:31 lr 0.000040	 wd 0.0000	time 0.4322 (0.4655)	loss 1.4183 (1.3737)	grad_norm 3.9178 (5.1976)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:35:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:14:38 lr 0.000040	 wd 0.0000	time 0.4233 (0.4619)	loss 1.6282 (1.3687)	grad_norm 5.7200 (5.2382)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:36:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:13:47 lr 0.000040	 wd 0.0000	time 0.4307 (0.4594)	loss 1.2060 (1.3702)	grad_norm 4.2954 (5.2820)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:37:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:12:58 lr 0.000040	 wd 0.0000	time 0.4289 (0.4575)	loss 1.2024 (1.3692)	grad_norm 4.5253 (5.3284)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:37:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:12:10 lr 0.000040	 wd 0.0000	time 0.4333 (0.4562)	loss 1.4443 (1.3692)	grad_norm 5.3333 (5.3373)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:38:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:11:23 lr 0.000040	 wd 0.0000	time 0.4462 (0.4551)	loss 1.5452 (1.3705)	grad_norm 4.9578 (5.3032)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:39:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:10:36 lr 0.000040	 wd 0.0000	time 0.4234 (0.4542)	loss 1.3682 (1.3711)	grad_norm 4.8756 (5.3278)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:40:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:09:50 lr 0.000040	 wd 0.0000	time 0.4452 (0.4536)	loss 1.1126 (1.3691)	grad_norm 4.2210 (5.3755)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:40:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:09:04 lr 0.000040	 wd 0.0000	time 0.4303 (0.4530)	loss 1.7006 (1.3695)	grad_norm 3.7160 (5.3997)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:41:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:08:18 lr 0.000040	 wd 0.0000	time 0.4281 (0.4524)	loss 1.5799 (1.3699)	grad_norm 6.4242 (5.3996)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:42:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:07:32 lr 0.000040	 wd 0.0000	time 0.4235 (0.4519)	loss 1.2463 (1.3731)	grad_norm 6.2633 (5.3907)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:43:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:06:47 lr 0.000040	 wd 0.0000	time 0.4332 (0.4515)	loss 1.1293 (1.3720)	grad_norm 4.9334 (5.3603)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:43:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:06:01 lr 0.000040	 wd 0.0000	time 0.4212 (0.4512)	loss 1.5727 (1.3710)	grad_norm 4.3925 (5.3450)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:44:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:05:16 lr 0.000040	 wd 0.0000	time 0.4244 (0.4509)	loss 1.3088 (1.3700)	grad_norm 10.3319 (5.3428)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:45:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:04:31 lr 0.000040	 wd 0.0000	time 0.4328 (0.4506)	loss 1.5431 (1.3698)	grad_norm 3.5808 (5.3066)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:46:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:03:46 lr 0.000039	 wd 0.0000	time 0.4328 (0.4503)	loss 1.7081 (1.3705)	grad_norm 6.0258 (5.3210)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:46:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:03:00 lr 0.000039	 wd 0.0000	time 0.4250 (0.4501)	loss 1.3819 (1.3699)	grad_norm 4.2827 (5.3058)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:47:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:02:15 lr 0.000039	 wd 0.0000	time 0.4306 (0.4498)	loss 1.0430 (1.3679)	grad_norm 7.8007 (5.2718)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:48:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:01:30 lr 0.000039	 wd 0.0000	time 0.4330 (0.4497)	loss 1.2895 (1.3679)	grad_norm 5.9213 (5.2667)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:49:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:45 lr 0.000039	 wd 0.0000	time 0.4274 (0.4495)	loss 1.5252 (1.3672)	grad_norm 4.3972 (5.2850)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:49:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.4165 (0.4493)	loss 1.0441 (1.3669)	grad_norm 6.3571 (5.2873)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:49:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 6 training takes 0:18:46
[2024-07-04 14:50:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.411 (11.411)	Loss 0.4238 (0.4238)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 11714MB
[2024-07-04 14:50:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.094 Acc@5 97.330
[2024-07-04 14:50:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-04 14:50:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.16%
[2024-07-04 14:50:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][0/2502]	eta 7:28:17 lr 0.000039	 wd 0.0000	time 10.7504 (10.7504)	loss 1.6734 (1.6734)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:51:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:22:01 lr 0.000039	 wd 0.0000	time 0.4268 (0.5503)	loss 1.3805 (1.3930)	grad_norm 5.2152 (4.7611)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:51:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:19:05 lr 0.000039	 wd 0.0000	time 0.4344 (0.4978)	loss 1.5325 (1.3980)	grad_norm 4.9715 (5.0976)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:52:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:17:37 lr 0.000039	 wd 0.0000	time 0.4280 (0.4800)	loss 1.4729 (1.3802)	grad_norm 4.6328 (4.9305)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:53:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:16:30 lr 0.000039	 wd 0.0000	time 0.4418 (0.4710)	loss 0.9854 (1.3862)	grad_norm 5.1154 (4.8328)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:54:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:15:32 lr 0.000039	 wd 0.0000	time 0.4353 (0.4658)	loss 1.4990 (1.3776)	grad_norm 3.5881 (4.8968)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 14:54:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:14:39 lr 0.000039	 wd 0.0000	time 0.4356 (0.4622)	loss 1.2288 (1.3777)	grad_norm 4.0261 (4.8389)	loss_scale 1024.0000 (535.8536)	mem 11714MB
[2024-07-04 14:55:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:13:48 lr 0.000039	 wd 0.0000	time 0.4406 (0.4596)	loss 1.6260 (1.3756)	grad_norm 5.8590 (4.9509)	loss_scale 1024.0000 (605.4893)	mem 11714MB
[2024-07-04 14:56:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:12:58 lr 0.000039	 wd 0.0000	time 0.4298 (0.4577)	loss 0.9787 (1.3714)	grad_norm 3.7600 (4.9464)	loss_scale 1024.0000 (657.7378)	mem 11714MB
[2024-07-04 14:57:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:12:10 lr 0.000039	 wd 0.0000	time 0.4343 (0.4562)	loss 0.8629 (1.3699)	grad_norm 4.7416 (4.9751)	loss_scale 1024.0000 (698.3885)	mem 11714MB
[2024-07-04 14:57:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:11:23 lr 0.000039	 wd 0.0000	time 0.4305 (0.4551)	loss 1.5906 (1.3721)	grad_norm 3.9242 (4.9369)	loss_scale 1024.0000 (730.9171)	mem 11714MB
[2024-07-04 14:58:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:10:36 lr 0.000039	 wd 0.0000	time 0.4222 (0.4540)	loss 1.3953 (1.3674)	grad_norm 3.5945 (4.9010)	loss_scale 1024.0000 (757.5368)	mem 11714MB
[2024-07-04 14:59:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:09:50 lr 0.000039	 wd 0.0000	time 0.4262 (0.4532)	loss 1.4918 (1.3653)	grad_norm 3.5159 (4.9141)	loss_scale 1024.0000 (779.7236)	mem 11714MB
[2024-07-04 15:00:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:09:03 lr 0.000039	 wd 0.0000	time 0.4415 (0.4525)	loss 1.6926 (1.3656)	grad_norm 3.5518 (4.9122)	loss_scale 1024.0000 (798.4996)	mem 11714MB
[2024-07-04 15:00:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:08:18 lr 0.000039	 wd 0.0000	time 0.4278 (0.4520)	loss 1.4663 (1.3661)	grad_norm 2.6324 (4.8891)	loss_scale 1024.0000 (814.5953)	mem 11714MB
[2024-07-04 15:01:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:07:32 lr 0.000039	 wd 0.0000	time 0.4331 (0.4515)	loss 1.5509 (1.3661)	grad_norm 5.1150 (4.8680)	loss_scale 1024.0000 (828.5463)	mem 11714MB
[2024-07-04 15:02:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:06:46 lr 0.000039	 wd 0.0000	time 0.4343 (0.4511)	loss 1.6245 (1.3673)	grad_norm 3.6245 (4.8505)	loss_scale 1024.0000 (840.7545)	mem 11714MB
[2024-07-04 15:03:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:06:01 lr 0.000039	 wd 0.0000	time 0.4210 (0.4507)	loss 1.4688 (1.3668)	grad_norm 5.1984 (4.8540)	loss_scale 1024.0000 (851.5273)	mem 11714MB
[2024-07-04 15:03:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:05:16 lr 0.000039	 wd 0.0000	time 0.4250 (0.4505)	loss 1.0870 (1.3654)	grad_norm 4.1355 (4.8426)	loss_scale 1024.0000 (861.1038)	mem 11714MB
[2024-07-04 15:04:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:04:31 lr 0.000039	 wd 0.0000	time 0.4273 (0.4502)	loss 1.4692 (1.3682)	grad_norm 6.7433 (4.8693)	loss_scale 1024.0000 (869.6728)	mem 11714MB
[2024-07-04 15:05:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:03:45 lr 0.000039	 wd 0.0000	time 0.4370 (0.4500)	loss 1.4043 (1.3698)	grad_norm 4.3483 (4.8865)	loss_scale 1024.0000 (877.3853)	mem 11714MB
[2024-07-04 15:06:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:03:00 lr 0.000039	 wd 0.0000	time 0.4263 (0.4497)	loss 1.6310 (1.3712)	grad_norm 5.0815 (4.8888)	loss_scale 1024.0000 (884.3636)	mem 11714MB
[2024-07-04 15:06:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:02:15 lr 0.000039	 wd 0.0000	time 0.4280 (0.4495)	loss 1.1058 (1.3687)	grad_norm 4.8335 (4.8940)	loss_scale 1024.0000 (890.7079)	mem 11714MB
[2024-07-04 15:07:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:01:30 lr 0.000039	 wd 0.0000	time 0.4297 (0.4494)	loss 1.1970 (1.3684)	grad_norm 3.4899 (4.9078)	loss_scale 1024.0000 (896.5007)	mem 11714MB
[2024-07-04 15:08:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:45 lr 0.000039	 wd 0.0000	time 0.4300 (0.4492)	loss 1.4297 (1.3685)	grad_norm 6.2482 (4.9154)	loss_scale 1024.0000 (901.8109)	mem 11714MB
[2024-07-04 15:09:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.4306 (0.4490)	loss 1.6660 (1.3685)	grad_norm 3.7644 (4.9054)	loss_scale 1024.0000 (906.6965)	mem 11714MB
[2024-07-04 15:09:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 7 training takes 0:18:46
[2024-07-04 15:09:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.425 (11.425)	Loss 0.4216 (0.4216)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 11714MB
[2024-07-04 15:09:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.190 Acc@5 97.366
[2024-07-04 15:09:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-04 15:09:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.19%
[2024-07-04 15:09:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saving......
[2024-07-04 15:09:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saved !!!
[2024-07-04 15:09:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][0/2502]	eta 7:04:41 lr 0.000039	 wd 0.0000	time 10.1843 (10.1843)	loss 1.7285 (1.7285)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:10:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:21:41 lr 0.000039	 wd 0.0000	time 0.4316 (0.5419)	loss 1.2205 (1.3550)	grad_norm 4.5159 (4.8535)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:11:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:18:58 lr 0.000039	 wd 0.0000	time 0.4300 (0.4947)	loss 1.5920 (1.3772)	grad_norm 3.1401 (4.9836)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:11:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:17:33 lr 0.000038	 wd 0.0000	time 0.4354 (0.4783)	loss 1.4136 (1.3741)	grad_norm 24.4705 (5.1788)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:12:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:16:28 lr 0.000038	 wd 0.0000	time 0.4256 (0.4701)	loss 1.5217 (1.3682)	grad_norm 4.1599 (5.1801)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:13:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:15:31 lr 0.000038	 wd 0.0000	time 0.4306 (0.4651)	loss 1.4900 (1.3654)	grad_norm 3.3098 (5.3022)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:14:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:14:38 lr 0.000038	 wd 0.0000	time 0.4175 (0.4618)	loss 1.3339 (1.3665)	grad_norm 4.5480 (5.1545)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:14:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:13:47 lr 0.000038	 wd 0.0000	time 0.4320 (0.4594)	loss 1.4917 (1.3685)	grad_norm 4.2507 (5.1773)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:15:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:12:58 lr 0.000038	 wd 0.0000	time 0.4223 (0.4576)	loss 1.1897 (1.3663)	grad_norm 5.1416 (5.1200)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:16:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:12:10 lr 0.000038	 wd 0.0000	time 0.4302 (0.4562)	loss 1.6234 (1.3698)	grad_norm 8.2005 (5.1939)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:17:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:11:23 lr 0.000038	 wd 0.0000	time 0.4248 (0.4549)	loss 1.3987 (1.3657)	grad_norm 6.3880 (5.2234)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:17:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:10:36 lr 0.000038	 wd 0.0000	time 0.4363 (0.4539)	loss 1.2623 (1.3655)	grad_norm 6.2486 (5.2301)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:18:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:09:50 lr 0.000038	 wd 0.0000	time 0.4392 (0.4533)	loss 1.1690 (1.3649)	grad_norm 3.9222 (5.1710)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:19:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:09:04 lr 0.000038	 wd 0.0000	time 0.4306 (0.4527)	loss 1.5347 (1.3636)	grad_norm 3.5946 (5.1527)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:20:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:08:18 lr 0.000038	 wd 0.0000	time 0.4437 (0.4522)	loss 1.5812 (1.3623)	grad_norm 4.5855 (5.1387)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:20:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:07:32 lr 0.000038	 wd 0.0000	time 0.4311 (0.4518)	loss 1.4623 (1.3625)	grad_norm 4.0707 (5.0951)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:21:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:06:47 lr 0.000038	 wd 0.0000	time 0.4306 (0.4514)	loss 1.6985 (1.3603)	grad_norm 4.2271 (5.0668)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:22:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:06:01 lr 0.000038	 wd 0.0000	time 0.4296 (0.4511)	loss 1.6386 (1.3612)	grad_norm 5.0041 (5.1119)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:23:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:05:16 lr 0.000038	 wd 0.0000	time 0.4322 (0.4508)	loss 1.2263 (1.3618)	grad_norm 2.8175 (5.1544)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:23:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:04:31 lr 0.000038	 wd 0.0000	time 0.4330 (0.4506)	loss 1.0793 (1.3617)	grad_norm 3.0306 (5.1494)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:24:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:03:46 lr 0.000038	 wd 0.0000	time 0.4263 (0.4504)	loss 1.0602 (1.3619)	grad_norm 5.0093 (5.1218)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 15:25:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:03:00 lr 0.000038	 wd 0.0000	time 0.4329 (0.4502)	loss 1.4977 (1.3616)	grad_norm 6.0000 (5.1142)	loss_scale 2048.0000 (1038.6216)	mem 11714MB
[2024-07-04 15:25:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:02:15 lr 0.000038	 wd 0.0000	time 0.4359 (0.4499)	loss 1.2588 (1.3608)	grad_norm 4.2873 (5.0820)	loss_scale 2048.0000 (1084.4816)	mem 11714MB
[2024-07-04 15:26:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:01:30 lr 0.000038	 wd 0.0000	time 0.4154 (0.4497)	loss 1.4617 (1.3609)	grad_norm 4.2747 (5.0595)	loss_scale 2048.0000 (1126.3555)	mem 11714MB
[2024-07-04 15:27:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:45 lr 0.000038	 wd 0.0000	time 0.4244 (0.4495)	loss 1.2257 (1.3607)	grad_norm 5.5176 (5.0472)	loss_scale 2048.0000 (1164.7414)	mem 11714MB
[2024-07-04 15:28:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000038	 wd 0.0000	time 0.4327 (0.4493)	loss 1.1408 (1.3606)	grad_norm 9.1412 (5.0460)	loss_scale 2048.0000 (1200.0576)	mem 11714MB
[2024-07-04 15:28:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 8 training takes 0:18:46
[2024-07-04 15:28:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.696 (11.696)	Loss 0.4104 (0.4104)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 11714MB
[2024-07-04 15:28:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.142 Acc@5 97.328
[2024-07-04 15:28:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-04 15:28:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.19%
[2024-07-04 15:28:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][0/2502]	eta 8:00:55 lr 0.000038	 wd 0.0000	time 11.5329 (11.5329)	loss 1.5178 (1.5178)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 11714MB
[2024-07-04 15:29:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:22:14 lr 0.000038	 wd 0.0000	time 0.4370 (0.5557)	loss 1.1920 (1.3854)	grad_norm 4.7454 (4.7661)	loss_scale 2048.0000 (2048.0000)	mem 11714MB
[2024-07-04 15:30:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:19:14 lr 0.000037	 wd 0.0000	time 0.4259 (0.5014)	loss 1.4197 (1.3578)	grad_norm 5.3712 (4.8574)	loss_scale 2048.0000 (2048.0000)	mem 11714MB
[2024-07-04 15:31:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:17:43 lr 0.000037	 wd 0.0000	time 0.4309 (0.4831)	loss 1.2983 (1.3619)	grad_norm 7.0905 (4.8117)	loss_scale 2048.0000 (2048.0000)	mem 11714MB
[2024-07-04 15:31:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:16:35 lr 0.000037	 wd 0.0000	time 0.4343 (0.4738)	loss 1.4982 (1.3602)	grad_norm 4.5535 (4.8799)	loss_scale 2048.0000 (2048.0000)	mem 11714MB
[2024-07-04 15:32:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:15:37 lr 0.000037	 wd 0.0000	time 0.4284 (0.4681)	loss 1.5037 (1.3563)	grad_norm 3.6340 (4.8058)	loss_scale 2048.0000 (2048.0000)	mem 11714MB
[2024-07-04 15:33:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:14:43 lr 0.000037	 wd 0.0000	time 0.4429 (0.4643)	loss 1.3359 (1.3586)	grad_norm 5.1869 (4.9924)	loss_scale 2048.0000 (2048.0000)	mem 11714MB
[2024-07-04 15:34:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:13:51 lr 0.000037	 wd 0.0000	time 0.4202 (0.4616)	loss 1.4283 (1.3610)	grad_norm 3.5499 (4.9781)	loss_scale 2048.0000 (2048.0000)	mem 11714MB
[2024-07-04 15:34:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:13:02 lr 0.000037	 wd 0.0000	time 0.4223 (0.4595)	loss 0.9893 (1.3639)	grad_norm 3.6310 (4.9737)	loss_scale 2048.0000 (2048.0000)	mem 11714MB
[2024-07-04 15:35:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:12:13 lr 0.000037	 wd 0.0000	time 0.4318 (0.4581)	loss 1.1684 (1.3641)	grad_norm 3.8056 (4.9746)	loss_scale 2048.0000 (2048.0000)	mem 11714MB
[2024-07-04 15:36:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:11:26 lr 0.000037	 wd 0.0000	time 0.4246 (0.4569)	loss 1.3523 (1.3627)	grad_norm 6.4713 (inf)	loss_scale 1024.0000 (2017.3107)	mem 11714MB
[2024-07-04 15:37:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:10:39 lr 0.000037	 wd 0.0000	time 0.4312 (0.4559)	loss 1.5766 (1.3616)	grad_norm 4.4226 (inf)	loss_scale 1024.0000 (1927.0917)	mem 11714MB
[2024-07-04 15:37:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:09:52 lr 0.000037	 wd 0.0000	time 0.4183 (0.4551)	loss 1.4695 (1.3579)	grad_norm 3.8256 (inf)	loss_scale 1024.0000 (1851.8968)	mem 11714MB
[2024-07-04 15:38:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:09:06 lr 0.000037	 wd 0.0000	time 0.4291 (0.4544)	loss 1.4415 (1.3592)	grad_norm 3.9917 (inf)	loss_scale 1024.0000 (1788.2613)	mem 11714MB
[2024-07-04 15:39:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:08:20 lr 0.000037	 wd 0.0000	time 0.4320 (0.4538)	loss 1.4640 (1.3597)	grad_norm 4.1164 (inf)	loss_scale 1024.0000 (1733.7102)	mem 11714MB
[2024-07-04 15:40:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:07:34 lr 0.000037	 wd 0.0000	time 0.4321 (0.4533)	loss 1.4466 (1.3593)	grad_norm 4.4147 (inf)	loss_scale 1024.0000 (1686.4277)	mem 11714MB
[2024-07-04 15:40:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:06:48 lr 0.000037	 wd 0.0000	time 0.4272 (0.4528)	loss 1.6006 (1.3603)	grad_norm 3.3436 (inf)	loss_scale 1024.0000 (1645.0518)	mem 11714MB
[2024-07-04 15:41:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:06:02 lr 0.000037	 wd 0.0000	time 0.4318 (0.4523)	loss 1.4340 (1.3603)	grad_norm 6.6341 (inf)	loss_scale 1024.0000 (1608.5409)	mem 11714MB
[2024-07-04 15:42:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:05:17 lr 0.000037	 wd 0.0000	time 0.4209 (0.4520)	loss 1.3613 (1.3602)	grad_norm 5.2118 (inf)	loss_scale 1024.0000 (1576.0844)	mem 11714MB
[2024-07-04 15:42:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:04:31 lr 0.000037	 wd 0.0000	time 0.4336 (0.4517)	loss 1.3508 (1.3590)	grad_norm 6.4118 (inf)	loss_scale 1024.0000 (1547.0426)	mem 11714MB
[2024-07-04 15:43:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:03:46 lr 0.000037	 wd 0.0000	time 0.4273 (0.4514)	loss 1.3770 (1.3609)	grad_norm 5.3999 (inf)	loss_scale 1024.0000 (1520.9035)	mem 11714MB
[2024-07-04 15:44:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:03:01 lr 0.000036	 wd 0.0000	time 0.4288 (0.4511)	loss 1.5110 (1.3612)	grad_norm 4.4322 (inf)	loss_scale 1024.0000 (1497.2527)	mem 11714MB
[2024-07-04 15:45:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:02:16 lr 0.000036	 wd 0.0000	time 0.4224 (0.4509)	loss 1.1886 (1.3597)	grad_norm 3.4710 (inf)	loss_scale 1024.0000 (1475.7510)	mem 11714MB
[2024-07-04 15:45:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:01:31 lr 0.000036	 wd 0.0000	time 0.4430 (0.4508)	loss 1.4288 (1.3597)	grad_norm 5.8841 (inf)	loss_scale 1024.0000 (1456.1182)	mem 11714MB
[2024-07-04 15:46:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:45 lr 0.000036	 wd 0.0000	time 0.4322 (0.4506)	loss 1.4811 (1.3598)	grad_norm 3.8666 (inf)	loss_scale 1024.0000 (1438.1208)	mem 11714MB
[2024-07-04 15:47:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000036	 wd 0.0000	time 0.4231 (0.4504)	loss 1.2767 (1.3602)	grad_norm 3.3522 (nan)	loss_scale 512.0000 (1405.5946)	mem 11714MB
[2024-07-04 15:47:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 9 training takes 0:18:49
[2024-07-04 15:47:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 10.946 (10.946)	Loss 0.4031 (0.4031)	Acc@1 93.359 (93.359)	Acc@5 98.633 (98.633)	Mem 11714MB
[2024-07-04 15:47:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.318 Acc@5 97.374
[2024-07-04 15:47:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-04 15:47:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.32%
[2024-07-04 15:47:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saving......
[2024-07-04 15:47:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saved !!!
[2024-07-04 15:48:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][0/2502]	eta 7:16:06 lr 0.000036	 wd 0.0000	time 10.4582 (10.4582)	loss 1.5173 (1.5173)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 15:48:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:21:49 lr 0.000036	 wd 0.0000	time 0.4293 (0.5452)	loss 1.3785 (1.3938)	grad_norm 3.1667 (4.7925)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 15:49:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:19:01 lr 0.000036	 wd 0.0000	time 0.4288 (0.4960)	loss 1.5418 (1.3562)	grad_norm 4.1254 (4.8497)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 15:50:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:17:35 lr 0.000036	 wd 0.0000	time 0.4275 (0.4792)	loss 1.3059 (1.3579)	grad_norm 4.8453 (4.7079)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 15:51:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:16:29 lr 0.000036	 wd 0.0000	time 0.4289 (0.4708)	loss 1.6552 (1.3545)	grad_norm 5.4937 (4.7114)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 15:51:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:15:32 lr 0.000036	 wd 0.0000	time 0.4264 (0.4659)	loss 1.4467 (1.3567)	grad_norm 3.5782 (4.7081)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 15:52:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:14:39 lr 0.000036	 wd 0.0000	time 0.4407 (0.4623)	loss 1.4628 (1.3627)	grad_norm 5.8460 (4.7888)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 15:53:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:13:48 lr 0.000036	 wd 0.0000	time 0.4301 (0.4598)	loss 1.4902 (1.3636)	grad_norm 4.0708 (4.7851)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 15:54:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:12:59 lr 0.000036	 wd 0.0000	time 0.4251 (0.4580)	loss 1.5293 (1.3651)	grad_norm 3.8489 (4.7927)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 15:54:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:12:11 lr 0.000036	 wd 0.0000	time 0.4259 (0.4566)	loss 1.4639 (1.3649)	grad_norm 5.8375 (4.7510)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 15:55:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:11:24 lr 0.000036	 wd 0.0000	time 0.4420 (0.4554)	loss 1.5843 (1.3615)	grad_norm 8.2674 (4.8176)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 15:56:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:10:37 lr 0.000036	 wd 0.0000	time 0.4307 (0.4545)	loss 1.4713 (1.3576)	grad_norm 5.1402 (4.8041)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 15:56:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:09:50 lr 0.000035	 wd 0.0000	time 0.4312 (0.4537)	loss 1.4260 (1.3575)	grad_norm 8.3197 (4.7952)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 15:57:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:09:04 lr 0.000035	 wd 0.0000	time 0.4325 (0.4530)	loss 1.3052 (1.3562)	grad_norm 4.3407 (4.9312)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 15:58:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:08:18 lr 0.000035	 wd 0.0000	time 0.4346 (0.4525)	loss 0.9756 (1.3583)	grad_norm 5.5329 (4.8956)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 15:59:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:07:32 lr 0.000035	 wd 0.0000	time 0.4332 (0.4520)	loss 0.9398 (1.3554)	grad_norm 4.0985 (4.8940)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 15:59:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:06:47 lr 0.000035	 wd 0.0000	time 0.4462 (0.4516)	loss 1.0339 (1.3523)	grad_norm 3.7144 (4.8884)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:00:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:06:01 lr 0.000035	 wd 0.0000	time 0.4236 (0.4513)	loss 1.1729 (1.3537)	grad_norm 3.8025 (4.8976)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:01:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:05:16 lr 0.000035	 wd 0.0000	time 0.4383 (0.4510)	loss 1.3834 (1.3548)	grad_norm 3.6822 (4.8686)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:02:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:04:31 lr 0.000035	 wd 0.0000	time 0.4017 (0.4508)	loss 1.3805 (1.3551)	grad_norm 4.4990 (4.8732)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:02:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:03:46 lr 0.000035	 wd 0.0000	time 0.4344 (0.4505)	loss 1.5737 (1.3572)	grad_norm 3.6708 (4.8669)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:03:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:03:00 lr 0.000035	 wd 0.0000	time 0.4196 (0.4502)	loss 1.3452 (1.3564)	grad_norm 3.9533 (4.8725)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:04:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:02:15 lr 0.000035	 wd 0.0000	time 0.4112 (0.4500)	loss 1.5178 (1.3558)	grad_norm 5.9773 (4.8754)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:05:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:01:30 lr 0.000035	 wd 0.0000	time 0.4232 (0.4498)	loss 1.5281 (1.3568)	grad_norm 4.4081 (4.8729)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:05:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:45 lr 0.000035	 wd 0.0000	time 0.4290 (0.4497)	loss 1.3918 (1.3582)	grad_norm 6.3912 (4.8737)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:06:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.4342 (0.4495)	loss 1.4530 (1.3595)	grad_norm 3.2955 (4.8918)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:06:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 10 training takes 0:18:47
[2024-07-04 16:06:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.046 (11.046)	Loss 0.4133 (0.4133)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 11714MB
[2024-07-04 16:07:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.264 Acc@5 97.382
[2024-07-04 16:07:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-04 16:07:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.32%
[2024-07-04 16:07:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][0/2502]	eta 7:27:35 lr 0.000035	 wd 0.0000	time 10.7334 (10.7334)	loss 1.3223 (1.3223)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:08:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:22:06 lr 0.000035	 wd 0.0000	time 0.4281 (0.5524)	loss 1.2379 (1.3264)	grad_norm 4.9785 (5.3985)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:08:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:19:10 lr 0.000034	 wd 0.0000	time 0.4226 (0.4996)	loss 1.5361 (1.3410)	grad_norm 3.5623 (4.9231)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:09:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:17:39 lr 0.000034	 wd 0.0000	time 0.4366 (0.4813)	loss 1.4989 (1.3476)	grad_norm 4.2279 (5.2676)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:10:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:16:33 lr 0.000034	 wd 0.0000	time 0.4220 (0.4725)	loss 1.4544 (1.3444)	grad_norm 3.6248 (5.2672)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:10:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:15:35 lr 0.000034	 wd 0.0000	time 0.4288 (0.4671)	loss 1.4839 (1.3483)	grad_norm 3.1965 (5.1864)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:11:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:14:41 lr 0.000034	 wd 0.0000	time 0.4190 (0.4636)	loss 1.6193 (1.3423)	grad_norm 3.4226 (5.1565)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:12:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:13:50 lr 0.000034	 wd 0.0000	time 0.4290 (0.4610)	loss 1.4281 (1.3435)	grad_norm 3.0228 (5.1578)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:13:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:13:01 lr 0.000034	 wd 0.0000	time 0.4263 (0.4590)	loss 1.4984 (1.3466)	grad_norm 3.2214 (5.0906)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:13:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:12:12 lr 0.000034	 wd 0.0000	time 0.4319 (0.4575)	loss 1.4790 (1.3437)	grad_norm 4.0199 (5.0497)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:14:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:11:25 lr 0.000034	 wd 0.0000	time 0.4391 (0.4563)	loss 1.3261 (1.3438)	grad_norm 4.5542 (5.0160)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:15:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:10:38 lr 0.000034	 wd 0.0000	time 0.4333 (0.4553)	loss 1.2765 (1.3464)	grad_norm 5.0005 (5.1933)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:16:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:09:51 lr 0.000034	 wd 0.0000	time 0.4337 (0.4545)	loss 1.6925 (1.3488)	grad_norm 3.9559 (5.1389)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:16:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:09:05 lr 0.000034	 wd 0.0000	time 0.4331 (0.4539)	loss 0.9185 (1.3475)	grad_norm 3.8150 (5.1436)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:17:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:08:19 lr 0.000034	 wd 0.0000	time 0.4221 (0.4534)	loss 1.3953 (1.3488)	grad_norm 3.0050 (5.1285)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 16:18:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:07:33 lr 0.000034	 wd 0.0000	time 0.4300 (0.4529)	loss 1.6434 (1.3496)	grad_norm 5.6305 (5.1191)	loss_scale 1024.0000 (539.9707)	mem 11714MB
[2024-07-04 16:19:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:06:48 lr 0.000034	 wd 0.0000	time 0.4332 (0.4524)	loss 0.8108 (1.3493)	grad_norm 6.0071 (5.1271)	loss_scale 1024.0000 (570.2036)	mem 11714MB
[2024-07-04 16:19:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:06:02 lr 0.000033	 wd 0.0000	time 0.4337 (0.4520)	loss 1.0889 (1.3502)	grad_norm 5.7074 (5.0817)	loss_scale 1024.0000 (596.8818)	mem 11714MB
[2024-07-04 16:20:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:05:17 lr 0.000033	 wd 0.0000	time 0.4337 (0.4517)	loss 1.4886 (1.3516)	grad_norm 4.2278 (5.0569)	loss_scale 1024.0000 (620.5974)	mem 11714MB
[2024-07-04 16:21:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:04:31 lr 0.000033	 wd 0.0000	time 0.4295 (0.4513)	loss 1.2145 (1.3504)	grad_norm 4.0403 (5.0248)	loss_scale 1024.0000 (641.8180)	mem 11714MB
[2024-07-04 16:22:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:03:46 lr 0.000033	 wd 0.0000	time 0.4319 (0.4509)	loss 1.3602 (1.3495)	grad_norm 4.4042 (4.9966)	loss_scale 1024.0000 (660.9175)	mem 11714MB
[2024-07-04 16:22:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:03:01 lr 0.000033	 wd 0.0000	time 0.4229 (0.4506)	loss 1.1762 (1.3506)	grad_norm 4.6832 (4.9916)	loss_scale 1024.0000 (678.1990)	mem 11714MB
[2024-07-04 16:23:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:02:16 lr 0.000033	 wd 0.0000	time 0.4293 (0.4503)	loss 1.5393 (1.3517)	grad_norm 3.7761 (4.9668)	loss_scale 1024.0000 (693.9100)	mem 11714MB
[2024-07-04 16:24:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:01:30 lr 0.000033	 wd 0.0000	time 0.4314 (0.4501)	loss 1.5007 (1.3524)	grad_norm 5.5137 (4.9387)	loss_scale 1024.0000 (708.2555)	mem 11714MB
[2024-07-04 16:25:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:45 lr 0.000033	 wd 0.0000	time 0.4367 (0.4500)	loss 1.2739 (1.3523)	grad_norm 3.6432 (4.9373)	loss_scale 1024.0000 (721.4061)	mem 11714MB
[2024-07-04 16:25:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000033	 wd 0.0000	time 0.4366 (0.4497)	loss 0.8526 (1.3528)	grad_norm 3.7578 (5.0186)	loss_scale 1024.0000 (733.5050)	mem 11714MB
[2024-07-04 16:25:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 11 training takes 0:18:47
[2024-07-04 16:26:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 10.633 (10.633)	Loss 0.4065 (0.4065)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 11714MB
[2024-07-04 16:26:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.208 Acc@5 97.354
[2024-07-04 16:26:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-04 16:26:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.32%
[2024-07-04 16:26:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][0/2502]	eta 7:40:55 lr 0.000033	 wd 0.0000	time 11.0532 (11.0532)	loss 1.2386 (1.2386)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:27:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:22:07 lr 0.000033	 wd 0.0000	time 0.4139 (0.5525)	loss 1.2889 (1.3163)	grad_norm 2.8656 (4.4299)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:27:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:19:10 lr 0.000033	 wd 0.0000	time 0.4259 (0.4998)	loss 1.2889 (1.3408)	grad_norm 5.1284 (4.6262)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:28:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:17:40 lr 0.000033	 wd 0.0000	time 0.4299 (0.4816)	loss 0.7124 (1.3456)	grad_norm 4.1685 (4.6979)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:29:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:16:33 lr 0.000033	 wd 0.0000	time 0.4314 (0.4727)	loss 1.3454 (1.3492)	grad_norm 3.7108 (4.8135)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:30:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:15:35 lr 0.000032	 wd 0.0000	time 0.4276 (0.4671)	loss 1.4912 (1.3448)	grad_norm 2.9304 (4.8287)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:30:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:14:41 lr 0.000032	 wd 0.0000	time 0.4339 (0.4633)	loss 1.4892 (1.3453)	grad_norm 6.7366 (5.0879)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:31:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:13:50 lr 0.000032	 wd 0.0000	time 0.4280 (0.4606)	loss 1.3185 (1.3435)	grad_norm 5.0545 (5.1199)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:32:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:13:00 lr 0.000032	 wd 0.0000	time 0.4283 (0.4586)	loss 1.1838 (1.3427)	grad_norm 5.4858 (5.1307)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:33:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:12:12 lr 0.000032	 wd 0.0000	time 0.4379 (0.4571)	loss 1.4869 (1.3411)	grad_norm 3.8900 (5.1041)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:33:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:11:24 lr 0.000032	 wd 0.0000	time 0.4348 (0.4558)	loss 1.4469 (1.3413)	grad_norm 4.5410 (5.0891)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:34:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:10:37 lr 0.000032	 wd 0.0000	time 0.4164 (0.4547)	loss 1.3596 (1.3403)	grad_norm 5.5732 (5.1121)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:35:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:09:51 lr 0.000032	 wd 0.0000	time 0.4283 (0.4539)	loss 1.2436 (1.3406)	grad_norm 5.2982 (5.0879)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:36:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:09:04 lr 0.000032	 wd 0.0000	time 0.4348 (0.4532)	loss 1.5190 (1.3428)	grad_norm 4.7507 (5.1994)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:36:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:08:18 lr 0.000032	 wd 0.0000	time 0.4390 (0.4526)	loss 1.5455 (1.3441)	grad_norm 4.2975 (5.1677)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:37:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:07:33 lr 0.000032	 wd 0.0000	time 0.4204 (0.4521)	loss 1.2665 (1.3438)	grad_norm 5.7817 (5.1539)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:38:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:06:47 lr 0.000032	 wd 0.0000	time 0.4262 (0.4516)	loss 1.2920 (1.3450)	grad_norm 5.0361 (5.1186)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:39:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:06:01 lr 0.000031	 wd 0.0000	time 0.4306 (0.4513)	loss 1.3077 (1.3467)	grad_norm 5.6723 (5.1012)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:39:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:05:16 lr 0.000031	 wd 0.0000	time 0.4322 (0.4509)	loss 1.3281 (1.3475)	grad_norm 6.4960 (5.0757)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:40:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:04:31 lr 0.000031	 wd 0.0000	time 0.4427 (0.4506)	loss 1.4219 (1.3485)	grad_norm 4.6733 (5.0463)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:41:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:03:46 lr 0.000031	 wd 0.0000	time 0.4349 (0.4503)	loss 1.1992 (1.3494)	grad_norm 4.6757 (5.0666)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:42:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:03:00 lr 0.000031	 wd 0.0000	time 0.4307 (0.4501)	loss 1.3543 (1.3519)	grad_norm 5.2880 (5.0610)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:42:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:02:15 lr 0.000031	 wd 0.0000	time 0.4340 (0.4499)	loss 1.1042 (1.3522)	grad_norm 3.7062 (5.0534)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:43:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:01:30 lr 0.000031	 wd 0.0000	time 0.4321 (0.4497)	loss 1.3540 (1.3520)	grad_norm 5.0353 (5.0472)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:44:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:45 lr 0.000031	 wd 0.0000	time 0.4434 (0.4495)	loss 1.4252 (1.3516)	grad_norm 3.7719 (5.0775)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:44:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000031	 wd 0.0000	time 0.4232 (0.4492)	loss 1.4723 (1.3512)	grad_norm 5.2903 (5.0757)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:45:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 12 training takes 0:18:46
[2024-07-04 16:45:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.244 (11.244)	Loss 0.4089 (0.4089)	Acc@1 91.602 (91.602)	Acc@5 98.047 (98.047)	Mem 11714MB
[2024-07-04 16:45:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.304 Acc@5 97.364
[2024-07-04 16:45:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-04 16:45:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.32%
[2024-07-04 16:45:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][0/2502]	eta 8:10:52 lr 0.000031	 wd 0.0000	time 11.7715 (11.7715)	loss 1.3759 (1.3759)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:46:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:22:23 lr 0.000031	 wd 0.0000	time 0.4292 (0.5593)	loss 1.2264 (1.3428)	grad_norm 4.6952 (5.1152)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:47:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:19:18 lr 0.000031	 wd 0.0000	time 0.4330 (0.5032)	loss 1.4301 (1.3391)	grad_norm 3.8363 (5.0552)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:47:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:17:45 lr 0.000031	 wd 0.0000	time 0.4368 (0.4840)	loss 1.1754 (1.3458)	grad_norm 6.2574 (5.1533)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:48:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:16:36 lr 0.000030	 wd 0.0000	time 0.4400 (0.4742)	loss 1.5318 (1.3512)	grad_norm 3.8911 (5.1785)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 16:49:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:15:37 lr 0.000030	 wd 0.0000	time 0.4306 (0.4682)	loss 1.3766 (1.3469)	grad_norm 4.1005 (5.2954)	loss_scale 2048.0000 (1199.7764)	mem 11714MB
[2024-07-04 16:50:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:14:43 lr 0.000030	 wd 0.0000	time 0.4317 (0.4646)	loss 1.3717 (1.3448)	grad_norm 4.3501 (5.2023)	loss_scale 2048.0000 (1340.9118)	mem 11714MB
[2024-07-04 16:50:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:13:52 lr 0.000030	 wd 0.0000	time 0.4350 (0.4619)	loss 1.5127 (1.3439)	grad_norm 4.7683 (5.1503)	loss_scale 2048.0000 (1441.7803)	mem 11714MB
[2024-07-04 16:51:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:13:02 lr 0.000030	 wd 0.0000	time 0.4297 (0.4599)	loss 1.4199 (1.3468)	grad_norm 4.6789 (5.0769)	loss_scale 2048.0000 (1517.4632)	mem 11714MB
[2024-07-04 16:52:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:12:14 lr 0.000030	 wd 0.0000	time 0.4287 (0.4583)	loss 1.5374 (1.3439)	grad_norm 7.0757 (5.0236)	loss_scale 2048.0000 (1576.3463)	mem 11714MB
[2024-07-04 16:53:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:11:26 lr 0.000030	 wd 0.0000	time 0.4257 (0.4570)	loss 1.4330 (1.3458)	grad_norm 3.5488 (4.9915)	loss_scale 2048.0000 (1623.4645)	mem 11714MB
[2024-07-04 16:53:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:10:39 lr 0.000030	 wd 0.0000	time 0.4386 (0.4560)	loss 1.4488 (1.3478)	grad_norm 4.0229 (5.0885)	loss_scale 2048.0000 (1662.0236)	mem 11714MB
[2024-07-04 16:54:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:09:52 lr 0.000030	 wd 0.0000	time 0.4362 (0.4550)	loss 1.5473 (1.3482)	grad_norm 15.2287 (5.1034)	loss_scale 2048.0000 (1694.1615)	mem 11714MB
[2024-07-04 16:55:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:09:06 lr 0.000030	 wd 0.0000	time 0.4298 (0.4543)	loss 0.9150 (1.3469)	grad_norm 3.7350 (5.0419)	loss_scale 2048.0000 (1721.3590)	mem 11714MB
[2024-07-04 16:56:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:08:20 lr 0.000030	 wd 0.0000	time 0.4180 (0.4537)	loss 1.0046 (1.3460)	grad_norm 4.0530 (5.0624)	loss_scale 2048.0000 (1744.6738)	mem 11714MB
[2024-07-04 16:56:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:07:34 lr 0.000030	 wd 0.0000	time 0.4335 (0.4532)	loss 1.4992 (1.3461)	grad_norm 5.3142 (inf)	loss_scale 1024.0000 (1736.2292)	mem 11714MB
[2024-07-04 16:57:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:06:48 lr 0.000029	 wd 0.0000	time 0.4304 (0.4528)	loss 1.2979 (1.3469)	grad_norm 5.1976 (inf)	loss_scale 1024.0000 (1691.7427)	mem 11714MB
[2024-07-04 16:58:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:06:02 lr 0.000029	 wd 0.0000	time 0.4314 (0.4525)	loss 1.4173 (1.3461)	grad_norm 3.5268 (inf)	loss_scale 1024.0000 (1652.4868)	mem 11714MB
[2024-07-04 16:59:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:05:17 lr 0.000029	 wd 0.0000	time 0.4299 (0.4521)	loss 1.2714 (1.3472)	grad_norm 4.1964 (inf)	loss_scale 1024.0000 (1617.5902)	mem 11714MB
[2024-07-04 16:59:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:04:31 lr 0.000029	 wd 0.0000	time 0.4099 (0.4517)	loss 1.3073 (1.3469)	grad_norm 5.3560 (inf)	loss_scale 1024.0000 (1586.3651)	mem 11714MB
[2024-07-04 17:00:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:03:46 lr 0.000029	 wd 0.0000	time 0.4292 (0.4513)	loss 1.1965 (1.3474)	grad_norm 6.4951 (inf)	loss_scale 1024.0000 (1558.2609)	mem 11714MB
[2024-07-04 17:01:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:03:01 lr 0.000029	 wd 0.0000	time 0.4275 (0.4510)	loss 1.3993 (1.3480)	grad_norm 3.0342 (inf)	loss_scale 1024.0000 (1532.8320)	mem 11714MB
[2024-07-04 17:01:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:02:16 lr 0.000029	 wd 0.0000	time 0.4311 (0.4508)	loss 1.2828 (1.3495)	grad_norm 4.3263 (inf)	loss_scale 1024.0000 (1509.7138)	mem 11714MB
[2024-07-04 17:02:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:01:31 lr 0.000029	 wd 0.0000	time 0.4331 (0.4505)	loss 1.6205 (1.3495)	grad_norm 4.0025 (inf)	loss_scale 1024.0000 (1488.6050)	mem 11714MB
[2024-07-04 17:03:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:45 lr 0.000029	 wd 0.0000	time 0.4261 (0.4503)	loss 1.3204 (1.3483)	grad_norm 4.4380 (inf)	loss_scale 1024.0000 (1469.2545)	mem 11714MB
[2024-07-04 17:04:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000029	 wd 0.0000	time 0.4356 (0.4499)	loss 1.2375 (1.3484)	grad_norm 3.7589 (inf)	loss_scale 1024.0000 (1451.4514)	mem 11714MB
[2024-07-04 17:04:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 13 training takes 0:18:48
[2024-07-04 17:04:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 10.834 (10.834)	Loss 0.4019 (0.4019)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 11714MB
[2024-07-04 17:04:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.348 Acc@5 97.328
[2024-07-04 17:04:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-04 17:04:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.35%
[2024-07-04 17:04:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saving......
[2024-07-04 17:04:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saved !!!
[2024-07-04 17:04:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][0/2502]	eta 6:54:25 lr 0.000029	 wd 0.0000	time 9.9381 (9.9381)	loss 1.4639 (1.4639)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:05:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:21:36 lr 0.000029	 wd 0.0000	time 0.4255 (0.5399)	loss 1.6355 (1.3538)	grad_norm 7.9834 (6.0137)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:06:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:18:54 lr 0.000028	 wd 0.0000	time 0.4212 (0.4929)	loss 0.9263 (1.3512)	grad_norm 4.8011 (5.8072)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:07:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:17:30 lr 0.000028	 wd 0.0000	time 0.4346 (0.4769)	loss 1.5834 (1.3497)	grad_norm 5.3178 (5.8341)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:07:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:16:25 lr 0.000028	 wd 0.0000	time 0.4342 (0.4689)	loss 1.6141 (1.3437)	grad_norm 2.2498 (6.2312)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:08:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:15:29 lr 0.000028	 wd 0.0000	time 0.4122 (0.4642)	loss 1.0978 (1.3457)	grad_norm 3.4416 (6.0508)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:09:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:14:36 lr 0.000028	 wd 0.0000	time 0.4243 (0.4610)	loss 1.4210 (1.3473)	grad_norm 4.1629 (5.8760)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:10:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:13:46 lr 0.000028	 wd 0.0000	time 0.4264 (0.4589)	loss 1.5076 (1.3469)	grad_norm 4.9587 (inf)	loss_scale 512.0000 (974.3338)	mem 11714MB
[2024-07-04 17:10:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:12:57 lr 0.000028	 wd 0.0000	time 0.4320 (0.4571)	loss 1.3996 (1.3532)	grad_norm 4.6175 (inf)	loss_scale 512.0000 (916.6142)	mem 11714MB
[2024-07-04 17:11:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:12:10 lr 0.000028	 wd 0.0000	time 0.4361 (0.4558)	loss 1.1477 (1.3553)	grad_norm 4.8414 (inf)	loss_scale 512.0000 (871.7070)	mem 11714MB
[2024-07-04 17:12:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:11:22 lr 0.000028	 wd 0.0000	time 0.4249 (0.4547)	loss 1.4483 (1.3524)	grad_norm 4.7661 (inf)	loss_scale 512.0000 (835.7722)	mem 11714MB
[2024-07-04 17:12:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:10:36 lr 0.000028	 wd 0.0000	time 0.4239 (0.4538)	loss 1.5370 (1.3558)	grad_norm 3.1802 (inf)	loss_scale 512.0000 (806.3651)	mem 11714MB
[2024-07-04 17:13:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:09:50 lr 0.000028	 wd 0.0000	time 0.4332 (0.4533)	loss 1.4753 (1.3546)	grad_norm 4.1832 (inf)	loss_scale 512.0000 (781.8551)	mem 11714MB
[2024-07-04 17:14:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:09:04 lr 0.000027	 wd 0.0000	time 0.4330 (0.4526)	loss 1.6103 (1.3542)	grad_norm 4.1925 (inf)	loss_scale 512.0000 (761.1130)	mem 11714MB
[2024-07-04 17:15:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:08:18 lr 0.000027	 wd 0.0000	time 0.4360 (0.4521)	loss 1.3151 (1.3542)	grad_norm 4.3981 (inf)	loss_scale 512.0000 (743.3319)	mem 11714MB
[2024-07-04 17:15:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:07:32 lr 0.000027	 wd 0.0000	time 0.4336 (0.4517)	loss 1.5894 (1.3547)	grad_norm 5.6609 (inf)	loss_scale 512.0000 (727.9201)	mem 11714MB
[2024-07-04 17:16:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:06:47 lr 0.000027	 wd 0.0000	time 0.4285 (0.4513)	loss 1.3998 (1.3542)	grad_norm 9.0583 (inf)	loss_scale 512.0000 (714.4335)	mem 11714MB
[2024-07-04 17:17:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:06:01 lr 0.000027	 wd 0.0000	time 0.4290 (0.4510)	loss 1.5486 (1.3551)	grad_norm 4.3016 (inf)	loss_scale 512.0000 (702.5326)	mem 11714MB
[2024-07-04 17:18:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:05:16 lr 0.000027	 wd 0.0000	time 0.4239 (0.4507)	loss 1.3563 (1.3553)	grad_norm 4.5454 (inf)	loss_scale 512.0000 (691.9534)	mem 11714MB
[2024-07-04 17:18:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:04:31 lr 0.000027	 wd 0.0000	time 0.4279 (0.4504)	loss 1.3243 (1.3545)	grad_norm 4.2113 (inf)	loss_scale 512.0000 (682.4871)	mem 11714MB
[2024-07-04 17:19:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:03:45 lr 0.000027	 wd 0.0000	time 0.4363 (0.4502)	loss 1.4482 (1.3530)	grad_norm 9.1724 (inf)	loss_scale 512.0000 (673.9670)	mem 11714MB
[2024-07-04 17:20:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:03:00 lr 0.000027	 wd 0.0000	time 0.4195 (0.4500)	loss 1.5101 (1.3540)	grad_norm 5.7119 (inf)	loss_scale 512.0000 (666.2580)	mem 11714MB
[2024-07-04 17:21:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:02:15 lr 0.000027	 wd 0.0000	time 0.4275 (0.4498)	loss 1.4397 (1.3551)	grad_norm 4.0866 (inf)	loss_scale 512.0000 (659.2494)	mem 11714MB
[2024-07-04 17:21:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:01:30 lr 0.000027	 wd 0.0000	time 0.4307 (0.4496)	loss 1.4728 (1.3550)	grad_norm 7.0105 (inf)	loss_scale 512.0000 (652.8501)	mem 11714MB
[2024-07-04 17:22:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:45 lr 0.000026	 wd 0.0000	time 0.4349 (0.4494)	loss 1.3607 (1.3550)	grad_norm 3.8633 (inf)	loss_scale 512.0000 (646.9838)	mem 11714MB
[2024-07-04 17:23:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.4252 (0.4491)	loss 1.0461 (1.3537)	grad_norm 6.7749 (inf)	loss_scale 512.0000 (641.5866)	mem 11714MB
[2024-07-04 17:23:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 14 training takes 0:18:46
[2024-07-04 17:23:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.524 (11.524)	Loss 0.4204 (0.4204)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 11714MB
[2024-07-04 17:23:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.378 Acc@5 97.412
[2024-07-04 17:23:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.4%
[2024-07-04 17:23:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.38%
[2024-07-04 17:23:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saving......
[2024-07-04 17:23:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saved !!!
[2024-07-04 17:24:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][0/2502]	eta 6:50:27 lr 0.000026	 wd 0.0000	time 9.8433 (9.8433)	loss 1.3382 (1.3382)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:24:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:21:32 lr 0.000026	 wd 0.0000	time 0.4201 (0.5379)	loss 1.4418 (1.3282)	grad_norm 10.5431 (5.9407)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:25:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:18:50 lr 0.000026	 wd 0.0000	time 0.4207 (0.4910)	loss 1.6454 (1.3345)	grad_norm 5.3333 (5.3659)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:26:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:17:28 lr 0.000026	 wd 0.0000	time 0.4296 (0.4762)	loss 1.3813 (1.3474)	grad_norm 5.1000 (5.3227)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:26:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:16:25 lr 0.000026	 wd 0.0000	time 0.4063 (0.4687)	loss 1.5074 (1.3456)	grad_norm 4.5865 (5.2739)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:27:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:15:28 lr 0.000026	 wd 0.0000	time 0.4299 (0.4640)	loss 1.3983 (1.3469)	grad_norm 6.3047 (5.2825)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:28:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:14:36 lr 0.000026	 wd 0.0000	time 0.4272 (0.4610)	loss 1.4002 (1.3521)	grad_norm 4.0153 (5.3227)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:29:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:13:46 lr 0.000026	 wd 0.0000	time 0.4263 (0.4589)	loss 1.5787 (1.3467)	grad_norm 3.3107 (5.3584)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:29:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:12:58 lr 0.000026	 wd 0.0000	time 0.4275 (0.4571)	loss 1.6542 (1.3512)	grad_norm 4.6837 (5.3251)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:30:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:12:10 lr 0.000025	 wd 0.0000	time 0.4367 (0.4558)	loss 1.5068 (1.3496)	grad_norm 6.7510 (5.3328)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:31:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:11:23 lr 0.000025	 wd 0.0000	time 0.4310 (0.4548)	loss 1.5435 (1.3522)	grad_norm 3.2854 (5.2928)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:32:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:10:36 lr 0.000025	 wd 0.0000	time 0.4076 (0.4540)	loss 1.3619 (1.3526)	grad_norm 4.0866 (5.2805)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:32:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:09:49 lr 0.000025	 wd 0.0000	time 0.4270 (0.4531)	loss 1.3568 (1.3496)	grad_norm 4.4905 (5.2357)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:33:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:09:03 lr 0.000025	 wd 0.0000	time 0.4320 (0.4525)	loss 1.6066 (1.3498)	grad_norm 4.4801 (5.2445)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:34:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:08:18 lr 0.000025	 wd 0.0000	time 0.4414 (0.4519)	loss 1.4166 (1.3507)	grad_norm 4.8531 (5.2299)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:35:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:07:32 lr 0.000025	 wd 0.0000	time 0.4184 (0.4515)	loss 1.5233 (1.3479)	grad_norm 4.5237 (5.2088)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:35:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:06:46 lr 0.000025	 wd 0.0000	time 0.4306 (0.4511)	loss 1.5207 (1.3480)	grad_norm 4.1986 (5.1811)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:36:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:06:01 lr 0.000025	 wd 0.0000	time 0.4267 (0.4507)	loss 0.9534 (1.3456)	grad_norm 4.4739 (5.1758)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:37:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:05:16 lr 0.000025	 wd 0.0000	time 0.4237 (0.4505)	loss 1.4378 (1.3467)	grad_norm 5.9928 (5.1845)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:38:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:04:31 lr 0.000024	 wd 0.0000	time 0.4288 (0.4502)	loss 1.3548 (1.3472)	grad_norm 6.9847 (5.1596)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:38:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:03:45 lr 0.000024	 wd 0.0000	time 0.4306 (0.4500)	loss 1.7594 (1.3486)	grad_norm 3.5191 (5.1452)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:39:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:03:00 lr 0.000024	 wd 0.0000	time 0.4309 (0.4498)	loss 0.8998 (1.3470)	grad_norm 3.6883 (5.1315)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 17:40:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:02:15 lr 0.000024	 wd 0.0000	time 0.4282 (0.4496)	loss 1.5318 (1.3485)	grad_norm 6.9610 (5.1323)	loss_scale 1024.0000 (528.2835)	mem 11714MB
[2024-07-04 17:41:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:01:30 lr 0.000024	 wd 0.0000	time 0.4302 (0.4495)	loss 1.5868 (1.3483)	grad_norm 5.3940 (5.1208)	loss_scale 1024.0000 (549.8270)	mem 11714MB
[2024-07-04 17:41:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:45 lr 0.000024	 wd 0.0000	time 0.4238 (0.4492)	loss 1.6550 (1.3484)	grad_norm 5.1587 (5.1132)	loss_scale 1024.0000 (569.5760)	mem 11714MB
[2024-07-04 17:42:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.4241 (0.4490)	loss 1.6502 (1.3484)	grad_norm 4.0840 (5.1033)	loss_scale 1024.0000 (587.7457)	mem 11714MB
[2024-07-04 17:42:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 15 training takes 0:18:46
[2024-07-04 17:42:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_15.pth saving......
[2024-07-04 17:42:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_15.pth saved !!!
[2024-07-04 17:42:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 10.490 (10.490)	Loss 0.4070 (0.4070)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 11714MB
[2024-07-04 17:43:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.474 Acc@5 97.388
[2024-07-04 17:43:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.5%
[2024-07-04 17:43:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.47%
[2024-07-04 17:43:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saving......
[2024-07-04 17:43:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saved !!!
[2024-07-04 17:43:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][0/2502]	eta 7:18:50 lr 0.000024	 wd 0.0000	time 10.5239 (10.5239)	loss 1.4212 (1.4212)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:43:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:21:49 lr 0.000024	 wd 0.0000	time 0.4356 (0.5452)	loss 1.8709 (1.3490)	grad_norm 5.8100 (4.8795)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:44:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:18:59 lr 0.000024	 wd 0.0000	time 0.4307 (0.4948)	loss 1.2510 (1.3670)	grad_norm 7.5541 (5.0257)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:45:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:17:34 lr 0.000024	 wd 0.0000	time 0.4094 (0.4787)	loss 1.0402 (1.3566)	grad_norm 4.6334 (5.0718)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:46:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:16:28 lr 0.000024	 wd 0.0000	time 0.4352 (0.4705)	loss 1.1551 (1.3433)	grad_norm 4.8878 (5.0279)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:46:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:15:31 lr 0.000023	 wd 0.0000	time 0.4245 (0.4654)	loss 1.3085 (1.3465)	grad_norm 4.2313 (5.1008)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:47:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:14:38 lr 0.000023	 wd 0.0000	time 0.4198 (0.4620)	loss 1.5229 (1.3505)	grad_norm 4.9307 (5.1204)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:48:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:13:47 lr 0.000023	 wd 0.0000	time 0.4353 (0.4594)	loss 1.4745 (1.3471)	grad_norm 4.4716 (5.1098)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:49:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:12:58 lr 0.000023	 wd 0.0000	time 0.4411 (0.4576)	loss 1.3891 (1.3458)	grad_norm 4.6580 (5.0649)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:49:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:12:10 lr 0.000023	 wd 0.0000	time 0.4236 (0.4561)	loss 1.5206 (1.3433)	grad_norm 3.5906 (5.0832)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:50:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:11:23 lr 0.000023	 wd 0.0000	time 0.4354 (0.4549)	loss 1.2248 (1.3428)	grad_norm 5.0951 (5.0342)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:51:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:10:36 lr 0.000023	 wd 0.0000	time 0.4463 (0.4542)	loss 1.3320 (1.3401)	grad_norm 4.7363 (5.0502)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:52:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:09:50 lr 0.000023	 wd 0.0000	time 0.4342 (0.4534)	loss 1.5214 (1.3408)	grad_norm 5.3550 (5.0626)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:52:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:09:04 lr 0.000023	 wd 0.0000	time 0.4088 (0.4528)	loss 1.1628 (1.3422)	grad_norm 3.5428 (5.0546)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:53:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:08:18 lr 0.000023	 wd 0.0000	time 0.4304 (0.4523)	loss 1.4750 (1.3401)	grad_norm 3.5088 (5.0683)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:54:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:07:32 lr 0.000022	 wd 0.0000	time 0.4340 (0.4519)	loss 1.2729 (1.3404)	grad_norm 5.7416 (5.0653)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:55:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:06:47 lr 0.000022	 wd 0.0000	time 0.4347 (0.4515)	loss 1.2165 (1.3396)	grad_norm 7.0211 (5.0603)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:55:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:06:01 lr 0.000022	 wd 0.0000	time 0.4357 (0.4511)	loss 1.0703 (1.3389)	grad_norm 5.4811 (5.0565)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:56:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:05:16 lr 0.000022	 wd 0.0000	time 0.4339 (0.4509)	loss 1.3854 (1.3385)	grad_norm 4.0651 (5.0542)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 17:57:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:04:31 lr 0.000022	 wd 0.0000	time 0.4298 (0.4506)	loss 1.5083 (1.3387)	grad_norm 3.7781 (inf)	loss_scale 512.0000 (1013.7654)	mem 11714MB
[2024-07-04 17:58:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:03:46 lr 0.000022	 wd 0.0000	time 0.4376 (0.4504)	loss 1.0034 (1.3393)	grad_norm 3.8220 (inf)	loss_scale 512.0000 (988.6897)	mem 11714MB
[2024-07-04 17:58:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:03:00 lr 0.000022	 wd 0.0000	time 0.4234 (0.4502)	loss 1.3399 (1.3385)	grad_norm 4.6506 (inf)	loss_scale 512.0000 (966.0010)	mem 11714MB
[2024-07-04 17:59:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:02:15 lr 0.000022	 wd 0.0000	time 0.4308 (0.4500)	loss 1.0952 (1.3384)	grad_norm 4.0536 (inf)	loss_scale 512.0000 (945.3739)	mem 11714MB
[2024-07-04 18:00:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:01:30 lr 0.000022	 wd 0.0000	time 0.4264 (0.4498)	loss 1.5864 (1.3393)	grad_norm 4.7277 (inf)	loss_scale 512.0000 (926.5398)	mem 11714MB
[2024-07-04 18:01:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:45 lr 0.000022	 wd 0.0000	time 0.4303 (0.4497)	loss 0.9942 (1.3388)	grad_norm 6.7840 (inf)	loss_scale 512.0000 (909.2745)	mem 11714MB
[2024-07-04 18:01:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.4273 (0.4495)	loss 1.2364 (1.3375)	grad_norm 5.5660 (inf)	loss_scale 512.0000 (893.3898)	mem 11714MB
[2024-07-04 18:01:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 16 training takes 0:18:47
[2024-07-04 18:02:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.862 (11.862)	Loss 0.4094 (0.4094)	Acc@1 92.969 (92.969)	Acc@5 98.438 (98.438)	Mem 11714MB
[2024-07-04 18:02:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.532 Acc@5 97.444
[2024-07-04 18:02:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.5%
[2024-07-04 18:02:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.53%
[2024-07-04 18:02:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saving......
[2024-07-04 18:02:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saved !!!
[2024-07-04 18:02:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][0/2502]	eta 6:56:17 lr 0.000021	 wd 0.0000	time 9.9831 (9.9831)	loss 1.6631 (1.6631)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 18:03:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:21:36 lr 0.000021	 wd 0.0000	time 0.4271 (0.5398)	loss 1.2739 (1.3507)	grad_norm 3.6347 (4.5644)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 18:03:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:18:53 lr 0.000021	 wd 0.0000	time 0.4333 (0.4926)	loss 1.4408 (1.3592)	grad_norm 8.1404 (4.7344)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 18:04:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:17:30 lr 0.000021	 wd 0.0000	time 0.4327 (0.4769)	loss 1.3658 (1.3375)	grad_norm 3.3564 (4.7668)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 18:05:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:16:26 lr 0.000021	 wd 0.0000	time 0.4295 (0.4692)	loss 1.4577 (1.3392)	grad_norm 5.6638 (4.6914)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 18:06:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:15:29 lr 0.000021	 wd 0.0000	time 0.4341 (0.4641)	loss 0.8887 (1.3320)	grad_norm 5.2838 (4.7920)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 18:06:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:14:36 lr 0.000021	 wd 0.0000	time 0.4326 (0.4610)	loss 1.0427 (1.3344)	grad_norm 4.4047 (4.8567)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 18:07:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:13:46 lr 0.000021	 wd 0.0000	time 0.4341 (0.4587)	loss 1.3127 (1.3377)	grad_norm 6.4738 (4.9127)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 18:08:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:12:57 lr 0.000021	 wd 0.0000	time 0.4380 (0.4570)	loss 1.2829 (1.3368)	grad_norm 4.1971 (4.9706)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 18:09:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:12:09 lr 0.000021	 wd 0.0000	time 0.4360 (0.4556)	loss 1.0736 (1.3352)	grad_norm 4.7259 (4.9845)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 18:09:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:11:22 lr 0.000020	 wd 0.0000	time 0.4354 (0.4545)	loss 1.4088 (1.3355)	grad_norm 6.2245 (5.1225)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 18:10:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:10:36 lr 0.000020	 wd 0.0000	time 0.4160 (0.4536)	loss 1.4488 (1.3341)	grad_norm 2.8665 (5.1015)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 18:11:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:09:49 lr 0.000020	 wd 0.0000	time 0.4163 (0.4530)	loss 1.4744 (1.3341)	grad_norm 3.4439 (5.1616)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 18:12:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:09:03 lr 0.000020	 wd 0.0000	time 0.4312 (0.4523)	loss 1.3060 (1.3324)	grad_norm 5.0338 (5.1104)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 18:12:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:08:17 lr 0.000020	 wd 0.0000	time 0.4179 (0.4518)	loss 1.4766 (1.3334)	grad_norm 6.3620 (5.1116)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 18:13:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:07:32 lr 0.000020	 wd 0.0000	time 0.4349 (0.4514)	loss 1.5186 (1.3334)	grad_norm 3.9639 (5.0781)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 18:14:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:06:46 lr 0.000020	 wd 0.0000	time 0.4264 (0.4510)	loss 1.2157 (1.3353)	grad_norm 3.2698 (5.0932)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 18:15:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:06:01 lr 0.000020	 wd 0.0000	time 0.4326 (0.4506)	loss 1.5229 (1.3357)	grad_norm 4.0912 (5.1002)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 18:15:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:05:16 lr 0.000020	 wd 0.0000	time 0.4447 (0.4504)	loss 0.9650 (1.3358)	grad_norm 5.5037 (nan)	loss_scale 256.0000 (501.1971)	mem 11714MB
[2024-07-04 18:16:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:04:30 lr 0.000020	 wd 0.0000	time 0.4257 (0.4501)	loss 1.4183 (1.3366)	grad_norm 7.7361 (nan)	loss_scale 256.0000 (488.2988)	mem 11714MB
[2024-07-04 18:17:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:03:45 lr 0.000019	 wd 0.0000	time 0.4341 (0.4499)	loss 1.3999 (1.3376)	grad_norm 5.6693 (nan)	loss_scale 256.0000 (476.6897)	mem 11714MB
[2024-07-04 18:18:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:03:00 lr 0.000019	 wd 0.0000	time 0.4197 (0.4496)	loss 1.5166 (1.3382)	grad_norm 4.6843 (nan)	loss_scale 256.0000 (466.1856)	mem 11714MB
[2024-07-04 18:18:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:02:15 lr 0.000019	 wd 0.0000	time 0.4210 (0.4495)	loss 0.9770 (1.3392)	grad_norm 3.0016 (nan)	loss_scale 256.0000 (456.6361)	mem 11714MB
[2024-07-04 18:19:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:01:30 lr 0.000019	 wd 0.0000	time 0.4264 (0.4492)	loss 1.3790 (1.3388)	grad_norm 4.1691 (nan)	loss_scale 256.0000 (447.9166)	mem 11714MB
[2024-07-04 18:20:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:45 lr 0.000019	 wd 0.0000	time 0.4268 (0.4491)	loss 1.1838 (1.3383)	grad_norm 4.1245 (nan)	loss_scale 256.0000 (439.9234)	mem 11714MB
[2024-07-04 18:20:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000019	 wd 0.0000	time 0.4300 (0.4489)	loss 1.2862 (1.3382)	grad_norm 4.1133 (nan)	loss_scale 256.0000 (432.5694)	mem 11714MB
[2024-07-04 18:21:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 17 training takes 0:18:45
[2024-07-04 18:21:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 12.036 (12.036)	Loss 0.4124 (0.4124)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 11714MB
[2024-07-04 18:21:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.468 Acc@5 97.444
[2024-07-04 18:21:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.5%
[2024-07-04 18:21:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.53%
[2024-07-04 18:21:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][0/2502]	eta 8:07:20 lr 0.000019	 wd 0.0000	time 11.6867 (11.6867)	loss 1.3076 (1.3076)	grad_norm 0.0000 (0.0000)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:22:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:22:15 lr 0.000019	 wd 0.0000	time 0.4300 (0.5560)	loss 1.4830 (1.3290)	grad_norm 7.1079 (4.9601)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:23:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:19:10 lr 0.000019	 wd 0.0000	time 0.4300 (0.4998)	loss 1.3770 (1.3301)	grad_norm 5.1997 (5.0663)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:23:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:17:39 lr 0.000019	 wd 0.0000	time 0.4292 (0.4810)	loss 1.4381 (1.3415)	grad_norm 4.8929 (5.1493)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:24:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:16:32 lr 0.000019	 wd 0.0000	time 0.4276 (0.4720)	loss 1.0485 (1.3396)	grad_norm 6.2086 (5.1592)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:25:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:15:33 lr 0.000018	 wd 0.0000	time 0.4269 (0.4665)	loss 1.2740 (1.3486)	grad_norm 5.3515 (5.1407)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:26:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:14:40 lr 0.000018	 wd 0.0000	time 0.4206 (0.4627)	loss 1.1125 (1.3387)	grad_norm 3.8385 (5.1009)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:26:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:13:49 lr 0.000018	 wd 0.0000	time 0.4225 (0.4602)	loss 1.3475 (1.3396)	grad_norm 3.3075 (5.1693)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:27:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:12:59 lr 0.000018	 wd 0.0000	time 0.4086 (0.4581)	loss 1.2276 (1.3329)	grad_norm 3.8772 (5.1151)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:28:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:12:11 lr 0.000018	 wd 0.0000	time 0.4214 (0.4566)	loss 1.3878 (1.3322)	grad_norm 4.2409 (5.1049)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:29:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:11:23 lr 0.000018	 wd 0.0000	time 0.4287 (0.4554)	loss 1.4219 (1.3322)	grad_norm 5.7483 (5.1278)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:29:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:10:37 lr 0.000018	 wd 0.0000	time 0.4291 (0.4545)	loss 1.3443 (1.3346)	grad_norm 6.7196 (5.1183)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:30:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:09:50 lr 0.000018	 wd 0.0000	time 0.4368 (0.4537)	loss 1.4985 (1.3352)	grad_norm 4.6356 (5.1253)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:31:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:09:04 lr 0.000018	 wd 0.0000	time 0.4349 (0.4531)	loss 1.1600 (1.3357)	grad_norm 3.7971 (5.1657)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:31:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:08:18 lr 0.000018	 wd 0.0000	time 0.4369 (0.4525)	loss 1.3198 (1.3340)	grad_norm 4.4285 (5.1660)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:32:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:07:32 lr 0.000017	 wd 0.0000	time 0.4261 (0.4519)	loss 1.3369 (1.3312)	grad_norm 4.3442 (5.1614)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:33:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:06:47 lr 0.000017	 wd 0.0000	time 0.4169 (0.4515)	loss 1.4203 (1.3313)	grad_norm 5.8650 (5.1367)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:34:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:06:01 lr 0.000017	 wd 0.0000	time 0.4253 (0.4510)	loss 1.2020 (1.3300)	grad_norm 5.0495 (5.1371)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:34:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:05:16 lr 0.000017	 wd 0.0000	time 0.4170 (0.4507)	loss 1.1222 (1.3295)	grad_norm 3.5798 (5.1188)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:35:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:04:31 lr 0.000017	 wd 0.0000	time 0.4320 (0.4504)	loss 1.1923 (1.3289)	grad_norm 4.7811 (5.0944)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:36:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:03:45 lr 0.000017	 wd 0.0000	time 0.4347 (0.4501)	loss 1.4858 (1.3308)	grad_norm 5.9939 (5.0870)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:37:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:03:00 lr 0.000017	 wd 0.0000	time 0.4301 (0.4499)	loss 1.3785 (1.3313)	grad_norm 6.0576 (5.0913)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:37:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:02:15 lr 0.000017	 wd 0.0000	time 0.4268 (0.4497)	loss 1.3301 (1.3320)	grad_norm 3.9152 (5.0847)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:38:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:01:30 lr 0.000017	 wd 0.0000	time 0.4354 (0.4495)	loss 1.2502 (1.3324)	grad_norm 5.4835 (5.0912)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:39:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:45 lr 0.000017	 wd 0.0000	time 0.4267 (0.4493)	loss 1.5214 (1.3329)	grad_norm 12.0887 (5.1430)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:40:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.4359 (0.4490)	loss 1.3160 (1.3338)	grad_norm 4.6329 (5.1488)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:40:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 18 training takes 0:18:46
[2024-07-04 18:40:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.332 (11.332)	Loss 0.4070 (0.4070)	Acc@1 92.773 (92.773)	Acc@5 98.438 (98.438)	Mem 11714MB
[2024-07-04 18:40:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.516 Acc@5 97.420
[2024-07-04 18:40:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.5%
[2024-07-04 18:40:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.53%
[2024-07-04 18:40:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][0/2502]	eta 8:02:01 lr 0.000016	 wd 0.0000	time 11.5593 (11.5593)	loss 1.4455 (1.4455)	grad_norm 0.0000 (0.0000)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:41:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:22:15 lr 0.000016	 wd 0.0000	time 0.4281 (0.5561)	loss 1.5842 (1.3137)	grad_norm 4.2069 (5.0151)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:42:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:19:12 lr 0.000016	 wd 0.0000	time 0.4073 (0.5008)	loss 1.4344 (1.3096)	grad_norm 14.4987 (5.1143)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:43:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:17:41 lr 0.000016	 wd 0.0000	time 0.4348 (0.4821)	loss 1.4700 (1.3226)	grad_norm 8.0033 (5.0369)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:43:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:16:33 lr 0.000016	 wd 0.0000	time 0.4403 (0.4728)	loss 1.1369 (1.3181)	grad_norm 5.9916 (5.1099)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:44:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:15:35 lr 0.000016	 wd 0.0000	time 0.4254 (0.4672)	loss 1.3994 (1.3176)	grad_norm 4.5743 (5.2249)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:45:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:14:41 lr 0.000016	 wd 0.0000	time 0.4210 (0.4632)	loss 1.1656 (1.3223)	grad_norm 5.4699 (5.3234)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:45:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:13:49 lr 0.000016	 wd 0.0000	time 0.4242 (0.4605)	loss 1.5710 (1.3277)	grad_norm 4.2067 (5.3586)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 18:46:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:13:00 lr 0.000016	 wd 0.0000	time 0.4320 (0.4585)	loss 1.4154 (1.3304)	grad_norm 4.4751 (5.3821)	loss_scale 512.0000 (281.5680)	mem 11714MB
[2024-07-04 18:47:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:12:12 lr 0.000016	 wd 0.0000	time 0.4328 (0.4569)	loss 1.4295 (1.3331)	grad_norm 4.2935 (5.3592)	loss_scale 512.0000 (307.1432)	mem 11714MB
[2024-07-04 18:48:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:11:24 lr 0.000016	 wd 0.0000	time 0.4295 (0.4559)	loss 1.6242 (1.3327)	grad_norm 4.4893 (5.3457)	loss_scale 512.0000 (327.6084)	mem 11714MB
[2024-07-04 18:48:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:10:37 lr 0.000015	 wd 0.0000	time 0.4273 (0.4548)	loss 1.0812 (1.3321)	grad_norm 4.1085 (5.3644)	loss_scale 512.0000 (344.3560)	mem 11714MB
[2024-07-04 18:49:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:09:51 lr 0.000015	 wd 0.0000	time 0.4171 (0.4541)	loss 1.3839 (1.3351)	grad_norm 3.7570 (5.3939)	loss_scale 512.0000 (358.3147)	mem 11714MB
[2024-07-04 18:50:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:09:05 lr 0.000015	 wd 0.0000	time 0.4259 (0.4535)	loss 1.1761 (1.3345)	grad_norm 8.5286 (5.4264)	loss_scale 512.0000 (370.1276)	mem 11714MB
[2024-07-04 18:51:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:08:19 lr 0.000015	 wd 0.0000	time 0.4308 (0.4530)	loss 1.3916 (1.3348)	grad_norm 4.6142 (5.4429)	loss_scale 512.0000 (380.2541)	mem 11714MB
[2024-07-04 18:51:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:07:33 lr 0.000015	 wd 0.0000	time 0.4342 (0.4526)	loss 1.5042 (1.3355)	grad_norm 4.7020 (5.4412)	loss_scale 512.0000 (389.0313)	mem 11714MB
[2024-07-04 18:52:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:06:47 lr 0.000015	 wd 0.0000	time 0.4177 (0.4521)	loss 1.4361 (1.3384)	grad_norm 5.2174 (5.4572)	loss_scale 512.0000 (396.7121)	mem 11714MB
[2024-07-04 18:53:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:06:02 lr 0.000015	 wd 0.0000	time 0.4415 (0.4518)	loss 1.6569 (1.3402)	grad_norm 4.7599 (5.4462)	loss_scale 512.0000 (403.4897)	mem 11714MB
[2024-07-04 18:54:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:05:16 lr 0.000015	 wd 0.0000	time 0.4250 (0.4514)	loss 1.3342 (1.3398)	grad_norm 3.6362 (5.4759)	loss_scale 512.0000 (409.5147)	mem 11714MB
[2024-07-04 18:54:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:04:31 lr 0.000015	 wd 0.0000	time 0.4262 (0.4512)	loss 1.1264 (1.3401)	grad_norm 4.5038 (5.4462)	loss_scale 512.0000 (414.9058)	mem 11714MB
[2024-07-04 18:55:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:03:46 lr 0.000015	 wd 0.0000	time 0.4288 (0.4509)	loss 1.5601 (1.3388)	grad_norm 4.8957 (5.4364)	loss_scale 512.0000 (419.7581)	mem 11714MB
[2024-07-04 18:56:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:03:01 lr 0.000014	 wd 0.0000	time 0.4294 (0.4506)	loss 1.4151 (1.3389)	grad_norm 4.2159 (5.4130)	loss_scale 512.0000 (424.1485)	mem 11714MB
[2024-07-04 18:57:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:02:16 lr 0.000014	 wd 0.0000	time 0.4288 (0.4504)	loss 1.2281 (1.3387)	grad_norm 6.3912 (5.4382)	loss_scale 512.0000 (428.1399)	mem 11714MB
[2024-07-04 18:57:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:01:30 lr 0.000014	 wd 0.0000	time 0.4185 (0.4502)	loss 1.5362 (1.3383)	grad_norm 4.0606 (5.4946)	loss_scale 512.0000 (431.7844)	mem 11714MB
[2024-07-04 18:58:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:45 lr 0.000014	 wd 0.0000	time 0.4337 (0.4501)	loss 1.3546 (1.3360)	grad_norm 4.5105 (5.4643)	loss_scale 512.0000 (435.1254)	mem 11714MB
[2024-07-04 18:59:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.4239 (0.4498)	loss 1.4372 (1.3367)	grad_norm 3.7479 (5.4566)	loss_scale 512.0000 (438.1991)	mem 11714MB
[2024-07-04 18:59:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 19 training takes 0:18:48
[2024-07-04 18:59:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.495 (11.495)	Loss 0.4014 (0.4014)	Acc@1 92.969 (92.969)	Acc@5 98.438 (98.438)	Mem 11714MB
[2024-07-04 18:59:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.574 Acc@5 97.444
[2024-07-04 18:59:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-04 18:59:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.57%
[2024-07-04 18:59:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saving......
[2024-07-04 18:59:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saved !!!
[2024-07-04 18:59:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][0/2502]	eta 6:46:46 lr 0.000014	 wd 0.0000	time 9.7549 (9.7549)	loss 1.5487 (1.5487)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:00:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:21:37 lr 0.000014	 wd 0.0000	time 0.4320 (0.5401)	loss 1.5456 (1.3731)	grad_norm 3.5991 (5.0549)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:01:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:18:54 lr 0.000014	 wd 0.0000	time 0.4218 (0.4928)	loss 1.5543 (1.3477)	grad_norm 3.8920 (6.0674)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:02:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:17:30 lr 0.000014	 wd 0.0000	time 0.4341 (0.4772)	loss 1.2428 (1.3446)	grad_norm 4.9856 (5.7522)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:02:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:16:27 lr 0.000014	 wd 0.0000	time 0.4288 (0.4696)	loss 1.4081 (1.3333)	grad_norm 3.8584 (5.6496)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:03:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:15:30 lr 0.000014	 wd 0.0000	time 0.4269 (0.4646)	loss 1.1915 (1.3295)	grad_norm 8.0062 (5.6637)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:04:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:14:37 lr 0.000014	 wd 0.0000	time 0.4286 (0.4614)	loss 1.4251 (1.3313)	grad_norm 5.0810 (5.5737)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:05:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:13:47 lr 0.000013	 wd 0.0000	time 0.4330 (0.4590)	loss 1.3818 (1.3319)	grad_norm 12.2275 (5.5606)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:05:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:12:58 lr 0.000013	 wd 0.0000	time 0.4250 (0.4572)	loss 1.1271 (1.3331)	grad_norm 3.5445 (5.4515)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:06:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:12:10 lr 0.000013	 wd 0.0000	time 0.4326 (0.4559)	loss 1.2446 (1.3300)	grad_norm 4.4189 (5.4235)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:07:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:11:23 lr 0.000013	 wd 0.0000	time 0.4279 (0.4548)	loss 1.0118 (1.3341)	grad_norm 7.1446 (5.4715)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:08:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:10:36 lr 0.000013	 wd 0.0000	time 0.4318 (0.4539)	loss 1.2805 (1.3334)	grad_norm 4.7934 (5.4491)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:08:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:09:50 lr 0.000013	 wd 0.0000	time 0.4202 (0.4532)	loss 1.3605 (1.3344)	grad_norm 4.8030 (5.4391)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:09:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:09:04 lr 0.000013	 wd 0.0000	time 0.4351 (0.4527)	loss 1.3427 (1.3352)	grad_norm 6.9733 (5.4525)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:10:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:08:18 lr 0.000013	 wd 0.0000	time 0.4346 (0.4522)	loss 1.1188 (1.3354)	grad_norm 3.6047 (5.3945)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:11:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:07:32 lr 0.000013	 wd 0.0000	time 0.4408 (0.4517)	loss 1.4625 (1.3345)	grad_norm 3.7479 (5.3850)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:11:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:06:47 lr 0.000013	 wd 0.0000	time 0.4332 (0.4513)	loss 1.5745 (1.3344)	grad_norm 5.3776 (5.3967)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:12:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:06:01 lr 0.000012	 wd 0.0000	time 0.4275 (0.4509)	loss 1.5366 (1.3344)	grad_norm 4.1058 (5.3681)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:13:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:05:16 lr 0.000012	 wd 0.0000	time 0.4330 (0.4507)	loss 1.5844 (1.3356)	grad_norm 5.5064 (5.3631)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:14:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:04:31 lr 0.000012	 wd 0.0000	time 0.4228 (0.4504)	loss 1.4438 (1.3353)	grad_norm 3.9944 (5.3457)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:14:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:03:45 lr 0.000012	 wd 0.0000	time 0.4218 (0.4502)	loss 1.4621 (1.3364)	grad_norm 4.8028 (5.3427)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:15:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:03:00 lr 0.000012	 wd 0.0000	time 0.4275 (0.4500)	loss 1.4377 (1.3357)	grad_norm 4.7970 (5.3517)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:16:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:02:15 lr 0.000012	 wd 0.0000	time 0.4257 (0.4497)	loss 1.4325 (1.3352)	grad_norm 3.6642 (5.3275)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:17:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:01:30 lr 0.000012	 wd 0.0000	time 0.4250 (0.4495)	loss 1.5177 (1.3355)	grad_norm 6.3846 (5.3363)	loss_scale 1024.0000 (530.2460)	mem 11714MB
[2024-07-04 19:17:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:45 lr 0.000012	 wd 0.0000	time 0.4330 (0.4493)	loss 1.5054 (1.3370)	grad_norm 3.2237 (5.3249)	loss_scale 1024.0000 (550.8105)	mem 11714MB
[2024-07-04 19:18:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000012	 wd 0.0000	time 0.4246 (0.4490)	loss 1.4635 (1.3372)	grad_norm 5.4623 (5.3259)	loss_scale 1024.0000 (569.7305)	mem 11714MB
[2024-07-04 19:18:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 20 training takes 0:18:46
[2024-07-04 19:18:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 10.775 (10.775)	Loss 0.4109 (0.4109)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 11714MB
[2024-07-04 19:18:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.566 Acc@5 97.468
[2024-07-04 19:18:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-04 19:18:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.57%
[2024-07-04 19:19:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][0/2502]	eta 7:57:56 lr 0.000012	 wd 0.0000	time 11.4615 (11.4615)	loss 1.4706 (1.4706)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:19:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:22:13 lr 0.000012	 wd 0.0000	time 0.4269 (0.5550)	loss 0.9509 (1.3389)	grad_norm 4.7902 (4.9407)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:20:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:19:10 lr 0.000012	 wd 0.0000	time 0.4284 (0.4998)	loss 1.3987 (1.3467)	grad_norm 4.0947 (4.9960)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:21:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:17:40 lr 0.000012	 wd 0.0000	time 0.4016 (0.4814)	loss 1.2090 (1.3522)	grad_norm 10.4327 (5.2414)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:22:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:16:33 lr 0.000011	 wd 0.0000	time 0.4314 (0.4725)	loss 1.5244 (1.3504)	grad_norm 4.0783 (5.1794)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:22:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:15:34 lr 0.000011	 wd 0.0000	time 0.4238 (0.4669)	loss 1.6087 (1.3501)	grad_norm 6.5650 (5.1533)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:23:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:14:40 lr 0.000011	 wd 0.0000	time 0.4326 (0.4631)	loss 1.3903 (1.3435)	grad_norm 6.2154 (5.2408)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:24:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:13:49 lr 0.000011	 wd 0.0000	time 0.4282 (0.4605)	loss 1.6534 (1.3421)	grad_norm 6.9232 (5.3228)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:25:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:13:00 lr 0.000011	 wd 0.0000	time 0.4319 (0.4586)	loss 1.4199 (1.3389)	grad_norm 3.4454 (5.2765)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:25:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:12:12 lr 0.000011	 wd 0.0000	time 0.4270 (0.4571)	loss 1.3219 (1.3405)	grad_norm 14.6485 (5.3254)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:26:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:11:24 lr 0.000011	 wd 0.0000	time 0.4308 (0.4557)	loss 1.5789 (1.3390)	grad_norm 5.0654 (5.3846)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:27:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:10:37 lr 0.000011	 wd 0.0000	time 0.4318 (0.4548)	loss 0.8105 (1.3382)	grad_norm 3.8421 (5.3419)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:28:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:09:51 lr 0.000011	 wd 0.0000	time 0.4359 (0.4540)	loss 1.0643 (1.3366)	grad_norm 4.9945 (5.3587)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:28:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:09:04 lr 0.000011	 wd 0.0000	time 0.4322 (0.4532)	loss 1.5741 (1.3363)	grad_norm 7.6428 (5.3364)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:29:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:08:18 lr 0.000011	 wd 0.0000	time 0.4203 (0.4526)	loss 1.3930 (1.3375)	grad_norm 6.4562 (5.3499)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:30:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:07:32 lr 0.000010	 wd 0.0000	time 0.4240 (0.4521)	loss 1.1525 (1.3370)	grad_norm 3.0590 (5.3511)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:31:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:06:47 lr 0.000010	 wd 0.0000	time 0.4295 (0.4517)	loss 1.3659 (1.3374)	grad_norm 4.5309 (5.3417)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:31:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:06:01 lr 0.000010	 wd 0.0000	time 0.4316 (0.4514)	loss 1.3161 (1.3390)	grad_norm 4.2385 (5.3359)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:32:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:05:16 lr 0.000010	 wd 0.0000	time 0.4336 (0.4511)	loss 1.2548 (1.3383)	grad_norm 6.0938 (5.3286)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:33:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:04:31 lr 0.000010	 wd 0.0000	time 0.4295 (0.4508)	loss 1.3197 (1.3392)	grad_norm 3.8341 (5.3056)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:34:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:03:46 lr 0.000010	 wd 0.0000	time 0.4357 (0.4506)	loss 1.0243 (1.3376)	grad_norm 6.6702 (5.3120)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:34:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:03:01 lr 0.000010	 wd 0.0000	time 0.4283 (0.4503)	loss 1.0952 (1.3358)	grad_norm 3.9879 (5.3341)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:35:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:02:15 lr 0.000010	 wd 0.0000	time 0.4247 (0.4500)	loss 1.4829 (1.3357)	grad_norm 5.3688 (5.3329)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:36:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:01:30 lr 0.000010	 wd 0.0000	time 0.4386 (0.4498)	loss 1.3619 (1.3364)	grad_norm 5.4591 (5.3333)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 19:36:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:45 lr 0.000010	 wd 0.0000	time 0.4312 (0.4496)	loss 1.5114 (1.3378)	grad_norm 3.4593 (nan)	loss_scale 512.0000 (1009.0729)	mem 11714MB
[2024-07-04 19:37:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.4201 (0.4493)	loss 1.3495 (1.3372)	grad_norm 5.6680 (nan)	loss_scale 512.0000 (989.1979)	mem 11714MB
[2024-07-04 19:37:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 21 training takes 0:18:46
[2024-07-04 19:37:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.349 (11.349)	Loss 0.4019 (0.4019)	Acc@1 92.969 (92.969)	Acc@5 98.438 (98.438)	Mem 11714MB
[2024-07-04 19:38:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.610 Acc@5 97.478
[2024-07-04 19:38:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-04 19:38:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.61%
[2024-07-04 19:38:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saving......
[2024-07-04 19:38:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saved !!!
[2024-07-04 19:38:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][0/2502]	eta 7:05:16 lr 0.000010	 wd 0.0000	time 10.1985 (10.1985)	loss 1.0537 (1.0537)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:39:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:21:40 lr 0.000010	 wd 0.0000	time 0.4313 (0.5415)	loss 1.5604 (1.3406)	grad_norm 4.0763 (4.7401)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:39:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:18:55 lr 0.000009	 wd 0.0000	time 0.4251 (0.4934)	loss 1.2586 (1.3351)	grad_norm 5.5401 (4.8359)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:40:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:17:31 lr 0.000009	 wd 0.0000	time 0.4176 (0.4776)	loss 1.6159 (1.3338)	grad_norm 6.3896 (5.1833)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:41:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:16:26 lr 0.000009	 wd 0.0000	time 0.4254 (0.4695)	loss 1.4321 (1.3444)	grad_norm 4.4435 (5.1599)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:42:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:15:29 lr 0.000009	 wd 0.0000	time 0.4219 (0.4644)	loss 1.6253 (1.3454)	grad_norm 5.9150 (5.1441)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:42:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:14:37 lr 0.000009	 wd 0.0000	time 0.4241 (0.4614)	loss 1.5640 (1.3426)	grad_norm 3.8829 (5.2282)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:43:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:13:47 lr 0.000009	 wd 0.0000	time 0.4232 (0.4591)	loss 1.4247 (1.3455)	grad_norm 4.3055 (5.3655)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:44:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:12:58 lr 0.000009	 wd 0.0000	time 0.4363 (0.4574)	loss 1.2837 (1.3421)	grad_norm 3.3781 (5.4722)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:45:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:12:10 lr 0.000009	 wd 0.0000	time 0.4335 (0.4561)	loss 1.4742 (1.3455)	grad_norm 4.6633 (5.4261)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:45:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:11:23 lr 0.000009	 wd 0.0000	time 0.4287 (0.4550)	loss 1.3512 (1.3444)	grad_norm 2.9867 (5.4337)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:46:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:10:36 lr 0.000009	 wd 0.0000	time 0.4283 (0.4541)	loss 1.4520 (1.3417)	grad_norm 4.9973 (5.4752)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:47:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:09:50 lr 0.000009	 wd 0.0000	time 0.4321 (0.4534)	loss 1.3969 (1.3378)	grad_norm 3.8390 (5.4222)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:47:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:09:04 lr 0.000009	 wd 0.0000	time 0.4352 (0.4528)	loss 1.2892 (1.3351)	grad_norm 6.8051 (5.4809)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:48:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:08:18 lr 0.000008	 wd 0.0000	time 0.4302 (0.4522)	loss 1.2606 (1.3358)	grad_norm 3.8471 (5.4737)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:49:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:07:32 lr 0.000008	 wd 0.0000	time 0.4288 (0.4518)	loss 1.0489 (1.3367)	grad_norm 5.0855 (5.4551)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:50:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:06:47 lr 0.000008	 wd 0.0000	time 0.4308 (0.4514)	loss 1.5508 (1.3375)	grad_norm 5.5692 (5.4819)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:50:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:06:01 lr 0.000008	 wd 0.0000	time 0.4257 (0.4511)	loss 1.3269 (1.3354)	grad_norm 7.3496 (5.4596)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:51:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:05:16 lr 0.000008	 wd 0.0000	time 0.4346 (0.4508)	loss 1.2699 (1.3343)	grad_norm 10.7241 (5.4677)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:52:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:04:31 lr 0.000008	 wd 0.0000	time 0.4315 (0.4505)	loss 1.5565 (1.3356)	grad_norm 3.3374 (5.4705)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:53:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:03:46 lr 0.000008	 wd 0.0000	time 0.4288 (0.4503)	loss 1.5207 (1.3352)	grad_norm 4.0830 (5.4386)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:53:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:03:00 lr 0.000008	 wd 0.0000	time 0.4288 (0.4501)	loss 1.2637 (1.3356)	grad_norm 7.3308 (5.4608)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:54:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:02:15 lr 0.000008	 wd 0.0000	time 0.4262 (0.4498)	loss 1.1505 (1.3366)	grad_norm 4.5538 (5.4529)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:55:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:01:30 lr 0.000008	 wd 0.0000	time 0.4187 (0.4496)	loss 1.4738 (1.3367)	grad_norm 5.0061 (5.4728)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:56:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:45 lr 0.000008	 wd 0.0000	time 0.4234 (0.4495)	loss 1.2035 (1.3372)	grad_norm 5.3598 (5.4884)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:56:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.4243 (0.4493)	loss 1.5851 (1.3372)	grad_norm 4.4725 (5.4861)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:56:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 22 training takes 0:18:46
[2024-07-04 19:57:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.031 (11.031)	Loss 0.4001 (0.4001)	Acc@1 92.969 (92.969)	Acc@5 98.438 (98.438)	Mem 11714MB
[2024-07-04 19:57:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.650 Acc@5 97.482
[2024-07-04 19:57:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-04 19:57:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.65%
[2024-07-04 19:57:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saving......
[2024-07-04 19:57:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saved !!!
[2024-07-04 19:57:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][0/2502]	eta 6:42:11 lr 0.000008	 wd 0.0000	time 9.6449 (9.6449)	loss 1.4877 (1.4877)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:58:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:21:31 lr 0.000008	 wd 0.0000	time 0.4272 (0.5375)	loss 1.5759 (1.3539)	grad_norm 4.9023 (5.1353)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:59:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:18:52 lr 0.000007	 wd 0.0000	time 0.4247 (0.4920)	loss 1.0247 (1.3271)	grad_norm 7.0253 (5.2654)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 19:59:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:17:28 lr 0.000007	 wd 0.0000	time 0.4303 (0.4763)	loss 1.3852 (1.3208)	grad_norm 3.6790 (5.2317)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 20:00:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:16:25 lr 0.000007	 wd 0.0000	time 0.4173 (0.4686)	loss 1.3243 (1.3249)	grad_norm 8.4942 (5.4701)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 20:01:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:15:29 lr 0.000007	 wd 0.0000	time 0.4347 (0.4641)	loss 1.3678 (1.3294)	grad_norm 5.4564 (5.3914)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 20:01:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:14:36 lr 0.000007	 wd 0.0000	time 0.4412 (0.4608)	loss 1.2815 (1.3328)	grad_norm 4.5514 (5.4445)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 20:02:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:13:46 lr 0.000007	 wd 0.0000	time 0.4214 (0.4587)	loss 1.2473 (1.3293)	grad_norm 3.9640 (5.4507)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 20:03:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:12:57 lr 0.000007	 wd 0.0000	time 0.4296 (0.4570)	loss 1.4049 (1.3283)	grad_norm 4.7038 (5.4228)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 20:04:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:12:09 lr 0.000007	 wd 0.0000	time 0.4258 (0.4556)	loss 1.5633 (1.3275)	grad_norm 4.2414 (5.4560)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 20:04:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:11:22 lr 0.000007	 wd 0.0000	time 0.4288 (0.4545)	loss 1.1274 (1.3272)	grad_norm 8.8672 (5.4134)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 20:05:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:10:36 lr 0.000007	 wd 0.0000	time 0.4350 (0.4537)	loss 1.4844 (1.3264)	grad_norm 4.4614 (5.4337)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 20:06:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:09:49 lr 0.000007	 wd 0.0000	time 0.4343 (0.4530)	loss 1.3779 (1.3270)	grad_norm 5.5820 (5.4364)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 20:07:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:09:03 lr 0.000007	 wd 0.0000	time 0.4341 (0.4525)	loss 1.3145 (1.3274)	grad_norm 3.0133 (5.4986)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 20:07:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:08:18 lr 0.000007	 wd 0.0000	time 0.4324 (0.4520)	loss 1.5865 (1.3292)	grad_norm 4.7384 (5.5103)	loss_scale 1024.0000 (539.0435)	mem 11714MB
[2024-07-04 20:08:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:07:32 lr 0.000006	 wd 0.0000	time 0.4323 (0.4514)	loss 1.4410 (1.3297)	grad_norm 4.7483 (5.4796)	loss_scale 1024.0000 (571.3524)	mem 11714MB
[2024-07-04 20:09:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:06:46 lr 0.000006	 wd 0.0000	time 0.4359 (0.4510)	loss 1.1908 (1.3293)	grad_norm 5.7144 (5.4886)	loss_scale 1024.0000 (599.6252)	mem 11714MB
[2024-07-04 20:10:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:06:01 lr 0.000006	 wd 0.0000	time 0.4342 (0.4507)	loss 1.4238 (1.3292)	grad_norm 6.2935 (5.4806)	loss_scale 1024.0000 (624.5738)	mem 11714MB
[2024-07-04 20:10:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:05:16 lr 0.000006	 wd 0.0000	time 0.4270 (0.4504)	loss 1.0729 (1.3292)	grad_norm 3.9102 (5.5261)	loss_scale 1024.0000 (646.7518)	mem 11714MB
[2024-07-04 20:11:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:04:31 lr 0.000006	 wd 0.0000	time 0.4306 (0.4502)	loss 0.9460 (1.3278)	grad_norm 4.2172 (5.5576)	loss_scale 1024.0000 (666.5965)	mem 11714MB
[2024-07-04 20:12:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:03:45 lr 0.000006	 wd 0.0000	time 0.4334 (0.4500)	loss 1.4753 (1.3267)	grad_norm 5.7787 (5.5587)	loss_scale 1024.0000 (684.4578)	mem 11714MB
[2024-07-04 20:13:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:03:00 lr 0.000006	 wd 0.0000	time 0.4249 (0.4498)	loss 1.3714 (1.3276)	grad_norm 5.0814 (5.5314)	loss_scale 1024.0000 (700.6188)	mem 11714MB
[2024-07-04 20:13:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:02:15 lr 0.000006	 wd 0.0000	time 0.4256 (0.4496)	loss 1.4984 (1.3251)	grad_norm 3.8768 (5.5169)	loss_scale 1024.0000 (715.3112)	mem 11714MB
[2024-07-04 20:14:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:01:30 lr 0.000006	 wd 0.0000	time 0.4228 (0.4494)	loss 1.4783 (1.3240)	grad_norm 4.7018 (5.5222)	loss_scale 1024.0000 (728.7266)	mem 11714MB
[2024-07-04 20:15:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:45 lr 0.000006	 wd 0.0000	time 0.4374 (0.4493)	loss 1.4412 (1.3257)	grad_norm 3.2314 (5.5066)	loss_scale 1024.0000 (741.0246)	mem 11714MB
[2024-07-04 20:16:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000006	 wd 0.0000	time 0.4296 (0.4490)	loss 1.2991 (1.3252)	grad_norm 5.3296 (5.4895)	loss_scale 1024.0000 (752.3391)	mem 11714MB
[2024-07-04 20:16:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 23 training takes 0:18:45
[2024-07-04 20:16:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.253 (11.253)	Loss 0.3984 (0.3984)	Acc@1 92.969 (92.969)	Acc@5 98.633 (98.633)	Mem 11714MB
[2024-07-04 20:16:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.704 Acc@5 97.500
[2024-07-04 20:16:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-04 20:16:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.70%
[2024-07-04 20:16:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saving......
[2024-07-04 20:16:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saved !!!
[2024-07-04 20:16:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][0/2502]	eta 7:04:04 lr 0.000006	 wd 0.0000	time 10.1695 (10.1695)	loss 1.2227 (1.2227)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 20:17:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:21:37 lr 0.000006	 wd 0.0000	time 0.4333 (0.5402)	loss 1.3486 (1.3340)	grad_norm 4.2587 (nan)	loss_scale 512.0000 (912.4752)	mem 11714MB
[2024-07-04 20:18:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:18:54 lr 0.000006	 wd 0.0000	time 0.4364 (0.4927)	loss 1.0751 (1.3294)	grad_norm 4.1347 (nan)	loss_scale 512.0000 (713.2338)	mem 11714MB
[2024-07-04 20:18:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:17:29 lr 0.000006	 wd 0.0000	time 0.4333 (0.4768)	loss 1.2833 (1.3312)	grad_norm 4.3775 (nan)	loss_scale 512.0000 (646.3787)	mem 11714MB
[2024-07-04 20:19:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:16:25 lr 0.000005	 wd 0.0000	time 0.4327 (0.4686)	loss 1.2359 (1.3407)	grad_norm 6.0884 (nan)	loss_scale 512.0000 (612.8678)	mem 11714MB
[2024-07-04 20:20:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:15:28 lr 0.000005	 wd 0.0000	time 0.4253 (0.4637)	loss 0.9959 (1.3384)	grad_norm 4.2630 (nan)	loss_scale 512.0000 (592.7345)	mem 11714MB
[2024-07-04 20:21:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:14:35 lr 0.000005	 wd 0.0000	time 0.4306 (0.4602)	loss 1.2155 (1.3368)	grad_norm 4.1065 (nan)	loss_scale 512.0000 (579.3012)	mem 11714MB
[2024-07-04 20:21:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:13:45 lr 0.000005	 wd 0.0000	time 0.4304 (0.4579)	loss 0.8122 (1.3332)	grad_norm 4.1268 (nan)	loss_scale 512.0000 (569.7004)	mem 11714MB
[2024-07-04 20:22:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:12:56 lr 0.000005	 wd 0.0000	time 0.4320 (0.4562)	loss 1.2015 (1.3303)	grad_norm 4.7677 (nan)	loss_scale 512.0000 (562.4969)	mem 11714MB
[2024-07-04 20:23:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:12:08 lr 0.000005	 wd 0.0000	time 0.4252 (0.4548)	loss 1.2707 (1.3300)	grad_norm 4.1822 (nan)	loss_scale 512.0000 (556.8923)	mem 11714MB
[2024-07-04 20:24:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:11:21 lr 0.000005	 wd 0.0000	time 0.4206 (0.4537)	loss 1.4255 (1.3321)	grad_norm 5.9652 (nan)	loss_scale 512.0000 (552.4076)	mem 11714MB
[2024-07-04 20:24:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:10:34 lr 0.000005	 wd 0.0000	time 0.4088 (0.4529)	loss 1.4620 (1.3300)	grad_norm 4.7174 (nan)	loss_scale 512.0000 (548.7375)	mem 11714MB
[2024-07-04 20:25:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:09:48 lr 0.000005	 wd 0.0000	time 0.4269 (0.4522)	loss 1.2250 (1.3290)	grad_norm 4.1854 (nan)	loss_scale 256.0000 (537.5787)	mem 11714MB
[2024-07-04 20:26:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:09:02 lr 0.000005	 wd 0.0000	time 0.4255 (0.4517)	loss 0.8958 (1.3298)	grad_norm 9.5057 (nan)	loss_scale 256.0000 (515.9354)	mem 11714MB
[2024-07-04 20:27:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:08:17 lr 0.000005	 wd 0.0000	time 0.4302 (0.4512)	loss 1.3682 (1.3316)	grad_norm 4.8846 (nan)	loss_scale 256.0000 (497.3819)	mem 11714MB
[2024-07-04 20:27:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:07:31 lr 0.000005	 wd 0.0000	time 0.4338 (0.4508)	loss 1.4042 (1.3311)	grad_norm 4.0168 (nan)	loss_scale 256.0000 (481.3005)	mem 11714MB
[2024-07-04 20:28:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:06:46 lr 0.000005	 wd 0.0000	time 0.4253 (0.4503)	loss 1.4282 (1.3311)	grad_norm 3.2325 (nan)	loss_scale 256.0000 (467.2280)	mem 11714MB
[2024-07-04 20:29:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:06:00 lr 0.000005	 wd 0.0000	time 0.4253 (0.4500)	loss 1.4590 (1.3310)	grad_norm 3.6334 (nan)	loss_scale 256.0000 (454.8101)	mem 11714MB
[2024-07-04 20:30:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:05:15 lr 0.000005	 wd 0.0000	time 0.4333 (0.4497)	loss 1.4592 (1.3319)	grad_norm 5.1097 (nan)	loss_scale 256.0000 (443.7712)	mem 11714MB
[2024-07-04 20:30:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:04:30 lr 0.000005	 wd 0.0000	time 0.4344 (0.4494)	loss 1.3282 (1.3307)	grad_norm 4.6404 (nan)	loss_scale 256.0000 (433.8937)	mem 11714MB
[2024-07-04 20:31:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:03:45 lr 0.000004	 wd 0.0000	time 0.4360 (0.4492)	loss 1.4495 (1.3297)	grad_norm 8.9804 (nan)	loss_scale 256.0000 (425.0035)	mem 11714MB
[2024-07-04 20:32:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:03:00 lr 0.000004	 wd 0.0000	time 0.4390 (0.4489)	loss 1.4065 (1.3291)	grad_norm 5.3876 (nan)	loss_scale 256.0000 (416.9595)	mem 11714MB
[2024-07-04 20:33:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:02:15 lr 0.000004	 wd 0.0000	time 0.4336 (0.4488)	loss 1.4174 (1.3277)	grad_norm 3.9750 (nan)	loss_scale 256.0000 (409.6465)	mem 11714MB
[2024-07-04 20:33:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:01:30 lr 0.000004	 wd 0.0000	time 0.4306 (0.4486)	loss 1.3662 (1.3285)	grad_norm 4.1770 (nan)	loss_scale 256.0000 (402.9691)	mem 11714MB
[2024-07-04 20:34:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:45 lr 0.000004	 wd 0.0000	time 0.4338 (0.4484)	loss 1.3924 (1.3275)	grad_norm 3.8191 (nan)	loss_scale 256.0000 (396.8480)	mem 11714MB
[2024-07-04 20:35:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000004	 wd 0.0000	time 0.4288 (0.4481)	loss 0.9709 (1.3265)	grad_norm 4.8984 (nan)	loss_scale 256.0000 (391.2163)	mem 11714MB
[2024-07-04 20:35:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 24 training takes 0:18:44
[2024-07-04 20:35:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.435 (11.435)	Loss 0.4016 (0.4016)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 11714MB
[2024-07-04 20:35:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.680 Acc@5 97.508
[2024-07-04 20:35:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-04 20:35:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.70%
[2024-07-04 20:35:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][0/2502]	eta 7:51:46 lr 0.000004	 wd 0.0000	time 11.3137 (11.3137)	loss 1.0245 (1.0245)	grad_norm 0.0000 (0.0000)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:36:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:22:07 lr 0.000004	 wd 0.0000	time 0.4317 (0.5526)	loss 1.4560 (1.3481)	grad_norm 4.7692 (5.8201)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:37:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:19:09 lr 0.000004	 wd 0.0000	time 0.4244 (0.4994)	loss 1.3993 (1.3386)	grad_norm 5.5988 (5.5125)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:38:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:17:40 lr 0.000004	 wd 0.0000	time 0.4322 (0.4815)	loss 1.4232 (1.3304)	grad_norm 5.5048 (5.4857)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:38:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:16:33 lr 0.000004	 wd 0.0000	time 0.4206 (0.4725)	loss 1.4710 (1.3233)	grad_norm 4.2049 (5.4243)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:39:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:15:34 lr 0.000004	 wd 0.0000	time 0.4257 (0.4669)	loss 1.4946 (1.3242)	grad_norm 7.5942 (5.6807)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:40:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:14:41 lr 0.000004	 wd 0.0000	time 0.4345 (0.4634)	loss 1.0836 (1.3249)	grad_norm 4.3116 (5.5339)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:41:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:13:50 lr 0.000004	 wd 0.0000	time 0.4384 (0.4608)	loss 1.3008 (1.3239)	grad_norm 3.8662 (5.4976)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:41:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:13:01 lr 0.000004	 wd 0.0000	time 0.4244 (0.4589)	loss 1.5630 (1.3231)	grad_norm 4.1994 (5.4734)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:42:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:12:12 lr 0.000004	 wd 0.0000	time 0.4394 (0.4574)	loss 1.4392 (1.3209)	grad_norm 6.7098 (5.4592)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:43:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:11:25 lr 0.000004	 wd 0.0000	time 0.4299 (0.4561)	loss 1.1551 (1.3216)	grad_norm 4.4705 (5.4486)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:44:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:10:38 lr 0.000004	 wd 0.0000	time 0.4268 (0.4552)	loss 0.9662 (1.3175)	grad_norm 3.9918 (5.3913)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:44:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:09:51 lr 0.000004	 wd 0.0000	time 0.4309 (0.4544)	loss 1.5929 (1.3201)	grad_norm 4.8723 (5.4177)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:45:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:09:05 lr 0.000003	 wd 0.0000	time 0.4246 (0.4537)	loss 1.2563 (1.3198)	grad_norm 6.4194 (5.4228)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:46:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:08:19 lr 0.000003	 wd 0.0000	time 0.4317 (0.4530)	loss 1.1480 (1.3201)	grad_norm 5.5908 (5.4116)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:47:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:07:33 lr 0.000003	 wd 0.0000	time 0.4310 (0.4525)	loss 1.2625 (1.3219)	grad_norm 5.2599 (5.4042)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:47:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:06:47 lr 0.000003	 wd 0.0000	time 0.4341 (0.4521)	loss 1.2046 (1.3221)	grad_norm 3.4650 (5.3740)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:48:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:06:02 lr 0.000003	 wd 0.0000	time 0.4368 (0.4516)	loss 1.3463 (1.3228)	grad_norm 3.3087 (5.3594)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:49:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:05:16 lr 0.000003	 wd 0.0000	time 0.4239 (0.4513)	loss 1.5102 (1.3223)	grad_norm 4.9938 (5.3384)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:49:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:04:31 lr 0.000003	 wd 0.0000	time 0.4261 (0.4510)	loss 1.4527 (1.3250)	grad_norm 6.2201 (5.3685)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:50:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:03:46 lr 0.000003	 wd 0.0000	time 0.4306 (0.4508)	loss 1.5390 (1.3246)	grad_norm 5.8222 (5.3784)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:51:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:03:01 lr 0.000003	 wd 0.0000	time 0.4397 (0.4505)	loss 1.4304 (1.3245)	grad_norm 4.1871 (5.4022)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:52:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:02:15 lr 0.000003	 wd 0.0000	time 0.4364 (0.4503)	loss 1.5445 (1.3218)	grad_norm 4.6525 (5.4137)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:52:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:01:30 lr 0.000003	 wd 0.0000	time 0.4270 (0.4501)	loss 1.4873 (1.3218)	grad_norm 3.6787 (5.3966)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:53:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:45 lr 0.000003	 wd 0.0000	time 0.4228 (0.4500)	loss 1.5316 (1.3223)	grad_norm 10.4806 (5.4128)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:54:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.4335 (0.4497)	loss 1.4154 (1.3229)	grad_norm 3.5021 (5.3919)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:54:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 25 training takes 0:18:49
[2024-07-04 20:54:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 10.713 (10.713)	Loss 0.3977 (0.3977)	Acc@1 92.969 (92.969)	Acc@5 98.438 (98.438)	Mem 11714MB
[2024-07-04 20:54:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.700 Acc@5 97.514
[2024-07-04 20:54:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-04 20:54:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.70%
[2024-07-04 20:55:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][0/2502]	eta 7:55:23 lr 0.000003	 wd 0.0000	time 11.4001 (11.4001)	loss 1.5381 (1.5381)	grad_norm 0.0000 (0.0000)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:55:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:22:08 lr 0.000003	 wd 0.0000	time 0.4330 (0.5529)	loss 1.1003 (1.3497)	grad_norm 5.5591 (5.3582)	loss_scale 256.0000 (256.0000)	mem 11714MB
[2024-07-04 20:56:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:19:08 lr 0.000003	 wd 0.0000	time 0.4278 (0.4991)	loss 1.5315 (1.3491)	grad_norm 5.8139 (5.5414)	loss_scale 512.0000 (309.4925)	mem 11714MB
[2024-07-04 20:57:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:17:39 lr 0.000003	 wd 0.0000	time 0.4320 (0.4812)	loss 1.4381 (1.3395)	grad_norm 4.8211 (5.5088)	loss_scale 512.0000 (376.7708)	mem 11714MB
[2024-07-04 20:58:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:16:31 lr 0.000003	 wd 0.0000	time 0.4147 (0.4719)	loss 1.6411 (1.3361)	grad_norm 3.6861 (5.4141)	loss_scale 512.0000 (410.4938)	mem 11714MB
[2024-07-04 20:58:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:15:33 lr 0.000003	 wd 0.0000	time 0.4257 (0.4662)	loss 1.5410 (1.3357)	grad_norm 4.3138 (5.4060)	loss_scale 512.0000 (430.7545)	mem 11714MB
[2024-07-04 20:59:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:14:39 lr 0.000003	 wd 0.0000	time 0.4335 (0.4625)	loss 1.3799 (1.3346)	grad_norm 12.6435 (5.3507)	loss_scale 512.0000 (444.2729)	mem 11714MB
[2024-07-04 21:00:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:13:48 lr 0.000003	 wd 0.0000	time 0.4291 (0.4600)	loss 1.4219 (1.3358)	grad_norm 3.9478 (5.3094)	loss_scale 512.0000 (453.9344)	mem 11714MB
[2024-07-04 21:01:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:12:59 lr 0.000002	 wd 0.0000	time 0.4419 (0.4581)	loss 1.4552 (1.3364)	grad_norm 4.1605 (5.3206)	loss_scale 512.0000 (461.1835)	mem 11714MB
[2024-07-04 21:01:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:12:11 lr 0.000002	 wd 0.0000	time 0.4320 (0.4566)	loss 1.3477 (1.3321)	grad_norm 7.9007 (5.4323)	loss_scale 512.0000 (466.8235)	mem 11714MB
[2024-07-04 21:02:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:11:23 lr 0.000002	 wd 0.0000	time 0.4261 (0.4554)	loss 1.2278 (1.3316)	grad_norm 5.1182 (5.3585)	loss_scale 512.0000 (471.3367)	mem 11714MB
[2024-07-04 21:03:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:10:37 lr 0.000002	 wd 0.0000	time 0.4287 (0.4545)	loss 1.6551 (1.3306)	grad_norm 7.2023 (5.3059)	loss_scale 512.0000 (475.0300)	mem 11714MB
[2024-07-04 21:04:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:09:50 lr 0.000002	 wd 0.0000	time 0.4235 (0.4537)	loss 1.1047 (1.3294)	grad_norm 3.8566 (5.2800)	loss_scale 512.0000 (478.1082)	mem 11714MB
[2024-07-04 21:04:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:09:04 lr 0.000002	 wd 0.0000	time 0.4301 (0.4529)	loss 1.2649 (1.3303)	grad_norm 5.5402 (5.2614)	loss_scale 512.0000 (480.7133)	mem 11714MB
[2024-07-04 21:05:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:08:18 lr 0.000002	 wd 0.0000	time 0.4218 (0.4524)	loss 1.6080 (1.3285)	grad_norm 3.8282 (5.2372)	loss_scale 512.0000 (482.9465)	mem 11714MB
[2024-07-04 21:06:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:07:32 lr 0.000002	 wd 0.0000	time 0.4267 (0.4519)	loss 0.9397 (1.3270)	grad_norm 5.5155 (5.2453)	loss_scale 512.0000 (484.8821)	mem 11714MB
[2024-07-04 21:07:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:06:47 lr 0.000002	 wd 0.0000	time 0.4348 (0.4516)	loss 1.2840 (1.3259)	grad_norm 4.8359 (5.2553)	loss_scale 512.0000 (486.5759)	mem 11714MB
[2024-07-04 21:07:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:06:01 lr 0.000002	 wd 0.0000	time 0.4205 (0.4512)	loss 1.3774 (1.3268)	grad_norm 3.6038 (5.2378)	loss_scale 512.0000 (488.0705)	mem 11714MB
[2024-07-04 21:08:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:05:16 lr 0.000002	 wd 0.0000	time 0.4277 (0.4509)	loss 1.1839 (1.3250)	grad_norm 4.3926 (5.2291)	loss_scale 512.0000 (489.3992)	mem 11714MB
[2024-07-04 21:09:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:04:31 lr 0.000002	 wd 0.0000	time 0.4334 (0.4506)	loss 1.6164 (1.3254)	grad_norm 3.0898 (5.2503)	loss_scale 512.0000 (490.5881)	mem 11714MB
[2024-07-04 21:09:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:03:46 lr 0.000002	 wd 0.0000	time 0.4244 (0.4503)	loss 1.5868 (1.3263)	grad_norm 3.7801 (5.2306)	loss_scale 512.0000 (491.6582)	mem 11714MB
[2024-07-04 21:10:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:03:00 lr 0.000002	 wd 0.0000	time 0.4239 (0.4501)	loss 1.4870 (1.3253)	grad_norm 7.7811 (5.2363)	loss_scale 512.0000 (492.6264)	mem 11714MB
[2024-07-04 21:11:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:02:15 lr 0.000002	 wd 0.0000	time 0.4245 (0.4498)	loss 1.2099 (1.3250)	grad_norm 4.4542 (5.2390)	loss_scale 512.0000 (493.5066)	mem 11714MB
[2024-07-04 21:12:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:01:30 lr 0.000002	 wd 0.0000	time 0.4284 (0.4496)	loss 1.5214 (1.3239)	grad_norm 3.8209 (5.2332)	loss_scale 512.0000 (494.3103)	mem 11714MB
[2024-07-04 21:12:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:45 lr 0.000002	 wd 0.0000	time 0.4339 (0.4494)	loss 1.3536 (1.3241)	grad_norm 5.1032 (5.2332)	loss_scale 512.0000 (495.0471)	mem 11714MB
[2024-07-04 21:13:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.4400 (0.4494)	loss 1.2127 (1.3244)	grad_norm 14.4458 (5.2242)	loss_scale 512.0000 (495.7249)	mem 11714MB
[2024-07-04 21:13:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 26 training takes 0:18:49
[2024-07-04 21:13:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 10.126 (10.126)	Loss 0.3994 (0.3994)	Acc@1 92.969 (92.969)	Acc@5 98.438 (98.438)	Mem 11714MB
[2024-07-04 21:14:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.708 Acc@5 97.500
[2024-07-04 21:14:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-04 21:14:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.71%
[2024-07-04 21:14:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saving......
[2024-07-04 21:14:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saved !!!
[2024-07-04 21:14:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][0/2502]	eta 7:05:19 lr 0.000002	 wd 0.0000	time 10.1996 (10.1996)	loss 1.1687 (1.1687)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 21:15:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:21:44 lr 0.000002	 wd 0.0000	time 0.4286 (0.5432)	loss 1.5429 (1.2979)	grad_norm 3.5677 (5.1518)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 21:15:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:18:58 lr 0.000002	 wd 0.0000	time 0.4316 (0.4945)	loss 1.3600 (1.3130)	grad_norm 3.6089 (5.4024)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 21:16:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:17:32 lr 0.000002	 wd 0.0000	time 0.4385 (0.4781)	loss 1.0200 (1.3131)	grad_norm 3.3591 (5.3316)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 21:17:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:16:27 lr 0.000002	 wd 0.0000	time 0.4225 (0.4698)	loss 1.1408 (1.3254)	grad_norm 7.3311 (5.1974)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 21:18:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:15:30 lr 0.000002	 wd 0.0000	time 0.4322 (0.4649)	loss 1.4256 (1.3242)	grad_norm 4.4190 (5.2355)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 21:18:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:14:37 lr 0.000002	 wd 0.0000	time 0.4375 (0.4616)	loss 1.2076 (1.3260)	grad_norm 7.1505 (5.2746)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 21:19:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:13:47 lr 0.000002	 wd 0.0000	time 0.4073 (0.4594)	loss 1.2054 (1.3249)	grad_norm 5.6311 (5.3357)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 21:20:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:12:58 lr 0.000002	 wd 0.0000	time 0.4296 (0.4575)	loss 1.0353 (1.3268)	grad_norm 4.4495 (5.4372)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 21:21:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:12:10 lr 0.000001	 wd 0.0000	time 0.4234 (0.4560)	loss 1.4826 (1.3285)	grad_norm 3.8892 (5.4250)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 21:21:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:11:23 lr 0.000001	 wd 0.0000	time 0.4326 (0.4549)	loss 1.0349 (1.3285)	grad_norm 4.4515 (5.3896)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 21:22:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:10:36 lr 0.000001	 wd 0.0000	time 0.4191 (0.4540)	loss 1.1506 (1.3259)	grad_norm 9.3164 (5.4137)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 21:23:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:09:50 lr 0.000001	 wd 0.0000	time 0.4283 (0.4532)	loss 1.2817 (1.3257)	grad_norm 5.1186 (5.3997)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 21:24:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:09:03 lr 0.000001	 wd 0.0000	time 0.4266 (0.4525)	loss 1.4257 (1.3271)	grad_norm 3.6605 (5.3698)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 21:24:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:08:18 lr 0.000001	 wd 0.0000	time 0.4109 (0.4521)	loss 1.1072 (1.3272)	grad_norm 4.4244 (5.3617)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 21:25:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:07:32 lr 0.000001	 wd 0.0000	time 0.4333 (0.4516)	loss 1.2888 (1.3276)	grad_norm 4.0364 (5.3463)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 21:26:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:06:47 lr 0.000001	 wd 0.0000	time 0.4388 (0.4513)	loss 1.5205 (1.3276)	grad_norm 5.2844 (5.3180)	loss_scale 512.0000 (512.0000)	mem 11714MB
[2024-07-04 21:27:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:06:01 lr 0.000001	 wd 0.0000	time 0.4326 (0.4510)	loss 1.4266 (1.3268)	grad_norm 6.1757 (5.3013)	loss_scale 1024.0000 (525.2440)	mem 11714MB
[2024-07-04 21:27:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:05:16 lr 0.000001	 wd 0.0000	time 0.4336 (0.4507)	loss 1.5793 (1.3267)	grad_norm 11.5961 (5.3505)	loss_scale 1024.0000 (552.9373)	mem 11714MB
[2024-07-04 21:28:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:04:31 lr 0.000001	 wd 0.0000	time 0.4393 (0.4504)	loss 1.4527 (1.3264)	grad_norm 6.6229 (5.3616)	loss_scale 1024.0000 (577.7170)	mem 11714MB
[2024-07-04 21:29:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:03:45 lr 0.000001	 wd 0.0000	time 0.4263 (0.4502)	loss 1.1841 (1.3257)	grad_norm 6.3682 (5.3484)	loss_scale 1024.0000 (600.0200)	mem 11714MB
[2024-07-04 21:30:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:03:00 lr 0.000001	 wd 0.0000	time 0.4185 (0.4500)	loss 0.9448 (1.3274)	grad_norm 3.8483 (5.3354)	loss_scale 1024.0000 (620.1999)	mem 11714MB
[2024-07-04 21:30:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:02:15 lr 0.000001	 wd 0.0000	time 0.4286 (0.4498)	loss 1.3969 (1.3266)	grad_norm 3.7871 (5.3612)	loss_scale 1024.0000 (638.5461)	mem 11714MB
[2024-07-04 21:31:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:01:30 lr 0.000001	 wd 0.0000	time 0.4209 (0.4495)	loss 1.2968 (1.3254)	grad_norm 3.4209 (5.3506)	loss_scale 1024.0000 (655.2977)	mem 11714MB
[2024-07-04 21:32:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:45 lr 0.000001	 wd 0.0000	time 0.4337 (0.4494)	loss 1.3555 (1.3261)	grad_norm 4.3049 (5.3537)	loss_scale 1024.0000 (670.6539)	mem 11714MB
[2024-07-04 21:32:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.4225 (0.4491)	loss 1.5561 (1.3259)	grad_norm 4.0168 (5.3528)	loss_scale 1024.0000 (684.7821)	mem 11714MB
[2024-07-04 21:33:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 27 training takes 0:18:51
[2024-07-04 21:33:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.498 (11.498)	Loss 0.3989 (0.3989)	Acc@1 92.969 (92.969)	Acc@5 98.438 (98.438)	Mem 11714MB
[2024-07-04 21:33:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.726 Acc@5 97.516
[2024-07-04 21:33:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-04 21:33:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.73%
[2024-07-04 21:33:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saving......
[2024-07-04 21:33:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saved !!!
[2024-07-04 21:33:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][0/2502]	eta 7:02:05 lr 0.000001	 wd 0.0000	time 10.1222 (10.1222)	loss 1.2628 (1.2628)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:34:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:21:41 lr 0.000001	 wd 0.0000	time 0.4243 (0.5419)	loss 1.4535 (1.3107)	grad_norm 7.3631 (5.2558)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:35:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:18:54 lr 0.000001	 wd 0.0000	time 0.4314 (0.4927)	loss 1.4005 (1.3382)	grad_norm 4.9881 (5.3617)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:36:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:17:28 lr 0.000001	 wd 0.0000	time 0.4287 (0.4764)	loss 1.5608 (1.3344)	grad_norm 4.6537 (5.4319)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:36:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:16:24 lr 0.000001	 wd 0.0000	time 0.4194 (0.4684)	loss 1.4574 (1.3346)	grad_norm 4.2922 (5.4974)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:37:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:15:28 lr 0.000001	 wd 0.0000	time 0.4323 (0.4636)	loss 1.5199 (1.3404)	grad_norm 9.3329 (5.5277)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:38:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:14:35 lr 0.000001	 wd 0.0000	time 0.4292 (0.4603)	loss 1.3425 (1.3346)	grad_norm 3.5402 (5.5243)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:38:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:13:45 lr 0.000001	 wd 0.0000	time 0.4234 (0.4579)	loss 1.2646 (1.3325)	grad_norm 5.1711 (5.4496)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:39:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:12:56 lr 0.000001	 wd 0.0000	time 0.4229 (0.4562)	loss 1.4869 (1.3300)	grad_norm 4.5921 (5.4574)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:40:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:12:08 lr 0.000001	 wd 0.0000	time 0.4179 (0.4549)	loss 1.4727 (1.3313)	grad_norm 3.8018 (5.4136)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:41:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:11:21 lr 0.000001	 wd 0.0000	time 0.4279 (0.4536)	loss 1.4802 (1.3312)	grad_norm 16.0855 (5.4332)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:41:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:10:34 lr 0.000001	 wd 0.0000	time 0.4272 (0.4528)	loss 1.3140 (1.3331)	grad_norm 6.0155 (5.4093)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:42:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:09:48 lr 0.000001	 wd 0.0000	time 0.4238 (0.4521)	loss 1.3097 (1.3333)	grad_norm 6.4535 (5.4431)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:43:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:09:02 lr 0.000001	 wd 0.0000	time 0.4286 (0.4516)	loss 1.0522 (1.3312)	grad_norm 4.7168 (5.4369)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:44:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:08:17 lr 0.000001	 wd 0.0000	time 0.4310 (0.4512)	loss 1.4733 (1.3306)	grad_norm 4.3134 (5.3983)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:44:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:07:31 lr 0.000001	 wd 0.0000	time 0.4308 (0.4508)	loss 1.4530 (1.3283)	grad_norm 4.5344 (5.3987)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:45:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:06:46 lr 0.000001	 wd 0.0000	time 0.4293 (0.4504)	loss 1.4789 (1.3280)	grad_norm 4.2906 (5.3808)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:46:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:06:01 lr 0.000001	 wd 0.0000	time 0.4345 (0.4501)	loss 1.4010 (1.3283)	grad_norm 7.2500 (5.4257)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:47:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:05:15 lr 0.000001	 wd 0.0000	time 0.4359 (0.4499)	loss 1.4266 (1.3301)	grad_norm 5.4189 (5.4599)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:47:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:04:30 lr 0.000001	 wd 0.0000	time 0.4305 (0.4496)	loss 1.0504 (1.3296)	grad_norm 3.7047 (5.4433)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:48:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:03:45 lr 0.000001	 wd 0.0000	time 0.4308 (0.4495)	loss 0.9340 (1.3275)	grad_norm 9.5990 (5.3981)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:49:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:03:00 lr 0.000001	 wd 0.0000	time 0.4261 (0.4493)	loss 1.0781 (1.3260)	grad_norm 4.5192 (5.3936)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:50:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:02:15 lr 0.000001	 wd 0.0000	time 0.4383 (0.4491)	loss 1.0533 (1.3260)	grad_norm 4.6175 (5.3960)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:50:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:01:30 lr 0.000001	 wd 0.0000	time 0.4265 (0.4490)	loss 1.0783 (1.3258)	grad_norm 5.1378 (5.4249)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:51:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:45 lr 0.000001	 wd 0.0000	time 0.4085 (0.4488)	loss 1.2904 (1.3252)	grad_norm 4.5178 (5.4180)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:52:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.4233 (0.4486)	loss 0.9009 (1.3233)	grad_norm 5.3072 (5.4123)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:52:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 28 training takes 0:18:48
[2024-07-04 21:52:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 11.506 (11.506)	Loss 0.3982 (0.3982)	Acc@1 92.969 (92.969)	Acc@5 98.438 (98.438)	Mem 11714MB
[2024-07-04 21:52:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.732 Acc@5 97.506
[2024-07-04 21:52:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-04 21:52:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.73%
[2024-07-04 21:52:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saving......
[2024-07-04 21:52:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saved !!!
[2024-07-04 21:53:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][0/2502]	eta 7:04:59 lr 0.000001	 wd 0.0000	time 10.1915 (10.1915)	loss 0.8380 (0.8380)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:53:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:21:39 lr 0.000001	 wd 0.0000	time 0.4307 (0.5410)	loss 1.6381 (1.3329)	grad_norm 5.6124 (5.2583)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:54:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:18:56 lr 0.000001	 wd 0.0000	time 0.4297 (0.4936)	loss 1.3205 (1.3337)	grad_norm 10.0837 (5.3585)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:55:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:17:30 lr 0.000001	 wd 0.0000	time 0.4304 (0.4771)	loss 1.1305 (1.3311)	grad_norm 7.0461 (5.3736)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:56:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:16:25 lr 0.000001	 wd 0.0000	time 0.4349 (0.4687)	loss 1.4530 (1.3313)	grad_norm 3.7358 (5.3751)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:56:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:15:28 lr 0.000001	 wd 0.0000	time 0.4199 (0.4638)	loss 0.7508 (1.3245)	grad_norm 8.2538 (5.4583)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:57:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:14:35 lr 0.000000	 wd 0.0000	time 0.4215 (0.4605)	loss 1.1168 (1.3224)	grad_norm 3.0886 (5.4255)	loss_scale 1024.0000 (1024.0000)	mem 11714MB
[2024-07-04 21:58:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:13:45 lr 0.000000	 wd 0.0000	time 0.4281 (0.4582)	loss 1.4058 (1.3263)	grad_norm 8.5172 (inf)	loss_scale 512.0000 (953.8830)	mem 11714MB
[2024-07-04 21:59:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:12:56 lr 0.000000	 wd 0.0000	time 0.4241 (0.4564)	loss 1.4221 (1.3291)	grad_norm 3.6076 (inf)	loss_scale 512.0000 (898.7166)	mem 11714MB
[2024-07-04 21:59:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:12:08 lr 0.000000	 wd 0.0000	time 0.4170 (0.4550)	loss 1.5304 (1.3347)	grad_norm 3.5273 (inf)	loss_scale 512.0000 (855.7958)	mem 11714MB
[2024-07-04 22:00:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:11:21 lr 0.000000	 wd 0.0000	time 0.4268 (0.4539)	loss 1.2924 (1.3342)	grad_norm 4.7073 (inf)	loss_scale 512.0000 (821.4505)	mem 11714MB
[2024-07-04 22:01:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:10:35 lr 0.000000	 wd 0.0000	time 0.4270 (0.4530)	loss 1.6780 (1.3359)	grad_norm 7.1794 (inf)	loss_scale 512.0000 (793.3442)	mem 11714MB
[2024-07-04 22:02:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:09:48 lr 0.000000	 wd 0.0000	time 0.4197 (0.4523)	loss 1.4867 (1.3367)	grad_norm 4.3365 (inf)	loss_scale 512.0000 (769.9184)	mem 11714MB
[2024-07-04 22:02:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:09:02 lr 0.000000	 wd 0.0000	time 0.4221 (0.4517)	loss 1.4507 (1.3346)	grad_norm 3.5226 (inf)	loss_scale 512.0000 (750.0938)	mem 11714MB
[2024-07-04 22:03:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:08:17 lr 0.000000	 wd 0.0000	time 0.4277 (0.4511)	loss 1.5488 (1.3348)	grad_norm 4.0959 (inf)	loss_scale 512.0000 (733.0992)	mem 11714MB
[2024-07-04 22:04:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:07:31 lr 0.000000	 wd 0.0000	time 0.4240 (0.4507)	loss 1.3610 (1.3342)	grad_norm 3.6113 (inf)	loss_scale 512.0000 (718.3691)	mem 11714MB
[2024-07-04 22:04:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:06:46 lr 0.000000	 wd 0.0000	time 0.4241 (0.4503)	loss 1.5011 (1.3306)	grad_norm 5.1452 (inf)	loss_scale 512.0000 (705.4791)	mem 11714MB
[2024-07-04 22:05:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:06:00 lr 0.000000	 wd 0.0000	time 0.4262 (0.4499)	loss 1.3968 (1.3286)	grad_norm 3.6549 (inf)	loss_scale 512.0000 (694.1046)	mem 11714MB
[2024-07-04 22:06:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:05:15 lr 0.000000	 wd 0.0000	time 0.4386 (0.4496)	loss 1.3550 (1.3290)	grad_norm 10.9749 (inf)	loss_scale 512.0000 (683.9933)	mem 11714MB
[2024-07-04 22:07:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:04:30 lr 0.000000	 wd 0.0000	time 0.4279 (0.4493)	loss 0.9158 (1.3296)	grad_norm 6.2733 (inf)	loss_scale 512.0000 (674.9458)	mem 11714MB
[2024-07-04 22:07:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:03:45 lr 0.000000	 wd 0.0000	time 0.4260 (0.4491)	loss 0.9014 (1.3287)	grad_norm 5.5981 (inf)	loss_scale 512.0000 (666.8026)	mem 11714MB
[2024-07-04 22:08:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:03:00 lr 0.000000	 wd 0.0000	time 0.4214 (0.4489)	loss 1.4238 (1.3273)	grad_norm 4.2364 (inf)	loss_scale 512.0000 (659.4346)	mem 11714MB
[2024-07-04 22:09:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:02:15 lr 0.000000	 wd 0.0000	time 0.4259 (0.4487)	loss 0.9720 (1.3280)	grad_norm 4.6354 (inf)	loss_scale 512.0000 (652.7360)	mem 11714MB
[2024-07-04 22:10:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:01:30 lr 0.000000	 wd 0.0000	time 0.4280 (0.4485)	loss 1.4339 (1.3276)	grad_norm 3.3153 (inf)	loss_scale 512.0000 (646.6197)	mem 11714MB
[2024-07-04 22:10:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 0.4241 (0.4483)	loss 1.2237 (1.3276)	grad_norm 4.5113 (inf)	loss_scale 512.0000 (641.0129)	mem 11714MB
[2024-07-04 22:11:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000000	 wd 0.0000	time 0.4246 (0.4480)	loss 1.5344 (1.3261)	grad_norm 5.1566 (inf)	loss_scale 512.0000 (635.8545)	mem 11714MB
[2024-07-04 22:11:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 29 training takes 0:18:46
[2024-07-04 22:11:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_29.pth saving......
[2024-07-04 22:11:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_29.pth saved !!!
[2024-07-04 22:11:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 9.896 (9.896)	Loss 0.3982 (0.3982)	Acc@1 92.969 (92.969)	Acc@5 98.438 (98.438)	Mem 11714MB
[2024-07-04 22:12:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.742 Acc@5 97.506
[2024-07-04 22:12:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-04 22:12:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.74%
[2024-07-04 22:12:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saving......
[2024-07-04 22:12:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process2/ckpt_epoch_best.pth saved !!!
[2024-07-04 22:12:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process2] (main.py 189): INFO Training time 8:57:49
