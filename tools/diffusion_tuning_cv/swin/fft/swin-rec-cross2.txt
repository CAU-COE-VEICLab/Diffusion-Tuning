[2024-07-02 22:34:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune/config.json
[2024-07-02 22:34:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    FINETUNE_MODE: part1
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: swin_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    DEPTHS:
    - 3
    - 3
    - 9
    - 3
    DIMS:
    - 96
    - 192
    - 384
    - 768
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 4.0e-05
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: false
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.0e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 4.0e-08
  WEIGHT_DECAY: 1.0e-08

[2024-07-02 22:34:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/swin/diffusion_ft_swin_base_patch4_window7_224_22kto1k_finetune_crosslayer_proces2-fullfinetune.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-02 22:34:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 108): INFO Creating model:swin_diffusion_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune
[2024-07-02 22:34:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 110): INFO SwinTransformer_Diffusion_Finetune(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-02 22:34:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 113): INFO number of params: 87768224
[2024-07-02 22:34:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 116): INFO number of GFLOPs: 15.438473216
[2024-07-02 22:34:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 150): INFO no checkpoint found in pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune, ignoring auto resume
[2024-07-02 22:34:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth for fine-tuning......
[2024-07-02 22:34:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])
[2024-07-02 22:34:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth'
[2024-07-02 22:34:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 18.197 (18.197)	Loss 0.3960 (0.3960)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 1731MB
[2024-07-02 22:35:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 85.070 Acc@5 97.562
[2024-07-02 22:35:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 162): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-02 22:35:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 168): INFO Start training
[2024-07-02 22:35:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][0/2502]	eta 11:22:14 lr 0.000000	 wd 0.0000	time 16.3608 (16.3608)	loss 1.4802 (1.4802)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 11179MB
[2024-07-02 22:35:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:20:30 lr 0.000000	 wd 0.0000	time 0.3098 (0.5123)	loss 1.3372 (1.3257)	grad_norm 4.2312 (nan)	loss_scale 8192.0000 (9570.8515)	mem 12172MB
[2024-07-02 22:36:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:16:19 lr 0.000001	 wd 0.0000	time 0.3313 (0.4253)	loss 1.2376 (1.3089)	grad_norm 4.2885 (nan)	loss_scale 4096.0000 (7743.6816)	mem 12172MB
[2024-07-02 22:37:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:14:32 lr 0.000001	 wd 0.0000	time 0.4602 (0.3961)	loss 1.2345 (1.2923)	grad_norm 6.6895 (nan)	loss_scale 4096.0000 (6531.8272)	mem 12172MB
[2024-07-02 22:37:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:13:26 lr 0.000001	 wd 0.0000	time 0.3272 (0.3835)	loss 1.7878 (1.2947)	grad_norm 5.7237 (nan)	loss_scale 2048.0000 (5720.0998)	mem 12172MB
[2024-07-02 22:38:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:12:30 lr 0.000002	 wd 0.0000	time 0.3066 (0.3749)	loss 1.4957 (1.2947)	grad_norm 5.0948 (nan)	loss_scale 2048.0000 (4987.1457)	mem 12172MB
[2024-07-02 22:38:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:11:40 lr 0.000002	 wd 0.0000	time 0.3075 (0.3684)	loss 0.9023 (1.2983)	grad_norm 3.5267 (nan)	loss_scale 2048.0000 (4498.1032)	mem 12172MB
[2024-07-02 22:39:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:10:58 lr 0.000002	 wd 0.0000	time 0.3242 (0.3656)	loss 1.3686 (1.2967)	grad_norm 3.8915 (nan)	loss_scale 2048.0000 (4148.5877)	mem 12172MB
[2024-07-02 22:39:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:10:16 lr 0.000003	 wd 0.0000	time 0.3119 (0.3625)	loss 1.5295 (1.2967)	grad_norm 14.6298 (nan)	loss_scale 2048.0000 (3886.3421)	mem 12172MB
[2024-07-02 22:40:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:09:36 lr 0.000003	 wd 0.0000	time 0.2962 (0.3598)	loss 1.4922 (1.2921)	grad_norm 3.6763 (nan)	loss_scale 2048.0000 (3682.3085)	mem 12172MB
[2024-07-02 22:41:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:08:58 lr 0.000003	 wd 0.0000	time 0.3251 (0.3588)	loss 1.2840 (1.2914)	grad_norm 3.7686 (nan)	loss_scale 2048.0000 (3519.0410)	mem 12172MB
[2024-07-02 22:41:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:08:21 lr 0.000004	 wd 0.0000	time 0.3079 (0.3574)	loss 1.4421 (1.2921)	grad_norm 4.2384 (nan)	loss_scale 2048.0000 (3385.4314)	mem 12172MB
[2024-07-02 22:42:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:07:44 lr 0.000004	 wd 0.0000	time 0.3366 (0.3565)	loss 1.2566 (1.2951)	grad_norm 3.6689 (nan)	loss_scale 2048.0000 (3274.0716)	mem 12172MB
[2024-07-02 22:42:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:07:07 lr 0.000004	 wd 0.0000	time 0.3314 (0.3559)	loss 1.4425 (1.2968)	grad_norm 4.0722 (nan)	loss_scale 2048.0000 (3179.8309)	mem 12172MB
[2024-07-02 22:43:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:06:31 lr 0.000005	 wd 0.0000	time 0.3022 (0.3550)	loss 1.4909 (1.2973)	grad_norm 5.1283 (nan)	loss_scale 2048.0000 (3099.0435)	mem 12172MB
[2024-07-02 22:43:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:05:55 lr 0.000005	 wd 0.0000	time 0.3195 (0.3543)	loss 1.2673 (1.2967)	grad_norm 5.8407 (nan)	loss_scale 1024.0000 (2992.1812)	mem 12172MB
[2024-07-02 22:44:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:05:18 lr 0.000005	 wd 0.0000	time 0.3184 (0.3534)	loss 1.6564 (1.2973)	grad_norm 25.4942 (nan)	loss_scale 1024.0000 (2869.2467)	mem 12172MB
[2024-07-02 22:45:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:04:42 lr 0.000005	 wd 0.0000	time 0.3164 (0.3527)	loss 1.4903 (1.2967)	grad_norm 3.6935 (nan)	loss_scale 1024.0000 (2760.7666)	mem 12172MB
[2024-07-02 22:45:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:04:08 lr 0.000006	 wd 0.0000	time 0.3100 (0.3538)	loss 1.1273 (1.2967)	grad_norm 4.1047 (nan)	loss_scale 1024.0000 (2664.3331)	mem 12172MB
[2024-07-02 22:46:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:03:32 lr 0.000006	 wd 0.0000	time 0.3167 (0.3530)	loss 1.3348 (1.2957)	grad_norm 3.9103 (nan)	loss_scale 1024.0000 (2578.0452)	mem 12172MB
[2024-07-02 22:46:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:57 lr 0.000006	 wd 0.0000	time 0.3086 (0.3527)	loss 1.4701 (1.2934)	grad_norm 4.2576 (nan)	loss_scale 1024.0000 (2500.3818)	mem 12172MB
[2024-07-02 22:47:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:02:21 lr 0.000007	 wd 0.0000	time 0.3060 (0.3532)	loss 1.2974 (1.2944)	grad_norm 4.9667 (nan)	loss_scale 1024.0000 (2430.1114)	mem 12172MB
[2024-07-02 22:48:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:46 lr 0.000007	 wd 0.0000	time 0.3744 (0.3539)	loss 1.4280 (1.2944)	grad_norm 4.0050 (nan)	loss_scale 1024.0000 (2366.2263)	mem 12172MB
[2024-07-02 22:48:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:01:11 lr 0.000007	 wd 0.0000	time 0.3310 (0.3530)	loss 1.2923 (1.2930)	grad_norm 3.8670 (nan)	loss_scale 1024.0000 (2307.8940)	mem 12172MB
[2024-07-02 22:49:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:35 lr 0.000008	 wd 0.0000	time 0.3308 (0.3529)	loss 1.3799 (1.2932)	grad_norm 5.5640 (nan)	loss_scale 1024.0000 (2254.4207)	mem 12172MB
[2024-07-02 22:49:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.3005 (0.3518)	loss 1.5203 (1.2933)	grad_norm 4.1298 (nan)	loss_scale 1024.0000 (2205.2235)	mem 12172MB
[2024-07-02 22:49:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 0 training takes 0:14:43
[2024-07-02 22:49:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune/ckpt_epoch_0.pth saving......
[2024-07-02 22:49:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune/ckpt_epoch_0.pth saved !!!
[2024-07-02 22:50:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 14.872 (14.872)	Loss 0.3975 (0.3975)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-02 22:50:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 85.020 Acc@5 97.536
[2024-07-02 22:50:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-02 22:50:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-02 22:50:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune/ckpt_epoch_best.pth saving......
[2024-07-02 22:50:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune/ckpt_epoch_best.pth saved !!!
[2024-07-02 22:50:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][0/2502]	eta 12:42:35 lr 0.000008	 wd 0.0000	time 18.2876 (18.2876)	loss 1.1719 (1.1719)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 22:51:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:21:37 lr 0.000008	 wd 0.0000	time 0.3332 (0.5404)	loss 1.1087 (1.3166)	grad_norm 5.7552 (4.9637)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 22:51:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:16:59 lr 0.000009	 wd 0.0000	time 0.2740 (0.4430)	loss 1.3260 (1.3230)	grad_norm 3.7557 (4.8886)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 22:52:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:15:02 lr 0.000009	 wd 0.0000	time 0.3030 (0.4098)	loss 1.6412 (1.3100)	grad_norm 9.2031 (4.8926)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 22:52:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:13:53 lr 0.000009	 wd 0.0000	time 0.3175 (0.3965)	loss 0.8364 (1.2959)	grad_norm 4.7530 (4.8790)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 22:53:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:12:51 lr 0.000010	 wd 0.0000	time 0.3187 (0.3856)	loss 1.5585 (1.2943)	grad_norm 3.7460 (4.9240)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 22:54:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:12:00 lr 0.000010	 wd 0.0000	time 0.3189 (0.3787)	loss 1.2767 (1.2912)	grad_norm 12.9317 (4.9751)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 22:54:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:11:13 lr 0.000010	 wd 0.0000	time 0.3152 (0.3735)	loss 1.3973 (1.2900)	grad_norm 6.3276 (5.0460)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 22:55:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:10:28 lr 0.000011	 wd 0.0000	time 0.3120 (0.3692)	loss 1.4220 (1.2928)	grad_norm 5.3456 (5.0342)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 22:55:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:09:48 lr 0.000011	 wd 0.0000	time 0.3119 (0.3671)	loss 1.4766 (1.2915)	grad_norm 3.8412 (5.1413)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 22:56:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:09:07 lr 0.000011	 wd 0.0000	time 0.3271 (0.3644)	loss 1.3786 (1.2899)	grad_norm 4.6116 (5.1131)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 22:56:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:08:27 lr 0.000012	 wd 0.0000	time 0.3405 (0.3621)	loss 1.0166 (1.2900)	grad_norm 5.6251 (5.0856)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 22:57:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:07:50 lr 0.000012	 wd 0.0000	time 0.3150 (0.3613)	loss 1.3235 (1.2924)	grad_norm 5.1778 (5.0897)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 22:58:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:07:12 lr 0.000012	 wd 0.0000	time 0.3510 (0.3597)	loss 1.4220 (1.2937)	grad_norm 5.1785 (5.1511)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 22:58:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:06:35 lr 0.000012	 wd 0.0000	time 0.3193 (0.3588)	loss 1.4227 (1.2920)	grad_norm 3.3119 (5.1394)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 22:59:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:05:58 lr 0.000013	 wd 0.0000	time 0.2889 (0.3579)	loss 0.8837 (1.2901)	grad_norm 4.5675 (5.1596)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 22:59:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:05:21 lr 0.000013	 wd 0.0000	time 0.3280 (0.3567)	loss 0.8718 (1.2891)	grad_norm 4.9405 (5.1666)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:00:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:04:46 lr 0.000013	 wd 0.0000	time 0.3768 (0.3566)	loss 1.3080 (1.2891)	grad_norm 4.3097 (5.2062)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:01:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:04:10 lr 0.000014	 wd 0.0000	time 0.2935 (0.3562)	loss 1.2408 (1.2884)	grad_norm 2.9472 (5.1836)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:01:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:03:33 lr 0.000014	 wd 0.0000	time 0.2889 (0.3552)	loss 1.3183 (1.2892)	grad_norm 5.3724 (5.1784)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:02:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:58 lr 0.000014	 wd 0.0000	time 0.2943 (0.3552)	loss 1.3727 (1.2889)	grad_norm 6.7078 (5.1906)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:02:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:02:22 lr 0.000015	 wd 0.0000	time 0.3094 (0.3545)	loss 1.4387 (1.2899)	grad_norm 4.9672 (5.2300)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:03:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:46 lr 0.000015	 wd 0.0000	time 1.1502 (0.3542)	loss 1.0350 (1.2904)	grad_norm 4.2040 (5.2140)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:03:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:01:11 lr 0.000015	 wd 0.0000	time 0.3312 (0.3538)	loss 1.3154 (1.2907)	grad_norm 5.8364 (5.2257)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:04:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:36 lr 0.000016	 wd 0.0000	time 0.3590 (0.3534)	loss 1.4345 (1.2891)	grad_norm 3.9735 (5.2037)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:05:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.2981 (0.3528)	loss 1.0514 (1.2904)	grad_norm 3.9320 (5.1897)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:05:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 1 training takes 0:14:46
[2024-07-02 23:05:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 20.088 (20.088)	Loss 0.4070 (0.4070)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-02 23:05:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.934 Acc@5 97.560
[2024-07-02 23:05:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-02 23:05:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-02 23:05:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][0/2502]	eta 11:21:14 lr 0.000016	 wd 0.0000	time 16.3368 (16.3368)	loss 1.3807 (1.3807)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:06:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:20:31 lr 0.000016	 wd 0.0000	time 0.3155 (0.5127)	loss 1.3561 (1.2650)	grad_norm 4.5401 (5.3640)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:07:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:16:22 lr 0.000017	 wd 0.0000	time 0.3084 (0.4269)	loss 1.4117 (1.2825)	grad_norm 3.8034 (5.4863)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:07:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:14:36 lr 0.000017	 wd 0.0000	time 0.3028 (0.3981)	loss 1.0927 (1.2855)	grad_norm 7.8637 (5.5409)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:08:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:13:24 lr 0.000017	 wd 0.0000	time 0.3370 (0.3827)	loss 1.4151 (1.2814)	grad_norm 5.2292 (5.3350)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:08:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:12:29 lr 0.000018	 wd 0.0000	time 0.3273 (0.3742)	loss 1.3471 (1.2842)	grad_norm 5.8556 (inf)	loss_scale 1024.0000 (1073.0539)	mem 12172MB
[2024-07-02 23:09:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:11:42 lr 0.000018	 wd 0.0000	time 0.3435 (0.3692)	loss 1.1720 (1.2782)	grad_norm 7.6673 (inf)	loss_scale 1024.0000 (1064.8918)	mem 12172MB
[2024-07-02 23:09:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:10:59 lr 0.000018	 wd 0.0000	time 0.3014 (0.3662)	loss 1.1655 (1.2814)	grad_norm 4.0414 (inf)	loss_scale 1024.0000 (1059.0585)	mem 12172MB
[2024-07-02 23:10:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:10:19 lr 0.000019	 wd 0.0000	time 0.3385 (0.3641)	loss 1.4296 (1.2797)	grad_norm 4.1062 (inf)	loss_scale 1024.0000 (1054.6816)	mem 12172MB
[2024-07-02 23:11:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:09:38 lr 0.000019	 wd 0.0000	time 0.3692 (0.3614)	loss 1.3934 (1.2849)	grad_norm 8.8068 (inf)	loss_scale 1024.0000 (1051.2764)	mem 12172MB
[2024-07-02 23:11:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:08:59 lr 0.000019	 wd 0.0000	time 0.3520 (0.3593)	loss 1.3784 (1.2863)	grad_norm 3.8005 (inf)	loss_scale 1024.0000 (1048.5514)	mem 12172MB
[2024-07-02 23:12:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:08:23 lr 0.000020	 wd 0.0000	time 0.3132 (0.3591)	loss 1.1177 (1.2875)	grad_norm 7.3511 (inf)	loss_scale 1024.0000 (1046.3215)	mem 12172MB
[2024-07-02 23:12:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:07:47 lr 0.000020	 wd 0.0000	time 0.3045 (0.3590)	loss 1.2172 (1.2867)	grad_norm 3.9972 (inf)	loss_scale 1024.0000 (1044.4629)	mem 12172MB
[2024-07-02 23:13:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:07:09 lr 0.000020	 wd 0.0000	time 0.3348 (0.3574)	loss 1.5604 (1.2890)	grad_norm 4.6436 (inf)	loss_scale 1024.0000 (1042.8901)	mem 12172MB
[2024-07-02 23:13:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:06:34 lr 0.000020	 wd 0.0000	time 0.2867 (0.3577)	loss 1.2989 (1.2894)	grad_norm 6.9354 (inf)	loss_scale 1024.0000 (1041.5418)	mem 12172MB
[2024-07-02 23:14:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:05:57 lr 0.000021	 wd 0.0000	time 0.3250 (0.3564)	loss 1.4640 (1.2878)	grad_norm 3.4070 (inf)	loss_scale 1024.0000 (1040.3731)	mem 12172MB
[2024-07-02 23:15:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:05:21 lr 0.000021	 wd 0.0000	time 0.2876 (0.3568)	loss 1.1714 (1.2877)	grad_norm 4.6184 (inf)	loss_scale 1024.0000 (1039.3504)	mem 12172MB
[2024-07-02 23:15:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:04:45 lr 0.000021	 wd 0.0000	time 0.3199 (0.3562)	loss 1.2201 (1.2867)	grad_norm 5.2686 (inf)	loss_scale 1024.0000 (1038.4480)	mem 12172MB
[2024-07-02 23:16:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:04:09 lr 0.000022	 wd 0.0000	time 0.3166 (0.3554)	loss 1.2219 (1.2865)	grad_norm 6.2532 (inf)	loss_scale 1024.0000 (1037.6458)	mem 12172MB
[2024-07-02 23:16:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:03:34 lr 0.000022	 wd 0.0000	time 0.3198 (0.3558)	loss 0.8948 (1.2847)	grad_norm 4.0499 (inf)	loss_scale 1024.0000 (1036.9279)	mem 12172MB
[2024-07-02 23:17:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:02:58 lr 0.000022	 wd 0.0000	time 0.3242 (0.3565)	loss 1.0827 (1.2825)	grad_norm 5.9662 (inf)	loss_scale 1024.0000 (1036.2819)	mem 12172MB
[2024-07-02 23:18:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:02:22 lr 0.000023	 wd 0.0000	time 0.3354 (0.3556)	loss 1.3577 (1.2829)	grad_norm 13.7875 (inf)	loss_scale 1024.0000 (1035.6973)	mem 12172MB
[2024-07-02 23:18:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:47 lr 0.000023	 wd 0.0000	time 0.3542 (0.3554)	loss 1.4786 (1.2825)	grad_norm 4.3370 (inf)	loss_scale 1024.0000 (1035.1658)	mem 12172MB
[2024-07-02 23:19:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:01:11 lr 0.000023	 wd 0.0000	time 0.3444 (0.3548)	loss 1.5517 (1.2825)	grad_norm 5.3301 (inf)	loss_scale 1024.0000 (1034.6806)	mem 12172MB
[2024-07-02 23:19:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:36 lr 0.000024	 wd 0.0000	time 0.3102 (0.3540)	loss 1.3687 (1.2817)	grad_norm 3.4650 (inf)	loss_scale 1024.0000 (1034.2357)	mem 12172MB
[2024-07-02 23:20:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.2946 (0.3533)	loss 1.4303 (1.2817)	grad_norm 3.8151 (inf)	loss_scale 1024.0000 (1033.8265)	mem 12172MB
[2024-07-02 23:20:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 2 training takes 0:14:53
[2024-07-02 23:20:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 17.206 (17.206)	Loss 0.4009 (0.4009)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-02 23:20:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.882 Acc@5 97.518
[2024-07-02 23:20:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-02 23:20:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-02 23:21:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][0/2502]	eta 10:48:59 lr 0.000024	 wd 0.0000	time 15.5633 (15.5633)	loss 0.9261 (0.9261)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:21:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:20:57 lr 0.000024	 wd 0.0000	time 0.3537 (0.5234)	loss 1.3976 (1.2514)	grad_norm 4.1413 (4.8195)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:22:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:16:41 lr 0.000025	 wd 0.0000	time 1.0547 (0.4350)	loss 1.3048 (1.2682)	grad_norm 7.7030 (5.1239)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:22:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:14:48 lr 0.000025	 wd 0.0000	time 0.3297 (0.4036)	loss 1.4607 (1.2635)	grad_norm 3.9564 (5.2092)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:23:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:13:36 lr 0.000025	 wd 0.0000	time 0.3376 (0.3887)	loss 1.4495 (1.2671)	grad_norm 3.4735 (5.1636)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:24:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:12:38 lr 0.000026	 wd 0.0000	time 0.3234 (0.3788)	loss 1.3537 (1.2667)	grad_norm 5.8116 (5.2868)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:24:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:11:47 lr 0.000026	 wd 0.0000	time 0.2969 (0.3720)	loss 1.2819 (1.2677)	grad_norm 4.8792 (5.2015)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:25:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:11:11 lr 0.000026	 wd 0.0000	time 0.3411 (0.3727)	loss 1.5395 (1.2693)	grad_norm 6.5695 (5.2769)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:25:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:10:27 lr 0.000027	 wd 0.0000	time 0.3598 (0.3689)	loss 0.9947 (1.2695)	grad_norm 5.6017 (5.3338)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:26:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:09:45 lr 0.000027	 wd 0.0000	time 0.2903 (0.3654)	loss 1.3951 (1.2706)	grad_norm 4.3212 (5.3054)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:27:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:09:10 lr 0.000027	 wd 0.0000	time 0.3320 (0.3668)	loss 1.4010 (1.2730)	grad_norm 3.6783 (inf)	loss_scale 512.0000 (1016.8392)	mem 12172MB
[2024-07-02 23:27:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:08:33 lr 0.000028	 wd 0.0000	time 0.3204 (0.3661)	loss 1.2890 (1.2751)	grad_norm 3.3894 (inf)	loss_scale 512.0000 (970.9864)	mem 12172MB
[2024-07-02 23:28:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:07:54 lr 0.000028	 wd 0.0000	time 0.3360 (0.3641)	loss 1.1664 (1.2732)	grad_norm 3.4755 (inf)	loss_scale 512.0000 (932.7694)	mem 12172MB
[2024-07-02 23:28:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:07:16 lr 0.000028	 wd 0.0000	time 0.3487 (0.3630)	loss 1.2215 (1.2756)	grad_norm 4.3933 (inf)	loss_scale 512.0000 (900.4274)	mem 12172MB
[2024-07-02 23:29:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:06:38 lr 0.000028	 wd 0.0000	time 0.2970 (0.3614)	loss 1.1920 (1.2758)	grad_norm 5.6725 (inf)	loss_scale 512.0000 (872.7024)	mem 12172MB
[2024-07-02 23:29:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:06:01 lr 0.000029	 wd 0.0000	time 0.3639 (0.3607)	loss 1.3921 (1.2775)	grad_norm 6.8099 (inf)	loss_scale 512.0000 (848.6716)	mem 12172MB
[2024-07-02 23:30:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:05:24 lr 0.000029	 wd 0.0000	time 0.3167 (0.3600)	loss 1.3937 (1.2763)	grad_norm 3.4661 (inf)	loss_scale 512.0000 (827.6427)	mem 12172MB
[2024-07-02 23:31:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:04:47 lr 0.000029	 wd 0.0000	time 0.3183 (0.3587)	loss 1.0689 (1.2754)	grad_norm 5.3297 (inf)	loss_scale 512.0000 (809.0864)	mem 12172MB
[2024-07-02 23:31:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:04:12 lr 0.000030	 wd 0.0000	time 0.3151 (0.3597)	loss 1.3847 (1.2758)	grad_norm 4.3088 (inf)	loss_scale 512.0000 (792.5908)	mem 12172MB
[2024-07-02 23:32:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:03:35 lr 0.000030	 wd 0.0000	time 0.3520 (0.3587)	loss 1.3428 (1.2750)	grad_norm 4.4672 (inf)	loss_scale 512.0000 (777.8306)	mem 12172MB
[2024-07-02 23:32:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:59 lr 0.000030	 wd 0.0000	time 0.3057 (0.3577)	loss 1.1120 (1.2755)	grad_norm 4.8211 (inf)	loss_scale 512.0000 (764.5457)	mem 12172MB
[2024-07-02 23:33:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:02:23 lr 0.000031	 wd 0.0000	time 0.3338 (0.3571)	loss 1.0704 (1.2745)	grad_norm 3.6897 (inf)	loss_scale 512.0000 (752.5255)	mem 12172MB
[2024-07-02 23:34:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:47 lr 0.000031	 wd 0.0000	time 0.3091 (0.3565)	loss 1.2802 (1.2753)	grad_norm 4.3014 (inf)	loss_scale 512.0000 (741.5975)	mem 12172MB
[2024-07-02 23:34:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:01:11 lr 0.000031	 wd 0.0000	time 0.3098 (0.3560)	loss 1.4071 (1.2761)	grad_norm 4.1891 (inf)	loss_scale 512.0000 (731.6193)	mem 12172MB
[2024-07-02 23:35:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:36 lr 0.000032	 wd 0.0000	time 0.2983 (0.3555)	loss 0.9765 (1.2753)	grad_norm 4.7435 (inf)	loss_scale 512.0000 (722.4723)	mem 12172MB
[2024-07-02 23:35:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000032	 wd 0.0000	time 0.3194 (0.3544)	loss 1.3529 (1.2758)	grad_norm 4.1773 (inf)	loss_scale 512.0000 (714.0568)	mem 12172MB
[2024-07-02 23:35:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 3 training takes 0:14:50
[2024-07-02 23:36:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 18.345 (18.345)	Loss 0.4021 (0.4021)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 12172MB
[2024-07-02 23:36:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.890 Acc@5 97.520
[2024-07-02 23:36:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-02 23:36:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-02 23:36:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][0/2502]	eta 13:57:05 lr 0.000032	 wd 0.0000	time 20.0740 (20.0740)	loss 1.3230 (1.3230)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:37:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:21:42 lr 0.000032	 wd 0.0000	time 0.3346 (0.5424)	loss 1.1422 (1.3061)	grad_norm 5.1622 (5.1830)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:37:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:17:03 lr 0.000033	 wd 0.0000	time 0.3462 (0.4445)	loss 1.1117 (1.2938)	grad_norm 3.9337 (5.0001)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:38:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:15:12 lr 0.000033	 wd 0.0000	time 0.3273 (0.4142)	loss 1.0505 (1.2933)	grad_norm 7.7220 (5.0175)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:38:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:13:51 lr 0.000033	 wd 0.0000	time 0.3137 (0.3956)	loss 1.2932 (1.2830)	grad_norm 3.8833 (4.9225)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:39:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:12:49 lr 0.000034	 wd 0.0000	time 0.3169 (0.3846)	loss 1.3037 (1.2782)	grad_norm 4.0408 (5.0179)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:40:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:11:59 lr 0.000034	 wd 0.0000	time 0.3140 (0.3785)	loss 1.3272 (1.2725)	grad_norm 4.6424 (5.0343)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:40:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:11:12 lr 0.000034	 wd 0.0000	time 0.3022 (0.3733)	loss 1.1785 (1.2728)	grad_norm 4.0752 (4.9835)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:41:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:10:27 lr 0.000035	 wd 0.0000	time 0.2924 (0.3688)	loss 1.2139 (1.2734)	grad_norm 2.9334 (4.9491)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:41:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:09:49 lr 0.000035	 wd 0.0000	time 0.3152 (0.3681)	loss 1.3606 (1.2739)	grad_norm 4.8065 (5.0520)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:42:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:09:09 lr 0.000035	 wd 0.0000	time 0.3370 (0.3655)	loss 1.4202 (1.2744)	grad_norm 5.5966 (5.1588)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:42:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:08:28 lr 0.000036	 wd 0.0000	time 0.3145 (0.3629)	loss 1.4608 (1.2750)	grad_norm 4.0784 (5.1801)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:43:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:07:52 lr 0.000036	 wd 0.0000	time 0.2959 (0.3625)	loss 0.9394 (1.2741)	grad_norm 14.3619 (5.2077)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:44:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:07:13 lr 0.000036	 wd 0.0000	time 0.3208 (0.3609)	loss 1.4690 (1.2732)	grad_norm 5.2845 (5.2295)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:44:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:06:36 lr 0.000036	 wd 0.0000	time 0.3103 (0.3600)	loss 1.3705 (1.2733)	grad_norm 9.5166 (5.2149)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:45:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:06:00 lr 0.000037	 wd 0.0000	time 0.3376 (0.3593)	loss 1.2373 (1.2762)	grad_norm 4.0334 (5.1995)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:45:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:05:23 lr 0.000037	 wd 0.0000	time 0.3378 (0.3588)	loss 1.1059 (1.2754)	grad_norm 4.9704 (5.2241)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:46:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:04:47 lr 0.000037	 wd 0.0000	time 0.3164 (0.3589)	loss 1.4408 (1.2750)	grad_norm 6.2408 (5.2349)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:47:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:04:11 lr 0.000038	 wd 0.0000	time 0.3325 (0.3581)	loss 1.4751 (1.2747)	grad_norm 3.6447 (5.2412)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:47:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:03:34 lr 0.000038	 wd 0.0000	time 0.3026 (0.3571)	loss 1.4051 (1.2744)	grad_norm 6.2743 (5.2215)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:48:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:02:59 lr 0.000038	 wd 0.0000	time 0.3034 (0.3573)	loss 1.4673 (1.2746)	grad_norm 8.8688 (5.2345)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:48:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:02:23 lr 0.000039	 wd 0.0000	time 0.3295 (0.3565)	loss 1.3023 (1.2746)	grad_norm 4.6316 (5.2317)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:49:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:47 lr 0.000039	 wd 0.0000	time 0.3000 (0.3555)	loss 0.9258 (1.2720)	grad_norm 4.4336 (5.2060)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:49:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:01:11 lr 0.000039	 wd 0.0000	time 0.3267 (0.3551)	loss 1.1760 (1.2728)	grad_norm 4.5701 (5.1933)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:50:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:36 lr 0.000040	 wd 0.0000	time 0.3235 (0.3544)	loss 1.3478 (1.2726)	grad_norm 3.3508 (5.1716)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-02 23:51:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.3257 (0.3536)	loss 0.8108 (1.2721)	grad_norm 4.1457 (5.1997)	loss_scale 1024.0000 (515.2755)	mem 12172MB
[2024-07-02 23:51:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 4 training takes 0:14:48
[2024-07-02 23:51:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 18.816 (18.816)	Loss 0.4019 (0.4019)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 12172MB
[2024-07-02 23:51:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.812 Acc@5 97.432
[2024-07-02 23:51:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-02 23:51:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-02 23:51:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][0/2502]	eta 10:59:44 lr 0.000040	 wd 0.0000	time 15.8213 (15.8213)	loss 1.4669 (1.4669)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:52:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:19:54 lr 0.000040	 wd 0.0000	time 0.3353 (0.4974)	loss 1.2356 (1.2849)	grad_norm 5.7392 (6.2722)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:52:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:16:11 lr 0.000040	 wd 0.0000	time 0.3233 (0.4219)	loss 1.3454 (1.2998)	grad_norm 4.2745 (5.4416)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:53:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:14:31 lr 0.000040	 wd 0.0000	time 0.3210 (0.3959)	loss 1.5244 (1.2867)	grad_norm 5.1008 (5.1588)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:54:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:13:29 lr 0.000040	 wd 0.0000	time 0.3239 (0.3850)	loss 1.0611 (1.2876)	grad_norm 3.7372 (5.1112)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:54:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:12:33 lr 0.000040	 wd 0.0000	time 0.3106 (0.3762)	loss 1.5697 (1.2835)	grad_norm 3.3036 (5.2100)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:55:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:11:46 lr 0.000040	 wd 0.0000	time 0.3303 (0.3714)	loss 1.4262 (1.2859)	grad_norm 3.7332 (5.3349)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:55:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:11:01 lr 0.000040	 wd 0.0000	time 0.3110 (0.3669)	loss 1.3897 (1.2836)	grad_norm 5.1598 (5.3025)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:56:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:10:21 lr 0.000040	 wd 0.0000	time 0.3613 (0.3654)	loss 1.0214 (1.2773)	grad_norm 4.0206 (5.2881)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:57:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:09:41 lr 0.000040	 wd 0.0000	time 0.3128 (0.3630)	loss 0.7700 (1.2763)	grad_norm 3.5683 (5.2574)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:57:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:09:01 lr 0.000040	 wd 0.0000	time 0.3300 (0.3607)	loss 1.2744 (1.2787)	grad_norm 3.4910 (5.2458)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:58:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:08:24 lr 0.000040	 wd 0.0000	time 0.3241 (0.3599)	loss 1.4484 (1.2746)	grad_norm 5.3840 (5.1877)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:58:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:07:47 lr 0.000040	 wd 0.0000	time 0.3226 (0.3591)	loss 1.3809 (1.2740)	grad_norm 4.4434 (5.1247)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:59:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:07:09 lr 0.000040	 wd 0.0000	time 0.3052 (0.3574)	loss 1.3746 (1.2739)	grad_norm 3.6198 (5.1430)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-02 23:59:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:06:33 lr 0.000040	 wd 0.0000	time 0.3094 (0.3568)	loss 1.3444 (1.2737)	grad_norm 3.6666 (5.1225)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:00:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:05:56 lr 0.000040	 wd 0.0000	time 0.3284 (0.3561)	loss 1.2439 (1.2737)	grad_norm 3.8071 (5.0884)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:01:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:05:20 lr 0.000040	 wd 0.0000	time 0.3335 (0.3552)	loss 1.3951 (1.2750)	grad_norm 6.3583 (5.0957)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:01:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:04:44 lr 0.000040	 wd 0.0000	time 0.3236 (0.3548)	loss 1.3390 (1.2752)	grad_norm 3.0146 (5.0643)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:02:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:04:08 lr 0.000040	 wd 0.0000	time 0.3085 (0.3543)	loss 0.9684 (1.2743)	grad_norm 4.5272 (5.0646)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:02:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:03:33 lr 0.000040	 wd 0.0000	time 0.3191 (0.3540)	loss 1.3955 (1.2763)	grad_norm 4.1999 (5.0427)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:03:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:02:57 lr 0.000040	 wd 0.0000	time 0.3072 (0.3538)	loss 1.3161 (1.2777)	grad_norm 3.2834 (5.0503)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:03:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:02:21 lr 0.000040	 wd 0.0000	time 0.3124 (0.3531)	loss 1.4501 (1.2788)	grad_norm 4.3739 (5.0544)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:04:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:46 lr 0.000040	 wd 0.0000	time 0.3324 (0.3526)	loss 1.2592 (1.2766)	grad_norm 4.3246 (5.0531)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:05:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:01:11 lr 0.000040	 wd 0.0000	time 0.2981 (0.3520)	loss 0.8742 (1.2763)	grad_norm 8.7638 (5.0546)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:05:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:35 lr 0.000040	 wd 0.0000	time 0.3204 (0.3513)	loss 1.5551 (1.2765)	grad_norm 3.9706 (5.0402)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:06:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.2939 (0.3504)	loss 1.3554 (1.2763)	grad_norm 4.4802 (5.0427)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:06:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 5 training takes 0:14:48
[2024-07-03 00:06:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 17.148 (17.148)	Loss 0.4192 (0.4192)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 12172MB
[2024-07-03 00:06:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.712 Acc@5 97.486
[2024-07-03 00:06:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-03 00:06:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-03 00:07:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][0/2502]	eta 10:42:39 lr 0.000040	 wd 0.0000	time 15.4113 (15.4113)	loss 1.6528 (1.6528)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:07:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:20:13 lr 0.000040	 wd 0.0000	time 0.3126 (0.5051)	loss 1.1624 (1.2624)	grad_norm 4.4893 (4.7269)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:08:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:16:13 lr 0.000040	 wd 0.0000	time 0.3420 (0.4229)	loss 1.3626 (1.2784)	grad_norm 4.9385 (4.9896)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:08:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:14:27 lr 0.000040	 wd 0.0000	time 0.3326 (0.3942)	loss 1.4756 (1.2833)	grad_norm 4.7963 (4.9378)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:09:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:13:17 lr 0.000040	 wd 0.0000	time 0.3030 (0.3795)	loss 1.3422 (1.2761)	grad_norm 4.3809 (4.8314)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:09:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:12:24 lr 0.000040	 wd 0.0000	time 0.3136 (0.3717)	loss 1.3696 (1.2731)	grad_norm 9.0967 (4.8485)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:10:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:11:36 lr 0.000040	 wd 0.0000	time 0.3301 (0.3664)	loss 1.4615 (1.2749)	grad_norm 5.6044 (4.9328)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:11:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:11:01 lr 0.000040	 wd 0.0000	time 0.3007 (0.3669)	loss 1.2998 (1.2755)	grad_norm 10.1968 (4.9152)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:11:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:10:19 lr 0.000040	 wd 0.0000	time 0.2989 (0.3640)	loss 1.0630 (1.2752)	grad_norm 4.7624 (4.9457)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:12:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:09:39 lr 0.000040	 wd 0.0000	time 0.3181 (0.3617)	loss 1.4582 (1.2768)	grad_norm 3.6434 (4.9379)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:12:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:09:04 lr 0.000040	 wd 0.0000	time 0.3240 (0.3623)	loss 1.2385 (1.2734)	grad_norm 4.3269 (4.9448)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:13:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:08:27 lr 0.000040	 wd 0.0000	time 0.3786 (0.3622)	loss 1.2102 (1.2715)	grad_norm 4.3702 (4.9411)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:14:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:07:49 lr 0.000040	 wd 0.0000	time 0.3207 (0.3603)	loss 1.0429 (1.2727)	grad_norm 5.6505 (4.9606)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:14:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:07:12 lr 0.000040	 wd 0.0000	time 0.3525 (0.3600)	loss 1.4230 (1.2720)	grad_norm 3.8209 (4.9809)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:15:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:06:35 lr 0.000040	 wd 0.0000	time 0.3054 (0.3589)	loss 1.6479 (1.2702)	grad_norm 5.3626 (5.0171)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:15:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:05:58 lr 0.000040	 wd 0.0000	time 0.3442 (0.3574)	loss 1.3557 (1.2726)	grad_norm 3.4621 (5.0131)	loss_scale 2048.0000 (1037.6442)	mem 12172MB
[2024-07-03 00:16:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:05:22 lr 0.000040	 wd 0.0000	time 0.3303 (0.3571)	loss 1.3722 (1.2712)	grad_norm 6.4485 (5.0250)	loss_scale 2048.0000 (1100.7520)	mem 12172MB
[2024-07-03 00:16:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:04:45 lr 0.000040	 wd 0.0000	time 0.3701 (0.3561)	loss 1.5082 (1.2711)	grad_norm 3.6003 (5.0204)	loss_scale 2048.0000 (1156.4397)	mem 12172MB
[2024-07-03 00:17:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:04:09 lr 0.000040	 wd 0.0000	time 0.3419 (0.3557)	loss 1.0323 (1.2712)	grad_norm 4.0916 (5.0247)	loss_scale 2048.0000 (1205.9434)	mem 12172MB
[2024-07-03 00:18:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:03:33 lr 0.000040	 wd 0.0000	time 0.3327 (0.3549)	loss 1.1529 (1.2713)	grad_norm 5.3403 (5.0274)	loss_scale 2048.0000 (1250.2388)	mem 12172MB
[2024-07-03 00:18:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:02:57 lr 0.000039	 wd 0.0000	time 0.3085 (0.3539)	loss 0.9927 (1.2717)	grad_norm 4.5937 (nan)	loss_scale 1024.0000 (1277.8251)	mem 12172MB
[2024-07-03 00:19:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:02:22 lr 0.000039	 wd 0.0000	time 0.3346 (0.3536)	loss 1.4059 (1.2711)	grad_norm 5.1048 (nan)	loss_scale 1024.0000 (1265.7439)	mem 12172MB
[2024-07-03 00:19:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:46 lr 0.000039	 wd 0.0000	time 0.3105 (0.3532)	loss 1.1704 (1.2711)	grad_norm 3.1587 (nan)	loss_scale 1024.0000 (1254.7606)	mem 12172MB
[2024-07-03 00:20:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:01:11 lr 0.000039	 wd 0.0000	time 0.3113 (0.3525)	loss 1.3987 (1.2717)	grad_norm 5.7064 (nan)	loss_scale 1024.0000 (1244.7319)	mem 12172MB
[2024-07-03 00:20:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:35 lr 0.000039	 wd 0.0000	time 0.3065 (0.3520)	loss 1.0641 (1.2713)	grad_norm 11.8251 (nan)	loss_scale 1024.0000 (1235.5385)	mem 12172MB
[2024-07-03 00:21:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.3023 (0.3516)	loss 0.9148 (1.2717)	grad_norm 3.7929 (nan)	loss_scale 1024.0000 (1227.0804)	mem 12172MB
[2024-07-03 00:21:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 6 training takes 0:14:44
[2024-07-03 00:21:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 17.253 (17.253)	Loss 0.4231 (0.4231)	Acc@1 91.797 (91.797)	Acc@5 98.438 (98.438)	Mem 12172MB
[2024-07-03 00:22:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.682 Acc@5 97.384
[2024-07-03 00:22:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-03 00:22:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-03 00:22:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][0/2502]	eta 11:11:49 lr 0.000039	 wd 0.0000	time 16.1110 (16.1110)	loss 1.5857 (1.5857)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:22:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:20:50 lr 0.000039	 wd 0.0000	time 0.2987 (0.5204)	loss 1.3084 (1.2893)	grad_norm 4.7693 (5.4150)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:23:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:16:31 lr 0.000039	 wd 0.0000	time 0.3079 (0.4308)	loss 1.4544 (1.2673)	grad_norm 5.7850 (5.1843)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:24:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:15:02 lr 0.000039	 wd 0.0000	time 0.3269 (0.4099)	loss 1.2321 (1.2657)	grad_norm 4.4822 (5.1273)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:24:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:13:47 lr 0.000039	 wd 0.0000	time 0.3005 (0.3935)	loss 1.3571 (1.2676)	grad_norm 5.6040 (5.2220)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:25:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:12:50 lr 0.000039	 wd 0.0000	time 0.3125 (0.3850)	loss 1.4131 (1.2636)	grad_norm 4.2237 (5.2632)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:25:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:12:07 lr 0.000039	 wd 0.0000	time 0.3291 (0.3827)	loss 1.2949 (1.2676)	grad_norm 4.8793 (5.1320)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:26:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:11:20 lr 0.000039	 wd 0.0000	time 0.3114 (0.3774)	loss 1.2981 (1.2705)	grad_norm 3.4505 (5.0810)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:27:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:10:35 lr 0.000039	 wd 0.0000	time 0.3229 (0.3737)	loss 0.9618 (1.2727)	grad_norm 4.3592 (5.1903)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:27:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:09:56 lr 0.000039	 wd 0.0000	time 0.3456 (0.3723)	loss 1.1177 (1.2750)	grad_norm 5.0246 (5.2064)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:28:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:09:15 lr 0.000039	 wd 0.0000	time 0.3057 (0.3695)	loss 1.2028 (1.2722)	grad_norm 3.7645 (5.1849)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:28:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:08:34 lr 0.000039	 wd 0.0000	time 0.3243 (0.3669)	loss 1.2857 (1.2706)	grad_norm 3.2960 (5.1864)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:29:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:07:56 lr 0.000039	 wd 0.0000	time 0.3354 (0.3663)	loss 1.2387 (1.2682)	grad_norm 6.0814 (5.1856)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:29:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:07:18 lr 0.000039	 wd 0.0000	time 0.3180 (0.3650)	loss 1.3184 (1.2693)	grad_norm 4.1129 (5.1978)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:30:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:06:40 lr 0.000039	 wd 0.0000	time 0.3362 (0.3633)	loss 1.4488 (1.2699)	grad_norm 5.4787 (5.1742)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:31:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:06:03 lr 0.000039	 wd 0.0000	time 0.3036 (0.3632)	loss 1.3677 (1.2689)	grad_norm 6.0832 (5.1880)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:31:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:05:26 lr 0.000039	 wd 0.0000	time 0.3137 (0.3621)	loss 1.4064 (1.2704)	grad_norm 8.6978 (5.1689)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:32:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:04:49 lr 0.000039	 wd 0.0000	time 0.2844 (0.3609)	loss 1.4798 (1.2708)	grad_norm 5.4785 (5.1670)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:32:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:04:13 lr 0.000039	 wd 0.0000	time 0.3224 (0.3616)	loss 1.2522 (1.2706)	grad_norm 6.6273 (5.1831)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:33:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:03:37 lr 0.000039	 wd 0.0000	time 0.3404 (0.3610)	loss 1.2384 (1.2699)	grad_norm 6.3265 (5.2554)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:34:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:03:00 lr 0.000039	 wd 0.0000	time 0.3163 (0.3600)	loss 1.3780 (1.2706)	grad_norm 3.1005 (5.2537)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:34:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:02:24 lr 0.000039	 wd 0.0000	time 0.3292 (0.3594)	loss 1.5401 (1.2723)	grad_norm 6.8660 (5.2558)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:35:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:48 lr 0.000039	 wd 0.0000	time 0.3310 (0.3584)	loss 1.1931 (1.2708)	grad_norm 4.3305 (5.2524)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:35:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:01:12 lr 0.000039	 wd 0.0000	time 0.3177 (0.3579)	loss 1.4197 (1.2713)	grad_norm 4.1909 (5.2388)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:36:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:36 lr 0.000039	 wd 0.0000	time 0.3356 (0.3573)	loss 1.3234 (1.2713)	grad_norm 8.9587 (5.2334)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:36:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.3007 (0.3563)	loss 1.1960 (1.2715)	grad_norm 4.6652 (5.2203)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:36:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 7 training takes 0:14:54
[2024-07-03 00:37:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 22.602 (22.602)	Loss 0.4143 (0.4143)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 12172MB
[2024-07-03 00:37:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.742 Acc@5 97.454
[2024-07-03 00:37:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-03 00:37:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-03 00:37:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][0/2502]	eta 10:56:25 lr 0.000039	 wd 0.0000	time 15.7416 (15.7416)	loss 1.4136 (1.4136)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:38:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:19:52 lr 0.000039	 wd 0.0000	time 0.3126 (0.4966)	loss 1.4062 (1.2971)	grad_norm 12.8441 (5.4040)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:38:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:16:28 lr 0.000039	 wd 0.0000	time 0.3086 (0.4293)	loss 1.2854 (1.2714)	grad_norm 3.8161 (5.1014)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:39:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:14:44 lr 0.000038	 wd 0.0000	time 0.3267 (0.4019)	loss 1.2611 (1.2670)	grad_norm 19.0372 (5.3284)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:40:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:13:32 lr 0.000038	 wd 0.0000	time 0.3117 (0.3867)	loss 1.3519 (1.2647)	grad_norm 5.1433 (5.1791)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:40:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:12:36 lr 0.000038	 wd 0.0000	time 0.3252 (0.3779)	loss 1.4435 (1.2715)	grad_norm 3.9844 (5.2397)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:41:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:11:51 lr 0.000038	 wd 0.0000	time 0.3040 (0.3740)	loss 1.4661 (1.2753)	grad_norm 4.9345 (5.1420)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:41:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:11:07 lr 0.000038	 wd 0.0000	time 0.3001 (0.3704)	loss 1.4451 (1.2754)	grad_norm 5.0318 (5.0734)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:42:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:10:27 lr 0.000038	 wd 0.0000	time 0.3216 (0.3686)	loss 1.3490 (1.2749)	grad_norm 3.8254 (5.0677)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:43:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:09:48 lr 0.000038	 wd 0.0000	time 0.3399 (0.3677)	loss 1.4318 (1.2754)	grad_norm 3.5124 (5.0081)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:43:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:09:07 lr 0.000038	 wd 0.0000	time 0.3619 (0.3648)	loss 1.3379 (1.2735)	grad_norm 3.2923 (5.0007)	loss_scale 2048.0000 (1052.6434)	mem 12172MB
[2024-07-03 00:44:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:08:32 lr 0.000038	 wd 0.0000	time 0.3411 (0.3656)	loss 1.4080 (1.2704)	grad_norm 5.3672 (5.0074)	loss_scale 2048.0000 (1143.0481)	mem 12172MB
[2024-07-03 00:44:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:07:56 lr 0.000038	 wd 0.0000	time 0.3256 (0.3656)	loss 1.3566 (1.2699)	grad_norm 5.4965 (inf)	loss_scale 1024.0000 (1213.2823)	mem 12172MB
[2024-07-03 00:45:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:07:18 lr 0.000038	 wd 0.0000	time 0.4295 (0.3652)	loss 1.0089 (1.2682)	grad_norm 4.0426 (inf)	loss_scale 1024.0000 (1198.7333)	mem 12172MB
[2024-07-03 00:46:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:06:43 lr 0.000038	 wd 0.0000	time 0.2965 (0.3659)	loss 0.8641 (1.2696)	grad_norm 5.8193 (inf)	loss_scale 1024.0000 (1186.2612)	mem 12172MB
[2024-07-03 00:46:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:06:04 lr 0.000038	 wd 0.0000	time 0.3199 (0.3641)	loss 0.9002 (1.2666)	grad_norm 4.8706 (inf)	loss_scale 1024.0000 (1175.4510)	mem 12172MB
[2024-07-03 00:47:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:05:28 lr 0.000038	 wd 0.0000	time 0.2823 (0.3640)	loss 1.1941 (1.2639)	grad_norm 6.5049 (inf)	loss_scale 1024.0000 (1165.9913)	mem 12172MB
[2024-07-03 00:47:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:04:51 lr 0.000038	 wd 0.0000	time 0.3091 (0.3632)	loss 1.1590 (1.2653)	grad_norm 4.4669 (inf)	loss_scale 1024.0000 (1157.6437)	mem 12172MB
[2024-07-03 00:48:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:04:13 lr 0.000038	 wd 0.0000	time 0.3216 (0.3618)	loss 1.3823 (1.2673)	grad_norm 2.7845 (inf)	loss_scale 1024.0000 (1150.2232)	mem 12172MB
[2024-07-03 00:49:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:03:38 lr 0.000038	 wd 0.0000	time 0.3099 (0.3622)	loss 1.2080 (1.2674)	grad_norm 5.7509 (inf)	loss_scale 1024.0000 (1143.5834)	mem 12172MB
[2024-07-03 00:49:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:03:01 lr 0.000038	 wd 0.0000	time 0.3134 (0.3614)	loss 1.6501 (1.2692)	grad_norm 3.7426 (inf)	loss_scale 1024.0000 (1137.6072)	mem 12172MB
[2024-07-03 00:50:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:02:24 lr 0.000038	 wd 0.0000	time 0.2917 (0.3604)	loss 1.2637 (1.2694)	grad_norm 5.4418 (inf)	loss_scale 1024.0000 (1132.1999)	mem 12172MB
[2024-07-03 00:50:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:48 lr 0.000038	 wd 0.0000	time 0.3207 (0.3604)	loss 1.3565 (1.2682)	grad_norm 9.0278 (inf)	loss_scale 1024.0000 (1127.2840)	mem 12172MB
[2024-07-03 00:51:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:01:12 lr 0.000038	 wd 0.0000	time 0.3051 (0.3594)	loss 1.2787 (1.2689)	grad_norm 4.6891 (inf)	loss_scale 1024.0000 (1122.7953)	mem 12172MB
[2024-07-03 00:51:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:36 lr 0.000038	 wd 0.0000	time 0.2979 (0.3587)	loss 1.3433 (1.2706)	grad_norm 4.5670 (inf)	loss_scale 1024.0000 (1118.6805)	mem 12172MB
[2024-07-03 00:52:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000038	 wd 0.0000	time 0.3030 (0.3576)	loss 1.4757 (1.2718)	grad_norm 3.8090 (inf)	loss_scale 1024.0000 (1114.8948)	mem 12172MB
[2024-07-03 00:52:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 8 training takes 0:15:02
[2024-07-03 00:52:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 16.577 (16.577)	Loss 0.4126 (0.4126)	Acc@1 91.797 (91.797)	Acc@5 98.438 (98.438)	Mem 12172MB
[2024-07-03 00:53:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.780 Acc@5 97.432
[2024-07-03 00:53:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-03 00:53:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-03 00:53:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][0/2502]	eta 10:54:49 lr 0.000038	 wd 0.0000	time 15.7032 (15.7032)	loss 1.2818 (1.2818)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:53:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:20:29 lr 0.000038	 wd 0.0000	time 0.3026 (0.5117)	loss 1.2297 (1.2475)	grad_norm 5.1362 (4.9678)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:54:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:16:20 lr 0.000037	 wd 0.0000	time 0.3071 (0.4258)	loss 1.3865 (1.2513)	grad_norm 4.2425 (4.9031)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:55:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:14:32 lr 0.000037	 wd 0.0000	time 0.3108 (0.3964)	loss 1.3368 (1.2614)	grad_norm 5.1901 (5.1052)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:55:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:13:27 lr 0.000037	 wd 0.0000	time 0.3244 (0.3840)	loss 1.5111 (1.2567)	grad_norm 3.6599 (5.0008)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:56:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:12:31 lr 0.000037	 wd 0.0000	time 0.3088 (0.3755)	loss 1.2388 (1.2624)	grad_norm 3.9946 (4.9103)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:56:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:11:45 lr 0.000037	 wd 0.0000	time 0.3044 (0.3709)	loss 1.3364 (1.2569)	grad_norm 4.5241 (4.9712)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:57:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:11:11 lr 0.000037	 wd 0.0000	time 0.3062 (0.3727)	loss 1.4224 (1.2575)	grad_norm 2.9243 (5.0352)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:57:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:10:27 lr 0.000037	 wd 0.0000	time 0.3071 (0.3690)	loss 1.3185 (1.2624)	grad_norm 3.3771 (5.0362)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:58:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:09:45 lr 0.000037	 wd 0.0000	time 0.3191 (0.3657)	loss 1.4481 (1.2595)	grad_norm 4.2687 (5.0387)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:59:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:09:09 lr 0.000037	 wd 0.0000	time 0.3041 (0.3658)	loss 1.4220 (1.2620)	grad_norm 3.8660 (5.0393)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 00:59:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:08:32 lr 0.000037	 wd 0.0000	time 0.2930 (0.3653)	loss 1.2648 (1.2655)	grad_norm 6.6834 (5.0395)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:00:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:07:54 lr 0.000037	 wd 0.0000	time 0.3091 (0.3645)	loss 1.4951 (1.2679)	grad_norm 3.0461 (5.0422)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:00:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:07:17 lr 0.000037	 wd 0.0000	time 0.2842 (0.3636)	loss 0.8799 (1.2652)	grad_norm 4.6450 (5.0155)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:01:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:06:39 lr 0.000037	 wd 0.0000	time 0.3300 (0.3623)	loss 1.3240 (1.2673)	grad_norm 4.3539 (4.9872)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:02:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:06:02 lr 0.000037	 wd 0.0000	time 0.3034 (0.3615)	loss 1.4428 (1.2695)	grad_norm 4.4092 (5.0042)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:02:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:05:25 lr 0.000037	 wd 0.0000	time 0.3257 (0.3607)	loss 0.8528 (1.2692)	grad_norm 3.8423 (4.9864)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:03:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:04:48 lr 0.000037	 wd 0.0000	time 0.3181 (0.3594)	loss 1.0029 (1.2707)	grad_norm 4.5052 (4.9922)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:03:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:04:12 lr 0.000037	 wd 0.0000	time 0.3170 (0.3596)	loss 1.3804 (1.2714)	grad_norm 4.8855 (4.9931)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:04:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:03:35 lr 0.000037	 wd 0.0000	time 0.3132 (0.3586)	loss 1.3414 (1.2706)	grad_norm 4.3560 (4.9799)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:04:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:02:59 lr 0.000037	 wd 0.0000	time 0.3031 (0.3574)	loss 1.4631 (1.2699)	grad_norm 5.9714 (4.9644)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:05:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:02:23 lr 0.000036	 wd 0.0000	time 0.3171 (0.3574)	loss 1.1110 (1.2707)	grad_norm 4.5201 (4.9476)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:06:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:47 lr 0.000036	 wd 0.0000	time 0.3416 (0.3565)	loss 1.3716 (1.2721)	grad_norm 8.1238 (4.9487)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:06:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:01:11 lr 0.000036	 wd 0.0000	time 0.3190 (0.3558)	loss 1.3168 (1.2728)	grad_norm 7.4931 (4.9408)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:07:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:36 lr 0.000036	 wd 0.0000	time 0.3285 (0.3569)	loss 1.1562 (1.2726)	grad_norm 3.8295 (4.9452)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:07:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000036	 wd 0.0000	time 0.3058 (0.3558)	loss 0.8287 (1.2737)	grad_norm 3.6387 (4.9416)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:07:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 9 training takes 0:14:53
[2024-07-03 01:08:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 16.493 (16.493)	Loss 0.3948 (0.3948)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-03 01:08:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.870 Acc@5 97.406
[2024-07-03 01:08:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-03 01:08:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-03 01:08:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][0/2502]	eta 11:12:22 lr 0.000036	 wd 0.0000	time 16.1242 (16.1242)	loss 1.1734 (1.1734)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:09:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:20:29 lr 0.000036	 wd 0.0000	time 0.3405 (0.5118)	loss 1.1543 (1.2374)	grad_norm 3.6759 (4.7801)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:09:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:16:24 lr 0.000036	 wd 0.0000	time 0.3076 (0.4277)	loss 1.3139 (1.2614)	grad_norm 4.2014 (4.7987)	loss_scale 2048.0000 (1074.9453)	mem 12172MB
[2024-07-03 01:10:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:14:43 lr 0.000036	 wd 0.0000	time 0.3414 (0.4013)	loss 0.8499 (1.2631)	grad_norm 5.2345 (4.8491)	loss_scale 2048.0000 (1398.2193)	mem 12172MB
[2024-07-03 01:11:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:13:32 lr 0.000036	 wd 0.0000	time 0.3607 (0.3867)	loss 1.4530 (1.2689)	grad_norm 5.6553 (4.8247)	loss_scale 2048.0000 (1560.2594)	mem 12172MB
[2024-07-03 01:11:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:12:40 lr 0.000036	 wd 0.0000	time 0.3443 (0.3796)	loss 1.4596 (1.2677)	grad_norm 5.6051 (4.8007)	loss_scale 2048.0000 (1657.6128)	mem 12172MB
[2024-07-03 01:12:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:11:56 lr 0.000036	 wd 0.0000	time 0.2992 (0.3765)	loss 1.5268 (1.2662)	grad_norm 5.1351 (4.7694)	loss_scale 2048.0000 (1722.5691)	mem 12172MB
[2024-07-03 01:12:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:11:09 lr 0.000036	 wd 0.0000	time 0.3192 (0.3713)	loss 1.3351 (1.2642)	grad_norm 3.9285 (4.8040)	loss_scale 2048.0000 (1768.9929)	mem 12172MB
[2024-07-03 01:13:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:10:26 lr 0.000036	 wd 0.0000	time 0.3141 (0.3681)	loss 1.2072 (1.2651)	grad_norm 5.2927 (inf)	loss_scale 1024.0000 (1757.8027)	mem 12172MB
[2024-07-03 01:14:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:09:45 lr 0.000036	 wd 0.0000	time 0.3159 (0.3655)	loss 1.3877 (1.2653)	grad_norm 3.9847 (inf)	loss_scale 1024.0000 (1676.3596)	mem 12172MB
[2024-07-03 01:14:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:09:05 lr 0.000036	 wd 0.0000	time 0.3194 (0.3629)	loss 1.4886 (1.2638)	grad_norm 5.0536 (inf)	loss_scale 1024.0000 (1611.1888)	mem 12172MB
[2024-07-03 01:15:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:08:26 lr 0.000036	 wd 0.0000	time 0.3171 (0.3615)	loss 1.2850 (1.2618)	grad_norm 4.4006 (inf)	loss_scale 1024.0000 (1557.8565)	mem 12172MB
[2024-07-03 01:15:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:07:48 lr 0.000035	 wd 0.0000	time 0.3172 (0.3598)	loss 1.1614 (1.2620)	grad_norm 4.8097 (inf)	loss_scale 1024.0000 (1513.4055)	mem 12172MB
[2024-07-03 01:16:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:07:10 lr 0.000035	 wd 0.0000	time 0.3265 (0.3584)	loss 1.5400 (1.2647)	grad_norm 14.8499 (inf)	loss_scale 1024.0000 (1475.7879)	mem 12172MB
[2024-07-03 01:16:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:06:34 lr 0.000035	 wd 0.0000	time 0.3590 (0.3580)	loss 1.3587 (1.2667)	grad_norm 3.8412 (inf)	loss_scale 1024.0000 (1443.5403)	mem 12172MB
[2024-07-03 01:17:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:05:57 lr 0.000035	 wd 0.0000	time 0.3216 (0.3570)	loss 1.1704 (1.2671)	grad_norm 3.6994 (inf)	loss_scale 1024.0000 (1415.5896)	mem 12172MB
[2024-07-03 01:18:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:05:21 lr 0.000035	 wd 0.0000	time 0.3090 (0.3559)	loss 1.1474 (1.2685)	grad_norm 3.7980 (inf)	loss_scale 1024.0000 (1391.1305)	mem 12172MB
[2024-07-03 01:18:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:04:45 lr 0.000035	 wd 0.0000	time 0.3140 (0.3557)	loss 1.3192 (1.2692)	grad_norm 3.8146 (inf)	loss_scale 1024.0000 (1369.5473)	mem 12172MB
[2024-07-03 01:19:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:04:09 lr 0.000035	 wd 0.0000	time 0.3192 (0.3550)	loss 1.2857 (1.2695)	grad_norm 5.5862 (inf)	loss_scale 1024.0000 (1350.3609)	mem 12172MB
[2024-07-03 01:19:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:03:33 lr 0.000035	 wd 0.0000	time 0.3185 (0.3540)	loss 1.3368 (1.2705)	grad_norm 5.6059 (inf)	loss_scale 1024.0000 (1333.1931)	mem 12172MB
[2024-07-03 01:20:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:02:57 lr 0.000035	 wd 0.0000	time 0.3044 (0.3542)	loss 1.2237 (1.2704)	grad_norm 4.6085 (inf)	loss_scale 1024.0000 (1317.7411)	mem 12172MB
[2024-07-03 01:20:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:02:22 lr 0.000035	 wd 0.0000	time 0.3038 (0.3557)	loss 1.4160 (1.2718)	grad_norm 3.8226 (inf)	loss_scale 1024.0000 (1303.7601)	mem 12172MB
[2024-07-03 01:21:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:47 lr 0.000035	 wd 0.0000	time 0.3222 (0.3564)	loss 0.9207 (1.2723)	grad_norm 3.8995 (inf)	loss_scale 1024.0000 (1291.0495)	mem 12172MB
[2024-07-03 01:22:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:01:11 lr 0.000035	 wd 0.0000	time 0.7707 (0.3561)	loss 1.3804 (1.2718)	grad_norm 5.4699 (inf)	loss_scale 1024.0000 (1279.4437)	mem 12172MB
[2024-07-03 01:22:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:36 lr 0.000035	 wd 0.0000	time 0.3170 (0.3557)	loss 1.3560 (1.2720)	grad_norm 3.3658 (inf)	loss_scale 1024.0000 (1268.8047)	mem 12172MB
[2024-07-03 01:23:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.2963 (0.3547)	loss 1.4091 (1.2716)	grad_norm 11.6698 (inf)	loss_scale 1024.0000 (1259.0164)	mem 12172MB
[2024-07-03 01:23:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 10 training takes 0:15:00
[2024-07-03 01:23:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 16.340 (16.340)	Loss 0.4148 (0.4148)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-03 01:23:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.832 Acc@5 97.452
[2024-07-03 01:23:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-03 01:23:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-03 01:24:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][0/2502]	eta 10:54:52 lr 0.000035	 wd 0.0000	time 15.7045 (15.7045)	loss 1.4519 (1.4519)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:24:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:21:35 lr 0.000035	 wd 0.0000	time 0.3093 (0.5395)	loss 1.2447 (1.2695)	grad_norm 3.9112 (5.0899)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:25:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:17:00 lr 0.000034	 wd 0.0000	time 0.3160 (0.4432)	loss 1.4718 (1.2724)	grad_norm 14.9572 (5.1106)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:26:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:15:04 lr 0.000034	 wd 0.0000	time 0.3325 (0.4106)	loss 1.1515 (1.2722)	grad_norm 4.1600 (4.8638)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:26:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:13:47 lr 0.000034	 wd 0.0000	time 0.3275 (0.3935)	loss 1.3574 (1.2757)	grad_norm 3.7854 (4.8676)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:27:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:12:49 lr 0.000034	 wd 0.0000	time 0.3108 (0.3845)	loss 1.2609 (1.2687)	grad_norm 2.5654 (4.9445)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:27:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:11:56 lr 0.000034	 wd 0.0000	time 0.3316 (0.3769)	loss 1.3683 (1.2669)	grad_norm 3.8529 (4.8729)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:28:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:11:15 lr 0.000034	 wd 0.0000	time 0.3135 (0.3746)	loss 1.3322 (1.2669)	grad_norm 3.7571 (4.9659)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:28:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:10:30 lr 0.000034	 wd 0.0000	time 0.2835 (0.3703)	loss 1.5915 (1.2698)	grad_norm 3.8327 (4.9185)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:29:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:09:47 lr 0.000034	 wd 0.0000	time 0.3130 (0.3667)	loss 1.4288 (1.2701)	grad_norm 3.6015 (4.9011)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:30:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:09:09 lr 0.000034	 wd 0.0000	time 0.3175 (0.3661)	loss 1.3320 (1.2699)	grad_norm 4.8718 (4.8726)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:30:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:08:29 lr 0.000034	 wd 0.0000	time 0.3267 (0.3635)	loss 1.3099 (1.2716)	grad_norm 5.3388 (4.9088)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:31:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:07:50 lr 0.000034	 wd 0.0000	time 0.3028 (0.3616)	loss 1.4785 (1.2722)	grad_norm 4.1298 (4.9229)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:31:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:07:13 lr 0.000034	 wd 0.0000	time 0.3340 (0.3608)	loss 1.0212 (1.2710)	grad_norm 4.8634 (4.8954)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:32:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:06:36 lr 0.000034	 wd 0.0000	time 0.3200 (0.3597)	loss 0.8895 (1.2709)	grad_norm 3.7001 (4.9060)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:32:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:05:59 lr 0.000034	 wd 0.0000	time 0.3219 (0.3583)	loss 1.3763 (1.2703)	grad_norm 5.7562 (4.9294)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:33:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:05:24 lr 0.000034	 wd 0.0000	time 0.3190 (0.3597)	loss 1.2089 (1.2715)	grad_norm 4.0873 (4.9145)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:34:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:04:47 lr 0.000033	 wd 0.0000	time 0.3159 (0.3586)	loss 1.2880 (1.2704)	grad_norm 3.6288 (4.9167)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:34:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:04:13 lr 0.000033	 wd 0.0000	time 0.2972 (0.3611)	loss 1.2560 (1.2722)	grad_norm 3.8201 (4.9162)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:35:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:03:36 lr 0.000033	 wd 0.0000	time 0.3290 (0.3599)	loss 1.4398 (1.2721)	grad_norm 3.6486 (4.8879)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:35:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:03:00 lr 0.000033	 wd 0.0000	time 0.2922 (0.3589)	loss 1.1287 (1.2718)	grad_norm 5.7794 (4.8911)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:36:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:02:24 lr 0.000033	 wd 0.0000	time 0.2931 (0.3585)	loss 1.3078 (1.2710)	grad_norm 7.7269 (4.8863)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:37:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:47 lr 0.000033	 wd 0.0000	time 0.3351 (0.3576)	loss 1.3425 (1.2726)	grad_norm 3.3232 (4.8812)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:37:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:01:12 lr 0.000033	 wd 0.0000	time 0.3055 (0.3569)	loss 1.3788 (1.2721)	grad_norm 5.4070 (4.8975)	loss_scale 2048.0000 (1040.9109)	mem 12172MB
[2024-07-03 01:38:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:36 lr 0.000033	 wd 0.0000	time 0.3293 (0.3571)	loss 1.2989 (1.2715)	grad_norm 4.6696 (4.9130)	loss_scale 2048.0000 (1082.8555)	mem 12172MB
[2024-07-03 01:38:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000033	 wd 0.0000	time 0.3034 (0.3563)	loss 1.3062 (1.2715)	grad_norm 6.0318 (4.9173)	loss_scale 2048.0000 (1121.4458)	mem 12172MB
[2024-07-03 01:38:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 11 training takes 0:14:56
[2024-07-03 01:39:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 17.261 (17.261)	Loss 0.4150 (0.4150)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 12172MB
[2024-07-03 01:39:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.712 Acc@5 97.362
[2024-07-03 01:39:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-03 01:39:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-03 01:39:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][0/2502]	eta 19:54:12 lr 0.000033	 wd 0.0000	time 28.6383 (28.6383)	loss 1.5481 (1.5481)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 01:40:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:25:22 lr 0.000033	 wd 0.0000	time 0.2966 (0.6339)	loss 1.4259 (1.2685)	grad_norm 7.2177 (4.9256)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 01:41:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:18:40 lr 0.000033	 wd 0.0000	time 0.3213 (0.4870)	loss 0.8310 (1.2752)	grad_norm 4.7063 (4.8748)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 01:41:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:16:08 lr 0.000033	 wd 0.0000	time 0.2909 (0.4398)	loss 1.2353 (1.2742)	grad_norm 4.8039 (4.7505)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 01:42:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:14:31 lr 0.000033	 wd 0.0000	time 0.2894 (0.4148)	loss 1.2337 (1.2681)	grad_norm 3.0839 (nan)	loss_scale 1024.0000 (1981.6060)	mem 12172MB
[2024-07-03 01:42:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:13:21 lr 0.000032	 wd 0.0000	time 0.3110 (0.4005)	loss 0.9560 (1.2698)	grad_norm 4.0382 (nan)	loss_scale 1024.0000 (1790.4671)	mem 12172MB
[2024-07-03 01:43:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:12:24 lr 0.000032	 wd 0.0000	time 0.3188 (0.3915)	loss 1.2744 (1.2665)	grad_norm 4.3263 (nan)	loss_scale 1024.0000 (1662.9351)	mem 12172MB
[2024-07-03 01:43:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:11:31 lr 0.000032	 wd 0.0000	time 0.2832 (0.3839)	loss 1.3362 (1.2667)	grad_norm 5.9699 (nan)	loss_scale 1024.0000 (1571.7889)	mem 12172MB
[2024-07-03 01:44:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:10:43 lr 0.000032	 wd 0.0000	time 0.3057 (0.3783)	loss 1.5799 (1.2760)	grad_norm 4.4887 (nan)	loss_scale 1024.0000 (1503.4007)	mem 12172MB
[2024-07-03 01:45:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:10:02 lr 0.000032	 wd 0.0000	time 0.2899 (0.3762)	loss 0.9875 (1.2773)	grad_norm 4.5572 (nan)	loss_scale 1024.0000 (1450.1931)	mem 12172MB
[2024-07-03 01:45:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:09:19 lr 0.000032	 wd 0.0000	time 0.3384 (0.3725)	loss 1.3107 (1.2759)	grad_norm 4.2795 (nan)	loss_scale 1024.0000 (1407.6164)	mem 12172MB
[2024-07-03 01:46:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:08:38 lr 0.000032	 wd 0.0000	time 0.3725 (0.3698)	loss 1.3871 (1.2806)	grad_norm 5.2822 (nan)	loss_scale 1024.0000 (1372.7738)	mem 12172MB
[2024-07-03 01:46:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:07:59 lr 0.000032	 wd 0.0000	time 0.3100 (0.3683)	loss 1.4996 (1.2791)	grad_norm 6.8891 (nan)	loss_scale 1024.0000 (1343.7336)	mem 12172MB
[2024-07-03 01:47:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:07:20 lr 0.000032	 wd 0.0000	time 0.3246 (0.3663)	loss 1.4656 (1.2795)	grad_norm 4.8513 (nan)	loss_scale 1024.0000 (1319.1576)	mem 12172MB
[2024-07-03 01:47:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:06:41 lr 0.000032	 wd 0.0000	time 0.3213 (0.3646)	loss 1.4452 (1.2794)	grad_norm 7.6930 (nan)	loss_scale 1024.0000 (1298.0899)	mem 12172MB
[2024-07-03 01:48:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:06:03 lr 0.000032	 wd 0.0000	time 0.3066 (0.3631)	loss 1.3697 (1.2803)	grad_norm 5.4599 (nan)	loss_scale 1024.0000 (1279.8294)	mem 12172MB
[2024-07-03 01:49:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:05:26 lr 0.000032	 wd 0.0000	time 0.3228 (0.3623)	loss 1.3885 (1.2786)	grad_norm 5.2646 (nan)	loss_scale 1024.0000 (1263.8501)	mem 12172MB
[2024-07-03 01:49:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:04:49 lr 0.000031	 wd 0.0000	time 0.3252 (0.3611)	loss 1.3474 (1.2798)	grad_norm 4.1490 (nan)	loss_scale 1024.0000 (1249.7496)	mem 12172MB
[2024-07-03 01:50:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:04:12 lr 0.000031	 wd 0.0000	time 0.3402 (0.3601)	loss 1.2657 (1.2805)	grad_norm 4.8889 (nan)	loss_scale 1024.0000 (1237.2149)	mem 12172MB
[2024-07-03 01:50:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:03:36 lr 0.000031	 wd 0.0000	time 0.3175 (0.3592)	loss 1.2655 (1.2802)	grad_norm 3.8585 (nan)	loss_scale 1024.0000 (1225.9989)	mem 12172MB
[2024-07-03 01:51:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:03:00 lr 0.000031	 wd 0.0000	time 0.3240 (0.3591)	loss 1.3203 (1.2797)	grad_norm 3.7564 (nan)	loss_scale 1024.0000 (1215.9040)	mem 12172MB
[2024-07-03 01:51:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:02:24 lr 0.000031	 wd 0.0000	time 0.3060 (0.3584)	loss 1.4298 (1.2804)	grad_norm 4.5055 (nan)	loss_scale 1024.0000 (1206.7701)	mem 12172MB
[2024-07-03 01:52:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:47 lr 0.000031	 wd 0.0000	time 0.3618 (0.3575)	loss 1.4184 (1.2812)	grad_norm 5.7281 (nan)	loss_scale 1024.0000 (1198.4662)	mem 12172MB
[2024-07-03 01:53:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:01:12 lr 0.000031	 wd 0.0000	time 0.3337 (0.3579)	loss 1.2788 (1.2808)	grad_norm 4.2235 (nan)	loss_scale 1024.0000 (1190.8840)	mem 12172MB
[2024-07-03 01:53:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:36 lr 0.000031	 wd 0.0000	time 0.3308 (0.3571)	loss 1.4260 (1.2806)	grad_norm 4.4332 (nan)	loss_scale 1024.0000 (1183.9334)	mem 12172MB
[2024-07-03 01:54:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000031	 wd 0.0000	time 0.2986 (0.3560)	loss 1.0076 (1.2791)	grad_norm 5.3696 (nan)	loss_scale 1024.0000 (1177.5386)	mem 12172MB
[2024-07-03 01:54:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 12 training takes 0:14:54
[2024-07-03 01:54:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 21.332 (21.332)	Loss 0.4011 (0.4011)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 12172MB
[2024-07-03 01:54:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.824 Acc@5 97.458
[2024-07-03 01:54:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-03 01:54:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-03 01:55:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][0/2502]	eta 10:33:41 lr 0.000031	 wd 0.0000	time 15.1963 (15.1963)	loss 1.2933 (1.2933)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:55:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:19:57 lr 0.000031	 wd 0.0000	time 0.3108 (0.4986)	loss 1.3945 (1.2728)	grad_norm 3.6921 (4.7333)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:56:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:16:22 lr 0.000031	 wd 0.0000	time 0.3358 (0.4270)	loss 1.5006 (1.2755)	grad_norm 4.8561 (4.7729)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:56:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:14:35 lr 0.000031	 wd 0.0000	time 0.3454 (0.3975)	loss 1.4896 (1.2811)	grad_norm 5.1139 (4.6970)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:57:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:13:23 lr 0.000030	 wd 0.0000	time 0.3101 (0.3823)	loss 1.3619 (1.2782)	grad_norm 3.7350 (4.6361)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:57:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:12:30 lr 0.000030	 wd 0.0000	time 0.3031 (0.3750)	loss 1.3947 (1.2728)	grad_norm 5.6725 (4.7050)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:58:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:11:43 lr 0.000030	 wd 0.0000	time 0.3268 (0.3698)	loss 1.4255 (1.2773)	grad_norm 4.6328 (4.7540)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:59:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:10:58 lr 0.000030	 wd 0.0000	time 0.3046 (0.3653)	loss 1.5900 (1.2734)	grad_norm 4.4870 (4.7691)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 01:59:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:10:23 lr 0.000030	 wd 0.0000	time 0.3027 (0.3663)	loss 1.4192 (1.2762)	grad_norm 4.8867 (4.7817)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 02:00:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:09:42 lr 0.000030	 wd 0.0000	time 0.2899 (0.3637)	loss 1.4552 (1.2722)	grad_norm 4.3411 (4.7792)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 02:00:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:09:02 lr 0.000030	 wd 0.0000	time 0.3200 (0.3611)	loss 1.4243 (1.2746)	grad_norm 10.0963 (4.7767)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 02:01:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:08:27 lr 0.000030	 wd 0.0000	time 0.2976 (0.3620)	loss 1.3598 (1.2766)	grad_norm 8.3783 (4.7916)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 02:02:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:07:48 lr 0.000030	 wd 0.0000	time 0.2925 (0.3601)	loss 1.5577 (1.2738)	grad_norm 4.1075 (4.7972)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 02:02:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:07:11 lr 0.000030	 wd 0.0000	time 0.3217 (0.3588)	loss 1.4405 (1.2732)	grad_norm 4.7126 (4.7664)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 02:03:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:06:34 lr 0.000030	 wd 0.0000	time 0.3053 (0.3579)	loss 1.5250 (1.2739)	grad_norm 3.7959 (4.8034)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 02:03:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:05:57 lr 0.000030	 wd 0.0000	time 0.3253 (0.3568)	loss 1.4150 (1.2733)	grad_norm 5.0874 (4.7906)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 02:04:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:05:21 lr 0.000029	 wd 0.0000	time 0.7072 (0.3568)	loss 1.4030 (1.2729)	grad_norm 4.5648 (4.8147)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 02:04:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:04:45 lr 0.000029	 wd 0.0000	time 0.3192 (0.3559)	loss 0.8327 (1.2705)	grad_norm 4.5995 (4.8098)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 02:05:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:04:09 lr 0.000029	 wd 0.0000	time 0.3280 (0.3549)	loss 1.2597 (1.2718)	grad_norm 4.7740 (4.8195)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 02:06:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:03:34 lr 0.000029	 wd 0.0000	time 0.3254 (0.3560)	loss 1.1208 (1.2719)	grad_norm 5.8957 (4.8423)	loss_scale 2048.0000 (1039.0826)	mem 12172MB
[2024-07-03 02:06:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:02:58 lr 0.000029	 wd 0.0000	time 0.3196 (0.3557)	loss 1.3163 (1.2725)	grad_norm 4.4276 (4.8316)	loss_scale 2048.0000 (1089.5032)	mem 12172MB
[2024-07-03 02:07:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:02:22 lr 0.000029	 wd 0.0000	time 0.3350 (0.3548)	loss 1.0543 (1.2721)	grad_norm 10.5255 (4.8509)	loss_scale 2048.0000 (1135.1242)	mem 12172MB
[2024-07-03 02:07:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:47 lr 0.000029	 wd 0.0000	time 2.4938 (0.3555)	loss 1.4828 (1.2739)	grad_norm 4.1376 (4.8271)	loss_scale 2048.0000 (1176.5997)	mem 12172MB
[2024-07-03 02:08:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:01:11 lr 0.000029	 wd 0.0000	time 0.3233 (0.3550)	loss 1.2974 (1.2729)	grad_norm 4.1890 (4.8447)	loss_scale 2048.0000 (1214.4702)	mem 12172MB
[2024-07-03 02:08:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:36 lr 0.000029	 wd 0.0000	time 0.2907 (0.3542)	loss 1.3660 (1.2736)	grad_norm 4.8661 (4.8782)	loss_scale 2048.0000 (1249.1862)	mem 12172MB
[2024-07-03 02:09:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000029	 wd 0.0000	time 0.3050 (0.3536)	loss 1.3918 (1.2732)	grad_norm 3.3118 (4.9111)	loss_scale 2048.0000 (1281.1259)	mem 12172MB
[2024-07-03 02:09:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 13 training takes 0:14:51
[2024-07-03 02:09:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 17.824 (17.824)	Loss 0.4023 (0.4023)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 12172MB
[2024-07-03 02:10:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.824 Acc@5 97.484
[2024-07-03 02:10:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-03 02:10:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-03 02:10:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][0/2502]	eta 10:21:09 lr 0.000029	 wd 0.0000	time 14.8958 (14.8958)	loss 1.4930 (1.4930)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 02:11:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:20:19 lr 0.000029	 wd 0.0000	time 0.3178 (0.5077)	loss 1.4176 (1.2696)	grad_norm 4.4273 (4.8206)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 02:11:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:16:18 lr 0.000028	 wd 0.0000	time 0.3030 (0.4250)	loss 1.1536 (1.2928)	grad_norm 3.8330 (4.8943)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 02:12:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:14:38 lr 0.000028	 wd 0.0000	time 0.3247 (0.3992)	loss 1.0190 (1.2798)	grad_norm 3.9706 (4.9267)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 02:12:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:13:28 lr 0.000028	 wd 0.0000	time 0.3148 (0.3846)	loss 1.0765 (1.2687)	grad_norm 4.8557 (4.9964)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 02:13:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:12:32 lr 0.000028	 wd 0.0000	time 0.3208 (0.3757)	loss 1.3330 (1.2694)	grad_norm 3.4761 (4.8866)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 02:13:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:11:44 lr 0.000028	 wd 0.0000	time 0.3339 (0.3702)	loss 1.5098 (1.2729)	grad_norm 4.5696 (4.9738)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 02:14:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:11:02 lr 0.000028	 wd 0.0000	time 0.3030 (0.3676)	loss 1.2486 (1.2693)	grad_norm 3.5282 (4.9787)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 02:15:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:10:22 lr 0.000028	 wd 0.0000	time 0.2955 (0.3655)	loss 1.2422 (1.2669)	grad_norm 3.8322 (4.9395)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 02:15:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:09:40 lr 0.000028	 wd 0.0000	time 0.3183 (0.3623)	loss 1.4771 (1.2656)	grad_norm 4.3854 (4.9720)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 02:16:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:09:01 lr 0.000028	 wd 0.0000	time 0.2995 (0.3608)	loss 1.0844 (1.2644)	grad_norm 3.1678 (4.9603)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 02:16:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:08:23 lr 0.000028	 wd 0.0000	time 0.3287 (0.3592)	loss 1.2973 (1.2622)	grad_norm 9.9141 (nan)	loss_scale 1024.0000 (2020.0981)	mem 12172MB
[2024-07-03 02:17:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:07:45 lr 0.000028	 wd 0.0000	time 0.3391 (0.3578)	loss 1.4513 (1.2624)	grad_norm 5.7972 (nan)	loss_scale 1024.0000 (1937.1590)	mem 12172MB
[2024-07-03 02:17:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:07:09 lr 0.000027	 wd 0.0000	time 0.2974 (0.3573)	loss 1.1156 (1.2638)	grad_norm 3.3041 (nan)	loss_scale 1024.0000 (1866.9700)	mem 12172MB
[2024-07-03 02:18:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:06:32 lr 0.000027	 wd 0.0000	time 0.2946 (0.3560)	loss 1.3609 (1.2633)	grad_norm 3.8818 (nan)	loss_scale 1024.0000 (1806.8009)	mem 12172MB
[2024-07-03 02:19:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:05:56 lr 0.000027	 wd 0.0000	time 1.9372 (0.3558)	loss 1.2817 (1.2643)	grad_norm 3.8042 (nan)	loss_scale 1024.0000 (1754.6489)	mem 12172MB
[2024-07-03 02:19:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:05:20 lr 0.000027	 wd 0.0000	time 0.3192 (0.3553)	loss 1.3024 (1.2653)	grad_norm 5.4542 (nan)	loss_scale 1024.0000 (1709.0119)	mem 12172MB
[2024-07-03 02:20:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:04:44 lr 0.000027	 wd 0.0000	time 0.3081 (0.3545)	loss 1.1412 (1.2655)	grad_norm 5.0368 (nan)	loss_scale 512.0000 (1653.6908)	mem 12172MB
[2024-07-03 02:20:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:04:08 lr 0.000027	 wd 0.0000	time 0.4403 (0.3543)	loss 1.2337 (1.2648)	grad_norm 4.7665 (nan)	loss_scale 512.0000 (1590.2987)	mem 12172MB
[2024-07-03 02:21:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:03:33 lr 0.000027	 wd 0.0000	time 0.3226 (0.3542)	loss 1.3443 (1.2649)	grad_norm 4.5833 (nan)	loss_scale 512.0000 (1533.5760)	mem 12172MB
[2024-07-03 02:21:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:02:57 lr 0.000027	 wd 0.0000	time 0.3212 (0.3533)	loss 0.9403 (1.2664)	grad_norm 8.7603 (nan)	loss_scale 512.0000 (1482.5227)	mem 12172MB
[2024-07-03 02:22:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:02:21 lr 0.000027	 wd 0.0000	time 0.3431 (0.3527)	loss 1.5563 (1.2656)	grad_norm 5.8043 (nan)	loss_scale 512.0000 (1436.3294)	mem 12172MB
[2024-07-03 02:23:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:46 lr 0.000027	 wd 0.0000	time 0.3195 (0.3531)	loss 1.2017 (1.2660)	grad_norm 3.4495 (nan)	loss_scale 512.0000 (1394.3335)	mem 12172MB
[2024-07-03 02:23:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:01:11 lr 0.000027	 wd 0.0000	time 0.3109 (0.3526)	loss 1.2973 (1.2670)	grad_norm 6.2829 (nan)	loss_scale 512.0000 (1355.9878)	mem 12172MB
[2024-07-03 02:24:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:36 lr 0.000026	 wd 0.0000	time 0.2793 (0.3531)	loss 1.2024 (1.2680)	grad_norm 5.5469 (nan)	loss_scale 512.0000 (1320.8363)	mem 12172MB
[2024-07-03 02:24:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.2978 (0.3523)	loss 1.2544 (1.2673)	grad_norm 5.1057 (nan)	loss_scale 512.0000 (1288.4958)	mem 12172MB
[2024-07-03 02:24:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 14 training takes 0:14:45
[2024-07-03 02:25:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 17.473 (17.473)	Loss 0.3972 (0.3972)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-03 02:25:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.788 Acc@5 97.480
[2024-07-03 02:25:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-03 02:25:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-03 02:25:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][0/2502]	eta 22:45:13 lr 0.000026	 wd 0.0000	time 32.7393 (32.7393)	loss 1.2677 (1.2677)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:26:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:26:36 lr 0.000026	 wd 0.0000	time 0.3123 (0.6648)	loss 0.9896 (1.2602)	grad_norm 5.0791 (4.9924)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:27:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:19:21 lr 0.000026	 wd 0.0000	time 0.3015 (0.5044)	loss 1.3611 (1.2717)	grad_norm 3.5732 (4.8443)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:27:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:16:40 lr 0.000026	 wd 0.0000	time 0.3161 (0.4544)	loss 1.3005 (1.2585)	grad_norm 5.6726 (5.0506)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:28:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:14:56 lr 0.000026	 wd 0.0000	time 0.3198 (0.4263)	loss 1.2589 (1.2621)	grad_norm 3.8869 (4.8286)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:28:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:13:43 lr 0.000026	 wd 0.0000	time 0.3322 (0.4111)	loss 0.8179 (1.2558)	grad_norm 3.2242 (5.0493)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:29:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:12:44 lr 0.000026	 wd 0.0000	time 0.2994 (0.4021)	loss 0.8087 (1.2591)	grad_norm 3.9876 (4.9265)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:29:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:11:50 lr 0.000026	 wd 0.0000	time 0.3392 (0.3942)	loss 1.1122 (1.2626)	grad_norm 3.6279 (4.9393)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:30:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:11:01 lr 0.000026	 wd 0.0000	time 0.3253 (0.3888)	loss 1.4529 (1.2634)	grad_norm 5.1087 (4.9747)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:31:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:10:14 lr 0.000025	 wd 0.0000	time 0.3317 (0.3835)	loss 1.0983 (1.2624)	grad_norm 3.7840 (5.0159)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:31:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:09:29 lr 0.000025	 wd 0.0000	time 0.3622 (0.3790)	loss 1.2512 (1.2623)	grad_norm 2.9031 (4.9772)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:32:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:08:48 lr 0.000025	 wd 0.0000	time 0.3551 (0.3769)	loss 1.2081 (1.2597)	grad_norm 5.1883 (4.9351)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:32:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:08:07 lr 0.000025	 wd 0.0000	time 0.3264 (0.3743)	loss 1.5047 (1.2599)	grad_norm 4.8663 (4.9678)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:33:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:07:26 lr 0.000025	 wd 0.0000	time 0.3093 (0.3716)	loss 1.2753 (1.2586)	grad_norm 3.5986 (4.9571)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:34:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:06:48 lr 0.000025	 wd 0.0000	time 0.2839 (0.3706)	loss 1.2422 (1.2592)	grad_norm 4.2408 (4.9622)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:34:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:06:09 lr 0.000025	 wd 0.0000	time 0.3463 (0.3688)	loss 1.5308 (1.2587)	grad_norm 5.1186 (4.9588)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:35:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:05:30 lr 0.000025	 wd 0.0000	time 0.3034 (0.3669)	loss 1.1495 (1.2615)	grad_norm 3.3974 (4.9462)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:35:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:04:53 lr 0.000025	 wd 0.0000	time 0.3203 (0.3655)	loss 1.4927 (1.2618)	grad_norm 4.3691 (4.9886)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:36:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:04:15 lr 0.000025	 wd 0.0000	time 0.3073 (0.3641)	loss 0.9905 (1.2617)	grad_norm 4.0799 (5.0204)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:36:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:03:38 lr 0.000024	 wd 0.0000	time 0.3308 (0.3627)	loss 1.5525 (1.2627)	grad_norm 3.8755 (4.9988)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:37:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:03:01 lr 0.000024	 wd 0.0000	time 0.3192 (0.3620)	loss 1.6804 (1.2653)	grad_norm 3.9708 (4.9690)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:38:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:02:25 lr 0.000024	 wd 0.0000	time 0.3092 (0.3609)	loss 1.5224 (1.2660)	grad_norm 4.0252 (4.9581)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:38:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:48 lr 0.000024	 wd 0.0000	time 0.3345 (0.3598)	loss 0.8186 (1.2671)	grad_norm 2.7683 (4.9369)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:39:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:01:12 lr 0.000024	 wd 0.0000	time 0.3204 (0.3592)	loss 1.4063 (1.2674)	grad_norm 4.0844 (4.9311)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:39:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:36 lr 0.000024	 wd 0.0000	time 0.3230 (0.3586)	loss 1.1323 (1.2666)	grad_norm 4.8485 (4.9179)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:40:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.3266 (0.3577)	loss 1.3104 (1.2669)	grad_norm 4.1175 (4.9358)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:40:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 15 training takes 0:15:05
[2024-07-03 02:40:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune/ckpt_epoch_15.pth saving......
[2024-07-03 02:40:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune/ckpt_epoch_15.pth saved !!!
[2024-07-03 02:40:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 16.625 (16.625)	Loss 0.4019 (0.4019)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-03 02:40:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.852 Acc@5 97.496
[2024-07-03 02:40:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-03 02:40:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-03 02:41:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][0/2502]	eta 11:52:58 lr 0.000024	 wd 0.0000	time 17.0976 (17.0976)	loss 1.1055 (1.1055)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:41:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:20:20 lr 0.000024	 wd 0.0000	time 0.3389 (0.5081)	loss 1.3730 (1.2695)	grad_norm 3.4822 (4.7318)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:42:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:16:45 lr 0.000024	 wd 0.0000	time 0.3542 (0.4368)	loss 1.2092 (1.2768)	grad_norm 3.3870 (4.8256)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:43:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:14:55 lr 0.000024	 wd 0.0000	time 0.3207 (0.4068)	loss 1.2746 (1.2852)	grad_norm 5.6194 (4.7797)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:43:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:13:38 lr 0.000024	 wd 0.0000	time 0.3244 (0.3894)	loss 1.1153 (1.2796)	grad_norm 3.8252 (4.8252)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:44:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:12:44 lr 0.000023	 wd 0.0000	time 0.3080 (0.3819)	loss 1.2756 (1.2871)	grad_norm 4.8477 (4.8423)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:44:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:11:55 lr 0.000023	 wd 0.0000	time 0.2953 (0.3763)	loss 0.9891 (1.2780)	grad_norm 4.7723 (4.7865)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 02:45:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:11:09 lr 0.000023	 wd 0.0000	time 0.2874 (0.3714)	loss 1.2205 (1.2803)	grad_norm 4.4378 (4.8504)	loss_scale 1024.0000 (551.4408)	mem 12172MB
[2024-07-03 02:45:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:10:29 lr 0.000023	 wd 0.0000	time 0.3087 (0.3701)	loss 1.2396 (1.2739)	grad_norm 16.2297 (4.9085)	loss_scale 1024.0000 (610.4370)	mem 12172MB
[2024-07-03 02:46:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:09:47 lr 0.000023	 wd 0.0000	time 0.3500 (0.3668)	loss 1.2729 (1.2739)	grad_norm 4.2886 (4.9739)	loss_scale 1024.0000 (656.3374)	mem 12172MB
[2024-07-03 02:47:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:09:07 lr 0.000023	 wd 0.0000	time 0.3088 (0.3646)	loss 1.4069 (1.2743)	grad_norm 4.3427 (4.9391)	loss_scale 1024.0000 (693.0669)	mem 12172MB
[2024-07-03 02:47:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:08:28 lr 0.000023	 wd 0.0000	time 0.2919 (0.3627)	loss 1.2592 (1.2765)	grad_norm 11.0272 (4.9184)	loss_scale 1024.0000 (723.1244)	mem 12172MB
[2024-07-03 02:48:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:07:50 lr 0.000023	 wd 0.0000	time 0.3266 (0.3611)	loss 1.4308 (1.2756)	grad_norm 3.8631 (4.8913)	loss_scale 1024.0000 (748.1765)	mem 12172MB
[2024-07-03 02:48:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:07:13 lr 0.000023	 wd 0.0000	time 0.3238 (0.3603)	loss 1.0244 (1.2761)	grad_norm 6.4911 (4.8858)	loss_scale 1024.0000 (769.3774)	mem 12172MB
[2024-07-03 02:49:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:06:35 lr 0.000023	 wd 0.0000	time 0.3255 (0.3589)	loss 1.1935 (1.2737)	grad_norm 4.6402 (4.9519)	loss_scale 1024.0000 (787.5517)	mem 12172MB
[2024-07-03 02:49:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:05:58 lr 0.000022	 wd 0.0000	time 0.3094 (0.3576)	loss 1.3277 (1.2713)	grad_norm 3.3801 (4.9672)	loss_scale 1024.0000 (803.3045)	mem 12172MB
[2024-07-03 02:50:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:05:22 lr 0.000022	 wd 0.0000	time 0.3155 (0.3572)	loss 1.3361 (1.2707)	grad_norm 4.7799 (4.9504)	loss_scale 1024.0000 (817.0893)	mem 12172MB
[2024-07-03 02:51:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:04:45 lr 0.000022	 wd 0.0000	time 0.3323 (0.3561)	loss 1.0039 (1.2689)	grad_norm 5.0921 (4.9552)	loss_scale 1024.0000 (829.2534)	mem 12172MB
[2024-07-03 02:51:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:04:09 lr 0.000022	 wd 0.0000	time 0.3530 (0.3550)	loss 1.0594 (1.2680)	grad_norm 7.2067 (4.9413)	loss_scale 1024.0000 (840.0666)	mem 12172MB
[2024-07-03 02:52:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:03:34 lr 0.000022	 wd 0.0000	time 0.3233 (0.3560)	loss 1.1895 (1.2673)	grad_norm 3.8469 (4.9270)	loss_scale 1024.0000 (849.7422)	mem 12172MB
[2024-07-03 02:52:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:02:58 lr 0.000022	 wd 0.0000	time 0.3351 (0.3551)	loss 1.4725 (1.2674)	grad_norm 3.7561 (4.9332)	loss_scale 1024.0000 (858.4508)	mem 12172MB
[2024-07-03 02:53:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:02:22 lr 0.000022	 wd 0.0000	time 0.3408 (0.3542)	loss 1.3816 (1.2670)	grad_norm 3.4918 (4.9285)	loss_scale 1024.0000 (866.3303)	mem 12172MB
[2024-07-03 02:53:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:47 lr 0.000022	 wd 0.0000	time 0.3467 (0.3544)	loss 1.2711 (1.2678)	grad_norm 3.8679 (4.9148)	loss_scale 1024.0000 (873.4939)	mem 12172MB
[2024-07-03 02:54:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:01:11 lr 0.000022	 wd 0.0000	time 0.3050 (0.3537)	loss 1.2095 (1.2680)	grad_norm 4.4562 (4.9269)	loss_scale 1024.0000 (880.0348)	mem 12172MB
[2024-07-03 02:55:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:35 lr 0.000022	 wd 0.0000	time 0.3500 (0.3529)	loss 1.2413 (1.2679)	grad_norm 5.8654 (4.9461)	loss_scale 1024.0000 (886.0308)	mem 12172MB
[2024-07-03 02:55:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.3014 (0.3526)	loss 1.3575 (1.2677)	grad_norm 3.1305 (4.9344)	loss_scale 1024.0000 (891.5474)	mem 12172MB
[2024-07-03 02:55:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 16 training takes 0:14:50
[2024-07-03 02:56:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 16.824 (16.824)	Loss 0.3975 (0.3975)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-03 02:56:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.930 Acc@5 97.492
[2024-07-03 02:56:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-03 02:56:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-03 02:56:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][0/2502]	eta 11:01:48 lr 0.000021	 wd 0.0000	time 15.8705 (15.8705)	loss 1.3322 (1.3322)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 02:57:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:21:19 lr 0.000021	 wd 0.0000	time 0.3319 (0.5325)	loss 1.4765 (1.2466)	grad_norm 4.1921 (4.3992)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 02:57:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:16:45 lr 0.000021	 wd 0.0000	time 0.3794 (0.4368)	loss 1.4251 (1.2606)	grad_norm 4.4020 (4.5227)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 02:58:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:14:50 lr 0.000021	 wd 0.0000	time 0.3435 (0.4045)	loss 1.3379 (1.2576)	grad_norm 4.2516 (nan)	loss_scale 512.0000 (925.3422)	mem 12172MB
[2024-07-03 02:58:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:13:37 lr 0.000021	 wd 0.0000	time 0.3072 (0.3889)	loss 1.0586 (1.2570)	grad_norm 4.2036 (nan)	loss_scale 512.0000 (822.2643)	mem 12172MB
[2024-07-03 02:59:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:12:43 lr 0.000021	 wd 0.0000	time 0.3324 (0.3813)	loss 1.2602 (1.2541)	grad_norm 4.3243 (nan)	loss_scale 512.0000 (760.3353)	mem 12172MB
[2024-07-03 03:00:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:11:51 lr 0.000021	 wd 0.0000	time 0.3000 (0.3741)	loss 1.1077 (1.2594)	grad_norm 3.6885 (nan)	loss_scale 512.0000 (719.0150)	mem 12172MB
[2024-07-03 03:00:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:11:08 lr 0.000021	 wd 0.0000	time 0.2856 (0.3712)	loss 1.2638 (1.2631)	grad_norm 4.9955 (nan)	loss_scale 512.0000 (689.4836)	mem 12172MB
[2024-07-03 03:01:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:10:24 lr 0.000021	 wd 0.0000	time 0.3052 (0.3672)	loss 1.1989 (1.2667)	grad_norm 4.7072 (nan)	loss_scale 512.0000 (667.3258)	mem 12172MB
[2024-07-03 03:01:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:09:43 lr 0.000021	 wd 0.0000	time 0.3935 (0.3645)	loss 1.3871 (1.2694)	grad_norm 5.9905 (nan)	loss_scale 512.0000 (650.0866)	mem 12172MB
[2024-07-03 03:02:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:09:06 lr 0.000020	 wd 0.0000	time 0.2966 (0.3637)	loss 1.4338 (1.2674)	grad_norm 5.0143 (nan)	loss_scale 512.0000 (636.2917)	mem 12172MB
[2024-07-03 03:02:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:08:27 lr 0.000020	 wd 0.0000	time 0.3159 (0.3617)	loss 1.0886 (1.2657)	grad_norm 2.8596 (nan)	loss_scale 512.0000 (625.0027)	mem 12172MB
[2024-07-03 03:03:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:07:50 lr 0.000020	 wd 0.0000	time 0.3104 (0.3615)	loss 1.3356 (1.2681)	grad_norm 3.3325 (nan)	loss_scale 512.0000 (615.5937)	mem 12172MB
[2024-07-03 03:04:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:07:14 lr 0.000020	 wd 0.0000	time 0.3251 (0.3611)	loss 1.1790 (1.2683)	grad_norm 5.3297 (nan)	loss_scale 512.0000 (607.6311)	mem 12172MB
[2024-07-03 03:04:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:06:36 lr 0.000020	 wd 0.0000	time 0.3373 (0.3597)	loss 1.4052 (1.2689)	grad_norm 5.6168 (nan)	loss_scale 512.0000 (600.8051)	mem 12172MB
[2024-07-03 03:05:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:06:00 lr 0.000020	 wd 0.0000	time 0.2996 (0.3596)	loss 1.4587 (1.2696)	grad_norm 4.9544 (nan)	loss_scale 512.0000 (594.8887)	mem 12172MB
[2024-07-03 03:05:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:05:23 lr 0.000020	 wd 0.0000	time 0.3070 (0.3589)	loss 1.3536 (1.2707)	grad_norm 4.0339 (nan)	loss_scale 512.0000 (589.7114)	mem 12172MB
[2024-07-03 03:06:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:04:47 lr 0.000020	 wd 0.0000	time 0.3189 (0.3582)	loss 1.4896 (1.2719)	grad_norm 7.8846 (nan)	loss_scale 512.0000 (585.1429)	mem 12172MB
[2024-07-03 03:07:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:04:12 lr 0.000020	 wd 0.0000	time 0.3375 (0.3594)	loss 1.3078 (1.2726)	grad_norm 6.7932 (nan)	loss_scale 512.0000 (581.0816)	mem 12172MB
[2024-07-03 03:07:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:03:35 lr 0.000020	 wd 0.0000	time 0.2906 (0.3585)	loss 1.1753 (1.2733)	grad_norm 3.6784 (nan)	loss_scale 512.0000 (577.4477)	mem 12172MB
[2024-07-03 03:08:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:02:59 lr 0.000019	 wd 0.0000	time 0.3056 (0.3574)	loss 1.3461 (1.2711)	grad_norm 4.1105 (nan)	loss_scale 512.0000 (574.1769)	mem 12172MB
[2024-07-03 03:08:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:02:23 lr 0.000019	 wd 0.0000	time 0.3286 (0.3568)	loss 1.4356 (1.2710)	grad_norm 3.9666 (nan)	loss_scale 512.0000 (571.2175)	mem 12172MB
[2024-07-03 03:09:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:47 lr 0.000019	 wd 0.0000	time 0.3193 (0.3558)	loss 1.2747 (1.2715)	grad_norm 4.2347 (nan)	loss_scale 512.0000 (568.5270)	mem 12172MB
[2024-07-03 03:09:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:01:11 lr 0.000019	 wd 0.0000	time 0.3462 (0.3550)	loss 1.4973 (1.2710)	grad_norm 5.2326 (nan)	loss_scale 512.0000 (566.0704)	mem 12172MB
[2024-07-03 03:10:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:36 lr 0.000019	 wd 0.0000	time 0.3472 (0.3545)	loss 1.3581 (1.2693)	grad_norm 3.7774 (nan)	loss_scale 512.0000 (563.8184)	mem 12172MB
[2024-07-03 03:10:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000019	 wd 0.0000	time 0.2982 (0.3536)	loss 1.2256 (1.2700)	grad_norm 3.4191 (nan)	loss_scale 512.0000 (561.7465)	mem 12172MB
[2024-07-03 03:11:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 17 training takes 0:14:48
[2024-07-03 03:11:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 16.966 (16.966)	Loss 0.3970 (0.3970)	Acc@1 92.969 (92.969)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-03 03:11:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.920 Acc@5 97.484
[2024-07-03 03:11:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-03 03:11:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-03 03:11:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][0/2502]	eta 12:54:49 lr 0.000019	 wd 0.0000	time 18.5809 (18.5809)	loss 1.4702 (1.4702)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 03:12:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:20:59 lr 0.000019	 wd 0.0000	time 0.3189 (0.5242)	loss 1.4697 (1.3057)	grad_norm 5.3624 (4.8636)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 03:12:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:16:39 lr 0.000019	 wd 0.0000	time 0.3297 (0.4344)	loss 1.4157 (1.2830)	grad_norm 5.0484 (4.8130)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 03:13:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:14:54 lr 0.000019	 wd 0.0000	time 0.3086 (0.4063)	loss 1.4477 (1.2800)	grad_norm 3.9072 (4.8858)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 03:14:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:13:39 lr 0.000019	 wd 0.0000	time 0.3258 (0.3901)	loss 1.3245 (1.2769)	grad_norm 4.1470 (4.9019)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 03:14:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:12:43 lr 0.000018	 wd 0.0000	time 0.3328 (0.3813)	loss 1.1875 (1.2712)	grad_norm 4.8596 (4.8875)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 03:15:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:12:00 lr 0.000018	 wd 0.0000	time 0.3284 (0.3788)	loss 1.5271 (1.2706)	grad_norm 3.1850 (4.8649)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 03:15:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:11:12 lr 0.000018	 wd 0.0000	time 0.3096 (0.3733)	loss 1.5189 (1.2722)	grad_norm 4.0554 (4.8480)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 03:16:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:10:27 lr 0.000018	 wd 0.0000	time 0.3270 (0.3690)	loss 1.0215 (1.2693)	grad_norm 4.4749 (4.8295)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 03:17:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:09:47 lr 0.000018	 wd 0.0000	time 0.3066 (0.3665)	loss 1.3101 (1.2664)	grad_norm 5.2342 (4.8345)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 03:17:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:09:06 lr 0.000018	 wd 0.0000	time 0.2975 (0.3641)	loss 1.0451 (1.2702)	grad_norm 7.0158 (4.8229)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 03:18:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:08:27 lr 0.000018	 wd 0.0000	time 0.3293 (0.3620)	loss 1.2178 (1.2688)	grad_norm 3.4626 (4.7991)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 03:18:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:07:50 lr 0.000018	 wd 0.0000	time 0.3305 (0.3616)	loss 1.4080 (1.2690)	grad_norm 4.2490 (4.8280)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 03:19:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:07:12 lr 0.000018	 wd 0.0000	time 0.3327 (0.3600)	loss 1.4708 (1.2698)	grad_norm 4.6811 (4.8412)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 03:19:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:06:37 lr 0.000018	 wd 0.0000	time 0.2990 (0.3610)	loss 1.0983 (1.2692)	grad_norm 3.6780 (4.8504)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 03:20:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:06:00 lr 0.000017	 wd 0.0000	time 0.3101 (0.3598)	loss 1.4199 (1.2675)	grad_norm 8.6310 (4.8260)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 03:21:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:05:23 lr 0.000017	 wd 0.0000	time 0.3311 (0.3585)	loss 1.5372 (1.2675)	grad_norm 4.5084 (4.8488)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 03:21:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:04:46 lr 0.000017	 wd 0.0000	time 0.3120 (0.3577)	loss 1.4153 (1.2663)	grad_norm 5.5742 (4.8388)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 03:22:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:04:10 lr 0.000017	 wd 0.0000	time 0.3391 (0.3569)	loss 1.2924 (1.2678)	grad_norm 3.3722 (4.8566)	loss_scale 1024.0000 (529.0572)	mem 12172MB
[2024-07-03 03:22:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:03:34 lr 0.000017	 wd 0.0000	time 0.3214 (0.3560)	loss 1.4433 (1.2679)	grad_norm 4.1229 (4.8440)	loss_scale 1024.0000 (555.0931)	mem 12172MB
[2024-07-03 03:23:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:02:58 lr 0.000017	 wd 0.0000	time 0.2916 (0.3563)	loss 1.3148 (1.2698)	grad_norm 3.1670 (4.8466)	loss_scale 1024.0000 (578.5267)	mem 12172MB
[2024-07-03 03:23:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:02:22 lr 0.000017	 wd 0.0000	time 0.3348 (0.3556)	loss 1.2930 (1.2693)	grad_norm 4.2245 (4.8510)	loss_scale 1024.0000 (599.7297)	mem 12172MB
[2024-07-03 03:24:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:47 lr 0.000017	 wd 0.0000	time 0.3218 (0.3550)	loss 1.3674 (1.2692)	grad_norm 14.1120 (4.8768)	loss_scale 1024.0000 (619.0059)	mem 12172MB
[2024-07-03 03:25:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:01:11 lr 0.000017	 wd 0.0000	time 0.3098 (0.3548)	loss 1.3470 (1.2692)	grad_norm 4.8536 (4.8833)	loss_scale 1024.0000 (636.6067)	mem 12172MB
[2024-07-03 03:25:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:36 lr 0.000017	 wd 0.0000	time 0.3045 (0.3542)	loss 1.4486 (1.2709)	grad_norm 6.8632 (4.9020)	loss_scale 1024.0000 (652.7414)	mem 12172MB
[2024-07-03 03:26:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.3335 (0.3535)	loss 1.4589 (1.2707)	grad_norm 4.3732 (4.9085)	loss_scale 1024.0000 (667.5858)	mem 12172MB
[2024-07-03 03:26:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 18 training takes 0:14:47
[2024-07-03 03:26:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 19.187 (19.187)	Loss 0.3914 (0.3914)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-03 03:26:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.870 Acc@5 97.468
[2024-07-03 03:26:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-03 03:26:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-03 03:27:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][0/2502]	eta 11:09:05 lr 0.000016	 wd 0.0000	time 16.0455 (16.0455)	loss 1.3662 (1.3662)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:27:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:20:00 lr 0.000016	 wd 0.0000	time 0.3291 (0.4997)	loss 1.0456 (1.2767)	grad_norm 4.6317 (5.1563)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:28:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:16:10 lr 0.000016	 wd 0.0000	time 0.3328 (0.4218)	loss 1.4729 (1.2735)	grad_norm 4.8928 (5.2401)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:28:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:14:29 lr 0.000016	 wd 0.0000	time 0.3090 (0.3949)	loss 1.2961 (1.2827)	grad_norm 5.6404 (5.1523)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:29:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:13:20 lr 0.000016	 wd 0.0000	time 0.3202 (0.3807)	loss 1.4732 (1.2830)	grad_norm 4.7333 (5.0650)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:29:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:12:28 lr 0.000016	 wd 0.0000	time 0.3125 (0.3737)	loss 1.5314 (1.2815)	grad_norm 5.4516 (4.9669)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:30:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:11:41 lr 0.000016	 wd 0.0000	time 0.3239 (0.3686)	loss 1.5148 (1.2770)	grad_norm 5.5941 (5.0005)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:31:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:10:57 lr 0.000016	 wd 0.0000	time 0.3047 (0.3650)	loss 1.5344 (1.2789)	grad_norm 4.2733 (4.9716)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:31:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:10:18 lr 0.000016	 wd 0.0000	time 0.3317 (0.3633)	loss 1.2216 (1.2754)	grad_norm 4.3994 (5.0037)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:32:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:09:38 lr 0.000016	 wd 0.0000	time 0.3165 (0.3612)	loss 1.3660 (1.2770)	grad_norm 3.9666 (5.0040)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:32:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:08:59 lr 0.000016	 wd 0.0000	time 0.3191 (0.3589)	loss 1.4230 (1.2796)	grad_norm 5.9045 (4.9674)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:33:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:08:22 lr 0.000015	 wd 0.0000	time 0.3341 (0.3584)	loss 0.8237 (1.2776)	grad_norm 3.7326 (4.9851)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:33:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:07:45 lr 0.000015	 wd 0.0000	time 0.3404 (0.3573)	loss 1.0232 (1.2752)	grad_norm 4.4107 (4.9820)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:34:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:07:08 lr 0.000015	 wd 0.0000	time 0.3662 (0.3567)	loss 1.3408 (1.2751)	grad_norm 4.4952 (4.9830)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:35:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:06:32 lr 0.000015	 wd 0.0000	time 0.2954 (0.3565)	loss 1.3001 (1.2762)	grad_norm 5.2578 (4.9759)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:35:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:05:56 lr 0.000015	 wd 0.0000	time 0.3212 (0.3557)	loss 1.1794 (1.2760)	grad_norm 6.4729 (4.9902)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:36:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:05:20 lr 0.000015	 wd 0.0000	time 0.3258 (0.3553)	loss 1.2638 (1.2768)	grad_norm 5.2856 (4.9943)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:36:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:04:45 lr 0.000015	 wd 0.0000	time 0.2982 (0.3556)	loss 1.4059 (1.2775)	grad_norm 6.2788 (4.9846)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:37:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:04:08 lr 0.000015	 wd 0.0000	time 0.3032 (0.3547)	loss 1.2429 (1.2773)	grad_norm 5.0514 (4.9674)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:38:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:03:34 lr 0.000015	 wd 0.0000	time 0.2870 (0.3560)	loss 1.2814 (1.2778)	grad_norm 3.8223 (4.9541)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:38:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:02:58 lr 0.000015	 wd 0.0000	time 0.3271 (0.3558)	loss 0.8851 (1.2772)	grad_norm 5.7131 (4.9756)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:39:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:02:22 lr 0.000014	 wd 0.0000	time 0.3418 (0.3549)	loss 1.1110 (1.2768)	grad_norm 4.9208 (4.9859)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:39:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:47 lr 0.000014	 wd 0.0000	time 0.3444 (0.3552)	loss 1.3751 (1.2751)	grad_norm 3.8579 (4.9777)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:40:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:01:11 lr 0.000014	 wd 0.0000	time 0.3075 (0.3552)	loss 1.3257 (1.2746)	grad_norm 4.4995 (4.9664)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:40:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:36 lr 0.000014	 wd 0.0000	time 0.2848 (0.3544)	loss 1.4229 (1.2757)	grad_norm 3.9426 (4.9714)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:41:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.3082 (0.3542)	loss 1.1856 (1.2757)	grad_norm 8.4079 (4.9483)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:41:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 19 training takes 0:14:54
[2024-07-03 03:41:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 16.667 (16.667)	Loss 0.3862 (0.3862)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-03 03:42:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 85.042 Acc@5 97.478
[2024-07-03 03:42:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-03 03:42:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.04%
[2024-07-03 03:42:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune/ckpt_epoch_best.pth saving......
[2024-07-03 03:42:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune/ckpt_epoch_best.pth saved !!!
[2024-07-03 03:42:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][0/2502]	eta 10:18:02 lr 0.000014	 wd 0.0000	time 14.8210 (14.8210)	loss 0.9900 (0.9900)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:43:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:20:11 lr 0.000014	 wd 0.0000	time 0.3364 (0.5044)	loss 1.6562 (1.2667)	grad_norm 5.6115 (4.5862)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:43:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:16:24 lr 0.000014	 wd 0.0000	time 0.3060 (0.4276)	loss 1.2872 (1.2726)	grad_norm 4.5277 (4.9914)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:44:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:14:39 lr 0.000014	 wd 0.0000	time 0.2964 (0.3995)	loss 1.3384 (1.2721)	grad_norm 3.9636 (4.8311)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:44:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:13:38 lr 0.000014	 wd 0.0000	time 0.3112 (0.3895)	loss 1.4377 (1.2792)	grad_norm 3.3468 (4.8376)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:45:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:12:39 lr 0.000014	 wd 0.0000	time 0.3349 (0.3794)	loss 1.3082 (1.2781)	grad_norm 4.9155 (4.9907)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:45:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:11:48 lr 0.000014	 wd 0.0000	time 0.3182 (0.3726)	loss 1.3917 (1.2743)	grad_norm 4.7693 (4.9467)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:46:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:11:14 lr 0.000013	 wd 0.0000	time 0.3277 (0.3744)	loss 1.3951 (1.2798)	grad_norm 3.7615 (5.0377)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 03:47:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:10:30 lr 0.000013	 wd 0.0000	time 0.3434 (0.3703)	loss 1.1964 (1.2772)	grad_norm 3.1876 (5.0025)	loss_scale 2048.0000 (1105.8177)	mem 12172MB
[2024-07-03 03:47:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:09:48 lr 0.000013	 wd 0.0000	time 0.3559 (0.3675)	loss 1.5307 (1.2805)	grad_norm 3.3558 (5.0042)	loss_scale 2048.0000 (1210.3885)	mem 12172MB
[2024-07-03 03:48:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:09:11 lr 0.000013	 wd 0.0000	time 0.3383 (0.3675)	loss 1.2997 (1.2800)	grad_norm 4.2528 (5.0260)	loss_scale 2048.0000 (1294.0659)	mem 12172MB
[2024-07-03 03:48:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:08:31 lr 0.000013	 wd 0.0000	time 0.3290 (0.3651)	loss 1.3706 (1.2775)	grad_norm 4.1406 (5.0495)	loss_scale 2048.0000 (1362.5431)	mem 12172MB
[2024-07-03 03:49:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:07:58 lr 0.000013	 wd 0.0000	time 0.3337 (0.3674)	loss 1.2995 (1.2747)	grad_norm 4.1750 (5.0269)	loss_scale 2048.0000 (1419.6170)	mem 12172MB
[2024-07-03 03:50:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:07:19 lr 0.000013	 wd 0.0000	time 0.3299 (0.3653)	loss 1.1174 (1.2715)	grad_norm 14.5959 (5.0160)	loss_scale 2048.0000 (1467.9170)	mem 12172MB
[2024-07-03 03:50:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:06:40 lr 0.000013	 wd 0.0000	time 0.3214 (0.3635)	loss 1.2515 (1.2730)	grad_norm 4.4171 (5.0227)	loss_scale 2048.0000 (1509.3219)	mem 12172MB
[2024-07-03 03:51:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:06:03 lr 0.000013	 wd 0.0000	time 0.3603 (0.3631)	loss 1.1687 (1.2745)	grad_norm 7.0106 (5.0204)	loss_scale 2048.0000 (1545.2099)	mem 12172MB
[2024-07-03 03:51:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:05:26 lr 0.000013	 wd 0.0000	time 0.3362 (0.3623)	loss 1.4160 (1.2752)	grad_norm 4.6185 (5.0224)	loss_scale 2048.0000 (1576.6146)	mem 12172MB
[2024-07-03 03:52:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:04:49 lr 0.000012	 wd 0.0000	time 0.3215 (0.3611)	loss 1.4812 (1.2749)	grad_norm 4.4226 (4.9826)	loss_scale 2048.0000 (1604.3269)	mem 12172MB
[2024-07-03 03:53:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:04:15 lr 0.000012	 wd 0.0000	time 0.3245 (0.3645)	loss 1.2106 (1.2742)	grad_norm 5.1328 (4.9797)	loss_scale 2048.0000 (1628.9617)	mem 12172MB
[2024-07-03 03:53:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:03:38 lr 0.000012	 wd 0.0000	time 0.3053 (0.3633)	loss 1.5217 (1.2750)	grad_norm 3.4847 (4.9803)	loss_scale 2048.0000 (1651.0047)	mem 12172MB
[2024-07-03 03:54:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:03:01 lr 0.000012	 wd 0.0000	time 0.3286 (0.3622)	loss 1.3809 (1.2744)	grad_norm 4.9365 (4.9608)	loss_scale 2048.0000 (1670.8446)	mem 12172MB
[2024-07-03 03:54:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:02:25 lr 0.000012	 wd 0.0000	time 0.3287 (0.3627)	loss 1.3576 (1.2751)	grad_norm 4.7281 (4.9664)	loss_scale 2048.0000 (1688.7958)	mem 12172MB
[2024-07-03 03:55:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:49 lr 0.000012	 wd 0.0000	time 0.3083 (0.3620)	loss 1.1934 (1.2765)	grad_norm 4.2119 (4.9973)	loss_scale 2048.0000 (1705.1159)	mem 12172MB
[2024-07-03 03:56:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:01:13 lr 0.000012	 wd 0.0000	time 0.3399 (0.3617)	loss 1.2396 (1.2769)	grad_norm 3.8865 (4.9903)	loss_scale 2048.0000 (1720.0174)	mem 12172MB
[2024-07-03 03:56:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:36 lr 0.000012	 wd 0.0000	time 0.3225 (0.3609)	loss 1.1893 (1.2772)	grad_norm 3.5082 (4.9958)	loss_scale 2048.0000 (1733.6776)	mem 12172MB
[2024-07-03 03:57:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000012	 wd 0.0000	time 0.3026 (0.3598)	loss 1.4086 (1.2779)	grad_norm 4.9263 (5.0087)	loss_scale 2048.0000 (1746.2455)	mem 12172MB
[2024-07-03 03:57:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 20 training takes 0:15:04
[2024-07-03 03:57:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 17.210 (17.210)	Loss 0.3997 (0.3997)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-03 03:57:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.898 Acc@5 97.492
[2024-07-03 03:57:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-03 03:57:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.04%
[2024-07-03 03:58:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][0/2502]	eta 11:01:10 lr 0.000012	 wd 0.0000	time 15.8555 (15.8555)	loss 1.4550 (1.4550)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 03:58:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:19:51 lr 0.000012	 wd 0.0000	time 0.3054 (0.4960)	loss 1.4985 (1.3097)	grad_norm 3.2671 (5.0915)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 03:59:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:16:11 lr 0.000012	 wd 0.0000	time 0.3169 (0.4220)	loss 0.9140 (1.2799)	grad_norm 3.5526 (4.9812)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 03:59:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:14:32 lr 0.000012	 wd 0.0000	time 0.2851 (0.3963)	loss 1.3612 (1.2727)	grad_norm 6.5606 (4.8752)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 04:00:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:13:30 lr 0.000011	 wd 0.0000	time 0.3106 (0.3854)	loss 1.2551 (1.2753)	grad_norm 3.6131 (4.8329)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 04:01:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:12:45 lr 0.000011	 wd 0.0000	time 0.3438 (0.3825)	loss 1.2263 (1.2740)	grad_norm 3.7383 (4.8997)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 04:01:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:11:57 lr 0.000011	 wd 0.0000	time 0.3250 (0.3772)	loss 1.1615 (1.2761)	grad_norm 4.8801 (4.9149)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 04:02:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:11:09 lr 0.000011	 wd 0.0000	time 0.3175 (0.3717)	loss 1.1940 (1.2704)	grad_norm 5.1337 (4.9882)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 04:02:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:10:31 lr 0.000011	 wd 0.0000	time 0.3928 (0.3710)	loss 1.1831 (1.2687)	grad_norm 3.7059 (5.0518)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 04:03:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:09:50 lr 0.000011	 wd 0.0000	time 0.3160 (0.3683)	loss 1.4863 (1.2682)	grad_norm 4.4482 (5.0787)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 04:03:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:09:08 lr 0.000011	 wd 0.0000	time 0.3313 (0.3651)	loss 1.0412 (1.2674)	grad_norm 4.0357 (5.1051)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 04:04:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:08:29 lr 0.000011	 wd 0.0000	time 0.2974 (0.3638)	loss 1.3692 (1.2678)	grad_norm 3.5306 (5.0945)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 04:05:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:07:51 lr 0.000011	 wd 0.0000	time 0.3086 (0.3618)	loss 1.3508 (1.2680)	grad_norm 4.2297 (5.0773)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 04:05:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:07:12 lr 0.000011	 wd 0.0000	time 0.3548 (0.3601)	loss 1.4765 (1.2674)	grad_norm 4.5823 (5.1683)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 04:06:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:06:35 lr 0.000011	 wd 0.0000	time 0.3029 (0.3593)	loss 1.2553 (1.2682)	grad_norm 3.4139 (5.1417)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 04:06:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:05:58 lr 0.000010	 wd 0.0000	time 0.3034 (0.3580)	loss 1.5827 (1.2679)	grad_norm 3.6239 (5.1548)	loss_scale 2048.0000 (2048.0000)	mem 12172MB
[2024-07-03 04:07:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:05:21 lr 0.000010	 wd 0.0000	time 0.3109 (0.3568)	loss 1.2175 (1.2674)	grad_norm 7.1456 (nan)	loss_scale 1024.0000 (2028.8120)	mem 12172MB
[2024-07-03 04:07:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:04:46 lr 0.000010	 wd 0.0000	time 0.3080 (0.3567)	loss 1.4120 (1.2681)	grad_norm 3.8429 (nan)	loss_scale 1024.0000 (1969.7402)	mem 12172MB
[2024-07-03 04:08:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:04:09 lr 0.000010	 wd 0.0000	time 0.3255 (0.3558)	loss 1.0127 (1.2692)	grad_norm 5.0404 (nan)	loss_scale 1024.0000 (1917.2282)	mem 12172MB
[2024-07-03 04:09:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:03:33 lr 0.000010	 wd 0.0000	time 0.3141 (0.3548)	loss 1.0216 (1.2676)	grad_norm 4.0160 (nan)	loss_scale 1024.0000 (1870.2409)	mem 12172MB
[2024-07-03 04:09:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:02:57 lr 0.000010	 wd 0.0000	time 0.3040 (0.3544)	loss 1.2993 (1.2671)	grad_norm 3.3630 (nan)	loss_scale 1024.0000 (1827.9500)	mem 12172MB
[2024-07-03 04:10:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:02:22 lr 0.000010	 wd 0.0000	time 0.3317 (0.3537)	loss 1.1015 (1.2687)	grad_norm 5.8976 (nan)	loss_scale 1024.0000 (1789.6849)	mem 12172MB
[2024-07-03 04:10:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:46 lr 0.000010	 wd 0.0000	time 0.3763 (0.3536)	loss 1.5517 (1.2671)	grad_norm 4.0718 (nan)	loss_scale 1024.0000 (1754.8969)	mem 12172MB
[2024-07-03 04:11:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:01:11 lr 0.000010	 wd 0.0000	time 0.3327 (0.3531)	loss 1.5363 (1.2663)	grad_norm 3.6914 (nan)	loss_scale 1024.0000 (1723.1326)	mem 12172MB
[2024-07-03 04:11:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:36 lr 0.000010	 wd 0.0000	time 0.3298 (0.3532)	loss 1.2903 (1.2678)	grad_norm 3.1223 (nan)	loss_scale 1024.0000 (1694.0142)	mem 12172MB
[2024-07-03 04:12:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.3256 (0.3527)	loss 1.3518 (1.2671)	grad_norm 4.2528 (nan)	loss_scale 1024.0000 (1667.2243)	mem 12172MB
[2024-07-03 04:12:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 21 training takes 0:14:55
[2024-07-03 04:13:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 17.546 (17.546)	Loss 0.3899 (0.3899)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-03 04:13:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.982 Acc@5 97.512
[2024-07-03 04:13:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-03 04:13:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.04%
[2024-07-03 04:13:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][0/2502]	eta 11:31:05 lr 0.000010	 wd 0.0000	time 16.5729 (16.5729)	loss 1.1642 (1.1642)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:14:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:20:12 lr 0.000010	 wd 0.0000	time 0.3103 (0.5047)	loss 1.2689 (1.2875)	grad_norm 8.4081 (5.8525)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:14:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:16:15 lr 0.000009	 wd 0.0000	time 0.3020 (0.4237)	loss 0.9490 (1.2749)	grad_norm 4.4959 (5.2987)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:15:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:14:30 lr 0.000009	 wd 0.0000	time 0.3137 (0.3953)	loss 1.4283 (1.2791)	grad_norm 4.0843 (5.0601)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:15:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:13:22 lr 0.000009	 wd 0.0000	time 0.3822 (0.3816)	loss 1.2662 (1.2831)	grad_norm 11.7841 (5.1567)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:16:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:12:27 lr 0.000009	 wd 0.0000	time 0.3226 (0.3732)	loss 0.9701 (1.2825)	grad_norm 3.5618 (5.1756)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:17:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:11:42 lr 0.000009	 wd 0.0000	time 0.3064 (0.3696)	loss 1.3815 (1.2830)	grad_norm 3.9163 (5.0984)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:17:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:11:00 lr 0.000009	 wd 0.0000	time 0.3302 (0.3667)	loss 0.8484 (1.2771)	grad_norm 5.1405 (5.1479)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:18:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:10:19 lr 0.000009	 wd 0.0000	time 0.3262 (0.3642)	loss 1.2311 (1.2724)	grad_norm 3.8882 (5.0698)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:18:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:09:41 lr 0.000009	 wd 0.0000	time 0.3128 (0.3628)	loss 1.2466 (1.2706)	grad_norm 6.7155 (nan)	loss_scale 512.0000 (1010.3618)	mem 12172MB
[2024-07-03 04:19:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:09:02 lr 0.000009	 wd 0.0000	time 0.3193 (0.3612)	loss 1.4059 (1.2726)	grad_norm 4.5131 (nan)	loss_scale 512.0000 (960.5754)	mem 12172MB
[2024-07-03 04:19:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:08:23 lr 0.000009	 wd 0.0000	time 0.3273 (0.3593)	loss 1.2682 (1.2709)	grad_norm 4.4465 (nan)	loss_scale 512.0000 (919.8329)	mem 12172MB
[2024-07-03 04:20:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:07:45 lr 0.000009	 wd 0.0000	time 0.2884 (0.3574)	loss 1.2415 (1.2698)	grad_norm 5.6939 (nan)	loss_scale 512.0000 (885.8751)	mem 12172MB
[2024-07-03 04:21:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:07:12 lr 0.000009	 wd 0.0000	time 0.3091 (0.3597)	loss 0.9331 (1.2706)	grad_norm 3.4967 (nan)	loss_scale 512.0000 (857.1376)	mem 12172MB
[2024-07-03 04:21:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:06:35 lr 0.000008	 wd 0.0000	time 0.3381 (0.3591)	loss 1.4405 (1.2722)	grad_norm 4.1797 (nan)	loss_scale 512.0000 (832.5025)	mem 12172MB
[2024-07-03 04:22:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:05:59 lr 0.000008	 wd 0.0000	time 0.7035 (0.3592)	loss 1.0816 (1.2725)	grad_norm 4.2801 (nan)	loss_scale 512.0000 (811.1499)	mem 12172MB
[2024-07-03 04:22:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:05:23 lr 0.000008	 wd 0.0000	time 0.3418 (0.3592)	loss 1.4509 (1.2725)	grad_norm 5.7927 (nan)	loss_scale 512.0000 (792.4647)	mem 12172MB
[2024-07-03 04:23:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:04:47 lr 0.000008	 wd 0.0000	time 0.3139 (0.3581)	loss 1.2355 (1.2717)	grad_norm 7.8837 (nan)	loss_scale 512.0000 (775.9765)	mem 12172MB
[2024-07-03 04:24:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:04:10 lr 0.000008	 wd 0.0000	time 0.3338 (0.3570)	loss 1.5269 (1.2715)	grad_norm 4.5165 (nan)	loss_scale 512.0000 (761.3193)	mem 12172MB
[2024-07-03 04:24:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:03:34 lr 0.000008	 wd 0.0000	time 0.3135 (0.3569)	loss 1.4653 (1.2708)	grad_norm 6.3091 (nan)	loss_scale 512.0000 (748.2041)	mem 12172MB
[2024-07-03 04:25:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:02:58 lr 0.000008	 wd 0.0000	time 0.2988 (0.3559)	loss 1.3429 (1.2698)	grad_norm 3.5713 (nan)	loss_scale 512.0000 (736.3998)	mem 12172MB
[2024-07-03 04:25:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:02:22 lr 0.000008	 wd 0.0000	time 0.3167 (0.3557)	loss 1.4032 (1.2703)	grad_norm 6.4643 (nan)	loss_scale 512.0000 (725.7192)	mem 12172MB
[2024-07-03 04:26:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:47 lr 0.000008	 wd 0.0000	time 0.3085 (0.3550)	loss 1.3880 (1.2693)	grad_norm 4.1915 (nan)	loss_scale 512.0000 (716.0091)	mem 12172MB
[2024-07-03 04:26:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:01:11 lr 0.000008	 wd 0.0000	time 0.3163 (0.3542)	loss 1.5022 (1.2695)	grad_norm 4.4467 (nan)	loss_scale 512.0000 (707.1430)	mem 12172MB
[2024-07-03 04:27:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:36 lr 0.000008	 wd 0.0000	time 0.3629 (0.3537)	loss 1.0062 (1.2690)	grad_norm 3.5884 (nan)	loss_scale 512.0000 (699.0154)	mem 12172MB
[2024-07-03 04:28:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.3336 (0.3531)	loss 0.9917 (1.2683)	grad_norm 3.9976 (nan)	loss_scale 512.0000 (691.5378)	mem 12172MB
[2024-07-03 04:28:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 22 training takes 0:14:51
[2024-07-03 04:28:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 16.809 (16.809)	Loss 0.3914 (0.3914)	Acc@1 92.969 (92.969)	Acc@5 98.828 (98.828)	Mem 12172MB
[2024-07-03 04:28:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 84.956 Acc@5 97.532
[2024-07-03 04:28:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-03 04:28:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.04%
[2024-07-03 04:29:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][0/2502]	eta 16:11:09 lr 0.000008	 wd 0.0000	time 23.2893 (23.2893)	loss 1.0175 (1.0175)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:29:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:22:51 lr 0.000008	 wd 0.0000	time 0.2970 (0.5712)	loss 1.3958 (1.3081)	grad_norm 18.0078 (5.3061)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:30:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:17:36 lr 0.000007	 wd 0.0000	time 0.3179 (0.4590)	loss 1.4381 (1.2874)	grad_norm 5.5387 (5.2961)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:30:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:15:43 lr 0.000007	 wd 0.0000	time 0.3513 (0.4284)	loss 1.2863 (1.2832)	grad_norm 4.8285 (5.2302)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:31:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:14:15 lr 0.000007	 wd 0.0000	time 0.3048 (0.4068)	loss 1.6177 (1.2774)	grad_norm 4.0893 (5.2036)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:31:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:13:08 lr 0.000007	 wd 0.0000	time 0.3147 (0.3936)	loss 1.5236 (1.2810)	grad_norm 7.3805 (5.1329)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:32:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:12:20 lr 0.000007	 wd 0.0000	time 0.3255 (0.3895)	loss 1.1268 (1.2807)	grad_norm 3.9329 (5.0579)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:33:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:11:29 lr 0.000007	 wd 0.0000	time 0.3345 (0.3827)	loss 1.4235 (1.2779)	grad_norm 5.4459 (5.1552)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:33:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:10:42 lr 0.000007	 wd 0.0000	time 0.3221 (0.3776)	loss 1.5887 (1.2758)	grad_norm 3.6468 (5.1665)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:34:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:10:02 lr 0.000007	 wd 0.0000	time 0.3072 (0.3763)	loss 1.5806 (1.2728)	grad_norm 6.3227 (5.1991)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:34:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:09:19 lr 0.000007	 wd 0.0000	time 0.2877 (0.3726)	loss 1.0052 (1.2724)	grad_norm 4.3319 (5.1845)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:35:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:08:39 lr 0.000007	 wd 0.0000	time 0.2959 (0.3707)	loss 0.7896 (1.2674)	grad_norm 19.9731 (5.1973)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:36:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:08:00 lr 0.000007	 wd 0.0000	time 0.3455 (0.3691)	loss 1.4970 (1.2693)	grad_norm 4.5964 (5.2519)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:36:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:07:20 lr 0.000007	 wd 0.0000	time 0.3067 (0.3668)	loss 1.4597 (1.2704)	grad_norm 8.7787 (5.2146)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:37:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:06:42 lr 0.000007	 wd 0.0000	time 0.3246 (0.3656)	loss 1.2752 (1.2698)	grad_norm 4.0612 (5.1827)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:37:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:06:04 lr 0.000006	 wd 0.0000	time 0.3157 (0.3637)	loss 1.1512 (1.2714)	grad_norm 5.0494 (5.1488)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:38:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:05:26 lr 0.000006	 wd 0.0000	time 0.3259 (0.3623)	loss 1.1557 (1.2714)	grad_norm 5.3284 (5.1692)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:38:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:04:50 lr 0.000006	 wd 0.0000	time 0.2941 (0.3628)	loss 1.2789 (1.2720)	grad_norm 3.9151 (5.1583)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:39:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:04:14 lr 0.000006	 wd 0.0000	time 0.9791 (0.3622)	loss 1.2841 (1.2713)	grad_norm 4.4626 (5.1763)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:40:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:03:37 lr 0.000006	 wd 0.0000	time 0.2972 (0.3611)	loss 1.1592 (1.2736)	grad_norm 5.2503 (5.1507)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:40:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:03:01 lr 0.000006	 wd 0.0000	time 0.3176 (0.3606)	loss 1.3208 (1.2727)	grad_norm 3.9500 (5.1430)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:41:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:02:24 lr 0.000006	 wd 0.0000	time 0.3033 (0.3596)	loss 1.5936 (1.2727)	grad_norm 5.9256 (5.1601)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:41:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:48 lr 0.000006	 wd 0.0000	time 0.3417 (0.3587)	loss 1.4164 (1.2701)	grad_norm 5.2035 (5.1945)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:42:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:01:12 lr 0.000006	 wd 0.0000	time 0.3072 (0.3583)	loss 1.4378 (1.2699)	grad_norm 5.7630 (5.1822)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 04:42:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:36 lr 0.000006	 wd 0.0000	time 0.3135 (0.3574)	loss 1.4664 (1.2704)	grad_norm 3.7222 (5.1748)	loss_scale 1024.0000 (517.5444)	mem 12172MB
[2024-07-03 04:43:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000006	 wd 0.0000	time 0.3026 (0.3565)	loss 1.3693 (1.2712)	grad_norm 8.4264 (5.1672)	loss_scale 1024.0000 (537.7945)	mem 12172MB
[2024-07-03 04:43:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 23 training takes 0:14:59
[2024-07-03 04:43:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 18.300 (18.300)	Loss 0.3879 (0.3879)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 12172MB
[2024-07-03 04:44:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 85.030 Acc@5 97.522
[2024-07-03 04:44:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-03 04:44:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.04%
[2024-07-03 04:44:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][0/2502]	eta 11:33:35 lr 0.000006	 wd 0.0000	time 16.6330 (16.6330)	loss 1.4927 (1.4927)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:45:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:20:09 lr 0.000006	 wd 0.0000	time 0.2963 (0.5036)	loss 1.1475 (1.3004)	grad_norm 6.4478 (4.7350)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:45:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:16:41 lr 0.000006	 wd 0.0000	time 0.3225 (0.4349)	loss 1.5383 (1.2893)	grad_norm 6.5788 (4.8907)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:46:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:14:45 lr 0.000006	 wd 0.0000	time 0.3644 (0.4022)	loss 1.5463 (1.2799)	grad_norm 4.8064 (4.9524)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:46:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:13:31 lr 0.000005	 wd 0.0000	time 0.3039 (0.3861)	loss 1.3382 (1.2747)	grad_norm 3.9426 (4.9225)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:47:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:12:35 lr 0.000005	 wd 0.0000	time 0.3035 (0.3772)	loss 1.4639 (1.2770)	grad_norm 3.8988 (4.9364)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:47:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:11:45 lr 0.000005	 wd 0.0000	time 0.3015 (0.3709)	loss 1.2772 (1.2731)	grad_norm 5.1792 (4.8997)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:48:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:11:00 lr 0.000005	 wd 0.0000	time 0.3504 (0.3663)	loss 1.2345 (1.2748)	grad_norm 5.7308 (4.8951)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:49:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:10:21 lr 0.000005	 wd 0.0000	time 0.3087 (0.3652)	loss 1.3343 (1.2754)	grad_norm 4.8323 (4.8850)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:49:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:09:44 lr 0.000005	 wd 0.0000	time 1.6433 (0.3648)	loss 1.3343 (1.2734)	grad_norm 3.8032 (4.8823)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 04:50:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:09:07 lr 0.000005	 wd 0.0000	time 0.3154 (0.3648)	loss 1.2491 (1.2736)	grad_norm 4.1281 (inf)	loss_scale 512.0000 (997.4026)	mem 12172MB
[2024-07-03 04:50:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:08:30 lr 0.000005	 wd 0.0000	time 0.2925 (0.3640)	loss 1.3996 (1.2722)	grad_norm 6.0857 (inf)	loss_scale 512.0000 (953.3152)	mem 12172MB
[2024-07-03 04:51:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:07:51 lr 0.000005	 wd 0.0000	time 0.2869 (0.3622)	loss 1.1164 (1.2713)	grad_norm 3.8442 (inf)	loss_scale 512.0000 (916.5695)	mem 12172MB
[2024-07-03 04:52:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:07:14 lr 0.000005	 wd 0.0000	time 0.2957 (0.3611)	loss 1.1907 (1.2723)	grad_norm 6.2545 (inf)	loss_scale 512.0000 (885.4727)	mem 12172MB
[2024-07-03 04:52:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:06:36 lr 0.000005	 wd 0.0000	time 0.3296 (0.3596)	loss 1.1827 (1.2710)	grad_norm 7.7507 (inf)	loss_scale 512.0000 (858.8151)	mem 12172MB
[2024-07-03 04:53:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:05:58 lr 0.000005	 wd 0.0000	time 0.3178 (0.3581)	loss 0.9390 (1.2699)	grad_norm 4.5855 (inf)	loss_scale 512.0000 (835.7095)	mem 12172MB
[2024-07-03 04:53:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:05:22 lr 0.000005	 wd 0.0000	time 0.3067 (0.3578)	loss 1.3121 (1.2692)	grad_norm 4.8428 (inf)	loss_scale 512.0000 (815.4903)	mem 12172MB
[2024-07-03 04:54:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:04:47 lr 0.000005	 wd 0.0000	time 0.3005 (0.3586)	loss 1.6597 (1.2715)	grad_norm 5.6631 (inf)	loss_scale 512.0000 (797.6484)	mem 12172MB
[2024-07-03 04:54:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:04:11 lr 0.000005	 wd 0.0000	time 0.2865 (0.3581)	loss 1.1278 (1.2708)	grad_norm 6.0647 (inf)	loss_scale 512.0000 (781.7879)	mem 12172MB
[2024-07-03 04:55:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:03:36 lr 0.000005	 wd 0.0000	time 0.3185 (0.3591)	loss 1.3849 (1.2721)	grad_norm 3.7971 (inf)	loss_scale 512.0000 (767.5960)	mem 12172MB
[2024-07-03 04:56:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:02:59 lr 0.000004	 wd 0.0000	time 0.3181 (0.3581)	loss 1.4502 (1.2721)	grad_norm 4.6339 (inf)	loss_scale 512.0000 (754.8226)	mem 12172MB
[2024-07-03 04:56:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:02:23 lr 0.000004	 wd 0.0000	time 0.3348 (0.3571)	loss 1.3941 (1.2707)	grad_norm 4.4441 (inf)	loss_scale 512.0000 (743.2651)	mem 12172MB
[2024-07-03 04:57:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:47 lr 0.000004	 wd 0.0000	time 0.3425 (0.3573)	loss 1.1920 (1.2702)	grad_norm 3.3907 (inf)	loss_scale 512.0000 (732.7578)	mem 12172MB
[2024-07-03 04:57:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:01:12 lr 0.000004	 wd 0.0000	time 0.3313 (0.3566)	loss 1.6033 (1.2698)	grad_norm 3.4650 (inf)	loss_scale 512.0000 (723.1638)	mem 12172MB
[2024-07-03 04:58:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:36 lr 0.000004	 wd 0.0000	time 0.3582 (0.3558)	loss 1.4587 (1.2700)	grad_norm 4.6399 (inf)	loss_scale 512.0000 (714.3690)	mem 12172MB
[2024-07-03 04:59:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000004	 wd 0.0000	time 0.2996 (0.3554)	loss 1.1772 (1.2706)	grad_norm 3.8296 (inf)	loss_scale 512.0000 (706.2775)	mem 12172MB
[2024-07-03 04:59:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 24 training takes 0:15:01
[2024-07-03 04:59:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 17.405 (17.405)	Loss 0.3926 (0.3926)	Acc@1 92.969 (92.969)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-03 04:59:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 85.072 Acc@5 97.528
[2024-07-03 04:59:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-03 04:59:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.07%
[2024-07-03 04:59:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune/ckpt_epoch_best.pth saving......
[2024-07-03 04:59:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune/ckpt_epoch_best.pth saved !!!
[2024-07-03 05:00:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][0/2502]	eta 19:56:24 lr 0.000004	 wd 0.0000	time 28.6908 (28.6908)	loss 1.0152 (1.0152)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:00:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:24:48 lr 0.000004	 wd 0.0000	time 0.2962 (0.6199)	loss 1.2438 (1.2413)	grad_norm 3.9259 (4.4741)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:01:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:18:28 lr 0.000004	 wd 0.0000	time 0.2884 (0.4814)	loss 1.3412 (1.2635)	grad_norm 3.9927 (4.7428)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:02:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:16:25 lr 0.000004	 wd 0.0000	time 0.2934 (0.4475)	loss 0.9354 (1.2582)	grad_norm 3.3664 (5.0084)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:02:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:14:43 lr 0.000004	 wd 0.0000	time 0.3205 (0.4204)	loss 1.2082 (1.2716)	grad_norm 3.7550 (4.8946)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:03:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:13:30 lr 0.000004	 wd 0.0000	time 0.3169 (0.4048)	loss 1.3459 (1.2723)	grad_norm 6.3013 (5.0408)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:03:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:12:36 lr 0.000004	 wd 0.0000	time 0.2965 (0.3979)	loss 1.0840 (1.2738)	grad_norm 4.6901 (5.0478)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:04:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:11:42 lr 0.000004	 wd 0.0000	time 0.3294 (0.3901)	loss 1.1432 (1.2735)	grad_norm 4.8126 (5.0367)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:05:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:10:55 lr 0.000004	 wd 0.0000	time 0.3099 (0.3853)	loss 0.9865 (1.2742)	grad_norm 4.4610 (4.9892)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:05:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:10:10 lr 0.000004	 wd 0.0000	time 0.3263 (0.3814)	loss 1.3319 (1.2765)	grad_norm 3.8043 (5.0062)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:06:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:09:31 lr 0.000004	 wd 0.0000	time 0.3621 (0.3806)	loss 1.2336 (1.2771)	grad_norm 4.0122 (4.9814)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:06:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:08:51 lr 0.000004	 wd 0.0000	time 0.2726 (0.3789)	loss 1.2723 (1.2746)	grad_norm 4.6981 (4.9852)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:07:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:08:09 lr 0.000004	 wd 0.0000	time 0.3416 (0.3763)	loss 1.2250 (1.2759)	grad_norm 5.8886 (4.9706)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:08:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:07:29 lr 0.000003	 wd 0.0000	time 0.2912 (0.3736)	loss 1.4290 (1.2762)	grad_norm 5.7865 (4.9536)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:08:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:06:51 lr 0.000003	 wd 0.0000	time 0.3456 (0.3731)	loss 1.1211 (1.2773)	grad_norm 4.1659 (4.9596)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:09:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:06:11 lr 0.000003	 wd 0.0000	time 0.3289 (0.3711)	loss 1.1664 (1.2764)	grad_norm 3.5382 (4.9496)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:09:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:05:33 lr 0.000003	 wd 0.0000	time 0.3067 (0.3693)	loss 1.4086 (1.2764)	grad_norm 5.7637 (4.9416)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:10:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:04:55 lr 0.000003	 wd 0.0000	time 0.3163 (0.3685)	loss 1.2508 (1.2764)	grad_norm 3.8632 (4.9377)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:10:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:04:17 lr 0.000003	 wd 0.0000	time 0.2988 (0.3670)	loss 1.3099 (1.2757)	grad_norm 4.3885 (4.9265)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:11:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:03:40 lr 0.000003	 wd 0.0000	time 0.3159 (0.3665)	loss 1.5246 (1.2761)	grad_norm 4.4401 (4.9398)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:12:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:03:04 lr 0.000003	 wd 0.0000	time 0.3467 (0.3668)	loss 1.2419 (1.2756)	grad_norm 4.6784 (4.9227)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:12:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:02:26 lr 0.000003	 wd 0.0000	time 0.3316 (0.3655)	loss 0.8121 (1.2756)	grad_norm 5.7119 (4.9119)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:13:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:50 lr 0.000003	 wd 0.0000	time 0.2932 (0.3660)	loss 1.3419 (1.2744)	grad_norm 4.5280 (4.9096)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:13:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:01:13 lr 0.000003	 wd 0.0000	time 0.3135 (0.3658)	loss 1.3655 (1.2730)	grad_norm 3.1840 (4.9408)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:14:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:37 lr 0.000003	 wd 0.0000	time 0.3112 (0.3654)	loss 1.3534 (1.2743)	grad_norm 7.1094 (4.9425)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 05:15:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.3122 (0.3640)	loss 1.4273 (1.2744)	grad_norm 3.6784 (4.9380)	loss_scale 1024.0000 (523.0548)	mem 12172MB
[2024-07-03 05:15:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 25 training takes 0:15:30
[2024-07-03 05:15:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 16.383 (16.383)	Loss 0.3914 (0.3914)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-03 05:15:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 85.038 Acc@5 97.532
[2024-07-03 05:15:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-03 05:15:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.07%
[2024-07-03 05:16:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][0/2502]	eta 10:54:40 lr 0.000003	 wd 0.0000	time 15.6996 (15.6996)	loss 1.0899 (1.0899)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:16:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:20:57 lr 0.000003	 wd 0.0000	time 0.3316 (0.5236)	loss 1.4483 (1.2642)	grad_norm 3.5174 (4.8168)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:17:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:16:47 lr 0.000003	 wd 0.0000	time 0.2965 (0.4376)	loss 1.3810 (1.2893)	grad_norm 5.0278 (4.8588)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:17:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:14:51 lr 0.000003	 wd 0.0000	time 0.3035 (0.4047)	loss 1.2963 (1.2821)	grad_norm 10.8805 (4.8915)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:18:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:13:40 lr 0.000003	 wd 0.0000	time 0.3262 (0.3904)	loss 1.5747 (1.2844)	grad_norm 3.7637 (4.9559)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:19:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:12:39 lr 0.000003	 wd 0.0000	time 0.3003 (0.3794)	loss 1.5981 (1.2919)	grad_norm 7.5676 (4.9639)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:19:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:11:56 lr 0.000003	 wd 0.0000	time 0.3202 (0.3768)	loss 1.2316 (1.2878)	grad_norm 5.5348 (5.1277)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:20:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:11:19 lr 0.000003	 wd 0.0000	time 0.3048 (0.3773)	loss 1.3462 (1.2813)	grad_norm 4.4009 (5.0919)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:20:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:10:34 lr 0.000002	 wd 0.0000	time 0.3082 (0.3730)	loss 1.3244 (1.2782)	grad_norm 7.1435 (5.1052)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:21:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:09:52 lr 0.000002	 wd 0.0000	time 0.3152 (0.3698)	loss 1.3049 (1.2798)	grad_norm 5.6125 (5.0785)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:22:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:09:14 lr 0.000002	 wd 0.0000	time 0.3108 (0.3692)	loss 1.4028 (1.2799)	grad_norm 13.7631 (5.0584)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:22:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:08:33 lr 0.000002	 wd 0.0000	time 0.2994 (0.3665)	loss 1.3770 (1.2816)	grad_norm 4.8458 (5.0363)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:23:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:07:54 lr 0.000002	 wd 0.0000	time 0.3355 (0.3644)	loss 1.0107 (1.2822)	grad_norm 3.8327 (5.1557)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:23:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:07:15 lr 0.000002	 wd 0.0000	time 0.3059 (0.3624)	loss 0.9254 (1.2800)	grad_norm 6.5010 (5.1179)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:24:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:06:37 lr 0.000002	 wd 0.0000	time 0.3301 (0.3606)	loss 1.6875 (1.2800)	grad_norm 4.4924 (5.0902)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:24:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:06:00 lr 0.000002	 wd 0.0000	time 0.3511 (0.3597)	loss 1.4482 (1.2788)	grad_norm 5.4661 (5.1027)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:25:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:05:23 lr 0.000002	 wd 0.0000	time 0.3029 (0.3587)	loss 1.3444 (1.2777)	grad_norm 4.9114 (5.1301)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:26:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:04:46 lr 0.000002	 wd 0.0000	time 0.3110 (0.3576)	loss 1.2747 (1.2781)	grad_norm 5.0838 (5.1194)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:26:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:04:10 lr 0.000002	 wd 0.0000	time 0.3350 (0.3570)	loss 1.3682 (1.2797)	grad_norm 5.2726 (5.0959)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:27:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:03:34 lr 0.000002	 wd 0.0000	time 0.3295 (0.3565)	loss 1.0071 (1.2778)	grad_norm 4.1645 (5.0816)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:27:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:02:58 lr 0.000002	 wd 0.0000	time 0.3376 (0.3555)	loss 1.0971 (1.2776)	grad_norm 4.6521 (5.0770)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:28:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:02:22 lr 0.000002	 wd 0.0000	time 0.3289 (0.3552)	loss 0.9524 (1.2763)	grad_norm 6.4662 (5.0575)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:28:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:47 lr 0.000002	 wd 0.0000	time 0.3220 (0.3545)	loss 0.8619 (1.2760)	grad_norm 3.5871 (5.0595)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:29:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:01:11 lr 0.000002	 wd 0.0000	time 0.3278 (0.3537)	loss 1.0297 (1.2752)	grad_norm 5.3768 (5.0536)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:30:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:36 lr 0.000002	 wd 0.0000	time 0.3286 (0.3539)	loss 1.0473 (1.2749)	grad_norm 6.7336 (5.0805)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:30:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.2996 (0.3550)	loss 0.9866 (1.2734)	grad_norm 4.7360 (5.0804)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:30:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 26 training takes 0:14:56
[2024-07-03 05:31:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 17.801 (17.801)	Loss 0.3887 (0.3887)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-03 05:31:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 85.064 Acc@5 97.558
[2024-07-03 05:31:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-03 05:31:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.07%
[2024-07-03 05:31:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][0/2502]	eta 10:36:47 lr 0.000002	 wd 0.0000	time 15.2706 (15.2706)	loss 0.8462 (0.8462)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:32:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:19:53 lr 0.000002	 wd 0.0000	time 0.3210 (0.4967)	loss 1.3714 (1.2924)	grad_norm 5.2528 (5.0113)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:33:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:16:10 lr 0.000002	 wd 0.0000	time 0.2948 (0.4215)	loss 1.4325 (1.2814)	grad_norm 4.9789 (5.2173)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:33:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:14:28 lr 0.000002	 wd 0.0000	time 0.3806 (0.3945)	loss 1.2105 (1.2740)	grad_norm 4.3356 (5.1907)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:34:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:13:22 lr 0.000002	 wd 0.0000	time 0.3199 (0.3817)	loss 1.2691 (1.2741)	grad_norm 4.1117 (5.0856)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:34:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:12:27 lr 0.000002	 wd 0.0000	time 0.3219 (0.3734)	loss 0.7892 (1.2670)	grad_norm 4.9643 (5.1657)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:35:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:11:43 lr 0.000002	 wd 0.0000	time 0.3690 (0.3697)	loss 1.3150 (1.2682)	grad_norm 3.8281 (5.1124)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:35:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:10:59 lr 0.000002	 wd 0.0000	time 0.2829 (0.3659)	loss 1.3774 (1.2728)	grad_norm 3.3344 (5.1287)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:36:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:10:21 lr 0.000002	 wd 0.0000	time 0.3391 (0.3650)	loss 1.4789 (1.2757)	grad_norm 5.6272 (5.1007)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:37:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:09:40 lr 0.000001	 wd 0.0000	time 0.3179 (0.3626)	loss 1.3261 (1.2804)	grad_norm 4.1411 (5.1069)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:37:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:09:01 lr 0.000001	 wd 0.0000	time 0.3389 (0.3606)	loss 1.3182 (1.2794)	grad_norm 3.9032 (5.0619)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:38:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:08:26 lr 0.000001	 wd 0.0000	time 0.3233 (0.3615)	loss 1.2935 (1.2806)	grad_norm 4.1326 (5.1190)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:38:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:07:49 lr 0.000001	 wd 0.0000	time 0.3733 (0.3603)	loss 1.4676 (1.2806)	grad_norm 6.6393 (5.0918)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:39:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:07:11 lr 0.000001	 wd 0.0000	time 0.3493 (0.3587)	loss 1.3699 (1.2788)	grad_norm 4.2034 (5.0635)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:40:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:06:36 lr 0.000001	 wd 0.0000	time 0.3152 (0.3596)	loss 1.2753 (1.2800)	grad_norm 3.4474 (5.0250)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:40:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:05:59 lr 0.000001	 wd 0.0000	time 0.3116 (0.3584)	loss 1.4107 (1.2799)	grad_norm 5.5346 (5.0387)	loss_scale 2048.0000 (1063.5683)	mem 12172MB
[2024-07-03 05:41:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:05:22 lr 0.000001	 wd 0.0000	time 0.3633 (0.3573)	loss 1.4250 (1.2780)	grad_norm 7.3956 (5.0476)	loss_scale 2048.0000 (1125.0568)	mem 12172MB
[2024-07-03 05:41:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:04:46 lr 0.000001	 wd 0.0000	time 0.3128 (0.3572)	loss 1.3339 (1.2761)	grad_norm 5.2252 (5.0650)	loss_scale 2048.0000 (1179.3157)	mem 12172MB
[2024-07-03 05:42:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:04:09 lr 0.000001	 wd 0.0000	time 0.2981 (0.3561)	loss 1.3083 (1.2767)	grad_norm 3.3756 (inf)	loss_scale 1024.0000 (1171.8290)	mem 12172MB
[2024-07-03 05:43:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:03:34 lr 0.000001	 wd 0.0000	time 0.3714 (0.3569)	loss 0.9068 (1.2779)	grad_norm 5.1271 (inf)	loss_scale 1024.0000 (1164.0526)	mem 12172MB
[2024-07-03 05:43:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:02:58 lr 0.000001	 wd 0.0000	time 0.3630 (0.3563)	loss 0.8477 (1.2765)	grad_norm 5.7100 (inf)	loss_scale 1024.0000 (1157.0535)	mem 12172MB
[2024-07-03 05:44:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:02:22 lr 0.000001	 wd 0.0000	time 0.3134 (0.3553)	loss 1.6381 (1.2751)	grad_norm 4.1565 (inf)	loss_scale 1024.0000 (1150.7206)	mem 12172MB
[2024-07-03 05:44:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:47 lr 0.000001	 wd 0.0000	time 0.3094 (0.3549)	loss 0.9400 (1.2761)	grad_norm 4.5358 (inf)	loss_scale 1024.0000 (1144.9632)	mem 12172MB
[2024-07-03 05:45:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:01:11 lr 0.000001	 wd 0.0000	time 0.3471 (0.3544)	loss 1.4020 (1.2763)	grad_norm 3.4165 (inf)	loss_scale 1024.0000 (1139.7062)	mem 12172MB
[2024-07-03 05:45:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:36 lr 0.000001	 wd 0.0000	time 0.3068 (0.3539)	loss 1.1301 (1.2760)	grad_norm 3.6367 (inf)	loss_scale 1024.0000 (1134.8871)	mem 12172MB
[2024-07-03 05:46:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.2983 (0.3533)	loss 1.3623 (1.2745)	grad_norm 4.3141 (inf)	loss_scale 1024.0000 (1130.4534)	mem 12172MB
[2024-07-03 05:46:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 27 training takes 0:15:00
[2024-07-03 05:47:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 18.243 (18.243)	Loss 0.3901 (0.3901)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-03 05:47:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 85.064 Acc@5 97.546
[2024-07-03 05:47:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-03 05:47:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.07%
[2024-07-03 05:47:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][0/2502]	eta 11:00:42 lr 0.000001	 wd 0.0000	time 15.8443 (15.8443)	loss 1.2070 (1.2070)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:48:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:20:06 lr 0.000001	 wd 0.0000	time 0.2980 (0.5024)	loss 0.9208 (1.2574)	grad_norm 4.1988 (5.3230)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:48:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:16:40 lr 0.000001	 wd 0.0000	time 0.3212 (0.4348)	loss 1.0448 (1.2616)	grad_norm 4.0336 (5.1601)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:49:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:14:47 lr 0.000001	 wd 0.0000	time 0.3061 (0.4029)	loss 1.5116 (1.2762)	grad_norm 3.5571 (5.0187)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:49:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:13:37 lr 0.000001	 wd 0.0000	time 0.3127 (0.3887)	loss 1.4422 (1.2812)	grad_norm 4.8326 (4.9978)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:50:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:12:38 lr 0.000001	 wd 0.0000	time 0.3260 (0.3790)	loss 1.5292 (1.2808)	grad_norm 3.6428 (5.0247)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:51:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:11:49 lr 0.000001	 wd 0.0000	time 0.3828 (0.3732)	loss 1.3250 (1.2806)	grad_norm 3.6947 (5.0009)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:51:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:11:08 lr 0.000001	 wd 0.0000	time 0.3285 (0.3710)	loss 0.9781 (1.2830)	grad_norm 6.2628 (4.9827)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:52:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:10:24 lr 0.000001	 wd 0.0000	time 0.3475 (0.3670)	loss 1.5061 (1.2804)	grad_norm 7.2870 (5.0482)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:52:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:09:44 lr 0.000001	 wd 0.0000	time 0.3320 (0.3646)	loss 1.3855 (1.2805)	grad_norm 4.1075 (5.0538)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:53:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:09:04 lr 0.000001	 wd 0.0000	time 0.3222 (0.3623)	loss 1.3640 (1.2808)	grad_norm 12.2846 (5.1069)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:53:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:08:25 lr 0.000001	 wd 0.0000	time 0.3239 (0.3602)	loss 1.0157 (1.2792)	grad_norm 5.6374 (5.0902)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:54:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:07:50 lr 0.000001	 wd 0.0000	time 0.3765 (0.3615)	loss 1.0420 (1.2775)	grad_norm 4.3191 (5.1409)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:55:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:07:13 lr 0.000001	 wd 0.0000	time 0.3355 (0.3605)	loss 1.3036 (1.2747)	grad_norm 5.3514 (5.1121)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:55:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:06:35 lr 0.000001	 wd 0.0000	time 0.3398 (0.3590)	loss 0.9112 (1.2755)	grad_norm 5.2919 (5.1145)	loss_scale 1024.0000 (1024.0000)	mem 12172MB
[2024-07-03 05:56:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:06:02 lr 0.000001	 wd 0.0000	time 0.3147 (0.3615)	loss 1.4089 (1.2727)	grad_norm 5.1615 (nan)	loss_scale 512.0000 (1013.0846)	mem 12172MB
[2024-07-03 05:56:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:05:25 lr 0.000001	 wd 0.0000	time 0.3304 (0.3611)	loss 1.1655 (1.2729)	grad_norm 4.3996 (nan)	loss_scale 512.0000 (981.7864)	mem 12172MB
[2024-07-03 05:57:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:04:48 lr 0.000001	 wd 0.0000	time 0.3376 (0.3597)	loss 1.4240 (1.2739)	grad_norm 6.2459 (nan)	loss_scale 512.0000 (954.1681)	mem 12172MB
[2024-07-03 05:58:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:04:12 lr 0.000001	 wd 0.0000	time 0.3152 (0.3600)	loss 1.2990 (1.2731)	grad_norm 5.3144 (nan)	loss_scale 512.0000 (929.6169)	mem 12172MB
[2024-07-03 05:58:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:03:36 lr 0.000001	 wd 0.0000	time 0.3154 (0.3589)	loss 1.5708 (1.2719)	grad_norm 6.2454 (nan)	loss_scale 512.0000 (907.6486)	mem 12172MB
[2024-07-03 05:59:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:02:59 lr 0.000001	 wd 0.0000	time 0.3193 (0.3581)	loss 0.8381 (1.2714)	grad_norm 8.6207 (nan)	loss_scale 512.0000 (887.8761)	mem 12172MB
[2024-07-03 05:59:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:02:23 lr 0.000001	 wd 0.0000	time 0.3376 (0.3576)	loss 1.0732 (1.2716)	grad_norm 6.0767 (nan)	loss_scale 512.0000 (869.9857)	mem 12172MB
[2024-07-03 06:00:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:47 lr 0.000001	 wd 0.0000	time 0.3130 (0.3573)	loss 1.4130 (1.2706)	grad_norm 7.5662 (nan)	loss_scale 512.0000 (853.7210)	mem 12172MB
[2024-07-03 06:00:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:01:12 lr 0.000001	 wd 0.0000	time 0.3924 (0.3568)	loss 1.1483 (1.2708)	grad_norm 5.4946 (nan)	loss_scale 512.0000 (838.8701)	mem 12172MB
[2024-07-03 06:01:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:36 lr 0.000001	 wd 0.0000	time 0.3195 (0.3562)	loss 1.4705 (1.2698)	grad_norm 4.2220 (nan)	loss_scale 512.0000 (825.2561)	mem 12172MB
[2024-07-03 06:02:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.2978 (0.3555)	loss 1.1097 (1.2684)	grad_norm 19.4996 (nan)	loss_scale 512.0000 (812.7309)	mem 12172MB
[2024-07-03 06:02:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 28 training takes 0:14:58
[2024-07-03 06:02:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 29.964 (29.964)	Loss 0.3906 (0.3906)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-03 06:03:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 85.080 Acc@5 97.552
[2024-07-03 06:03:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-03 06:03:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.08%
[2024-07-03 06:03:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune/ckpt_epoch_best.pth saving......
[2024-07-03 06:03:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune/ckpt_epoch_best.pth saved !!!
[2024-07-03 06:03:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][0/2502]	eta 10:18:57 lr 0.000001	 wd 0.0000	time 14.8430 (14.8430)	loss 1.4188 (1.4188)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:03:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:19:18 lr 0.000001	 wd 0.0000	time 0.3104 (0.4822)	loss 1.4300 (1.2467)	grad_norm 5.5357 (5.1706)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:04:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:15:50 lr 0.000001	 wd 0.0000	time 0.3049 (0.4127)	loss 1.1132 (1.2644)	grad_norm 3.6235 (5.0936)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:05:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:14:17 lr 0.000001	 wd 0.0000	time 0.3235 (0.3896)	loss 1.4339 (1.2638)	grad_norm 3.4367 (5.0137)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:05:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:13:11 lr 0.000001	 wd 0.0000	time 0.3151 (0.3766)	loss 1.1751 (1.2681)	grad_norm 6.5129 (4.8943)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:06:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:12:25 lr 0.000001	 wd 0.0000	time 0.3540 (0.3722)	loss 0.8348 (1.2726)	grad_norm 4.4229 (4.9331)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:06:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:11:39 lr 0.000000	 wd 0.0000	time 0.3149 (0.3677)	loss 1.2582 (1.2773)	grad_norm 4.1921 (5.0552)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:07:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:10:54 lr 0.000000	 wd 0.0000	time 0.3114 (0.3632)	loss 1.5610 (1.2775)	grad_norm 6.1317 (5.0251)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:07:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:10:20 lr 0.000000	 wd 0.0000	time 0.3331 (0.3648)	loss 0.8052 (1.2767)	grad_norm 2.9290 (4.9683)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:08:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:09:41 lr 0.000000	 wd 0.0000	time 0.5257 (0.3629)	loss 1.2464 (1.2770)	grad_norm 6.5946 (4.9409)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:09:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:09:04 lr 0.000000	 wd 0.0000	time 0.3301 (0.3622)	loss 1.2392 (1.2761)	grad_norm 4.2210 (4.9338)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:09:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:08:26 lr 0.000000	 wd 0.0000	time 0.3295 (0.3612)	loss 1.2628 (1.2761)	grad_norm 4.2282 (4.9194)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:10:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:07:47 lr 0.000000	 wd 0.0000	time 0.3291 (0.3594)	loss 1.3418 (1.2732)	grad_norm 4.1203 (4.9108)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:10:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:07:12 lr 0.000000	 wd 0.0000	time 0.2978 (0.3598)	loss 1.4298 (1.2738)	grad_norm 6.9204 (4.9258)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:11:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:06:35 lr 0.000000	 wd 0.0000	time 0.3176 (0.3588)	loss 1.5264 (1.2714)	grad_norm 10.8871 (4.9512)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:12:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:05:58 lr 0.000000	 wd 0.0000	time 0.3193 (0.3577)	loss 1.2870 (1.2723)	grad_norm 4.8777 (4.9609)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:12:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:05:24 lr 0.000000	 wd 0.0000	time 0.2864 (0.3596)	loss 1.2494 (1.2739)	grad_norm 5.7831 (4.9445)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:13:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:04:47 lr 0.000000	 wd 0.0000	time 0.3278 (0.3591)	loss 1.0610 (1.2718)	grad_norm 4.0369 (4.9487)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:13:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:04:12 lr 0.000000	 wd 0.0000	time 0.3312 (0.3593)	loss 1.0959 (1.2734)	grad_norm 5.5124 (4.9359)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:14:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:03:36 lr 0.000000	 wd 0.0000	time 0.3195 (0.3597)	loss 1.2113 (1.2726)	grad_norm 3.9493 (4.9601)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:15:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:02:59 lr 0.000000	 wd 0.0000	time 0.3203 (0.3586)	loss 1.4936 (1.2726)	grad_norm 5.4541 (4.9567)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:15:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:02:23 lr 0.000000	 wd 0.0000	time 0.3488 (0.3576)	loss 1.3526 (1.2731)	grad_norm 4.9289 (4.9617)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:16:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:47 lr 0.000000	 wd 0.0000	time 0.3356 (0.3571)	loss 1.3806 (1.2749)	grad_norm 4.0770 (4.9647)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:16:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:01:11 lr 0.000000	 wd 0.0000	time 0.3008 (0.3563)	loss 1.4794 (1.2759)	grad_norm 3.6379 (4.9966)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:17:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 0.3169 (0.3556)	loss 1.4484 (1.2766)	grad_norm 5.0178 (5.0235)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:17:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000000	 wd 0.0000	time 0.2996 (0.3547)	loss 1.3310 (1.2761)	grad_norm 3.8878 (5.0189)	loss_scale 512.0000 (512.0000)	mem 12172MB
[2024-07-03 06:18:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 249): INFO EPOCH 29 training takes 0:14:59
[2024-07-03 06:18:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune/ckpt_epoch_29.pth saving......
[2024-07-03 06:18:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune/ckpt_epoch_29.pth saved !!!
[2024-07-03 06:18:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 289): INFO Test: [0/98]	Time 17.091 (17.091)	Loss 0.3909 (0.3909)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 12172MB
[2024-07-03 06:18:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 296): INFO  * Acc@1 85.092 Acc@5 97.544
[2024-07-03 06:18:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-03 06:18:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 182): INFO Max accuracy: 85.09%
[2024-07-03 06:18:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune/ckpt_epoch_best.pth saving......
[2024-07-03 06:18:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process2-full-finetune/ckpt_epoch_best.pth saved !!!
[2024-07-03 06:18:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_step_crosslayer_process2-full-finetune] (main.py 189): INFO Training time 7:43:36
