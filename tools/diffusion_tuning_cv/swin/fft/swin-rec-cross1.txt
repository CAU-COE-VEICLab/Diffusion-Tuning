[2024-07-02 16:27:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/config.json
[2024-07-02 16:27:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    FINETUNE_MODE: part1
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: swin_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    DEPTHS:
    - 3
    - 3
    - 9
    - 3
    DIMS:
    - 96
    - 192
    - 384
    - 768
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 4.0e-05
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.0e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 4.0e-08
  WEIGHT_DECAY: 1.0e-08

[2024-07-02 16:27:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/swin/diffusion_ft_swin_base_patch4_window7_224_22kto1k_finetune_crosslayer_proces1.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-02 16:27:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 108): INFO Creating model:swin_diffusion_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1
[2024-07-02 16:27:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 110): INFO SwinTransformer_Diffusion_Finetune(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-02 16:27:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 113): INFO number of params: 45780740
[2024-07-02 16:27:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 116): INFO number of GFLOPs: 15.438473216
[2024-07-02 16:27:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 150): INFO no checkpoint found in pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1, ignoring auto resume
[2024-07-02 16:27:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth for fine-tuning......
[2024-07-02 16:27:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])
[2024-07-02 16:27:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process0/ckpt_epoch_best.pth'
[2024-07-02 16:27:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 18.218 (18.218)	Loss 0.4043 (0.4043)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 1568MB
[2024-07-02 16:27:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.760 Acc@5 97.500
[2024-07-02 16:27:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 162): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-02 16:27:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 168): INFO Start training
[2024-07-02 16:28:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][0/2502]	eta 15:19:33 lr 0.000000	 wd 0.0000	time 22.0518 (22.0518)	loss 1.5222 (1.5222)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 9681MB
[2024-07-02 16:28:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:18:44 lr 0.000000	 wd 0.0000	time 0.2369 (0.4682)	loss 1.3546 (1.3515)	grad_norm 4.9786 (nan)	loss_scale 4096.0000 (8435.3267)	mem 10191MB
[2024-07-02 16:29:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:13:52 lr 0.000001	 wd 0.0000	time 0.2420 (0.3617)	loss 1.2588 (1.3343)	grad_norm 3.5166 (nan)	loss_scale 2048.0000 (6174.5672)	mem 10191MB
[2024-07-02 16:29:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:11:55 lr 0.000001	 wd 0.0000	time 0.2241 (0.3247)	loss 1.2671 (1.3169)	grad_norm 3.7863 (nan)	loss_scale 2048.0000 (4803.6146)	mem 10191MB
[2024-07-02 16:29:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:50 lr 0.000001	 wd 0.0000	time 0.2249 (0.3094)	loss 1.8083 (1.3190)	grad_norm 3.3608 (nan)	loss_scale 2048.0000 (4116.4289)	mem 10191MB
[2024-07-02 16:30:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:09:57 lr 0.000002	 wd 0.0000	time 0.2405 (0.2985)	loss 1.5170 (1.3194)	grad_norm 4.2555 (nan)	loss_scale 2048.0000 (3703.5689)	mem 10191MB
[2024-07-02 16:30:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:14 lr 0.000002	 wd 0.0000	time 0.2374 (0.2914)	loss 0.9374 (1.3234)	grad_norm 3.4531 (nan)	loss_scale 2048.0000 (3428.0998)	mem 10191MB
[2024-07-02 16:31:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:34 lr 0.000002	 wd 0.0000	time 0.2476 (0.2856)	loss 1.4038 (1.3219)	grad_norm 3.0057 (nan)	loss_scale 2048.0000 (3231.2240)	mem 10191MB
[2024-07-02 16:31:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:08:04 lr 0.000003	 wd 0.0000	time 0.2204 (0.2844)	loss 1.5143 (1.3219)	grad_norm 3.4635 (nan)	loss_scale 2048.0000 (3083.5056)	mem 10191MB
[2024-07-02 16:32:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:30 lr 0.000003	 wd 0.0000	time 0.2797 (0.2809)	loss 1.5154 (1.3173)	grad_norm 3.5371 (nan)	loss_scale 2048.0000 (2968.5771)	mem 10191MB
[2024-07-02 16:32:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:06:58 lr 0.000003	 wd 0.0000	time 0.2324 (0.2784)	loss 1.3242 (1.3166)	grad_norm 6.0737 (nan)	loss_scale 1024.0000 (2856.1518)	mem 10191MB
[2024-07-02 16:32:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:32 lr 0.000004	 wd 0.0000	time 0.2381 (0.2801)	loss 1.4718 (1.3175)	grad_norm 3.0480 (nan)	loss_scale 1024.0000 (2689.7439)	mem 10191MB
[2024-07-02 16:33:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:06:04 lr 0.000004	 wd 0.0000	time 0.2477 (0.2802)	loss 1.2644 (1.3206)	grad_norm 3.4166 (nan)	loss_scale 1024.0000 (2551.0475)	mem 10191MB
[2024-07-02 16:33:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:34 lr 0.000004	 wd 0.0000	time 0.2366 (0.2781)	loss 1.4730 (1.3223)	grad_norm 11.4273 (nan)	loss_scale 1024.0000 (2433.6726)	mem 10191MB
[2024-07-02 16:34:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:05:04 lr 0.000005	 wd 0.0000	time 0.2209 (0.2762)	loss 1.5146 (1.3230)	grad_norm 3.3008 (nan)	loss_scale 1024.0000 (2333.0535)	mem 10191MB
[2024-07-02 16:34:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:36 lr 0.000005	 wd 0.0000	time 0.2273 (0.2762)	loss 1.3025 (1.3223)	grad_norm 4.2631 (nan)	loss_scale 1024.0000 (2245.8414)	mem 10191MB
[2024-07-02 16:35:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:04:08 lr 0.000005	 wd 0.0000	time 0.2379 (0.2753)	loss 1.6696 (1.3231)	grad_norm 3.9901 (nan)	loss_scale 1024.0000 (2169.5240)	mem 10191MB
[2024-07-02 16:35:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:39 lr 0.000005	 wd 0.0000	time 0.2346 (0.2742)	loss 1.5287 (1.3225)	grad_norm 4.9419 (nan)	loss_scale 1024.0000 (2102.1799)	mem 10191MB
[2024-07-02 16:36:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:03:11 lr 0.000006	 wd 0.0000	time 0.2361 (0.2728)	loss 1.1710 (1.3226)	grad_norm 3.0203 (nan)	loss_scale 1024.0000 (2042.3143)	mem 10191MB
[2024-07-02 16:36:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:45 lr 0.000006	 wd 0.0000	time 0.2401 (0.2744)	loss 1.3659 (1.3216)	grad_norm 6.0659 (nan)	loss_scale 1024.0000 (1988.7470)	mem 10191MB
[2024-07-02 16:36:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:17 lr 0.000006	 wd 0.0000	time 0.2374 (0.2732)	loss 1.4907 (1.3193)	grad_norm 4.1754 (nan)	loss_scale 1024.0000 (1940.5337)	mem 10191MB
[2024-07-02 16:37:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:49 lr 0.000007	 wd 0.0000	time 0.2319 (0.2734)	loss 1.3446 (1.3203)	grad_norm 7.0530 (nan)	loss_scale 1024.0000 (1896.9100)	mem 10191MB
[2024-07-02 16:37:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:22 lr 0.000007	 wd 0.0000	time 0.2319 (0.2739)	loss 1.4440 (1.3204)	grad_norm 7.6307 (nan)	loss_scale 1024.0000 (1857.2503)	mem 10191MB
[2024-07-02 16:38:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:55 lr 0.000007	 wd 0.0000	time 0.2282 (0.2747)	loss 1.3306 (1.3191)	grad_norm 4.7234 (nan)	loss_scale 1024.0000 (1821.0378)	mem 10191MB
[2024-07-02 16:38:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:27 lr 0.000008	 wd 0.0000	time 0.2383 (0.2740)	loss 1.4272 (1.3194)	grad_norm 5.0995 (nan)	loss_scale 1024.0000 (1787.8417)	mem 10191MB
[2024-07-02 16:39:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.2255 (0.2727)	loss 1.5491 (1.3196)	grad_norm 4.2527 (nan)	loss_scale 1024.0000 (1757.3003)	mem 10191MB
[2024-07-02 16:39:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 0 training takes 0:11:25
[2024-07-02 16:39:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_0.pth saving......
[2024-07-02 16:39:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_0.pth saved !!!
[2024-07-02 16:39:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 23.977 (23.977)	Loss 0.4014 (0.4014)	Acc@1 92.969 (92.969)	Acc@5 98.438 (98.438)	Mem 10191MB
[2024-07-02 16:39:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.778 Acc@5 97.486
[2024-07-02 16:39:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-02 16:39:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 84.78%
[2024-07-02 16:39:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth saving......
[2024-07-02 16:39:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth saved !!!
[2024-07-02 16:40:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][0/2502]	eta 10:32:42 lr 0.000008	 wd 0.0000	time 15.1729 (15.1729)	loss 1.1917 (1.1917)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 16:40:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:16:11 lr 0.000008	 wd 0.0000	time 0.2366 (0.4045)	loss 1.1322 (1.3451)	grad_norm 6.9605 (5.0036)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 16:41:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:13:07 lr 0.000009	 wd 0.0000	time 0.2357 (0.3423)	loss 1.3386 (1.3507)	grad_norm 3.7456 (4.8069)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 16:41:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:35 lr 0.000009	 wd 0.0000	time 0.2268 (0.3159)	loss 1.6646 (1.3377)	grad_norm 4.2249 (4.8043)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 16:41:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:10:31 lr 0.000009	 wd 0.0000	time 0.2458 (0.3004)	loss 0.8731 (1.3235)	grad_norm 3.9534 (4.8461)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 16:42:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:09:41 lr 0.000010	 wd 0.0000	time 0.2359 (0.2906)	loss 1.5799 (1.3219)	grad_norm 5.9696 (4.8217)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 16:42:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:09:02 lr 0.000010	 wd 0.0000	time 0.2373 (0.2853)	loss 1.3217 (1.3186)	grad_norm 4.3269 (4.8621)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 16:43:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:32 lr 0.000010	 wd 0.0000	time 0.2475 (0.2845)	loss 1.4635 (1.3176)	grad_norm 4.8918 (4.8434)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 16:43:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:57 lr 0.000011	 wd 0.0000	time 0.2405 (0.2808)	loss 1.4720 (1.3207)	grad_norm 2.7665 (4.7905)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 16:44:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:25 lr 0.000011	 wd 0.0000	time 0.2739 (0.2778)	loss 1.5045 (1.3194)	grad_norm 5.7033 (4.8118)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 16:44:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:58 lr 0.000011	 wd 0.0000	time 0.2360 (0.2789)	loss 1.4106 (1.3175)	grad_norm 5.4161 (4.8131)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 16:44:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:06:28 lr 0.000012	 wd 0.0000	time 0.2741 (0.2774)	loss 1.0830 (1.3180)	grad_norm 3.7458 (4.8133)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 16:45:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:59 lr 0.000012	 wd 0.0000	time 0.2377 (0.2763)	loss 1.3487 (1.3205)	grad_norm 4.0941 (4.8026)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 16:45:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:30 lr 0.000012	 wd 0.0000	time 0.2359 (0.2746)	loss 1.4460 (1.3219)	grad_norm 4.9043 (4.7934)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 16:46:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:05:03 lr 0.000012	 wd 0.0000	time 0.2603 (0.2754)	loss 1.4409 (1.3202)	grad_norm 4.5463 (nan)	loss_scale 512.0000 (1003.5346)	mem 10191MB
[2024-07-02 16:46:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:34 lr 0.000013	 wd 0.0000	time 0.2341 (0.2739)	loss 0.9017 (1.3183)	grad_norm 4.6548 (nan)	loss_scale 512.0000 (970.7875)	mem 10191MB
[2024-07-02 16:47:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:04:05 lr 0.000013	 wd 0.0000	time 0.2525 (0.2727)	loss 0.9127 (1.3174)	grad_norm 3.1221 (nan)	loss_scale 512.0000 (942.1312)	mem 10191MB
[2024-07-02 16:47:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:37 lr 0.000013	 wd 0.0000	time 0.2697 (0.2715)	loss 1.3477 (1.3173)	grad_norm 4.6549 (nan)	loss_scale 512.0000 (916.8442)	mem 10191MB
[2024-07-02 16:48:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:03:13 lr 0.000014	 wd 0.0000	time 0.2388 (0.2754)	loss 1.2735 (1.3167)	grad_norm 3.3709 (nan)	loss_scale 512.0000 (894.3654)	mem 10191MB
[2024-07-02 16:48:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:45 lr 0.000014	 wd 0.0000	time 0.2445 (0.2741)	loss 1.3508 (1.3176)	grad_norm 4.9889 (nan)	loss_scale 512.0000 (874.2514)	mem 10191MB
[2024-07-02 16:48:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:16 lr 0.000014	 wd 0.0000	time 0.2320 (0.2728)	loss 1.3884 (1.3173)	grad_norm 3.8031 (nan)	loss_scale 512.0000 (856.1479)	mem 10191MB
[2024-07-02 16:49:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:49 lr 0.000015	 wd 0.0000	time 0.4716 (0.2732)	loss 1.4714 (1.3183)	grad_norm 3.3303 (nan)	loss_scale 512.0000 (839.7677)	mem 10191MB
[2024-07-02 16:49:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:22 lr 0.000015	 wd 0.0000	time 0.2241 (0.2725)	loss 1.0375 (1.3189)	grad_norm 4.0796 (nan)	loss_scale 512.0000 (824.8760)	mem 10191MB
[2024-07-02 16:50:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:54 lr 0.000015	 wd 0.0000	time 0.2419 (0.2716)	loss 1.3522 (1.3193)	grad_norm 3.6248 (nan)	loss_scale 512.0000 (811.2786)	mem 10191MB
[2024-07-02 16:50:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:27 lr 0.000016	 wd 0.0000	time 0.2509 (0.2709)	loss 1.4691 (1.3177)	grad_norm 4.5235 (nan)	loss_scale 512.0000 (798.8138)	mem 10191MB
[2024-07-02 16:51:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.2227 (0.2709)	loss 1.0624 (1.3190)	grad_norm 3.0433 (nan)	loss_scale 512.0000 (787.3459)	mem 10191MB
[2024-07-02 16:51:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 1 training takes 0:11:28
[2024-07-02 16:51:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 17.427 (17.427)	Loss 0.4077 (0.4077)	Acc@1 91.992 (91.992)	Acc@5 98.242 (98.242)	Mem 10191MB
[2024-07-02 16:51:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.706 Acc@5 97.518
[2024-07-02 16:51:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 16:51:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 84.78%
[2024-07-02 16:52:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][0/2502]	eta 11:08:22 lr 0.000016	 wd 0.0000	time 16.0284 (16.0284)	loss 1.4231 (1.4231)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 16:52:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:18:13 lr 0.000016	 wd 0.0000	time 0.2425 (0.4555)	loss 1.3987 (1.2961)	grad_norm 3.4379 (5.1867)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 16:53:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:13:57 lr 0.000017	 wd 0.0000	time 0.2416 (0.3637)	loss 1.4332 (1.3128)	grad_norm 5.4277 (5.0266)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 16:53:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:12:18 lr 0.000017	 wd 0.0000	time 0.2258 (0.3355)	loss 1.1179 (1.3159)	grad_norm 4.0696 (5.1154)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 16:53:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:10:59 lr 0.000017	 wd 0.0000	time 0.2220 (0.3138)	loss 1.4635 (1.3119)	grad_norm 5.0248 (4.8947)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 16:54:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:10:08 lr 0.000018	 wd 0.0000	time 0.2383 (0.3038)	loss 1.3884 (1.3145)	grad_norm 3.3237 (4.9359)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 16:54:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:09:23 lr 0.000018	 wd 0.0000	time 0.2418 (0.2964)	loss 1.2060 (1.3088)	grad_norm 4.0903 (4.9180)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 16:55:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:08:43 lr 0.000018	 wd 0.0000	time 0.2532 (0.2906)	loss 1.1974 (1.3121)	grad_norm 4.3574 (4.8792)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 16:55:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:08:07 lr 0.000019	 wd 0.0000	time 0.2434 (0.2864)	loss 1.4727 (1.3101)	grad_norm 5.8633 (4.8742)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 16:56:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:07:42 lr 0.000019	 wd 0.0000	time 0.2456 (0.2887)	loss 1.4276 (1.3153)	grad_norm 3.9824 (4.9966)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 16:56:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:07:08 lr 0.000019	 wd 0.0000	time 0.2476 (0.2854)	loss 1.4050 (1.3167)	grad_norm 3.4658 (4.9362)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 16:57:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:06:36 lr 0.000020	 wd 0.0000	time 0.2263 (0.2829)	loss 1.1502 (1.3178)	grad_norm 6.2096 (4.9405)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 16:57:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:06:06 lr 0.000020	 wd 0.0000	time 0.2401 (0.2815)	loss 1.2686 (1.3170)	grad_norm 3.8476 (4.9074)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 16:57:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:05:36 lr 0.000020	 wd 0.0000	time 0.2429 (0.2797)	loss 1.5994 (1.3193)	grad_norm 4.1985 (4.8887)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 16:58:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:05:06 lr 0.000020	 wd 0.0000	time 0.2439 (0.2783)	loss 1.3296 (1.3196)	grad_norm 6.4955 (4.8723)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 16:58:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:36 lr 0.000021	 wd 0.0000	time 0.2255 (0.2763)	loss 1.4904 (1.3179)	grad_norm 6.2580 (4.8866)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 16:59:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:04:08 lr 0.000021	 wd 0.0000	time 0.2363 (0.2756)	loss 1.1963 (1.3180)	grad_norm 6.8893 (4.9098)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 16:59:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:40 lr 0.000021	 wd 0.0000	time 0.2281 (0.2743)	loss 1.2577 (1.3168)	grad_norm 7.6948 (4.9068)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:00:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:03:11 lr 0.000022	 wd 0.0000	time 0.2452 (0.2730)	loss 1.2505 (1.3167)	grad_norm 5.1005 (4.9645)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:00:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:43 lr 0.000022	 wd 0.0000	time 0.2454 (0.2716)	loss 0.9287 (1.3151)	grad_norm 3.5064 (4.9747)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:00:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:02:16 lr 0.000022	 wd 0.0000	time 0.2395 (0.2721)	loss 1.1243 (1.3130)	grad_norm 3.8204 (5.0295)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:01:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:49 lr 0.000023	 wd 0.0000	time 0.2334 (0.2713)	loss 1.3884 (1.3132)	grad_norm 13.2256 (5.0298)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:01:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:21 lr 0.000023	 wd 0.0000	time 0.2331 (0.2708)	loss 1.5391 (1.3129)	grad_norm 4.0184 (5.0274)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:02:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:54 lr 0.000023	 wd 0.0000	time 0.2423 (0.2698)	loss 1.5804 (1.3129)	grad_norm 3.9535 (5.0240)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:02:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:27 lr 0.000024	 wd 0.0000	time 0.2239 (0.2709)	loss 1.4223 (1.3121)	grad_norm 2.8731 (4.9955)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:03:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.2207 (0.2709)	loss 1.4681 (1.3121)	grad_norm 2.8826 (4.9877)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:03:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 2 training takes 0:11:22
[2024-07-02 17:03:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 18.694 (18.694)	Loss 0.3967 (0.3967)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 10191MB
[2024-07-02 17:03:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.658 Acc@5 97.516
[2024-07-02 17:03:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 17:03:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 84.78%
[2024-07-02 17:03:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][0/2502]	eta 12:45:56 lr 0.000024	 wd 0.0000	time 18.3679 (18.3679)	loss 0.9298 (0.9298)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:04:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:17:27 lr 0.000024	 wd 0.0000	time 0.2592 (0.4359)	loss 1.4358 (1.2845)	grad_norm 6.5397 (4.9234)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:04:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:13:20 lr 0.000025	 wd 0.0000	time 0.2364 (0.3478)	loss 1.3648 (1.3006)	grad_norm 4.0645 (5.1725)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:05:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:11:38 lr 0.000025	 wd 0.0000	time 0.2668 (0.3173)	loss 1.5120 (1.2956)	grad_norm 3.7941 (5.1582)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:05:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:10:42 lr 0.000025	 wd 0.0000	time 0.2537 (0.3058)	loss 1.4506 (1.2982)	grad_norm 6.5523 (5.0549)	loss_scale 1024.0000 (588.6085)	mem 10191MB
[2024-07-02 17:06:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:09:51 lr 0.000026	 wd 0.0000	time 0.2438 (0.2955)	loss 1.3629 (1.2972)	grad_norm 4.7368 (5.1333)	loss_scale 1024.0000 (675.5130)	mem 10191MB
[2024-07-02 17:06:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:09:10 lr 0.000026	 wd 0.0000	time 0.2502 (0.2895)	loss 1.3256 (1.2985)	grad_norm 22.9340 (5.0609)	loss_scale 1024.0000 (733.4975)	mem 10191MB
[2024-07-02 17:06:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:08:31 lr 0.000026	 wd 0.0000	time 0.2333 (0.2841)	loss 1.6240 (1.3000)	grad_norm 4.9434 (4.9542)	loss_scale 1024.0000 (774.9387)	mem 10191MB
[2024-07-02 17:07:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:08:01 lr 0.000027	 wd 0.0000	time 0.2793 (0.2831)	loss 1.0399 (1.2999)	grad_norm 3.9331 (5.1355)	loss_scale 1024.0000 (806.0325)	mem 10191MB
[2024-07-02 17:07:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:07:33 lr 0.000027	 wd 0.0000	time 0.2431 (0.2833)	loss 1.4018 (1.3010)	grad_norm 4.3268 (5.1215)	loss_scale 1024.0000 (830.2242)	mem 10191MB
[2024-07-02 17:08:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:07:01 lr 0.000027	 wd 0.0000	time 0.2374 (0.2805)	loss 1.4223 (1.3033)	grad_norm 4.1194 (5.0708)	loss_scale 1024.0000 (849.5824)	mem 10191MB
[2024-07-02 17:08:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:06:29 lr 0.000028	 wd 0.0000	time 0.2286 (0.2778)	loss 1.3229 (1.3057)	grad_norm 3.9736 (5.0290)	loss_scale 1024.0000 (865.4242)	mem 10191MB
[2024-07-02 17:09:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:06:02 lr 0.000028	 wd 0.0000	time 0.2315 (0.2786)	loss 1.1975 (1.3038)	grad_norm 9.3249 (5.0105)	loss_scale 1024.0000 (878.6278)	mem 10191MB
[2024-07-02 17:09:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:05:32 lr 0.000028	 wd 0.0000	time 0.2336 (0.2768)	loss 1.2549 (1.3062)	grad_norm 4.2636 (5.0163)	loss_scale 1024.0000 (889.8017)	mem 10191MB
[2024-07-02 17:10:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:05:03 lr 0.000028	 wd 0.0000	time 0.2326 (0.2751)	loss 1.1919 (1.3065)	grad_norm 3.9399 (4.9688)	loss_scale 1024.0000 (899.3804)	mem 10191MB
[2024-07-02 17:10:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:35 lr 0.000029	 wd 0.0000	time 0.2616 (0.2754)	loss 1.4180 (1.3081)	grad_norm 4.0963 (4.9692)	loss_scale 1024.0000 (907.6829)	mem 10191MB
[2024-07-02 17:11:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:04:08 lr 0.000029	 wd 0.0000	time 0.2385 (0.2750)	loss 1.4612 (1.3069)	grad_norm 3.8770 (4.9445)	loss_scale 1024.0000 (914.9482)	mem 10191MB
[2024-07-02 17:11:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:39 lr 0.000029	 wd 0.0000	time 0.2404 (0.2742)	loss 1.0823 (1.3061)	grad_norm 5.8813 (4.9553)	loss_scale 1024.0000 (921.3592)	mem 10191MB
[2024-07-02 17:11:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:03:11 lr 0.000030	 wd 0.0000	time 0.2363 (0.2729)	loss 1.4375 (1.3064)	grad_norm 4.7720 (4.9636)	loss_scale 1024.0000 (927.0583)	mem 10191MB
[2024-07-02 17:12:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:45 lr 0.000030	 wd 0.0000	time 0.2528 (0.2752)	loss 1.3825 (1.3057)	grad_norm 9.3315 (4.9517)	loss_scale 1024.0000 (932.1578)	mem 10191MB
[2024-07-02 17:12:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:17 lr 0.000030	 wd 0.0000	time 0.2362 (0.2746)	loss 1.1170 (1.3061)	grad_norm 4.1567 (4.9627)	loss_scale 1024.0000 (936.7476)	mem 10191MB
[2024-07-02 17:13:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:49 lr 0.000031	 wd 0.0000	time 0.2522 (0.2734)	loss 1.0882 (1.3051)	grad_norm 4.2572 (4.9552)	loss_scale 1024.0000 (940.9005)	mem 10191MB
[2024-07-02 17:13:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:22 lr 0.000031	 wd 0.0000	time 0.2507 (0.2723)	loss 1.2999 (1.3058)	grad_norm 4.3601 (4.9517)	loss_scale 1024.0000 (944.6761)	mem 10191MB
[2024-07-02 17:14:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:55 lr 0.000031	 wd 0.0000	time 0.2324 (0.2732)	loss 1.4190 (1.3067)	grad_norm 3.5781 (4.9469)	loss_scale 1024.0000 (948.1234)	mem 10191MB
[2024-07-02 17:14:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:27 lr 0.000032	 wd 0.0000	time 0.2421 (0.2723)	loss 0.9949 (1.3060)	grad_norm 3.9066 (4.9451)	loss_scale 1024.0000 (951.2836)	mem 10191MB
[2024-07-02 17:14:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000032	 wd 0.0000	time 0.2237 (0.2714)	loss 1.3710 (1.3065)	grad_norm 3.9362 (4.9324)	loss_scale 1024.0000 (954.1911)	mem 10191MB
[2024-07-02 17:15:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 3 training takes 0:11:22
[2024-07-02 17:15:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 26.585 (26.585)	Loss 0.4028 (0.4028)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 10191MB
[2024-07-02 17:15:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.672 Acc@5 97.510
[2024-07-02 17:15:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 17:15:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 84.78%
[2024-07-02 17:15:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][0/2502]	eta 10:57:03 lr 0.000032	 wd 0.0000	time 15.7570 (15.7570)	loss 1.3730 (1.3730)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:16:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:17:20 lr 0.000032	 wd 0.0000	time 0.2395 (0.4333)	loss 1.1785 (1.3355)	grad_norm 3.8127 (5.7192)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:16:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:13:08 lr 0.000033	 wd 0.0000	time 0.2271 (0.3424)	loss 1.1375 (1.3236)	grad_norm 4.5245 (5.6174)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:17:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:11:58 lr 0.000033	 wd 0.0000	time 0.2218 (0.3264)	loss 1.0739 (1.3234)	grad_norm 6.7867 (5.4308)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:17:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:10:50 lr 0.000033	 wd 0.0000	time 0.2450 (0.3093)	loss 1.3512 (1.3132)	grad_norm 2.9081 (5.2644)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:18:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:09:56 lr 0.000034	 wd 0.0000	time 0.2359 (0.2981)	loss 1.3324 (1.3083)	grad_norm 3.6303 (5.1935)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:18:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:09:13 lr 0.000034	 wd 0.0000	time 0.2706 (0.2909)	loss 1.3716 (1.3033)	grad_norm 29.7223 (5.1676)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:19:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:08:46 lr 0.000034	 wd 0.0000	time 0.2552 (0.2924)	loss 1.2091 (1.3036)	grad_norm 4.3438 (5.3178)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:19:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:08:09 lr 0.000035	 wd 0.0000	time 0.2624 (0.2878)	loss 1.2413 (1.3045)	grad_norm 3.8048 (5.1832)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:19:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:07:34 lr 0.000035	 wd 0.0000	time 0.2535 (0.2838)	loss 1.4267 (1.3049)	grad_norm 2.8279 (5.2112)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:20:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:07:02 lr 0.000035	 wd 0.0000	time 0.2536 (0.2815)	loss 1.4471 (1.3057)	grad_norm 5.3658 (5.1564)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:20:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:06:32 lr 0.000036	 wd 0.0000	time 0.2289 (0.2798)	loss 1.4781 (1.3061)	grad_norm 3.8552 (5.1165)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:21:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:06:01 lr 0.000036	 wd 0.0000	time 0.2457 (0.2775)	loss 0.9773 (1.3051)	grad_norm 4.2010 (5.0932)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:21:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:05:31 lr 0.000036	 wd 0.0000	time 0.2416 (0.2755)	loss 1.4743 (1.3040)	grad_norm 5.9593 (5.0699)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:22:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:05:02 lr 0.000036	 wd 0.0000	time 0.2619 (0.2744)	loss 1.3903 (1.3039)	grad_norm 5.2386 (5.0306)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:22:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:33 lr 0.000037	 wd 0.0000	time 0.2387 (0.2733)	loss 1.2349 (1.3070)	grad_norm 6.1533 (5.0649)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:22:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:04:05 lr 0.000037	 wd 0.0000	time 0.2292 (0.2719)	loss 1.1342 (1.3063)	grad_norm 3.9972 (5.0522)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:23:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:37 lr 0.000037	 wd 0.0000	time 0.2397 (0.2715)	loss 1.4776 (1.3058)	grad_norm 5.9046 (5.0650)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:23:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:03:12 lr 0.000038	 wd 0.0000	time 0.2490 (0.2749)	loss 1.5055 (1.3055)	grad_norm 7.5875 (5.0534)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 17:24:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:44 lr 0.000038	 wd 0.0000	time 0.2358 (0.2739)	loss 1.4615 (1.3053)	grad_norm 4.0232 (5.0310)	loss_scale 2048.0000 (1057.3972)	mem 10191MB
[2024-07-02 17:24:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:02:16 lr 0.000038	 wd 0.0000	time 0.2141 (0.2726)	loss 1.5148 (1.3055)	grad_norm 3.4309 (5.0473)	loss_scale 2048.0000 (1106.9025)	mem 10191MB
[2024-07-02 17:25:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:49 lr 0.000039	 wd 0.0000	time 0.2679 (0.2734)	loss 1.3345 (1.3054)	grad_norm 4.1509 (5.0750)	loss_scale 2048.0000 (1151.6954)	mem 10191MB
[2024-07-02 17:25:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:22 lr 0.000039	 wd 0.0000	time 0.2565 (0.2729)	loss 0.9338 (1.3028)	grad_norm 3.8421 (5.0583)	loss_scale 2048.0000 (1192.4180)	mem 10191MB
[2024-07-02 17:26:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:54 lr 0.000039	 wd 0.0000	time 0.2332 (0.2719)	loss 1.1991 (1.3036)	grad_norm 3.4465 (5.0524)	loss_scale 2048.0000 (1229.6010)	mem 10191MB
[2024-07-02 17:26:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:27 lr 0.000040	 wd 0.0000	time 2.6738 (0.2720)	loss 1.3891 (1.3033)	grad_norm 3.1033 (5.0572)	loss_scale 2048.0000 (1263.6868)	mem 10191MB
[2024-07-02 17:26:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.2215 (0.2710)	loss 0.8372 (1.3029)	grad_norm 3.6722 (5.0334)	loss_scale 2048.0000 (1295.0468)	mem 10191MB
[2024-07-02 17:27:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 4 training takes 0:11:30
[2024-07-02 17:27:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 16.861 (16.861)	Loss 0.4065 (0.4065)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 10191MB
[2024-07-02 17:27:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.674 Acc@5 97.448
[2024-07-02 17:27:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 17:27:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 84.78%
[2024-07-02 17:27:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][0/2502]	eta 11:17:05 lr 0.000040	 wd 0.0000	time 16.2371 (16.2371)	loss 1.5087 (1.5087)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 17:28:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:16:29 lr 0.000040	 wd 0.0000	time 0.2631 (0.4120)	loss 1.2543 (1.3192)	grad_norm 4.0900 (4.8518)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 17:28:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:13:22 lr 0.000040	 wd 0.0000	time 0.2521 (0.3487)	loss 1.3727 (1.3316)	grad_norm 6.0402 (4.6422)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 17:29:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:11:44 lr 0.000040	 wd 0.0000	time 0.2278 (0.3199)	loss 1.5411 (1.3175)	grad_norm 5.9097 (4.8353)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 17:29:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:10:35 lr 0.000040	 wd 0.0000	time 0.2405 (0.3024)	loss 1.0930 (1.3188)	grad_norm 3.4951 (4.7968)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 17:30:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:09:51 lr 0.000040	 wd 0.0000	time 0.2356 (0.2956)	loss 1.6035 (1.3143)	grad_norm 3.4635 (nan)	loss_scale 1024.0000 (1949.8922)	mem 10191MB
[2024-07-02 17:30:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:09:15 lr 0.000040	 wd 0.0000	time 0.2439 (0.2919)	loss 1.4688 (1.3173)	grad_norm 4.1111 (nan)	loss_scale 1024.0000 (1795.8336)	mem 10191MB
[2024-07-02 17:31:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:08:37 lr 0.000040	 wd 0.0000	time 0.2352 (0.2870)	loss 1.4267 (1.3146)	grad_norm 6.7472 (nan)	loss_scale 1024.0000 (1685.7290)	mem 10191MB
[2024-07-02 17:31:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:08:06 lr 0.000040	 wd 0.0000	time 0.2380 (0.2859)	loss 1.0577 (1.3084)	grad_norm 3.2204 (nan)	loss_scale 1024.0000 (1603.1161)	mem 10191MB
[2024-07-02 17:31:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:07:36 lr 0.000040	 wd 0.0000	time 0.2329 (0.2849)	loss 0.7897 (1.3071)	grad_norm 3.5882 (nan)	loss_scale 1024.0000 (1538.8413)	mem 10191MB
[2024-07-02 17:32:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:07:02 lr 0.000040	 wd 0.0000	time 0.2368 (0.2815)	loss 1.3106 (1.3095)	grad_norm 3.3748 (nan)	loss_scale 1024.0000 (1487.4086)	mem 10191MB
[2024-07-02 17:32:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:06:35 lr 0.000040	 wd 0.0000	time 0.2353 (0.2818)	loss 1.4799 (1.3052)	grad_norm 3.0328 (nan)	loss_scale 1024.0000 (1445.3188)	mem 10191MB
[2024-07-02 17:33:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:06:03 lr 0.000040	 wd 0.0000	time 0.2341 (0.2791)	loss 1.4056 (1.3047)	grad_norm 4.1490 (nan)	loss_scale 1024.0000 (1410.2381)	mem 10191MB
[2024-07-02 17:33:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:05:35 lr 0.000040	 wd 0.0000	time 0.2484 (0.2790)	loss 1.4426 (1.3044)	grad_norm 3.9618 (nan)	loss_scale 1024.0000 (1380.5503)	mem 10191MB
[2024-07-02 17:34:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:05:05 lr 0.000040	 wd 0.0000	time 0.2392 (0.2772)	loss 1.3732 (1.3040)	grad_norm 3.1292 (nan)	loss_scale 1024.0000 (1355.1006)	mem 10191MB
[2024-07-02 17:34:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:04:36 lr 0.000040	 wd 0.0000	time 0.2414 (0.2758)	loss 1.2827 (1.3042)	grad_norm 3.3498 (nan)	loss_scale 1024.0000 (1333.0420)	mem 10191MB
[2024-07-02 17:35:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:04:10 lr 0.000040	 wd 0.0000	time 0.2334 (0.2773)	loss 1.4043 (1.3053)	grad_norm 3.9128 (nan)	loss_scale 512.0000 (1289.4341)	mem 10191MB
[2024-07-02 17:35:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:42 lr 0.000040	 wd 0.0000	time 0.2281 (0.2775)	loss 1.3808 (1.3054)	grad_norm 6.4621 (nan)	loss_scale 512.0000 (1243.7296)	mem 10191MB
[2024-07-02 17:35:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:03:14 lr 0.000040	 wd 0.0000	time 0.2369 (0.2765)	loss 0.9629 (1.3042)	grad_norm 4.5284 (nan)	loss_scale 512.0000 (1203.1005)	mem 10191MB
[2024-07-02 17:36:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:45 lr 0.000040	 wd 0.0000	time 0.2393 (0.2750)	loss 1.4534 (1.3062)	grad_norm 5.1341 (nan)	loss_scale 512.0000 (1166.7459)	mem 10191MB
[2024-07-02 17:36:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:02:19 lr 0.000040	 wd 0.0000	time 0.2135 (0.2774)	loss 1.3311 (1.3075)	grad_norm 2.8190 (nan)	loss_scale 512.0000 (1134.0250)	mem 10191MB
[2024-07-02 17:37:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:51 lr 0.000040	 wd 0.0000	time 0.2411 (0.2762)	loss 1.4642 (1.3082)	grad_norm 3.3889 (nan)	loss_scale 512.0000 (1104.4188)	mem 10191MB
[2024-07-02 17:37:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:23 lr 0.000040	 wd 0.0000	time 0.2334 (0.2750)	loss 1.2986 (1.3061)	grad_norm 2.5990 (nan)	loss_scale 512.0000 (1077.5030)	mem 10191MB
[2024-07-02 17:38:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:55 lr 0.000040	 wd 0.0000	time 0.2778 (0.2742)	loss 0.8983 (1.3056)	grad_norm 3.0282 (nan)	loss_scale 512.0000 (1052.9266)	mem 10191MB
[2024-07-02 17:38:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:27 lr 0.000040	 wd 0.0000	time 0.2420 (0.2736)	loss 1.5669 (1.3057)	grad_norm 7.9071 (nan)	loss_scale 512.0000 (1030.3973)	mem 10191MB
[2024-07-02 17:39:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.2404 (0.2725)	loss 1.3789 (1.3055)	grad_norm 4.3334 (nan)	loss_scale 512.0000 (1009.6697)	mem 10191MB
[2024-07-02 17:39:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 5 training takes 0:11:25
[2024-07-02 17:39:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 18.075 (18.075)	Loss 0.4058 (0.4058)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 10191MB
[2024-07-02 17:39:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.686 Acc@5 97.462
[2024-07-02 17:39:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 17:39:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 84.78%
[2024-07-02 17:39:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][0/2502]	eta 10:22:52 lr 0.000040	 wd 0.0000	time 14.9370 (14.9370)	loss 1.6783 (1.6783)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:40:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:17:02 lr 0.000040	 wd 0.0000	time 0.2403 (0.4257)	loss 1.1852 (1.2935)	grad_norm 4.2548 (4.9325)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:40:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:13:05 lr 0.000040	 wd 0.0000	time 0.2263 (0.3410)	loss 1.3796 (1.3086)	grad_norm 3.8558 (5.4860)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:41:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:11:25 lr 0.000040	 wd 0.0000	time 0.2367 (0.3113)	loss 1.4841 (1.3125)	grad_norm 7.2541 (5.2534)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:41:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:10:24 lr 0.000040	 wd 0.0000	time 0.2404 (0.2970)	loss 1.3555 (1.3050)	grad_norm 4.0793 (5.1461)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:41:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:09:37 lr 0.000040	 wd 0.0000	time 0.2436 (0.2887)	loss 1.3889 (1.3019)	grad_norm 3.5583 (5.0339)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:42:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:09:00 lr 0.000040	 wd 0.0000	time 0.2256 (0.2842)	loss 1.4824 (1.3037)	grad_norm 3.4115 (5.0223)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:42:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:08:24 lr 0.000040	 wd 0.0000	time 0.2524 (0.2802)	loss 1.3049 (1.3042)	grad_norm 78.6109 (5.1744)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:43:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:57 lr 0.000040	 wd 0.0000	time 0.2689 (0.2806)	loss 1.1118 (1.3040)	grad_norm 3.9063 (5.0675)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:43:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:07:27 lr 0.000040	 wd 0.0000	time 0.2346 (0.2796)	loss 1.4734 (1.3057)	grad_norm 4.0434 (5.0033)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:44:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:56 lr 0.000040	 wd 0.0000	time 0.2258 (0.2770)	loss 1.2423 (1.3021)	grad_norm 4.7351 (4.9528)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:44:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:06:28 lr 0.000040	 wd 0.0000	time 0.2436 (0.2771)	loss 1.2594 (1.3001)	grad_norm 4.3922 (4.9035)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:45:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:06:05 lr 0.000040	 wd 0.0000	time 0.2548 (0.2811)	loss 1.0705 (1.3012)	grad_norm 3.2121 (4.8611)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:45:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:05:37 lr 0.000040	 wd 0.0000	time 0.2463 (0.2811)	loss 1.4569 (1.3002)	grad_norm 8.0152 (4.9095)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:46:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:05:08 lr 0.000040	 wd 0.0000	time 0.2221 (0.2799)	loss 1.6940 (1.2983)	grad_norm 4.5518 (4.9355)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:46:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:39 lr 0.000040	 wd 0.0000	time 0.2494 (0.2787)	loss 1.3717 (1.3007)	grad_norm 5.4638 (4.9196)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:46:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:04:10 lr 0.000040	 wd 0.0000	time 0.2357 (0.2778)	loss 1.3791 (1.2990)	grad_norm 4.1998 (4.9022)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:47:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:41 lr 0.000040	 wd 0.0000	time 0.2271 (0.2765)	loss 1.4978 (1.2988)	grad_norm 2.9826 (4.8628)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:47:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:03:13 lr 0.000040	 wd 0.0000	time 0.2327 (0.2754)	loss 1.0741 (1.2986)	grad_norm 4.4669 (4.8399)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:48:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:45 lr 0.000040	 wd 0.0000	time 0.2601 (0.2757)	loss 1.1956 (1.2987)	grad_norm 2.7896 (4.9263)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:48:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:02:17 lr 0.000039	 wd 0.0000	time 0.2265 (0.2747)	loss 1.0323 (1.2991)	grad_norm 4.6440 (4.8846)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:49:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:49 lr 0.000039	 wd 0.0000	time 0.2481 (0.2736)	loss 1.4417 (1.2984)	grad_norm 3.1686 (4.8769)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:49:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:22 lr 0.000039	 wd 0.0000	time 0.2328 (0.2726)	loss 1.2029 (1.2983)	grad_norm 4.4514 (4.8571)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:50:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:55 lr 0.000039	 wd 0.0000	time 0.2367 (0.2741)	loss 1.4315 (1.2988)	grad_norm 3.9872 (4.8527)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:50:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:27 lr 0.000039	 wd 0.0000	time 0.2492 (0.2738)	loss 1.0823 (1.2981)	grad_norm 5.2289 (4.8417)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:50:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.2194 (0.2726)	loss 0.9307 (1.2986)	grad_norm 4.7990 (4.8227)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:50:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 6 training takes 0:11:25
[2024-07-02 17:51:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 24.258 (24.258)	Loss 0.4016 (0.4016)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 10191MB
[2024-07-02 17:51:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.782 Acc@5 97.418
[2024-07-02 17:51:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-02 17:51:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 84.78%
[2024-07-02 17:51:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth saving......
[2024-07-02 17:51:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth saved !!!
[2024-07-02 17:51:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][0/2502]	eta 10:12:46 lr 0.000039	 wd 0.0000	time 14.6949 (14.6949)	loss 1.6191 (1.6191)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:52:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:16:19 lr 0.000039	 wd 0.0000	time 0.2430 (0.4079)	loss 1.3184 (1.3118)	grad_norm 4.4796 (4.7700)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:52:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:12:37 lr 0.000039	 wd 0.0000	time 0.2317 (0.3291)	loss 1.5129 (1.2910)	grad_norm 3.0905 (4.5779)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:53:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:11:28 lr 0.000039	 wd 0.0000	time 0.2285 (0.3128)	loss 1.2355 (1.2908)	grad_norm 4.9118 (4.6176)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:53:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:10:26 lr 0.000039	 wd 0.0000	time 0.2371 (0.2982)	loss 1.3383 (1.2934)	grad_norm 3.0850 (4.6325)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:54:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:09:44 lr 0.000039	 wd 0.0000	time 0.2344 (0.2921)	loss 1.4257 (1.2902)	grad_norm 3.8112 (4.6669)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 17:54:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:09:03 lr 0.000039	 wd 0.0000	time 0.2249 (0.2857)	loss 1.3338 (1.2938)	grad_norm 15.4710 (4.7182)	loss_scale 1024.0000 (580.1531)	mem 10191MB
[2024-07-02 17:54:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:08:35 lr 0.000039	 wd 0.0000	time 0.2550 (0.2860)	loss 1.3391 (1.2961)	grad_norm 3.1382 (4.7446)	loss_scale 1024.0000 (643.4693)	mem 10191MB
[2024-07-02 17:55:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:08:00 lr 0.000039	 wd 0.0000	time 0.2575 (0.2822)	loss 0.9903 (1.2983)	grad_norm 5.0966 (4.6791)	loss_scale 1024.0000 (690.9763)	mem 10191MB
[2024-07-02 17:55:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:07:27 lr 0.000039	 wd 0.0000	time 0.2649 (0.2791)	loss 1.1573 (1.3008)	grad_norm 3.9189 (4.6379)	loss_scale 1024.0000 (727.9378)	mem 10191MB
[2024-07-02 17:56:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:55 lr 0.000039	 wd 0.0000	time 0.2404 (0.2768)	loss 1.2410 (1.2979)	grad_norm 4.9161 (4.6087)	loss_scale 1024.0000 (757.5145)	mem 10191MB
[2024-07-02 17:56:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:06:27 lr 0.000039	 wd 0.0000	time 0.2360 (0.2760)	loss 1.2841 (1.2963)	grad_norm 4.1620 (4.5840)	loss_scale 1024.0000 (781.7184)	mem 10191MB
[2024-07-02 17:57:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:57 lr 0.000039	 wd 0.0000	time 0.2360 (0.2744)	loss 1.2845 (1.2937)	grad_norm 3.9985 (4.5714)	loss_scale 1024.0000 (801.8918)	mem 10191MB
[2024-07-02 17:57:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:05:27 lr 0.000039	 wd 0.0000	time 0.2143 (0.2726)	loss 1.3651 (1.2946)	grad_norm 3.5234 (4.5862)	loss_scale 1024.0000 (818.9639)	mem 10191MB
[2024-07-02 17:58:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:05:02 lr 0.000039	 wd 0.0000	time 0.3767 (0.2745)	loss 1.4682 (1.2950)	grad_norm 9.2024 (4.5866)	loss_scale 1024.0000 (833.5989)	mem 10191MB
[2024-07-02 17:58:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:34 lr 0.000039	 wd 0.0000	time 0.2347 (0.2735)	loss 1.4112 (1.2941)	grad_norm 4.2798 (4.5899)	loss_scale 1024.0000 (846.2838)	mem 10191MB
[2024-07-02 17:58:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:04:05 lr 0.000039	 wd 0.0000	time 0.2307 (0.2724)	loss 1.4229 (1.2952)	grad_norm 3.4882 (4.6041)	loss_scale 1024.0000 (857.3841)	mem 10191MB
[2024-07-02 17:59:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:37 lr 0.000039	 wd 0.0000	time 0.2387 (0.2712)	loss 1.5032 (1.2953)	grad_norm 4.8060 (4.6248)	loss_scale 1024.0000 (867.1793)	mem 10191MB
[2024-07-02 17:59:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:03:12 lr 0.000039	 wd 0.0000	time 0.2415 (0.2742)	loss 1.2537 (1.2950)	grad_norm 5.3457 (4.6551)	loss_scale 1024.0000 (875.8867)	mem 10191MB
[2024-07-02 18:00:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:44 lr 0.000039	 wd 0.0000	time 0.2522 (0.2735)	loss 1.2836 (1.2942)	grad_norm 4.0033 (4.6691)	loss_scale 1024.0000 (883.6781)	mem 10191MB
[2024-07-02 18:00:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:02:16 lr 0.000039	 wd 0.0000	time 0.2278 (0.2724)	loss 1.4173 (1.2950)	grad_norm 4.0154 (nan)	loss_scale 512.0000 (871.7561)	mem 10191MB
[2024-07-02 18:01:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:49 lr 0.000039	 wd 0.0000	time 0.2363 (0.2715)	loss 1.5657 (1.2965)	grad_norm 3.9012 (nan)	loss_scale 512.0000 (854.6330)	mem 10191MB
[2024-07-02 18:01:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:21 lr 0.000039	 wd 0.0000	time 0.2242 (0.2715)	loss 1.2164 (1.2950)	grad_norm 3.2280 (nan)	loss_scale 512.0000 (839.0659)	mem 10191MB
[2024-07-02 18:02:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:54 lr 0.000039	 wd 0.0000	time 0.2425 (0.2708)	loss 1.4251 (1.2956)	grad_norm 3.4296 (nan)	loss_scale 512.0000 (824.8518)	mem 10191MB
[2024-07-02 18:02:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:27 lr 0.000039	 wd 0.0000	time 0.2368 (0.2705)	loss 1.3158 (1.2955)	grad_norm 3.0348 (nan)	loss_scale 512.0000 (811.8217)	mem 10191MB
[2024-07-02 18:02:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.2220 (0.2694)	loss 1.2211 (1.2957)	grad_norm 3.9682 (nan)	loss_scale 512.0000 (799.8337)	mem 10191MB
[2024-07-02 18:03:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 7 training takes 0:11:26
[2024-07-02 18:03:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 17.325 (17.325)	Loss 0.4148 (0.4148)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 10191MB
[2024-07-02 18:03:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.668 Acc@5 97.432
[2024-07-02 18:03:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 18:03:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 84.78%
[2024-07-02 18:03:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][0/2502]	eta 11:22:11 lr 0.000039	 wd 0.0000	time 16.3595 (16.3595)	loss 1.4487 (1.4487)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:04:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:16:34 lr 0.000039	 wd 0.0000	time 0.2306 (0.4141)	loss 1.4080 (1.3252)	grad_norm 4.0401 (4.5072)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:04:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:13:13 lr 0.000039	 wd 0.0000	time 0.2563 (0.3449)	loss 1.3195 (1.2995)	grad_norm 4.0014 (4.4992)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:05:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:11:35 lr 0.000038	 wd 0.0000	time 0.2559 (0.3157)	loss 1.2796 (1.2942)	grad_norm 5.9181 (4.5394)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:05:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:10:34 lr 0.000038	 wd 0.0000	time 0.2376 (0.3018)	loss 1.3912 (1.2915)	grad_norm 3.3405 (4.4950)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:05:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:09:43 lr 0.000038	 wd 0.0000	time 0.2449 (0.2917)	loss 1.4532 (1.2979)	grad_norm 3.7750 (4.4857)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:06:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:09:11 lr 0.000038	 wd 0.0000	time 0.2349 (0.2900)	loss 1.5061 (1.3014)	grad_norm 3.3110 (4.6026)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:06:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:08:34 lr 0.000038	 wd 0.0000	time 0.2343 (0.2853)	loss 1.4850 (1.3015)	grad_norm 4.4854 (4.6617)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:07:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:59 lr 0.000038	 wd 0.0000	time 0.2251 (0.2815)	loss 1.3561 (1.3007)	grad_norm 5.8597 (4.7180)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:07:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:07:28 lr 0.000038	 wd 0.0000	time 0.2219 (0.2802)	loss 1.4593 (1.3016)	grad_norm 3.9154 (4.6494)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:08:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:07:01 lr 0.000038	 wd 0.0000	time 0.2632 (0.2807)	loss 1.3497 (1.2994)	grad_norm 4.3834 (4.6257)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:08:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:06:30 lr 0.000038	 wd 0.0000	time 0.2426 (0.2782)	loss 1.4264 (1.2960)	grad_norm 9.2774 (4.6410)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:09:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:59 lr 0.000038	 wd 0.0000	time 0.2249 (0.2760)	loss 1.3958 (1.2952)	grad_norm 3.3159 (4.6683)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:09:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:05:33 lr 0.000038	 wd 0.0000	time 0.2641 (0.2773)	loss 1.0120 (1.2934)	grad_norm 2.8220 (4.6673)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:09:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:05:03 lr 0.000038	 wd 0.0000	time 0.2335 (0.2756)	loss 0.8744 (1.2945)	grad_norm 4.3823 (4.8909)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:10:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:04:35 lr 0.000038	 wd 0.0000	time 0.2353 (0.2748)	loss 0.8657 (1.2912)	grad_norm 3.7804 (4.8948)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:10:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:04:06 lr 0.000038	 wd 0.0000	time 0.2487 (0.2732)	loss 1.1917 (1.2883)	grad_norm 6.2411 (4.8828)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:11:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:38 lr 0.000038	 wd 0.0000	time 0.2363 (0.2729)	loss 1.1887 (1.2897)	grad_norm 3.0255 (4.8987)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:11:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:03:10 lr 0.000038	 wd 0.0000	time 0.2222 (0.2718)	loss 1.4251 (1.2916)	grad_norm 2.9639 (4.8676)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:12:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:42 lr 0.000038	 wd 0.0000	time 0.2402 (0.2706)	loss 1.2191 (1.2918)	grad_norm 4.2042 (4.8377)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:12:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:02:15 lr 0.000038	 wd 0.0000	time 0.2639 (0.2695)	loss 1.6861 (1.2934)	grad_norm 3.6612 (4.8254)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:12:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:48 lr 0.000038	 wd 0.0000	time 0.2914 (0.2698)	loss 1.3092 (1.2935)	grad_norm 3.1384 (4.8408)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:13:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:21 lr 0.000038	 wd 0.0000	time 0.2390 (0.2709)	loss 1.3825 (1.2924)	grad_norm 5.1038 (4.8350)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:13:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:54 lr 0.000038	 wd 0.0000	time 0.2344 (0.2698)	loss 1.2947 (1.2928)	grad_norm 5.9615 (4.8282)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:14:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:27 lr 0.000038	 wd 0.0000	time 0.5747 (0.2702)	loss 1.3656 (1.2946)	grad_norm 3.9020 (4.8140)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:14:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000038	 wd 0.0000	time 0.2217 (0.2698)	loss 1.5037 (1.2957)	grad_norm 3.7492 (4.8069)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:14:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 8 training takes 0:11:20
[2024-07-02 18:15:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 17.741 (17.741)	Loss 0.4016 (0.4016)	Acc@1 92.578 (92.578)	Acc@5 98.242 (98.242)	Mem 10191MB
[2024-07-02 18:15:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.708 Acc@5 97.452
[2024-07-02 18:15:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 18:15:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 84.78%
[2024-07-02 18:15:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][0/2502]	eta 10:48:54 lr 0.000038	 wd 0.0000	time 15.5615 (15.5615)	loss 1.3054 (1.3054)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:16:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:18:36 lr 0.000038	 wd 0.0000	time 0.2464 (0.4649)	loss 1.2348 (1.2690)	grad_norm 3.1169 (4.8188)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:16:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:13:48 lr 0.000037	 wd 0.0000	time 0.2385 (0.3601)	loss 1.4084 (1.2735)	grad_norm 3.6230 (4.5068)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:16:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:11:53 lr 0.000037	 wd 0.0000	time 0.2395 (0.3240)	loss 1.3252 (1.2840)	grad_norm 4.9931 (4.5631)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:17:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:10:44 lr 0.000037	 wd 0.0000	time 0.2280 (0.3065)	loss 1.5036 (1.2803)	grad_norm 3.1472 (4.5481)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:17:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:10:04 lr 0.000037	 wd 0.0000	time 0.3191 (0.3019)	loss 1.2732 (1.2852)	grad_norm 3.6468 (4.6158)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:18:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:09:20 lr 0.000037	 wd 0.0000	time 0.2273 (0.2949)	loss 1.3270 (1.2796)	grad_norm 4.0759 (4.6383)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:18:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:08:40 lr 0.000037	 wd 0.0000	time 0.2293 (0.2888)	loss 1.4648 (1.2803)	grad_norm 2.7018 (4.6147)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:19:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:08:08 lr 0.000037	 wd 0.0000	time 0.3057 (0.2873)	loss 1.3293 (1.2850)	grad_norm 4.1464 (4.5880)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:19:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:07:35 lr 0.000037	 wd 0.0000	time 0.2355 (0.2843)	loss 1.4783 (1.2826)	grad_norm 5.9800 (4.5999)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:20:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:07:06 lr 0.000037	 wd 0.0000	time 0.2351 (0.2838)	loss 1.4527 (1.2846)	grad_norm 4.0309 (4.6110)	loss_scale 1024.0000 (551.8961)	mem 10191MB
[2024-07-02 18:20:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:06:33 lr 0.000037	 wd 0.0000	time 0.2556 (0.2807)	loss 1.2839 (1.2882)	grad_norm 4.6073 (4.6140)	loss_scale 1024.0000 (594.7757)	mem 10191MB
[2024-07-02 18:20:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:06:04 lr 0.000037	 wd 0.0000	time 0.2615 (0.2799)	loss 1.5324 (1.2908)	grad_norm 3.9830 (4.6175)	loss_scale 1024.0000 (630.5146)	mem 10191MB
[2024-07-02 18:21:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:05:34 lr 0.000037	 wd 0.0000	time 0.2347 (0.2782)	loss 0.9051 (1.2882)	grad_norm 5.1025 (4.6213)	loss_scale 1024.0000 (660.7594)	mem 10191MB
[2024-07-02 18:21:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:05:04 lr 0.000037	 wd 0.0000	time 0.2424 (0.2765)	loss 1.3224 (1.2903)	grad_norm 3.7894 (4.6013)	loss_scale 1024.0000 (686.6867)	mem 10191MB
[2024-07-02 18:22:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:04:35 lr 0.000037	 wd 0.0000	time 0.2418 (0.2747)	loss 1.4829 (1.2926)	grad_norm 5.2414 (4.6148)	loss_scale 1024.0000 (709.1592)	mem 10191MB
[2024-07-02 18:22:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:04:07 lr 0.000037	 wd 0.0000	time 0.2991 (0.2747)	loss 0.9006 (1.2922)	grad_norm 4.3416 (4.6316)	loss_scale 1024.0000 (728.8245)	mem 10191MB
[2024-07-02 18:23:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:39 lr 0.000037	 wd 0.0000	time 0.2315 (0.2738)	loss 1.0244 (1.2937)	grad_norm 3.7984 (4.6288)	loss_scale 1024.0000 (746.1775)	mem 10191MB
[2024-07-02 18:23:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:03:11 lr 0.000037	 wd 0.0000	time 0.2133 (0.2725)	loss 1.4453 (1.2944)	grad_norm 3.9991 (4.6304)	loss_scale 1024.0000 (761.6036)	mem 10191MB
[2024-07-02 18:23:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:43 lr 0.000037	 wd 0.0000	time 0.2479 (0.2711)	loss 1.3416 (1.2935)	grad_norm 6.4318 (4.6434)	loss_scale 1024.0000 (775.4066)	mem 10191MB
[2024-07-02 18:24:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:02:15 lr 0.000037	 wd 0.0000	time 0.2270 (0.2707)	loss 1.4894 (1.2927)	grad_norm 5.1333 (4.6458)	loss_scale 1024.0000 (787.8301)	mem 10191MB
[2024-07-02 18:24:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:48 lr 0.000036	 wd 0.0000	time 0.2311 (0.2698)	loss 1.1315 (1.2934)	grad_norm 6.3946 (4.6576)	loss_scale 1024.0000 (799.0709)	mem 10191MB
[2024-07-02 18:25:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:21 lr 0.000036	 wd 0.0000	time 0.2222 (0.2689)	loss 1.3971 (1.2948)	grad_norm 4.6481 (4.6649)	loss_scale 1024.0000 (809.2903)	mem 10191MB
[2024-07-02 18:25:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:54 lr 0.000036	 wd 0.0000	time 0.2836 (0.2680)	loss 1.3426 (1.2955)	grad_norm 4.0875 (4.6509)	loss_scale 1024.0000 (818.6215)	mem 10191MB
[2024-07-02 18:26:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:27 lr 0.000036	 wd 0.0000	time 0.2281 (0.2674)	loss 1.2099 (1.2953)	grad_norm 7.2012 (4.6579)	loss_scale 1024.0000 (827.1753)	mem 10191MB
[2024-07-02 18:26:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000036	 wd 0.0000	time 0.2217 (0.2666)	loss 0.8649 (1.2963)	grad_norm 3.7427 (4.6399)	loss_scale 1024.0000 (835.0452)	mem 10191MB
[2024-07-02 18:26:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 9 training takes 0:11:10
[2024-07-02 18:26:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 16.335 (16.335)	Loss 0.3862 (0.3862)	Acc@1 92.969 (92.969)	Acc@5 98.633 (98.633)	Mem 10191MB
[2024-07-02 18:26:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.880 Acc@5 97.398
[2024-07-02 18:26:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-02 18:26:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 84.88%
[2024-07-02 18:26:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth saving......
[2024-07-02 18:26:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth saved !!!
[2024-07-02 18:27:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][0/2502]	eta 10:06:20 lr 0.000036	 wd 0.0000	time 14.5406 (14.5406)	loss 1.2500 (1.2500)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:27:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:16:25 lr 0.000036	 wd 0.0000	time 0.2349 (0.4104)	loss 1.1661 (1.2617)	grad_norm 3.1181 (4.5662)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:28:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:12:43 lr 0.000036	 wd 0.0000	time 0.2454 (0.3316)	loss 1.3209 (1.2859)	grad_norm 3.6752 (4.5822)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:28:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:11:12 lr 0.000036	 wd 0.0000	time 0.2294 (0.3055)	loss 0.8792 (1.2877)	grad_norm 3.6995 (4.5197)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:28:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:10:18 lr 0.000036	 wd 0.0000	time 0.2296 (0.2942)	loss 1.4628 (1.2928)	grad_norm 4.2122 (4.5439)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:29:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:09:35 lr 0.000036	 wd 0.0000	time 0.2516 (0.2877)	loss 1.4492 (1.2907)	grad_norm 2.8482 (4.5150)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:29:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:58 lr 0.000036	 wd 0.0000	time 0.2441 (0.2832)	loss 1.5365 (1.2894)	grad_norm 7.1334 (4.4854)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:30:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:08:22 lr 0.000036	 wd 0.0000	time 0.2283 (0.2790)	loss 1.3834 (1.2868)	grad_norm 3.1937 (4.4807)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:30:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:07:55 lr 0.000036	 wd 0.0000	time 0.2478 (0.2793)	loss 1.2380 (1.2879)	grad_norm 3.1790 (4.5119)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:31:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:07:24 lr 0.000036	 wd 0.0000	time 0.2318 (0.2773)	loss 1.4320 (1.2881)	grad_norm 3.6862 (4.5076)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:31:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:53 lr 0.000036	 wd 0.0000	time 0.2320 (0.2751)	loss 1.5234 (1.2865)	grad_norm 3.5802 (4.4788)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:32:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:06:22 lr 0.000036	 wd 0.0000	time 0.2346 (0.2729)	loss 1.3005 (1.2841)	grad_norm 4.5097 (4.4471)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:32:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:54 lr 0.000035	 wd 0.0000	time 0.2442 (0.2723)	loss 1.1883 (1.2846)	grad_norm 4.6305 (4.4220)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:32:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:05:28 lr 0.000035	 wd 0.0000	time 0.2337 (0.2729)	loss 1.5404 (1.2872)	grad_norm 5.4663 (4.4531)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:33:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:59 lr 0.000035	 wd 0.0000	time 0.2488 (0.2713)	loss 1.3651 (1.2894)	grad_norm 3.9457 (4.4223)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:33:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:04:30 lr 0.000035	 wd 0.0000	time 0.2237 (0.2698)	loss 1.1722 (1.2895)	grad_norm 10.1792 (4.4350)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:34:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:04:04 lr 0.000035	 wd 0.0000	time 0.2242 (0.2715)	loss 1.1393 (1.2906)	grad_norm 3.0507 (4.4160)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:34:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:37 lr 0.000035	 wd 0.0000	time 0.2248 (0.2707)	loss 1.3367 (1.2914)	grad_norm 4.7950 (4.4533)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:35:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:03:09 lr 0.000035	 wd 0.0000	time 0.2282 (0.2695)	loss 1.2969 (1.2915)	grad_norm 13.8500 (4.4644)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:35:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:42 lr 0.000035	 wd 0.0000	time 0.2457 (0.2707)	loss 1.3627 (1.2924)	grad_norm 6.8907 (4.4744)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:36:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:02:15 lr 0.000035	 wd 0.0000	time 0.2458 (0.2707)	loss 1.2478 (1.2924)	grad_norm 5.5155 (4.4548)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:36:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:48 lr 0.000035	 wd 0.0000	time 0.2470 (0.2698)	loss 1.3953 (1.2938)	grad_norm 3.9456 (4.4453)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:36:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:21 lr 0.000035	 wd 0.0000	time 0.2377 (0.2689)	loss 0.9482 (1.2943)	grad_norm 4.0914 (4.4509)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:37:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:54 lr 0.000035	 wd 0.0000	time 0.2395 (0.2694)	loss 1.3985 (1.2938)	grad_norm 7.4213 (4.4365)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:37:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:27 lr 0.000035	 wd 0.0000	time 0.2191 (0.2688)	loss 1.3865 (1.2940)	grad_norm 4.1073 (4.4304)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 18:38:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.2199 (0.2678)	loss 1.4242 (1.2935)	grad_norm 6.6893 (4.4384)	loss_scale 2048.0000 (1056.7549)	mem 10191MB
[2024-07-02 18:38:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 10 training takes 0:11:13
[2024-07-02 18:38:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 17.397 (17.397)	Loss 0.4045 (0.4045)	Acc@1 91.797 (91.797)	Acc@5 98.242 (98.242)	Mem 10191MB
[2024-07-02 18:38:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.856 Acc@5 97.456
[2024-07-02 18:38:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-02 18:38:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 84.88%
[2024-07-02 18:39:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][0/2502]	eta 13:05:24 lr 0.000035	 wd 0.0000	time 18.8348 (18.8348)	loss 1.4469 (1.4469)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 18:39:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:17:58 lr 0.000035	 wd 0.0000	time 0.2329 (0.4490)	loss 1.2579 (1.2901)	grad_norm 4.4550 (4.7415)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 18:39:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:13:30 lr 0.000034	 wd 0.0000	time 0.2340 (0.3522)	loss 1.4970 (1.2933)	grad_norm 3.8863 (4.7884)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 18:40:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:11:40 lr 0.000034	 wd 0.0000	time 0.2360 (0.3179)	loss 1.2020 (1.2942)	grad_norm 3.2478 (4.7448)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 18:40:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:10:46 lr 0.000034	 wd 0.0000	time 0.2324 (0.3078)	loss 1.3895 (1.2976)	grad_norm 3.7711 (4.6599)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 18:41:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:09:54 lr 0.000034	 wd 0.0000	time 0.2606 (0.2969)	loss 1.2607 (1.2903)	grad_norm 2.3191 (4.6752)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 18:41:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:09:10 lr 0.000034	 wd 0.0000	time 0.2481 (0.2894)	loss 1.3797 (1.2881)	grad_norm 4.0250 (4.6889)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 18:42:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:08:33 lr 0.000034	 wd 0.0000	time 0.2514 (0.2852)	loss 1.3389 (1.2879)	grad_norm 3.1701 (4.6348)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 18:42:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:08:00 lr 0.000034	 wd 0.0000	time 0.2382 (0.2820)	loss 1.5952 (1.2911)	grad_norm 3.2733 (4.6208)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 18:42:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:07:27 lr 0.000034	 wd 0.0000	time 0.2255 (0.2790)	loss 1.4191 (1.2909)	grad_norm 4.6630 (4.6111)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 18:43:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:55 lr 0.000034	 wd 0.0000	time 0.2378 (0.2763)	loss 1.3905 (1.2910)	grad_norm 5.1612 (4.6113)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 18:43:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:06:25 lr 0.000034	 wd 0.0000	time 0.2412 (0.2751)	loss 1.3329 (1.2928)	grad_norm 3.3505 (4.6033)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 18:44:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:56 lr 0.000034	 wd 0.0000	time 0.2292 (0.2737)	loss 1.5064 (1.2932)	grad_norm 5.4333 (4.6303)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 18:44:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:05:27 lr 0.000034	 wd 0.0000	time 0.2656 (0.2721)	loss 1.0243 (1.2919)	grad_norm 2.9137 (4.6498)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 18:45:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:58 lr 0.000034	 wd 0.0000	time 0.2433 (0.2706)	loss 0.9119 (1.2915)	grad_norm 3.5175 (4.6587)	loss_scale 2048.0000 (2048.0000)	mem 10191MB
[2024-07-02 18:45:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:04:32 lr 0.000034	 wd 0.0000	time 0.2460 (0.2716)	loss 1.4009 (1.2909)	grad_norm 9.2489 (nan)	loss_scale 1024.0000 (1979.7788)	mem 10191MB
[2024-07-02 18:45:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:04:04 lr 0.000034	 wd 0.0000	time 0.2329 (0.2707)	loss 1.2136 (1.2921)	grad_norm 3.7814 (nan)	loss_scale 1024.0000 (1920.0800)	mem 10191MB
[2024-07-02 18:46:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:36 lr 0.000033	 wd 0.0000	time 0.2298 (0.2695)	loss 1.3048 (1.2910)	grad_norm 3.4942 (nan)	loss_scale 1024.0000 (1867.4004)	mem 10191MB
[2024-07-02 18:46:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:03:08 lr 0.000033	 wd 0.0000	time 0.2206 (0.2683)	loss 1.2593 (1.2926)	grad_norm 6.6636 (nan)	loss_scale 1024.0000 (1820.5708)	mem 10191MB
[2024-07-02 18:47:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:45 lr 0.000033	 wd 0.0000	time 0.2353 (0.2744)	loss 1.4848 (1.2923)	grad_norm 3.5716 (nan)	loss_scale 1024.0000 (1778.6681)	mem 10191MB
[2024-07-02 18:47:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:02:17 lr 0.000033	 wd 0.0000	time 0.2323 (0.2735)	loss 1.1245 (1.2921)	grad_norm 3.9379 (nan)	loss_scale 1024.0000 (1740.9535)	mem 10191MB
[2024-07-02 18:48:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:49 lr 0.000033	 wd 0.0000	time 0.2152 (0.2723)	loss 1.3311 (1.2913)	grad_norm 3.2763 (nan)	loss_scale 1024.0000 (1706.8291)	mem 10191MB
[2024-07-02 18:48:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:22 lr 0.000033	 wd 0.0000	time 0.2297 (0.2728)	loss 1.3623 (1.2929)	grad_norm 3.0268 (nan)	loss_scale 1024.0000 (1675.8055)	mem 10191MB
[2024-07-02 18:49:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:55 lr 0.000033	 wd 0.0000	time 0.2406 (0.2724)	loss 1.4185 (1.2924)	grad_norm 5.0749 (nan)	loss_scale 512.0000 (1635.0178)	mem 10191MB
[2024-07-02 18:49:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:27 lr 0.000033	 wd 0.0000	time 0.2291 (0.2714)	loss 1.3220 (1.2917)	grad_norm 7.2032 (nan)	loss_scale 512.0000 (1588.2449)	mem 10191MB
[2024-07-02 18:49:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000033	 wd 0.0000	time 0.2243 (0.2710)	loss 1.3143 (1.2918)	grad_norm 4.5399 (nan)	loss_scale 512.0000 (1545.2123)	mem 10191MB
[2024-07-02 18:50:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 11 training takes 0:11:21
[2024-07-02 18:50:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 18.807 (18.807)	Loss 0.4021 (0.4021)	Acc@1 92.383 (92.383)	Acc@5 98.242 (98.242)	Mem 10191MB
[2024-07-02 18:50:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.866 Acc@5 97.440
[2024-07-02 18:50:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-02 18:50:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 84.88%
[2024-07-02 18:50:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][0/2502]	eta 11:05:34 lr 0.000033	 wd 0.0000	time 15.9608 (15.9608)	loss 1.5723 (1.5723)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:51:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:16:55 lr 0.000033	 wd 0.0000	time 0.2728 (0.4226)	loss 1.4583 (1.2888)	grad_norm 5.5302 (4.6826)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:51:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:12:56 lr 0.000033	 wd 0.0000	time 0.2367 (0.3372)	loss 0.8581 (1.2947)	grad_norm 3.7751 (4.5300)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:52:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:11:22 lr 0.000033	 wd 0.0000	time 0.2333 (0.3100)	loss 1.2574 (1.2943)	grad_norm 3.8861 (4.4967)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:52:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:10:20 lr 0.000033	 wd 0.0000	time 0.2479 (0.2954)	loss 1.2353 (1.2879)	grad_norm 2.8994 (4.5323)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:52:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:09:33 lr 0.000032	 wd 0.0000	time 0.2272 (0.2866)	loss 1.0116 (1.2900)	grad_norm 3.7624 (4.7055)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:53:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:08:54 lr 0.000032	 wd 0.0000	time 0.2427 (0.2810)	loss 1.2663 (1.2870)	grad_norm 3.4834 (4.7239)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:53:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:08:28 lr 0.000032	 wd 0.0000	time 0.2381 (0.2821)	loss 1.3441 (1.2868)	grad_norm 3.6495 (4.8658)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:54:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:07:54 lr 0.000032	 wd 0.0000	time 0.2341 (0.2786)	loss 1.5920 (1.2964)	grad_norm 7.4594 (4.8849)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:54:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:07:21 lr 0.000032	 wd 0.0000	time 0.2442 (0.2757)	loss 1.0207 (1.2978)	grad_norm 4.4576 (4.8854)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:55:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:59 lr 0.000032	 wd 0.0000	time 0.2432 (0.2792)	loss 1.3450 (1.2963)	grad_norm 3.5441 (4.8674)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:55:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:06:31 lr 0.000032	 wd 0.0000	time 0.2395 (0.2789)	loss 1.4189 (1.3013)	grad_norm 4.7112 (4.8617)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:56:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:06:00 lr 0.000032	 wd 0.0000	time 0.2427 (0.2769)	loss 1.5086 (1.2997)	grad_norm 3.6670 (4.8451)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:56:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:05:31 lr 0.000032	 wd 0.0000	time 0.2271 (0.2757)	loss 1.4853 (1.2998)	grad_norm 4.3476 (4.8372)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:57:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:05:07 lr 0.000032	 wd 0.0000	time 0.2356 (0.2793)	loss 1.4378 (1.2997)	grad_norm 4.6081 (4.7952)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:57:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:04:38 lr 0.000032	 wd 0.0000	time 0.2472 (0.2776)	loss 1.3699 (1.3003)	grad_norm 3.4557 (4.7842)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:57:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:04:09 lr 0.000032	 wd 0.0000	time 0.2286 (0.2761)	loss 1.4290 (1.2988)	grad_norm 4.6433 (4.7587)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:58:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:41 lr 0.000031	 wd 0.0000	time 0.2337 (0.2763)	loss 1.3515 (1.3000)	grad_norm 3.7843 (4.8341)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:58:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:03:13 lr 0.000031	 wd 0.0000	time 0.2412 (0.2757)	loss 1.2847 (1.3007)	grad_norm 4.5239 (4.8226)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:59:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:45 lr 0.000031	 wd 0.0000	time 0.2375 (0.2745)	loss 1.2574 (1.3005)	grad_norm 3.7792 (4.7975)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 18:59:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:02:17 lr 0.000031	 wd 0.0000	time 0.2355 (0.2732)	loss 1.3114 (1.2999)	grad_norm 8.2764 (4.7975)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:00:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:50 lr 0.000031	 wd 0.0000	time 0.2396 (0.2743)	loss 1.4636 (1.3007)	grad_norm 3.8634 (4.7669)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:00:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:22 lr 0.000031	 wd 0.0000	time 0.2339 (0.2740)	loss 1.4258 (1.3013)	grad_norm 3.1825 (4.7528)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:01:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:55 lr 0.000031	 wd 0.0000	time 0.2226 (0.2731)	loss 1.2883 (1.3008)	grad_norm 3.1780 (4.7502)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:01:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:27 lr 0.000031	 wd 0.0000	time 0.2302 (0.2720)	loss 1.4601 (1.3005)	grad_norm 6.2993 (4.7696)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:01:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000031	 wd 0.0000	time 0.2185 (0.2739)	loss 1.0480 (1.2989)	grad_norm 2.9178 (4.7731)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:02:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 12 training takes 0:11:30
[2024-07-02 19:02:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 16.971 (16.971)	Loss 0.4026 (0.4026)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 10191MB
[2024-07-02 19:02:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.824 Acc@5 97.526
[2024-07-02 19:02:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-02 19:02:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 84.88%
[2024-07-02 19:02:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][0/2502]	eta 11:14:24 lr 0.000031	 wd 0.0000	time 16.1729 (16.1729)	loss 1.2764 (1.2764)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:03:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:16:35 lr 0.000031	 wd 0.0000	time 0.2487 (0.4146)	loss 1.4396 (1.2924)	grad_norm 4.2532 (4.3567)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:03:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:13:11 lr 0.000031	 wd 0.0000	time 0.2447 (0.3440)	loss 1.5369 (1.2941)	grad_norm 4.5798 (4.6297)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:04:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:11:30 lr 0.000031	 wd 0.0000	time 0.2208 (0.3135)	loss 1.4619 (1.3004)	grad_norm 4.2239 (4.5173)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:04:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:10:25 lr 0.000030	 wd 0.0000	time 0.2343 (0.2977)	loss 1.3558 (1.2977)	grad_norm 3.4884 (4.3751)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:04:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:09:40 lr 0.000030	 wd 0.0000	time 0.2459 (0.2902)	loss 1.4138 (1.2926)	grad_norm 4.3270 (4.4951)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:05:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:09:01 lr 0.000030	 wd 0.0000	time 0.2126 (0.2847)	loss 1.4514 (1.2972)	grad_norm 5.1800 (4.5201)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:05:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:08:25 lr 0.000030	 wd 0.0000	time 0.2424 (0.2804)	loss 1.6088 (1.2932)	grad_norm 3.5905 (4.4679)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:06:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:51 lr 0.000030	 wd 0.0000	time 0.2443 (0.2770)	loss 1.4262 (1.2963)	grad_norm 5.8070 (4.4525)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:06:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:07:22 lr 0.000030	 wd 0.0000	time 0.3997 (0.2761)	loss 1.4680 (1.2921)	grad_norm 4.1436 (4.4858)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:07:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:53 lr 0.000030	 wd 0.0000	time 0.2464 (0.2751)	loss 1.4348 (1.2947)	grad_norm 3.2847 (4.4663)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:07:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:06:26 lr 0.000030	 wd 0.0000	time 0.2185 (0.2755)	loss 1.3809 (1.2965)	grad_norm 8.8574 (4.5221)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:08:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:57 lr 0.000030	 wd 0.0000	time 0.2213 (0.2744)	loss 1.6001 (1.2939)	grad_norm 5.3694 (4.5133)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:08:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:05:30 lr 0.000030	 wd 0.0000	time 0.2619 (0.2746)	loss 1.4451 (1.2932)	grad_norm 5.1723 (4.5150)	loss_scale 1024.0000 (535.6126)	mem 10191MB
[2024-07-02 19:08:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:05:01 lr 0.000030	 wd 0.0000	time 0.2354 (0.2732)	loss 1.5441 (1.2939)	grad_norm 2.9831 (4.5389)	loss_scale 1024.0000 (570.4725)	mem 10191MB
[2024-07-02 19:09:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:04:32 lr 0.000030	 wd 0.0000	time 0.2291 (0.2719)	loss 1.4272 (1.2932)	grad_norm 3.9763 (4.5191)	loss_scale 1024.0000 (600.6875)	mem 10191MB
[2024-07-02 19:09:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:04:05 lr 0.000029	 wd 0.0000	time 0.2451 (0.2719)	loss 1.4046 (1.2930)	grad_norm 5.1976 (4.5012)	loss_scale 1024.0000 (627.1280)	mem 10191MB
[2024-07-02 19:10:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:37 lr 0.000029	 wd 0.0000	time 0.2286 (0.2714)	loss 0.8322 (1.2904)	grad_norm 4.9284 (4.5119)	loss_scale 1024.0000 (650.4597)	mem 10191MB
[2024-07-02 19:10:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:03:09 lr 0.000029	 wd 0.0000	time 0.2208 (0.2704)	loss 1.2770 (1.2917)	grad_norm 4.7011 (4.5202)	loss_scale 1024.0000 (671.2004)	mem 10191MB
[2024-07-02 19:11:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:42 lr 0.000029	 wd 0.0000	time 0.2486 (0.2693)	loss 1.1266 (1.2920)	grad_norm 4.0995 (4.4894)	loss_scale 1024.0000 (689.7591)	mem 10191MB
[2024-07-02 19:11:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:02:15 lr 0.000029	 wd 0.0000	time 0.2276 (0.2697)	loss 1.3390 (1.2925)	grad_norm 5.0929 (4.5081)	loss_scale 1024.0000 (706.4628)	mem 10191MB
[2024-07-02 19:11:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:48 lr 0.000029	 wd 0.0000	time 0.2186 (0.2694)	loss 1.0666 (1.2921)	grad_norm 3.4439 (4.5027)	loss_scale 1024.0000 (721.5764)	mem 10191MB
[2024-07-02 19:12:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:21 lr 0.000029	 wd 0.0000	time 0.6882 (0.2688)	loss 1.4998 (1.2938)	grad_norm 4.2977 (4.4943)	loss_scale 1024.0000 (735.3167)	mem 10191MB
[2024-07-02 19:12:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:54 lr 0.000029	 wd 0.0000	time 0.2739 (0.2679)	loss 1.3007 (1.2928)	grad_norm 3.7910 (4.4851)	loss_scale 1024.0000 (747.8627)	mem 10191MB
[2024-07-02 19:13:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:27 lr 0.000029	 wd 0.0000	time 0.2371 (0.2683)	loss 1.3933 (1.2936)	grad_norm 5.3272 (4.4821)	loss_scale 1024.0000 (759.3636)	mem 10191MB
[2024-07-02 19:13:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000029	 wd 0.0000	time 0.2193 (0.2673)	loss 1.4017 (1.2930)	grad_norm 3.9857 (4.4772)	loss_scale 1024.0000 (769.9448)	mem 10191MB
[2024-07-02 19:13:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 13 training takes 0:11:13
[2024-07-02 19:14:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 17.108 (17.108)	Loss 0.4001 (0.4001)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 10191MB
[2024-07-02 19:14:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.824 Acc@5 97.506
[2024-07-02 19:14:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-02 19:14:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 84.88%
[2024-07-02 19:14:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][0/2502]	eta 10:40:20 lr 0.000029	 wd 0.0000	time 15.3559 (15.3559)	loss 1.4998 (1.4998)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:14:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:17:05 lr 0.000029	 wd 0.0000	time 0.2394 (0.4269)	loss 1.4561 (1.2878)	grad_norm 3.5121 (4.6289)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:15:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:13:07 lr 0.000028	 wd 0.0000	time 0.2417 (0.3422)	loss 1.1810 (1.3115)	grad_norm 3.3065 (4.8430)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:15:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:11:29 lr 0.000028	 wd 0.0000	time 0.2224 (0.3133)	loss 1.0725 (1.2997)	grad_norm 5.2837 (4.8753)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:16:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:10:25 lr 0.000028	 wd 0.0000	time 0.2363 (0.2975)	loss 1.1267 (1.2881)	grad_norm 5.4749 (4.9514)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:16:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:09:42 lr 0.000028	 wd 0.0000	time 0.3780 (0.2912)	loss 1.3767 (1.2891)	grad_norm 4.7987 (4.8775)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:17:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:09:03 lr 0.000028	 wd 0.0000	time 0.2343 (0.2857)	loss 1.5353 (1.2929)	grad_norm 3.9569 (inf)	loss_scale 512.0000 (993.3311)	mem 10191MB
[2024-07-02 19:17:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:08:26 lr 0.000028	 wd 0.0000	time 0.2406 (0.2812)	loss 1.2959 (1.2893)	grad_norm 3.4969 (inf)	loss_scale 512.0000 (924.6676)	mem 10191MB
[2024-07-02 19:17:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:08:00 lr 0.000028	 wd 0.0000	time 0.2318 (0.2823)	loss 1.2826 (1.2867)	grad_norm 5.7468 (inf)	loss_scale 512.0000 (873.1486)	mem 10191MB
[2024-07-02 19:18:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:07:29 lr 0.000028	 wd 0.0000	time 0.2391 (0.2803)	loss 1.4841 (1.2851)	grad_norm 3.5717 (inf)	loss_scale 512.0000 (833.0655)	mem 10191MB
[2024-07-02 19:18:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:06:57 lr 0.000028	 wd 0.0000	time 0.2199 (0.2783)	loss 1.1037 (1.2838)	grad_norm 3.0809 (inf)	loss_scale 512.0000 (800.9910)	mem 10191MB
[2024-07-02 19:19:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:06:26 lr 0.000028	 wd 0.0000	time 0.2316 (0.2758)	loss 1.3197 (1.2815)	grad_norm 2.9761 (inf)	loss_scale 512.0000 (774.7430)	mem 10191MB
[2024-07-02 19:19:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:06:00 lr 0.000028	 wd 0.0000	time 0.2652 (0.2771)	loss 1.4735 (1.2816)	grad_norm 2.6593 (inf)	loss_scale 512.0000 (752.8659)	mem 10191MB
[2024-07-02 19:20:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:05:30 lr 0.000027	 wd 0.0000	time 0.2656 (0.2753)	loss 1.1470 (1.2828)	grad_norm 2.5912 (inf)	loss_scale 512.0000 (734.3520)	mem 10191MB
[2024-07-02 19:20:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:05:01 lr 0.000027	 wd 0.0000	time 0.2429 (0.2736)	loss 1.3905 (1.2822)	grad_norm 4.3250 (inf)	loss_scale 512.0000 (718.4811)	mem 10191MB
[2024-07-02 19:21:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:04:32 lr 0.000027	 wd 0.0000	time 0.2412 (0.2720)	loss 1.2791 (1.2832)	grad_norm 13.0352 (inf)	loss_scale 512.0000 (704.7249)	mem 10191MB
[2024-07-02 19:21:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:04:06 lr 0.000027	 wd 0.0000	time 0.2320 (0.2737)	loss 1.3295 (1.2842)	grad_norm 4.8695 (inf)	loss_scale 512.0000 (692.6871)	mem 10191MB
[2024-07-02 19:21:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:38 lr 0.000027	 wd 0.0000	time 0.2513 (0.2728)	loss 1.1663 (1.2847)	grad_norm 5.5215 (inf)	loss_scale 512.0000 (682.0647)	mem 10191MB
[2024-07-02 19:22:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:03:10 lr 0.000027	 wd 0.0000	time 0.2282 (0.2718)	loss 1.2365 (1.2841)	grad_norm 4.8445 (inf)	loss_scale 512.0000 (672.6219)	mem 10191MB
[2024-07-02 19:22:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:43 lr 0.000027	 wd 0.0000	time 0.2694 (0.2708)	loss 1.3471 (1.2841)	grad_norm 4.2122 (inf)	loss_scale 512.0000 (664.1725)	mem 10191MB
[2024-07-02 19:23:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:02:15 lr 0.000027	 wd 0.0000	time 0.2379 (0.2705)	loss 0.9633 (1.2856)	grad_norm 4.1340 (inf)	loss_scale 512.0000 (656.5677)	mem 10191MB
[2024-07-02 19:23:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:48 lr 0.000027	 wd 0.0000	time 0.2257 (0.2695)	loss 1.5762 (1.2848)	grad_norm 3.5134 (inf)	loss_scale 512.0000 (649.6868)	mem 10191MB
[2024-07-02 19:24:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:21 lr 0.000027	 wd 0.0000	time 0.2217 (0.2685)	loss 1.2278 (1.2852)	grad_norm 3.4654 (inf)	loss_scale 512.0000 (643.4312)	mem 10191MB
[2024-07-02 19:24:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:54 lr 0.000027	 wd 0.0000	time 0.2248 (0.2681)	loss 1.3158 (1.2863)	grad_norm 3.9314 (inf)	loss_scale 512.0000 (637.7193)	mem 10191MB
[2024-07-02 19:24:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:27 lr 0.000026	 wd 0.0000	time 0.2635 (0.2678)	loss 1.2152 (1.2873)	grad_norm 6.8984 (inf)	loss_scale 512.0000 (632.4831)	mem 10191MB
[2024-07-02 19:25:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.2339 (0.2669)	loss 1.2789 (1.2865)	grad_norm 4.4978 (inf)	loss_scale 512.0000 (627.6657)	mem 10191MB
[2024-07-02 19:25:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 14 training takes 0:11:11
[2024-07-02 19:25:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 16.801 (16.801)	Loss 0.3982 (0.3982)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 10191MB
[2024-07-02 19:25:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.860 Acc@5 97.512
[2024-07-02 19:25:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-02 19:25:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 84.88%
[2024-07-02 19:26:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][0/2502]	eta 20:36:19 lr 0.000026	 wd 0.0000	time 29.6482 (29.6482)	loss 1.2896 (1.2896)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:26:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:22:36 lr 0.000026	 wd 0.0000	time 0.2352 (0.5648)	loss 1.0297 (1.2776)	grad_norm 6.0014 (4.8987)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:27:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:15:46 lr 0.000026	 wd 0.0000	time 0.2475 (0.4112)	loss 1.3904 (1.2879)	grad_norm 3.2998 (4.8239)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:27:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:13:18 lr 0.000026	 wd 0.0000	time 0.2434 (0.3628)	loss 1.3170 (1.2763)	grad_norm 3.9280 (4.7990)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:28:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:11:55 lr 0.000026	 wd 0.0000	time 0.2200 (0.3406)	loss 1.2782 (1.2799)	grad_norm 5.8826 (4.6584)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:28:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:10:46 lr 0.000026	 wd 0.0000	time 0.2341 (0.3231)	loss 0.8507 (1.2740)	grad_norm 7.5473 (4.7236)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:28:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:09:53 lr 0.000026	 wd 0.0000	time 0.2320 (0.3119)	loss 0.8337 (1.2777)	grad_norm 4.5965 (4.7752)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:29:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:09:13 lr 0.000026	 wd 0.0000	time 0.2355 (0.3074)	loss 1.1071 (1.2813)	grad_norm 3.2953 (4.7560)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:29:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:08:34 lr 0.000026	 wd 0.0000	time 0.2374 (0.3026)	loss 1.4737 (1.2827)	grad_norm 5.1152 (4.8494)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:30:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:07:56 lr 0.000025	 wd 0.0000	time 0.2428 (0.2971)	loss 1.1355 (1.2820)	grad_norm 3.5500 (4.8153)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:30:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:07:19 lr 0.000025	 wd 0.0000	time 0.2317 (0.2925)	loss 1.2569 (1.2819)	grad_norm 3.6515 (4.7697)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:31:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:06:48 lr 0.000025	 wd 0.0000	time 0.2337 (0.2916)	loss 1.2541 (1.2790)	grad_norm 2.7488 (4.7774)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:31:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:06:15 lr 0.000025	 wd 0.0000	time 0.2397 (0.2886)	loss 1.5276 (1.2791)	grad_norm 2.7627 (4.7406)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:32:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:05:43 lr 0.000025	 wd 0.0000	time 0.2526 (0.2858)	loss 1.2947 (1.2780)	grad_norm 7.5083 (4.7241)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:32:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:05:12 lr 0.000025	 wd 0.0000	time 0.2493 (0.2836)	loss 1.2597 (1.2785)	grad_norm 6.1363 (4.7510)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:32:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:04:45 lr 0.000025	 wd 0.0000	time 0.3056 (0.2849)	loss 1.5737 (1.2779)	grad_norm 4.7964 (4.7457)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:33:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:04:15 lr 0.000025	 wd 0.0000	time 0.2422 (0.2829)	loss 1.1757 (1.2806)	grad_norm 3.5237 (4.7386)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:33:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:45 lr 0.000025	 wd 0.0000	time 0.2234 (0.2811)	loss 1.4952 (1.2809)	grad_norm 3.2666 (4.7866)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:34:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:03:16 lr 0.000025	 wd 0.0000	time 0.2303 (0.2801)	loss 0.9974 (1.2809)	grad_norm 4.3944 (4.7556)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:34:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:48 lr 0.000024	 wd 0.0000	time 0.2551 (0.2797)	loss 1.5712 (1.2819)	grad_norm 3.7429 (4.7260)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:35:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:02:19 lr 0.000024	 wd 0.0000	time 0.2384 (0.2788)	loss 1.6816 (1.2846)	grad_norm 3.6409 (4.7246)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 19:35:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:51 lr 0.000024	 wd 0.0000	time 0.2388 (0.2775)	loss 1.5332 (1.2853)	grad_norm 3.5673 (4.7187)	loss_scale 1024.0000 (521.2604)	mem 10191MB
[2024-07-02 19:35:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:23 lr 0.000024	 wd 0.0000	time 0.2505 (0.2765)	loss 0.8620 (1.2865)	grad_norm 3.9549 (4.6901)	loss_scale 1024.0000 (544.1018)	mem 10191MB
[2024-07-02 19:36:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:55 lr 0.000024	 wd 0.0000	time 0.2300 (0.2763)	loss 1.4533 (1.2869)	grad_norm 3.9739 (4.6854)	loss_scale 1024.0000 (564.9578)	mem 10191MB
[2024-07-02 19:36:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:28 lr 0.000024	 wd 0.0000	time 0.2453 (0.2752)	loss 1.1288 (1.2860)	grad_norm 3.7602 (4.6963)	loss_scale 1024.0000 (584.0766)	mem 10191MB
[2024-07-02 19:37:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.2353 (0.2740)	loss 1.3440 (1.2861)	grad_norm 3.2011 (4.7104)	loss_scale 1024.0000 (601.6665)	mem 10191MB
[2024-07-02 19:37:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 15 training takes 0:11:28
[2024-07-02 19:37:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_15.pth saving......
[2024-07-02 19:37:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_15.pth saved !!!
[2024-07-02 19:37:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 22.336 (22.336)	Loss 0.3984 (0.3984)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 10191MB
[2024-07-02 19:37:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.956 Acc@5 97.538
[2024-07-02 19:37:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-02 19:37:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 84.96%
[2024-07-02 19:37:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth saving......
[2024-07-02 19:37:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth saved !!!
[2024-07-02 19:38:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][0/2502]	eta 10:25:01 lr 0.000024	 wd 0.0000	time 14.9886 (14.9886)	loss 1.1451 (1.1451)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:38:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:16:16 lr 0.000024	 wd 0.0000	time 0.2412 (0.4064)	loss 1.4104 (1.2922)	grad_norm 3.2978 (4.3884)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:39:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:12:35 lr 0.000024	 wd 0.0000	time 0.2401 (0.3282)	loss 1.2419 (1.2981)	grad_norm 9.0845 (4.4419)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:39:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:11:25 lr 0.000024	 wd 0.0000	time 0.2345 (0.3111)	loss 1.3030 (1.3061)	grad_norm 4.0286 (4.5105)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:39:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:10:23 lr 0.000024	 wd 0.0000	time 0.2230 (0.2965)	loss 1.1569 (1.3008)	grad_norm 2.9205 (4.3758)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:40:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:09:36 lr 0.000023	 wd 0.0000	time 0.2324 (0.2879)	loss 1.3102 (1.3084)	grad_norm 3.8479 (4.3961)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:40:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:57 lr 0.000023	 wd 0.0000	time 0.2836 (0.2824)	loss 1.0348 (1.2997)	grad_norm 5.2488 (4.3535)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:41:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:08:29 lr 0.000023	 wd 0.0000	time 0.2450 (0.2826)	loss 1.2662 (1.3017)	grad_norm 3.3944 (4.3771)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:41:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:07:55 lr 0.000023	 wd 0.0000	time 0.2372 (0.2792)	loss 1.2640 (1.2952)	grad_norm 4.6489 (4.3761)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:42:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:07:22 lr 0.000023	 wd 0.0000	time 0.2411 (0.2760)	loss 1.2852 (1.2949)	grad_norm 6.0553 (4.4512)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:42:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:06:53 lr 0.000023	 wd 0.0000	time 0.2438 (0.2756)	loss 1.4311 (1.2951)	grad_norm 3.5047 (4.4746)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:42:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:06:25 lr 0.000023	 wd 0.0000	time 0.2314 (0.2750)	loss 1.3061 (1.2970)	grad_norm 3.3955 (4.5032)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:43:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:56 lr 0.000023	 wd 0.0000	time 0.2191 (0.2735)	loss 1.4590 (1.2961)	grad_norm 3.3179 (4.4857)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:43:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:05:26 lr 0.000023	 wd 0.0000	time 0.2271 (0.2715)	loss 1.0284 (1.2962)	grad_norm 3.7080 (4.5111)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:44:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:05:08 lr 0.000023	 wd 0.0000	time 0.2373 (0.2802)	loss 1.2463 (1.2940)	grad_norm 4.4837 (4.5205)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:44:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:04:38 lr 0.000022	 wd 0.0000	time 0.2293 (0.2784)	loss 1.3380 (1.2915)	grad_norm 3.6121 (4.5105)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:45:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:04:09 lr 0.000022	 wd 0.0000	time 0.2286 (0.2767)	loss 1.3719 (1.2909)	grad_norm 5.2706 (4.5111)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:45:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:41 lr 0.000022	 wd 0.0000	time 0.2436 (0.2764)	loss 1.0199 (1.2893)	grad_norm 3.7292 (4.4886)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:46:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:03:13 lr 0.000022	 wd 0.0000	time 0.2303 (0.2758)	loss 1.0562 (1.2883)	grad_norm 5.5857 (4.5506)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:46:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:45 lr 0.000022	 wd 0.0000	time 0.2188 (0.2744)	loss 1.2267 (1.2877)	grad_norm 4.2903 (4.5711)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:47:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:02:17 lr 0.000022	 wd 0.0000	time 0.2397 (0.2732)	loss 1.4988 (1.2878)	grad_norm 7.2603 (4.5884)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:47:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:50 lr 0.000022	 wd 0.0000	time 0.2436 (0.2737)	loss 1.3843 (1.2873)	grad_norm 3.7406 (4.5777)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:47:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:22 lr 0.000022	 wd 0.0000	time 0.2312 (0.2728)	loss 1.2806 (1.2880)	grad_norm 2.8195 (4.5850)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:48:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:54 lr 0.000022	 wd 0.0000	time 0.2390 (0.2719)	loss 1.2177 (1.2884)	grad_norm 6.6062 (4.5883)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:48:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:27 lr 0.000022	 wd 0.0000	time 0.2470 (0.2709)	loss 1.2584 (1.2882)	grad_norm 3.6303 (4.5852)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:49:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.2188 (0.2699)	loss 1.3552 (1.2880)	grad_norm 4.1792 (4.5681)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:49:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 16 training takes 0:11:22
[2024-07-02 19:49:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 17.036 (17.036)	Loss 0.3999 (0.3999)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 10191MB
[2024-07-02 19:49:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 85.014 Acc@5 97.562
[2024-07-02 19:49:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-02 19:49:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 85.01%
[2024-07-02 19:49:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth saving......
[2024-07-02 19:49:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth saved !!!
[2024-07-02 19:50:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][0/2502]	eta 10:33:54 lr 0.000021	 wd 0.0000	time 15.2014 (15.2014)	loss 1.3668 (1.3668)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:50:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:16:02 lr 0.000021	 wd 0.0000	time 0.2407 (0.4006)	loss 1.4944 (1.2664)	grad_norm 4.3474 (4.4059)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:50:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:13:07 lr 0.000021	 wd 0.0000	time 0.2589 (0.3421)	loss 1.4636 (1.2811)	grad_norm 4.7150 (4.2634)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:51:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:11:37 lr 0.000021	 wd 0.0000	time 0.2436 (0.3168)	loss 1.3549 (1.2781)	grad_norm 5.3925 (4.3468)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:51:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:10:32 lr 0.000021	 wd 0.0000	time 0.2366 (0.3010)	loss 1.0694 (1.2776)	grad_norm 5.7946 (4.3990)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:52:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:09:44 lr 0.000021	 wd 0.0000	time 0.4145 (0.2918)	loss 1.2859 (1.2751)	grad_norm 4.0845 (4.4524)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:52:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:09:05 lr 0.000021	 wd 0.0000	time 0.2382 (0.2869)	loss 1.1330 (1.2806)	grad_norm 4.4118 (4.5139)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:53:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:08:31 lr 0.000021	 wd 0.0000	time 0.3179 (0.2836)	loss 1.2731 (1.2845)	grad_norm 6.0585 (4.5343)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:53:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:07:55 lr 0.000021	 wd 0.0000	time 0.2239 (0.2796)	loss 1.2650 (1.2881)	grad_norm 5.3240 (4.7056)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:54:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:07:26 lr 0.000021	 wd 0.0000	time 0.2395 (0.2788)	loss 1.3919 (1.2905)	grad_norm 11.5349 (4.6884)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:54:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:56 lr 0.000020	 wd 0.0000	time 0.2333 (0.2775)	loss 1.4403 (1.2886)	grad_norm 3.5276 (4.6727)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 19:54:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:06:25 lr 0.000020	 wd 0.0000	time 0.2236 (0.2751)	loss 1.0906 (1.2870)	grad_norm 3.1945 (4.6328)	loss_scale 2048.0000 (1063.0627)	mem 10191MB
[2024-07-02 19:55:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:55 lr 0.000020	 wd 0.0000	time 0.2485 (0.2731)	loss 1.3273 (1.2893)	grad_norm 3.0564 (4.6301)	loss_scale 2048.0000 (1145.0724)	mem 10191MB
[2024-07-02 19:55:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:05:31 lr 0.000020	 wd 0.0000	time 0.5487 (0.2758)	loss 1.1888 (1.2894)	grad_norm 4.8449 (4.6363)	loss_scale 2048.0000 (1214.4750)	mem 10191MB
[2024-07-02 19:56:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:05:02 lr 0.000020	 wd 0.0000	time 0.2484 (0.2744)	loss 1.4139 (1.2897)	grad_norm 3.5523 (4.6766)	loss_scale 2048.0000 (1273.9700)	mem 10191MB
[2024-07-02 19:56:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:04:33 lr 0.000020	 wd 0.0000	time 0.2309 (0.2731)	loss 1.4582 (1.2904)	grad_norm 4.8726 (4.6640)	loss_scale 2048.0000 (1325.5376)	mem 10191MB
[2024-07-02 19:57:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:04:04 lr 0.000020	 wd 0.0000	time 0.2152 (0.2716)	loss 1.3532 (1.2915)	grad_norm 3.1966 (4.6541)	loss_scale 2048.0000 (1370.6633)	mem 10191MB
[2024-07-02 19:57:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:37 lr 0.000020	 wd 0.0000	time 0.2289 (0.2713)	loss 1.5031 (1.2928)	grad_norm 4.3774 (4.6380)	loss_scale 2048.0000 (1410.4832)	mem 10191MB
[2024-07-02 19:57:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:03:09 lr 0.000020	 wd 0.0000	time 0.2510 (0.2702)	loss 1.3563 (1.2934)	grad_norm 3.7762 (4.6203)	loss_scale 2048.0000 (1445.8812)	mem 10191MB
[2024-07-02 19:58:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:42 lr 0.000020	 wd 0.0000	time 0.2371 (0.2693)	loss 1.1976 (1.2940)	grad_norm 3.4041 (4.6291)	loss_scale 2048.0000 (1477.5550)	mem 10191MB
[2024-07-02 19:58:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:02:14 lr 0.000019	 wd 0.0000	time 0.2511 (0.2689)	loss 1.3700 (1.2918)	grad_norm 7.6062 (nan)	loss_scale 1024.0000 (1495.8281)	mem 10191MB
[2024-07-02 19:59:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:48 lr 0.000019	 wd 0.0000	time 0.2449 (0.2688)	loss 1.4370 (1.2916)	grad_norm 4.1471 (nan)	loss_scale 1024.0000 (1473.3708)	mem 10191MB
[2024-07-02 19:59:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:20 lr 0.000019	 wd 0.0000	time 0.2367 (0.2681)	loss 1.2732 (1.2922)	grad_norm 2.9742 (nan)	loss_scale 1024.0000 (1452.9541)	mem 10191MB
[2024-07-02 20:00:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:53 lr 0.000019	 wd 0.0000	time 0.2254 (0.2673)	loss 1.5131 (1.2913)	grad_norm 3.7573 (nan)	loss_scale 1024.0000 (1434.3120)	mem 10191MB
[2024-07-02 20:00:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:27 lr 0.000019	 wd 0.0000	time 0.2629 (0.2669)	loss 1.3488 (1.2896)	grad_norm 4.9580 (nan)	loss_scale 1024.0000 (1417.2228)	mem 10191MB
[2024-07-02 20:00:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000019	 wd 0.0000	time 0.2367 (0.2660)	loss 1.2414 (1.2902)	grad_norm 6.0219 (nan)	loss_scale 1024.0000 (1401.5002)	mem 10191MB
[2024-07-02 20:00:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 17 training takes 0:11:10
[2024-07-02 20:01:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 17.661 (17.661)	Loss 0.4016 (0.4016)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 10191MB
[2024-07-02 20:01:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.834 Acc@5 97.538
[2024-07-02 20:01:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-02 20:01:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 85.01%
[2024-07-02 20:01:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][0/2502]	eta 11:19:32 lr 0.000019	 wd 0.0000	time 16.2959 (16.2959)	loss 1.5045 (1.5045)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:02:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:16:51 lr 0.000019	 wd 0.0000	time 0.2459 (0.4213)	loss 1.5076 (1.3271)	grad_norm 2.9012 (4.0992)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:02:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:12:55 lr 0.000019	 wd 0.0000	time 0.2436 (0.3370)	loss 1.4866 (1.3028)	grad_norm 3.2963 (4.3349)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:03:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:11:20 lr 0.000019	 wd 0.0000	time 0.2454 (0.3089)	loss 1.4941 (1.2996)	grad_norm 3.3544 (4.2461)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:03:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:10:18 lr 0.000019	 wd 0.0000	time 0.2482 (0.2942)	loss 1.3498 (1.2972)	grad_norm 3.6350 (4.3723)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:03:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:09:35 lr 0.000018	 wd 0.0000	time 0.3016 (0.2875)	loss 1.1938 (1.2912)	grad_norm 3.7090 (4.3011)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:04:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:09:01 lr 0.000018	 wd 0.0000	time 0.2401 (0.2848)	loss 1.5411 (1.2905)	grad_norm 2.4964 (4.5805)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:04:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:08:25 lr 0.000018	 wd 0.0000	time 0.2427 (0.2803)	loss 1.5298 (1.2921)	grad_norm 2.8051 (4.5299)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:05:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:51 lr 0.000018	 wd 0.0000	time 0.2504 (0.2769)	loss 1.0460 (1.2891)	grad_norm 4.9483 (4.4998)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:05:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:07:22 lr 0.000018	 wd 0.0000	time 0.2462 (0.2764)	loss 1.3217 (1.2863)	grad_norm 6.8795 (4.4661)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:06:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:51 lr 0.000018	 wd 0.0000	time 0.2280 (0.2739)	loss 1.0889 (1.2901)	grad_norm 3.3933 (4.4640)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:06:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:06:21 lr 0.000018	 wd 0.0000	time 0.2311 (0.2720)	loss 1.2413 (1.2891)	grad_norm 2.9624 (4.4586)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:06:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:52 lr 0.000018	 wd 0.0000	time 0.2344 (0.2705)	loss 1.4527 (1.2892)	grad_norm 8.3309 (4.4451)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:07:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:05:24 lr 0.000018	 wd 0.0000	time 0.2510 (0.2701)	loss 1.4828 (1.2901)	grad_norm 4.0256 (4.4200)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:07:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:56 lr 0.000018	 wd 0.0000	time 0.2378 (0.2687)	loss 1.1170 (1.2893)	grad_norm 3.5547 (4.4015)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:08:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:04:28 lr 0.000017	 wd 0.0000	time 0.2275 (0.2679)	loss 1.4526 (1.2877)	grad_norm 6.3382 (4.4125)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:08:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:04:00 lr 0.000017	 wd 0.0000	time 0.2276 (0.2670)	loss 1.5330 (1.2876)	grad_norm 4.2399 (4.4511)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:09:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:34 lr 0.000017	 wd 0.0000	time 0.2435 (0.2671)	loss 1.4176 (1.2865)	grad_norm 28.1560 (4.4877)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:09:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:03:07 lr 0.000017	 wd 0.0000	time 0.2352 (0.2668)	loss 1.3084 (1.2881)	grad_norm 3.2588 (4.6375)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:09:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:40 lr 0.000017	 wd 0.0000	time 0.2419 (0.2658)	loss 1.4994 (1.2881)	grad_norm 2.9394 (4.6479)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:10:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:02:14 lr 0.000017	 wd 0.0000	time 0.2451 (0.2679)	loss 1.3421 (1.2900)	grad_norm 3.0166 (4.6422)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:10:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:47 lr 0.000017	 wd 0.0000	time 0.2726 (0.2671)	loss 1.3101 (1.2895)	grad_norm 3.0219 (4.6378)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:11:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:20 lr 0.000017	 wd 0.0000	time 0.2222 (0.2669)	loss 1.3408 (1.2893)	grad_norm 4.5838 (4.6355)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:11:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:53 lr 0.000017	 wd 0.0000	time 0.2524 (0.2661)	loss 1.3836 (1.2894)	grad_norm 6.0804 (4.6463)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:12:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:27 lr 0.000017	 wd 0.0000	time 0.2479 (0.2672)	loss 1.4571 (1.2910)	grad_norm 4.2449 (4.6402)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:12:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.2234 (0.2662)	loss 1.4624 (1.2908)	grad_norm 3.9218 (4.6448)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:12:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 18 training takes 0:11:10
[2024-07-02 20:12:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 16.902 (16.902)	Loss 0.3933 (0.3933)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 10191MB
[2024-07-02 20:13:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.914 Acc@5 97.514
[2024-07-02 20:13:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-02 20:13:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 85.01%
[2024-07-02 20:13:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][0/2502]	eta 11:06:16 lr 0.000016	 wd 0.0000	time 15.9780 (15.9780)	loss 1.4184 (1.4184)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:13:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:18:29 lr 0.000016	 wd 0.0000	time 0.2387 (0.4620)	loss 1.0585 (1.2980)	grad_norm 3.6842 (4.1449)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:14:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:13:39 lr 0.000016	 wd 0.0000	time 0.2466 (0.3562)	loss 1.4933 (1.2951)	grad_norm 3.3562 (4.2720)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:14:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:11:48 lr 0.000016	 wd 0.0000	time 0.2257 (0.3220)	loss 1.3008 (1.3047)	grad_norm 5.4621 (4.1612)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:15:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:10:41 lr 0.000016	 wd 0.0000	time 0.2340 (0.3054)	loss 1.4479 (1.3043)	grad_norm 4.9778 (4.1229)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:15:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:09:58 lr 0.000016	 wd 0.0000	time 0.2410 (0.2987)	loss 1.5490 (1.3022)	grad_norm 6.2292 (4.3376)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:16:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:09:14 lr 0.000016	 wd 0.0000	time 0.2655 (0.2917)	loss 1.5271 (1.2977)	grad_norm 3.8563 (4.3248)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:16:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:08:35 lr 0.000016	 wd 0.0000	time 0.2249 (0.2863)	loss 1.5968 (1.2996)	grad_norm 4.0862 (4.3337)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:16:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:08:03 lr 0.000016	 wd 0.0000	time 0.2371 (0.2841)	loss 1.2394 (1.2964)	grad_norm 3.9863 (4.3480)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:17:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:07:31 lr 0.000016	 wd 0.0000	time 0.2210 (0.2819)	loss 1.3831 (1.2977)	grad_norm 3.4422 (4.3063)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:17:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:59 lr 0.000016	 wd 0.0000	time 0.2624 (0.2791)	loss 1.4477 (1.3001)	grad_norm 4.3099 (4.2923)	loss_scale 2048.0000 (1048.5514)	mem 10191MB
[2024-07-02 20:18:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:06:27 lr 0.000015	 wd 0.0000	time 0.2349 (0.2766)	loss 0.8403 (1.2983)	grad_norm 3.2066 (4.2853)	loss_scale 2048.0000 (1139.3279)	mem 10191MB
[2024-07-02 20:18:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:06:00 lr 0.000015	 wd 0.0000	time 0.2415 (0.2770)	loss 1.0586 (1.2957)	grad_norm 3.4093 (4.3072)	loss_scale 2048.0000 (1214.9875)	mem 10191MB
[2024-07-02 20:19:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:05:30 lr 0.000015	 wd 0.0000	time 0.2252 (0.2752)	loss 1.3630 (1.2954)	grad_norm 3.9296 (4.3279)	loss_scale 2048.0000 (1279.0161)	mem 10191MB
[2024-07-02 20:19:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:05:01 lr 0.000015	 wd 0.0000	time 0.2287 (0.2736)	loss 1.3216 (1.2966)	grad_norm 2.8203 (4.3593)	loss_scale 2048.0000 (1333.9044)	mem 10191MB
[2024-07-02 20:19:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:04:33 lr 0.000015	 wd 0.0000	time 0.2561 (0.2728)	loss 1.1946 (1.2965)	grad_norm 3.2145 (4.3751)	loss_scale 2048.0000 (1381.4790)	mem 10191MB
[2024-07-02 20:20:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:04:06 lr 0.000015	 wd 0.0000	time 0.2486 (0.2737)	loss 1.2663 (1.2971)	grad_norm 3.1773 (4.3856)	loss_scale 2048.0000 (1423.1106)	mem 10191MB
[2024-07-02 20:20:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:38 lr 0.000015	 wd 0.0000	time 0.2327 (0.2728)	loss 1.4485 (1.2978)	grad_norm 4.0511 (4.3593)	loss_scale 2048.0000 (1459.8471)	mem 10191MB
[2024-07-02 20:21:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:03:10 lr 0.000015	 wd 0.0000	time 0.2323 (0.2716)	loss 1.2806 (1.2978)	grad_norm 3.5028 (4.3708)	loss_scale 2048.0000 (1492.5042)	mem 10191MB
[2024-07-02 20:21:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:44 lr 0.000015	 wd 0.0000	time 0.2251 (0.2727)	loss 1.2865 (1.2982)	grad_norm 3.1399 (4.3608)	loss_scale 2048.0000 (1521.7254)	mem 10191MB
[2024-07-02 20:22:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:02:16 lr 0.000015	 wd 0.0000	time 0.2289 (0.2726)	loss 0.9364 (1.2976)	grad_norm 3.5967 (4.3837)	loss_scale 2048.0000 (1548.0260)	mem 10191MB
[2024-07-02 20:22:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:49 lr 0.000014	 wd 0.0000	time 0.2249 (0.2716)	loss 1.1107 (1.2970)	grad_norm 3.2061 (inf)	loss_scale 1024.0000 (1527.9581)	mem 10191MB
[2024-07-02 20:23:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:21 lr 0.000014	 wd 0.0000	time 0.2163 (0.2706)	loss 1.4222 (1.2953)	grad_norm 2.6067 (inf)	loss_scale 1024.0000 (1505.0613)	mem 10191MB
[2024-07-02 20:23:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:54 lr 0.000014	 wd 0.0000	time 0.2625 (0.2718)	loss 1.3490 (1.2947)	grad_norm 6.7953 (inf)	loss_scale 1024.0000 (1484.1547)	mem 10191MB
[2024-07-02 20:23:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:27 lr 0.000014	 wd 0.0000	time 0.2331 (0.2710)	loss 1.4495 (1.2958)	grad_norm 2.8207 (inf)	loss_scale 1024.0000 (1464.9896)	mem 10191MB
[2024-07-02 20:24:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.2212 (0.2712)	loss 1.2140 (1.2958)	grad_norm 5.5156 (inf)	loss_scale 1024.0000 (1447.3571)	mem 10191MB
[2024-07-02 20:24:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 19 training takes 0:11:22
[2024-07-02 20:24:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 16.529 (16.529)	Loss 0.3906 (0.3906)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 10191MB
[2024-07-02 20:25:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 85.000 Acc@5 97.528
[2024-07-02 20:25:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-02 20:25:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 85.01%
[2024-07-02 20:25:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][0/2502]	eta 10:31:34 lr 0.000014	 wd 0.0000	time 15.1457 (15.1457)	loss 1.0466 (1.0466)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:25:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:16:29 lr 0.000014	 wd 0.0000	time 0.2278 (0.4121)	loss 1.6533 (1.2900)	grad_norm 4.0955 (5.2401)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:26:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:12:45 lr 0.000014	 wd 0.0000	time 0.2309 (0.3326)	loss 1.3338 (1.2951)	grad_norm 5.7369 (4.8563)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:26:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:11:29 lr 0.000014	 wd 0.0000	time 0.2826 (0.3131)	loss 1.3657 (1.2937)	grad_norm 3.2634 (4.7000)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:27:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:10:33 lr 0.000014	 wd 0.0000	time 0.2417 (0.3013)	loss 1.4651 (1.3007)	grad_norm 3.8369 (4.5991)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:27:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:09:45 lr 0.000014	 wd 0.0000	time 0.2640 (0.2925)	loss 1.2990 (1.2995)	grad_norm 5.7397 (4.5623)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:27:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:09:03 lr 0.000014	 wd 0.0000	time 0.2248 (0.2857)	loss 1.4066 (1.2953)	grad_norm 5.0306 (4.5533)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:28:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:08:35 lr 0.000013	 wd 0.0000	time 0.2393 (0.2861)	loss 1.4099 (1.3007)	grad_norm 3.2937 (4.6555)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:28:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:08:01 lr 0.000013	 wd 0.0000	time 0.2285 (0.2830)	loss 1.2176 (1.2980)	grad_norm 5.6965 (4.6890)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:29:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:07:28 lr 0.000013	 wd 0.0000	time 0.2294 (0.2800)	loss 1.5544 (1.3012)	grad_norm 3.0550 (4.6808)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:29:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:56 lr 0.000013	 wd 0.0000	time 0.2262 (0.2771)	loss 1.3090 (1.3005)	grad_norm 3.3287 (4.7472)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:30:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:06:29 lr 0.000013	 wd 0.0000	time 0.2369 (0.2781)	loss 1.3809 (1.2980)	grad_norm 3.3669 (4.7856)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:30:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:59 lr 0.000013	 wd 0.0000	time 0.2505 (0.2761)	loss 1.3108 (1.2952)	grad_norm 4.4325 (4.8032)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:30:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:05:29 lr 0.000013	 wd 0.0000	time 0.2263 (0.2743)	loss 1.1139 (1.2919)	grad_norm 6.3551 (4.7886)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:31:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:05:00 lr 0.000013	 wd 0.0000	time 0.3553 (0.2729)	loss 1.2934 (1.2935)	grad_norm 5.3367 (4.7712)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:31:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:04:32 lr 0.000013	 wd 0.0000	time 0.2139 (0.2722)	loss 1.1994 (1.2951)	grad_norm 4.4898 (4.7642)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:32:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:04:04 lr 0.000013	 wd 0.0000	time 0.2328 (0.2708)	loss 1.4584 (1.2958)	grad_norm 3.7468 (4.7438)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:32:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:36 lr 0.000012	 wd 0.0000	time 0.2381 (0.2699)	loss 1.5006 (1.2955)	grad_norm 4.2055 (4.7466)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:33:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:03:09 lr 0.000012	 wd 0.0000	time 0.2253 (0.2701)	loss 1.2418 (1.2947)	grad_norm 3.0813 (4.7436)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:33:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:43 lr 0.000012	 wd 0.0000	time 0.2383 (0.2710)	loss 1.5594 (1.2955)	grad_norm 3.1302 (4.7289)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:34:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:02:15 lr 0.000012	 wd 0.0000	time 0.2345 (0.2699)	loss 1.4193 (1.2949)	grad_norm 3.1351 (4.7432)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:34:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:48 lr 0.000012	 wd 0.0000	time 0.2343 (0.2690)	loss 1.3494 (1.2956)	grad_norm 2.9414 (4.7360)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:34:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:21 lr 0.000012	 wd 0.0000	time 0.2335 (0.2702)	loss 1.2293 (1.2969)	grad_norm 3.8131 (4.7354)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:35:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:54 lr 0.000012	 wd 0.0000	time 0.2331 (0.2696)	loss 1.2524 (1.2973)	grad_norm 4.0340 (4.7126)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:35:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:27 lr 0.000012	 wd 0.0000	time 0.2440 (0.2689)	loss 1.1914 (1.2976)	grad_norm 3.2021 (4.7574)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:36:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000012	 wd 0.0000	time 0.2219 (0.2677)	loss 1.4243 (1.2983)	grad_norm 4.3463 (4.7785)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:36:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 20 training takes 0:11:13
[2024-07-02 20:36:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 18.882 (18.882)	Loss 0.4036 (0.4036)	Acc@1 92.773 (92.773)	Acc@5 98.438 (98.438)	Mem 10191MB
[2024-07-02 20:36:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 85.022 Acc@5 97.522
[2024-07-02 20:36:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-02 20:36:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-02 20:36:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth saving......
[2024-07-02 20:36:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth saved !!!
[2024-07-02 20:37:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][0/2502]	eta 10:00:51 lr 0.000012	 wd 0.0000	time 14.4093 (14.4093)	loss 1.4991 (1.4991)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:37:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:15:56 lr 0.000012	 wd 0.0000	time 0.2538 (0.3983)	loss 1.5054 (1.3316)	grad_norm 3.9281 (4.6075)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:37:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:12:28 lr 0.000012	 wd 0.0000	time 0.2300 (0.3252)	loss 0.9356 (1.3006)	grad_norm 5.2771 (4.5284)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:38:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:11:07 lr 0.000012	 wd 0.0000	time 0.2399 (0.3033)	loss 1.3660 (1.2940)	grad_norm 3.8412 (4.6928)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:38:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:10:09 lr 0.000011	 wd 0.0000	time 0.2522 (0.2901)	loss 1.2707 (1.2966)	grad_norm 3.0717 (4.6149)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:39:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:09:26 lr 0.000011	 wd 0.0000	time 0.2133 (0.2828)	loss 1.2625 (1.2954)	grad_norm 6.0602 (4.5991)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:39:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:48 lr 0.000011	 wd 0.0000	time 0.2617 (0.2777)	loss 1.1824 (1.2967)	grad_norm 4.0672 (4.6289)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:40:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:08:23 lr 0.000011	 wd 0.0000	time 0.2309 (0.2796)	loss 1.2416 (1.2912)	grad_norm 2.9872 (4.6947)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:40:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:49 lr 0.000011	 wd 0.0000	time 0.2503 (0.2761)	loss 1.2035 (1.2896)	grad_norm 3.9355 (4.6194)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:40:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:07:18 lr 0.000011	 wd 0.0000	time 0.2420 (0.2735)	loss 1.4748 (1.2889)	grad_norm 6.1112 (4.6223)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:41:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:54 lr 0.000011	 wd 0.0000	time 0.5321 (0.2757)	loss 1.0288 (1.2880)	grad_norm 2.9220 (4.5907)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:41:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:06:25 lr 0.000011	 wd 0.0000	time 0.2286 (0.2748)	loss 1.3728 (1.2883)	grad_norm 4.4591 (4.5750)	loss_scale 2048.0000 (1111.4260)	mem 10191MB
[2024-07-02 20:42:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:55 lr 0.000011	 wd 0.0000	time 0.2286 (0.2729)	loss 1.3517 (1.2885)	grad_norm 2.6231 (4.5436)	loss_scale 2048.0000 (1189.4088)	mem 10191MB
[2024-07-02 20:42:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:05:25 lr 0.000011	 wd 0.0000	time 0.2596 (0.2711)	loss 1.4802 (1.2879)	grad_norm 2.8826 (4.5072)	loss_scale 2048.0000 (1255.4035)	mem 10191MB
[2024-07-02 20:43:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:58 lr 0.000011	 wd 0.0000	time 0.2328 (0.2712)	loss 1.2734 (1.2885)	grad_norm 5.3116 (4.5117)	loss_scale 2048.0000 (1311.9772)	mem 10191MB
[2024-07-02 20:43:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:04:30 lr 0.000010	 wd 0.0000	time 0.2603 (0.2699)	loss 1.5887 (1.2881)	grad_norm 4.4845 (4.5309)	loss_scale 2048.0000 (1361.0127)	mem 10191MB
[2024-07-02 20:43:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:04:02 lr 0.000010	 wd 0.0000	time 0.2193 (0.2691)	loss 1.2250 (1.2877)	grad_norm 3.9222 (4.5294)	loss_scale 2048.0000 (1403.9225)	mem 10191MB
[2024-07-02 20:44:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:34 lr 0.000010	 wd 0.0000	time 0.2488 (0.2679)	loss 1.4262 (1.2884)	grad_norm 3.1552 (4.5430)	loss_scale 2048.0000 (1441.7872)	mem 10191MB
[2024-07-02 20:44:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:03:09 lr 0.000010	 wd 0.0000	time 0.2293 (0.2701)	loss 1.0401 (1.2894)	grad_norm 4.3221 (4.5399)	loss_scale 2048.0000 (1475.4470)	mem 10191MB
[2024-07-02 20:45:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:42 lr 0.000010	 wd 0.0000	time 0.2509 (0.2693)	loss 1.0457 (1.2877)	grad_norm 4.7677 (4.5281)	loss_scale 2048.0000 (1505.5655)	mem 10191MB
[2024-07-02 20:45:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:02:14 lr 0.000010	 wd 0.0000	time 0.2522 (0.2684)	loss 1.3314 (1.2873)	grad_norm 4.5157 (4.5347)	loss_scale 2048.0000 (1532.6737)	mem 10191MB
[2024-07-02 20:46:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:47 lr 0.000010	 wd 0.0000	time 0.2403 (0.2679)	loss 1.1365 (1.2890)	grad_norm 4.1450 (4.5464)	loss_scale 2048.0000 (1557.2013)	mem 10191MB
[2024-07-02 20:46:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:21 lr 0.000010	 wd 0.0000	time 0.2418 (0.2683)	loss 1.5437 (1.2873)	grad_norm 5.4218 (nan)	loss_scale 1024.0000 (1552.5161)	mem 10191MB
[2024-07-02 20:47:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:54 lr 0.000010	 wd 0.0000	time 0.2129 (0.2676)	loss 1.5501 (1.2865)	grad_norm 3.6298 (nan)	loss_scale 1024.0000 (1529.5472)	mem 10191MB
[2024-07-02 20:47:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:27 lr 0.000010	 wd 0.0000	time 0.2503 (0.2669)	loss 1.3098 (1.2878)	grad_norm 3.0961 (nan)	loss_scale 1024.0000 (1508.4915)	mem 10191MB
[2024-07-02 20:47:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.2311 (0.2660)	loss 1.3854 (1.2873)	grad_norm 6.6739 (nan)	loss_scale 1024.0000 (1489.1196)	mem 10191MB
[2024-07-02 20:48:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 21 training takes 0:11:19
[2024-07-02 20:48:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 18.011 (18.011)	Loss 0.3926 (0.3926)	Acc@1 92.969 (92.969)	Acc@5 98.438 (98.438)	Mem 10191MB
[2024-07-02 20:48:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 85.006 Acc@5 97.520
[2024-07-02 20:48:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-02 20:48:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-02 20:48:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][0/2502]	eta 11:16:00 lr 0.000010	 wd 0.0000	time 16.2113 (16.2113)	loss 1.1899 (1.1899)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 20:49:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:16:27 lr 0.000010	 wd 0.0000	time 0.2420 (0.4112)	loss 1.3105 (1.3075)	grad_norm 4.3996 (nan)	loss_scale 512.0000 (527.2079)	mem 10191MB
[2024-07-02 20:49:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:13:26 lr 0.000009	 wd 0.0000	time 0.2394 (0.3502)	loss 0.9769 (1.2949)	grad_norm 2.8956 (nan)	loss_scale 512.0000 (519.6418)	mem 10191MB
[2024-07-02 20:50:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:11:40 lr 0.000009	 wd 0.0000	time 0.2755 (0.3181)	loss 1.4447 (1.3000)	grad_norm 8.7102 (nan)	loss_scale 512.0000 (517.1030)	mem 10191MB
[2024-07-02 20:50:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:10:40 lr 0.000009	 wd 0.0000	time 0.2236 (0.3049)	loss 1.2843 (1.3041)	grad_norm 4.3967 (nan)	loss_scale 512.0000 (515.8304)	mem 10191MB
[2024-07-02 20:51:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:09:51 lr 0.000009	 wd 0.0000	time 0.3038 (0.2954)	loss 0.9768 (1.3032)	grad_norm 5.2112 (nan)	loss_scale 512.0000 (515.0659)	mem 10191MB
[2024-07-02 20:51:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:09:15 lr 0.000009	 wd 0.0000	time 0.2268 (0.2920)	loss 1.4097 (1.3034)	grad_norm 4.3045 (nan)	loss_scale 512.0000 (514.5557)	mem 10191MB
[2024-07-02 20:51:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:08:36 lr 0.000009	 wd 0.0000	time 0.2404 (0.2868)	loss 0.8630 (1.2975)	grad_norm 7.4813 (nan)	loss_scale 512.0000 (514.1912)	mem 10191MB
[2024-07-02 20:52:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:08:00 lr 0.000009	 wd 0.0000	time 0.2499 (0.2824)	loss 1.2486 (1.2930)	grad_norm 3.1926 (nan)	loss_scale 512.0000 (513.9176)	mem 10191MB
[2024-07-02 20:52:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:07:31 lr 0.000009	 wd 0.0000	time 0.2395 (0.2817)	loss 1.2706 (1.2912)	grad_norm 3.8392 (nan)	loss_scale 512.0000 (513.7048)	mem 10191MB
[2024-07-02 20:53:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:07:00 lr 0.000009	 wd 0.0000	time 0.2342 (0.2798)	loss 1.4521 (1.2932)	grad_norm 4.0091 (nan)	loss_scale 512.0000 (513.5345)	mem 10191MB
[2024-07-02 20:53:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:06:28 lr 0.000009	 wd 0.0000	time 0.2395 (0.2774)	loss 1.2857 (1.2916)	grad_norm 5.1656 (nan)	loss_scale 512.0000 (513.3951)	mem 10191MB
[2024-07-02 20:54:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:58 lr 0.000009	 wd 0.0000	time 0.2263 (0.2752)	loss 1.2700 (1.2905)	grad_norm 3.9079 (nan)	loss_scale 512.0000 (513.2789)	mem 10191MB
[2024-07-02 20:54:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:05:33 lr 0.000009	 wd 0.0000	time 0.2946 (0.2776)	loss 0.9468 (1.2915)	grad_norm 4.1560 (nan)	loss_scale 512.0000 (513.1806)	mem 10191MB
[2024-07-02 20:55:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:05:03 lr 0.000008	 wd 0.0000	time 0.2161 (0.2758)	loss 1.4444 (1.2932)	grad_norm 3.3475 (nan)	loss_scale 512.0000 (513.0964)	mem 10191MB
[2024-07-02 20:55:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:04:34 lr 0.000008	 wd 0.0000	time 0.2411 (0.2744)	loss 1.1167 (1.2935)	grad_norm 7.1152 (nan)	loss_scale 512.0000 (513.0233)	mem 10191MB
[2024-07-02 20:55:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:04:06 lr 0.000008	 wd 0.0000	time 0.2543 (0.2734)	loss 1.4751 (1.2935)	grad_norm 4.7951 (nan)	loss_scale 512.0000 (512.9594)	mem 10191MB
[2024-07-02 20:56:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:39 lr 0.000008	 wd 0.0000	time 0.2499 (0.2735)	loss 1.2708 (1.2929)	grad_norm 3.8192 (nan)	loss_scale 512.0000 (512.9030)	mem 10191MB
[2024-07-02 20:56:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:03:11 lr 0.000008	 wd 0.0000	time 0.2357 (0.2725)	loss 1.5550 (1.2927)	grad_norm 3.6465 (nan)	loss_scale 512.0000 (512.8529)	mem 10191MB
[2024-07-02 20:57:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:43 lr 0.000008	 wd 0.0000	time 0.2403 (0.2713)	loss 1.4800 (1.2921)	grad_norm 4.0349 (nan)	loss_scale 512.0000 (512.8080)	mem 10191MB
[2024-07-02 20:57:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:02:16 lr 0.000008	 wd 0.0000	time 0.2960 (0.2719)	loss 1.3738 (1.2911)	grad_norm 3.9205 (nan)	loss_scale 512.0000 (512.7676)	mem 10191MB
[2024-07-02 20:58:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:49 lr 0.000008	 wd 0.0000	time 0.2373 (0.2720)	loss 1.4223 (1.2916)	grad_norm 3.4344 (nan)	loss_scale 512.0000 (512.7311)	mem 10191MB
[2024-07-02 20:58:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:21 lr 0.000008	 wd 0.0000	time 0.2324 (0.2711)	loss 1.4205 (1.2907)	grad_norm 4.6537 (nan)	loss_scale 512.0000 (512.6979)	mem 10191MB
[2024-07-02 20:58:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:54 lr 0.000008	 wd 0.0000	time 0.2494 (0.2701)	loss 1.5164 (1.2907)	grad_norm 4.7669 (nan)	loss_scale 512.0000 (512.6675)	mem 10191MB
[2024-07-02 20:59:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:27 lr 0.000008	 wd 0.0000	time 0.2406 (0.2706)	loss 1.0133 (1.2903)	grad_norm 5.8844 (nan)	loss_scale 512.0000 (512.6397)	mem 10191MB
[2024-07-02 20:59:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.2283 (0.2698)	loss 1.0320 (1.2895)	grad_norm 3.8716 (nan)	loss_scale 512.0000 (512.6142)	mem 10191MB
[2024-07-02 20:59:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 22 training takes 0:11:22
[2024-07-02 21:00:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 16.456 (16.456)	Loss 0.3992 (0.3992)	Acc@1 93.164 (93.164)	Acc@5 98.438 (98.438)	Mem 10191MB
[2024-07-02 21:00:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.990 Acc@5 97.546
[2024-07-02 21:00:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-02 21:00:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-02 21:00:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][0/2502]	eta 10:58:48 lr 0.000008	 wd 0.0000	time 15.7988 (15.7988)	loss 1.0545 (1.0545)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:01:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:18:20 lr 0.000008	 wd 0.0000	time 0.2279 (0.4581)	loss 1.3986 (1.3275)	grad_norm 6.2921 (4.4884)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:01:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:13:38 lr 0.000007	 wd 0.0000	time 0.2535 (0.3555)	loss 1.4490 (1.3079)	grad_norm 4.6832 (4.5348)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:02:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:11:47 lr 0.000007	 wd 0.0000	time 0.2360 (0.3214)	loss 1.3097 (1.3038)	grad_norm 2.8492 (4.4843)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:02:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:10:40 lr 0.000007	 wd 0.0000	time 0.2433 (0.3047)	loss 1.6469 (1.2986)	grad_norm 5.8772 (4.4796)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:02:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:09:50 lr 0.000007	 wd 0.0000	time 0.2506 (0.2948)	loss 1.5361 (1.3021)	grad_norm 15.6136 (4.5997)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:03:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:09:07 lr 0.000007	 wd 0.0000	time 0.2559 (0.2881)	loss 1.1291 (1.3020)	grad_norm 3.3803 (4.5403)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:03:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:08:30 lr 0.000007	 wd 0.0000	time 0.2313 (0.2831)	loss 1.4562 (1.2990)	grad_norm 3.9243 (4.4697)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:04:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:08:01 lr 0.000007	 wd 0.0000	time 0.2399 (0.2827)	loss 1.6311 (1.2969)	grad_norm 3.6820 (4.4655)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:04:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:07:29 lr 0.000007	 wd 0.0000	time 0.2361 (0.2806)	loss 1.5995 (1.2940)	grad_norm 4.6667 (4.4971)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:05:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:57 lr 0.000007	 wd 0.0000	time 0.2401 (0.2780)	loss 1.0313 (1.2935)	grad_norm 6.0942 (4.4951)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:05:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:06:26 lr 0.000007	 wd 0.0000	time 0.2283 (0.2759)	loss 0.8065 (1.2885)	grad_norm 4.3063 (4.5192)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:06:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:59 lr 0.000007	 wd 0.0000	time 0.2317 (0.2765)	loss 1.4986 (1.2903)	grad_norm 3.8535 (4.5212)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:06:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:05:30 lr 0.000007	 wd 0.0000	time 0.2332 (0.2748)	loss 1.4709 (1.2915)	grad_norm 3.8722 (4.5525)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:06:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:05:01 lr 0.000007	 wd 0.0000	time 0.2249 (0.2736)	loss 1.2989 (1.2909)	grad_norm 5.9103 (4.5587)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:07:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:04:32 lr 0.000006	 wd 0.0000	time 0.2520 (0.2719)	loss 1.1528 (1.2925)	grad_norm 5.3037 (4.5735)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:07:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:04:05 lr 0.000006	 wd 0.0000	time 0.2296 (0.2726)	loss 1.1754 (1.2926)	grad_norm 3.9495 (4.5846)	loss_scale 1024.0000 (543.9800)	mem 10191MB
[2024-07-02 21:08:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:37 lr 0.000006	 wd 0.0000	time 0.2309 (0.2715)	loss 1.2953 (1.2932)	grad_norm 3.8579 (4.5997)	loss_scale 1024.0000 (572.1999)	mem 10191MB
[2024-07-02 21:08:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:03:09 lr 0.000006	 wd 0.0000	time 0.2353 (0.2703)	loss 1.3119 (1.2926)	grad_norm 5.2635 (4.6121)	loss_scale 1024.0000 (597.2860)	mem 10191MB
[2024-07-02 21:09:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:42 lr 0.000006	 wd 0.0000	time 0.3889 (0.2704)	loss 1.1569 (1.2949)	grad_norm 11.3700 (4.5929)	loss_scale 1024.0000 (619.7328)	mem 10191MB
[2024-07-02 21:09:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:02:15 lr 0.000006	 wd 0.0000	time 0.2492 (0.2699)	loss 1.3308 (1.2938)	grad_norm 3.8701 (4.5807)	loss_scale 1024.0000 (639.9360)	mem 10191MB
[2024-07-02 21:09:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:48 lr 0.000006	 wd 0.0000	time 0.2560 (0.2691)	loss 1.6014 (1.2938)	grad_norm 4.4156 (inf)	loss_scale 512.0000 (656.2665)	mem 10191MB
[2024-07-02 21:10:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:20 lr 0.000006	 wd 0.0000	time 0.2290 (0.2682)	loss 1.4358 (1.2913)	grad_norm 4.8763 (inf)	loss_scale 512.0000 (649.7119)	mem 10191MB
[2024-07-02 21:10:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:54 lr 0.000006	 wd 0.0000	time 0.2566 (0.2676)	loss 1.4437 (1.2910)	grad_norm 4.3435 (inf)	loss_scale 512.0000 (643.7271)	mem 10191MB
[2024-07-02 21:11:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:27 lr 0.000006	 wd 0.0000	time 0.2394 (0.2672)	loss 1.4954 (1.2917)	grad_norm 4.4042 (inf)	loss_scale 512.0000 (638.2407)	mem 10191MB
[2024-07-02 21:11:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000006	 wd 0.0000	time 0.2176 (0.2662)	loss 1.3704 (1.2924)	grad_norm 2.9638 (inf)	loss_scale 512.0000 (633.1931)	mem 10191MB
[2024-07-02 21:11:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 23 training takes 0:11:13
[2024-07-02 21:12:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 17.625 (17.625)	Loss 0.3943 (0.3943)	Acc@1 92.773 (92.773)	Acc@5 98.438 (98.438)	Mem 10191MB
[2024-07-02 21:12:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 85.016 Acc@5 97.564
[2024-07-02 21:12:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-02 21:12:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-02 21:12:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][0/2502]	eta 12:57:00 lr 0.000006	 wd 0.0000	time 18.6332 (18.6332)	loss 1.5103 (1.5103)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:12:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:17:39 lr 0.000006	 wd 0.0000	time 0.2377 (0.4413)	loss 1.1779 (1.3251)	grad_norm 5.6731 (5.0722)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:13:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:13:19 lr 0.000006	 wd 0.0000	time 0.2527 (0.3472)	loss 1.5704 (1.3124)	grad_norm 3.3418 (4.8153)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:13:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:11:32 lr 0.000006	 wd 0.0000	time 0.2209 (0.3145)	loss 1.5695 (1.3029)	grad_norm 3.7986 (4.7296)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:14:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:10:34 lr 0.000005	 wd 0.0000	time 0.2652 (0.3020)	loss 1.3752 (1.2976)	grad_norm 6.9428 (4.7099)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:14:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:09:47 lr 0.000005	 wd 0.0000	time 0.2676 (0.2936)	loss 1.4977 (1.2994)	grad_norm 4.6784 (4.7781)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:15:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:09:08 lr 0.000005	 wd 0.0000	time 0.2244 (0.2881)	loss 1.2974 (1.2952)	grad_norm 3.1395 (4.7588)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:15:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:08:30 lr 0.000005	 wd 0.0000	time 0.2476 (0.2835)	loss 1.2676 (1.2969)	grad_norm 3.4229 (4.7743)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:16:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:08:02 lr 0.000005	 wd 0.0000	time 0.2397 (0.2832)	loss 1.3509 (1.2977)	grad_norm 4.8011 (4.7328)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:16:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:07:28 lr 0.000005	 wd 0.0000	time 0.2419 (0.2798)	loss 1.3912 (1.2957)	grad_norm 5.4324 (4.6838)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:16:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:57 lr 0.000005	 wd 0.0000	time 0.2525 (0.2778)	loss 1.2901 (1.2958)	grad_norm 3.9934 (4.6496)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:17:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:06:29 lr 0.000005	 wd 0.0000	time 0.2423 (0.2778)	loss 1.4356 (1.2941)	grad_norm 5.5341 (4.6373)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:17:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:06:00 lr 0.000005	 wd 0.0000	time 0.2430 (0.2765)	loss 1.1214 (1.2929)	grad_norm 3.7215 (4.6328)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:18:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:05:30 lr 0.000005	 wd 0.0000	time 0.2414 (0.2753)	loss 1.2188 (1.2939)	grad_norm 6.8560 (4.6121)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:18:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:05:01 lr 0.000005	 wd 0.0000	time 0.2469 (0.2734)	loss 1.2015 (1.2926)	grad_norm 3.5606 (4.5905)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:19:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:34 lr 0.000005	 wd 0.0000	time 0.2422 (0.2739)	loss 0.9553 (1.2915)	grad_norm 4.0859 (4.5727)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:19:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:04:06 lr 0.000005	 wd 0.0000	time 0.2286 (0.2733)	loss 1.3529 (1.2909)	grad_norm 5.3382 (4.5722)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:19:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:38 lr 0.000005	 wd 0.0000	time 0.2415 (0.2721)	loss 1.6761 (1.2931)	grad_norm 3.2353 (4.5480)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:20:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:03:10 lr 0.000005	 wd 0.0000	time 0.2434 (0.2709)	loss 1.1268 (1.2926)	grad_norm 18.6960 (4.5626)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:20:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:45 lr 0.000005	 wd 0.0000	time 0.2476 (0.2754)	loss 1.4168 (1.2939)	grad_norm 3.0322 (4.5732)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:21:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:02:18 lr 0.000004	 wd 0.0000	time 0.2282 (0.2756)	loss 1.4760 (1.2940)	grad_norm 4.9761 (4.5735)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:21:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:50 lr 0.000004	 wd 0.0000	time 0.2210 (0.2743)	loss 1.4391 (1.2924)	grad_norm 4.9359 (4.5852)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:22:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:23 lr 0.000004	 wd 0.0000	time 0.2147 (0.2750)	loss 1.1979 (1.2919)	grad_norm 5.1656 (4.5884)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:22:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:55 lr 0.000004	 wd 0.0000	time 0.2554 (0.2740)	loss 1.6366 (1.2915)	grad_norm 3.7991 (4.5864)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:23:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:27 lr 0.000004	 wd 0.0000	time 0.2298 (0.2732)	loss 1.4810 (1.2918)	grad_norm 4.1409 (4.5869)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:23:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000004	 wd 0.0000	time 0.2131 (0.2719)	loss 1.1954 (1.2924)	grad_norm 6.3851 (4.5829)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:23:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 24 training takes 0:11:27
[2024-07-02 21:24:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 19.976 (19.976)	Loss 0.3984 (0.3984)	Acc@1 92.969 (92.969)	Acc@5 98.828 (98.828)	Mem 10191MB
[2024-07-02 21:24:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 85.068 Acc@5 97.552
[2024-07-02 21:24:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-02 21:24:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 85.07%
[2024-07-02 21:24:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth saving......
[2024-07-02 21:24:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth saved !!!
[2024-07-02 21:24:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][0/2502]	eta 10:47:38 lr 0.000004	 wd 0.0000	time 15.5309 (15.5309)	loss 1.0400 (1.0400)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:25:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:16:11 lr 0.000004	 wd 0.0000	time 0.2382 (0.4043)	loss 1.2815 (1.2616)	grad_norm 3.8320 (3.9693)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:25:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:12:44 lr 0.000004	 wd 0.0000	time 0.2719 (0.3321)	loss 1.3715 (1.2835)	grad_norm 4.5674 (4.2223)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:25:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:11:14 lr 0.000004	 wd 0.0000	time 0.2309 (0.3062)	loss 0.9769 (1.2782)	grad_norm 2.6174 (4.3155)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:26:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:10:15 lr 0.000004	 wd 0.0000	time 0.2591 (0.2930)	loss 1.2057 (1.2921)	grad_norm 5.5673 (4.3866)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:26:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:09:29 lr 0.000004	 wd 0.0000	time 0.2516 (0.2844)	loss 1.3662 (1.2932)	grad_norm 4.3081 (4.3901)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:27:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:55 lr 0.000004	 wd 0.0000	time 0.2552 (0.2818)	loss 1.1179 (1.2951)	grad_norm 3.3292 (4.4325)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:27:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:08:21 lr 0.000004	 wd 0.0000	time 0.2399 (0.2783)	loss 1.1703 (1.2949)	grad_norm 3.3866 (4.3931)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:28:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:07:48 lr 0.000004	 wd 0.0000	time 0.2383 (0.2754)	loss 1.0276 (1.2954)	grad_norm 16.2284 (4.4024)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:28:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:07:17 lr 0.000004	 wd 0.0000	time 0.2251 (0.2730)	loss 1.3572 (1.2977)	grad_norm 4.6968 (4.3668)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:28:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:51 lr 0.000004	 wd 0.0000	time 0.2461 (0.2740)	loss 1.2747 (1.2983)	grad_norm 4.2394 (4.3724)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:29:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:06:22 lr 0.000004	 wd 0.0000	time 0.2462 (0.2726)	loss 1.3081 (1.2960)	grad_norm 3.9480 (4.3932)	loss_scale 1024.0000 (517.5804)	mem 10191MB
[2024-07-02 21:29:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:52 lr 0.000004	 wd 0.0000	time 0.2383 (0.2709)	loss 1.2382 (1.2975)	grad_norm 2.9455 (4.3888)	loss_scale 1024.0000 (559.7469)	mem 10191MB
[2024-07-02 21:30:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:05:23 lr 0.000003	 wd 0.0000	time 0.2205 (0.2692)	loss 1.4646 (1.2978)	grad_norm 4.8815 (4.3965)	loss_scale 1024.0000 (595.4312)	mem 10191MB
[2024-07-02 21:30:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:56 lr 0.000003	 wd 0.0000	time 0.2230 (0.2693)	loss 1.1537 (1.2987)	grad_norm 2.7921 (4.4021)	loss_scale 1024.0000 (626.0214)	mem 10191MB
[2024-07-02 21:31:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:04:28 lr 0.000003	 wd 0.0000	time 0.2513 (0.2681)	loss 1.1953 (1.2978)	grad_norm 4.6482 (4.3987)	loss_scale 1024.0000 (652.5356)	mem 10191MB
[2024-07-02 21:31:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:04:01 lr 0.000003	 wd 0.0000	time 0.2311 (0.2674)	loss 1.4450 (1.2981)	grad_norm 4.7044 (4.4054)	loss_scale 1024.0000 (675.7377)	mem 10191MB
[2024-07-02 21:31:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:35 lr 0.000003	 wd 0.0000	time 0.2349 (0.2682)	loss 1.2469 (1.2981)	grad_norm 4.5675 (4.4104)	loss_scale 1024.0000 (696.2116)	mem 10191MB
[2024-07-02 21:32:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:03:08 lr 0.000003	 wd 0.0000	time 0.2484 (0.2681)	loss 1.3100 (1.2974)	grad_norm 5.1808 (4.4162)	loss_scale 1024.0000 (714.4120)	mem 10191MB
[2024-07-02 21:32:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:41 lr 0.000003	 wd 0.0000	time 0.2356 (0.2688)	loss 1.5230 (1.2977)	grad_norm 3.2835 (4.4284)	loss_scale 1024.0000 (730.6975)	mem 10191MB
[2024-07-02 21:33:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:02:14 lr 0.000003	 wd 0.0000	time 0.2274 (0.2678)	loss 1.2503 (1.2972)	grad_norm 4.0177 (4.4224)	loss_scale 1024.0000 (745.3553)	mem 10191MB
[2024-07-02 21:33:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:47 lr 0.000003	 wd 0.0000	time 0.2290 (0.2683)	loss 0.8477 (1.2974)	grad_norm 4.4690 (4.4400)	loss_scale 1024.0000 (758.6178)	mem 10191MB
[2024-07-02 21:34:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:20 lr 0.000003	 wd 0.0000	time 0.2290 (0.2676)	loss 1.3687 (1.2963)	grad_norm 3.3247 (4.4251)	loss_scale 1024.0000 (770.6751)	mem 10191MB
[2024-07-02 21:34:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:53 lr 0.000003	 wd 0.0000	time 0.2293 (0.2671)	loss 1.3814 (1.2949)	grad_norm 3.4415 (4.4523)	loss_scale 1024.0000 (781.6845)	mem 10191MB
[2024-07-02 21:35:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:27 lr 0.000003	 wd 0.0000	time 0.2377 (0.2663)	loss 1.3649 (1.2962)	grad_norm 3.4199 (4.4485)	loss_scale 1024.0000 (791.7768)	mem 10191MB
[2024-07-02 21:35:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.2404 (0.2656)	loss 1.4431 (1.2963)	grad_norm 3.6504 (4.4480)	loss_scale 1024.0000 (801.0620)	mem 10191MB
[2024-07-02 21:35:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 25 training takes 0:11:21
[2024-07-02 21:35:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 16.421 (16.421)	Loss 0.3965 (0.3965)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 10191MB
[2024-07-02 21:36:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 84.982 Acc@5 97.548
[2024-07-02 21:36:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-02 21:36:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 85.07%
[2024-07-02 21:36:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][0/2502]	eta 10:32:57 lr 0.000003	 wd 0.0000	time 15.1790 (15.1790)	loss 1.1482 (1.1482)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:37:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:18:31 lr 0.000003	 wd 0.0000	time 0.2307 (0.4626)	loss 1.4376 (1.2891)	grad_norm 4.0102 (5.0291)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:37:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:13:46 lr 0.000003	 wd 0.0000	time 0.2485 (0.3590)	loss 1.3780 (1.3147)	grad_norm 4.4346 (4.7374)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:37:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:11:53 lr 0.000003	 wd 0.0000	time 0.2298 (0.3238)	loss 1.2797 (1.3069)	grad_norm 4.6460 (4.6080)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:38:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:10:45 lr 0.000003	 wd 0.0000	time 0.2171 (0.3071)	loss 1.6137 (1.3088)	grad_norm 4.1852 (4.5514)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:38:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:09:55 lr 0.000003	 wd 0.0000	time 0.2412 (0.2976)	loss 1.6285 (1.3157)	grad_norm 3.8621 (4.4421)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:39:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:09:15 lr 0.000003	 wd 0.0000	time 0.2303 (0.2919)	loss 1.2348 (1.3114)	grad_norm 3.1871 (4.4137)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:39:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:08:37 lr 0.000003	 wd 0.0000	time 0.2551 (0.2869)	loss 1.3700 (1.3049)	grad_norm 4.0968 (4.3886)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:40:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:08:03 lr 0.000002	 wd 0.0000	time 0.3286 (0.2840)	loss 1.3688 (1.3017)	grad_norm 4.3285 (4.3605)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:40:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:07:33 lr 0.000002	 wd 0.0000	time 0.2298 (0.2833)	loss 1.3233 (1.3031)	grad_norm 3.0025 (4.4037)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:40:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:07:03 lr 0.000002	 wd 0.0000	time 0.2470 (0.2818)	loss 1.4395 (1.3030)	grad_norm 4.8810 (4.3883)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:41:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:06:31 lr 0.000002	 wd 0.0000	time 0.2374 (0.2791)	loss 1.4049 (1.3047)	grad_norm 6.6337 (4.4823)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:41:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:06:04 lr 0.000002	 wd 0.0000	time 0.2361 (0.2803)	loss 1.0280 (1.3054)	grad_norm 3.9191 (4.4503)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:42:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:05:36 lr 0.000002	 wd 0.0000	time 0.2414 (0.2799)	loss 0.9257 (1.3031)	grad_norm 7.5800 (4.4749)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:42:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:05:07 lr 0.000002	 wd 0.0000	time 0.2296 (0.2791)	loss 1.7307 (1.3030)	grad_norm 8.1441 (4.4627)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:43:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:04:37 lr 0.000002	 wd 0.0000	time 0.2251 (0.2772)	loss 1.4812 (1.3018)	grad_norm 3.7924 (4.4396)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:43:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:04:13 lr 0.000002	 wd 0.0000	time 0.2366 (0.2812)	loss 1.3908 (1.3006)	grad_norm 4.5646 (4.4501)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:44:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:44 lr 0.000002	 wd 0.0000	time 0.2433 (0.2795)	loss 1.2908 (1.3010)	grad_norm 4.1558 (4.4381)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:44:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:03:15 lr 0.000002	 wd 0.0000	time 0.2467 (0.2779)	loss 1.3842 (1.3026)	grad_norm 5.3182 (4.4528)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:45:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:48 lr 0.000002	 wd 0.0000	time 0.8215 (0.2800)	loss 1.0306 (1.3007)	grad_norm 3.1292 (4.4454)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:45:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:02:20 lr 0.000002	 wd 0.0000	time 0.2408 (0.2791)	loss 1.1334 (1.3005)	grad_norm 4.5344 (4.4518)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 21:46:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:51 lr 0.000002	 wd 0.0000	time 0.2337 (0.2778)	loss 0.9553 (1.2990)	grad_norm 7.8055 (inf)	loss_scale 512.0000 (1022.0505)	mem 10191MB
[2024-07-02 21:46:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:23 lr 0.000002	 wd 0.0000	time 0.2244 (0.2764)	loss 0.8694 (1.2988)	grad_norm 5.6592 (inf)	loss_scale 512.0000 (998.8769)	mem 10191MB
[2024-07-02 21:46:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:55 lr 0.000002	 wd 0.0000	time 0.2241 (0.2765)	loss 1.0600 (1.2978)	grad_norm 4.8079 (inf)	loss_scale 512.0000 (977.7175)	mem 10191MB
[2024-07-02 21:47:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:28 lr 0.000002	 wd 0.0000	time 0.2556 (0.2758)	loss 1.0627 (1.2976)	grad_norm 5.5464 (inf)	loss_scale 512.0000 (958.3207)	mem 10191MB
[2024-07-02 21:47:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.2198 (0.2747)	loss 1.0222 (1.2961)	grad_norm 3.7329 (inf)	loss_scale 512.0000 (940.4750)	mem 10191MB
[2024-07-02 21:47:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 26 training takes 0:11:35
[2024-07-02 21:48:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 16.478 (16.478)	Loss 0.3960 (0.3960)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 10191MB
[2024-07-02 21:48:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 85.024 Acc@5 97.564
[2024-07-02 21:48:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-02 21:48:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 85.07%
[2024-07-02 21:48:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][0/2502]	eta 11:16:50 lr 0.000002	 wd 0.0000	time 16.2311 (16.2311)	loss 0.8886 (0.8886)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:49:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:16:30 lr 0.000002	 wd 0.0000	time 0.2268 (0.4124)	loss 1.3919 (1.3140)	grad_norm 3.5627 (4.2499)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:49:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:12:49 lr 0.000002	 wd 0.0000	time 0.2470 (0.3341)	loss 1.4481 (1.3035)	grad_norm 4.8315 (4.2925)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:50:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:11:41 lr 0.000002	 wd 0.0000	time 0.2400 (0.3185)	loss 1.2345 (1.2958)	grad_norm 3.2262 (4.6884)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:50:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:10:34 lr 0.000002	 wd 0.0000	time 0.2421 (0.3020)	loss 1.3058 (1.2957)	grad_norm 3.1131 (4.5209)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:51:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:09:45 lr 0.000002	 wd 0.0000	time 0.2223 (0.2923)	loss 0.8118 (1.2891)	grad_norm 4.4797 (4.5011)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:51:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:09:04 lr 0.000002	 wd 0.0000	time 0.2479 (0.2860)	loss 1.3193 (1.2900)	grad_norm 5.0086 (4.4907)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:51:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:08:42 lr 0.000002	 wd 0.0000	time 0.2281 (0.2897)	loss 1.3921 (1.2944)	grad_norm 3.0005 (4.5591)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:52:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:08:05 lr 0.000002	 wd 0.0000	time 0.2532 (0.2853)	loss 1.5221 (1.2977)	grad_norm 3.9544 (4.5366)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:52:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:07:31 lr 0.000001	 wd 0.0000	time 0.2530 (0.2816)	loss 1.3345 (1.3024)	grad_norm 3.5309 (4.5681)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:53:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:07:04 lr 0.000001	 wd 0.0000	time 0.3349 (0.2829)	loss 1.3668 (1.3014)	grad_norm 5.1019 (4.6560)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:53:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:06:36 lr 0.000001	 wd 0.0000	time 0.2616 (0.2828)	loss 1.3124 (1.3023)	grad_norm 3.3558 (4.6902)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:54:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:06:05 lr 0.000001	 wd 0.0000	time 0.2315 (0.2805)	loss 1.4895 (1.3025)	grad_norm 10.5387 (4.6568)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:54:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:05:35 lr 0.000001	 wd 0.0000	time 0.2420 (0.2788)	loss 1.3983 (1.3008)	grad_norm 6.4132 (4.6707)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:55:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:05:09 lr 0.000001	 wd 0.0000	time 0.2540 (0.2806)	loss 1.2907 (1.3020)	grad_norm 3.4003 (4.6761)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:55:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:04:39 lr 0.000001	 wd 0.0000	time 0.2503 (0.2790)	loss 1.4615 (1.3020)	grad_norm 3.6422 (4.6418)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:56:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:04:11 lr 0.000001	 wd 0.0000	time 0.2425 (0.2790)	loss 1.4583 (1.3002)	grad_norm 3.6573 (4.6387)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:56:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:45 lr 0.000001	 wd 0.0000	time 0.2617 (0.2810)	loss 1.3522 (1.2982)	grad_norm 5.6447 (4.6372)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:56:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:03:16 lr 0.000001	 wd 0.0000	time 0.2306 (0.2805)	loss 1.3464 (1.2988)	grad_norm 4.4116 (4.6429)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:57:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:47 lr 0.000001	 wd 0.0000	time 0.2306 (0.2790)	loss 0.9252 (1.3000)	grad_norm 3.3060 (4.6306)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:57:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:02:19 lr 0.000001	 wd 0.0000	time 0.2474 (0.2777)	loss 0.8697 (1.2986)	grad_norm 3.3483 (4.6164)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:58:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:52 lr 0.000001	 wd 0.0000	time 0.2352 (0.2799)	loss 1.6771 (1.2974)	grad_norm 3.9995 (4.5993)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:58:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:24 lr 0.000001	 wd 0.0000	time 0.2675 (0.2786)	loss 0.9502 (1.2983)	grad_norm 6.3838 (4.5866)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:59:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:56 lr 0.000001	 wd 0.0000	time 0.2384 (0.2773)	loss 1.4410 (1.2986)	grad_norm 10.6031 (4.5882)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 21:59:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:28 lr 0.000001	 wd 0.0000	time 0.3657 (0.2765)	loss 1.1457 (1.2984)	grad_norm 3.3360 (4.5744)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 22:00:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.2196 (0.2753)	loss 1.4166 (1.2969)	grad_norm 2.9331 (4.5653)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 22:00:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 27 training takes 0:11:39
[2024-07-02 22:00:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 16.798 (16.798)	Loss 0.3955 (0.3955)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 10191MB
[2024-07-02 22:00:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 85.040 Acc@5 97.554
[2024-07-02 22:00:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-02 22:00:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 85.07%
[2024-07-02 22:01:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][0/2502]	eta 10:19:20 lr 0.000001	 wd 0.0000	time 14.8525 (14.8525)	loss 1.2203 (1.2203)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 22:01:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:16:48 lr 0.000001	 wd 0.0000	time 0.2610 (0.4198)	loss 0.9571 (1.2804)	grad_norm 3.8907 (4.2959)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 22:01:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:12:54 lr 0.000001	 wd 0.0000	time 0.2262 (0.3364)	loss 1.0736 (1.2847)	grad_norm 4.1453 (4.3020)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 22:02:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:11:19 lr 0.000001	 wd 0.0000	time 0.2258 (0.3087)	loss 1.5126 (1.2988)	grad_norm 3.1436 (4.4504)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 22:02:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:10:19 lr 0.000001	 wd 0.0000	time 0.2474 (0.2948)	loss 1.4831 (1.3037)	grad_norm 4.8729 (4.3745)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 22:03:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:09:35 lr 0.000001	 wd 0.0000	time 0.2494 (0.2875)	loss 1.5556 (1.3030)	grad_norm 3.9682 (4.4625)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 22:03:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:57 lr 0.000001	 wd 0.0000	time 0.2375 (0.2827)	loss 1.3488 (1.3029)	grad_norm 2.8263 (4.5000)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 22:04:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:08:22 lr 0.000001	 wd 0.0000	time 0.2147 (0.2786)	loss 0.9893 (1.3054)	grad_norm 3.5983 (4.5512)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 22:04:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:49 lr 0.000001	 wd 0.0000	time 0.2511 (0.2761)	loss 1.5438 (1.3030)	grad_norm 3.5024 (4.5266)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 22:05:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:07:27 lr 0.000001	 wd 0.0000	time 0.2282 (0.2796)	loss 1.4144 (1.3031)	grad_norm 3.6994 (4.5330)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 22:05:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:56 lr 0.000001	 wd 0.0000	time 0.2438 (0.2771)	loss 1.3814 (1.3036)	grad_norm 2.8575 (4.5365)	loss_scale 512.0000 (512.0000)	mem 10191MB
[2024-07-02 22:05:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:06:25 lr 0.000001	 wd 0.0000	time 0.2486 (0.2749)	loss 1.0318 (1.3022)	grad_norm 3.8628 (4.5232)	loss_scale 1024.0000 (517.5804)	mem 10191MB
[2024-07-02 22:06:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:57 lr 0.000001	 wd 0.0000	time 0.2700 (0.2745)	loss 1.0947 (1.3005)	grad_norm 3.5074 (4.5697)	loss_scale 1024.0000 (559.7469)	mem 10191MB
[2024-07-02 22:06:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:05:28 lr 0.000001	 wd 0.0000	time 0.2562 (0.2732)	loss 1.3369 (1.2978)	grad_norm 10.6171 (4.6307)	loss_scale 1024.0000 (595.4312)	mem 10191MB
[2024-07-02 22:07:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:59 lr 0.000001	 wd 0.0000	time 0.2308 (0.2718)	loss 0.9339 (1.2987)	grad_norm 4.4010 (4.6085)	loss_scale 1024.0000 (626.0214)	mem 10191MB
[2024-07-02 22:07:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:04:30 lr 0.000001	 wd 0.0000	time 0.2239 (0.2703)	loss 1.4345 (1.2959)	grad_norm 3.0601 (4.5754)	loss_scale 1024.0000 (652.5356)	mem 10191MB
[2024-07-02 22:08:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:04:03 lr 0.000001	 wd 0.0000	time 0.2308 (0.2703)	loss 1.1799 (1.2960)	grad_norm 24.9721 (4.5963)	loss_scale 1024.0000 (675.7377)	mem 10191MB
[2024-07-02 22:08:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:36 lr 0.000001	 wd 0.0000	time 0.2408 (0.2694)	loss 1.4514 (1.2970)	grad_norm 4.6407 (4.5817)	loss_scale 1024.0000 (696.2116)	mem 10191MB
[2024-07-02 22:08:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:03:08 lr 0.000001	 wd 0.0000	time 0.2347 (0.2684)	loss 1.3158 (1.2960)	grad_norm 3.4858 (4.5674)	loss_scale 1024.0000 (714.4120)	mem 10191MB
[2024-07-02 22:09:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:41 lr 0.000001	 wd 0.0000	time 0.2313 (0.2682)	loss 1.5899 (1.2948)	grad_norm 4.8604 (4.5606)	loss_scale 1024.0000 (730.6975)	mem 10191MB
[2024-07-02 22:09:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:02:14 lr 0.000001	 wd 0.0000	time 0.2136 (0.2685)	loss 0.8558 (1.2943)	grad_norm 3.6900 (4.5464)	loss_scale 1024.0000 (745.3553)	mem 10191MB
[2024-07-02 22:10:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:47 lr 0.000001	 wd 0.0000	time 0.2390 (0.2679)	loss 1.1182 (1.2945)	grad_norm 4.6074 (4.5686)	loss_scale 1024.0000 (758.6178)	mem 10191MB
[2024-07-02 22:10:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:20 lr 0.000001	 wd 0.0000	time 0.2342 (0.2670)	loss 1.4380 (1.2934)	grad_norm 3.8394 (4.5546)	loss_scale 1024.0000 (770.6751)	mem 10191MB
[2024-07-02 22:11:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:53 lr 0.000001	 wd 0.0000	time 0.5209 (0.2665)	loss 1.1901 (1.2938)	grad_norm 3.4022 (4.5521)	loss_scale 1024.0000 (781.6845)	mem 10191MB
[2024-07-02 22:11:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:27 lr 0.000001	 wd 0.0000	time 0.2328 (0.2687)	loss 1.5123 (1.2926)	grad_norm 4.7827 (4.5691)	loss_scale 1024.0000 (791.7768)	mem 10191MB
[2024-07-02 22:11:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.2214 (0.2676)	loss 1.1402 (1.2912)	grad_norm 4.1715 (4.5703)	loss_scale 1024.0000 (801.0620)	mem 10191MB
[2024-07-02 22:12:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 28 training takes 0:11:19
[2024-07-02 22:12:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 16.406 (16.406)	Loss 0.3960 (0.3960)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 10191MB
[2024-07-02 22:12:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 85.070 Acc@5 97.562
[2024-07-02 22:12:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-02 22:12:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 85.07%
[2024-07-02 22:12:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth saving......
[2024-07-02 22:12:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_best.pth saved !!!
[2024-07-02 22:12:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][0/2502]	eta 10:22:18 lr 0.000001	 wd 0.0000	time 14.9233 (14.9233)	loss 1.4264 (1.4264)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 10191MB
[2024-07-02 22:13:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:16:02 lr 0.000001	 wd 0.0000	time 0.2387 (0.4007)	loss 1.4435 (1.2708)	grad_norm 4.0706 (inf)	loss_scale 512.0000 (669.1485)	mem 10191MB
[2024-07-02 22:13:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:12:32 lr 0.000001	 wd 0.0000	time 0.2441 (0.3270)	loss 1.1526 (1.2876)	grad_norm 4.2656 (inf)	loss_scale 512.0000 (590.9652)	mem 10191MB
[2024-07-02 22:14:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:11:03 lr 0.000001	 wd 0.0000	time 0.2155 (0.3013)	loss 1.4792 (1.2875)	grad_norm 4.7415 (inf)	loss_scale 512.0000 (564.7309)	mem 10191MB
[2024-07-02 22:14:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:10:25 lr 0.000001	 wd 0.0000	time 0.2372 (0.2976)	loss 1.1843 (1.2920)	grad_norm 5.0488 (inf)	loss_scale 512.0000 (551.5810)	mem 10191MB
[2024-07-02 22:15:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:09:37 lr 0.000001	 wd 0.0000	time 0.2401 (0.2884)	loss 0.8840 (1.2960)	grad_norm 7.0147 (inf)	loss_scale 512.0000 (543.6806)	mem 10191MB
[2024-07-02 22:15:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:58 lr 0.000000	 wd 0.0000	time 0.2514 (0.2833)	loss 1.2927 (1.3003)	grad_norm 3.4111 (inf)	loss_scale 512.0000 (538.4093)	mem 10191MB
[2024-07-02 22:16:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:08:29 lr 0.000000	 wd 0.0000	time 0.2384 (0.2827)	loss 1.5726 (1.3000)	grad_norm 3.6390 (inf)	loss_scale 512.0000 (534.6419)	mem 10191MB
[2024-07-02 22:16:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:07:58 lr 0.000000	 wd 0.0000	time 0.7993 (0.2813)	loss 0.8195 (1.2992)	grad_norm 3.9160 (inf)	loss_scale 512.0000 (531.8152)	mem 10191MB
[2024-07-02 22:16:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:07:26 lr 0.000000	 wd 0.0000	time 0.2546 (0.2784)	loss 1.2709 (1.2994)	grad_norm 12.0320 (inf)	loss_scale 512.0000 (529.6160)	mem 10191MB
[2024-07-02 22:17:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:54 lr 0.000000	 wd 0.0000	time 0.2496 (0.2760)	loss 1.2773 (1.2981)	grad_norm 3.5777 (inf)	loss_scale 512.0000 (527.8561)	mem 10191MB
[2024-07-02 22:17:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:06:34 lr 0.000000	 wd 0.0000	time 0.2377 (0.2811)	loss 1.2817 (1.2980)	grad_norm 2.8096 (inf)	loss_scale 512.0000 (526.4160)	mem 10191MB
[2024-07-02 22:18:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:06:02 lr 0.000000	 wd 0.0000	time 0.2339 (0.2788)	loss 1.3492 (1.2954)	grad_norm 4.4829 (inf)	loss_scale 512.0000 (525.2157)	mem 10191MB
[2024-07-02 22:18:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:05:33 lr 0.000000	 wd 0.0000	time 0.2229 (0.2774)	loss 1.4668 (1.2960)	grad_norm 4.1769 (inf)	loss_scale 512.0000 (524.1998)	mem 10191MB
[2024-07-02 22:19:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:05:03 lr 0.000000	 wd 0.0000	time 0.2382 (0.2753)	loss 1.5391 (1.2934)	grad_norm 8.9343 (inf)	loss_scale 512.0000 (523.3291)	mem 10191MB
[2024-07-02 22:19:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:04:35 lr 0.000000	 wd 0.0000	time 0.2315 (0.2747)	loss 1.3112 (1.2943)	grad_norm 10.9373 (inf)	loss_scale 512.0000 (522.5743)	mem 10191MB
[2024-07-02 22:20:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:04:06 lr 0.000000	 wd 0.0000	time 0.2347 (0.2733)	loss 1.2671 (1.2959)	grad_norm 3.2239 (inf)	loss_scale 512.0000 (521.9138)	mem 10191MB
[2024-07-02 22:20:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:38 lr 0.000000	 wd 0.0000	time 0.2390 (0.2720)	loss 1.1068 (1.2938)	grad_norm 4.2191 (inf)	loss_scale 512.0000 (521.3310)	mem 10191MB
[2024-07-02 22:20:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:03:10 lr 0.000000	 wd 0.0000	time 0.2505 (0.2713)	loss 1.1141 (1.2954)	grad_norm 5.9749 (inf)	loss_scale 512.0000 (520.8129)	mem 10191MB
[2024-07-02 22:21:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:43 lr 0.000000	 wd 0.0000	time 0.2522 (0.2715)	loss 1.2360 (1.2946)	grad_norm 4.8953 (inf)	loss_scale 512.0000 (520.3493)	mem 10191MB
[2024-07-02 22:21:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:02:15 lr 0.000000	 wd 0.0000	time 0.2375 (0.2705)	loss 1.5161 (1.2945)	grad_norm 5.1908 (inf)	loss_scale 512.0000 (519.9320)	mem 10191MB
[2024-07-02 22:22:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:48 lr 0.000000	 wd 0.0000	time 0.2377 (0.2697)	loss 1.3856 (1.2952)	grad_norm 5.1206 (inf)	loss_scale 512.0000 (519.5545)	mem 10191MB
[2024-07-02 22:22:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:21 lr 0.000000	 wd 0.0000	time 0.2302 (0.2691)	loss 1.3942 (1.2969)	grad_norm 4.5203 (inf)	loss_scale 512.0000 (519.2113)	mem 10191MB
[2024-07-02 22:23:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:54 lr 0.000000	 wd 0.0000	time 0.2229 (0.2686)	loss 1.4591 (1.2979)	grad_norm 5.9507 (inf)	loss_scale 512.0000 (518.8979)	mem 10191MB
[2024-07-02 22:23:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.2308 (0.2679)	loss 1.4621 (1.2987)	grad_norm 4.4708 (inf)	loss_scale 512.0000 (518.6106)	mem 10191MB
[2024-07-02 22:23:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000000	 wd 0.0000	time 0.2179 (0.2668)	loss 1.3612 (1.2981)	grad_norm 7.9459 (inf)	loss_scale 512.0000 (518.3463)	mem 10191MB
[2024-07-02 22:24:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 249): INFO EPOCH 29 training takes 0:11:16
[2024-07-02 22:24:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_29.pth saving......
[2024-07-02 22:24:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_crosslayer_process1/ckpt_epoch_29.pth saved !!!
[2024-07-02 22:24:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 289): INFO Test: [0/98]	Time 18.538 (18.538)	Loss 0.3962 (0.3962)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 10191MB
[2024-07-02 22:24:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 296): INFO  * Acc@1 85.052 Acc@5 97.558
[2024-07-02 22:24:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-02 22:24:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 182): INFO Max accuracy: 85.07%
[2024-07-02 22:24:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_cross_layer_process1] (main.py 189): INFO Training time 5:56:47
