[2024-07-02 14:51:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/config.json
[2024-07-02 14:51:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_process1/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    FINETUNE_MODE: stage2
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: swin_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    DEPTHS:
    - 3
    - 3
    - 9
    - 3
    DIMS:
    - 96
    - 192
    - 384
    - 768
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_swin_base_patch4_22kto1k_finetune_process2
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 4.0e-05
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.0e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 4.0e-08
  WEIGHT_DECAY: 1.0e-08

[2024-07-02 14:51:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility/configs/swin/diffusion_ft_swin_base_patch4_window7_224_22kto1k_finetune_process2.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_process1/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_swin_base_patch4_22kto1k_finetune_process2", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-02 14:51:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 108): INFO Creating model:swin_diffusion_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2
[2024-07-02 14:51:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 110): INFO SwinTransformer_Diffusion_Finetune(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-02 14:51:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 113): INFO number of params: 59919880
[2024-07-02 14:51:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 116): INFO number of GFLOPs: 15.438473216
[2024-07-02 14:51:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 150): INFO no checkpoint found in pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2, ignoring auto resume
[2024-07-02 14:51:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_process1/ckpt_epoch_best.pth for fine-tuning......
[2024-07-02 14:51:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])
[2024-07-02 14:51:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_process1/ckpt_epoch_best.pth'
[2024-07-02 14:51:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 12.149 (12.149)	Loss 0.4163 (0.4163)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 1622MB
[2024-07-02 14:51:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 83.948 Acc@5 97.176
[2024-07-02 14:51:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 162): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-02 14:51:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 168): INFO Start training
[2024-07-02 14:52:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][0/2502]	eta 7:30:41 lr 0.000000	 wd 0.0000	time 10.8079 (10.8079)	loss 1.6419 (1.6419)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 6823MB
[2024-07-02 14:52:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:18:23 lr 0.000000	 wd 0.0000	time 0.3377 (0.4595)	loss 1.4275 (1.4137)	grad_norm 3.7089 (1.6725)	loss_scale 65536.0000 (65536.0000)	mem 7516MB
[2024-07-02 14:53:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:15:35 lr 0.000001	 wd 0.0000	time 0.3403 (0.4064)	loss 1.3158 (1.3975)	grad_norm nan (nan)	loss_scale 32768.0000 (65209.9502)	mem 7516MB
[2024-07-02 14:53:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:14:15 lr 0.000001	 wd 0.0000	time 0.3335 (0.3885)	loss 1.3210 (1.3786)	grad_norm 1.6433 (nan)	loss_scale 32768.0000 (54431.8937)	mem 7516MB
[2024-07-02 14:54:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:13:18 lr 0.000001	 wd 0.0000	time 0.3372 (0.3797)	loss 1.8805 (1.3805)	grad_norm 1.5362 (nan)	loss_scale 32768.0000 (49029.4264)	mem 7516MB
[2024-07-02 14:55:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:12:29 lr 0.000002	 wd 0.0000	time 0.3386 (0.3744)	loss 1.5682 (1.3811)	grad_norm 2.4559 (nan)	loss_scale 16384.0000 (42513.3733)	mem 7516MB
[2024-07-02 14:55:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:11:45 lr 0.000002	 wd 0.0000	time 0.3218 (0.3707)	loss 0.9917 (1.3856)	grad_norm 1.4929 (nan)	loss_scale 16384.0000 (38165.7238)	mem 7516MB
[2024-07-02 14:56:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:11:03 lr 0.000002	 wd 0.0000	time 0.3292 (0.3682)	loss 1.4820 (1.3834)	grad_norm 1.8301 (nan)	loss_scale 8192.0000 (34637.7860)	mem 7516MB
[2024-07-02 14:56:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:10:23 lr 0.000003	 wd 0.0000	time 0.3370 (0.3662)	loss 1.5871 (1.3833)	grad_norm 1.6213 (nan)	loss_scale 8192.0000 (31336.1898)	mem 7516MB
[2024-07-02 14:57:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:09:44 lr 0.000003	 wd 0.0000	time 0.3402 (0.3646)	loss 1.5834 (1.3784)	grad_norm 1.4220 (nan)	loss_scale 8192.0000 (28767.4673)	mem 7516MB
[2024-07-02 14:58:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:09:05 lr 0.000003	 wd 0.0000	time 0.3364 (0.3635)	loss 1.3791 (1.3775)	grad_norm 1.6110 (nan)	loss_scale 8192.0000 (26711.9760)	mem 7516MB
[2024-07-02 14:58:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:08:28 lr 0.000004	 wd 0.0000	time 0.3352 (0.3624)	loss 1.5385 (1.3777)	grad_norm 1.2411 (nan)	loss_scale 8192.0000 (25029.8710)	mem 7516MB
[2024-07-02 14:59:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:07:50 lr 0.000004	 wd 0.0000	time 0.3325 (0.3617)	loss 1.3516 (1.3809)	grad_norm 2.2393 (nan)	loss_scale 8192.0000 (23627.8834)	mem 7516MB
[2024-07-02 14:59:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:07:13 lr 0.000004	 wd 0.0000	time 0.3358 (0.3610)	loss 1.5152 (1.3824)	grad_norm 1.7845 (nan)	loss_scale 8192.0000 (22441.4204)	mem 7516MB
[2024-07-02 15:00:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:06:37 lr 0.000005	 wd 0.0000	time 0.3306 (0.3604)	loss 1.5925 (1.3831)	grad_norm 1.3668 (nan)	loss_scale 8192.0000 (21424.3312)	mem 7516MB
[2024-07-02 15:00:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:06:00 lr 0.000005	 wd 0.0000	time 0.3417 (0.3600)	loss 1.3734 (1.3823)	grad_norm 1.6349 (nan)	loss_scale 8192.0000 (20542.7635)	mem 7516MB
[2024-07-02 15:01:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:05:24 lr 0.000005	 wd 0.0000	time 0.3330 (0.3595)	loss 1.7460 (1.3830)	grad_norm 1.7197 (nan)	loss_scale 8192.0000 (19771.3229)	mem 7516MB
[2024-07-02 15:02:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:04:47 lr 0.000005	 wd 0.0000	time 0.3290 (0.3591)	loss 1.5882 (1.3823)	grad_norm 1.4780 (nan)	loss_scale 8192.0000 (19090.5867)	mem 7516MB
[2024-07-02 15:02:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:04:11 lr 0.000006	 wd 0.0000	time 0.3457 (0.3587)	loss 1.2322 (1.3823)	grad_norm 1.6013 (nan)	loss_scale 8192.0000 (18485.4459)	mem 7516MB
[2024-07-02 15:03:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:03:35 lr 0.000006	 wd 0.0000	time 0.3287 (0.3584)	loss 1.4602 (1.3814)	grad_norm 1.7134 (nan)	loss_scale 8192.0000 (17943.9705)	mem 7516MB
[2024-07-02 15:03:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:59 lr 0.000006	 wd 0.0000	time 0.3329 (0.3581)	loss 1.5264 (1.3790)	grad_norm 1.4602 (nan)	loss_scale 8192.0000 (17456.6157)	mem 7516MB
[2024-07-02 15:04:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:02:23 lr 0.000007	 wd 0.0000	time 0.3360 (0.3578)	loss 1.4091 (1.3801)	grad_norm 1.5424 (nan)	loss_scale 8192.0000 (17015.6535)	mem 7516MB
[2024-07-02 15:05:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:47 lr 0.000007	 wd 0.0000	time 0.3289 (0.3575)	loss 1.5335 (1.3800)	grad_norm 1.5576 (nan)	loss_scale 8192.0000 (16614.7606)	mem 7516MB
[2024-07-02 15:05:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:01:12 lr 0.000007	 wd 0.0000	time 0.3331 (0.3573)	loss 1.4160 (1.3786)	grad_norm 1.6152 (nan)	loss_scale 8192.0000 (16248.7127)	mem 7516MB
[2024-07-02 15:06:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:36 lr 0.000008	 wd 0.0000	time 0.3278 (0.3570)	loss 1.4753 (1.3789)	grad_norm 1.5906 (nan)	loss_scale 8192.0000 (15913.1562)	mem 7516MB
[2024-07-02 15:06:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.3383 (0.3568)	loss 1.6140 (1.3792)	grad_norm 1.4310 (nan)	loss_scale 8192.0000 (15604.4334)	mem 7516MB
[2024-07-02 15:06:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 0 training takes 0:14:55
[2024-07-02 15:06:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_0.pth saving......
[2024-07-02 15:06:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_0.pth saved !!!
[2024-07-02 15:07:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 10.054 (10.054)	Loss 0.4126 (0.4126)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 7516MB
[2024-07-02 15:07:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.030 Acc@5 97.240
[2024-07-02 15:07:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-02 15:07:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.03%
[2024-07-02 15:07:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saving......
[2024-07-02 15:07:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saved !!!
[2024-07-02 15:07:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][0/2502]	eta 6:52:13 lr 0.000008	 wd 0.0000	time 9.8856 (9.8856)	loss 1.2484 (1.2484)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:08:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:17:52 lr 0.000008	 wd 0.0000	time 0.3365 (0.4466)	loss 1.1773 (1.4037)	grad_norm 1.6822 (1.6195)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:08:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:15:19 lr 0.000009	 wd 0.0000	time 0.3288 (0.3994)	loss 1.4033 (1.4098)	grad_norm 1.8473 (1.6350)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:09:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:14:05 lr 0.000009	 wd 0.0000	time 0.3279 (0.3840)	loss 1.7243 (1.3964)	grad_norm 1.6447 (1.6955)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:09:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:13:10 lr 0.000009	 wd 0.0000	time 0.3411 (0.3762)	loss 0.9092 (1.3826)	grad_norm 1.4715 (1.6860)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:10:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:12:23 lr 0.000010	 wd 0.0000	time 0.3344 (0.3715)	loss 1.6850 (1.3802)	grad_norm 1.4943 (1.6893)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:10:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:11:40 lr 0.000010	 wd 0.0000	time 0.3403 (0.3684)	loss 1.3758 (1.3768)	grad_norm 2.6548 (1.7021)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:11:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:10:59 lr 0.000010	 wd 0.0000	time 0.3436 (0.3662)	loss 1.5099 (1.3750)	grad_norm 1.8218 (1.7000)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:12:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:10:20 lr 0.000011	 wd 0.0000	time 0.3400 (0.3645)	loss 1.5339 (1.3783)	grad_norm 1.3878 (1.7026)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:12:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:09:41 lr 0.000011	 wd 0.0000	time 0.3210 (0.3631)	loss 1.5492 (1.3766)	grad_norm 1.6553 (1.6935)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:13:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:09:03 lr 0.000011	 wd 0.0000	time 0.3331 (0.3620)	loss 1.4580 (1.3747)	grad_norm 2.0128 (1.6905)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:13:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:08:26 lr 0.000012	 wd 0.0000	time 0.3401 (0.3611)	loss 1.1418 (1.3750)	grad_norm 1.9620 (1.6904)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:14:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:07:49 lr 0.000012	 wd 0.0000	time 0.3335 (0.3603)	loss 1.4080 (1.3780)	grad_norm 1.4078 (1.6897)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:15:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:07:12 lr 0.000012	 wd 0.0000	time 0.3369 (0.3597)	loss 1.5215 (1.3794)	grad_norm 1.6083 (1.7070)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:15:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:06:35 lr 0.000012	 wd 0.0000	time 0.3214 (0.3591)	loss 1.5052 (1.3773)	grad_norm 1.6399 (1.7054)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:16:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:05:59 lr 0.000013	 wd 0.0000	time 0.3319 (0.3586)	loss 0.9540 (1.3756)	grad_norm 1.5989 (1.7113)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:16:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:05:23 lr 0.000013	 wd 0.0000	time 0.3316 (0.3582)	loss 0.9747 (1.3746)	grad_norm 1.6290 (1.7081)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:17:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:04:47 lr 0.000013	 wd 0.0000	time 0.3278 (0.3579)	loss 1.4085 (1.3745)	grad_norm 1.6229 (1.7143)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:18:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:04:11 lr 0.000014	 wd 0.0000	time 0.3374 (0.3576)	loss 1.3515 (1.3739)	grad_norm 1.3949 (1.7141)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:18:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:03:35 lr 0.000014	 wd 0.0000	time 0.3474 (0.3573)	loss 1.4129 (1.3750)	grad_norm 1.6338 (1.7158)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:19:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:59 lr 0.000014	 wd 0.0000	time 0.3425 (0.3571)	loss 1.4369 (1.3748)	grad_norm 2.8199 (1.7175)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:19:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:02:23 lr 0.000015	 wd 0.0000	time 0.3374 (0.3568)	loss 1.5381 (1.3758)	grad_norm 1.8470 (1.7181)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:20:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:47 lr 0.000015	 wd 0.0000	time 0.3365 (0.3566)	loss 1.0671 (1.3764)	grad_norm 4.7530 (1.7226)	loss_scale 16384.0000 (8333.4339)	mem 7516MB
[2024-07-02 15:20:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:01:12 lr 0.000015	 wd 0.0000	time 0.3375 (0.3565)	loss 1.3875 (1.3766)	grad_norm 1.6039 (1.7206)	loss_scale 16384.0000 (8683.3064)	mem 7516MB
[2024-07-02 15:21:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:36 lr 0.000016	 wd 0.0000	time 0.3275 (0.3563)	loss 1.5438 (1.3750)	grad_norm 1.6041 (1.7211)	loss_scale 16384.0000 (9004.0350)	mem 7516MB
[2024-07-02 15:22:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.3286 (0.3560)	loss 1.1276 (1.3764)	grad_norm 1.2891 (1.7187)	loss_scale 16384.0000 (9299.1156)	mem 7516MB
[2024-07-02 15:22:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 1 training takes 0:14:53
[2024-07-02 15:22:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.661 (11.661)	Loss 0.4221 (0.4221)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 7516MB
[2024-07-02 15:22:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.062 Acc@5 97.276
[2024-07-02 15:22:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-02 15:22:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.06%
[2024-07-02 15:22:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saving......
[2024-07-02 15:22:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saved !!!
[2024-07-02 15:22:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][0/2502]	eta 6:53:16 lr 0.000016	 wd 0.0000	time 9.9107 (9.9107)	loss 1.4451 (1.4451)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 15:23:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:17:52 lr 0.000016	 wd 0.0000	time 0.3363 (0.4463)	loss 1.4945 (1.3509)	grad_norm 1.4840 (1.7024)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 15:23:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:15:19 lr 0.000017	 wd 0.0000	time 0.3376 (0.3994)	loss 1.4875 (1.3693)	grad_norm 1.3991 (1.7948)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 15:24:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:14:04 lr 0.000017	 wd 0.0000	time 0.3372 (0.3833)	loss 1.1775 (1.3727)	grad_norm 1.7226 (1.7610)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 15:25:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:13:09 lr 0.000017	 wd 0.0000	time 0.3410 (0.3756)	loss 1.5401 (1.3686)	grad_norm 1.4730 (1.7755)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 15:25:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:12:22 lr 0.000018	 wd 0.0000	time 0.3385 (0.3710)	loss 1.4382 (1.3710)	grad_norm 2.2539 (nan)	loss_scale 8192.0000 (15893.4611)	mem 7516MB
[2024-07-02 15:26:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:11:40 lr 0.000018	 wd 0.0000	time 0.3317 (0.3681)	loss 1.2710 (1.3647)	grad_norm 1.5412 (nan)	loss_scale 8192.0000 (14612.0200)	mem 7516MB
[2024-07-02 15:26:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:10:59 lr 0.000018	 wd 0.0000	time 0.3399 (0.3657)	loss 1.2544 (1.3685)	grad_norm 1.6625 (nan)	loss_scale 8192.0000 (13696.1826)	mem 7516MB
[2024-07-02 15:27:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:10:19 lr 0.000019	 wd 0.0000	time 0.3346 (0.3640)	loss 1.5823 (1.3669)	grad_norm 1.8585 (nan)	loss_scale 8192.0000 (13009.0187)	mem 7516MB
[2024-07-02 15:28:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:09:41 lr 0.000019	 wd 0.0000	time 0.3456 (0.3627)	loss 1.5112 (1.3720)	grad_norm 1.5814 (nan)	loss_scale 8192.0000 (12474.3885)	mem 7516MB
[2024-07-02 15:28:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:09:03 lr 0.000019	 wd 0.0000	time 0.3435 (0.3618)	loss 1.4665 (1.3737)	grad_norm 1.4991 (nan)	loss_scale 8192.0000 (12046.5774)	mem 7516MB
[2024-07-02 15:29:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:08:26 lr 0.000020	 wd 0.0000	time 0.3420 (0.3610)	loss 1.1792 (1.3744)	grad_norm 1.5942 (nan)	loss_scale 8192.0000 (11696.4796)	mem 7516MB
[2024-07-02 15:29:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:07:49 lr 0.000020	 wd 0.0000	time 0.3366 (0.3603)	loss 1.3255 (1.3733)	grad_norm 1.6717 (nan)	loss_scale 8192.0000 (11404.6828)	mem 7516MB
[2024-07-02 15:30:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:07:12 lr 0.000020	 wd 0.0000	time 0.3423 (0.3597)	loss 1.6500 (1.3760)	grad_norm 1.9813 (nan)	loss_scale 8192.0000 (11157.7433)	mem 7516MB
[2024-07-02 15:31:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:06:35 lr 0.000020	 wd 0.0000	time 0.3366 (0.3593)	loss 1.4102 (1.3764)	grad_norm 7.0670 (nan)	loss_scale 8192.0000 (10946.0557)	mem 7516MB
[2024-07-02 15:31:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:05:59 lr 0.000021	 wd 0.0000	time 0.3441 (0.3588)	loss 1.5436 (1.3745)	grad_norm 3.9374 (nan)	loss_scale 8192.0000 (10762.5743)	mem 7516MB
[2024-07-02 15:32:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:05:23 lr 0.000021	 wd 0.0000	time 0.3337 (0.3585)	loss 1.2477 (1.3749)	grad_norm 1.8621 (nan)	loss_scale 8192.0000 (10602.0137)	mem 7516MB
[2024-07-02 15:32:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:04:47 lr 0.000021	 wd 0.0000	time 0.3421 (0.3581)	loss 1.3247 (1.3738)	grad_norm 2.4926 (nan)	loss_scale 8192.0000 (10460.3316)	mem 7516MB
[2024-07-02 15:33:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:04:11 lr 0.000022	 wd 0.0000	time 0.3452 (0.3578)	loss 1.3307 (1.3737)	grad_norm 1.8761 (nan)	loss_scale 8192.0000 (10334.3831)	mem 7516MB
[2024-07-02 15:33:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:03:35 lr 0.000022	 wd 0.0000	time 0.3364 (0.3575)	loss 0.9719 (1.3721)	grad_norm 1.5388 (nan)	loss_scale 8192.0000 (10221.6854)	mem 7516MB
[2024-07-02 15:34:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:02:59 lr 0.000022	 wd 0.0000	time 0.3408 (0.3573)	loss 1.1831 (1.3699)	grad_norm 1.5782 (nan)	loss_scale 8192.0000 (10120.2519)	mem 7516MB
[2024-07-02 15:35:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:02:23 lr 0.000023	 wd 0.0000	time 0.3380 (0.3571)	loss 1.4354 (1.3700)	grad_norm 2.2350 (nan)	loss_scale 8192.0000 (10028.4741)	mem 7516MB
[2024-07-02 15:35:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:47 lr 0.000023	 wd 0.0000	time 0.3245 (0.3569)	loss 1.6371 (1.3698)	grad_norm 1.5639 (nan)	loss_scale 8192.0000 (9945.0359)	mem 7516MB
[2024-07-02 15:36:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:01:12 lr 0.000023	 wd 0.0000	time 0.3324 (0.3568)	loss 1.6567 (1.3700)	grad_norm 1.4513 (nan)	loss_scale 8192.0000 (9868.8501)	mem 7516MB
[2024-07-02 15:36:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:36 lr 0.000024	 wd 0.0000	time 0.3354 (0.3566)	loss 1.4792 (1.3691)	grad_norm 1.4198 (nan)	loss_scale 8192.0000 (9799.0104)	mem 7516MB
[2024-07-02 15:37:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.3380 (0.3564)	loss 1.5362 (1.3693)	grad_norm 1.3900 (nan)	loss_scale 8192.0000 (9734.7557)	mem 7516MB
[2024-07-02 15:37:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 2 training takes 0:14:54
[2024-07-02 15:37:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.425 (11.425)	Loss 0.4102 (0.4102)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 7516MB
[2024-07-02 15:37:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.080 Acc@5 97.298
[2024-07-02 15:37:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-02 15:37:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.08%
[2024-07-02 15:37:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saving......
[2024-07-02 15:37:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saved !!!
[2024-07-02 15:38:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][0/2502]	eta 7:17:42 lr 0.000024	 wd 0.0000	time 10.4968 (10.4968)	loss 0.9801 (0.9801)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:38:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:18:02 lr 0.000024	 wd 0.0000	time 0.3234 (0.4507)	loss 1.4786 (1.3391)	grad_norm 1.8998 (1.7553)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:39:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:15:21 lr 0.000025	 wd 0.0000	time 0.3227 (0.4004)	loss 1.3993 (1.3563)	grad_norm 1.7839 (1.8104)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:39:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:14:05 lr 0.000025	 wd 0.0000	time 0.3400 (0.3841)	loss 1.5625 (1.3509)	grad_norm 1.3615 (1.7844)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:40:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:13:10 lr 0.000025	 wd 0.0000	time 0.3418 (0.3760)	loss 1.5481 (1.3542)	grad_norm 1.5214 (1.7689)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:41:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:12:23 lr 0.000026	 wd 0.0000	time 0.3405 (0.3712)	loss 1.4111 (1.3531)	grad_norm 1.6878 (1.7463)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:41:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:11:40 lr 0.000026	 wd 0.0000	time 0.3357 (0.3682)	loss 1.3904 (1.3541)	grad_norm 1.8804 (1.7404)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:42:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:10:59 lr 0.000026	 wd 0.0000	time 0.3261 (0.3658)	loss 1.7148 (1.3562)	grad_norm 2.6350 (1.7283)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:42:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:10:19 lr 0.000027	 wd 0.0000	time 0.3449 (0.3642)	loss 1.1089 (1.3563)	grad_norm 1.9396 (1.7391)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:43:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:09:41 lr 0.000027	 wd 0.0000	time 0.3331 (0.3630)	loss 1.4901 (1.3578)	grad_norm 1.5074 (1.7274)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:43:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:09:03 lr 0.000027	 wd 0.0000	time 0.3451 (0.3619)	loss 1.5059 (1.3606)	grad_norm 1.5003 (1.7300)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:44:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:08:26 lr 0.000028	 wd 0.0000	time 0.3268 (0.3611)	loss 1.4040 (1.3631)	grad_norm 1.9279 (1.7235)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:45:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:07:49 lr 0.000028	 wd 0.0000	time 0.3264 (0.3604)	loss 1.2302 (1.3613)	grad_norm 1.4796 (1.7263)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:45:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:07:12 lr 0.000028	 wd 0.0000	time 0.3436 (0.3598)	loss 1.2967 (1.3639)	grad_norm 1.4743 (1.7274)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:46:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:06:35 lr 0.000028	 wd 0.0000	time 0.3321 (0.3593)	loss 1.2416 (1.3644)	grad_norm 1.5582 (1.7195)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:46:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:05:59 lr 0.000029	 wd 0.0000	time 0.3281 (0.3589)	loss 1.4574 (1.3662)	grad_norm 1.6156 (1.7167)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:47:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:05:23 lr 0.000029	 wd 0.0000	time 0.3455 (0.3585)	loss 1.5352 (1.3651)	grad_norm 1.4480 (1.7152)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:48:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:04:47 lr 0.000029	 wd 0.0000	time 0.3405 (0.3581)	loss 1.1192 (1.3642)	grad_norm 1.6304 (1.7105)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:48:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:04:11 lr 0.000030	 wd 0.0000	time 0.3367 (0.3578)	loss 1.4796 (1.3646)	grad_norm 1.5335 (1.7061)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:49:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:03:35 lr 0.000030	 wd 0.0000	time 0.3387 (0.3576)	loss 1.4864 (1.3639)	grad_norm 1.4785 (1.7128)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:49:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:59 lr 0.000030	 wd 0.0000	time 0.3429 (0.3573)	loss 1.1615 (1.3646)	grad_norm 1.7396 (1.7111)	loss_scale 16384.0000 (8323.0065)	mem 7516MB
[2024-07-02 15:50:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:02:23 lr 0.000031	 wd 0.0000	time 0.3493 (0.3571)	loss 1.1645 (1.3635)	grad_norm 1.4256 (nan)	loss_scale 8192.0000 (8464.9367)	mem 7516MB
[2024-07-02 15:51:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:47 lr 0.000031	 wd 0.0000	time 0.3336 (0.3569)	loss 1.3801 (1.3644)	grad_norm 1.6103 (nan)	loss_scale 8192.0000 (8452.5361)	mem 7516MB
[2024-07-02 15:51:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:01:12 lr 0.000031	 wd 0.0000	time 0.3311 (0.3567)	loss 1.4893 (1.3654)	grad_norm 1.5328 (nan)	loss_scale 8192.0000 (8441.2134)	mem 7516MB
[2024-07-02 15:52:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:36 lr 0.000032	 wd 0.0000	time 0.3274 (0.3565)	loss 1.0289 (1.3646)	grad_norm 1.3477 (nan)	loss_scale 8192.0000 (8430.8338)	mem 7516MB
[2024-07-02 15:52:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000032	 wd 0.0000	time 0.3289 (0.3563)	loss 1.4334 (1.3650)	grad_norm 1.7763 (nan)	loss_scale 8192.0000 (8421.2843)	mem 7516MB
[2024-07-02 15:52:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 3 training takes 0:14:54
[2024-07-02 15:53:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.081 (11.081)	Loss 0.4160 (0.4160)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 15:53:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.066 Acc@5 97.354
[2024-07-02 15:53:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-02 15:53:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.08%
[2024-07-02 15:53:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][0/2502]	eta 7:39:13 lr 0.000032	 wd 0.0000	time 11.0125 (11.0125)	loss 1.4071 (1.4071)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:54:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:18:21 lr 0.000032	 wd 0.0000	time 0.3273 (0.4587)	loss 1.2430 (1.3936)	grad_norm 1.6161 (1.6248)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:54:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:15:33 lr 0.000033	 wd 0.0000	time 0.3378 (0.4054)	loss 1.1617 (1.3814)	grad_norm 1.4702 (1.6381)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:55:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:14:14 lr 0.000033	 wd 0.0000	time 0.3455 (0.3879)	loss 1.1095 (1.3821)	grad_norm 1.5178 (1.6733)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:55:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:13:15 lr 0.000033	 wd 0.0000	time 0.3398 (0.3786)	loss 1.4074 (1.3718)	grad_norm 1.6791 (1.6659)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:56:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:12:26 lr 0.000034	 wd 0.0000	time 0.3389 (0.3729)	loss 1.4531 (1.3675)	grad_norm 1.5895 (1.6567)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:56:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:11:42 lr 0.000034	 wd 0.0000	time 0.3287 (0.3695)	loss 1.4099 (1.3624)	grad_norm 1.6998 (1.6749)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:57:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:11:01 lr 0.000034	 wd 0.0000	time 0.3475 (0.3670)	loss 1.2681 (1.3627)	grad_norm 1.7992 (1.7129)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:58:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:10:21 lr 0.000035	 wd 0.0000	time 0.3176 (0.3652)	loss 1.3195 (1.3633)	grad_norm 1.4616 (1.6997)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:58:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:09:42 lr 0.000035	 wd 0.0000	time 0.3236 (0.3637)	loss 1.4703 (1.3639)	grad_norm 1.4635 (1.6895)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:59:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:09:04 lr 0.000035	 wd 0.0000	time 0.3320 (0.3627)	loss 1.5343 (1.3650)	grad_norm 1.4375 (1.6998)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 15:59:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:08:27 lr 0.000036	 wd 0.0000	time 0.3462 (0.3618)	loss 1.5747 (1.3656)	grad_norm 1.6346 (1.6895)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:00:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:07:50 lr 0.000036	 wd 0.0000	time 0.3400 (0.3611)	loss 1.0271 (1.3649)	grad_norm 1.4052 (1.6820)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:01:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:07:13 lr 0.000036	 wd 0.0000	time 0.3353 (0.3604)	loss 1.5493 (1.3637)	grad_norm 1.9528 (1.6830)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:01:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:06:36 lr 0.000036	 wd 0.0000	time 0.3288 (0.3598)	loss 1.4427 (1.3638)	grad_norm 1.6882 (1.6806)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:02:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:06:00 lr 0.000037	 wd 0.0000	time 0.3329 (0.3593)	loss 1.2800 (1.3667)	grad_norm 1.3602 (1.6869)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:02:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:05:23 lr 0.000037	 wd 0.0000	time 0.3454 (0.3589)	loss 1.2294 (1.3661)	grad_norm 1.5588 (1.6815)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:03:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:04:47 lr 0.000037	 wd 0.0000	time 0.3267 (0.3585)	loss 1.5437 (1.3658)	grad_norm 1.7037 (nan)	loss_scale 4096.0000 (8066.7842)	mem 7516MB
[2024-07-02 16:03:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:04:11 lr 0.000038	 wd 0.0000	time 0.3304 (0.3582)	loss 1.5432 (1.3656)	grad_norm 1.4713 (nan)	loss_scale 4096.0000 (7846.3076)	mem 7516MB
[2024-07-02 16:04:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:03:35 lr 0.000038	 wd 0.0000	time 0.3465 (0.3580)	loss 1.5476 (1.3654)	grad_norm 2.2001 (nan)	loss_scale 4096.0000 (7649.0268)	mem 7516MB
[2024-07-02 16:05:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:02:59 lr 0.000038	 wd 0.0000	time 0.3381 (0.3578)	loss 1.5719 (1.3656)	grad_norm 2.2855 (nan)	loss_scale 4096.0000 (7471.4643)	mem 7516MB
[2024-07-02 16:05:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:02:23 lr 0.000039	 wd 0.0000	time 0.3369 (0.3575)	loss 1.3764 (1.3656)	grad_norm 2.0790 (nan)	loss_scale 4096.0000 (7310.8044)	mem 7516MB
[2024-07-02 16:06:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:47 lr 0.000039	 wd 0.0000	time 0.3378 (0.3573)	loss 0.9780 (1.3630)	grad_norm 1.8404 (nan)	loss_scale 4096.0000 (7164.7433)	mem 7516MB
[2024-07-02 16:06:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:01:12 lr 0.000039	 wd 0.0000	time 0.3334 (0.3571)	loss 1.2696 (1.3639)	grad_norm 3.0616 (nan)	loss_scale 4096.0000 (7031.3777)	mem 7516MB
[2024-07-02 16:07:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:36 lr 0.000040	 wd 0.0000	time 0.3430 (0.3569)	loss 1.4733 (1.3636)	grad_norm 1.3152 (nan)	loss_scale 4096.0000 (6909.1212)	mem 7516MB
[2024-07-02 16:08:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.3319 (0.3567)	loss 0.9065 (1.3634)	grad_norm 1.3889 (nan)	loss_scale 4096.0000 (6796.6413)	mem 7516MB
[2024-07-02 16:08:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 4 training takes 0:14:55
[2024-07-02 16:08:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.043 (11.043)	Loss 0.4363 (0.4363)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 16:08:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.148 Acc@5 97.314
[2024-07-02 16:08:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-02 16:08:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-02 16:08:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saving......
[2024-07-02 16:08:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saved !!!
[2024-07-02 16:08:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][0/2502]	eta 7:07:17 lr 0.000040	 wd 0.0000	time 10.2467 (10.2467)	loss 1.5629 (1.5629)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:09:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:18:00 lr 0.000040	 wd 0.0000	time 0.3432 (0.4500)	loss 1.3032 (1.3773)	grad_norm 1.7970 (1.6562)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:09:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:15:23 lr 0.000040	 wd 0.0000	time 0.3481 (0.4012)	loss 1.4327 (1.3916)	grad_norm 1.3811 (1.6834)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:10:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:14:05 lr 0.000040	 wd 0.0000	time 0.3444 (0.3842)	loss 1.6471 (1.3783)	grad_norm 1.4434 (1.6670)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:11:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:13:09 lr 0.000040	 wd 0.0000	time 0.3376 (0.3756)	loss 1.1451 (1.3792)	grad_norm 2.1227 (1.6438)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:11:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:12:22 lr 0.000040	 wd 0.0000	time 0.3424 (0.3707)	loss 1.6917 (1.3746)	grad_norm 1.3416 (1.6280)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:12:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:11:38 lr 0.000040	 wd 0.0000	time 0.3124 (0.3674)	loss 1.5331 (1.3778)	grad_norm 1.4224 (1.6212)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:12:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:10:58 lr 0.000040	 wd 0.0000	time 0.3383 (0.3652)	loss 1.5057 (1.3752)	grad_norm 2.1239 (1.6336)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:13:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:10:18 lr 0.000040	 wd 0.0000	time 0.3316 (0.3635)	loss 1.1204 (1.3692)	grad_norm 1.3823 (1.6398)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:14:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:09:40 lr 0.000040	 wd 0.0000	time 0.3241 (0.3621)	loss 0.8341 (1.3677)	grad_norm 1.3865 (1.6382)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:14:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:09:02 lr 0.000040	 wd 0.0000	time 0.3415 (0.3612)	loss 1.3948 (1.3705)	grad_norm 1.3044 (1.6395)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:15:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:08:25 lr 0.000040	 wd 0.0000	time 0.3343 (0.3605)	loss 1.5306 (1.3661)	grad_norm 1.4987 (1.6411)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:15:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:07:48 lr 0.000040	 wd 0.0000	time 0.3257 (0.3599)	loss 1.4993 (1.3653)	grad_norm 1.9990 (1.6430)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:16:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:07:11 lr 0.000040	 wd 0.0000	time 0.3348 (0.3594)	loss 1.5234 (1.3654)	grad_norm 1.4926 (1.6496)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:16:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:06:35 lr 0.000040	 wd 0.0000	time 0.3154 (0.3588)	loss 1.4853 (1.3651)	grad_norm 1.5150 (1.6541)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:17:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:05:59 lr 0.000040	 wd 0.0000	time 0.3419 (0.3584)	loss 1.3068 (1.3651)	grad_norm 1.5197 (1.6543)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:18:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:05:22 lr 0.000040	 wd 0.0000	time 0.3342 (0.3580)	loss 1.4233 (1.3662)	grad_norm 1.5176 (1.6520)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:18:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:04:46 lr 0.000040	 wd 0.0000	time 0.3307 (0.3576)	loss 1.4815 (1.3663)	grad_norm 1.5097 (1.6477)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:19:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:04:10 lr 0.000040	 wd 0.0000	time 0.3361 (0.3573)	loss 1.0394 (1.3652)	grad_norm 2.0258 (1.6446)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:19:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:03:34 lr 0.000040	 wd 0.0000	time 0.3259 (0.3571)	loss 1.5330 (1.3671)	grad_norm 1.4826 (1.6499)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:20:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:02:59 lr 0.000040	 wd 0.0000	time 0.3406 (0.3569)	loss 1.4070 (1.3684)	grad_norm 2.7557 (1.6522)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:21:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:02:23 lr 0.000040	 wd 0.0000	time 0.3465 (0.3567)	loss 1.5975 (1.3693)	grad_norm 1.3681 (1.6560)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:21:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:47 lr 0.000040	 wd 0.0000	time 0.3323 (0.3565)	loss 1.3314 (1.3672)	grad_norm 1.3499 (1.6582)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:22:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:01:11 lr 0.000040	 wd 0.0000	time 0.3442 (0.3564)	loss 0.9417 (1.3666)	grad_norm 1.2730 (1.6583)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:22:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:36 lr 0.000040	 wd 0.0000	time 0.3378 (0.3562)	loss 1.6354 (1.3667)	grad_norm 2.0524 (1.6622)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:23:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.3388 (0.3560)	loss 1.4408 (1.3666)	grad_norm 1.6103 (1.6633)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:23:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 5 training takes 0:14:53
[2024-07-02 16:23:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.378 (11.378)	Loss 0.4355 (0.4355)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 16:23:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.100 Acc@5 97.324
[2024-07-02 16:23:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-02 16:23:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-02 16:24:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][0/2502]	eta 7:50:28 lr 0.000040	 wd 0.0000	time 11.2825 (11.2825)	loss 1.7761 (1.7761)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:24:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:18:25 lr 0.000040	 wd 0.0000	time 0.3316 (0.4601)	loss 1.2523 (1.3489)	grad_norm 1.4730 (1.5818)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:25:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:15:35 lr 0.000040	 wd 0.0000	time 0.3352 (0.4066)	loss 1.4244 (1.3652)	grad_norm 1.6244 (1.5998)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:25:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:14:15 lr 0.000040	 wd 0.0000	time 0.3416 (0.3886)	loss 1.5674 (1.3721)	grad_norm 1.6524 (1.6311)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:26:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:13:18 lr 0.000040	 wd 0.0000	time 0.3362 (0.3798)	loss 1.4087 (1.3647)	grad_norm 1.4578 (1.6420)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:26:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:12:29 lr 0.000040	 wd 0.0000	time 0.3358 (0.3744)	loss 1.5149 (1.3626)	grad_norm 2.4608 (1.6763)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:27:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:11:45 lr 0.000040	 wd 0.0000	time 0.3281 (0.3708)	loss 1.4970 (1.3640)	grad_norm 1.4205 (1.6795)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 16:28:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:11:02 lr 0.000040	 wd 0.0000	time 0.3347 (0.3679)	loss 1.3957 (1.3644)	grad_norm 1.8214 (1.6746)	loss_scale 8192.0000 (4423.2126)	mem 7516MB
[2024-07-02 16:28:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:10:22 lr 0.000040	 wd 0.0000	time 0.3277 (0.3658)	loss 1.1010 (1.3644)	grad_norm 1.6548 (1.6685)	loss_scale 8192.0000 (4893.7228)	mem 7516MB
[2024-07-02 16:29:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:09:43 lr 0.000040	 wd 0.0000	time 0.3455 (0.3643)	loss 1.5436 (1.3661)	grad_norm 2.3432 (1.6736)	loss_scale 8192.0000 (5259.7913)	mem 7516MB
[2024-07-02 16:29:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:09:05 lr 0.000040	 wd 0.0000	time 0.3303 (0.3630)	loss 1.3137 (1.3629)	grad_norm 1.9114 (1.6779)	loss_scale 8192.0000 (5552.7193)	mem 7516MB
[2024-07-02 16:30:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:08:27 lr 0.000040	 wd 0.0000	time 0.3308 (0.3621)	loss 1.2900 (1.3604)	grad_norm 1.5164 (1.6878)	loss_scale 8192.0000 (5792.4360)	mem 7516MB
[2024-07-02 16:31:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:07:50 lr 0.000040	 wd 0.0000	time 0.3361 (0.3613)	loss 1.1114 (1.3615)	grad_norm 1.5011 (1.6873)	loss_scale 8192.0000 (5992.2331)	mem 7516MB
[2024-07-02 16:31:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:07:13 lr 0.000040	 wd 0.0000	time 0.3221 (0.3606)	loss 1.5117 (1.3605)	grad_norm 1.8602 (1.6837)	loss_scale 8192.0000 (6161.3159)	mem 7516MB
[2024-07-02 16:32:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:06:36 lr 0.000040	 wd 0.0000	time 0.3415 (0.3600)	loss 1.7592 (1.3584)	grad_norm 1.6890 (1.6772)	loss_scale 8192.0000 (6306.2612)	mem 7516MB
[2024-07-02 16:32:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:06:00 lr 0.000040	 wd 0.0000	time 0.3319 (0.3594)	loss 1.4454 (1.3608)	grad_norm 1.3804 (1.6700)	loss_scale 8192.0000 (6431.8934)	mem 7516MB
[2024-07-02 16:33:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:05:23 lr 0.000040	 wd 0.0000	time 0.3369 (0.3590)	loss 1.4179 (1.3591)	grad_norm 2.1219 (1.6798)	loss_scale 8192.0000 (6541.8314)	mem 7516MB
[2024-07-02 16:34:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:04:47 lr 0.000040	 wd 0.0000	time 0.3377 (0.3586)	loss 1.5431 (1.3590)	grad_norm 1.5971 (1.6779)	loss_scale 8192.0000 (6638.8430)	mem 7516MB
[2024-07-02 16:34:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:04:11 lr 0.000040	 wd 0.0000	time 0.3432 (0.3582)	loss 1.0986 (1.3588)	grad_norm 1.5871 (1.6733)	loss_scale 8192.0000 (6725.0816)	mem 7516MB
[2024-07-02 16:35:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:03:35 lr 0.000040	 wd 0.0000	time 0.3310 (0.3579)	loss 1.2344 (1.3588)	grad_norm 1.4819 (1.6737)	loss_scale 8192.0000 (6802.2472)	mem 7516MB
[2024-07-02 16:35:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:02:59 lr 0.000039	 wd 0.0000	time 0.3335 (0.3577)	loss 1.0908 (1.3593)	grad_norm 1.4571 (1.6701)	loss_scale 8192.0000 (6871.7001)	mem 7516MB
[2024-07-02 16:36:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:02:23 lr 0.000039	 wd 0.0000	time 0.3430 (0.3575)	loss 1.4890 (1.3586)	grad_norm 1.5048 (1.6663)	loss_scale 8192.0000 (6934.5416)	mem 7516MB
[2024-07-02 16:36:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:47 lr 0.000039	 wd 0.0000	time 0.3303 (0.3573)	loss 1.2564 (1.3586)	grad_norm 1.6222 (1.6658)	loss_scale 8192.0000 (6991.6729)	mem 7516MB
[2024-07-02 16:37:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:01:12 lr 0.000039	 wd 0.0000	time 0.3442 (0.3571)	loss 1.4881 (1.3591)	grad_norm 1.3979 (1.6656)	loss_scale 8192.0000 (7043.8383)	mem 7516MB
[2024-07-02 16:38:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:36 lr 0.000039	 wd 0.0000	time 0.3379 (0.3569)	loss 1.1530 (1.3585)	grad_norm 2.2359 (1.6683)	loss_scale 8192.0000 (7091.6585)	mem 7516MB
[2024-07-02 16:38:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.3335 (0.3567)	loss 0.9805 (1.3589)	grad_norm 1.4514 (1.6664)	loss_scale 8192.0000 (7135.6545)	mem 7516MB
[2024-07-02 16:38:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 6 training takes 0:14:55
[2024-07-02 16:38:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.626 (11.626)	Loss 0.4316 (0.4316)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 16:39:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.060 Acc@5 97.302
[2024-07-02 16:39:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.1%
[2024-07-02 16:39:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.15%
[2024-07-02 16:39:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][0/2502]	eta 7:53:38 lr 0.000039	 wd 0.0000	time 11.3582 (11.3582)	loss 1.6680 (1.6680)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:39:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:18:27 lr 0.000039	 wd 0.0000	time 0.3349 (0.4610)	loss 1.3543 (1.3702)	grad_norm 1.7947 (1.5640)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:40:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:15:38 lr 0.000039	 wd 0.0000	time 0.3327 (0.4075)	loss 1.5802 (1.3509)	grad_norm 2.6298 (1.6060)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:41:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:14:16 lr 0.000039	 wd 0.0000	time 0.3318 (0.3891)	loss 1.3511 (1.3510)	grad_norm 1.6414 (1.6327)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:41:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:13:18 lr 0.000039	 wd 0.0000	time 0.3231 (0.3798)	loss 1.4301 (1.3545)	grad_norm 1.3901 (1.6349)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:42:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:12:28 lr 0.000039	 wd 0.0000	time 0.3225 (0.3739)	loss 1.5227 (1.3503)	grad_norm 2.3749 (1.6580)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:42:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:11:44 lr 0.000039	 wd 0.0000	time 0.3294 (0.3702)	loss 1.3716 (1.3541)	grad_norm 5.2340 (1.6655)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:43:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:11:02 lr 0.000039	 wd 0.0000	time 0.3389 (0.3677)	loss 1.3921 (1.3558)	grad_norm 1.2683 (1.6573)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:44:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:10:22 lr 0.000039	 wd 0.0000	time 0.3388 (0.3657)	loss 1.0520 (1.3577)	grad_norm 1.5651 (1.6538)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:44:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:09:43 lr 0.000039	 wd 0.0000	time 0.3380 (0.3643)	loss 1.1645 (1.3603)	grad_norm 1.9170 (1.6467)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:45:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:09:05 lr 0.000039	 wd 0.0000	time 0.3343 (0.3632)	loss 1.2578 (1.3572)	grad_norm 1.8533 (1.6521)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:45:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:08:27 lr 0.000039	 wd 0.0000	time 0.3241 (0.3622)	loss 1.3415 (1.3558)	grad_norm 1.5053 (1.6536)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:46:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:07:50 lr 0.000039	 wd 0.0000	time 0.3392 (0.3614)	loss 1.3137 (1.3528)	grad_norm 1.4594 (1.6580)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:46:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:07:13 lr 0.000039	 wd 0.0000	time 0.3338 (0.3606)	loss 1.4318 (1.3537)	grad_norm 2.0337 (1.6567)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:47:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:06:36 lr 0.000039	 wd 0.0000	time 0.3319 (0.3601)	loss 1.5433 (1.3540)	grad_norm 2.0702 (1.6664)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:48:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:06:00 lr 0.000039	 wd 0.0000	time 0.3410 (0.3596)	loss 1.4516 (1.3533)	grad_norm 2.3008 (1.6630)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:48:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:05:23 lr 0.000039	 wd 0.0000	time 0.3417 (0.3592)	loss 1.4985 (1.3546)	grad_norm 1.9756 (1.6617)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:49:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:04:47 lr 0.000039	 wd 0.0000	time 0.3377 (0.3588)	loss 1.5349 (1.3547)	grad_norm 3.3028 (1.6653)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:49:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:04:11 lr 0.000039	 wd 0.0000	time 0.3373 (0.3585)	loss 1.3179 (1.3544)	grad_norm 1.7945 (1.6711)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:50:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:03:35 lr 0.000039	 wd 0.0000	time 0.3445 (0.3582)	loss 1.3309 (1.3537)	grad_norm 1.5924 (1.6713)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:51:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:02:59 lr 0.000039	 wd 0.0000	time 0.3406 (0.3579)	loss 1.4741 (1.3545)	grad_norm 1.4279 (1.6754)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:51:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:02:23 lr 0.000039	 wd 0.0000	time 0.3369 (0.3576)	loss 1.6346 (1.3561)	grad_norm 1.6311 (1.6768)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:52:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:47 lr 0.000039	 wd 0.0000	time 0.3464 (0.3574)	loss 1.2559 (1.3546)	grad_norm 1.2554 (nan)	loss_scale 8192.0000 (8229.2194)	mem 7516MB
[2024-07-02 16:52:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:01:12 lr 0.000039	 wd 0.0000	time 0.3382 (0.3572)	loss 1.4933 (1.3552)	grad_norm 1.4655 (nan)	loss_scale 8192.0000 (8227.6019)	mem 7516MB
[2024-07-02 16:53:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:36 lr 0.000039	 wd 0.0000	time 0.3261 (0.3570)	loss 1.3759 (1.3549)	grad_norm 1.9340 (nan)	loss_scale 8192.0000 (8226.1191)	mem 7516MB
[2024-07-02 16:54:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.3443 (0.3567)	loss 1.3034 (1.3550)	grad_norm 1.8203 (nan)	loss_scale 8192.0000 (8224.7549)	mem 7516MB
[2024-07-02 16:54:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 7 training takes 0:14:55
[2024-07-02 16:54:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.868 (11.868)	Loss 0.4270 (0.4270)	Acc@1 91.602 (91.602)	Acc@5 98.438 (98.438)	Mem 7516MB
[2024-07-02 16:54:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.250 Acc@5 97.322
[2024-07-02 16:54:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-02 16:54:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.25%
[2024-07-02 16:54:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saving......
[2024-07-02 16:54:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saved !!!
[2024-07-02 16:54:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][0/2502]	eta 7:08:24 lr 0.000039	 wd 0.0000	time 10.2734 (10.2734)	loss 1.5434 (1.5434)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:55:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:17:56 lr 0.000039	 wd 0.0000	time 0.3413 (0.4483)	loss 1.4615 (1.3844)	grad_norm 1.5114 (1.6154)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:55:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:15:19 lr 0.000039	 wd 0.0000	time 0.3299 (0.3994)	loss 1.4182 (1.3575)	grad_norm 1.4864 (1.6123)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:56:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:14:03 lr 0.000038	 wd 0.0000	time 0.3357 (0.3832)	loss 1.3294 (1.3528)	grad_norm 1.5313 (1.6491)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:57:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:13:08 lr 0.000038	 wd 0.0000	time 0.3316 (0.3753)	loss 1.4292 (1.3496)	grad_norm 1.5863 (1.6413)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:57:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:12:21 lr 0.000038	 wd 0.0000	time 0.3387 (0.3705)	loss 1.4972 (1.3559)	grad_norm 1.6168 (1.6610)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:58:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:11:38 lr 0.000038	 wd 0.0000	time 0.3380 (0.3673)	loss 1.5440 (1.3602)	grad_norm 1.5249 (1.6564)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:58:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:10:57 lr 0.000038	 wd 0.0000	time 0.3365 (0.3650)	loss 1.5257 (1.3605)	grad_norm 1.5498 (1.6638)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:59:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:10:18 lr 0.000038	 wd 0.0000	time 0.3400 (0.3633)	loss 1.4123 (1.3597)	grad_norm 1.4583 (1.6509)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 16:59:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:09:40 lr 0.000038	 wd 0.0000	time 0.3339 (0.3621)	loss 1.5327 (1.3605)	grad_norm 1.5592 (1.6435)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:00:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:09:02 lr 0.000038	 wd 0.0000	time 0.3478 (0.3612)	loss 1.4140 (1.3583)	grad_norm 1.4274 (1.6417)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:01:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:08:25 lr 0.000038	 wd 0.0000	time 0.3200 (0.3605)	loss 1.4708 (1.3547)	grad_norm 1.6670 (1.6464)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:01:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:07:48 lr 0.000038	 wd 0.0000	time 0.3310 (0.3598)	loss 1.4163 (1.3538)	grad_norm 1.5480 (1.6530)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:02:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:07:11 lr 0.000038	 wd 0.0000	time 0.3102 (0.3592)	loss 1.0505 (1.3517)	grad_norm 1.6113 (1.6507)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:02:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:06:35 lr 0.000038	 wd 0.0000	time 0.3429 (0.3588)	loss 0.9570 (1.3527)	grad_norm 2.1978 (1.6533)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:03:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:05:59 lr 0.000038	 wd 0.0000	time 0.3455 (0.3584)	loss 0.9209 (1.3492)	grad_norm 2.6397 (1.6665)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:04:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:05:22 lr 0.000038	 wd 0.0000	time 0.3416 (0.3581)	loss 1.2676 (1.3464)	grad_norm 1.4288 (1.6685)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:04:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:04:46 lr 0.000038	 wd 0.0000	time 0.3453 (0.3578)	loss 1.2241 (1.3477)	grad_norm 1.3131 (1.6671)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:05:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:04:10 lr 0.000038	 wd 0.0000	time 0.3366 (0.3575)	loss 1.4862 (1.3496)	grad_norm 1.4294 (1.6715)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:05:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:03:35 lr 0.000038	 wd 0.0000	time 0.3257 (0.3572)	loss 1.2508 (1.3500)	grad_norm 1.6831 (1.6742)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:06:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:02:59 lr 0.000038	 wd 0.0000	time 0.3420 (0.3570)	loss 1.7424 (1.3520)	grad_norm 1.6521 (1.6752)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:06:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:02:23 lr 0.000038	 wd 0.0000	time 0.3423 (0.3568)	loss 1.3754 (1.3520)	grad_norm 1.6713 (1.6799)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:07:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:47 lr 0.000038	 wd 0.0000	time 0.3318 (0.3566)	loss 1.4466 (1.3510)	grad_norm 1.7100 (1.6814)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:08:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:01:11 lr 0.000038	 wd 0.0000	time 0.3346 (0.3564)	loss 1.3606 (1.3516)	grad_norm 1.6816 (1.6823)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:08:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:36 lr 0.000038	 wd 0.0000	time 0.3359 (0.3563)	loss 1.4233 (1.3534)	grad_norm 1.9393 (1.6823)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:09:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000038	 wd 0.0000	time 0.3239 (0.3560)	loss 1.5704 (1.3546)	grad_norm 1.4267 (1.6873)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:09:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 8 training takes 0:14:53
[2024-07-02 17:09:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 10.811 (10.811)	Loss 0.4285 (0.4285)	Acc@1 91.992 (91.992)	Acc@5 98.242 (98.242)	Mem 7516MB
[2024-07-02 17:09:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.324 Acc@5 97.364
[2024-07-02 17:09:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-02 17:09:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.32%
[2024-07-02 17:09:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saving......
[2024-07-02 17:09:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saved !!!
[2024-07-02 17:09:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][0/2502]	eta 7:04:29 lr 0.000038	 wd 0.0000	time 10.1797 (10.1797)	loss 1.3683 (1.3683)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:10:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:17:58 lr 0.000038	 wd 0.0000	time 0.3387 (0.4489)	loss 1.2850 (1.3248)	grad_norm 1.5143 (1.6085)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:11:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:15:22 lr 0.000037	 wd 0.0000	time 0.3326 (0.4009)	loss 1.5197 (1.3312)	grad_norm 1.9245 (1.5947)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:11:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:14:06 lr 0.000037	 wd 0.0000	time 0.3356 (0.3843)	loss 1.4108 (1.3418)	grad_norm 1.5518 (1.6438)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:12:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:13:10 lr 0.000037	 wd 0.0000	time 0.3509 (0.3761)	loss 1.5594 (1.3375)	grad_norm 1.2976 (1.6345)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:12:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:12:22 lr 0.000037	 wd 0.0000	time 0.3414 (0.3709)	loss 1.3235 (1.3429)	grad_norm 1.3622 (1.6237)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:13:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:11:39 lr 0.000037	 wd 0.0000	time 0.3413 (0.3678)	loss 1.3980 (1.3367)	grad_norm 1.4527 (1.6449)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:14:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:10:58 lr 0.000037	 wd 0.0000	time 0.3214 (0.3655)	loss 1.5121 (1.3370)	grad_norm 1.5548 (1.6399)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:14:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:10:19 lr 0.000037	 wd 0.0000	time 0.3439 (0.3639)	loss 1.3845 (1.3418)	grad_norm 1.5956 (1.6435)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:15:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:09:40 lr 0.000037	 wd 0.0000	time 0.3345 (0.3626)	loss 1.5027 (1.3393)	grad_norm 1.8122 (1.6452)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:15:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:09:03 lr 0.000037	 wd 0.0000	time 0.3394 (0.3615)	loss 1.4804 (1.3417)	grad_norm 1.4658 (1.6402)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:16:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:08:25 lr 0.000037	 wd 0.0000	time 0.3438 (0.3607)	loss 1.3478 (1.3455)	grad_norm 1.5723 (1.6524)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:17:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:07:48 lr 0.000037	 wd 0.0000	time 0.3332 (0.3601)	loss 1.6370 (1.3480)	grad_norm 1.3012 (1.6550)	loss_scale 16384.0000 (8546.6911)	mem 7516MB
[2024-07-02 17:17:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:07:12 lr 0.000037	 wd 0.0000	time 0.3410 (0.3595)	loss 0.9417 (1.3454)	grad_norm 1.3305 (1.6571)	loss_scale 16384.0000 (9149.0976)	mem 7516MB
[2024-07-02 17:18:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:06:35 lr 0.000037	 wd 0.0000	time 0.3477 (0.3590)	loss 1.3862 (1.3474)	grad_norm 1.4378 (1.6653)	loss_scale 16384.0000 (9665.5075)	mem 7516MB
[2024-07-02 17:18:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:05:59 lr 0.000037	 wd 0.0000	time 0.3296 (0.3586)	loss 1.5324 (1.3498)	grad_norm 1.7730 (1.6652)	loss_scale 16384.0000 (10113.1086)	mem 7516MB
[2024-07-02 17:19:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:05:23 lr 0.000037	 wd 0.0000	time 0.3289 (0.3583)	loss 0.9649 (1.3494)	grad_norm 1.4768 (1.6643)	loss_scale 16384.0000 (10504.7945)	mem 7516MB
[2024-07-02 17:19:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:04:47 lr 0.000037	 wd 0.0000	time 0.3420 (0.3579)	loss 1.0769 (1.3509)	grad_norm 1.5325 (1.6651)	loss_scale 16384.0000 (10850.4268)	mem 7516MB
[2024-07-02 17:20:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:04:11 lr 0.000037	 wd 0.0000	time 0.3309 (0.3577)	loss 1.4927 (1.3515)	grad_norm 1.5589 (1.6641)	loss_scale 16384.0000 (11157.6768)	mem 7516MB
[2024-07-02 17:21:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:03:35 lr 0.000037	 wd 0.0000	time 0.3289 (0.3574)	loss 1.3765 (1.3505)	grad_norm 1.4656 (1.6639)	loss_scale 16384.0000 (11432.6018)	mem 7516MB
[2024-07-02 17:21:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:02:59 lr 0.000037	 wd 0.0000	time 0.3337 (0.3571)	loss 1.5153 (1.3497)	grad_norm 1.3852 (1.6602)	loss_scale 16384.0000 (11680.0480)	mem 7516MB
[2024-07-02 17:22:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:02:23 lr 0.000036	 wd 0.0000	time 0.3428 (0.3569)	loss 1.1695 (1.3502)	grad_norm 1.7840 (1.6606)	loss_scale 16384.0000 (11903.9391)	mem 7516MB
[2024-07-02 17:22:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:47 lr 0.000036	 wd 0.0000	time 0.3279 (0.3567)	loss 1.4471 (1.3517)	grad_norm 1.7756 (1.6597)	loss_scale 16384.0000 (12107.4857)	mem 7516MB
[2024-07-02 17:23:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:01:12 lr 0.000036	 wd 0.0000	time 0.3259 (0.3566)	loss 1.4004 (1.3522)	grad_norm 1.6207 (1.6618)	loss_scale 16384.0000 (12293.3403)	mem 7516MB
[2024-07-02 17:24:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:36 lr 0.000036	 wd 0.0000	time 0.3377 (0.3564)	loss 1.2499 (1.3520)	grad_norm 2.3254 (1.6581)	loss_scale 16384.0000 (12463.7135)	mem 7516MB
[2024-07-02 17:24:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000036	 wd 0.0000	time 0.3330 (0.3562)	loss 0.9051 (1.3529)	grad_norm 1.4043 (1.6556)	loss_scale 16384.0000 (12620.4622)	mem 7516MB
[2024-07-02 17:24:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 9 training takes 0:14:53
[2024-07-02 17:24:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.835 (11.835)	Loss 0.4148 (0.4148)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 7516MB
[2024-07-02 17:25:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.302 Acc@5 97.336
[2024-07-02 17:25:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-02 17:25:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.32%
[2024-07-02 17:25:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][0/2502]	eta 7:30:22 lr 0.000036	 wd 0.0000	time 10.8004 (10.8004)	loss 1.3012 (1.3012)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:25:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:18:24 lr 0.000036	 wd 0.0000	time 0.3437 (0.4597)	loss 1.2107 (1.3154)	grad_norm 1.9285 (1.5896)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:26:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:15:34 lr 0.000036	 wd 0.0000	time 0.3391 (0.4061)	loss 1.3943 (1.3435)	grad_norm 1.8931 (1.6136)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:27:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:14:14 lr 0.000036	 wd 0.0000	time 0.3270 (0.3882)	loss 0.9040 (1.3458)	grad_norm 1.5683 (1.6466)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:27:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:13:16 lr 0.000036	 wd 0.0000	time 0.3297 (0.3790)	loss 1.5349 (1.3504)	grad_norm 1.5853 (1.6502)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:28:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:12:28 lr 0.000036	 wd 0.0000	time 0.3370 (0.3737)	loss 1.4737 (1.3474)	grad_norm 1.3521 (1.6474)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:28:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:11:43 lr 0.000036	 wd 0.0000	time 0.3337 (0.3700)	loss 1.5846 (1.3461)	grad_norm 2.0494 (1.6421)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:29:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:11:02 lr 0.000036	 wd 0.0000	time 0.3425 (0.3675)	loss 1.4336 (1.3434)	grad_norm 1.3904 (1.6749)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:29:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:10:22 lr 0.000036	 wd 0.0000	time 0.3344 (0.3657)	loss 1.2970 (1.3452)	grad_norm 1.3949 (1.6742)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:30:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:09:43 lr 0.000036	 wd 0.0000	time 0.3228 (0.3641)	loss 1.4747 (1.3448)	grad_norm 1.6600 (1.6646)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:31:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:09:05 lr 0.000036	 wd 0.0000	time 0.3286 (0.3629)	loss 1.5664 (1.3427)	grad_norm 1.8946 (1.6617)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:31:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:08:27 lr 0.000036	 wd 0.0000	time 0.3278 (0.3619)	loss 1.3300 (1.3402)	grad_norm 1.5623 (1.6586)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:32:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:07:50 lr 0.000035	 wd 0.0000	time 0.3422 (0.3612)	loss 1.2533 (1.3405)	grad_norm 1.5802 (1.6547)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:32:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:07:13 lr 0.000035	 wd 0.0000	time 0.3219 (0.3604)	loss 1.5517 (1.3432)	grad_norm 1.4586 (1.6615)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:33:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:06:36 lr 0.000035	 wd 0.0000	time 0.3410 (0.3599)	loss 1.4230 (1.3455)	grad_norm 1.4955 (1.6637)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:34:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:06:00 lr 0.000035	 wd 0.0000	time 0.3312 (0.3593)	loss 1.2339 (1.3457)	grad_norm 1.6078 (1.6637)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:34:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:05:23 lr 0.000035	 wd 0.0000	time 0.3288 (0.3590)	loss 1.2317 (1.3470)	grad_norm 1.4529 (1.6682)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:35:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:04:47 lr 0.000035	 wd 0.0000	time 0.3348 (0.3586)	loss 1.3991 (1.3477)	grad_norm 1.5767 (1.6689)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:35:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:04:11 lr 0.000035	 wd 0.0000	time 0.3318 (0.3582)	loss 1.3277 (1.3479)	grad_norm 2.1159 (1.6686)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:36:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:03:35 lr 0.000035	 wd 0.0000	time 0.3316 (0.3579)	loss 1.4336 (1.3487)	grad_norm 2.5096 (1.6719)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:37:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:02:59 lr 0.000035	 wd 0.0000	time 0.3372 (0.3576)	loss 1.3125 (1.3488)	grad_norm 1.7215 (1.6768)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:37:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:02:23 lr 0.000035	 wd 0.0000	time 0.3281 (0.3574)	loss 1.4358 (1.3504)	grad_norm 1.4925 (1.6771)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:38:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:47 lr 0.000035	 wd 0.0000	time 0.3241 (0.3572)	loss 0.9899 (1.3509)	grad_norm 1.5422 (1.6776)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:38:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:01:12 lr 0.000035	 wd 0.0000	time 0.3403 (0.3570)	loss 1.4602 (1.3503)	grad_norm 1.6794 (1.6782)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:39:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:36 lr 0.000035	 wd 0.0000	time 0.3426 (0.3568)	loss 1.4085 (1.3504)	grad_norm 1.6380 (1.6757)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:39:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.3354 (0.3566)	loss 1.4903 (1.3498)	grad_norm 1.4584 (1.6775)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:40:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 10 training takes 0:14:54
[2024-07-02 17:40:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 10.207 (10.207)	Loss 0.4199 (0.4199)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 17:40:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.414 Acc@5 97.388
[2024-07-02 17:40:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.4%
[2024-07-02 17:40:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.41%
[2024-07-02 17:40:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saving......
[2024-07-02 17:40:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saved !!!
[2024-07-02 17:40:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][0/2502]	eta 5:47:18 lr 0.000035	 wd 0.0000	time 8.3289 (8.3289)	loss 1.5371 (1.5371)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:41:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:17:40 lr 0.000035	 wd 0.0000	time 0.3316 (0.4414)	loss 1.3324 (1.3445)	grad_norm 1.8304 (1.6503)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 17:41:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:15:13 lr 0.000034	 wd 0.0000	time 0.3304 (0.3968)	loss 1.5423 (1.3458)	grad_norm 1.9965 (1.6309)	loss_scale 32768.0000 (20948.6965)	mem 7516MB
[2024-07-02 17:42:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:14:01 lr 0.000034	 wd 0.0000	time 0.3462 (0.3820)	loss 1.2494 (1.3471)	grad_norm 1.7747 (nan)	loss_scale 16384.0000 (22044.9169)	mem 7516MB
[2024-07-02 17:42:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:13:07 lr 0.000034	 wd 0.0000	time 0.3295 (0.3748)	loss 1.4413 (1.3522)	grad_norm 1.5506 (nan)	loss_scale 16384.0000 (20633.2170)	mem 7516MB
[2024-07-02 17:43:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:12:21 lr 0.000034	 wd 0.0000	time 0.3339 (0.3703)	loss 1.3315 (1.3446)	grad_norm 1.2641 (nan)	loss_scale 16384.0000 (19785.0699)	mem 7516MB
[2024-07-02 17:44:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:11:38 lr 0.000034	 wd 0.0000	time 0.3096 (0.3673)	loss 1.4370 (1.3431)	grad_norm 5.2661 (nan)	loss_scale 16384.0000 (19219.1681)	mem 7516MB
[2024-07-02 17:44:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:10:57 lr 0.000034	 wd 0.0000	time 0.3386 (0.3651)	loss 1.3861 (1.3434)	grad_norm 1.5318 (nan)	loss_scale 16384.0000 (18814.7218)	mem 7516MB
[2024-07-02 17:45:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:10:18 lr 0.000034	 wd 0.0000	time 0.3353 (0.3635)	loss 1.6613 (1.3463)	grad_norm 1.4642 (nan)	loss_scale 16384.0000 (18511.2609)	mem 7516MB
[2024-07-02 17:45:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:09:40 lr 0.000034	 wd 0.0000	time 0.3271 (0.3622)	loss 1.4751 (1.3466)	grad_norm 1.5251 (nan)	loss_scale 16384.0000 (18275.1609)	mem 7516MB
[2024-07-02 17:46:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:09:02 lr 0.000034	 wd 0.0000	time 0.3407 (0.3612)	loss 1.4296 (1.3465)	grad_norm 1.7699 (nan)	loss_scale 16384.0000 (18086.2338)	mem 7516MB
[2024-07-02 17:47:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:08:25 lr 0.000034	 wd 0.0000	time 0.3402 (0.3604)	loss 1.4104 (1.3481)	grad_norm 1.5259 (nan)	loss_scale 16384.0000 (17931.6258)	mem 7516MB
[2024-07-02 17:47:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:07:48 lr 0.000034	 wd 0.0000	time 0.3397 (0.3597)	loss 1.5672 (1.3489)	grad_norm 1.8020 (nan)	loss_scale 16384.0000 (17802.7644)	mem 7516MB
[2024-07-02 17:48:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:07:11 lr 0.000034	 wd 0.0000	time 0.3410 (0.3591)	loss 1.0851 (1.3474)	grad_norm 1.1985 (nan)	loss_scale 16384.0000 (17693.7125)	mem 7516MB
[2024-07-02 17:48:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:06:35 lr 0.000034	 wd 0.0000	time 0.3461 (0.3586)	loss 0.9806 (1.3474)	grad_norm 1.2754 (nan)	loss_scale 16384.0000 (17600.2284)	mem 7516MB
[2024-07-02 17:49:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:05:58 lr 0.000034	 wd 0.0000	time 0.3339 (0.3583)	loss 1.4426 (1.3466)	grad_norm 1.4299 (nan)	loss_scale 16384.0000 (17519.2005)	mem 7516MB
[2024-07-02 17:49:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:05:22 lr 0.000034	 wd 0.0000	time 0.3483 (0.3580)	loss 1.2747 (1.3477)	grad_norm 2.1093 (nan)	loss_scale 16384.0000 (17448.2948)	mem 7516MB
[2024-07-02 17:50:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:04:46 lr 0.000033	 wd 0.0000	time 0.3347 (0.3576)	loss 1.4010 (1.3465)	grad_norm 1.4630 (nan)	loss_scale 16384.0000 (17385.7260)	mem 7516MB
[2024-07-02 17:51:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:04:10 lr 0.000033	 wd 0.0000	time 0.3353 (0.3573)	loss 1.2944 (1.3480)	grad_norm 1.6793 (nan)	loss_scale 16384.0000 (17330.1055)	mem 7516MB
[2024-07-02 17:51:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:03:35 lr 0.000033	 wd 0.0000	time 0.3448 (0.3572)	loss 1.5286 (1.3478)	grad_norm 1.3753 (nan)	loss_scale 16384.0000 (17280.3367)	mem 7516MB
[2024-07-02 17:52:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:02:59 lr 0.000033	 wd 0.0000	time 0.3347 (0.3569)	loss 1.2055 (1.3476)	grad_norm 1.3093 (nan)	loss_scale 16384.0000 (17235.5422)	mem 7516MB
[2024-07-02 17:52:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:02:23 lr 0.000033	 wd 0.0000	time 0.3452 (0.3568)	loss 1.3843 (1.3469)	grad_norm 1.3347 (nan)	loss_scale 16384.0000 (17195.0119)	mem 7516MB
[2024-07-02 17:53:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:47 lr 0.000033	 wd 0.0000	time 0.3337 (0.3566)	loss 1.3892 (1.3484)	grad_norm 1.3233 (nan)	loss_scale 16384.0000 (17158.1645)	mem 7516MB
[2024-07-02 17:54:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:01:11 lr 0.000033	 wd 0.0000	time 0.3184 (0.3564)	loss 1.4677 (1.3478)	grad_norm 1.5472 (nan)	loss_scale 16384.0000 (17124.5198)	mem 7516MB
[2024-07-02 17:54:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:36 lr 0.000033	 wd 0.0000	time 0.3352 (0.3562)	loss 1.3627 (1.3470)	grad_norm 3.0415 (nan)	loss_scale 8192.0000 (16970.8488)	mem 7516MB
[2024-07-02 17:55:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000033	 wd 0.0000	time 0.3384 (0.3560)	loss 1.3920 (1.3470)	grad_norm 1.8031 (nan)	loss_scale 8192.0000 (16619.8353)	mem 7516MB
[2024-07-02 17:55:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 11 training takes 0:14:53
[2024-07-02 17:55:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.059 (11.059)	Loss 0.4158 (0.4158)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 17:55:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.302 Acc@5 97.302
[2024-07-02 17:55:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-02 17:55:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.41%
[2024-07-02 17:55:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][0/2502]	eta 7:35:13 lr 0.000033	 wd 0.0000	time 10.9167 (10.9167)	loss 1.6146 (1.6146)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:56:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:18:20 lr 0.000033	 wd 0.0000	time 0.3391 (0.4581)	loss 1.5109 (1.3411)	grad_norm 1.4499 (1.7177)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:57:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:15:33 lr 0.000033	 wd 0.0000	time 0.3394 (0.4056)	loss 0.8851 (1.3462)	grad_norm 1.3542 (1.7447)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:57:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:14:13 lr 0.000033	 wd 0.0000	time 0.3368 (0.3878)	loss 1.3119 (1.3472)	grad_norm 1.9893 (1.7035)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:58:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:13:16 lr 0.000033	 wd 0.0000	time 0.3394 (0.3788)	loss 1.2976 (1.3415)	grad_norm 1.3544 (1.7248)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:58:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:12:28 lr 0.000032	 wd 0.0000	time 0.3365 (0.3737)	loss 1.0946 (1.3433)	grad_norm 2.0479 (1.7528)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:59:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:11:43 lr 0.000032	 wd 0.0000	time 0.3381 (0.3701)	loss 1.3514 (1.3406)	grad_norm 1.7888 (1.7229)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 17:59:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:11:01 lr 0.000032	 wd 0.0000	time 0.3390 (0.3672)	loss 1.4074 (1.3410)	grad_norm 1.4818 (1.7114)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:00:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:10:21 lr 0.000032	 wd 0.0000	time 0.3285 (0.3654)	loss 1.6370 (1.3505)	grad_norm 1.7759 (1.7195)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:01:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:09:42 lr 0.000032	 wd 0.0000	time 0.3309 (0.3639)	loss 1.0416 (1.3522)	grad_norm 1.7121 (1.7069)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:01:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:09:04 lr 0.000032	 wd 0.0000	time 0.3427 (0.3627)	loss 1.3765 (1.3507)	grad_norm 1.5503 (1.7002)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:02:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:08:27 lr 0.000032	 wd 0.0000	time 0.3445 (0.3618)	loss 1.4805 (1.3555)	grad_norm 1.4046 (1.6964)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:02:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:07:49 lr 0.000032	 wd 0.0000	time 0.3423 (0.3609)	loss 1.5781 (1.3538)	grad_norm 1.5203 (1.6983)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:03:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:07:12 lr 0.000032	 wd 0.0000	time 0.3364 (0.3602)	loss 1.5727 (1.3540)	grad_norm 1.5405 (1.6969)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:04:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:06:36 lr 0.000032	 wd 0.0000	time 0.3312 (0.3596)	loss 1.5519 (1.3542)	grad_norm 1.4233 (1.6927)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:04:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:05:59 lr 0.000032	 wd 0.0000	time 0.3324 (0.3590)	loss 1.4405 (1.3547)	grad_norm 1.7843 (1.6933)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:05:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:05:23 lr 0.000032	 wd 0.0000	time 0.3442 (0.3586)	loss 1.4612 (1.3530)	grad_norm 1.4389 (1.6829)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:05:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:04:47 lr 0.000031	 wd 0.0000	time 0.3374 (0.3582)	loss 1.3835 (1.3540)	grad_norm 1.3944 (1.6852)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:06:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:04:11 lr 0.000031	 wd 0.0000	time 0.3447 (0.3579)	loss 1.3198 (1.3550)	grad_norm 1.6214 (1.6871)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:07:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:03:35 lr 0.000031	 wd 0.0000	time 0.3283 (0.3576)	loss 1.2906 (1.3546)	grad_norm 1.6080 (1.6860)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:07:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:02:59 lr 0.000031	 wd 0.0000	time 0.3241 (0.3574)	loss 1.3809 (1.3541)	grad_norm 1.5531 (1.6909)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:08:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:02:23 lr 0.000031	 wd 0.0000	time 0.3360 (0.3572)	loss 1.5071 (1.3547)	grad_norm 1.9003 (1.7018)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:08:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:47 lr 0.000031	 wd 0.0000	time 0.3290 (0.3570)	loss 1.4694 (1.3553)	grad_norm 1.4282 (1.7007)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:09:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:01:12 lr 0.000031	 wd 0.0000	time 0.3192 (0.3568)	loss 1.3666 (1.3550)	grad_norm 1.5717 (1.6976)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:09:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:36 lr 0.000031	 wd 0.0000	time 0.3371 (0.3566)	loss 1.5208 (1.3547)	grad_norm 1.5863 (1.6960)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:10:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000031	 wd 0.0000	time 0.3406 (0.3564)	loss 1.0716 (1.3531)	grad_norm 1.5763 (1.6932)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:10:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 12 training takes 0:14:54
[2024-07-02 18:10:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.675 (11.675)	Loss 0.4128 (0.4128)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 18:10:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.416 Acc@5 97.372
[2024-07-02 18:10:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.4%
[2024-07-02 18:10:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.42%
[2024-07-02 18:10:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saving......
[2024-07-02 18:11:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saved !!!
[2024-07-02 18:11:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][0/2502]	eta 6:58:04 lr 0.000031	 wd 0.0000	time 10.0259 (10.0259)	loss 1.3298 (1.3298)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:11:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:17:55 lr 0.000031	 wd 0.0000	time 0.3344 (0.4476)	loss 1.4692 (1.3431)	grad_norm 1.5236 (1.7295)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:12:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:15:19 lr 0.000031	 wd 0.0000	time 0.3328 (0.3996)	loss 1.5867 (1.3455)	grad_norm 1.4560 (1.6557)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 18:12:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:14:03 lr 0.000031	 wd 0.0000	time 0.3325 (0.3832)	loss 1.5144 (1.3510)	grad_norm 1.2560 (nan)	loss_scale 4096.0000 (7729.3289)	mem 7516MB
[2024-07-02 18:13:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:13:08 lr 0.000030	 wd 0.0000	time 0.3407 (0.3750)	loss 1.4278 (1.3489)	grad_norm 1.5794 (nan)	loss_scale 4096.0000 (6823.2618)	mem 7516MB
[2024-07-02 18:14:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:12:21 lr 0.000030	 wd 0.0000	time 0.3327 (0.3702)	loss 1.4640 (1.3436)	grad_norm 2.1823 (nan)	loss_scale 4096.0000 (6278.8982)	mem 7516MB
[2024-07-02 18:14:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:11:38 lr 0.000030	 wd 0.0000	time 0.3379 (0.3673)	loss 1.4809 (1.3475)	grad_norm 1.5068 (nan)	loss_scale 4096.0000 (5915.6872)	mem 7516MB
[2024-07-02 18:15:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:10:58 lr 0.000030	 wd 0.0000	time 0.3319 (0.3652)	loss 1.6855 (1.3439)	grad_norm 1.4722 (nan)	loss_scale 4096.0000 (5656.1027)	mem 7516MB
[2024-07-02 18:15:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:10:18 lr 0.000030	 wd 0.0000	time 0.3323 (0.3635)	loss 1.4874 (1.3472)	grad_norm 1.4188 (nan)	loss_scale 4096.0000 (5461.3333)	mem 7516MB
[2024-07-02 18:16:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:09:40 lr 0.000030	 wd 0.0000	time 0.3433 (0.3623)	loss 1.5689 (1.3432)	grad_norm 1.5819 (nan)	loss_scale 4096.0000 (5309.7980)	mem 7516MB
[2024-07-02 18:17:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:09:02 lr 0.000030	 wd 0.0000	time 0.3327 (0.3614)	loss 1.5079 (1.3461)	grad_norm 1.3759 (nan)	loss_scale 4096.0000 (5188.5395)	mem 7516MB
[2024-07-02 18:17:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:08:25 lr 0.000030	 wd 0.0000	time 0.3218 (0.3605)	loss 1.4649 (1.3482)	grad_norm 1.6446 (nan)	loss_scale 4096.0000 (5089.3079)	mem 7516MB
[2024-07-02 18:18:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:07:48 lr 0.000030	 wd 0.0000	time 0.3379 (0.3598)	loss 1.6277 (1.3454)	grad_norm 1.3722 (nan)	loss_scale 4096.0000 (5006.6012)	mem 7516MB
[2024-07-02 18:18:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:07:11 lr 0.000030	 wd 0.0000	time 0.3334 (0.3592)	loss 1.5343 (1.3447)	grad_norm 1.5134 (nan)	loss_scale 4096.0000 (4936.6088)	mem 7516MB
[2024-07-02 18:19:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:06:35 lr 0.000030	 wd 0.0000	time 0.3374 (0.3588)	loss 1.6056 (1.3453)	grad_norm 1.6199 (nan)	loss_scale 4096.0000 (4876.6081)	mem 7516MB
[2024-07-02 18:19:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:05:59 lr 0.000030	 wd 0.0000	time 0.3421 (0.3584)	loss 1.5024 (1.3449)	grad_norm 1.5406 (nan)	loss_scale 4096.0000 (4824.6023)	mem 7516MB
[2024-07-02 18:20:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:05:22 lr 0.000029	 wd 0.0000	time 0.3369 (0.3580)	loss 1.4938 (1.3447)	grad_norm 1.6150 (nan)	loss_scale 4096.0000 (4779.0931)	mem 7516MB
[2024-07-02 18:21:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:04:46 lr 0.000029	 wd 0.0000	time 0.3308 (0.3577)	loss 0.8816 (1.3422)	grad_norm 1.4922 (nan)	loss_scale 4096.0000 (4738.9347)	mem 7516MB
[2024-07-02 18:21:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:04:10 lr 0.000029	 wd 0.0000	time 0.3390 (0.3574)	loss 1.3261 (1.3436)	grad_norm 2.4769 (nan)	loss_scale 4096.0000 (4703.2360)	mem 7516MB
[2024-07-02 18:22:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:03:35 lr 0.000029	 wd 0.0000	time 0.3423 (0.3572)	loss 1.1469 (1.3437)	grad_norm 1.5074 (nan)	loss_scale 4096.0000 (4671.2930)	mem 7516MB
[2024-07-02 18:22:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:02:59 lr 0.000029	 wd 0.0000	time 0.3338 (0.3570)	loss 1.3868 (1.3443)	grad_norm 4.1499 (nan)	loss_scale 4096.0000 (4642.5427)	mem 7516MB
[2024-07-02 18:23:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:02:23 lr 0.000029	 wd 0.0000	time 0.3373 (0.3568)	loss 1.0908 (1.3438)	grad_norm 1.7175 (nan)	loss_scale 4096.0000 (4616.5293)	mem 7516MB
[2024-07-02 18:24:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:47 lr 0.000029	 wd 0.0000	time 0.3290 (0.3566)	loss 1.5192 (1.3455)	grad_norm 1.4392 (nan)	loss_scale 4096.0000 (4592.8796)	mem 7516MB
[2024-07-02 18:24:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:01:12 lr 0.000029	 wd 0.0000	time 0.3296 (0.3565)	loss 1.3599 (1.3445)	grad_norm 1.4979 (nan)	loss_scale 4096.0000 (4571.2855)	mem 7516MB
[2024-07-02 18:25:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:36 lr 0.000029	 wd 0.0000	time 0.3415 (0.3563)	loss 1.4950 (1.3452)	grad_norm 1.4776 (nan)	loss_scale 4096.0000 (4551.4902)	mem 7516MB
[2024-07-02 18:25:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000029	 wd 0.0000	time 0.3365 (0.3561)	loss 1.4279 (1.3446)	grad_norm 1.3116 (nan)	loss_scale 4096.0000 (4533.2779)	mem 7516MB
[2024-07-02 18:25:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 13 training takes 0:14:53
[2024-07-02 18:26:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.798 (11.798)	Loss 0.4131 (0.4131)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 7516MB
[2024-07-02 18:26:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.460 Acc@5 97.416
[2024-07-02 18:26:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.5%
[2024-07-02 18:26:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.46%
[2024-07-02 18:26:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saving......
[2024-07-02 18:26:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saved !!!
[2024-07-02 18:26:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][0/2502]	eta 7:12:37 lr 0.000029	 wd 0.0000	time 10.3745 (10.3745)	loss 1.5502 (1.5502)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 18:27:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:18:06 lr 0.000029	 wd 0.0000	time 0.3295 (0.4525)	loss 1.4753 (1.3387)	grad_norm 1.6459 (1.6125)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 18:27:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:15:26 lr 0.000028	 wd 0.0000	time 0.3446 (0.4023)	loss 1.2341 (1.3631)	grad_norm 1.4417 (1.6281)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 18:28:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:14:09 lr 0.000028	 wd 0.0000	time 0.3492 (0.3857)	loss 1.1329 (1.3521)	grad_norm 1.3540 (1.6104)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 18:28:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:13:13 lr 0.000028	 wd 0.0000	time 0.3304 (0.3773)	loss 1.1717 (1.3403)	grad_norm 1.5143 (1.6064)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 18:29:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:12:25 lr 0.000028	 wd 0.0000	time 0.3364 (0.3721)	loss 1.4156 (1.3414)	grad_norm 2.1310 (nan)	loss_scale 2048.0000 (4079.6487)	mem 7516MB
[2024-07-02 18:30:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:11:41 lr 0.000028	 wd 0.0000	time 0.3113 (0.3687)	loss 1.5770 (1.3448)	grad_norm 1.9726 (nan)	loss_scale 2048.0000 (3741.6040)	mem 7516MB
[2024-07-02 18:30:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:11:00 lr 0.000028	 wd 0.0000	time 0.3377 (0.3663)	loss 1.3147 (1.3417)	grad_norm 3.0664 (nan)	loss_scale 2048.0000 (3500.0057)	mem 7516MB
[2024-07-02 18:31:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:10:20 lr 0.000028	 wd 0.0000	time 0.3287 (0.3644)	loss 1.3183 (1.3390)	grad_norm 1.7343 (nan)	loss_scale 2048.0000 (3318.7316)	mem 7516MB
[2024-07-02 18:31:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:09:41 lr 0.000028	 wd 0.0000	time 0.3376 (0.3631)	loss 1.5860 (1.3373)	grad_norm 1.9777 (nan)	loss_scale 2048.0000 (3177.6959)	mem 7516MB
[2024-07-02 18:32:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:09:03 lr 0.000028	 wd 0.0000	time 0.3396 (0.3619)	loss 1.1143 (1.3355)	grad_norm 1.2519 (nan)	loss_scale 2048.0000 (3064.8392)	mem 7516MB
[2024-07-02 18:32:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:08:26 lr 0.000028	 wd 0.0000	time 0.3389 (0.3610)	loss 1.3978 (1.3330)	grad_norm 1.5311 (nan)	loss_scale 2048.0000 (2972.4832)	mem 7516MB
[2024-07-02 18:33:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:07:49 lr 0.000028	 wd 0.0000	time 0.3438 (0.3602)	loss 1.5236 (1.3333)	grad_norm 1.4074 (nan)	loss_scale 2048.0000 (2895.5071)	mem 7516MB
[2024-07-02 18:34:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:07:12 lr 0.000027	 wd 0.0000	time 0.3371 (0.3596)	loss 1.2070 (1.3347)	grad_norm 1.4267 (nan)	loss_scale 2048.0000 (2830.3643)	mem 7516MB
[2024-07-02 18:34:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:06:35 lr 0.000027	 wd 0.0000	time 0.3285 (0.3591)	loss 1.4808 (1.3341)	grad_norm 1.5498 (nan)	loss_scale 2048.0000 (2774.5211)	mem 7516MB
[2024-07-02 18:35:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:05:59 lr 0.000027	 wd 0.0000	time 0.3297 (0.3587)	loss 1.3765 (1.3348)	grad_norm 1.4672 (nan)	loss_scale 2048.0000 (2726.1186)	mem 7516MB
[2024-07-02 18:35:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:05:23 lr 0.000027	 wd 0.0000	time 0.3426 (0.3583)	loss 1.3791 (1.3357)	grad_norm 1.6940 (nan)	loss_scale 2048.0000 (2683.7626)	mem 7516MB
[2024-07-02 18:36:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:04:47 lr 0.000027	 wd 0.0000	time 0.3345 (0.3579)	loss 1.2307 (1.3360)	grad_norm 1.7089 (nan)	loss_scale 2048.0000 (2646.3868)	mem 7516MB
[2024-07-02 18:37:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:04:11 lr 0.000027	 wd 0.0000	time 0.3256 (0.3576)	loss 1.2871 (1.3355)	grad_norm 1.5233 (nan)	loss_scale 2048.0000 (2613.1616)	mem 7516MB
[2024-07-02 18:37:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:03:35 lr 0.000027	 wd 0.0000	time 0.3436 (0.3573)	loss 1.4217 (1.3354)	grad_norm 2.5817 (nan)	loss_scale 2048.0000 (2583.4319)	mem 7516MB
[2024-07-02 18:38:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:02:59 lr 0.000027	 wd 0.0000	time 0.3253 (0.3571)	loss 1.0255 (1.3370)	grad_norm 1.4684 (nan)	loss_scale 2048.0000 (2556.6737)	mem 7516MB
[2024-07-02 18:38:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:02:23 lr 0.000027	 wd 0.0000	time 0.3441 (0.3568)	loss 1.6370 (1.3361)	grad_norm 1.8972 (nan)	loss_scale 2048.0000 (2532.4626)	mem 7516MB
[2024-07-02 18:39:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:47 lr 0.000027	 wd 0.0000	time 0.3371 (0.3566)	loss 1.2515 (1.3366)	grad_norm 1.3849 (nan)	loss_scale 2048.0000 (2510.4516)	mem 7516MB
[2024-07-02 18:39:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:01:12 lr 0.000027	 wd 0.0000	time 0.3203 (0.3565)	loss 1.3391 (1.3375)	grad_norm 1.9548 (nan)	loss_scale 2048.0000 (2490.3538)	mem 7516MB
[2024-07-02 18:40:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:36 lr 0.000026	 wd 0.0000	time 0.3421 (0.3564)	loss 1.2821 (1.3386)	grad_norm 2.0260 (nan)	loss_scale 2048.0000 (2471.9300)	mem 7516MB
[2024-07-02 18:41:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.3334 (0.3561)	loss 1.3483 (1.3377)	grad_norm 1.7249 (nan)	loss_scale 2048.0000 (2454.9796)	mem 7516MB
[2024-07-02 18:41:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 14 training takes 0:14:53
[2024-07-02 18:41:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.115 (11.115)	Loss 0.4177 (0.4177)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 18:41:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.488 Acc@5 97.400
[2024-07-02 18:41:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.5%
[2024-07-02 18:41:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.49%
[2024-07-02 18:41:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saving......
[2024-07-02 18:41:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saved !!!
[2024-07-02 18:41:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][0/2502]	eta 6:58:24 lr 0.000026	 wd 0.0000	time 10.0337 (10.0337)	loss 1.3627 (1.3627)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:42:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:17:57 lr 0.000026	 wd 0.0000	time 0.3427 (0.4484)	loss 1.0429 (1.3284)	grad_norm 1.5087 (1.5561)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:42:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:15:21 lr 0.000026	 wd 0.0000	time 0.3389 (0.4001)	loss 1.4300 (1.3388)	grad_norm 1.5763 (1.6128)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:43:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:14:05 lr 0.000026	 wd 0.0000	time 0.3460 (0.3839)	loss 1.3501 (1.3258)	grad_norm 1.2547 (1.6352)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:44:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:13:10 lr 0.000026	 wd 0.0000	time 0.3297 (0.3759)	loss 1.3480 (1.3294)	grad_norm 1.4855 (1.6258)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:44:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:12:23 lr 0.000026	 wd 0.0000	time 0.3442 (0.3712)	loss 0.8759 (1.3243)	grad_norm 1.2486 (1.6248)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:45:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:11:40 lr 0.000026	 wd 0.0000	time 0.3290 (0.3681)	loss 0.8687 (1.3275)	grad_norm 1.6366 (1.6419)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:45:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:10:58 lr 0.000026	 wd 0.0000	time 0.3426 (0.3657)	loss 1.1405 (1.3312)	grad_norm 1.5915 (1.6571)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:46:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:10:19 lr 0.000026	 wd 0.0000	time 0.3270 (0.3639)	loss 1.5241 (1.3325)	grad_norm 1.6196 (1.6524)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:47:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:09:41 lr 0.000025	 wd 0.0000	time 0.3394 (0.3627)	loss 1.1815 (1.3317)	grad_norm 3.0357 (1.6481)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:47:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:09:03 lr 0.000025	 wd 0.0000	time 0.3355 (0.3616)	loss 1.3575 (1.3319)	grad_norm 1.3527 (1.6486)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:48:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:08:25 lr 0.000025	 wd 0.0000	time 0.3439 (0.3608)	loss 1.3094 (1.3288)	grad_norm 1.3803 (1.6625)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:48:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:07:48 lr 0.000025	 wd 0.0000	time 0.3377 (0.3601)	loss 1.5572 (1.3289)	grad_norm 1.3262 (1.6579)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:49:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:07:12 lr 0.000025	 wd 0.0000	time 0.3323 (0.3596)	loss 1.3415 (1.3277)	grad_norm 1.8174 (1.6629)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:50:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:06:35 lr 0.000025	 wd 0.0000	time 0.3359 (0.3590)	loss 1.2988 (1.3285)	grad_norm 1.3970 (1.6620)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:50:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:05:59 lr 0.000025	 wd 0.0000	time 0.3342 (0.3586)	loss 1.5924 (1.3279)	grad_norm 1.5896 (1.6614)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:51:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:05:23 lr 0.000025	 wd 0.0000	time 0.3208 (0.3583)	loss 1.2288 (1.3308)	grad_norm 1.3826 (1.6652)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:51:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:04:47 lr 0.000025	 wd 0.0000	time 0.3287 (0.3579)	loss 1.5531 (1.3311)	grad_norm 1.5563 (1.6663)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:52:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:04:11 lr 0.000025	 wd 0.0000	time 0.3322 (0.3576)	loss 1.0515 (1.3308)	grad_norm 1.4050 (1.6639)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:52:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:03:35 lr 0.000024	 wd 0.0000	time 0.3402 (0.3574)	loss 1.5853 (1.3319)	grad_norm 1.4412 (1.6614)	loss_scale 2048.0000 (2048.0000)	mem 7516MB
[2024-07-02 18:53:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:02:59 lr 0.000024	 wd 0.0000	time 0.3413 (0.3571)	loss 1.7619 (1.3346)	grad_norm 1.9471 (1.6617)	loss_scale 4096.0000 (2054.1409)	mem 7516MB
[2024-07-02 18:54:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:02:23 lr 0.000024	 wd 0.0000	time 0.3416 (0.3570)	loss 1.6163 (1.3354)	grad_norm 1.5122 (1.6685)	loss_scale 4096.0000 (2151.3260)	mem 7516MB
[2024-07-02 18:54:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:47 lr 0.000024	 wd 0.0000	time 0.3377 (0.3568)	loss 0.9070 (1.3364)	grad_norm 1.3204 (1.6662)	loss_scale 4096.0000 (2239.6801)	mem 7516MB
[2024-07-02 18:55:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:01:12 lr 0.000024	 wd 0.0000	time 0.3251 (0.3566)	loss 1.5107 (1.3368)	grad_norm 1.4398 (1.6668)	loss_scale 4096.0000 (2320.3546)	mem 7516MB
[2024-07-02 18:55:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:36 lr 0.000024	 wd 0.0000	time 0.3423 (0.3565)	loss 1.1880 (1.3357)	grad_norm 1.5712 (1.6630)	loss_scale 4096.0000 (2394.3090)	mem 7516MB
[2024-07-02 18:56:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.3416 (0.3562)	loss 1.4006 (1.3359)	grad_norm 1.5021 (1.6641)	loss_scale 4096.0000 (2462.3495)	mem 7516MB
[2024-07-02 18:56:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 15 training takes 0:14:53
[2024-07-02 18:56:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_15.pth saving......
[2024-07-02 18:56:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_15.pth saved !!!
[2024-07-02 18:56:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 10.919 (10.919)	Loss 0.4141 (0.4141)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 18:56:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.390 Acc@5 97.424
[2024-07-02 18:56:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.4%
[2024-07-02 18:56:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.49%
[2024-07-02 18:57:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][0/2502]	eta 7:23:22 lr 0.000024	 wd 0.0000	time 10.6327 (10.6327)	loss 1.1858 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 18:57:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:18:29 lr 0.000024	 wd 0.0000	time 0.3425 (0.4620)	loss 1.4981 (1.3393)	grad_norm 1.6164 (1.7629)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 18:58:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:15:36 lr 0.000024	 wd 0.0000	time 0.3403 (0.4068)	loss 1.2839 (1.3466)	grad_norm 1.3778 (1.7059)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 18:58:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:14:15 lr 0.000024	 wd 0.0000	time 0.3369 (0.3883)	loss 1.3236 (1.3546)	grad_norm 1.7599 (1.6680)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 18:59:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:13:17 lr 0.000024	 wd 0.0000	time 0.3298 (0.3794)	loss 1.2005 (1.3487)	grad_norm 1.6949 (1.6821)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:00:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:12:28 lr 0.000023	 wd 0.0000	time 0.3416 (0.3737)	loss 1.3625 (1.3566)	grad_norm 1.4709 (1.6500)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:00:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:11:43 lr 0.000023	 wd 0.0000	time 0.3428 (0.3698)	loss 1.0464 (1.3478)	grad_norm 1.5991 (1.6562)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:01:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:11:01 lr 0.000023	 wd 0.0000	time 0.3388 (0.3671)	loss 1.2979 (1.3497)	grad_norm 1.5486 (1.6594)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:01:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:10:21 lr 0.000023	 wd 0.0000	time 0.3316 (0.3651)	loss 1.3113 (1.3437)	grad_norm 1.4294 (1.6674)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:02:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:09:42 lr 0.000023	 wd 0.0000	time 0.3266 (0.3635)	loss 1.3284 (1.3432)	grad_norm 1.5533 (1.6619)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:02:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:09:04 lr 0.000023	 wd 0.0000	time 0.3330 (0.3623)	loss 1.4660 (1.3434)	grad_norm 1.4773 (1.6682)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:03:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:08:26 lr 0.000023	 wd 0.0000	time 0.3207 (0.3614)	loss 1.2963 (1.3455)	grad_norm 6.5858 (1.6722)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:04:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:07:49 lr 0.000023	 wd 0.0000	time 0.3364 (0.3606)	loss 1.5226 (1.3449)	grad_norm 1.6038 (1.6668)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:04:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:07:12 lr 0.000023	 wd 0.0000	time 0.3216 (0.3601)	loss 1.0406 (1.3450)	grad_norm 1.5165 (1.6711)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:05:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:06:36 lr 0.000023	 wd 0.0000	time 0.3344 (0.3595)	loss 1.2906 (1.3425)	grad_norm 1.3740 (1.6705)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:05:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:05:59 lr 0.000022	 wd 0.0000	time 0.3324 (0.3590)	loss 1.3696 (1.3399)	grad_norm 1.8281 (1.6788)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:06:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:05:23 lr 0.000022	 wd 0.0000	time 0.3336 (0.3586)	loss 1.3985 (1.3393)	grad_norm 1.9475 (1.6758)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:07:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:04:47 lr 0.000022	 wd 0.0000	time 0.3362 (0.3583)	loss 1.0583 (1.3376)	grad_norm 1.6928 (1.6767)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:07:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:04:11 lr 0.000022	 wd 0.0000	time 0.3421 (0.3580)	loss 1.0882 (1.3366)	grad_norm 1.4742 (1.6817)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:08:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:03:35 lr 0.000022	 wd 0.0000	time 0.3360 (0.3576)	loss 1.2831 (1.3359)	grad_norm 1.3196 (1.6820)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:08:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:02:59 lr 0.000022	 wd 0.0000	time 0.3314 (0.3575)	loss 1.5392 (1.3358)	grad_norm 2.0228 (1.6864)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:09:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:02:23 lr 0.000022	 wd 0.0000	time 0.3362 (0.3573)	loss 1.4355 (1.3353)	grad_norm 1.4651 (1.6828)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:10:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:47 lr 0.000022	 wd 0.0000	time 0.3355 (0.3571)	loss 1.3449 (1.3360)	grad_norm 2.3240 (1.6828)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:10:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:01:12 lr 0.000022	 wd 0.0000	time 0.3232 (0.3569)	loss 1.2426 (1.3363)	grad_norm 1.5330 (1.6846)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:11:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:36 lr 0.000022	 wd 0.0000	time 0.3330 (0.3567)	loss 1.3011 (1.3362)	grad_norm 1.8593 (1.6833)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:11:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.3320 (0.3564)	loss 1.3862 (1.3359)	grad_norm 1.4368 (1.6802)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:11:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 16 training takes 0:14:54
[2024-07-02 19:12:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.007 (11.007)	Loss 0.4136 (0.4136)	Acc@1 91.797 (91.797)	Acc@5 98.438 (98.438)	Mem 7516MB
[2024-07-02 19:12:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.550 Acc@5 97.424
[2024-07-02 19:12:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-02 19:12:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.55%
[2024-07-02 19:12:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saving......
[2024-07-02 19:12:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saved !!!
[2024-07-02 19:12:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][0/2502]	eta 7:16:32 lr 0.000021	 wd 0.0000	time 10.4684 (10.4684)	loss 1.4172 (1.4172)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:13:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:18:01 lr 0.000021	 wd 0.0000	time 0.3350 (0.4503)	loss 1.5681 (1.3174)	grad_norm 1.7466 (1.6880)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:13:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:15:22 lr 0.000021	 wd 0.0000	time 0.3312 (0.4006)	loss 1.5014 (1.3306)	grad_norm 1.7534 (1.6674)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:14:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:14:06 lr 0.000021	 wd 0.0000	time 0.3427 (0.3845)	loss 1.3987 (1.3269)	grad_norm 1.6971 (1.6707)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:14:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:13:11 lr 0.000021	 wd 0.0000	time 0.3125 (0.3765)	loss 1.1111 (1.3256)	grad_norm 1.4251 (1.6483)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:15:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:12:23 lr 0.000021	 wd 0.0000	time 0.3354 (0.3714)	loss 1.3378 (1.3236)	grad_norm 1.6223 (1.6446)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:15:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:11:39 lr 0.000021	 wd 0.0000	time 0.3381 (0.3678)	loss 1.1648 (1.3291)	grad_norm 1.4460 (1.6453)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:16:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:10:58 lr 0.000021	 wd 0.0000	time 0.3297 (0.3654)	loss 1.3408 (1.3333)	grad_norm 1.7469 (1.6538)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:17:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:10:18 lr 0.000021	 wd 0.0000	time 0.3433 (0.3636)	loss 1.2976 (1.3363)	grad_norm 1.8934 (1.6651)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:17:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:09:40 lr 0.000021	 wd 0.0000	time 0.3315 (0.3623)	loss 1.4408 (1.3385)	grad_norm 1.4137 (1.6759)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 19:18:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:09:02 lr 0.000020	 wd 0.0000	time 0.3476 (0.3615)	loss 1.4868 (1.3362)	grad_norm 1.5781 (1.6658)	loss_scale 8192.0000 (4136.9191)	mem 7516MB
[2024-07-02 19:18:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:08:25 lr 0.000020	 wd 0.0000	time 0.3176 (0.3606)	loss 1.1606 (1.3346)	grad_norm 1.4231 (1.6778)	loss_scale 8192.0000 (4505.2280)	mem 7516MB
[2024-07-02 19:19:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:07:48 lr 0.000020	 wd 0.0000	time 0.3433 (0.3599)	loss 1.4134 (1.3368)	grad_norm 1.3103 (1.6799)	loss_scale 8192.0000 (4812.2032)	mem 7516MB
[2024-07-02 19:20:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:07:11 lr 0.000020	 wd 0.0000	time 0.3388 (0.3594)	loss 1.2282 (1.3366)	grad_norm 2.2375 (1.6772)	loss_scale 8192.0000 (5071.9877)	mem 7516MB
[2024-07-02 19:20:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:06:35 lr 0.000020	 wd 0.0000	time 0.3379 (0.3589)	loss 1.4846 (1.3371)	grad_norm 1.6506 (1.6859)	loss_scale 8192.0000 (5294.6867)	mem 7516MB
[2024-07-02 19:21:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:05:59 lr 0.000020	 wd 0.0000	time 0.3394 (0.3584)	loss 1.5152 (1.3377)	grad_norm 1.4748 (1.6827)	loss_scale 8192.0000 (5487.7122)	mem 7516MB
[2024-07-02 19:21:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:05:22 lr 0.000020	 wd 0.0000	time 0.3275 (0.3580)	loss 1.4132 (1.3389)	grad_norm 1.6756 (1.6799)	loss_scale 8192.0000 (5656.6246)	mem 7516MB
[2024-07-02 19:22:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:04:46 lr 0.000020	 wd 0.0000	time 0.3419 (0.3577)	loss 1.5775 (1.3403)	grad_norm 1.5175 (1.6797)	loss_scale 8192.0000 (5805.6767)	mem 7516MB
[2024-07-02 19:22:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:04:10 lr 0.000020	 wd 0.0000	time 0.3364 (0.3574)	loss 1.4060 (1.3408)	grad_norm 1.5656 (1.6787)	loss_scale 8192.0000 (5938.1766)	mem 7516MB
[2024-07-02 19:23:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:03:35 lr 0.000020	 wd 0.0000	time 0.3125 (0.3572)	loss 1.2136 (1.3415)	grad_norm 1.4607 (1.6799)	loss_scale 8192.0000 (6056.7365)	mem 7516MB
[2024-07-02 19:24:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:02:59 lr 0.000019	 wd 0.0000	time 0.3356 (0.3570)	loss 1.3976 (1.3391)	grad_norm 3.6039 (1.6787)	loss_scale 8192.0000 (6163.4463)	mem 7516MB
[2024-07-02 19:24:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:02:23 lr 0.000019	 wd 0.0000	time 0.3437 (0.3568)	loss 1.5076 (1.3390)	grad_norm 1.3105 (1.6745)	loss_scale 8192.0000 (6259.9981)	mem 7516MB
[2024-07-02 19:25:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:47 lr 0.000019	 wd 0.0000	time 0.3314 (0.3565)	loss 1.2969 (1.3397)	grad_norm 1.3195 (1.6742)	loss_scale 8192.0000 (6347.7765)	mem 7516MB
[2024-07-02 19:25:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:01:11 lr 0.000019	 wd 0.0000	time 0.3285 (0.3563)	loss 1.5715 (1.3389)	grad_norm 1.6090 (1.6716)	loss_scale 8192.0000 (6427.9252)	mem 7516MB
[2024-07-02 19:26:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:36 lr 0.000019	 wd 0.0000	time 0.3489 (0.3562)	loss 1.4472 (1.3371)	grad_norm 1.5609 (1.6716)	loss_scale 8192.0000 (6501.3978)	mem 7516MB
[2024-07-02 19:27:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000019	 wd 0.0000	time 0.3400 (0.3560)	loss 1.3393 (1.3377)	grad_norm 1.3629 (1.6681)	loss_scale 8192.0000 (6568.9948)	mem 7516MB
[2024-07-02 19:27:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 17 training takes 0:14:53
[2024-07-02 19:27:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 10.791 (10.791)	Loss 0.4192 (0.4192)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 19:27:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.586 Acc@5 97.416
[2024-07-02 19:27:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-02 19:27:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.59%
[2024-07-02 19:27:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saving......
[2024-07-02 19:27:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saved !!!
[2024-07-02 19:27:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][0/2502]	eta 6:51:57 lr 0.000019	 wd 0.0000	time 9.8793 (9.8793)	loss 1.5674 (1.5674)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:28:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:17:51 lr 0.000019	 wd 0.0000	time 0.3321 (0.4462)	loss 1.5255 (1.3735)	grad_norm 1.6179 (1.6892)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:28:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:15:16 lr 0.000019	 wd 0.0000	time 0.3334 (0.3983)	loss 1.5690 (1.3506)	grad_norm 1.5875 (1.7135)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:29:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:14:03 lr 0.000019	 wd 0.0000	time 0.3462 (0.3830)	loss 1.5402 (1.3474)	grad_norm 1.4281 (1.7098)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:30:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:13:08 lr 0.000019	 wd 0.0000	time 0.3452 (0.3753)	loss 1.4173 (1.3445)	grad_norm 1.5641 (1.7123)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:30:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:12:21 lr 0.000018	 wd 0.0000	time 0.3284 (0.3705)	loss 1.2055 (1.3381)	grad_norm 1.6834 (1.6934)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:31:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:11:38 lr 0.000018	 wd 0.0000	time 0.3336 (0.3674)	loss 1.5442 (1.3366)	grad_norm 2.0630 (1.6830)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:31:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:10:58 lr 0.000018	 wd 0.0000	time 0.3252 (0.3652)	loss 1.5521 (1.3377)	grad_norm 1.6292 (1.7077)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:32:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:10:19 lr 0.000018	 wd 0.0000	time 0.3432 (0.3637)	loss 1.1127 (1.3348)	grad_norm 1.6529 (1.7013)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:33:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:09:40 lr 0.000018	 wd 0.0000	time 0.3270 (0.3625)	loss 1.3797 (1.3313)	grad_norm 1.6680 (1.6905)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:33:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:09:02 lr 0.000018	 wd 0.0000	time 0.3370 (0.3615)	loss 1.1280 (1.3351)	grad_norm 1.6769 (1.6959)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:34:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:08:25 lr 0.000018	 wd 0.0000	time 0.3310 (0.3606)	loss 1.2719 (1.3342)	grad_norm 1.4315 (1.6888)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:34:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:07:48 lr 0.000018	 wd 0.0000	time 0.3383 (0.3600)	loss 1.5011 (1.3345)	grad_norm 1.6411 (1.6933)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:35:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:07:11 lr 0.000018	 wd 0.0000	time 0.3279 (0.3594)	loss 1.5453 (1.3354)	grad_norm 1.6010 (1.6923)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:35:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:06:35 lr 0.000018	 wd 0.0000	time 0.3346 (0.3589)	loss 1.1944 (1.3346)	grad_norm 1.4583 (1.6910)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:36:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:05:59 lr 0.000017	 wd 0.0000	time 0.3432 (0.3584)	loss 1.5256 (1.3329)	grad_norm 1.4752 (1.6863)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:37:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:05:22 lr 0.000017	 wd 0.0000	time 0.3449 (0.3581)	loss 1.5593 (1.3327)	grad_norm 1.5803 (1.6874)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:37:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:04:46 lr 0.000017	 wd 0.0000	time 0.3237 (0.3578)	loss 1.4162 (1.3317)	grad_norm 1.4620 (1.6815)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:38:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:04:10 lr 0.000017	 wd 0.0000	time 0.3137 (0.3574)	loss 1.3581 (1.3332)	grad_norm 1.4193 (1.6824)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:38:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:03:34 lr 0.000017	 wd 0.0000	time 0.3458 (0.3571)	loss 1.5496 (1.3332)	grad_norm 1.4077 (1.6788)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:39:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:02:59 lr 0.000017	 wd 0.0000	time 0.3374 (0.3569)	loss 1.4159 (1.3351)	grad_norm 1.3934 (1.6781)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:40:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:02:23 lr 0.000017	 wd 0.0000	time 0.3368 (0.3567)	loss 1.3417 (1.3345)	grad_norm 1.4828 (1.6741)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:40:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:47 lr 0.000017	 wd 0.0000	time 0.3306 (0.3565)	loss 1.4014 (1.3343)	grad_norm 1.9122 (1.6774)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:41:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:01:11 lr 0.000017	 wd 0.0000	time 0.3486 (0.3564)	loss 1.4380 (1.3344)	grad_norm 1.5380 (1.6773)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:41:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:36 lr 0.000017	 wd 0.0000	time 0.3414 (0.3562)	loss 1.5264 (1.3360)	grad_norm 2.3836 (1.6792)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:42:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.3334 (0.3560)	loss 1.5242 (1.3359)	grad_norm 1.5964 (1.6778)	loss_scale 16384.0000 (8231.3059)	mem 7516MB
[2024-07-02 19:42:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 18 training takes 0:14:53
[2024-07-02 19:42:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 10.754 (10.754)	Loss 0.4072 (0.4072)	Acc@1 92.969 (92.969)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 19:42:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.562 Acc@5 97.448
[2024-07-02 19:42:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-02 19:42:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.59%
[2024-07-02 19:43:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][0/2502]	eta 7:58:29 lr 0.000016	 wd 0.0000	time 11.4748 (11.4748)	loss 1.4637 (1.4637)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 19:43:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:18:28 lr 0.000016	 wd 0.0000	time 0.3363 (0.4615)	loss 1.1143 (1.3423)	grad_norm 1.6780 (1.6637)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 19:44:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:15:35 lr 0.000016	 wd 0.0000	time 0.3357 (0.4066)	loss 1.5137 (1.3370)	grad_norm 1.5723 (1.6850)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 19:44:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:14:14 lr 0.000016	 wd 0.0000	time 0.3413 (0.3882)	loss 1.3746 (1.3475)	grad_norm 1.7113 (1.6582)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 19:45:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:13:16 lr 0.000016	 wd 0.0000	time 0.3332 (0.3789)	loss 1.5172 (1.3471)	grad_norm 1.5217 (1.6459)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 19:45:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:12:27 lr 0.000016	 wd 0.0000	time 0.3283 (0.3734)	loss 1.5904 (1.3450)	grad_norm 1.5626 (nan)	loss_scale 8192.0000 (14945.0858)	mem 7516MB
[2024-07-02 19:46:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:11:43 lr 0.000016	 wd 0.0000	time 0.3342 (0.3697)	loss 1.5622 (1.3406)	grad_norm 1.4513 (nan)	loss_scale 8192.0000 (13821.4443)	mem 7516MB
[2024-07-02 19:47:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:11:02 lr 0.000016	 wd 0.0000	time 0.3315 (0.3674)	loss 1.6246 (1.3425)	grad_norm 1.5892 (nan)	loss_scale 8192.0000 (13018.3852)	mem 7516MB
[2024-07-02 19:47:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:10:22 lr 0.000016	 wd 0.0000	time 0.3192 (0.3656)	loss 1.2986 (1.3392)	grad_norm 1.4071 (nan)	loss_scale 8192.0000 (12415.8402)	mem 7516MB
[2024-07-02 19:48:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:09:43 lr 0.000016	 wd 0.0000	time 0.3418 (0.3641)	loss 1.4202 (1.3408)	grad_norm 1.3210 (nan)	loss_scale 8192.0000 (11947.0455)	mem 7516MB
[2024-07-02 19:48:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:09:05 lr 0.000016	 wd 0.0000	time 0.3477 (0.3630)	loss 1.4700 (1.3437)	grad_norm 2.0340 (nan)	loss_scale 8192.0000 (11571.9161)	mem 7516MB
[2024-07-02 19:49:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:08:27 lr 0.000015	 wd 0.0000	time 0.3297 (0.3620)	loss 0.8662 (1.3419)	grad_norm 1.3354 (nan)	loss_scale 8192.0000 (11264.9301)	mem 7516MB
[2024-07-02 19:50:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:07:50 lr 0.000015	 wd 0.0000	time 0.3291 (0.3612)	loss 1.1065 (1.3393)	grad_norm 1.8043 (nan)	loss_scale 8192.0000 (11009.0658)	mem 7516MB
[2024-07-02 19:50:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:07:13 lr 0.000015	 wd 0.0000	time 0.3365 (0.3605)	loss 1.4422 (1.3391)	grad_norm 1.4520 (nan)	loss_scale 8192.0000 (10792.5350)	mem 7516MB
[2024-07-02 19:51:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:06:36 lr 0.000015	 wd 0.0000	time 0.3350 (0.3600)	loss 1.3941 (1.3408)	grad_norm 1.6023 (nan)	loss_scale 8192.0000 (10606.9151)	mem 7516MB
[2024-07-02 19:51:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:06:00 lr 0.000015	 wd 0.0000	time 0.3323 (0.3595)	loss 1.2373 (1.3405)	grad_norm 2.1494 (nan)	loss_scale 8192.0000 (10446.0280)	mem 7516MB
[2024-07-02 19:52:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:05:23 lr 0.000015	 wd 0.0000	time 0.3430 (0.3591)	loss 1.3386 (1.3411)	grad_norm 1.5444 (nan)	loss_scale 8192.0000 (10305.2392)	mem 7516MB
[2024-07-02 19:53:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:04:47 lr 0.000015	 wd 0.0000	time 0.3450 (0.3588)	loss 1.4978 (1.3419)	grad_norm 1.4883 (nan)	loss_scale 8192.0000 (10181.0041)	mem 7516MB
[2024-07-02 19:53:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:04:11 lr 0.000015	 wd 0.0000	time 0.3336 (0.3585)	loss 1.3388 (1.3418)	grad_norm 1.9419 (nan)	loss_scale 8192.0000 (10070.5652)	mem 7516MB
[2024-07-02 19:54:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:03:35 lr 0.000015	 wd 0.0000	time 0.3336 (0.3582)	loss 1.3079 (1.3422)	grad_norm 1.5820 (nan)	loss_scale 8192.0000 (9971.7454)	mem 7516MB
[2024-07-02 19:54:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:02:59 lr 0.000015	 wd 0.0000	time 0.3343 (0.3579)	loss 0.9793 (1.3415)	grad_norm 1.4922 (nan)	loss_scale 8192.0000 (9882.8026)	mem 7516MB
[2024-07-02 19:55:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:02:23 lr 0.000014	 wd 0.0000	time 0.3270 (0.3577)	loss 1.1653 (1.3409)	grad_norm 1.3258 (nan)	loss_scale 8192.0000 (9802.3265)	mem 7516MB
[2024-07-02 19:55:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:47 lr 0.000014	 wd 0.0000	time 0.3354 (0.3574)	loss 1.4523 (1.3391)	grad_norm 5.2415 (nan)	loss_scale 8192.0000 (9729.1631)	mem 7516MB
[2024-07-02 19:56:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:01:12 lr 0.000014	 wd 0.0000	time 0.3367 (0.3573)	loss 1.3844 (1.3385)	grad_norm 1.6065 (nan)	loss_scale 8192.0000 (9662.3590)	mem 7516MB
[2024-07-02 19:57:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:36 lr 0.000014	 wd 0.0000	time 0.3376 (0.3571)	loss 1.5222 (1.3396)	grad_norm 1.4559 (nan)	loss_scale 8192.0000 (9601.1195)	mem 7516MB
[2024-07-02 19:57:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.3360 (0.3568)	loss 1.2429 (1.3396)	grad_norm 1.7150 (nan)	loss_scale 8192.0000 (9544.7773)	mem 7516MB
[2024-07-02 19:57:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 19 training takes 0:14:55
[2024-07-02 19:57:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 10.779 (10.779)	Loss 0.4104 (0.4104)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 19:58:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.550 Acc@5 97.476
[2024-07-02 19:58:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-02 19:58:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.59%
[2024-07-02 19:58:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][0/2502]	eta 6:59:57 lr 0.000014	 wd 0.0000	time 10.0708 (10.0708)	loss 1.0493 (1.0493)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:58:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:18:17 lr 0.000014	 wd 0.0000	time 0.3491 (0.4571)	loss 1.6986 (1.3313)	grad_norm 1.4708 (1.6971)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 19:59:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:15:33 lr 0.000014	 wd 0.0000	time 0.3214 (0.4055)	loss 1.4000 (1.3384)	grad_norm 1.5947 (1.6604)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:00:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:14:14 lr 0.000014	 wd 0.0000	time 0.3282 (0.3879)	loss 1.4216 (1.3370)	grad_norm 1.7434 (1.6376)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:00:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:13:16 lr 0.000014	 wd 0.0000	time 0.3241 (0.3788)	loss 1.5171 (1.3444)	grad_norm 1.4311 (1.6447)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:01:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:12:26 lr 0.000014	 wd 0.0000	time 0.3429 (0.3729)	loss 1.3266 (1.3428)	grad_norm 2.1001 (1.6510)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:01:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:11:42 lr 0.000014	 wd 0.0000	time 0.3371 (0.3692)	loss 1.4067 (1.3386)	grad_norm 1.7207 (1.6547)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:02:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:11:00 lr 0.000013	 wd 0.0000	time 0.3435 (0.3667)	loss 1.4410 (1.3441)	grad_norm 2.1917 (1.6672)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:03:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:10:20 lr 0.000013	 wd 0.0000	time 0.3416 (0.3647)	loss 1.2342 (1.3413)	grad_norm 1.3985 (1.6608)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:03:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:09:41 lr 0.000013	 wd 0.0000	time 0.3439 (0.3633)	loss 1.6251 (1.3444)	grad_norm 5.5776 (1.6662)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:04:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:09:04 lr 0.000013	 wd 0.0000	time 0.3385 (0.3622)	loss 1.3468 (1.3438)	grad_norm 1.3126 (1.6669)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:04:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:08:26 lr 0.000013	 wd 0.0000	time 0.3390 (0.3613)	loss 1.4340 (1.3409)	grad_norm 1.4953 (1.6691)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:05:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:07:49 lr 0.000013	 wd 0.0000	time 0.3295 (0.3605)	loss 1.3837 (1.3382)	grad_norm 1.7769 (1.6712)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:05:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:07:12 lr 0.000013	 wd 0.0000	time 0.3456 (0.3599)	loss 1.1798 (1.3347)	grad_norm 2.4214 (1.6653)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:06:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:06:36 lr 0.000013	 wd 0.0000	time 0.3385 (0.3594)	loss 1.3367 (1.3365)	grad_norm 1.6860 (1.6652)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:07:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:05:59 lr 0.000013	 wd 0.0000	time 0.3341 (0.3589)	loss 1.2311 (1.3378)	grad_norm 2.3399 (1.6667)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:07:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:05:23 lr 0.000013	 wd 0.0000	time 0.3408 (0.3586)	loss 1.5337 (1.3386)	grad_norm 1.6744 (1.6738)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:08:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:04:47 lr 0.000012	 wd 0.0000	time 0.3438 (0.3582)	loss 1.5343 (1.3381)	grad_norm 2.1175 (1.6776)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:08:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:04:11 lr 0.000012	 wd 0.0000	time 0.3405 (0.3579)	loss 1.3043 (1.3371)	grad_norm 1.4320 (1.6795)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:09:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:03:35 lr 0.000012	 wd 0.0000	time 0.3260 (0.3576)	loss 1.6137 (1.3378)	grad_norm 1.4515 (1.6838)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:10:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:02:59 lr 0.000012	 wd 0.0000	time 0.3250 (0.3573)	loss 1.4412 (1.3371)	grad_norm 1.6828 (1.6785)	loss_scale 16384.0000 (8560.4558)	mem 7516MB
[2024-07-02 20:10:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:02:23 lr 0.000012	 wd 0.0000	time 0.3394 (0.3571)	loss 1.3986 (1.3377)	grad_norm 1.4028 (nan)	loss_scale 8192.0000 (8620.9005)	mem 7516MB
[2024-07-02 20:11:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:47 lr 0.000012	 wd 0.0000	time 0.3450 (0.3569)	loss 1.2892 (1.3389)	grad_norm 1.5502 (nan)	loss_scale 8192.0000 (8601.4139)	mem 7516MB
[2024-07-02 20:11:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:01:12 lr 0.000012	 wd 0.0000	time 0.3390 (0.3567)	loss 1.2969 (1.3392)	grad_norm 1.5733 (nan)	loss_scale 8192.0000 (8583.6210)	mem 7516MB
[2024-07-02 20:12:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:36 lr 0.000012	 wd 0.0000	time 0.3314 (0.3565)	loss 1.2391 (1.3396)	grad_norm 1.4430 (nan)	loss_scale 8192.0000 (8567.3103)	mem 7516MB
[2024-07-02 20:12:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000012	 wd 0.0000	time 0.3331 (0.3562)	loss 1.4600 (1.3403)	grad_norm 1.6050 (nan)	loss_scale 8192.0000 (8552.3039)	mem 7516MB
[2024-07-02 20:13:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 20 training takes 0:14:53
[2024-07-02 20:13:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.576 (11.576)	Loss 0.4131 (0.4131)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 7516MB
[2024-07-02 20:13:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.578 Acc@5 97.460
[2024-07-02 20:13:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-02 20:13:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.59%
[2024-07-02 20:13:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][0/2502]	eta 7:18:28 lr 0.000012	 wd 0.0000	time 10.5148 (10.5148)	loss 1.5410 (1.5410)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:14:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:18:17 lr 0.000012	 wd 0.0000	time 0.3190 (0.4568)	loss 1.5738 (1.3713)	grad_norm 1.3819 (1.6501)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:14:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:15:32 lr 0.000012	 wd 0.0000	time 0.3374 (0.4051)	loss 0.9694 (1.3417)	grad_norm 2.6652 (1.7110)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:15:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:14:14 lr 0.000012	 wd 0.0000	time 0.3404 (0.3879)	loss 1.3885 (1.3340)	grad_norm 1.5515 (1.7143)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:15:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:13:16 lr 0.000011	 wd 0.0000	time 0.3356 (0.3787)	loss 1.3329 (1.3369)	grad_norm 1.6310 (1.6808)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:16:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:12:26 lr 0.000011	 wd 0.0000	time 0.3272 (0.3731)	loss 1.2990 (1.3357)	grad_norm 1.7769 (1.6571)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:17:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:11:42 lr 0.000011	 wd 0.0000	time 0.3313 (0.3695)	loss 1.2117 (1.3373)	grad_norm 1.5078 (1.6503)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:17:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:11:01 lr 0.000011	 wd 0.0000	time 0.3398 (0.3670)	loss 1.2495 (1.3319)	grad_norm 1.5238 (1.6552)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:18:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:10:21 lr 0.000011	 wd 0.0000	time 0.3107 (0.3651)	loss 1.2497 (1.3302)	grad_norm 1.4031 (1.6551)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:18:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:09:42 lr 0.000011	 wd 0.0000	time 0.3305 (0.3637)	loss 1.5398 (1.3293)	grad_norm 1.8869 (1.6685)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:19:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:09:04 lr 0.000011	 wd 0.0000	time 0.3277 (0.3625)	loss 1.0745 (1.3283)	grad_norm 1.3996 (1.6675)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:20:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:08:27 lr 0.000011	 wd 0.0000	time 0.3344 (0.3617)	loss 1.4079 (1.3283)	grad_norm 1.4793 (1.6669)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:20:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:07:49 lr 0.000011	 wd 0.0000	time 0.3401 (0.3609)	loss 1.3638 (1.3284)	grad_norm 1.4638 (1.6659)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:21:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:07:13 lr 0.000011	 wd 0.0000	time 0.3396 (0.3603)	loss 1.5084 (1.3276)	grad_norm 1.5287 (1.6740)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:21:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:06:36 lr 0.000011	 wd 0.0000	time 0.3324 (0.3597)	loss 1.3092 (1.3282)	grad_norm 1.5712 (1.6747)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:22:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:05:59 lr 0.000010	 wd 0.0000	time 0.3341 (0.3592)	loss 1.6477 (1.3278)	grad_norm 1.5443 (1.6743)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:23:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:05:23 lr 0.000010	 wd 0.0000	time 0.3338 (0.3589)	loss 1.2503 (1.3272)	grad_norm 1.5210 (1.6746)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:23:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:04:47 lr 0.000010	 wd 0.0000	time 0.3425 (0.3586)	loss 1.4744 (1.3279)	grad_norm 1.6695 (1.6736)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:24:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:04:11 lr 0.000010	 wd 0.0000	time 0.3396 (0.3583)	loss 1.0692 (1.3288)	grad_norm 1.5220 (1.6689)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 20:24:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:03:35 lr 0.000010	 wd 0.0000	time 0.3356 (0.3580)	loss 1.0575 (1.3271)	grad_norm 1.9727 (nan)	loss_scale 4096.0000 (8006.6996)	mem 7516MB
[2024-07-02 20:25:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:02:59 lr 0.000010	 wd 0.0000	time 0.3392 (0.3577)	loss 1.3855 (1.3268)	grad_norm 3.6972 (nan)	loss_scale 4096.0000 (7811.2624)	mem 7516MB
[2024-07-02 20:25:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:02:23 lr 0.000010	 wd 0.0000	time 0.3405 (0.3574)	loss 1.1660 (1.3284)	grad_norm 1.6752 (nan)	loss_scale 4096.0000 (7634.4293)	mem 7516MB
[2024-07-02 20:26:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:47 lr 0.000010	 wd 0.0000	time 0.3390 (0.3571)	loss 1.5832 (1.3267)	grad_norm 5.1538 (nan)	loss_scale 4096.0000 (7473.6647)	mem 7516MB
[2024-07-02 20:27:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:01:12 lr 0.000010	 wd 0.0000	time 0.3323 (0.3569)	loss 1.5798 (1.3259)	grad_norm 1.7049 (nan)	loss_scale 4096.0000 (7326.8735)	mem 7516MB
[2024-07-02 20:27:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:36 lr 0.000010	 wd 0.0000	time 0.3378 (0.3567)	loss 1.3365 (1.3272)	grad_norm 1.3999 (nan)	loss_scale 4096.0000 (7192.3099)	mem 7516MB
[2024-07-02 20:28:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.3466 (0.3564)	loss 1.4062 (1.3266)	grad_norm 1.4499 (nan)	loss_scale 4096.0000 (7068.5070)	mem 7516MB
[2024-07-02 20:28:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 21 training takes 0:14:56
[2024-07-02 20:28:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.462 (11.462)	Loss 0.4084 (0.4084)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 20:28:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.600 Acc@5 97.468
[2024-07-02 20:28:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-02 20:28:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.60%
[2024-07-02 20:28:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saving......
[2024-07-02 20:28:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saved !!!
[2024-07-02 20:28:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][0/2502]	eta 7:26:53 lr 0.000010	 wd 0.0000	time 10.7169 (10.7169)	loss 1.2251 (1.2251)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:29:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:18:12 lr 0.000010	 wd 0.0000	time 0.3298 (0.4549)	loss 1.3480 (1.3498)	grad_norm 1.6300 (1.6281)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:30:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:15:29 lr 0.000009	 wd 0.0000	time 0.3388 (0.4037)	loss 1.0095 (1.3360)	grad_norm 1.4970 (1.6040)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:30:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:14:11 lr 0.000009	 wd 0.0000	time 0.3343 (0.3866)	loss 1.4646 (1.3399)	grad_norm 1.9744 (1.6022)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:31:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:13:14 lr 0.000009	 wd 0.0000	time 0.3339 (0.3780)	loss 1.3044 (1.3433)	grad_norm 1.6531 (1.6272)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:31:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:12:26 lr 0.000009	 wd 0.0000	time 0.3265 (0.3729)	loss 1.0141 (1.3426)	grad_norm 1.4063 (1.6418)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:32:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:11:42 lr 0.000009	 wd 0.0000	time 0.3345 (0.3695)	loss 1.4220 (1.3426)	grad_norm 1.7441 (1.6503)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:33:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:11:01 lr 0.000009	 wd 0.0000	time 0.3456 (0.3669)	loss 0.8879 (1.3362)	grad_norm 1.6195 (1.6505)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:33:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:10:21 lr 0.000009	 wd 0.0000	time 0.3326 (0.3650)	loss 1.2526 (1.3315)	grad_norm 1.6688 (1.6424)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:34:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:09:42 lr 0.000009	 wd 0.0000	time 0.3283 (0.3635)	loss 1.3128 (1.3293)	grad_norm 1.5277 (1.6442)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:34:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:09:04 lr 0.000009	 wd 0.0000	time 0.3460 (0.3624)	loss 1.4747 (1.3313)	grad_norm 1.7295 (1.6456)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:35:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:08:26 lr 0.000009	 wd 0.0000	time 0.3443 (0.3614)	loss 1.3424 (1.3296)	grad_norm 5.6531 (1.6553)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:36:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:07:49 lr 0.000009	 wd 0.0000	time 0.3459 (0.3607)	loss 1.3043 (1.3284)	grad_norm 1.4603 (1.6716)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:36:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:07:12 lr 0.000009	 wd 0.0000	time 0.3230 (0.3600)	loss 1.0192 (1.3293)	grad_norm 1.5241 (1.6684)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:37:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:06:36 lr 0.000008	 wd 0.0000	time 0.3270 (0.3595)	loss 1.4998 (1.3310)	grad_norm 1.7398 (1.6731)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:37:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:05:59 lr 0.000008	 wd 0.0000	time 0.3432 (0.3591)	loss 1.1561 (1.3314)	grad_norm 1.7140 (1.6710)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:38:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:05:23 lr 0.000008	 wd 0.0000	time 0.3390 (0.3586)	loss 1.5097 (1.3313)	grad_norm 1.5075 (1.6697)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:38:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:04:47 lr 0.000008	 wd 0.0000	time 0.3423 (0.3583)	loss 1.2917 (1.3305)	grad_norm 1.8456 (1.6707)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:39:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:04:11 lr 0.000008	 wd 0.0000	time 0.3335 (0.3579)	loss 1.5691 (1.3303)	grad_norm 1.6575 (1.6668)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:40:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:03:35 lr 0.000008	 wd 0.0000	time 0.3350 (0.3576)	loss 1.4969 (1.3296)	grad_norm 1.7590 (1.6716)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:40:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:02:59 lr 0.000008	 wd 0.0000	time 0.3110 (0.3573)	loss 1.4328 (1.3286)	grad_norm 1.5365 (1.6742)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:41:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:02:23 lr 0.000008	 wd 0.0000	time 0.3252 (0.3571)	loss 1.4765 (1.3291)	grad_norm 2.0794 (1.6782)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:41:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:47 lr 0.000008	 wd 0.0000	time 0.3297 (0.3568)	loss 1.4525 (1.3280)	grad_norm 1.6838 (1.6742)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:42:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:01:12 lr 0.000008	 wd 0.0000	time 0.3335 (0.3566)	loss 1.5797 (1.3281)	grad_norm 1.6210 (1.6715)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:43:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:36 lr 0.000008	 wd 0.0000	time 0.3341 (0.3564)	loss 1.0646 (1.3276)	grad_norm 1.6263 (1.6686)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:43:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.3366 (0.3561)	loss 1.0250 (1.3268)	grad_norm 1.6328 (1.6676)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:43:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 22 training takes 0:14:55
[2024-07-02 20:43:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.472 (11.472)	Loss 0.4087 (0.4087)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 20:44:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.618 Acc@5 97.470
[2024-07-02 20:44:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-02 20:44:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.62%
[2024-07-02 20:44:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saving......
[2024-07-02 20:44:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saved !!!
[2024-07-02 20:44:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][0/2502]	eta 7:15:30 lr 0.000008	 wd 0.0000	time 10.4438 (10.4438)	loss 1.0808 (1.0808)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:44:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:18:04 lr 0.000008	 wd 0.0000	time 0.3304 (0.4516)	loss 1.4467 (1.3683)	grad_norm 1.4867 (1.7291)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:45:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:15:25 lr 0.000007	 wd 0.0000	time 0.3182 (0.4023)	loss 1.5184 (1.3456)	grad_norm 3.5943 (1.7036)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:46:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:14:09 lr 0.000007	 wd 0.0000	time 0.3174 (0.3856)	loss 1.3337 (1.3406)	grad_norm 1.6201 (1.6870)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:46:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:13:13 lr 0.000007	 wd 0.0000	time 0.3349 (0.3775)	loss 1.6689 (1.3356)	grad_norm 1.7094 (1.6923)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:47:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:12:26 lr 0.000007	 wd 0.0000	time 0.3329 (0.3727)	loss 1.5567 (1.3395)	grad_norm 1.7266 (1.6793)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:47:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:11:42 lr 0.000007	 wd 0.0000	time 0.3368 (0.3692)	loss 1.1889 (1.3394)	grad_norm 1.5218 (1.6858)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:48:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:11:01 lr 0.000007	 wd 0.0000	time 0.3405 (0.3668)	loss 1.4715 (1.3360)	grad_norm 1.5717 (1.6984)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:49:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:10:21 lr 0.000007	 wd 0.0000	time 0.3410 (0.3651)	loss 1.6428 (1.3333)	grad_norm 1.3298 (1.6864)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 20:49:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:09:42 lr 0.000007	 wd 0.0000	time 0.3343 (0.3637)	loss 1.6314 (1.3302)	grad_norm 1.9307 (1.6844)	loss_scale 8192.0000 (4505.1454)	mem 7516MB
[2024-07-02 20:50:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:09:04 lr 0.000007	 wd 0.0000	time 0.3370 (0.3625)	loss 1.0689 (1.3296)	grad_norm 1.6731 (1.6770)	loss_scale 8192.0000 (4873.4625)	mem 7516MB
[2024-07-02 20:50:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:08:27 lr 0.000007	 wd 0.0000	time 0.3219 (0.3616)	loss 0.8241 (1.3245)	grad_norm 1.5245 (1.6722)	loss_scale 8192.0000 (5174.8738)	mem 7516MB
[2024-07-02 20:51:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:07:49 lr 0.000007	 wd 0.0000	time 0.3337 (0.3609)	loss 1.5397 (1.3261)	grad_norm 1.6534 (1.6758)	loss_scale 8192.0000 (5426.0916)	mem 7516MB
[2024-07-02 20:52:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:07:13 lr 0.000007	 wd 0.0000	time 0.3344 (0.3603)	loss 1.5313 (1.3275)	grad_norm 1.3991 (1.6798)	loss_scale 8192.0000 (5638.6902)	mem 7516MB
[2024-07-02 20:52:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:06:36 lr 0.000007	 wd 0.0000	time 0.3416 (0.3597)	loss 1.3226 (1.3267)	grad_norm 2.7410 (1.6811)	loss_scale 8192.0000 (5820.9393)	mem 7516MB
[2024-07-02 20:53:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:05:59 lr 0.000006	 wd 0.0000	time 0.3350 (0.3592)	loss 1.2213 (1.3282)	grad_norm 1.7090 (1.6791)	loss_scale 8192.0000 (5978.9047)	mem 7516MB
[2024-07-02 20:53:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:05:23 lr 0.000006	 wd 0.0000	time 0.3340 (0.3588)	loss 1.1896 (1.3282)	grad_norm 1.5413 (1.6802)	loss_scale 8192.0000 (6117.1368)	mem 7516MB
[2024-07-02 20:54:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:04:47 lr 0.000006	 wd 0.0000	time 0.3425 (0.3585)	loss 1.3434 (1.3285)	grad_norm 1.4961 (1.6836)	loss_scale 8192.0000 (6239.1158)	mem 7516MB
[2024-07-02 20:54:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:04:11 lr 0.000006	 wd 0.0000	time 0.3275 (0.3581)	loss 1.3498 (1.3279)	grad_norm 1.4871 (1.6871)	loss_scale 8192.0000 (6347.5491)	mem 7516MB
[2024-07-02 20:55:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:03:35 lr 0.000006	 wd 0.0000	time 0.3282 (0.3577)	loss 1.2017 (1.3301)	grad_norm 1.9427 (1.6894)	loss_scale 8192.0000 (6444.5744)	mem 7516MB
[2024-07-02 20:56:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:02:59 lr 0.000006	 wd 0.0000	time 0.3392 (0.3574)	loss 1.3517 (1.3289)	grad_norm 2.0206 (1.6894)	loss_scale 8192.0000 (6531.9020)	mem 7516MB
[2024-07-02 20:56:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:02:23 lr 0.000006	 wd 0.0000	time 0.3425 (0.3572)	loss 1.6439 (1.3291)	grad_norm 1.5168 (1.6909)	loss_scale 8192.0000 (6610.9167)	mem 7516MB
[2024-07-02 20:57:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:47 lr 0.000006	 wd 0.0000	time 0.3476 (0.3571)	loss 1.4842 (1.3265)	grad_norm 1.5182 (1.6928)	loss_scale 8192.0000 (6682.7515)	mem 7516MB
[2024-07-02 20:57:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:01:12 lr 0.000006	 wd 0.0000	time 0.3454 (0.3569)	loss 1.4603 (1.3261)	grad_norm 1.4919 (1.6963)	loss_scale 8192.0000 (6748.3425)	mem 7516MB
[2024-07-02 20:58:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:36 lr 0.000006	 wd 0.0000	time 0.3379 (0.3568)	loss 1.5554 (1.3268)	grad_norm 1.4449 (1.6942)	loss_scale 8192.0000 (6808.4698)	mem 7516MB
[2024-07-02 20:59:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000006	 wd 0.0000	time 0.3309 (0.3565)	loss 1.4102 (1.3276)	grad_norm 1.9824 (1.6932)	loss_scale 8192.0000 (6863.7889)	mem 7516MB
[2024-07-02 20:59:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 23 training takes 0:14:57
[2024-07-02 20:59:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.081 (11.081)	Loss 0.4092 (0.4092)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 20:59:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.654 Acc@5 97.454
[2024-07-02 20:59:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 20:59:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.65%
[2024-07-02 20:59:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saving......
[2024-07-02 20:59:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saved !!!
[2024-07-02 20:59:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][0/2502]	eta 7:18:52 lr 0.000006	 wd 0.0000	time 10.5247 (10.5247)	loss 1.5343 (1.5343)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:00:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:18:08 lr 0.000006	 wd 0.0000	time 0.3425 (0.4533)	loss 1.2078 (1.3597)	grad_norm 1.6301 (1.6495)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:00:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:15:27 lr 0.000006	 wd 0.0000	time 0.3376 (0.4029)	loss 1.5984 (1.3486)	grad_norm 1.6588 (1.6711)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:01:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:14:10 lr 0.000006	 wd 0.0000	time 0.3466 (0.3861)	loss 1.5763 (1.3386)	grad_norm 1.6502 (1.6685)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:02:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:13:14 lr 0.000005	 wd 0.0000	time 0.3450 (0.3778)	loss 1.4095 (1.3326)	grad_norm 1.5252 (1.6768)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:02:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:12:26 lr 0.000005	 wd 0.0000	time 0.3357 (0.3729)	loss 1.5059 (1.3346)	grad_norm 1.7162 (1.6759)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:03:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:11:42 lr 0.000005	 wd 0.0000	time 0.3297 (0.3693)	loss 1.3319 (1.3302)	grad_norm 1.5061 (1.6706)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:03:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:11:01 lr 0.000005	 wd 0.0000	time 0.3189 (0.3670)	loss 1.2934 (1.3321)	grad_norm 1.5845 (1.6933)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:04:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:10:21 lr 0.000005	 wd 0.0000	time 0.3341 (0.3652)	loss 1.3745 (1.3330)	grad_norm 2.3521 (1.6913)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:05:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:09:42 lr 0.000005	 wd 0.0000	time 0.3482 (0.3638)	loss 1.4135 (1.3307)	grad_norm 1.7924 (1.6814)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:05:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:09:04 lr 0.000005	 wd 0.0000	time 0.3386 (0.3627)	loss 1.2802 (1.3310)	grad_norm 1.5634 (1.6891)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:06:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:08:27 lr 0.000005	 wd 0.0000	time 0.3299 (0.3618)	loss 1.4659 (1.3292)	grad_norm 2.0019 (1.6916)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:06:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:07:50 lr 0.000005	 wd 0.0000	time 0.3393 (0.3611)	loss 1.1375 (1.3278)	grad_norm 1.6314 (1.6913)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:07:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:07:13 lr 0.000005	 wd 0.0000	time 0.3346 (0.3605)	loss 1.2469 (1.3283)	grad_norm 1.9611 (1.6906)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:08:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:06:36 lr 0.000005	 wd 0.0000	time 0.3391 (0.3599)	loss 1.2195 (1.3269)	grad_norm 1.6944 (1.6836)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:08:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:06:00 lr 0.000005	 wd 0.0000	time 0.3298 (0.3594)	loss 1.0001 (1.3259)	grad_norm 2.4408 (1.6817)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:09:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:05:23 lr 0.000005	 wd 0.0000	time 0.3372 (0.3589)	loss 1.3788 (1.3253)	grad_norm 1.6953 (1.6817)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:09:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:04:47 lr 0.000005	 wd 0.0000	time 0.3369 (0.3585)	loss 1.7049 (1.3275)	grad_norm 1.5447 (1.6874)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:10:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:04:11 lr 0.000005	 wd 0.0000	time 0.3363 (0.3582)	loss 1.1573 (1.3268)	grad_norm 1.6073 (1.6906)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:10:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:03:35 lr 0.000005	 wd 0.0000	time 0.3309 (0.3579)	loss 1.4535 (1.3281)	grad_norm 1.4890 (1.6896)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:11:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:02:59 lr 0.000004	 wd 0.0000	time 0.3361 (0.3577)	loss 1.5187 (1.3280)	grad_norm 1.5622 (1.6854)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:12:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:02:23 lr 0.000004	 wd 0.0000	time 0.3381 (0.3575)	loss 1.4767 (1.3265)	grad_norm 3.3090 (1.6850)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:12:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:47 lr 0.000004	 wd 0.0000	time 0.3210 (0.3572)	loss 1.2618 (1.3261)	grad_norm 1.5723 (1.6833)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:13:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:01:12 lr 0.000004	 wd 0.0000	time 0.3389 (0.3570)	loss 1.6601 (1.3256)	grad_norm 1.4613 (1.6853)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:13:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:36 lr 0.000004	 wd 0.0000	time 0.3337 (0.3568)	loss 1.5335 (1.3256)	grad_norm 1.3534 (1.6833)	loss_scale 16384.0000 (8505.8959)	mem 7516MB
[2024-07-02 21:14:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000004	 wd 0.0000	time 0.3396 (0.3565)	loss 1.2185 (1.3261)	grad_norm 1.7724 (1.6801)	loss_scale 16384.0000 (8820.8940)	mem 7516MB
[2024-07-02 21:14:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 24 training takes 0:14:57
[2024-07-02 21:14:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.178 (11.178)	Loss 0.4109 (0.4109)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 7516MB
[2024-07-02 21:15:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.642 Acc@5 97.484
[2024-07-02 21:15:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-02 21:15:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.65%
[2024-07-02 21:15:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][0/2502]	eta 7:42:08 lr 0.000004	 wd 0.0000	time 11.0826 (11.0826)	loss 1.0659 (1.0659)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:15:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:18:26 lr 0.000004	 wd 0.0000	time 0.3331 (0.4606)	loss 1.3127 (1.2979)	grad_norm 1.4251 (1.6686)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:16:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:15:36 lr 0.000004	 wd 0.0000	time 0.3311 (0.4069)	loss 1.4098 (1.3180)	grad_norm 1.4279 (1.6920)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:17:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:14:15 lr 0.000004	 wd 0.0000	time 0.3405 (0.3887)	loss 1.0140 (1.3122)	grad_norm 1.3604 (1.7060)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:17:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:13:17 lr 0.000004	 wd 0.0000	time 0.3419 (0.3795)	loss 1.2385 (1.3251)	grad_norm 1.4862 (1.7310)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:18:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:12:28 lr 0.000004	 wd 0.0000	time 0.3372 (0.3740)	loss 1.3875 (1.3259)	grad_norm 1.4436 (1.7223)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:18:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:11:44 lr 0.000004	 wd 0.0000	time 0.3335 (0.3705)	loss 1.1486 (1.3281)	grad_norm 1.6326 (1.7150)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:19:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:11:03 lr 0.000004	 wd 0.0000	time 0.3421 (0.3681)	loss 1.2165 (1.3279)	grad_norm 1.5541 (1.7192)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:19:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:10:23 lr 0.000004	 wd 0.0000	time 0.3417 (0.3660)	loss 1.0744 (1.3282)	grad_norm 1.6813 (1.7292)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:20:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:09:43 lr 0.000004	 wd 0.0000	time 0.3341 (0.3644)	loss 1.4011 (1.3301)	grad_norm 1.8978 (1.7256)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:21:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:09:05 lr 0.000004	 wd 0.0000	time 0.3386 (0.3632)	loss 1.3098 (1.3310)	grad_norm 1.6956 (1.7181)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:21:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:08:27 lr 0.000004	 wd 0.0000	time 0.3395 (0.3623)	loss 1.3783 (1.3288)	grad_norm 1.7082 (1.7176)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:22:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:07:50 lr 0.000004	 wd 0.0000	time 0.3327 (0.3614)	loss 1.2988 (1.3301)	grad_norm 1.5064 (1.7176)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:22:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:07:13 lr 0.000003	 wd 0.0000	time 0.3357 (0.3608)	loss 1.4974 (1.3304)	grad_norm 1.6218 (1.7081)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:23:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:06:37 lr 0.000003	 wd 0.0000	time 0.3279 (0.3603)	loss 1.1763 (1.3314)	grad_norm 1.6268 (1.7054)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:24:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:06:00 lr 0.000003	 wd 0.0000	time 0.3223 (0.3598)	loss 1.2281 (1.3305)	grad_norm 1.6523 (1.7116)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:24:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:05:24 lr 0.000003	 wd 0.0000	time 0.3275 (0.3593)	loss 1.4930 (1.3306)	grad_norm 1.7082 (1.7047)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:25:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:04:47 lr 0.000003	 wd 0.0000	time 0.3368 (0.3588)	loss 1.2720 (1.3306)	grad_norm 1.6269 (1.6996)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:25:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:04:11 lr 0.000003	 wd 0.0000	time 0.3330 (0.3584)	loss 1.3992 (1.3297)	grad_norm 2.4628 (1.6978)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:26:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:03:35 lr 0.000003	 wd 0.0000	time 0.3231 (0.3581)	loss 1.5986 (1.3299)	grad_norm 1.7839 (1.7026)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:26:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:02:59 lr 0.000003	 wd 0.0000	time 0.3246 (0.3578)	loss 1.2715 (1.3294)	grad_norm 3.0000 (1.7061)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:27:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:02:23 lr 0.000003	 wd 0.0000	time 0.3431 (0.3575)	loss 0.8878 (1.3296)	grad_norm 1.6976 (1.7121)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:28:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:47 lr 0.000003	 wd 0.0000	time 0.3195 (0.3573)	loss 1.3924 (1.3284)	grad_norm 1.4781 (1.7122)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:28:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:01:12 lr 0.000003	 wd 0.0000	time 0.3205 (0.3571)	loss 1.4230 (1.3270)	grad_norm 1.6199 (1.7176)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:29:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:36 lr 0.000003	 wd 0.0000	time 0.3415 (0.3569)	loss 1.4191 (1.3283)	grad_norm 1.9626 (1.7173)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:29:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.3306 (0.3567)	loss 1.4856 (1.3285)	grad_norm 1.6597 (1.7136)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:30:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 25 training takes 0:14:57
[2024-07-02 21:30:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.311 (11.311)	Loss 0.4099 (0.4099)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 21:30:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.662 Acc@5 97.486
[2024-07-02 21:30:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 21:30:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.66%
[2024-07-02 21:30:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saving......
[2024-07-02 21:30:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saved !!!
[2024-07-02 21:30:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][0/2502]	eta 7:24:48 lr 0.000003	 wd 0.0000	time 10.6668 (10.6668)	loss 1.1787 (1.1787)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:31:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:18:10 lr 0.000003	 wd 0.0000	time 0.3318 (0.4541)	loss 1.4823 (1.3201)	grad_norm 1.5096 (1.6576)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:31:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:15:28 lr 0.000003	 wd 0.0000	time 0.3419 (0.4035)	loss 1.4255 (1.3477)	grad_norm 1.8827 (1.6638)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:32:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:14:11 lr 0.000003	 wd 0.0000	time 0.3344 (0.3866)	loss 1.3109 (1.3400)	grad_norm 1.4926 (1.6900)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:33:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:13:14 lr 0.000003	 wd 0.0000	time 0.3322 (0.3781)	loss 1.6600 (1.3420)	grad_norm 1.4895 (1.7164)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:33:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:12:26 lr 0.000003	 wd 0.0000	time 0.3458 (0.3730)	loss 1.6419 (1.3488)	grad_norm 1.4397 (1.7129)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:34:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:11:43 lr 0.000003	 wd 0.0000	time 0.3326 (0.3696)	loss 1.2730 (1.3440)	grad_norm 1.5951 (1.7334)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:34:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:11:01 lr 0.000003	 wd 0.0000	time 0.3439 (0.3674)	loss 1.4137 (1.3375)	grad_norm 2.5669 (1.7392)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:35:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:10:22 lr 0.000002	 wd 0.0000	time 0.3381 (0.3656)	loss 1.3689 (1.3341)	grad_norm 1.4824 (1.7319)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:36:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:09:43 lr 0.000002	 wd 0.0000	time 0.3377 (0.3641)	loss 1.3411 (1.3359)	grad_norm 1.3834 (1.7325)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:36:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:09:05 lr 0.000002	 wd 0.0000	time 0.3450 (0.3630)	loss 1.4674 (1.3357)	grad_norm 1.4826 (1.7217)	loss_scale 16384.0000 (16384.0000)	mem 7516MB
[2024-07-02 21:37:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:08:27 lr 0.000002	 wd 0.0000	time 0.3378 (0.3620)	loss 1.4589 (1.3375)	grad_norm 1.6377 (nan)	loss_scale 8192.0000 (15833.4024)	mem 7516MB
[2024-07-02 21:37:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:07:50 lr 0.000002	 wd 0.0000	time 0.3376 (0.3613)	loss 1.0489 (1.3378)	grad_norm 1.6384 (nan)	loss_scale 8192.0000 (15197.1490)	mem 7516MB
[2024-07-02 21:38:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:07:13 lr 0.000002	 wd 0.0000	time 0.3307 (0.3607)	loss 0.9427 (1.3353)	grad_norm 1.7150 (nan)	loss_scale 8192.0000 (14658.7056)	mem 7516MB
[2024-07-02 21:38:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:06:36 lr 0.000002	 wd 0.0000	time 0.3163 (0.3602)	loss 1.7489 (1.3352)	grad_norm 1.5836 (nan)	loss_scale 8192.0000 (14197.1278)	mem 7516MB
[2024-07-02 21:39:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:06:00 lr 0.000002	 wd 0.0000	time 0.3383 (0.3597)	loss 1.4956 (1.3339)	grad_norm 1.5838 (nan)	loss_scale 8192.0000 (13797.0526)	mem 7516MB
[2024-07-02 21:40:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:05:24 lr 0.000002	 wd 0.0000	time 0.3317 (0.3593)	loss 1.4334 (1.3327)	grad_norm 1.4952 (nan)	loss_scale 8192.0000 (13446.9557)	mem 7516MB
[2024-07-02 21:40:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:04:47 lr 0.000002	 wd 0.0000	time 0.3327 (0.3588)	loss 1.3484 (1.3330)	grad_norm 1.6888 (nan)	loss_scale 8192.0000 (13138.0223)	mem 7516MB
[2024-07-02 21:41:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:04:11 lr 0.000002	 wd 0.0000	time 0.3402 (0.3585)	loss 1.4376 (1.3345)	grad_norm 1.8350 (nan)	loss_scale 8192.0000 (12863.3959)	mem 7516MB
[2024-07-02 21:41:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:03:35 lr 0.000002	 wd 0.0000	time 0.3361 (0.3582)	loss 1.0676 (1.3327)	grad_norm 1.7545 (nan)	loss_scale 8192.0000 (12617.6623)	mem 7516MB
[2024-07-02 21:42:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:02:59 lr 0.000002	 wd 0.0000	time 0.3338 (0.3580)	loss 1.1831 (1.3326)	grad_norm 1.4500 (nan)	loss_scale 8192.0000 (12396.4898)	mem 7516MB
[2024-07-02 21:43:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:02:23 lr 0.000002	 wd 0.0000	time 0.3340 (0.3578)	loss 0.9901 (1.3311)	grad_norm 1.9994 (nan)	loss_scale 8192.0000 (12196.3713)	mem 7516MB
[2024-07-02 21:43:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:47 lr 0.000002	 wd 0.0000	time 0.3308 (0.3575)	loss 0.9116 (1.3308)	grad_norm 1.8714 (nan)	loss_scale 8192.0000 (12014.4371)	mem 7516MB
[2024-07-02 21:44:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:01:12 lr 0.000002	 wd 0.0000	time 0.3395 (0.3573)	loss 1.0730 (1.3298)	grad_norm 1.7348 (nan)	loss_scale 8192.0000 (11848.3164)	mem 7516MB
[2024-07-02 21:44:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:36 lr 0.000002	 wd 0.0000	time 0.3488 (0.3571)	loss 1.1053 (1.3294)	grad_norm 1.7336 (nan)	loss_scale 8192.0000 (11696.0333)	mem 7516MB
[2024-07-02 21:45:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.3324 (0.3568)	loss 1.0608 (1.3277)	grad_norm 1.5641 (nan)	loss_scale 8192.0000 (11555.9280)	mem 7516MB
[2024-07-02 21:45:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 26 training takes 0:14:59
[2024-07-02 21:45:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.338 (11.338)	Loss 0.4102 (0.4102)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 21:46:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.684 Acc@5 97.464
[2024-07-02 21:46:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 21:46:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.68%
[2024-07-02 21:46:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saving......
[2024-07-02 21:46:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saved !!!
[2024-07-02 21:46:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][0/2502]	eta 6:57:42 lr 0.000002	 wd 0.0000	time 10.0171 (10.0171)	loss 0.9256 (0.9256)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:46:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:17:57 lr 0.000002	 wd 0.0000	time 0.3337 (0.4484)	loss 1.4350 (1.3441)	grad_norm 1.5004 (1.6924)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:47:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:15:22 lr 0.000002	 wd 0.0000	time 0.3400 (0.4008)	loss 1.4840 (1.3349)	grad_norm 1.7087 (1.6728)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 21:47:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:14:08 lr 0.000002	 wd 0.0000	time 0.3440 (0.3853)	loss 1.2633 (1.3273)	grad_norm nan (nan)	loss_scale 4096.0000 (8164.7841)	mem 7516MB
[2024-07-02 21:48:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:13:12 lr 0.000002	 wd 0.0000	time 0.3337 (0.3773)	loss 1.3320 (1.3268)	grad_norm 1.5667 (nan)	loss_scale 4096.0000 (7150.1247)	mem 7516MB
[2024-07-02 21:49:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:12:25 lr 0.000002	 wd 0.0000	time 0.3303 (0.3725)	loss 0.8312 (1.3200)	grad_norm 1.7982 (nan)	loss_scale 4096.0000 (6540.5190)	mem 7516MB
[2024-07-02 21:49:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:11:42 lr 0.000002	 wd 0.0000	time 0.3288 (0.3692)	loss 1.3574 (1.3206)	grad_norm 1.5171 (nan)	loss_scale 4096.0000 (6133.7770)	mem 7516MB
[2024-07-02 21:50:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:11:01 lr 0.000002	 wd 0.0000	time 0.3317 (0.3669)	loss 1.4263 (1.3254)	grad_norm 1.3953 (nan)	loss_scale 4096.0000 (5843.0813)	mem 7516MB
[2024-07-02 21:50:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:10:21 lr 0.000002	 wd 0.0000	time 0.3373 (0.3651)	loss 1.5403 (1.3283)	grad_norm 1.7654 (nan)	loss_scale 4096.0000 (5624.9688)	mem 7516MB
[2024-07-02 21:51:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:09:42 lr 0.000001	 wd 0.0000	time 0.3388 (0.3637)	loss 1.3753 (1.3331)	grad_norm 1.4452 (nan)	loss_scale 4096.0000 (5455.2719)	mem 7516MB
[2024-07-02 21:52:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:09:04 lr 0.000001	 wd 0.0000	time 0.3387 (0.3625)	loss 1.3734 (1.3322)	grad_norm 1.4613 (nan)	loss_scale 4096.0000 (5319.4805)	mem 7516MB
[2024-07-02 21:52:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:08:27 lr 0.000001	 wd 0.0000	time 0.3312 (0.3616)	loss 1.3600 (1.3331)	grad_norm 1.3301 (nan)	loss_scale 4096.0000 (5208.3560)	mem 7516MB
[2024-07-02 21:53:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:07:49 lr 0.000001	 wd 0.0000	time 0.3306 (0.3608)	loss 1.5270 (1.3334)	grad_norm 1.5487 (nan)	loss_scale 4096.0000 (5115.7369)	mem 7516MB
[2024-07-02 21:53:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:07:12 lr 0.000001	 wd 0.0000	time 0.3376 (0.3602)	loss 1.4297 (1.3315)	grad_norm 1.7799 (nan)	loss_scale 4096.0000 (5037.3559)	mem 7516MB
[2024-07-02 21:54:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:06:36 lr 0.000001	 wd 0.0000	time 0.3366 (0.3597)	loss 1.3312 (1.3326)	grad_norm 1.4278 (nan)	loss_scale 4096.0000 (4970.1642)	mem 7516MB
[2024-07-02 21:55:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:05:59 lr 0.000001	 wd 0.0000	time 0.3393 (0.3593)	loss 1.4778 (1.3324)	grad_norm 1.4578 (nan)	loss_scale 4096.0000 (4911.9254)	mem 7516MB
[2024-07-02 21:55:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:05:23 lr 0.000001	 wd 0.0000	time 0.3304 (0.3589)	loss 1.4613 (1.3306)	grad_norm 1.4888 (nan)	loss_scale 4096.0000 (4860.9619)	mem 7516MB
[2024-07-02 21:56:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:04:47 lr 0.000001	 wd 0.0000	time 0.3379 (0.3584)	loss 1.3564 (1.3286)	grad_norm 1.6692 (nan)	loss_scale 4096.0000 (4815.9906)	mem 7516MB
[2024-07-02 21:56:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:04:11 lr 0.000001	 wd 0.0000	time 0.3427 (0.3581)	loss 1.4131 (1.3293)	grad_norm 1.4071 (nan)	loss_scale 4096.0000 (4776.0133)	mem 7516MB
[2024-07-02 21:57:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:03:35 lr 0.000001	 wd 0.0000	time 0.3395 (0.3579)	loss 0.9359 (1.3303)	grad_norm 1.6468 (nan)	loss_scale 4096.0000 (4740.2420)	mem 7516MB
[2024-07-02 21:57:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:02:59 lr 0.000001	 wd 0.0000	time 0.3292 (0.3576)	loss 0.8633 (1.3289)	grad_norm 1.6074 (nan)	loss_scale 4096.0000 (4708.0460)	mem 7516MB
[2024-07-02 21:58:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:02:23 lr 0.000001	 wd 0.0000	time 0.3299 (0.3574)	loss 1.7233 (1.3277)	grad_norm 1.8475 (nan)	loss_scale 4096.0000 (4678.9148)	mem 7516MB
[2024-07-02 21:59:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:47 lr 0.000001	 wd 0.0000	time 0.3386 (0.3572)	loss 0.9895 (1.3287)	grad_norm 1.8118 (nan)	loss_scale 4096.0000 (4652.4307)	mem 7516MB
[2024-07-02 21:59:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:01:12 lr 0.000001	 wd 0.0000	time 0.3270 (0.3570)	loss 1.4786 (1.3289)	grad_norm 1.4393 (nan)	loss_scale 4096.0000 (4628.2486)	mem 7516MB
[2024-07-02 22:00:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:36 lr 0.000001	 wd 0.0000	time 0.3237 (0.3568)	loss 1.1726 (1.3286)	grad_norm 1.5963 (nan)	loss_scale 4096.0000 (4606.0808)	mem 7516MB
[2024-07-02 22:00:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.3358 (0.3566)	loss 1.4474 (1.3272)	grad_norm 1.4297 (nan)	loss_scale 4096.0000 (4585.6857)	mem 7516MB
[2024-07-02 22:00:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 27 training takes 0:14:57
[2024-07-02 22:01:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 10.219 (10.219)	Loss 0.4106 (0.4106)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 22:01:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.696 Acc@5 97.480
[2024-07-02 22:01:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 22:01:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.70%
[2024-07-02 22:01:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saving......
[2024-07-02 22:01:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_best.pth saved !!!
[2024-07-02 22:01:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][0/2502]	eta 7:21:44 lr 0.000001	 wd 0.0000	time 10.5932 (10.5932)	loss 1.2263 (1.2263)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 22:02:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:18:08 lr 0.000001	 wd 0.0000	time 0.3393 (0.4532)	loss 0.9672 (1.3081)	grad_norm 1.6090 (1.6527)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 22:02:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:15:26 lr 0.000001	 wd 0.0000	time 0.3285 (0.4025)	loss 1.0918 (1.3124)	grad_norm 2.0199 (1.6700)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 22:03:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:14:08 lr 0.000001	 wd 0.0000	time 0.3290 (0.3854)	loss 1.5495 (1.3275)	grad_norm 1.5222 (1.6622)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 22:03:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:13:11 lr 0.000001	 wd 0.0000	time 0.3222 (0.3765)	loss 1.4885 (1.3324)	grad_norm 1.7271 (1.6596)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 22:04:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:12:23 lr 0.000001	 wd 0.0000	time 0.3330 (0.3712)	loss 1.5632 (1.3322)	grad_norm 1.4581 (1.6798)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 22:05:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:11:39 lr 0.000001	 wd 0.0000	time 0.3368 (0.3678)	loss 1.3839 (1.3327)	grad_norm 1.5282 (1.6856)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 22:05:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:10:58 lr 0.000001	 wd 0.0000	time 0.3321 (0.3655)	loss 1.0227 (1.3352)	grad_norm 1.6873 (1.7219)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 22:06:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:10:19 lr 0.000001	 wd 0.0000	time 0.3409 (0.3638)	loss 1.5803 (1.3327)	grad_norm 1.5603 (1.7148)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 22:06:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:09:40 lr 0.000001	 wd 0.0000	time 0.3368 (0.3625)	loss 1.4756 (1.3328)	grad_norm 1.5388 (1.7079)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 22:07:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:09:03 lr 0.000001	 wd 0.0000	time 0.3440 (0.3616)	loss 1.4313 (1.3335)	grad_norm 1.5584 (1.7174)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 22:08:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:08:25 lr 0.000001	 wd 0.0000	time 0.3416 (0.3607)	loss 1.0341 (1.3322)	grad_norm 1.6723 (1.7204)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 22:08:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:07:48 lr 0.000001	 wd 0.0000	time 0.3352 (0.3601)	loss 1.1140 (1.3306)	grad_norm 1.7662 (1.7421)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 22:09:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:07:12 lr 0.000001	 wd 0.0000	time 0.3454 (0.3596)	loss 1.3877 (1.3277)	grad_norm 2.1311 (1.7479)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 22:09:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:06:35 lr 0.000001	 wd 0.0000	time 0.3236 (0.3591)	loss 0.9688 (1.3285)	grad_norm 1.4411 (1.7391)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 22:10:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:05:59 lr 0.000001	 wd 0.0000	time 0.3332 (0.3587)	loss 1.4685 (1.3255)	grad_norm 2.2478 (1.7374)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 22:11:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:05:23 lr 0.000001	 wd 0.0000	time 0.3332 (0.3583)	loss 1.2187 (1.3256)	grad_norm 1.7973 (1.7342)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 22:11:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:04:47 lr 0.000001	 wd 0.0000	time 0.3315 (0.3579)	loss 1.4517 (1.3266)	grad_norm 1.9421 (1.7360)	loss_scale 4096.0000 (4096.0000)	mem 7516MB
[2024-07-02 22:12:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:04:10 lr 0.000001	 wd 0.0000	time 0.3375 (0.3575)	loss 1.3373 (1.3257)	grad_norm 1.6160 (1.7326)	loss_scale 8192.0000 (4105.0972)	mem 7516MB
[2024-07-02 22:12:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:03:35 lr 0.000001	 wd 0.0000	time 0.3328 (0.3573)	loss 1.6001 (1.3246)	grad_norm 1.6021 (1.7279)	loss_scale 8192.0000 (4320.0842)	mem 7516MB
[2024-07-02 22:13:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:02:59 lr 0.000001	 wd 0.0000	time 0.3430 (0.3571)	loss 0.8658 (1.3240)	grad_norm 1.5247 (1.7353)	loss_scale 8192.0000 (4513.5832)	mem 7516MB
[2024-07-02 22:13:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:02:23 lr 0.000001	 wd 0.0000	time 0.3193 (0.3569)	loss 1.1572 (1.3243)	grad_norm 1.6220 (1.7310)	loss_scale 8192.0000 (4688.6625)	mem 7516MB
[2024-07-02 22:14:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:47 lr 0.000001	 wd 0.0000	time 0.3153 (0.3568)	loss 1.4688 (1.3233)	grad_norm 3.9494 (1.7322)	loss_scale 8192.0000 (4847.8328)	mem 7516MB
[2024-07-02 22:15:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:01:12 lr 0.000001	 wd 0.0000	time 0.3263 (0.3566)	loss 1.2057 (1.3236)	grad_norm 1.9468 (1.7341)	loss_scale 8192.0000 (4993.1682)	mem 7516MB
[2024-07-02 22:15:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:36 lr 0.000001	 wd 0.0000	time 0.3365 (0.3565)	loss 1.5456 (1.3225)	grad_norm 1.7192 (1.7337)	loss_scale 8192.0000 (5126.3973)	mem 7516MB
[2024-07-02 22:16:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.3393 (0.3563)	loss 1.1788 (1.3210)	grad_norm 1.6850 (1.7324)	loss_scale 8192.0000 (5248.9724)	mem 7516MB
[2024-07-02 22:16:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 28 training takes 0:14:57
[2024-07-02 22:16:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 11.487 (11.487)	Loss 0.4104 (0.4104)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 22:16:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.674 Acc@5 97.490
[2024-07-02 22:16:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 22:16:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.70%
[2024-07-02 22:17:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][0/2502]	eta 7:44:51 lr 0.000001	 wd 0.0000	time 11.1477 (11.1477)	loss 1.4531 (1.4531)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 22:17:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:18:28 lr 0.000001	 wd 0.0000	time 0.3216 (0.4613)	loss 1.4571 (1.2997)	grad_norm 1.5923 (1.6583)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 22:18:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:15:38 lr 0.000001	 wd 0.0000	time 0.3420 (0.4077)	loss 1.1665 (1.3168)	grad_norm 1.7233 (1.7442)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 22:18:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:14:18 lr 0.000001	 wd 0.0000	time 0.3358 (0.3897)	loss 1.4950 (1.3166)	grad_norm 1.4304 (1.7619)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 22:19:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:13:19 lr 0.000001	 wd 0.0000	time 0.3337 (0.3805)	loss 1.2149 (1.3216)	grad_norm 1.8887 (1.7699)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 22:20:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:12:30 lr 0.000001	 wd 0.0000	time 0.3363 (0.3749)	loss 0.9004 (1.3262)	grad_norm 1.3381 (1.7422)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 22:20:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:11:45 lr 0.000000	 wd 0.0000	time 0.3336 (0.3711)	loss 1.3153 (1.3305)	grad_norm 9.3242 (1.7557)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 22:21:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:11:03 lr 0.000000	 wd 0.0000	time 0.3400 (0.3683)	loss 1.6252 (1.3305)	grad_norm 1.6057 (1.7447)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 22:21:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:10:23 lr 0.000000	 wd 0.0000	time 0.3379 (0.3664)	loss 0.8289 (1.3292)	grad_norm 1.2943 (1.7258)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 22:22:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:09:44 lr 0.000000	 wd 0.0000	time 0.3430 (0.3648)	loss 1.3184 (1.3293)	grad_norm 1.5828 (1.7131)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 22:22:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:09:06 lr 0.000000	 wd 0.0000	time 0.3126 (0.3636)	loss 1.2994 (1.3279)	grad_norm 1.5756 (1.7267)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 22:23:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:08:28 lr 0.000000	 wd 0.0000	time 0.3108 (0.3626)	loss 1.3105 (1.3279)	grad_norm 1.2519 (1.7157)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 22:24:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:07:51 lr 0.000000	 wd 0.0000	time 0.3392 (0.3618)	loss 1.3669 (1.3252)	grad_norm 1.3913 (1.7125)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 22:24:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:07:13 lr 0.000000	 wd 0.0000	time 0.3251 (0.3610)	loss 1.5069 (1.3258)	grad_norm 1.6493 (1.7066)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 22:25:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:06:37 lr 0.000000	 wd 0.0000	time 0.3201 (0.3604)	loss 1.5489 (1.3230)	grad_norm 1.7151 (1.7052)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 22:25:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:06:00 lr 0.000000	 wd 0.0000	time 0.3210 (0.3598)	loss 1.3379 (1.3239)	grad_norm 1.6342 (1.6982)	loss_scale 8192.0000 (8192.0000)	mem 7516MB
[2024-07-02 22:26:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:05:24 lr 0.000000	 wd 0.0000	time 0.3398 (0.3594)	loss 1.3023 (1.3257)	grad_norm 1.6870 (nan)	loss_scale 4096.0000 (7982.2111)	mem 7516MB
[2024-07-02 22:27:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:04:47 lr 0.000000	 wd 0.0000	time 0.3328 (0.3591)	loss 1.1098 (1.3235)	grad_norm 1.7973 (nan)	loss_scale 4096.0000 (7753.7449)	mem 7516MB
[2024-07-02 22:27:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:04:11 lr 0.000000	 wd 0.0000	time 0.3419 (0.3587)	loss 1.1020 (1.3253)	grad_norm 1.6281 (nan)	loss_scale 4096.0000 (7550.6496)	mem 7516MB
[2024-07-02 22:28:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:03:35 lr 0.000000	 wd 0.0000	time 0.3250 (0.3585)	loss 1.2691 (1.3246)	grad_norm 1.6951 (nan)	loss_scale 4096.0000 (7368.9216)	mem 7516MB
[2024-07-02 22:28:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:02:59 lr 0.000000	 wd 0.0000	time 0.3291 (0.3581)	loss 1.5576 (1.3243)	grad_norm 1.7725 (nan)	loss_scale 4096.0000 (7205.3573)	mem 7516MB
[2024-07-02 22:29:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:02:23 lr 0.000000	 wd 0.0000	time 0.3333 (0.3578)	loss 1.3914 (1.3251)	grad_norm 1.5274 (nan)	loss_scale 4096.0000 (7057.3632)	mem 7516MB
[2024-07-02 22:30:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:47 lr 0.000000	 wd 0.0000	time 0.3364 (0.3576)	loss 1.4335 (1.3268)	grad_norm 1.3731 (nan)	loss_scale 4096.0000 (6922.8169)	mem 7516MB
[2024-07-02 22:30:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:01:12 lr 0.000000	 wd 0.0000	time 0.3375 (0.3574)	loss 1.5045 (1.3277)	grad_norm 1.5486 (nan)	loss_scale 4096.0000 (6799.9652)	mem 7516MB
[2024-07-02 22:31:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 0.3372 (0.3573)	loss 1.5138 (1.3284)	grad_norm 1.5997 (nan)	loss_scale 4096.0000 (6687.3469)	mem 7516MB
[2024-07-02 22:31:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000000	 wd 0.0000	time 0.3318 (0.3570)	loss 1.4102 (1.3278)	grad_norm 1.6245 (nan)	loss_scale 4096.0000 (6583.7345)	mem 7516MB
[2024-07-02 22:31:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 249): INFO EPOCH 29 training takes 0:14:58
[2024-07-02 22:31:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_29.pth saving......
[2024-07-02 22:31:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2/diffusion_ft_swin_base_patch4_22kto1k_finetune_process2/ckpt_epoch_29.pth saved !!!
[2024-07-02 22:32:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 289): INFO Test: [0/98]	Time 9.805 (9.805)	Loss 0.4102 (0.4102)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7516MB
[2024-07-02 22:32:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 296): INFO  * Acc@1 84.678 Acc@5 97.472
[2024-07-02 22:32:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-02 22:32:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 182): INFO Max accuracy: 84.70%
[2024-07-02 22:32:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process2] (main.py 189): INFO Training time 7:40:25
