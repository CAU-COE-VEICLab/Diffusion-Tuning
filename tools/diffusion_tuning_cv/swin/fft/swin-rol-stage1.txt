[2024-07-03 21:20:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/config.json
[2024-07-03 21:20:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    FINETUNE_MODE: sequence_stage1
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: swin_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    DEPTHS:
    - 3
    - 3
    - 9
    - 3
    DIMS:
    - 96
    - 192
    - 384
    - 768
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 4.0e-05
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.0e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 4.0e-08
  WEIGHT_DECAY: 1.0e-08

[2024-07-03 21:20:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility/configs/swin/diffusion_ft_swin_base_patch4_window7_224_22kto1k_sequence_stage_process1.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-03 21:21:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 108): INFO Creating model:swin_diffusion_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1
[2024-07-03 21:21:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 110): INFO SwinTransformer_Diffusion_Finetune(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-03 21:21:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 113): INFO number of params: 3672128
[2024-07-03 21:21:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 116): INFO number of GFLOPs: 15.438473216
[2024-07-03 21:21:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 150): INFO no checkpoint found in pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1, ignoring auto resume
[2024-07-03 21:21:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune/ckpt_epoch_best.pth for fine-tuning......
[2024-07-03 21:21:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])
[2024-07-03 21:21:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility/pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process0/diffusion_ft_swin_base_patch4_22kto1k_finetune/ckpt_epoch_best.pth'
[2024-07-03 21:21:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 12.993 (12.993)	Loss 0.4207 (0.4207)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 1406MB
[2024-07-03 21:21:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.784 Acc@5 97.110
[2024-07-03 21:21:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 162): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-03 21:21:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 168): INFO Start training
[2024-07-03 21:21:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][0/2502]	eta 7:45:22 lr 0.000000	 wd 0.0000	time 11.1601 (11.1601)	loss 1.6343 (1.6343)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 9202MB
[2024-07-03 21:22:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:14:31 lr 0.000000	 wd 0.0000	time 0.2433 (0.3629)	loss 1.4451 (1.4194)	grad_norm 3.9008 (nan)	loss_scale 4096.0000 (6650.9307)	mem 9231MB
[2024-07-03 21:22:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:11:49 lr 0.000001	 wd 0.0000	time 0.2357 (0.3080)	loss 1.3102 (1.4019)	grad_norm 4.2186 (nan)	loss_scale 1024.0000 (4004.2985)	mem 9231MB
[2024-07-03 21:22:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:10:37 lr 0.000001	 wd 0.0000	time 0.2505 (0.2897)	loss 1.3165 (1.3825)	grad_norm 2.7936 (nan)	loss_scale 1024.0000 (3014.1661)	mem 9231MB
[2024-07-03 21:23:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:09:49 lr 0.000001	 wd 0.0000	time 0.2505 (0.2806)	loss 1.8633 (1.3845)	grad_norm 4.5436 (nan)	loss_scale 1024.0000 (2517.8653)	mem 9231MB
[2024-07-03 21:23:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:09:10 lr 0.000002	 wd 0.0000	time 0.2484 (0.2752)	loss 1.5907 (1.3851)	grad_norm 4.9609 (nan)	loss_scale 1024.0000 (2219.6886)	mem 9231MB
[2024-07-03 21:24:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:08:36 lr 0.000002	 wd 0.0000	time 0.2462 (0.2716)	loss 0.9970 (1.3895)	grad_norm 5.2503 (nan)	loss_scale 1024.0000 (2020.7388)	mem 9231MB
[2024-07-03 21:24:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:04 lr 0.000002	 wd 0.0000	time 0.2505 (0.2691)	loss 1.4839 (1.3874)	grad_norm 3.6642 (nan)	loss_scale 1024.0000 (1878.5506)	mem 9231MB
[2024-07-03 21:25:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:34 lr 0.000003	 wd 0.0000	time 0.2501 (0.2672)	loss 1.5927 (1.3875)	grad_norm 2.7444 (nan)	loss_scale 1024.0000 (1771.8652)	mem 9231MB
[2024-07-03 21:25:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:05 lr 0.000003	 wd 0.0000	time 0.2486 (0.2658)	loss 1.6009 (1.3826)	grad_norm 4.5765 (nan)	loss_scale 1024.0000 (1688.8613)	mem 9231MB
[2024-07-03 21:25:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:06:37 lr 0.000003	 wd 0.0000	time 0.2500 (0.2646)	loss 1.3905 (1.3820)	grad_norm 5.1265 (nan)	loss_scale 1024.0000 (1622.4416)	mem 9231MB
[2024-07-03 21:26:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:09 lr 0.000004	 wd 0.0000	time 0.2479 (0.2637)	loss 1.5296 (1.3825)	grad_norm 7.9850 (nan)	loss_scale 1024.0000 (1568.0872)	mem 9231MB
[2024-07-03 21:26:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:42 lr 0.000004	 wd 0.0000	time 0.2448 (0.2630)	loss 1.3425 (1.3858)	grad_norm 4.5438 (nan)	loss_scale 1024.0000 (1522.7843)	mem 9231MB
[2024-07-03 21:27:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:15 lr 0.000004	 wd 0.0000	time 0.2496 (0.2623)	loss 1.5415 (1.3878)	grad_norm 10.0603 (nan)	loss_scale 1024.0000 (1484.4458)	mem 9231MB
[2024-07-03 21:27:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:48 lr 0.000005	 wd 0.0000	time 0.2539 (0.2618)	loss 1.5809 (1.3887)	grad_norm 4.1043 (nan)	loss_scale 1024.0000 (1451.5803)	mem 9231MB
[2024-07-03 21:28:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:21 lr 0.000005	 wd 0.0000	time 0.2527 (0.2614)	loss 1.3841 (1.3881)	grad_norm 3.9980 (nan)	loss_scale 1024.0000 (1423.0939)	mem 9231MB
[2024-07-03 21:28:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:55 lr 0.000005	 wd 0.0000	time 0.2510 (0.2610)	loss 1.7680 (1.3891)	grad_norm 6.1363 (nan)	loss_scale 1024.0000 (1398.1661)	mem 9231MB
[2024-07-03 21:28:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:29 lr 0.000005	 wd 0.0000	time 0.2531 (0.2606)	loss 1.5970 (1.3885)	grad_norm 5.1829 (nan)	loss_scale 1024.0000 (1376.1693)	mem 9231MB
[2024-07-03 21:29:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:03:02 lr 0.000006	 wd 0.0000	time 0.2544 (0.2604)	loss 1.2376 (1.3886)	grad_norm 3.8093 (nan)	loss_scale 1024.0000 (1356.6152)	mem 9231MB
[2024-07-03 21:29:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:36 lr 0.000006	 wd 0.0000	time 0.2502 (0.2601)	loss 1.4520 (1.3880)	grad_norm 6.4624 (nan)	loss_scale 1024.0000 (1339.1184)	mem 9231MB
[2024-07-03 21:30:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:10 lr 0.000006	 wd 0.0000	time 0.2552 (0.2599)	loss 1.5425 (1.3857)	grad_norm 4.3963 (nan)	loss_scale 1024.0000 (1323.3703)	mem 9231MB
[2024-07-03 21:30:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:44 lr 0.000007	 wd 0.0000	time 0.2567 (0.2597)	loss 1.4131 (1.3870)	grad_norm 7.2366 (nan)	loss_scale 1024.0000 (1309.1214)	mem 9231MB
[2024-07-03 21:31:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:18 lr 0.000007	 wd 0.0000	time 0.2539 (0.2595)	loss 1.5485 (1.3871)	grad_norm 4.5184 (nan)	loss_scale 1024.0000 (1296.1672)	mem 9231MB
[2024-07-03 21:31:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:52 lr 0.000007	 wd 0.0000	time 0.2505 (0.2593)	loss 1.4261 (1.3859)	grad_norm 17.2090 (nan)	loss_scale 1024.0000 (1284.3390)	mem 9231MB
[2024-07-03 21:31:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:26 lr 0.000008	 wd 0.0000	time 0.2471 (0.2591)	loss 1.4867 (1.3864)	grad_norm 4.6553 (nan)	loss_scale 1024.0000 (1273.4960)	mem 9231MB
[2024-07-03 21:32:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.2495 (0.2589)	loss 1.6149 (1.3868)	grad_norm 3.0565 (nan)	loss_scale 1024.0000 (1263.5202)	mem 9231MB
[2024-07-03 21:32:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 0 training takes 0:10:50
[2024-07-03 21:32:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_0.pth saving......
[2024-07-03 21:32:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_0.pth saved !!!
[2024-07-03 21:32:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 10.857 (10.857)	Loss 0.4197 (0.4197)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 9231MB
[2024-07-03 21:32:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.772 Acc@5 97.126
[2024-07-03 21:32:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-03 21:32:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.77%
[2024-07-03 21:32:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth saving......
[2024-07-03 21:32:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth saved !!!
[2024-07-03 21:32:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][0/2502]	eta 7:00:55 lr 0.000008	 wd 0.0000	time 10.0942 (10.0942)	loss 1.2409 (1.2409)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:33:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:14:20 lr 0.000008	 wd 0.0000	time 0.2494 (0.3581)	loss 1.1898 (1.4163)	grad_norm 5.2783 (5.3778)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:33:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:11:44 lr 0.000009	 wd 0.0000	time 0.2525 (0.3060)	loss 1.4263 (1.4220)	grad_norm 22.2777 (5.2833)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:34:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:10:35 lr 0.000009	 wd 0.0000	time 0.2507 (0.2885)	loss 1.7329 (1.4081)	grad_norm 6.1866 (5.1034)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:34:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:09:48 lr 0.000009	 wd 0.0000	time 0.2507 (0.2798)	loss 0.9202 (1.3939)	grad_norm 5.6638 (5.0071)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:35:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:09:09 lr 0.000010	 wd 0.0000	time 0.2520 (0.2746)	loss 1.6797 (1.3918)	grad_norm 3.7121 (4.9650)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:35:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:08:35 lr 0.000010	 wd 0.0000	time 0.2494 (0.2711)	loss 1.3906 (1.3884)	grad_norm 4.4424 (5.0272)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:35:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:04 lr 0.000010	 wd 0.0000	time 0.2521 (0.2686)	loss 1.5297 (1.3867)	grad_norm 5.8109 (4.9623)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:36:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:34 lr 0.000011	 wd 0.0000	time 0.2502 (0.2668)	loss 1.5647 (1.3902)	grad_norm 3.0492 (4.9728)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:36:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:05 lr 0.000011	 wd 0.0000	time 0.2516 (0.2655)	loss 1.5611 (1.3888)	grad_norm 4.3379 (4.9694)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:37:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:37 lr 0.000011	 wd 0.0000	time 0.2502 (0.2644)	loss 1.4793 (1.3870)	grad_norm 3.6257 (4.9297)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:37:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:06:09 lr 0.000012	 wd 0.0000	time 0.2505 (0.2635)	loss 1.1363 (1.3874)	grad_norm 3.0425 (4.9343)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:38:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:42 lr 0.000012	 wd 0.0000	time 0.2484 (0.2628)	loss 1.4351 (1.3905)	grad_norm 4.5962 (4.9235)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:38:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:15 lr 0.000012	 wd 0.0000	time 0.2523 (0.2622)	loss 1.5285 (1.3920)	grad_norm 4.1192 (4.9234)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:38:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:48 lr 0.000012	 wd 0.0000	time 0.2511 (0.2617)	loss 1.4998 (1.3900)	grad_norm 3.9908 (4.9251)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:39:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:21 lr 0.000013	 wd 0.0000	time 0.2505 (0.2613)	loss 0.9729 (1.3883)	grad_norm 4.2205 (4.9299)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:39:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:55 lr 0.000013	 wd 0.0000	time 0.2511 (0.2609)	loss 0.9899 (1.3875)	grad_norm 3.7733 (4.9618)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:40:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:28 lr 0.000013	 wd 0.0000	time 0.2488 (0.2606)	loss 1.4308 (1.3876)	grad_norm 4.4358 (4.9690)	loss_scale 2048.0000 (1069.7519)	mem 9231MB
[2024-07-03 21:40:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:03:02 lr 0.000014	 wd 0.0000	time 0.2513 (0.2603)	loss 1.3599 (1.3870)	grad_norm 5.7320 (4.9417)	loss_scale 2048.0000 (1124.0689)	mem 9231MB
[2024-07-03 21:40:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:36 lr 0.000014	 wd 0.0000	time 0.2501 (0.2600)	loss 1.4152 (1.3880)	grad_norm 9.8853 (4.9371)	loss_scale 2048.0000 (1172.6712)	mem 9231MB
[2024-07-03 21:41:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:10 lr 0.000014	 wd 0.0000	time 0.2509 (0.2598)	loss 1.4521 (1.3880)	grad_norm 3.5966 (4.9422)	loss_scale 2048.0000 (1216.4158)	mem 9231MB
[2024-07-03 21:41:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:44 lr 0.000015	 wd 0.0000	time 0.2496 (0.2596)	loss 1.5816 (1.3891)	grad_norm 3.6166 (4.9364)	loss_scale 2048.0000 (1255.9962)	mem 9231MB
[2024-07-03 21:42:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:18 lr 0.000015	 wd 0.0000	time 0.2514 (0.2594)	loss 1.0795 (1.3898)	grad_norm 3.9018 (4.9393)	loss_scale 2048.0000 (1291.9800)	mem 9231MB
[2024-07-03 21:42:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:52 lr 0.000015	 wd 0.0000	time 0.2497 (0.2592)	loss 1.3918 (1.3901)	grad_norm 5.4433 (4.9574)	loss_scale 2048.0000 (1324.8362)	mem 9231MB
[2024-07-03 21:43:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:26 lr 0.000016	 wd 0.0000	time 0.2508 (0.2591)	loss 1.5682 (1.3885)	grad_norm 4.4156 (4.9545)	loss_scale 2048.0000 (1354.9554)	mem 9231MB
[2024-07-03 21:43:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.2496 (0.2589)	loss 1.1273 (1.3900)	grad_norm 3.6816 (4.9536)	loss_scale 2048.0000 (1382.6661)	mem 9231MB
[2024-07-03 21:43:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 1 training takes 0:10:50
[2024-07-03 21:43:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.330 (11.330)	Loss 0.4197 (0.4197)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 9231MB
[2024-07-03 21:43:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.758 Acc@5 97.118
[2024-07-03 21:43:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-03 21:43:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.77%
[2024-07-03 21:44:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][0/2502]	eta 7:33:22 lr 0.000016	 wd 0.0000	time 10.8724 (10.8724)	loss 1.4617 (1.4617)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 9231MB
[2024-07-03 21:44:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:14:31 lr 0.000016	 wd 0.0000	time 0.2509 (0.3630)	loss 1.5157 (1.3672)	grad_norm 5.6223 (inf)	loss_scale 1024.0000 (1541.0693)	mem 9231MB
[2024-07-03 21:45:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:11:50 lr 0.000017	 wd 0.0000	time 0.2499 (0.3086)	loss 1.5193 (1.3866)	grad_norm 3.7741 (inf)	loss_scale 1024.0000 (1283.8209)	mem 9231MB
[2024-07-03 21:45:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:10:39 lr 0.000017	 wd 0.0000	time 0.2491 (0.2902)	loss 1.1893 (1.3913)	grad_norm 8.6519 (inf)	loss_scale 1024.0000 (1197.5017)	mem 9231MB
[2024-07-03 21:45:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:09:50 lr 0.000017	 wd 0.0000	time 0.2487 (0.2810)	loss 1.5679 (1.3867)	grad_norm 4.4981 (inf)	loss_scale 1024.0000 (1154.2344)	mem 9231MB
[2024-07-03 21:46:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:09:11 lr 0.000018	 wd 0.0000	time 0.2489 (0.2756)	loss 1.4567 (1.3888)	grad_norm 4.2197 (inf)	loss_scale 1024.0000 (1128.2395)	mem 9231MB
[2024-07-03 21:46:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:37 lr 0.000018	 wd 0.0000	time 0.2509 (0.2720)	loss 1.2979 (1.3826)	grad_norm 3.7087 (inf)	loss_scale 1024.0000 (1110.8952)	mem 9231MB
[2024-07-03 21:47:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:08:05 lr 0.000018	 wd 0.0000	time 0.2499 (0.2695)	loss 1.2538 (1.3861)	grad_norm 3.8792 (inf)	loss_scale 1024.0000 (1098.4993)	mem 9231MB
[2024-07-03 21:47:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:35 lr 0.000019	 wd 0.0000	time 0.2511 (0.2676)	loss 1.5887 (1.3845)	grad_norm 4.5631 (inf)	loss_scale 1024.0000 (1089.1985)	mem 9231MB
[2024-07-03 21:47:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:07:06 lr 0.000019	 wd 0.0000	time 0.2537 (0.2662)	loss 1.5311 (1.3896)	grad_norm 3.7379 (inf)	loss_scale 1024.0000 (1081.9623)	mem 9231MB
[2024-07-03 21:48:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:38 lr 0.000019	 wd 0.0000	time 0.2488 (0.2650)	loss 1.5019 (1.3914)	grad_norm 3.6316 (inf)	loss_scale 1024.0000 (1076.1718)	mem 9231MB
[2024-07-03 21:48:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:06:10 lr 0.000020	 wd 0.0000	time 0.2518 (0.2641)	loss 1.1988 (1.3918)	grad_norm 4.8065 (inf)	loss_scale 1024.0000 (1071.4332)	mem 9231MB
[2024-07-03 21:49:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:42 lr 0.000020	 wd 0.0000	time 0.2494 (0.2633)	loss 1.3537 (1.3909)	grad_norm 5.8043 (inf)	loss_scale 1024.0000 (1067.4838)	mem 9231MB
[2024-07-03 21:49:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:05:15 lr 0.000020	 wd 0.0000	time 0.2506 (0.2627)	loss 1.6800 (1.3936)	grad_norm 4.5419 (inf)	loss_scale 1024.0000 (1064.1414)	mem 9231MB
[2024-07-03 21:50:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:48 lr 0.000020	 wd 0.0000	time 0.2527 (0.2621)	loss 1.4116 (1.3941)	grad_norm 3.6705 (inf)	loss_scale 1024.0000 (1061.2762)	mem 9231MB
[2024-07-03 21:50:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:22 lr 0.000021	 wd 0.0000	time 0.2502 (0.2616)	loss 1.5580 (1.3921)	grad_norm 3.8895 (inf)	loss_scale 1024.0000 (1058.7928)	mem 9231MB
[2024-07-03 21:50:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:55 lr 0.000021	 wd 0.0000	time 0.2518 (0.2612)	loss 1.2812 (1.3925)	grad_norm 3.4391 (inf)	loss_scale 1024.0000 (1056.6196)	mem 9231MB
[2024-07-03 21:51:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:29 lr 0.000021	 wd 0.0000	time 0.2514 (0.2609)	loss 1.3361 (1.3914)	grad_norm 4.5495 (inf)	loss_scale 1024.0000 (1054.7019)	mem 9231MB
[2024-07-03 21:51:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:03:02 lr 0.000022	 wd 0.0000	time 0.2515 (0.2606)	loss 1.3510 (1.3913)	grad_norm 4.3842 (inf)	loss_scale 1024.0000 (1052.9972)	mem 9231MB
[2024-07-03 21:52:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:36 lr 0.000022	 wd 0.0000	time 0.2531 (0.2603)	loss 0.9885 (1.3896)	grad_norm 7.5026 (inf)	loss_scale 1024.0000 (1051.4719)	mem 9231MB
[2024-07-03 21:52:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:02:10 lr 0.000022	 wd 0.0000	time 0.2566 (0.2601)	loss 1.1890 (1.3873)	grad_norm 6.8642 (inf)	loss_scale 1024.0000 (1050.0990)	mem 9231MB
[2024-07-03 21:53:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:44 lr 0.000023	 wd 0.0000	time 0.2521 (0.2598)	loss 1.4487 (1.3875)	grad_norm 5.0244 (inf)	loss_scale 1024.0000 (1048.8567)	mem 9231MB
[2024-07-03 21:53:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:18 lr 0.000023	 wd 0.0000	time 0.2501 (0.2597)	loss 1.6287 (1.3872)	grad_norm 4.0468 (inf)	loss_scale 1024.0000 (1047.7274)	mem 9231MB
[2024-07-03 21:53:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:52 lr 0.000023	 wd 0.0000	time 0.2482 (0.2595)	loss 1.6946 (1.3876)	grad_norm 3.6330 (inf)	loss_scale 1024.0000 (1046.6962)	mem 9231MB
[2024-07-03 21:54:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:26 lr 0.000024	 wd 0.0000	time 0.2543 (0.2593)	loss 1.5130 (1.3867)	grad_norm 3.7960 (inf)	loss_scale 1024.0000 (1045.7509)	mem 9231MB
[2024-07-03 21:54:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.2493 (0.2591)	loss 1.5644 (1.3869)	grad_norm 5.5710 (inf)	loss_scale 1024.0000 (1044.8812)	mem 9231MB
[2024-07-03 21:54:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 2 training takes 0:10:50
[2024-07-03 21:55:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.979 (11.979)	Loss 0.4214 (0.4214)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-03 21:55:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.768 Acc@5 97.116
[2024-07-03 21:55:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-03 21:55:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.77%
[2024-07-03 21:55:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][0/2502]	eta 6:38:47 lr 0.000024	 wd 0.0000	time 9.5634 (9.5634)	loss 0.9931 (0.9931)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:55:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:14:21 lr 0.000024	 wd 0.0000	time 0.2501 (0.3586)	loss 1.4890 (1.3610)	grad_norm 4.4223 (5.0254)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:56:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:11:45 lr 0.000025	 wd 0.0000	time 0.2494 (0.3063)	loss 1.4250 (1.3775)	grad_norm 3.8212 (5.0973)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:56:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:10:35 lr 0.000025	 wd 0.0000	time 0.2483 (0.2887)	loss 1.5817 (1.3714)	grad_norm 5.0340 (5.1280)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:57:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:09:48 lr 0.000025	 wd 0.0000	time 0.2482 (0.2799)	loss 1.5549 (1.3746)	grad_norm 4.2685 (5.0307)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:57:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:09:09 lr 0.000026	 wd 0.0000	time 0.2440 (0.2746)	loss 1.4526 (1.3732)	grad_norm 6.2398 (4.9860)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:57:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:08:35 lr 0.000026	 wd 0.0000	time 0.2514 (0.2712)	loss 1.4284 (1.3738)	grad_norm 3.6138 (4.9599)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:58:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:08:04 lr 0.000026	 wd 0.0000	time 0.2523 (0.2688)	loss 1.7034 (1.3758)	grad_norm 4.5051 (4.9612)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:58:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:34 lr 0.000027	 wd 0.0000	time 0.2533 (0.2670)	loss 1.1176 (1.3759)	grad_norm 3.5224 (5.0098)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:59:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:07:05 lr 0.000027	 wd 0.0000	time 0.2486 (0.2656)	loss 1.5106 (1.3774)	grad_norm 5.0678 (5.0261)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 21:59:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:37 lr 0.000027	 wd 0.0000	time 0.2538 (0.2645)	loss 1.5141 (1.3805)	grad_norm 3.2021 (5.0217)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:00:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:06:09 lr 0.000028	 wd 0.0000	time 0.2549 (0.2636)	loss 1.3953 (1.3831)	grad_norm 10.0656 (5.0759)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:00:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:42 lr 0.000028	 wd 0.0000	time 0.2502 (0.2629)	loss 1.2364 (1.3812)	grad_norm 3.1867 (5.0641)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:00:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:05:15 lr 0.000028	 wd 0.0000	time 0.2497 (0.2623)	loss 1.3129 (1.3839)	grad_norm 6.6733 (5.0633)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:01:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:48 lr 0.000028	 wd 0.0000	time 0.2565 (0.2618)	loss 1.2773 (1.3846)	grad_norm 8.8556 (5.0299)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:01:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:21 lr 0.000029	 wd 0.0000	time 0.2506 (0.2613)	loss 1.4751 (1.3863)	grad_norm 3.9654 (5.0547)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:02:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:55 lr 0.000029	 wd 0.0000	time 0.2491 (0.2609)	loss 1.5325 (1.3852)	grad_norm 3.1987 (5.0370)	loss_scale 2048.0000 (1057.2592)	mem 9231MB
[2024-07-03 22:02:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:28 lr 0.000029	 wd 0.0000	time 0.2505 (0.2606)	loss 1.1430 (1.3842)	grad_norm 5.1117 (5.0351)	loss_scale 2048.0000 (1115.5038)	mem 9231MB
[2024-07-03 22:03:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:03:02 lr 0.000030	 wd 0.0000	time 0.2500 (0.2603)	loss 1.5282 (1.3845)	grad_norm 3.7610 (5.0492)	loss_scale 2048.0000 (1167.2804)	mem 9231MB
[2024-07-03 22:03:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:36 lr 0.000030	 wd 0.0000	time 0.2542 (0.2600)	loss 1.5149 (1.3838)	grad_norm 4.1193 (inf)	loss_scale 1024.0000 (1179.1352)	mem 9231MB
[2024-07-03 22:03:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:10 lr 0.000030	 wd 0.0000	time 0.2542 (0.2598)	loss 1.1849 (1.3844)	grad_norm 4.3665 (inf)	loss_scale 1024.0000 (1171.3823)	mem 9231MB
[2024-07-03 22:04:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:44 lr 0.000031	 wd 0.0000	time 0.2496 (0.2596)	loss 1.1801 (1.3833)	grad_norm 3.3546 (nan)	loss_scale 512.0000 (1155.1071)	mem 9231MB
[2024-07-03 22:04:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:18 lr 0.000031	 wd 0.0000	time 0.2523 (0.2594)	loss 1.4060 (1.3842)	grad_norm 4.0284 (nan)	loss_scale 512.0000 (1125.8882)	mem 9231MB
[2024-07-03 22:05:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:52 lr 0.000031	 wd 0.0000	time 0.2501 (0.2592)	loss 1.5123 (1.3852)	grad_norm 3.9340 (nan)	loss_scale 512.0000 (1099.2090)	mem 9231MB
[2024-07-03 22:05:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:26 lr 0.000032	 wd 0.0000	time 0.2481 (0.2591)	loss 1.0133 (1.3844)	grad_norm 5.8891 (nan)	loss_scale 512.0000 (1074.7522)	mem 9231MB
[2024-07-03 22:06:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000032	 wd 0.0000	time 0.2504 (0.2588)	loss 1.4684 (1.3847)	grad_norm 3.8685 (nan)	loss_scale 512.0000 (1052.2511)	mem 9231MB
[2024-07-03 22:06:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 3 training takes 0:10:50
[2024-07-03 22:06:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.714 (11.714)	Loss 0.4175 (0.4175)	Acc@1 91.797 (91.797)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-03 22:06:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.752 Acc@5 97.102
[2024-07-03 22:06:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-03 22:06:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.77%
[2024-07-03 22:06:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][0/2502]	eta 7:31:20 lr 0.000032	 wd 0.0000	time 10.8236 (10.8236)	loss 1.4295 (1.4295)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:07:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:14:31 lr 0.000032	 wd 0.0000	time 0.2481 (0.3626)	loss 1.2829 (1.4140)	grad_norm 9.5955 (4.9389)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:07:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:11:49 lr 0.000033	 wd 0.0000	time 0.2502 (0.3082)	loss 1.1415 (1.4028)	grad_norm 4.8452 (5.4092)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:07:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:10:38 lr 0.000033	 wd 0.0000	time 0.2493 (0.2899)	loss 1.1193 (1.4042)	grad_norm 7.4003 (5.4969)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:08:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:09:50 lr 0.000033	 wd 0.0000	time 0.2471 (0.2808)	loss 1.4501 (1.3939)	grad_norm 5.6544 (5.4562)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:08:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:09:11 lr 0.000034	 wd 0.0000	time 0.2494 (0.2753)	loss 1.4344 (1.3894)	grad_norm 5.2549 (5.2692)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:09:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:08:36 lr 0.000034	 wd 0.0000	time 0.2443 (0.2718)	loss 1.4311 (1.3844)	grad_norm 7.7846 (5.2084)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:09:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:08:05 lr 0.000034	 wd 0.0000	time 0.2491 (0.2692)	loss 1.2896 (1.3845)	grad_norm 4.0568 (5.1891)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:10:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:34 lr 0.000035	 wd 0.0000	time 0.2495 (0.2673)	loss 1.3713 (1.3854)	grad_norm 3.0127 (5.1099)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:10:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:07:05 lr 0.000035	 wd 0.0000	time 0.2503 (0.2659)	loss 1.4974 (1.3863)	grad_norm inf (inf)	loss_scale 256.0000 (511.4317)	mem 9231MB
[2024-07-03 22:10:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:37 lr 0.000035	 wd 0.0000	time 0.2518 (0.2647)	loss 1.5677 (1.3871)	grad_norm 3.3373 (inf)	loss_scale 256.0000 (485.9141)	mem 9231MB
[2024-07-03 22:11:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:06:09 lr 0.000036	 wd 0.0000	time 0.2508 (0.2637)	loss 1.5785 (1.3873)	grad_norm 3.9581 (inf)	loss_scale 256.0000 (465.0318)	mem 9231MB
[2024-07-03 22:11:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:42 lr 0.000036	 wd 0.0000	time 0.2503 (0.2629)	loss 1.0697 (1.3865)	grad_norm 9.2677 (inf)	loss_scale 256.0000 (447.6270)	mem 9231MB
[2024-07-03 22:12:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:05:15 lr 0.000036	 wd 0.0000	time 0.2514 (0.2623)	loss 1.5595 (1.3854)	grad_norm 5.0663 (inf)	loss_scale 256.0000 (432.8978)	mem 9231MB
[2024-07-03 22:12:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:48 lr 0.000036	 wd 0.0000	time 0.2496 (0.2617)	loss 1.4831 (1.3856)	grad_norm 4.3082 (inf)	loss_scale 256.0000 (420.2712)	mem 9231MB
[2024-07-03 22:12:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:21 lr 0.000037	 wd 0.0000	time 0.2588 (0.2612)	loss 1.3094 (1.3887)	grad_norm 7.1201 (inf)	loss_scale 256.0000 (409.3271)	mem 9231MB
[2024-07-03 22:13:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:55 lr 0.000037	 wd 0.0000	time 0.2497 (0.2608)	loss 1.1954 (1.3880)	grad_norm 5.2366 (inf)	loss_scale 256.0000 (399.7502)	mem 9231MB
[2024-07-03 22:13:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:28 lr 0.000037	 wd 0.0000	time 0.2456 (0.2605)	loss 1.5825 (1.3878)	grad_norm 7.5170 (inf)	loss_scale 256.0000 (391.2992)	mem 9231MB
[2024-07-03 22:14:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:03:02 lr 0.000038	 wd 0.0000	time 0.2481 (0.2602)	loss 1.5784 (1.3875)	grad_norm 3.8359 (inf)	loss_scale 256.0000 (383.7868)	mem 9231MB
[2024-07-03 22:14:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:36 lr 0.000038	 wd 0.0000	time 0.2498 (0.2599)	loss 1.5763 (1.3874)	grad_norm 4.5105 (inf)	loss_scale 256.0000 (377.0647)	mem 9231MB
[2024-07-03 22:15:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:02:10 lr 0.000038	 wd 0.0000	time 0.2497 (0.2597)	loss 1.5751 (1.3875)	grad_norm 4.3542 (inf)	loss_scale 256.0000 (371.0145)	mem 9231MB
[2024-07-03 22:15:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:44 lr 0.000039	 wd 0.0000	time 0.2490 (0.2595)	loss 1.3671 (1.3876)	grad_norm 3.8975 (inf)	loss_scale 256.0000 (365.5402)	mem 9231MB
[2024-07-03 22:15:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:18 lr 0.000039	 wd 0.0000	time 0.2501 (0.2593)	loss 1.0122 (1.3848)	grad_norm 5.5030 (inf)	loss_scale 256.0000 (360.5634)	mem 9231MB
[2024-07-03 22:16:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:52 lr 0.000039	 wd 0.0000	time 0.2523 (0.2591)	loss 1.3233 (1.3858)	grad_norm 4.3507 (inf)	loss_scale 256.0000 (356.0191)	mem 9231MB
[2024-07-03 22:16:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:26 lr 0.000040	 wd 0.0000	time 0.2462 (0.2589)	loss 1.4895 (1.3853)	grad_norm 2.9610 (inf)	loss_scale 256.0000 (351.8534)	mem 9231MB
[2024-07-03 22:17:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.2508 (0.2587)	loss 0.9017 (1.3851)	grad_norm 3.5105 (inf)	loss_scale 256.0000 (348.0208)	mem 9231MB
[2024-07-03 22:17:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 4 training takes 0:10:49
[2024-07-03 22:17:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.532 (11.532)	Loss 0.4270 (0.4270)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 9231MB
[2024-07-03 22:17:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.758 Acc@5 97.158
[2024-07-03 22:17:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-03 22:17:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.77%
[2024-07-03 22:17:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][0/2502]	eta 7:55:39 lr 0.000040	 wd 0.0000	time 11.4066 (11.4066)	loss 1.6045 (1.6045)	grad_norm 0.0000 (0.0000)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:18:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:14:33 lr 0.000040	 wd 0.0000	time 0.2490 (0.3639)	loss 1.3333 (1.4006)	grad_norm 5.4647 (4.9150)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:18:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:11:50 lr 0.000040	 wd 0.0000	time 0.2497 (0.3087)	loss 1.4658 (1.4155)	grad_norm 5.5096 (4.7881)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:19:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:39 lr 0.000040	 wd 0.0000	time 0.2483 (0.2903)	loss 1.6761 (1.4018)	grad_norm 4.1800 (4.9610)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:19:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:50 lr 0.000040	 wd 0.0000	time 0.2520 (0.2811)	loss 1.1592 (1.4029)	grad_norm 4.1816 (4.9360)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:19:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:09:11 lr 0.000040	 wd 0.0000	time 0.2490 (0.2755)	loss 1.6853 (1.3981)	grad_norm 3.7010 (5.0469)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:20:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:37 lr 0.000040	 wd 0.0000	time 0.2495 (0.2719)	loss 1.5699 (1.4011)	grad_norm 4.1175 (5.0450)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:20:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:08:05 lr 0.000040	 wd 0.0000	time 0.2501 (0.2693)	loss 1.4773 (1.3983)	grad_norm 5.4955 (5.0047)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:21:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:35 lr 0.000040	 wd 0.0000	time 0.2509 (0.2674)	loss 1.0911 (1.3921)	grad_norm 3.6677 (5.0716)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:21:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:07:06 lr 0.000040	 wd 0.0000	time 0.2509 (0.2660)	loss 0.8452 (1.3909)	grad_norm 3.3194 (5.2376)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:22:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:37 lr 0.000040	 wd 0.0000	time 0.2491 (0.2648)	loss 1.4023 (1.3936)	grad_norm 4.4410 (5.2339)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:22:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:06:09 lr 0.000040	 wd 0.0000	time 0.2507 (0.2638)	loss 1.5764 (1.3893)	grad_norm 3.6602 (5.2421)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:22:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:42 lr 0.000040	 wd 0.0000	time 0.2505 (0.2631)	loss 1.5409 (1.3887)	grad_norm 4.9294 (5.2150)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:23:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:05:15 lr 0.000040	 wd 0.0000	time 0.2504 (0.2624)	loss 1.5467 (1.3886)	grad_norm 4.8585 (5.1868)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:23:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:48 lr 0.000040	 wd 0.0000	time 0.2507 (0.2619)	loss 1.5018 (1.3881)	grad_norm 5.7940 (5.1695)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:24:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:04:21 lr 0.000040	 wd 0.0000	time 0.2524 (0.2614)	loss 1.3302 (1.3882)	grad_norm 3.8939 (5.2224)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:24:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:55 lr 0.000040	 wd 0.0000	time 0.2557 (0.2610)	loss 1.4533 (1.3891)	grad_norm 10.1291 (5.2250)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:25:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:29 lr 0.000040	 wd 0.0000	time 0.2556 (0.2606)	loss 1.4951 (1.3891)	grad_norm 5.0600 (5.2275)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:25:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:03:02 lr 0.000040	 wd 0.0000	time 0.2495 (0.2603)	loss 1.0699 (1.3879)	grad_norm 19.5880 (5.2334)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:25:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:36 lr 0.000040	 wd 0.0000	time 0.2510 (0.2601)	loss 1.5720 (1.3901)	grad_norm 23.8560 (5.2523)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:26:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:02:10 lr 0.000040	 wd 0.0000	time 0.2519 (0.2598)	loss 1.4350 (1.3915)	grad_norm 6.2584 (5.3075)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:26:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:44 lr 0.000040	 wd 0.0000	time 0.2565 (0.2596)	loss 1.6593 (1.3925)	grad_norm 4.2757 (5.2955)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:27:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:18 lr 0.000040	 wd 0.0000	time 0.2555 (0.2594)	loss 1.3999 (1.3905)	grad_norm 3.2027 (5.2733)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:27:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:52 lr 0.000040	 wd 0.0000	time 0.2495 (0.2592)	loss 0.9640 (1.3900)	grad_norm 3.3552 (5.2665)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-03 22:28:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:26 lr 0.000040	 wd 0.0000	time 0.2512 (0.2590)	loss 1.6368 (1.3902)	grad_norm 9.5506 (5.2512)	loss_scale 512.0000 (256.4265)	mem 9231MB
[2024-07-03 22:28:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.2501 (0.2588)	loss 1.5132 (1.3900)	grad_norm 4.8860 (5.2319)	loss_scale 512.0000 (266.6453)	mem 9231MB
[2024-07-03 22:28:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 5 training takes 0:10:50
[2024-07-03 22:28:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.485 (11.485)	Loss 0.4131 (0.4131)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-03 22:28:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.728 Acc@5 97.158
[2024-07-03 22:28:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-03 22:28:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.77%
[2024-07-03 22:29:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][0/2502]	eta 8:00:08 lr 0.000040	 wd 0.0000	time 11.5141 (11.5141)	loss 1.7556 (1.7556)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:29:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:14:38 lr 0.000040	 wd 0.0000	time 0.2497 (0.3656)	loss 1.2566 (1.3740)	grad_norm 4.5763 (5.4538)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:29:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:11:53 lr 0.000040	 wd 0.0000	time 0.2518 (0.3098)	loss 1.4779 (1.3912)	grad_norm 3.8530 (5.0936)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:30:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:10:40 lr 0.000040	 wd 0.0000	time 0.2478 (0.2910)	loss 1.5877 (1.3982)	grad_norm 3.7653 (5.2819)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:30:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:09:51 lr 0.000040	 wd 0.0000	time 0.2509 (0.2816)	loss 1.4278 (1.3918)	grad_norm 4.8220 (5.1861)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:31:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:09:12 lr 0.000040	 wd 0.0000	time 0.2481 (0.2759)	loss 1.5471 (1.3892)	grad_norm 3.7178 (5.2151)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:31:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:08:37 lr 0.000040	 wd 0.0000	time 0.2574 (0.2723)	loss 1.5340 (1.3905)	grad_norm 3.7684 (5.2313)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:32:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:08:05 lr 0.000040	 wd 0.0000	time 0.2494 (0.2696)	loss 1.4235 (1.3909)	grad_norm 4.3666 (5.6950)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:32:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:35 lr 0.000040	 wd 0.0000	time 0.2497 (0.2677)	loss 1.1584 (1.3907)	grad_norm 4.7606 (5.6803)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:32:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:07:06 lr 0.000040	 wd 0.0000	time 0.2507 (0.2662)	loss 1.5867 (1.3924)	grad_norm 3.0257 (5.5860)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:33:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:38 lr 0.000040	 wd 0.0000	time 0.2500 (0.2650)	loss 1.3387 (1.3889)	grad_norm 4.1687 (5.5311)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:33:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:06:10 lr 0.000040	 wd 0.0000	time 0.2506 (0.2640)	loss 1.3397 (1.3864)	grad_norm 5.9645 (5.4536)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:34:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:42 lr 0.000040	 wd 0.0000	time 0.2509 (0.2633)	loss 1.1405 (1.3874)	grad_norm 6.6866 (5.4538)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:34:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:05:15 lr 0.000040	 wd 0.0000	time 0.2508 (0.2626)	loss 1.5517 (1.3861)	grad_norm 3.9782 (5.4887)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:35:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:48 lr 0.000040	 wd 0.0000	time 0.2500 (0.2620)	loss 1.7964 (1.3841)	grad_norm 6.1010 (5.4858)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:35:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:22 lr 0.000040	 wd 0.0000	time 0.2508 (0.2616)	loss 1.4921 (1.3862)	grad_norm 4.7704 (5.4627)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:35:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:55 lr 0.000040	 wd 0.0000	time 0.2502 (0.2611)	loss 1.4601 (1.3845)	grad_norm 4.5063 (5.4555)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:36:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:29 lr 0.000040	 wd 0.0000	time 0.2495 (0.2608)	loss 1.5494 (1.3845)	grad_norm 4.0271 (5.4348)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:36:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:03:02 lr 0.000040	 wd 0.0000	time 0.2537 (0.2605)	loss 1.1439 (1.3842)	grad_norm 3.6158 (5.4606)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:37:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:36 lr 0.000040	 wd 0.0000	time 0.2496 (0.2602)	loss 1.2277 (1.3843)	grad_norm 7.0484 (5.4419)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:37:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:02:10 lr 0.000039	 wd 0.0000	time 0.2486 (0.2599)	loss 1.0964 (1.3848)	grad_norm 16.4169 (5.4331)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:37:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:44 lr 0.000039	 wd 0.0000	time 0.2538 (0.2597)	loss 1.5487 (1.3840)	grad_norm 4.9353 (5.4206)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:38:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:18 lr 0.000039	 wd 0.0000	time 0.2563 (0.2595)	loss 1.2838 (1.3842)	grad_norm 3.4316 (5.3795)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:38:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:52 lr 0.000039	 wd 0.0000	time 0.2516 (0.2593)	loss 1.5368 (1.3848)	grad_norm 3.4300 (5.3579)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:39:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:26 lr 0.000039	 wd 0.0000	time 0.2515 (0.2591)	loss 1.1558 (1.3842)	grad_norm 6.4438 (5.3434)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:39:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.2489 (0.2589)	loss 1.0267 (1.3847)	grad_norm 5.0512 (5.3552)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:39:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 6 training takes 0:10:50
[2024-07-03 22:39:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.672 (11.672)	Loss 0.4167 (0.4167)	Acc@1 92.773 (92.773)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-03 22:40:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.640 Acc@5 97.124
[2024-07-03 22:40:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.6%
[2024-07-03 22:40:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.77%
[2024-07-03 22:40:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][0/2502]	eta 7:51:40 lr 0.000039	 wd 0.0000	time 11.3113 (11.3113)	loss 1.7043 (1.7043)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:40:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:14:32 lr 0.000039	 wd 0.0000	time 0.2504 (0.3634)	loss 1.3598 (1.3989)	grad_norm 6.5829 (4.8090)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:41:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:11:50 lr 0.000039	 wd 0.0000	time 0.2522 (0.3085)	loss 1.6156 (1.3779)	grad_norm 7.0933 (5.0365)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:41:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:10:38 lr 0.000039	 wd 0.0000	time 0.2484 (0.2901)	loss 1.3664 (1.3796)	grad_norm 14.1696 (4.9875)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:42:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:09:50 lr 0.000039	 wd 0.0000	time 0.2496 (0.2809)	loss 1.4373 (1.3837)	grad_norm 5.0779 (4.9904)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:42:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:09:11 lr 0.000039	 wd 0.0000	time 0.2512 (0.2754)	loss 1.5478 (1.3798)	grad_norm 3.1368 (5.0657)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:42:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:36 lr 0.000039	 wd 0.0000	time 0.2488 (0.2718)	loss 1.4026 (1.3830)	grad_norm 3.5034 (5.0002)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:43:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:08:05 lr 0.000039	 wd 0.0000	time 0.2493 (0.2693)	loss 1.4187 (1.3851)	grad_norm 7.7949 (5.0187)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:43:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:07:35 lr 0.000039	 wd 0.0000	time 0.2498 (0.2674)	loss 1.0309 (1.3867)	grad_norm 4.9329 (5.0422)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:44:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:07:06 lr 0.000039	 wd 0.0000	time 0.2504 (0.2659)	loss 1.1976 (1.3892)	grad_norm 3.7423 (5.1835)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:44:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:37 lr 0.000039	 wd 0.0000	time 0.2482 (0.2648)	loss 1.2634 (1.3859)	grad_norm 5.1575 (5.1536)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:44:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:06:10 lr 0.000039	 wd 0.0000	time 0.2474 (0.2639)	loss 1.3398 (1.3844)	grad_norm 4.2355 (5.1857)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:45:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:42 lr 0.000039	 wd 0.0000	time 0.2483 (0.2631)	loss 1.3627 (1.3813)	grad_norm 4.2700 (5.2112)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:45:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:05:15 lr 0.000039	 wd 0.0000	time 0.2514 (0.2625)	loss 1.4809 (1.3822)	grad_norm 4.0573 (5.2250)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 22:46:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:48 lr 0.000039	 wd 0.0000	time 0.2547 (0.2619)	loss 1.5695 (1.3826)	grad_norm 4.5066 (5.2008)	loss_scale 1024.0000 (514.9236)	mem 9231MB
[2024-07-03 22:46:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:21 lr 0.000039	 wd 0.0000	time 0.2510 (0.2614)	loss 1.4901 (1.3818)	grad_norm 3.7774 (5.1726)	loss_scale 1024.0000 (548.8394)	mem 9231MB
[2024-07-03 22:47:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:55 lr 0.000039	 wd 0.0000	time 0.2508 (0.2610)	loss 1.4958 (1.3828)	grad_norm 6.0362 (5.1702)	loss_scale 1024.0000 (578.5184)	mem 9231MB
[2024-07-03 22:47:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:29 lr 0.000039	 wd 0.0000	time 0.2579 (0.2607)	loss 1.5449 (1.3828)	grad_norm 6.0015 (5.1905)	loss_scale 1024.0000 (604.7078)	mem 9231MB
[2024-07-03 22:47:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:03:02 lr 0.000039	 wd 0.0000	time 0.2512 (0.2604)	loss 1.3513 (1.3823)	grad_norm 5.0571 (5.2047)	loss_scale 1024.0000 (627.9889)	mem 9231MB
[2024-07-03 22:48:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:36 lr 0.000039	 wd 0.0000	time 0.2511 (0.2601)	loss 1.3758 (1.3817)	grad_norm 3.9699 (5.1837)	loss_scale 1024.0000 (648.8206)	mem 9231MB
[2024-07-03 22:48:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:02:10 lr 0.000039	 wd 0.0000	time 0.2504 (0.2599)	loss 1.4923 (1.3826)	grad_norm 3.3190 (5.1550)	loss_scale 1024.0000 (667.5702)	mem 9231MB
[2024-07-03 22:49:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:44 lr 0.000039	 wd 0.0000	time 0.2549 (0.2596)	loss 1.6302 (1.3843)	grad_norm 4.3545 (5.1411)	loss_scale 1024.0000 (684.5350)	mem 9231MB
[2024-07-03 22:49:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:18 lr 0.000039	 wd 0.0000	time 0.2542 (0.2594)	loss 1.2827 (1.3827)	grad_norm 3.2819 (5.1531)	loss_scale 1024.0000 (699.9582)	mem 9231MB
[2024-07-03 22:50:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:52 lr 0.000039	 wd 0.0000	time 0.2512 (0.2593)	loss 1.5650 (1.3832)	grad_norm 4.3172 (5.1667)	loss_scale 1024.0000 (714.0409)	mem 9231MB
[2024-07-03 22:50:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:26 lr 0.000039	 wd 0.0000	time 0.2508 (0.2591)	loss 1.3728 (1.3828)	grad_norm 6.1414 (5.1705)	loss_scale 1024.0000 (726.9504)	mem 9231MB
[2024-07-03 22:50:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.2491 (0.2589)	loss 1.3380 (1.3828)	grad_norm 7.5202 (5.1562)	loss_scale 1024.0000 (738.8277)	mem 9231MB
[2024-07-03 22:50:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 7 training takes 0:10:50
[2024-07-03 22:51:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 10.920 (10.920)	Loss 0.4180 (0.4180)	Acc@1 92.383 (92.383)	Acc@5 98.242 (98.242)	Mem 9231MB
[2024-07-03 22:51:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.706 Acc@5 97.134
[2024-07-03 22:51:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-03 22:51:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.77%
[2024-07-03 22:51:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][0/2502]	eta 7:55:22 lr 0.000039	 wd 0.0000	time 11.4000 (11.4000)	loss 1.5436 (1.5436)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:51:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:14:33 lr 0.000039	 wd 0.0000	time 0.2506 (0.3637)	loss 1.5103 (1.4178)	grad_norm 3.4846 (4.8108)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:52:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:11:50 lr 0.000039	 wd 0.0000	time 0.2497 (0.3086)	loss 1.4686 (1.3887)	grad_norm 3.7687 (4.7475)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:52:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:10:38 lr 0.000038	 wd 0.0000	time 0.2475 (0.2901)	loss 1.3863 (1.3838)	grad_norm 4.8976 (5.1007)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:53:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:09:50 lr 0.000038	 wd 0.0000	time 0.2483 (0.2809)	loss 1.5005 (1.3809)	grad_norm 3.8323 (5.0090)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:53:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:09:11 lr 0.000038	 wd 0.0000	time 0.2465 (0.2754)	loss 1.5129 (1.3873)	grad_norm 4.3467 (4.9308)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:54:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:36 lr 0.000038	 wd 0.0000	time 0.2502 (0.2718)	loss 1.5956 (1.3914)	grad_norm 4.3637 (4.9210)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:54:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:08:05 lr 0.000038	 wd 0.0000	time 0.2538 (0.2693)	loss 1.5506 (1.3916)	grad_norm 6.8298 (4.9436)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:54:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:35 lr 0.000038	 wd 0.0000	time 0.2505 (0.2674)	loss 1.4675 (1.3904)	grad_norm 5.2684 (4.9192)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:55:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:07:05 lr 0.000038	 wd 0.0000	time 0.2504 (0.2659)	loss 1.5739 (1.3913)	grad_norm 3.6526 (4.9249)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:55:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:37 lr 0.000038	 wd 0.0000	time 0.2527 (0.2648)	loss 1.4694 (1.3890)	grad_norm 3.3165 (4.9567)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:56:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:06:09 lr 0.000038	 wd 0.0000	time 0.2507 (0.2639)	loss 1.5000 (1.3855)	grad_norm 4.2914 (4.9172)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:56:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:42 lr 0.000038	 wd 0.0000	time 0.2500 (0.2631)	loss 1.4518 (1.3844)	grad_norm 4.2392 (4.9540)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:57:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:05:15 lr 0.000038	 wd 0.0000	time 0.2501 (0.2624)	loss 1.0940 (1.3822)	grad_norm 5.6336 (4.9272)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:57:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:48 lr 0.000038	 wd 0.0000	time 0.2496 (0.2619)	loss 0.9675 (1.3833)	grad_norm 5.5117 (4.9380)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:57:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:04:21 lr 0.000038	 wd 0.0000	time 0.2499 (0.2614)	loss 0.9491 (1.3798)	grad_norm 7.4191 (4.9753)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:58:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:55 lr 0.000038	 wd 0.0000	time 0.2515 (0.2610)	loss 1.2818 (1.3769)	grad_norm 5.3058 (4.9716)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:58:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:29 lr 0.000038	 wd 0.0000	time 0.2513 (0.2607)	loss 1.2276 (1.3783)	grad_norm 4.1660 (5.0155)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:59:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:03:02 lr 0.000038	 wd 0.0000	time 0.2560 (0.2604)	loss 1.4905 (1.3803)	grad_norm 9.4974 (5.0198)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 22:59:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:36 lr 0.000038	 wd 0.0000	time 0.2545 (0.2601)	loss 1.3265 (1.3807)	grad_norm 4.2660 (5.0223)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:00:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:02:10 lr 0.000038	 wd 0.0000	time 0.2445 (0.2599)	loss 1.7655 (1.3827)	grad_norm 3.6498 (inf)	loss_scale 512.0000 (1012.2299)	mem 9231MB
[2024-07-03 23:00:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:44 lr 0.000038	 wd 0.0000	time 0.2459 (0.2596)	loss 1.4155 (1.3826)	grad_norm 4.8250 (inf)	loss_scale 512.0000 (988.4208)	mem 9231MB
[2024-07-03 23:00:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:18 lr 0.000038	 wd 0.0000	time 0.2544 (0.2594)	loss 1.5144 (1.3816)	grad_norm 3.7803 (inf)	loss_scale 512.0000 (966.7751)	mem 9231MB
[2024-07-03 23:01:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:52 lr 0.000038	 wd 0.0000	time 0.2512 (0.2592)	loss 1.3915 (1.3822)	grad_norm 4.7349 (inf)	loss_scale 512.0000 (947.0109)	mem 9231MB
[2024-07-03 23:01:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:26 lr 0.000038	 wd 0.0000	time 0.2524 (0.2591)	loss 1.4441 (1.3840)	grad_norm 3.6006 (inf)	loss_scale 512.0000 (928.8930)	mem 9231MB
[2024-07-03 23:02:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000038	 wd 0.0000	time 0.2499 (0.2589)	loss 1.6425 (1.3852)	grad_norm 8.0661 (inf)	loss_scale 512.0000 (912.2239)	mem 9231MB
[2024-07-03 23:02:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 8 training takes 0:10:50
[2024-07-03 23:02:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.481 (11.481)	Loss 0.4126 (0.4126)	Acc@1 92.578 (92.578)	Acc@5 98.242 (98.242)	Mem 9231MB
[2024-07-03 23:02:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.794 Acc@5 97.116
[2024-07-03 23:02:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-03 23:02:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.79%
[2024-07-03 23:02:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth saving......
[2024-07-03 23:02:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth saved !!!
[2024-07-03 23:02:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][0/2502]	eta 6:45:36 lr 0.000038	 wd 0.0000	time 9.7269 (9.7269)	loss 1.3894 (1.3894)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:03:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:14:05 lr 0.000038	 wd 0.0000	time 0.2490 (0.3519)	loss 1.3055 (1.3582)	grad_norm 3.9738 (4.8654)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:03:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:11:37 lr 0.000037	 wd 0.0000	time 0.2488 (0.3028)	loss 1.5652 (1.3654)	grad_norm 5.0518 (5.1449)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:04:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:30 lr 0.000037	 wd 0.0000	time 0.2478 (0.2864)	loss 1.4456 (1.3754)	grad_norm 6.6192 (4.8676)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:04:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:44 lr 0.000037	 wd 0.0000	time 0.2493 (0.2782)	loss 1.5854 (1.3705)	grad_norm 3.1444 (5.1675)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:04:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:09:07 lr 0.000037	 wd 0.0000	time 0.2494 (0.2733)	loss 1.3800 (1.3752)	grad_norm 4.7011 (5.1815)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:05:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:33 lr 0.000037	 wd 0.0000	time 0.2500 (0.2701)	loss 1.4589 (1.3690)	grad_norm 3.8003 (5.1527)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:05:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:08:02 lr 0.000037	 wd 0.0000	time 0.2496 (0.2678)	loss 1.5730 (1.3692)	grad_norm 3.5531 (5.1620)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:06:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:32 lr 0.000037	 wd 0.0000	time 0.2499 (0.2661)	loss 1.4369 (1.3743)	grad_norm 4.1836 (5.1358)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:06:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:07:04 lr 0.000037	 wd 0.0000	time 0.2482 (0.2647)	loss 1.5762 (1.3714)	grad_norm 5.1332 (5.1640)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:07:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:36 lr 0.000037	 wd 0.0000	time 0.2533 (0.2637)	loss 1.5519 (1.3736)	grad_norm 3.5931 (5.2054)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:07:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:06:08 lr 0.000037	 wd 0.0000	time 0.2501 (0.2629)	loss 1.3432 (1.3773)	grad_norm 6.0935 (5.2392)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:07:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:41 lr 0.000037	 wd 0.0000	time 0.2578 (0.2622)	loss 1.6723 (1.3800)	grad_norm 2.6872 (5.2182)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:08:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:05:14 lr 0.000037	 wd 0.0000	time 0.2501 (0.2616)	loss 0.9975 (1.3776)	grad_norm 4.1981 (5.1926)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:08:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:47 lr 0.000037	 wd 0.0000	time 0.2487 (0.2611)	loss 1.4078 (1.3798)	grad_norm 4.3936 (5.1934)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:09:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:04:21 lr 0.000037	 wd 0.0000	time 0.2537 (0.2607)	loss 1.5691 (1.3822)	grad_norm 4.0888 (5.1632)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:09:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:54 lr 0.000037	 wd 0.0000	time 0.2502 (0.2603)	loss 1.0315 (1.3819)	grad_norm 3.8015 (5.1662)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:09:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:28 lr 0.000037	 wd 0.0000	time 0.2473 (0.2600)	loss 1.0721 (1.3832)	grad_norm 4.4593 (5.1532)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:10:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:03:02 lr 0.000037	 wd 0.0000	time 0.2505 (0.2597)	loss 1.5297 (1.3838)	grad_norm 4.5045 (5.1682)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:10:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:36 lr 0.000037	 wd 0.0000	time 0.2494 (0.2595)	loss 1.4083 (1.3830)	grad_norm 4.1483 (5.1778)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:11:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:02:10 lr 0.000037	 wd 0.0000	time 0.2507 (0.2592)	loss 1.5447 (1.3822)	grad_norm 3.7111 (5.1514)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:11:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:44 lr 0.000036	 wd 0.0000	time 0.2504 (0.2590)	loss 1.2063 (1.3829)	grad_norm 4.7432 (5.1748)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:12:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:18 lr 0.000036	 wd 0.0000	time 0.2510 (0.2589)	loss 1.4849 (1.3843)	grad_norm 5.2350 (5.1685)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:12:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:52 lr 0.000036	 wd 0.0000	time 0.2485 (0.2587)	loss 1.4551 (1.3848)	grad_norm 3.4813 (5.1537)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:12:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:26 lr 0.000036	 wd 0.0000	time 0.2505 (0.2585)	loss 1.2730 (1.3845)	grad_norm 3.5926 (5.1527)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:13:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000036	 wd 0.0000	time 0.2492 (0.2583)	loss 0.9245 (1.3854)	grad_norm 3.2734 (5.1356)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:13:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 9 training takes 0:10:48
[2024-07-03 23:13:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.520 (11.520)	Loss 0.4124 (0.4124)	Acc@1 92.773 (92.773)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-03 23:13:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.672 Acc@5 97.114
[2024-07-03 23:13:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-03 23:13:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.79%
[2024-07-03 23:13:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][0/2502]	eta 7:45:52 lr 0.000036	 wd 0.0000	time 11.1722 (11.1722)	loss 1.3197 (1.3197)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:14:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:14:30 lr 0.000036	 wd 0.0000	time 0.2476 (0.3625)	loss 1.2216 (1.3501)	grad_norm 3.1323 (4.4830)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:14:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:11:48 lr 0.000036	 wd 0.0000	time 0.2489 (0.3080)	loss 1.3984 (1.3774)	grad_norm 7.7709 (4.5869)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:15:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:38 lr 0.000036	 wd 0.0000	time 0.2509 (0.2899)	loss 0.9192 (1.3800)	grad_norm 2.8850 (4.6542)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:15:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:50 lr 0.000036	 wd 0.0000	time 0.2481 (0.2807)	loss 1.6090 (1.3850)	grad_norm 6.3660 (4.7466)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:16:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:09:11 lr 0.000036	 wd 0.0000	time 0.2521 (0.2753)	loss 1.5078 (1.3816)	grad_norm 3.4663 (4.7870)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:16:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:36 lr 0.000036	 wd 0.0000	time 0.2492 (0.2717)	loss 1.6264 (1.3808)	grad_norm 10.0200 (4.8250)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:16:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:08:05 lr 0.000036	 wd 0.0000	time 0.2497 (0.2691)	loss 1.4803 (1.3779)	grad_norm 3.0012 (4.8574)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:17:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:07:34 lr 0.000036	 wd 0.0000	time 0.2508 (0.2673)	loss 1.3194 (1.3790)	grad_norm 3.6875 (4.8082)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:17:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:07:05 lr 0.000036	 wd 0.0000	time 0.2459 (0.2658)	loss 1.5162 (1.3786)	grad_norm 4.1019 (4.7765)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:18:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:37 lr 0.000036	 wd 0.0000	time 0.2500 (0.2647)	loss 1.6053 (1.3765)	grad_norm 3.8875 (4.7570)	loss_scale 1024.0000 (537.5744)	mem 9231MB
[2024-07-03 23:18:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:06:09 lr 0.000036	 wd 0.0000	time 0.2494 (0.2637)	loss 1.3812 (1.3743)	grad_norm 4.1057 (4.7502)	loss_scale 1024.0000 (581.7548)	mem 9231MB
[2024-07-03 23:19:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:42 lr 0.000035	 wd 0.0000	time 0.2499 (0.2630)	loss 1.3021 (1.3749)	grad_norm 4.8836 (4.8783)	loss_scale 1024.0000 (618.5779)	mem 9231MB
[2024-07-03 23:19:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:05:15 lr 0.000035	 wd 0.0000	time 0.2512 (0.2623)	loss 1.5763 (1.3774)	grad_norm 6.3886 (4.9312)	loss_scale 1024.0000 (649.7402)	mem 9231MB
[2024-07-03 23:19:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:48 lr 0.000035	 wd 0.0000	time 0.2504 (0.2618)	loss 1.4739 (1.3795)	grad_norm 4.3735 (4.9495)	loss_scale 1024.0000 (676.4540)	mem 9231MB
[2024-07-03 23:20:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:04:21 lr 0.000035	 wd 0.0000	time 0.2512 (0.2613)	loss 1.3149 (1.3796)	grad_norm 5.0518 (4.9302)	loss_scale 1024.0000 (699.6083)	mem 9231MB
[2024-07-03 23:20:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:55 lr 0.000035	 wd 0.0000	time 0.2535 (0.2609)	loss 1.2480 (1.3808)	grad_norm 5.1522 (4.9322)	loss_scale 1024.0000 (719.8701)	mem 9231MB
[2024-07-03 23:21:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:28 lr 0.000035	 wd 0.0000	time 0.2529 (0.2606)	loss 1.4504 (1.3816)	grad_norm 3.5143 (4.9201)	loss_scale 1024.0000 (737.7496)	mem 9231MB
[2024-07-03 23:21:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:03:02 lr 0.000035	 wd 0.0000	time 0.2508 (0.2602)	loss 1.3524 (1.3816)	grad_norm 5.5898 (4.9453)	loss_scale 1024.0000 (753.6435)	mem 9231MB
[2024-07-03 23:22:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:36 lr 0.000035	 wd 0.0000	time 0.2523 (0.2600)	loss 1.4799 (1.3823)	grad_norm 8.8567 (4.9413)	loss_scale 1024.0000 (767.8653)	mem 9231MB
[2024-07-03 23:22:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:02:10 lr 0.000035	 wd 0.0000	time 0.2516 (0.2597)	loss 1.3354 (1.3826)	grad_norm 4.1873 (4.9189)	loss_scale 1024.0000 (780.6657)	mem 9231MB
[2024-07-03 23:22:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:44 lr 0.000035	 wd 0.0000	time 0.2510 (0.2595)	loss 1.5309 (1.3840)	grad_norm 7.0462 (4.8916)	loss_scale 1024.0000 (792.2475)	mem 9231MB
[2024-07-03 23:23:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:18 lr 0.000035	 wd 0.0000	time 0.2496 (0.2593)	loss 1.0122 (1.3845)	grad_norm 3.7355 (4.8937)	loss_scale 1024.0000 (802.7769)	mem 9231MB
[2024-07-03 23:23:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:52 lr 0.000035	 wd 0.0000	time 0.2500 (0.2591)	loss 1.4848 (1.3839)	grad_norm 4.2888 (4.9089)	loss_scale 1024.0000 (812.3911)	mem 9231MB
[2024-07-03 23:24:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:26 lr 0.000035	 wd 0.0000	time 0.2568 (0.2590)	loss 1.4798 (1.3840)	grad_norm 5.7334 (4.9132)	loss_scale 1024.0000 (821.2045)	mem 9231MB
[2024-07-03 23:24:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.2500 (0.2588)	loss 1.5363 (1.3836)	grad_norm 4.3312 (4.9173)	loss_scale 1024.0000 (829.3131)	mem 9231MB
[2024-07-03 23:24:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 10 training takes 0:10:50
[2024-07-03 23:24:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.447 (11.447)	Loss 0.4175 (0.4175)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-03 23:25:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.732 Acc@5 97.130
[2024-07-03 23:25:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-03 23:25:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.79%
[2024-07-03 23:25:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][0/2502]	eta 7:33:49 lr 0.000035	 wd 0.0000	time 10.8832 (10.8832)	loss 1.5864 (1.5864)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:25:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:14:26 lr 0.000035	 wd 0.0000	time 0.2486 (0.3609)	loss 1.3818 (1.3804)	grad_norm 7.6340 (5.7660)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:26:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:11:47 lr 0.000034	 wd 0.0000	time 0.2504 (0.3072)	loss 1.5666 (1.3843)	grad_norm 4.2692 (5.2782)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:26:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:10:36 lr 0.000034	 wd 0.0000	time 0.2526 (0.2893)	loss 1.2819 (1.3841)	grad_norm 7.9043 (5.0425)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:26:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:09:49 lr 0.000034	 wd 0.0000	time 0.2496 (0.2803)	loss 1.5074 (1.3889)	grad_norm 9.3961 (5.0498)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:27:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:09:10 lr 0.000034	 wd 0.0000	time 0.2466 (0.2749)	loss 1.3366 (1.3817)	grad_norm 3.5317 (4.9094)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:27:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:36 lr 0.000034	 wd 0.0000	time 0.2494 (0.2714)	loss 1.4410 (1.3795)	grad_norm 3.2188 (4.8922)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:28:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:08:04 lr 0.000034	 wd 0.0000	time 0.2549 (0.2689)	loss 1.4213 (1.3798)	grad_norm 3.4350 (4.9332)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:28:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:07:34 lr 0.000034	 wd 0.0000	time 0.2509 (0.2670)	loss 1.7152 (1.3827)	grad_norm 14.2978 (4.9893)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:29:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:07:05 lr 0.000034	 wd 0.0000	time 0.2488 (0.2656)	loss 1.5466 (1.3833)	grad_norm 4.2016 (5.0321)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:29:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:37 lr 0.000034	 wd 0.0000	time 0.2509 (0.2645)	loss 1.5085 (1.3831)	grad_norm 3.2686 (4.9860)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:29:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:06:09 lr 0.000034	 wd 0.0000	time 0.2472 (0.2636)	loss 1.4300 (1.3852)	grad_norm 5.7372 (4.9504)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:30:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:42 lr 0.000034	 wd 0.0000	time 0.2490 (0.2628)	loss 1.6408 (1.3857)	grad_norm 4.9760 (4.9618)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:30:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:05:15 lr 0.000034	 wd 0.0000	time 0.2503 (0.2622)	loss 1.0815 (1.3839)	grad_norm 2.8236 (4.9845)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:31:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:48 lr 0.000034	 wd 0.0000	time 0.2514 (0.2617)	loss 0.9906 (1.3838)	grad_norm 3.9536 (4.9841)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:31:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:04:21 lr 0.000034	 wd 0.0000	time 0.2491 (0.2612)	loss 1.4759 (1.3830)	grad_norm 3.2630 (4.9974)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:31:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:55 lr 0.000034	 wd 0.0000	time 0.2526 (0.2608)	loss 1.2767 (1.3842)	grad_norm 4.0284 (4.9930)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:32:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:28 lr 0.000033	 wd 0.0000	time 0.2507 (0.2604)	loss 1.3949 (1.3829)	grad_norm 3.6502 (5.0042)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:32:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:03:02 lr 0.000033	 wd 0.0000	time 0.2533 (0.2601)	loss 1.3452 (1.3847)	grad_norm 5.9598 (4.9947)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:33:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:36 lr 0.000033	 wd 0.0000	time 0.2492 (0.2599)	loss 1.5653 (1.3845)	grad_norm 3.6197 (5.0481)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:33:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:02:10 lr 0.000033	 wd 0.0000	time 0.2513 (0.2597)	loss 1.2319 (1.3842)	grad_norm 4.7676 (5.0299)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:34:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:44 lr 0.000033	 wd 0.0000	time 0.2540 (0.2595)	loss 1.4259 (1.3835)	grad_norm 3.2334 (5.0408)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:34:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:18 lr 0.000033	 wd 0.0000	time 0.2500 (0.2593)	loss 1.4249 (1.3849)	grad_norm 3.6978 (5.0402)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:34:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:52 lr 0.000033	 wd 0.0000	time 0.2505 (0.2591)	loss 1.5570 (1.3843)	grad_norm 3.5479 (5.0385)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:35:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:26 lr 0.000033	 wd 0.0000	time 0.2522 (0.2590)	loss 1.3908 (1.3836)	grad_norm 7.7464 (5.0868)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:35:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000033	 wd 0.0000	time 0.2499 (0.2588)	loss 1.4255 (1.3836)	grad_norm 5.0716 (5.0843)	loss_scale 2048.0000 (1045.2907)	mem 9231MB
[2024-07-03 23:35:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 11 training takes 0:10:50
[2024-07-03 23:36:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.702 (11.702)	Loss 0.4099 (0.4099)	Acc@1 93.359 (93.359)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-03 23:36:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.778 Acc@5 97.150
[2024-07-03 23:36:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-03 23:36:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.79%
[2024-07-03 23:36:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][0/2502]	eta 7:39:11 lr 0.000033	 wd 0.0000	time 11.0117 (11.0117)	loss 1.6506 (1.6506)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 9231MB
[2024-07-03 23:36:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:14:34 lr 0.000033	 wd 0.0000	time 0.2496 (0.3639)	loss 1.5623 (1.3823)	grad_norm 4.6133 (4.8146)	loss_scale 2048.0000 (2048.0000)	mem 9231MB
[2024-07-03 23:37:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:11:50 lr 0.000033	 wd 0.0000	time 0.2495 (0.3088)	loss 0.9086 (1.3866)	grad_norm 3.1906 (5.1525)	loss_scale 2048.0000 (2048.0000)	mem 9231MB
[2024-07-03 23:37:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:39 lr 0.000033	 wd 0.0000	time 0.2488 (0.2905)	loss 1.3393 (1.3883)	grad_norm 8.4235 (4.9480)	loss_scale 2048.0000 (2048.0000)	mem 9231MB
[2024-07-03 23:38:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:51 lr 0.000033	 wd 0.0000	time 0.2504 (0.2813)	loss 1.3422 (1.3815)	grad_norm 12.9265 (nan)	loss_scale 1024.0000 (1807.9601)	mem 9231MB
[2024-07-03 23:38:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:09:12 lr 0.000032	 wd 0.0000	time 0.2486 (0.2757)	loss 1.1323 (1.3826)	grad_norm 4.4405 (nan)	loss_scale 1024.0000 (1651.4810)	mem 9231MB
[2024-07-03 23:38:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:08:37 lr 0.000032	 wd 0.0000	time 0.2505 (0.2722)	loss 1.3943 (1.3798)	grad_norm 3.8719 (nan)	loss_scale 1024.0000 (1547.0749)	mem 9231MB
[2024-07-03 23:39:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:08:05 lr 0.000032	 wd 0.0000	time 0.2486 (0.2696)	loss 1.4600 (1.3793)	grad_norm 3.8195 (nan)	loss_scale 1024.0000 (1472.4565)	mem 9231MB
[2024-07-03 23:39:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:07:35 lr 0.000032	 wd 0.0000	time 0.2505 (0.2677)	loss 1.7053 (1.3885)	grad_norm 3.7465 (nan)	loss_scale 1024.0000 (1416.4694)	mem 9231MB
[2024-07-03 23:40:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:07:06 lr 0.000032	 wd 0.0000	time 0.2514 (0.2662)	loss 1.0989 (1.3905)	grad_norm 6.9763 (nan)	loss_scale 1024.0000 (1372.9101)	mem 9231MB
[2024-07-03 23:40:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:38 lr 0.000032	 wd 0.0000	time 0.2506 (0.2650)	loss 1.4727 (1.3889)	grad_norm 7.4729 (nan)	loss_scale 1024.0000 (1338.0539)	mem 9231MB
[2024-07-03 23:41:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:06:10 lr 0.000032	 wd 0.0000	time 0.2522 (0.2640)	loss 1.5528 (1.3939)	grad_norm 4.2765 (nan)	loss_scale 1024.0000 (1309.5295)	mem 9231MB
[2024-07-03 23:41:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:42 lr 0.000032	 wd 0.0000	time 0.2509 (0.2632)	loss 1.6392 (1.3922)	grad_norm 3.7511 (nan)	loss_scale 1024.0000 (1285.7552)	mem 9231MB
[2024-07-03 23:41:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:05:15 lr 0.000032	 wd 0.0000	time 0.2495 (0.2625)	loss 1.5885 (1.3922)	grad_norm 4.0473 (nan)	loss_scale 1024.0000 (1265.6357)	mem 9231MB
[2024-07-03 23:42:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:48 lr 0.000032	 wd 0.0000	time 0.2472 (0.2620)	loss 1.6251 (1.3923)	grad_norm 8.8987 (nan)	loss_scale 1024.0000 (1248.3883)	mem 9231MB
[2024-07-03 23:42:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:04:21 lr 0.000032	 wd 0.0000	time 0.2503 (0.2615)	loss 1.5069 (1.3932)	grad_norm 3.4259 (nan)	loss_scale 1024.0000 (1233.4390)	mem 9231MB
[2024-07-03 23:43:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:55 lr 0.000032	 wd 0.0000	time 0.2498 (0.2610)	loss 1.5185 (1.3916)	grad_norm 3.6733 (nan)	loss_scale 1024.0000 (1220.3573)	mem 9231MB
[2024-07-03 23:43:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:29 lr 0.000031	 wd 0.0000	time 0.2496 (0.2607)	loss 1.4512 (1.3929)	grad_norm 6.6837 (nan)	loss_scale 1024.0000 (1208.8136)	mem 9231MB
[2024-07-03 23:44:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:03:02 lr 0.000031	 wd 0.0000	time 0.2503 (0.2604)	loss 1.3720 (1.3938)	grad_norm 4.9489 (nan)	loss_scale 1024.0000 (1198.5519)	mem 9231MB
[2024-07-03 23:44:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:36 lr 0.000031	 wd 0.0000	time 0.2508 (0.2601)	loss 1.3129 (1.3935)	grad_norm 4.6610 (nan)	loss_scale 1024.0000 (1189.3698)	mem 9231MB
[2024-07-03 23:44:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:02:10 lr 0.000031	 wd 0.0000	time 0.2567 (0.2599)	loss 1.4464 (1.3930)	grad_norm 3.0006 (nan)	loss_scale 1024.0000 (1181.1054)	mem 9231MB
[2024-07-03 23:45:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:44 lr 0.000031	 wd 0.0000	time 0.2507 (0.2597)	loss 1.5439 (1.3935)	grad_norm 6.2046 (nan)	loss_scale 1024.0000 (1173.6278)	mem 9231MB
[2024-07-03 23:45:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:18 lr 0.000031	 wd 0.0000	time 0.2511 (0.2595)	loss 1.5453 (1.3943)	grad_norm 3.1575 (nan)	loss_scale 1024.0000 (1166.8296)	mem 9231MB
[2024-07-03 23:46:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:52 lr 0.000031	 wd 0.0000	time 0.2537 (0.2593)	loss 1.4150 (1.3940)	grad_norm 6.2500 (nan)	loss_scale 1024.0000 (1160.6223)	mem 9231MB
[2024-07-03 23:46:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:26 lr 0.000031	 wd 0.0000	time 0.2489 (0.2591)	loss 1.5564 (1.3937)	grad_norm 6.1581 (nan)	loss_scale 1024.0000 (1154.9321)	mem 9231MB
[2024-07-03 23:47:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000031	 wd 0.0000	time 0.2485 (0.2589)	loss 1.1206 (1.3921)	grad_norm 3.2461 (nan)	loss_scale 1024.0000 (1149.6969)	mem 9231MB
[2024-07-03 23:47:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 12 training takes 0:10:50
[2024-07-03 23:47:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.174 (11.174)	Loss 0.4106 (0.4106)	Acc@1 92.969 (92.969)	Acc@5 98.242 (98.242)	Mem 9231MB
[2024-07-03 23:47:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.834 Acc@5 97.152
[2024-07-03 23:47:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-03 23:47:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.83%
[2024-07-03 23:47:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth saving......
[2024-07-03 23:47:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth saved !!!
[2024-07-03 23:47:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][0/2502]	eta 7:25:19 lr 0.000031	 wd 0.0000	time 10.6792 (10.6792)	loss 1.3897 (1.3897)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:48:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:14:18 lr 0.000031	 wd 0.0000	time 0.2475 (0.3572)	loss 1.5045 (1.3846)	grad_norm 5.7611 (5.4204)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:48:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:11:43 lr 0.000031	 wd 0.0000	time 0.2502 (0.3055)	loss 1.6668 (1.3868)	grad_norm 5.6010 (5.0621)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:48:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:10:34 lr 0.000031	 wd 0.0000	time 0.2492 (0.2882)	loss 1.5461 (1.3928)	grad_norm 3.6431 (4.8959)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:49:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:09:47 lr 0.000030	 wd 0.0000	time 0.2518 (0.2795)	loss 1.4797 (1.3891)	grad_norm 4.2447 (4.8429)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:49:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:09:09 lr 0.000030	 wd 0.0000	time 0.2527 (0.2743)	loss 1.5237 (1.3840)	grad_norm 3.9522 (4.8635)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:50:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:35 lr 0.000030	 wd 0.0000	time 0.2507 (0.2709)	loss 1.5213 (1.3883)	grad_norm 3.7680 (4.8221)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:50:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:08:03 lr 0.000030	 wd 0.0000	time 0.2546 (0.2685)	loss 1.7201 (1.3840)	grad_norm 6.2969 (4.7599)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:51:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:34 lr 0.000030	 wd 0.0000	time 0.2503 (0.2667)	loss 1.5497 (1.3873)	grad_norm 7.3089 (4.7633)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-03 23:51:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:07:05 lr 0.000030	 wd 0.0000	time 0.2506 (0.2653)	loss 1.6830 (1.3829)	grad_norm 7.3060 (nan)	loss_scale 512.0000 (1002.4062)	mem 9231MB
[2024-07-03 23:51:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:36 lr 0.000030	 wd 0.0000	time 0.2496 (0.2642)	loss 1.5531 (1.3858)	grad_norm 6.5882 (nan)	loss_scale 512.0000 (953.4146)	mem 9231MB
[2024-07-03 23:52:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:06:09 lr 0.000030	 wd 0.0000	time 0.2503 (0.2633)	loss 1.4848 (1.3881)	grad_norm 3.2224 (nan)	loss_scale 512.0000 (913.3224)	mem 9231MB
[2024-07-03 23:52:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:41 lr 0.000030	 wd 0.0000	time 0.2498 (0.2626)	loss 1.6918 (1.3855)	grad_norm 3.1456 (nan)	loss_scale 512.0000 (879.9067)	mem 9231MB
[2024-07-03 23:53:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:05:14 lr 0.000030	 wd 0.0000	time 0.2509 (0.2620)	loss 1.5928 (1.3847)	grad_norm 3.2856 (nan)	loss_scale 512.0000 (851.6280)	mem 9231MB
[2024-07-03 23:53:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:48 lr 0.000030	 wd 0.0000	time 0.2514 (0.2614)	loss 1.6613 (1.3854)	grad_norm 4.4168 (nan)	loss_scale 512.0000 (827.3862)	mem 9231MB
[2024-07-03 23:54:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:04:21 lr 0.000030	 wd 0.0000	time 0.2487 (0.2610)	loss 1.5928 (1.3848)	grad_norm 10.5731 (nan)	loss_scale 512.0000 (806.3744)	mem 9231MB
[2024-07-03 23:54:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:55 lr 0.000029	 wd 0.0000	time 0.2505 (0.2606)	loss 1.5202 (1.3846)	grad_norm 5.4884 (nan)	loss_scale 512.0000 (787.9875)	mem 9231MB
[2024-07-03 23:54:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:28 lr 0.000029	 wd 0.0000	time 0.2511 (0.2603)	loss 0.9001 (1.3821)	grad_norm 3.9310 (nan)	loss_scale 512.0000 (771.7625)	mem 9231MB
[2024-07-03 23:55:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:03:02 lr 0.000029	 wd 0.0000	time 0.2501 (0.2600)	loss 1.4572 (1.3835)	grad_norm 4.3457 (nan)	loss_scale 512.0000 (757.3393)	mem 9231MB
[2024-07-03 23:55:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:36 lr 0.000029	 wd 0.0000	time 0.2543 (0.2598)	loss 1.1680 (1.3838)	grad_norm 3.9170 (nan)	loss_scale 512.0000 (744.4335)	mem 9231MB
[2024-07-03 23:56:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:02:10 lr 0.000029	 wd 0.0000	time 0.2516 (0.2596)	loss 1.4172 (1.3842)	grad_norm 4.2238 (nan)	loss_scale 512.0000 (732.8176)	mem 9231MB
[2024-07-03 23:56:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:44 lr 0.000029	 wd 0.0000	time 0.2500 (0.2594)	loss 1.1766 (1.3838)	grad_norm 5.0956 (nan)	loss_scale 512.0000 (722.3075)	mem 9231MB
[2024-07-03 23:57:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:18 lr 0.000029	 wd 0.0000	time 0.2497 (0.2592)	loss 1.5719 (1.3857)	grad_norm 3.9046 (nan)	loss_scale 512.0000 (712.7524)	mem 9231MB
[2024-07-03 23:57:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:52 lr 0.000029	 wd 0.0000	time 0.2499 (0.2590)	loss 1.3875 (1.3848)	grad_norm 4.6316 (nan)	loss_scale 512.0000 (704.0278)	mem 9231MB
[2024-07-03 23:57:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:26 lr 0.000029	 wd 0.0000	time 0.2508 (0.2588)	loss 1.4925 (1.3856)	grad_norm 5.7404 (nan)	loss_scale 512.0000 (696.0300)	mem 9231MB
[2024-07-03 23:58:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000029	 wd 0.0000	time 0.2491 (0.2586)	loss 1.5019 (1.3851)	grad_norm 4.5937 (nan)	loss_scale 512.0000 (688.6717)	mem 9231MB
[2024-07-03 23:58:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 13 training takes 0:10:49
[2024-07-03 23:58:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.155 (11.155)	Loss 0.4153 (0.4153)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-03 23:58:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.834 Acc@5 97.154
[2024-07-03 23:58:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-03 23:58:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.83%
[2024-07-03 23:58:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth saving......
[2024-07-03 23:58:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth saved !!!
[2024-07-03 23:58:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][0/2502]	eta 7:23:56 lr 0.000029	 wd 0.0000	time 10.6462 (10.6462)	loss 1.5614 (1.5614)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:59:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:14:22 lr 0.000029	 wd 0.0000	time 0.2508 (0.3592)	loss 1.5169 (1.3829)	grad_norm 13.0888 (4.8033)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-03 23:59:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:11:45 lr 0.000028	 wd 0.0000	time 0.2475 (0.3065)	loss 1.2684 (1.4072)	grad_norm 3.9023 (4.6861)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:00:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:10:36 lr 0.000028	 wd 0.0000	time 0.2493 (0.2888)	loss 1.1833 (1.3966)	grad_norm 4.5715 (4.7459)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:00:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:09:48 lr 0.000028	 wd 0.0000	time 0.2491 (0.2800)	loss 1.2613 (1.3838)	grad_norm 3.4910 (4.7249)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:01:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:09:09 lr 0.000028	 wd 0.0000	time 0.2521 (0.2747)	loss 1.4306 (1.3848)	grad_norm 3.4254 (4.8203)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:01:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:08:35 lr 0.000028	 wd 0.0000	time 0.2501 (0.2712)	loss 1.6107 (1.3885)	grad_norm 4.4610 (4.8295)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:01:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:08:04 lr 0.000028	 wd 0.0000	time 0.2504 (0.2688)	loss 1.3611 (1.3850)	grad_norm 4.1500 (4.9621)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:02:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:34 lr 0.000028	 wd 0.0000	time 0.2512 (0.2669)	loss 1.3539 (1.3816)	grad_norm 3.9066 (4.9212)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:02:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:07:05 lr 0.000028	 wd 0.0000	time 0.2528 (0.2655)	loss 1.6037 (1.3800)	grad_norm 6.7805 (4.9042)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:03:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:06:37 lr 0.000028	 wd 0.0000	time 0.2551 (0.2644)	loss 1.1662 (1.3783)	grad_norm 4.4379 (4.9224)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:03:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:06:09 lr 0.000028	 wd 0.0000	time 0.2500 (0.2635)	loss 1.4161 (1.3759)	grad_norm 2.9463 (4.9758)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:03:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:42 lr 0.000028	 wd 0.0000	time 0.2504 (0.2628)	loss 1.5096 (1.3759)	grad_norm 3.9931 (4.9848)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:04:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:05:15 lr 0.000027	 wd 0.0000	time 0.2486 (0.2621)	loss 1.2589 (1.3774)	grad_norm 3.9879 (4.9799)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:04:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:48 lr 0.000027	 wd 0.0000	time 0.2508 (0.2616)	loss 1.5287 (1.3766)	grad_norm 4.4577 (4.9404)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:05:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:04:21 lr 0.000027	 wd 0.0000	time 0.2464 (0.2612)	loss 1.3907 (1.3774)	grad_norm 3.4754 (5.0061)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:05:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:55 lr 0.000027	 wd 0.0000	time 0.2466 (0.2608)	loss 1.3624 (1.3782)	grad_norm 9.5734 (5.0439)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:06:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:28 lr 0.000027	 wd 0.0000	time 0.2501 (0.2604)	loss 1.2568 (1.3786)	grad_norm 17.2202 (5.0355)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:06:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:03:02 lr 0.000027	 wd 0.0000	time 0.2504 (0.2601)	loss 1.3228 (1.3780)	grad_norm 4.5577 (5.0476)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:06:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:36 lr 0.000027	 wd 0.0000	time 0.2514 (0.2599)	loss 1.4473 (1.3780)	grad_norm 5.1661 (5.0301)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:07:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:02:10 lr 0.000027	 wd 0.0000	time 0.2529 (0.2596)	loss 1.0798 (1.3795)	grad_norm 4.5392 (5.0010)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:07:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:44 lr 0.000027	 wd 0.0000	time 0.2548 (0.2594)	loss 1.6828 (1.3786)	grad_norm 7.3753 (5.0184)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:08:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:18 lr 0.000027	 wd 0.0000	time 0.2500 (0.2593)	loss 1.2734 (1.3788)	grad_norm 2.8851 (5.0106)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:08:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:52 lr 0.000027	 wd 0.0000	time 0.2487 (0.2591)	loss 1.3969 (1.3797)	grad_norm 4.7545 (5.0027)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:09:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:26 lr 0.000026	 wd 0.0000	time 0.2494 (0.2589)	loss 1.2848 (1.3807)	grad_norm 4.2368 (4.9955)	loss_scale 1024.0000 (520.5298)	mem 9231MB
[2024-07-04 00:09:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.2501 (0.2588)	loss 1.3881 (1.3799)	grad_norm 6.3467 (5.0241)	loss_scale 1024.0000 (540.6605)	mem 9231MB
[2024-07-04 00:09:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 14 training takes 0:10:49
[2024-07-04 00:09:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 10.925 (10.925)	Loss 0.4119 (0.4119)	Acc@1 93.359 (93.359)	Acc@5 98.633 (98.633)	Mem 9231MB
[2024-07-04 00:09:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.808 Acc@5 97.180
[2024-07-04 00:09:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-04 00:09:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.83%
[2024-07-04 00:10:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][0/2502]	eta 7:36:25 lr 0.000026	 wd 0.0000	time 10.9454 (10.9454)	loss 1.4318 (1.4318)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:10:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:14:28 lr 0.000026	 wd 0.0000	time 0.2496 (0.3614)	loss 1.1046 (1.3708)	grad_norm 5.3849 (4.8619)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:10:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:11:48 lr 0.000026	 wd 0.0000	time 0.2497 (0.3076)	loss 1.5359 (1.3811)	grad_norm 4.4261 (5.0732)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:11:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:10:37 lr 0.000026	 wd 0.0000	time 0.2486 (0.2896)	loss 1.3820 (1.3682)	grad_norm 2.8591 (5.0951)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:11:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:09:49 lr 0.000026	 wd 0.0000	time 0.2505 (0.2805)	loss 1.3821 (1.3719)	grad_norm 5.3603 (5.0051)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:12:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:09:10 lr 0.000026	 wd 0.0000	time 0.2499 (0.2751)	loss 0.9231 (1.3668)	grad_norm 3.7174 (5.0103)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:12:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:08:36 lr 0.000026	 wd 0.0000	time 0.2500 (0.2715)	loss 0.9223 (1.3697)	grad_norm 4.8667 (5.1755)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:13:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:08:04 lr 0.000026	 wd 0.0000	time 0.2493 (0.2690)	loss 1.1762 (1.3735)	grad_norm 4.6068 (5.1112)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:13:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:07:34 lr 0.000026	 wd 0.0000	time 0.2547 (0.2671)	loss 1.5585 (1.3745)	grad_norm 3.1429 (5.1070)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:13:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:07:05 lr 0.000025	 wd 0.0000	time 0.2544 (0.2657)	loss 1.2043 (1.3738)	grad_norm 4.5218 (5.0764)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:14:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:06:37 lr 0.000025	 wd 0.0000	time 0.2533 (0.2646)	loss 1.3829 (1.3741)	grad_norm 3.1367 (5.0380)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:14:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:06:09 lr 0.000025	 wd 0.0000	time 0.2496 (0.2637)	loss 1.3622 (1.3710)	grad_norm 3.1944 (4.9956)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:15:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:42 lr 0.000025	 wd 0.0000	time 0.2503 (0.2629)	loss 1.6011 (1.3712)	grad_norm 8.3000 (5.0280)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:15:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:05:15 lr 0.000025	 wd 0.0000	time 0.2527 (0.2622)	loss 1.3796 (1.3700)	grad_norm 3.9467 (5.0404)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:16:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:48 lr 0.000025	 wd 0.0000	time 0.2498 (0.2617)	loss 1.3690 (1.3710)	grad_norm 9.4701 (5.0827)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:16:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:04:21 lr 0.000025	 wd 0.0000	time 0.2496 (0.2612)	loss 1.6600 (1.3704)	grad_norm 3.9664 (5.0842)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:16:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:55 lr 0.000025	 wd 0.0000	time 0.2506 (0.2608)	loss 1.2581 (1.3729)	grad_norm 3.3112 (5.0603)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:17:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:28 lr 0.000025	 wd 0.0000	time 0.2510 (0.2605)	loss 1.5725 (1.3733)	grad_norm 4.0534 (5.0632)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:17:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:03:02 lr 0.000025	 wd 0.0000	time 0.2501 (0.2602)	loss 1.1043 (1.3730)	grad_norm 4.3141 (5.0434)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:18:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:36 lr 0.000024	 wd 0.0000	time 0.2502 (0.2599)	loss 1.6524 (1.3743)	grad_norm 11.5430 (5.0370)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:18:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:02:10 lr 0.000024	 wd 0.0000	time 0.2501 (0.2597)	loss 1.8042 (1.3771)	grad_norm 4.4118 (5.0231)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:19:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:44 lr 0.000024	 wd 0.0000	time 0.2496 (0.2595)	loss 1.6416 (1.3778)	grad_norm 4.7774 (5.0559)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:19:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:18 lr 0.000024	 wd 0.0000	time 0.2472 (0.2593)	loss 0.9573 (1.3788)	grad_norm 3.7323 (5.0426)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:19:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:52 lr 0.000024	 wd 0.0000	time 0.2519 (0.2591)	loss 1.5796 (1.3791)	grad_norm 6.8853 (5.0444)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:20:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:26 lr 0.000024	 wd 0.0000	time 0.2513 (0.2589)	loss 1.2011 (1.3781)	grad_norm 4.4239 (5.0382)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:20:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.2503 (0.2587)	loss 1.4418 (1.3784)	grad_norm 3.0301 (5.0348)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:20:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 15 training takes 0:10:50
[2024-07-04 00:20:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_15.pth saving......
[2024-07-04 00:20:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_15.pth saved !!!
[2024-07-04 00:20:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 10.614 (10.614)	Loss 0.4099 (0.4099)	Acc@1 93.164 (93.164)	Acc@5 98.242 (98.242)	Mem 9231MB
[2024-07-04 00:21:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.808 Acc@5 97.144
[2024-07-04 00:21:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-04 00:21:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.83%
[2024-07-04 00:21:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][0/2502]	eta 7:56:59 lr 0.000024	 wd 0.0000	time 11.4386 (11.4386)	loss 1.2226 (1.2226)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:21:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:14:35 lr 0.000024	 wd 0.0000	time 0.2496 (0.3645)	loss 1.5480 (1.3883)	grad_norm 3.3655 (4.6624)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:22:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:11:51 lr 0.000024	 wd 0.0000	time 0.2490 (0.3092)	loss 1.3534 (1.3933)	grad_norm 5.1645 (4.8749)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:22:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:10:39 lr 0.000024	 wd 0.0000	time 0.2435 (0.2906)	loss 1.3699 (1.4008)	grad_norm 6.9381 (4.9893)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:23:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:09:51 lr 0.000024	 wd 0.0000	time 0.2488 (0.2813)	loss 1.2398 (1.3953)	grad_norm 15.5205 (5.1111)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:23:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:09:12 lr 0.000023	 wd 0.0000	time 0.2494 (0.2757)	loss 1.4377 (1.4031)	grad_norm 5.4127 (4.9781)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:23:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:37 lr 0.000023	 wd 0.0000	time 0.2511 (0.2721)	loss 1.0931 (1.3943)	grad_norm 3.3233 (4.9439)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:24:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:08:05 lr 0.000023	 wd 0.0000	time 0.2500 (0.2695)	loss 1.3536 (1.3955)	grad_norm 5.0931 (4.9808)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:24:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:07:35 lr 0.000023	 wd 0.0000	time 0.2535 (0.2676)	loss 1.3840 (1.3893)	grad_norm 5.2998 (4.9755)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:25:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:07:06 lr 0.000023	 wd 0.0000	time 0.2503 (0.2662)	loss 1.3314 (1.3881)	grad_norm 3.2259 (4.9981)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:25:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:06:38 lr 0.000023	 wd 0.0000	time 0.2506 (0.2650)	loss 1.4708 (1.3881)	grad_norm 4.9831 (5.0086)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:26:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:06:10 lr 0.000023	 wd 0.0000	time 0.2495 (0.2640)	loss 1.3724 (1.3903)	grad_norm 8.4267 (5.0132)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:26:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:42 lr 0.000023	 wd 0.0000	time 0.2541 (0.2632)	loss 1.5772 (1.3896)	grad_norm 5.1935 (4.9792)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:26:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:05:15 lr 0.000023	 wd 0.0000	time 0.2533 (0.2625)	loss 1.0908 (1.3898)	grad_norm 3.0862 (4.9713)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 00:27:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:48 lr 0.000023	 wd 0.0000	time 0.2500 (0.2620)	loss 1.3295 (1.3873)	grad_norm 3.2331 (nan)	loss_scale 1024.0000 (1051.7744)	mem 9231MB
[2024-07-04 00:27:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:04:22 lr 0.000022	 wd 0.0000	time 0.2499 (0.2615)	loss 1.4303 (1.3846)	grad_norm 4.5531 (nan)	loss_scale 1024.0000 (1049.9241)	mem 9231MB
[2024-07-04 00:28:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:55 lr 0.000022	 wd 0.0000	time 0.2546 (0.2611)	loss 1.4723 (1.3841)	grad_norm 5.2100 (nan)	loss_scale 1024.0000 (1048.3048)	mem 9231MB
[2024-07-04 00:28:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:29 lr 0.000022	 wd 0.0000	time 0.2546 (0.2607)	loss 1.1149 (1.3823)	grad_norm 15.6942 (nan)	loss_scale 1024.0000 (1046.8760)	mem 9231MB
[2024-07-04 00:29:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:03:02 lr 0.000022	 wd 0.0000	time 0.2494 (0.2604)	loss 1.1479 (1.3813)	grad_norm 5.2825 (nan)	loss_scale 1024.0000 (1045.6058)	mem 9231MB
[2024-07-04 00:29:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:36 lr 0.000022	 wd 0.0000	time 0.2503 (0.2602)	loss 1.2965 (1.3807)	grad_norm 4.8042 (nan)	loss_scale 1024.0000 (1044.4692)	mem 9231MB
[2024-07-04 00:29:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:02:10 lr 0.000022	 wd 0.0000	time 0.2530 (0.2599)	loss 1.5913 (1.3806)	grad_norm 7.8709 (nan)	loss_scale 1024.0000 (1043.4463)	mem 9231MB
[2024-07-04 00:30:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:44 lr 0.000022	 wd 0.0000	time 0.2502 (0.2597)	loss 1.4860 (1.3801)	grad_norm 5.5688 (nan)	loss_scale 1024.0000 (1042.5207)	mem 9231MB
[2024-07-04 00:30:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:18 lr 0.000022	 wd 0.0000	time 0.2495 (0.2595)	loss 1.3556 (1.3808)	grad_norm 3.4843 (nan)	loss_scale 1024.0000 (1041.6792)	mem 9231MB
[2024-07-04 00:31:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:52 lr 0.000022	 wd 0.0000	time 0.2517 (0.2593)	loss 1.3054 (1.3812)	grad_norm 6.3538 (nan)	loss_scale 1024.0000 (1040.9109)	mem 9231MB
[2024-07-04 00:31:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:26 lr 0.000022	 wd 0.0000	time 0.2568 (0.2591)	loss 1.3880 (1.3810)	grad_norm 10.4122 (nan)	loss_scale 512.0000 (1021.0146)	mem 9231MB
[2024-07-04 00:31:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.2493 (0.2589)	loss 1.4278 (1.3807)	grad_norm 4.7846 (nan)	loss_scale 512.0000 (1000.6621)	mem 9231MB
[2024-07-04 00:32:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 16 training takes 0:10:50
[2024-07-04 00:32:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.758 (11.758)	Loss 0.4084 (0.4084)	Acc@1 93.359 (93.359)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-04 00:32:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.818 Acc@5 97.148
[2024-07-04 00:32:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-04 00:32:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.83%
[2024-07-04 00:32:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][0/2502]	eta 7:47:24 lr 0.000021	 wd 0.0000	time 11.2089 (11.2089)	loss 1.4928 (1.4928)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:33:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:14:31 lr 0.000021	 wd 0.0000	time 0.2484 (0.3628)	loss 1.5922 (1.3600)	grad_norm 3.6556 (4.8481)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:33:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:11:49 lr 0.000021	 wd 0.0000	time 0.2497 (0.3082)	loss 1.5634 (1.3749)	grad_norm 5.1511 (4.9410)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:33:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:38 lr 0.000021	 wd 0.0000	time 0.2488 (0.2899)	loss 1.4090 (1.3715)	grad_norm 6.3573 (5.0529)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:34:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:09:50 lr 0.000021	 wd 0.0000	time 0.2499 (0.2809)	loss 1.1488 (1.3700)	grad_norm 3.5730 (4.9352)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:34:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:09:11 lr 0.000021	 wd 0.0000	time 0.2505 (0.2755)	loss 1.4105 (1.3672)	grad_norm 4.8708 (4.9512)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:35:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:37 lr 0.000021	 wd 0.0000	time 0.2498 (0.2719)	loss 1.1839 (1.3726)	grad_norm 3.5640 (5.0612)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:35:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:08:05 lr 0.000021	 wd 0.0000	time 0.2493 (0.2693)	loss 1.3696 (1.3771)	grad_norm 3.9825 (5.2229)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:35:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:07:35 lr 0.000021	 wd 0.0000	time 0.2499 (0.2674)	loss 1.3575 (1.3804)	grad_norm 7.0516 (5.1385)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:36:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:07:06 lr 0.000021	 wd 0.0000	time 0.2496 (0.2660)	loss 1.4835 (1.3830)	grad_norm 8.1622 (5.0582)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:36:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:37 lr 0.000020	 wd 0.0000	time 0.2518 (0.2647)	loss 1.5559 (1.3808)	grad_norm 4.2377 (5.0339)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:37:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:06:09 lr 0.000020	 wd 0.0000	time 0.2495 (0.2638)	loss 1.1885 (1.3792)	grad_norm 3.6494 (5.0040)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:37:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:42 lr 0.000020	 wd 0.0000	time 0.2498 (0.2630)	loss 1.4352 (1.3817)	grad_norm 3.6003 (5.0204)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:38:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:05:15 lr 0.000020	 wd 0.0000	time 0.2499 (0.2624)	loss 1.2717 (1.3815)	grad_norm 4.4283 (4.9836)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:38:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:48 lr 0.000020	 wd 0.0000	time 0.2511 (0.2618)	loss 1.5439 (1.3820)	grad_norm 4.1476 (5.0187)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:38:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:04:21 lr 0.000020	 wd 0.0000	time 0.2508 (0.2614)	loss 1.5179 (1.3826)	grad_norm 4.8926 (5.0060)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:39:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:55 lr 0.000020	 wd 0.0000	time 0.2535 (0.2610)	loss 1.4541 (1.3840)	grad_norm 4.6709 (5.0312)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:39:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:29 lr 0.000020	 wd 0.0000	time 0.2510 (0.2606)	loss 1.6457 (1.3856)	grad_norm 4.1533 (5.0125)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:40:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:03:02 lr 0.000020	 wd 0.0000	time 0.2510 (0.2603)	loss 1.4252 (1.3860)	grad_norm 7.3697 (5.0613)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:40:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:36 lr 0.000020	 wd 0.0000	time 0.2505 (0.2601)	loss 1.2570 (1.3866)	grad_norm 7.7746 (5.0755)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:41:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:02:10 lr 0.000019	 wd 0.0000	time 0.2450 (0.2598)	loss 1.4493 (1.3843)	grad_norm 4.0356 (5.0494)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:41:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:44 lr 0.000019	 wd 0.0000	time 0.2507 (0.2596)	loss 1.5365 (1.3843)	grad_norm 3.3890 (5.0391)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:41:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:18 lr 0.000019	 wd 0.0000	time 0.2505 (0.2594)	loss 1.3299 (1.3846)	grad_norm 3.3058 (5.0423)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:42:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:52 lr 0.000019	 wd 0.0000	time 0.2484 (0.2592)	loss 1.6230 (1.3837)	grad_norm 4.2338 (5.0587)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:42:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:26 lr 0.000019	 wd 0.0000	time 0.2489 (0.2590)	loss 1.4758 (1.3819)	grad_norm 5.9742 (5.0711)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:43:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000019	 wd 0.0000	time 0.2503 (0.2588)	loss 1.3872 (1.3825)	grad_norm 4.0217 (5.0708)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:43:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 17 training takes 0:10:50
[2024-07-04 00:43:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.052 (11.052)	Loss 0.4062 (0.4062)	Acc@1 93.359 (93.359)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-04 00:43:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.802 Acc@5 97.142
[2024-07-04 00:43:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-04 00:43:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.83%
[2024-07-04 00:43:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][0/2502]	eta 7:37:39 lr 0.000019	 wd 0.0000	time 10.9751 (10.9751)	loss 1.6421 (1.6421)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:44:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:14:35 lr 0.000019	 wd 0.0000	time 0.2481 (0.3644)	loss 1.5949 (1.4250)	grad_norm 3.1632 (5.1300)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:44:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:11:51 lr 0.000019	 wd 0.0000	time 0.2560 (0.3091)	loss 1.5823 (1.3985)	grad_norm 5.1343 (4.9339)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:45:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:10:40 lr 0.000019	 wd 0.0000	time 0.2486 (0.2907)	loss 1.5833 (1.3947)	grad_norm 3.8178 (4.8741)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:45:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:09:51 lr 0.000019	 wd 0.0000	time 0.2546 (0.2814)	loss 1.4400 (1.3910)	grad_norm 8.8173 (5.0503)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:45:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:09:12 lr 0.000018	 wd 0.0000	time 0.2501 (0.2758)	loss 1.2553 (1.3836)	grad_norm 3.4583 (5.0049)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:46:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:08:37 lr 0.000018	 wd 0.0000	time 0.2524 (0.2721)	loss 1.5955 (1.3825)	grad_norm 3.4116 (4.9730)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:46:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:08:05 lr 0.000018	 wd 0.0000	time 0.2500 (0.2695)	loss 1.6077 (1.3840)	grad_norm 3.2108 (4.9801)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:47:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:35 lr 0.000018	 wd 0.0000	time 0.2490 (0.2675)	loss 1.1506 (1.3809)	grad_norm 3.8294 (4.9486)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 00:47:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:07:06 lr 0.000018	 wd 0.0000	time 0.2496 (0.2661)	loss 1.4105 (1.3775)	grad_norm 5.8102 (inf)	loss_scale 256.0000 (501.2031)	mem 9231MB
[2024-07-04 00:48:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:37 lr 0.000018	 wd 0.0000	time 0.2543 (0.2649)	loss 1.1604 (1.3816)	grad_norm 8.3796 (inf)	loss_scale 256.0000 (476.7073)	mem 9231MB
[2024-07-04 00:48:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:06:10 lr 0.000018	 wd 0.0000	time 0.2507 (0.2640)	loss 1.3294 (1.3808)	grad_norm 5.8229 (inf)	loss_scale 256.0000 (456.6612)	mem 9231MB
[2024-07-04 00:48:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:42 lr 0.000018	 wd 0.0000	time 0.2486 (0.2632)	loss 1.5573 (1.3811)	grad_norm 6.7535 (inf)	loss_scale 256.0000 (439.9534)	mem 9231MB
[2024-07-04 00:49:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:05:15 lr 0.000018	 wd 0.0000	time 0.2541 (0.2625)	loss 1.6039 (1.3820)	grad_norm 3.6864 (inf)	loss_scale 256.0000 (425.8140)	mem 9231MB
[2024-07-04 00:49:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:48 lr 0.000018	 wd 0.0000	time 0.2505 (0.2620)	loss 1.2388 (1.3813)	grad_norm 3.6211 (inf)	loss_scale 256.0000 (413.6931)	mem 9231MB
[2024-07-04 00:50:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:04:22 lr 0.000017	 wd 0.0000	time 0.2524 (0.2615)	loss 1.5763 (1.3796)	grad_norm 4.6736 (inf)	loss_scale 256.0000 (403.1872)	mem 9231MB
[2024-07-04 00:50:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:55 lr 0.000017	 wd 0.0000	time 0.2518 (0.2611)	loss 1.6268 (1.3795)	grad_norm 6.2023 (inf)	loss_scale 256.0000 (393.9938)	mem 9231MB
[2024-07-04 00:51:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:29 lr 0.000017	 wd 0.0000	time 0.2505 (0.2607)	loss 1.5197 (1.3784)	grad_norm 6.3463 (inf)	loss_scale 256.0000 (385.8812)	mem 9231MB
[2024-07-04 00:51:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:03:02 lr 0.000017	 wd 0.0000	time 0.2505 (0.2604)	loss 1.3736 (1.3799)	grad_norm 9.7056 (inf)	loss_scale 256.0000 (378.6696)	mem 9231MB
[2024-07-04 00:51:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:36 lr 0.000017	 wd 0.0000	time 0.2498 (0.2601)	loss 1.5928 (1.3799)	grad_norm 3.6627 (inf)	loss_scale 256.0000 (372.2167)	mem 9231MB
[2024-07-04 00:52:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:02:10 lr 0.000017	 wd 0.0000	time 0.2502 (0.2599)	loss 1.4696 (1.3821)	grad_norm 5.7776 (inf)	loss_scale 256.0000 (366.4088)	mem 9231MB
[2024-07-04 00:52:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:44 lr 0.000017	 wd 0.0000	time 0.2500 (0.2597)	loss 1.3945 (1.3815)	grad_norm 3.9482 (inf)	loss_scale 256.0000 (361.1537)	mem 9231MB
[2024-07-04 00:53:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:18 lr 0.000017	 wd 0.0000	time 0.2504 (0.2596)	loss 1.4588 (1.3814)	grad_norm 2.8467 (inf)	loss_scale 256.0000 (356.3762)	mem 9231MB
[2024-07-04 00:53:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:52 lr 0.000017	 wd 0.0000	time 0.2504 (0.2594)	loss 1.4573 (1.3814)	grad_norm 4.1359 (inf)	loss_scale 256.0000 (352.0139)	mem 9231MB
[2024-07-04 00:54:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:26 lr 0.000017	 wd 0.0000	time 0.2512 (0.2592)	loss 1.5624 (1.3828)	grad_norm 12.1863 (inf)	loss_scale 256.0000 (348.0150)	mem 9231MB
[2024-07-04 00:54:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.2479 (0.2590)	loss 1.5497 (1.3825)	grad_norm 4.2351 (inf)	loss_scale 256.0000 (344.3359)	mem 9231MB
[2024-07-04 00:54:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 18 training takes 0:10:50
[2024-07-04 00:54:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.895 (11.895)	Loss 0.4062 (0.4062)	Acc@1 92.773 (92.773)	Acc@5 98.242 (98.242)	Mem 9231MB
[2024-07-04 00:54:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.776 Acc@5 97.158
[2024-07-04 00:54:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-04 00:54:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.83%
[2024-07-04 00:55:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][0/2502]	eta 8:00:38 lr 0.000016	 wd 0.0000	time 11.5261 (11.5261)	loss 1.5233 (1.5233)	grad_norm 0.0000 (0.0000)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 00:55:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:14:36 lr 0.000016	 wd 0.0000	time 0.2489 (0.3647)	loss 1.1331 (1.3864)	grad_norm 5.9064 (5.4763)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 00:55:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:11:51 lr 0.000016	 wd 0.0000	time 0.2475 (0.3092)	loss 1.5483 (1.3846)	grad_norm 4.0993 (5.0247)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 00:56:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:10:39 lr 0.000016	 wd 0.0000	time 0.2462 (0.2906)	loss 1.3902 (1.3962)	grad_norm 6.7729 (5.0194)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 00:56:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:09:51 lr 0.000016	 wd 0.0000	time 0.2464 (0.2813)	loss 1.5999 (1.3955)	grad_norm 3.4685 (4.9949)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 00:57:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:09:11 lr 0.000016	 wd 0.0000	time 0.2487 (0.2757)	loss 1.6519 (1.3928)	grad_norm 6.2622 (5.1057)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 00:57:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:37 lr 0.000016	 wd 0.0000	time 0.2491 (0.2720)	loss 1.5674 (1.3885)	grad_norm 4.8660 (5.0797)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 00:58:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:08:05 lr 0.000016	 wd 0.0000	time 0.2498 (0.2694)	loss 1.6892 (1.3905)	grad_norm 3.5848 (5.1351)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 00:58:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:07:35 lr 0.000016	 wd 0.0000	time 0.2490 (0.2674)	loss 1.3478 (1.3872)	grad_norm 3.9263 (5.0923)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 00:58:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:07:06 lr 0.000016	 wd 0.0000	time 0.2493 (0.2659)	loss 1.4681 (1.3889)	grad_norm 13.9413 (5.1161)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 00:59:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:37 lr 0.000016	 wd 0.0000	time 0.2482 (0.2648)	loss 1.5480 (1.3913)	grad_norm 5.4002 (5.0870)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 00:59:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:06:09 lr 0.000015	 wd 0.0000	time 0.2500 (0.2638)	loss 0.9213 (1.3896)	grad_norm 3.7552 (5.0900)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:00:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:42 lr 0.000015	 wd 0.0000	time 0.2495 (0.2630)	loss 1.1550 (1.3871)	grad_norm 5.8527 (5.2703)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:00:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:05:15 lr 0.000015	 wd 0.0000	time 0.2516 (0.2624)	loss 1.5177 (1.3873)	grad_norm 8.3468 (5.2808)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:00:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:48 lr 0.000015	 wd 0.0000	time 0.2507 (0.2618)	loss 1.4716 (1.3889)	grad_norm 4.2086 (5.2457)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:01:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:04:21 lr 0.000015	 wd 0.0000	time 0.2554 (0.2614)	loss 1.2722 (1.3888)	grad_norm 4.5625 (5.2267)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:01:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:55 lr 0.000015	 wd 0.0000	time 0.2508 (0.2610)	loss 1.4448 (1.3894)	grad_norm 3.7118 (5.1806)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:02:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:29 lr 0.000015	 wd 0.0000	time 0.2532 (0.2606)	loss 1.5496 (1.3901)	grad_norm 5.5495 (5.1718)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:02:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:03:02 lr 0.000015	 wd 0.0000	time 0.2498 (0.2603)	loss 1.3574 (1.3901)	grad_norm 7.8512 (5.1702)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:03:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:36 lr 0.000015	 wd 0.0000	time 0.2506 (0.2600)	loss 1.3327 (1.3906)	grad_norm 4.3738 (5.1597)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:03:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:02:10 lr 0.000015	 wd 0.0000	time 0.2503 (0.2598)	loss 1.0390 (1.3898)	grad_norm 7.3070 (5.1332)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:03:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:44 lr 0.000014	 wd 0.0000	time 0.2511 (0.2596)	loss 1.2158 (1.3891)	grad_norm 5.1962 (5.1223)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:04:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:18 lr 0.000014	 wd 0.0000	time 0.2554 (0.2594)	loss 1.5233 (1.3872)	grad_norm 3.5286 (5.1069)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:04:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:52 lr 0.000014	 wd 0.0000	time 0.2557 (0.2592)	loss 1.4139 (1.3866)	grad_norm 6.7900 (5.1125)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:05:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:26 lr 0.000014	 wd 0.0000	time 0.2474 (0.2590)	loss 1.5889 (1.3876)	grad_norm 7.0262 (5.1118)	loss_scale 512.0000 (260.2649)	mem 9231MB
[2024-07-04 01:05:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.2498 (0.2588)	loss 1.2912 (1.3876)	grad_norm 5.8814 (5.1123)	loss_scale 512.0000 (270.3303)	mem 9231MB
[2024-07-04 01:05:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 19 training takes 0:10:50
[2024-07-04 01:05:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.098 (11.098)	Loss 0.4053 (0.4053)	Acc@1 93.164 (93.164)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-04 01:06:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.796 Acc@5 97.138
[2024-07-04 01:06:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-04 01:06:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.83%
[2024-07-04 01:06:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][0/2502]	eta 7:56:11 lr 0.000014	 wd 0.0000	time 11.4193 (11.4193)	loss 1.0928 (1.0928)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:06:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:14:35 lr 0.000014	 wd 0.0000	time 0.2504 (0.3646)	loss 1.7366 (1.3834)	grad_norm 3.6008 (4.8544)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:07:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:11:51 lr 0.000014	 wd 0.0000	time 0.2481 (0.3091)	loss 1.4467 (1.3899)	grad_norm 3.9291 (5.0826)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:07:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:10:39 lr 0.000014	 wd 0.0000	time 0.2497 (0.2905)	loss 1.4672 (1.3876)	grad_norm 5.1163 (4.9638)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:07:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:09:51 lr 0.000014	 wd 0.0000	time 0.2533 (0.2813)	loss 1.5645 (1.3940)	grad_norm 2.8313 (4.8850)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:08:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:09:11 lr 0.000014	 wd 0.0000	time 0.2498 (0.2757)	loss 1.4136 (1.3932)	grad_norm 4.3257 (5.2460)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:08:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:08:37 lr 0.000014	 wd 0.0000	time 0.2515 (0.2721)	loss 1.5006 (1.3890)	grad_norm 4.1858 (5.2959)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:09:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:08:05 lr 0.000013	 wd 0.0000	time 0.2450 (0.2695)	loss 1.4778 (1.3942)	grad_norm 5.4047 (5.2385)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:09:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:07:35 lr 0.000013	 wd 0.0000	time 0.2495 (0.2676)	loss 1.2925 (1.3913)	grad_norm 4.4782 (5.1975)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:10:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:07:06 lr 0.000013	 wd 0.0000	time 0.2511 (0.2661)	loss 1.6575 (1.3942)	grad_norm 4.2266 (5.1756)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:10:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:37 lr 0.000013	 wd 0.0000	time 0.2502 (0.2649)	loss 1.3901 (1.3937)	grad_norm 4.0024 (5.1191)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:10:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:06:10 lr 0.000013	 wd 0.0000	time 0.2502 (0.2639)	loss 1.4463 (1.3909)	grad_norm 3.0876 (5.0783)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:11:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:42 lr 0.000013	 wd 0.0000	time 0.2506 (0.2631)	loss 1.4697 (1.3881)	grad_norm 5.0942 (5.0919)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:11:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:05:15 lr 0.000013	 wd 0.0000	time 0.2491 (0.2625)	loss 1.2429 (1.3845)	grad_norm 4.1117 (5.0891)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:12:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:48 lr 0.000013	 wd 0.0000	time 0.2506 (0.2619)	loss 1.3802 (1.3863)	grad_norm 5.5979 (5.0949)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:12:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:04:21 lr 0.000013	 wd 0.0000	time 0.2502 (0.2614)	loss 1.2928 (1.3877)	grad_norm 5.4747 (5.0865)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:13:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:55 lr 0.000013	 wd 0.0000	time 0.2500 (0.2610)	loss 1.6001 (1.3883)	grad_norm 3.9675 (5.0782)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:13:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:29 lr 0.000012	 wd 0.0000	time 0.2479 (0.2607)	loss 1.5890 (1.3877)	grad_norm 3.8253 (5.0859)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:13:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:03:02 lr 0.000012	 wd 0.0000	time 0.2521 (0.2604)	loss 1.3515 (1.3865)	grad_norm 3.2679 (5.0598)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:14:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:36 lr 0.000012	 wd 0.0000	time 0.2507 (0.2601)	loss 1.6818 (1.3873)	grad_norm 5.7337 (inf)	loss_scale 256.0000 (500.6881)	mem 9231MB
[2024-07-04 01:14:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:02:10 lr 0.000012	 wd 0.0000	time 0.2582 (0.2598)	loss 1.5323 (1.3865)	grad_norm 6.6565 (inf)	loss_scale 256.0000 (488.4598)	mem 9231MB
[2024-07-04 01:15:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:44 lr 0.000012	 wd 0.0000	time 0.2496 (0.2596)	loss 1.4201 (1.3872)	grad_norm 3.1968 (inf)	loss_scale 256.0000 (477.3955)	mem 9231MB
[2024-07-04 01:15:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:18 lr 0.000012	 wd 0.0000	time 0.2532 (0.2594)	loss 1.3418 (1.3884)	grad_norm 4.7372 (inf)	loss_scale 256.0000 (467.3367)	mem 9231MB
[2024-07-04 01:16:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:52 lr 0.000012	 wd 0.0000	time 0.2543 (0.2592)	loss 1.3340 (1.3887)	grad_norm 3.5361 (inf)	loss_scale 256.0000 (458.1521)	mem 9231MB
[2024-07-04 01:16:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:26 lr 0.000012	 wd 0.0000	time 0.2512 (0.2591)	loss 1.2912 (1.3891)	grad_norm 6.3329 (inf)	loss_scale 256.0000 (449.7326)	mem 9231MB
[2024-07-04 01:16:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000012	 wd 0.0000	time 0.2491 (0.2589)	loss 1.5137 (1.3899)	grad_norm 4.8466 (inf)	loss_scale 256.0000 (441.9864)	mem 9231MB
[2024-07-04 01:16:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 20 training takes 0:10:51
[2024-07-04 01:17:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.466 (11.466)	Loss 0.4067 (0.4067)	Acc@1 93.359 (93.359)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-04 01:17:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.804 Acc@5 97.174
[2024-07-04 01:17:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-04 01:17:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.83%
[2024-07-04 01:17:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][0/2502]	eta 7:31:29 lr 0.000012	 wd 0.0000	time 10.8270 (10.8270)	loss 1.6171 (1.6171)	grad_norm 0.0000 (0.0000)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:17:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:14:25 lr 0.000012	 wd 0.0000	time 0.2475 (0.3603)	loss 1.6077 (1.4250)	grad_norm 3.7224 (5.2076)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:18:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:11:46 lr 0.000012	 wd 0.0000	time 0.2483 (0.3068)	loss 0.9874 (1.3949)	grad_norm 3.6109 (5.0041)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:18:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:10:36 lr 0.000012	 wd 0.0000	time 0.2484 (0.2889)	loss 1.4147 (1.3855)	grad_norm 3.4657 (4.8495)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:19:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:09:48 lr 0.000011	 wd 0.0000	time 0.2480 (0.2800)	loss 1.3771 (1.3876)	grad_norm 3.5145 (5.1205)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:19:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:09:09 lr 0.000011	 wd 0.0000	time 0.2497 (0.2747)	loss 1.3536 (1.3865)	grad_norm 17.7186 (5.2727)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:20:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:35 lr 0.000011	 wd 0.0000	time 0.2497 (0.2712)	loss 1.2906 (1.3879)	grad_norm 4.0769 (5.1481)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:20:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:08:04 lr 0.000011	 wd 0.0000	time 0.2520 (0.2687)	loss 1.3044 (1.3822)	grad_norm 3.9951 (5.1845)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:20:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:34 lr 0.000011	 wd 0.0000	time 0.2495 (0.2668)	loss 1.3088 (1.3807)	grad_norm 3.3701 (5.0992)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:21:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:07:05 lr 0.000011	 wd 0.0000	time 0.2498 (0.2654)	loss 1.5824 (1.3794)	grad_norm 3.4089 (5.1162)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:21:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:36 lr 0.000011	 wd 0.0000	time 0.2506 (0.2643)	loss 1.1060 (1.3783)	grad_norm 3.9467 (5.1511)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:22:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:06:09 lr 0.000011	 wd 0.0000	time 0.2510 (0.2634)	loss 1.4419 (1.3785)	grad_norm 3.0517 (5.0824)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:22:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:41 lr 0.000011	 wd 0.0000	time 0.2511 (0.2627)	loss 1.4368 (1.3788)	grad_norm 3.1834 (5.1034)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:23:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:05:14 lr 0.000011	 wd 0.0000	time 0.2516 (0.2620)	loss 1.5616 (1.3784)	grad_norm 3.5676 (5.0627)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:23:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:48 lr 0.000011	 wd 0.0000	time 0.2524 (0.2615)	loss 1.3815 (1.3789)	grad_norm 5.8655 (5.0228)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:23:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:04:21 lr 0.000010	 wd 0.0000	time 0.2449 (0.2610)	loss 1.7055 (1.3784)	grad_norm 4.9332 (4.9985)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:24:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:55 lr 0.000010	 wd 0.0000	time 0.2512 (0.2606)	loss 1.3100 (1.3779)	grad_norm 5.2645 (4.9753)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:24:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:28 lr 0.000010	 wd 0.0000	time 0.2499 (0.2603)	loss 1.5082 (1.3784)	grad_norm 3.8337 (4.9705)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:25:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:03:02 lr 0.000010	 wd 0.0000	time 0.2500 (0.2600)	loss 1.1002 (1.3793)	grad_norm 5.9491 (4.9809)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:25:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:36 lr 0.000010	 wd 0.0000	time 0.2496 (0.2598)	loss 1.0750 (1.3776)	grad_norm 4.4785 (5.0002)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:26:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:02:10 lr 0.000010	 wd 0.0000	time 0.2522 (0.2596)	loss 1.4371 (1.3772)	grad_norm 5.1072 (4.9738)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:26:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:44 lr 0.000010	 wd 0.0000	time 0.2500 (0.2593)	loss 1.2024 (1.3790)	grad_norm 4.5517 (5.0976)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:26:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:18 lr 0.000010	 wd 0.0000	time 0.2464 (0.2592)	loss 1.6570 (1.3772)	grad_norm 4.1414 (5.1004)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:27:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:52 lr 0.000010	 wd 0.0000	time 0.2540 (0.2590)	loss 1.6497 (1.3763)	grad_norm 4.3637 (5.0842)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:27:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:26 lr 0.000010	 wd 0.0000	time 0.2549 (0.2588)	loss 1.3905 (1.3777)	grad_norm 3.1072 (5.0638)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:28:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.2493 (0.2586)	loss 1.4849 (1.3772)	grad_norm 4.7349 (5.0812)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:28:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 21 training takes 0:10:50
[2024-07-04 01:28:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 10.933 (10.933)	Loss 0.4023 (0.4023)	Acc@1 93.359 (93.359)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-04 01:28:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.848 Acc@5 97.176
[2024-07-04 01:28:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-04 01:28:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.85%
[2024-07-04 01:28:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth saving......
[2024-07-04 01:28:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth saved !!!
[2024-07-04 01:28:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][0/2502]	eta 7:02:17 lr 0.000010	 wd 0.0000	time 10.1267 (10.1267)	loss 1.2590 (1.2590)	grad_norm 0.0000 (0.0000)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:29:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:14:10 lr 0.000010	 wd 0.0000	time 0.2493 (0.3542)	loss 1.3919 (1.3994)	grad_norm 3.8183 (4.9003)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:29:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:11:39 lr 0.000009	 wd 0.0000	time 0.2481 (0.3039)	loss 1.0433 (1.3881)	grad_norm 3.2162 (4.9456)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:30:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:10:32 lr 0.000009	 wd 0.0000	time 0.2479 (0.2871)	loss 1.5224 (1.3914)	grad_norm 5.5941 (4.8342)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:30:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:09:45 lr 0.000009	 wd 0.0000	time 0.2491 (0.2786)	loss 1.3667 (1.3956)	grad_norm 5.3370 (5.0841)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:30:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:09:07 lr 0.000009	 wd 0.0000	time 0.2524 (0.2736)	loss 1.0357 (1.3940)	grad_norm 4.5496 (5.2043)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:31:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:34 lr 0.000009	 wd 0.0000	time 0.2502 (0.2703)	loss 1.4849 (1.3941)	grad_norm 3.7298 (5.0374)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:31:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:08:02 lr 0.000009	 wd 0.0000	time 0.2528 (0.2680)	loss 0.9266 (1.3878)	grad_norm 5.1155 (5.0074)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:32:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:07:33 lr 0.000009	 wd 0.0000	time 0.2500 (0.2662)	loss 1.3389 (1.3831)	grad_norm 5.2947 (4.9795)	loss_scale 256.0000 (256.0000)	mem 9231MB
[2024-07-04 01:32:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:07:04 lr 0.000009	 wd 0.0000	time 0.2494 (0.2649)	loss 1.3447 (1.3806)	grad_norm 3.6331 (4.9831)	loss_scale 512.0000 (281.0033)	mem 9231MB
[2024-07-04 01:33:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:36 lr 0.000009	 wd 0.0000	time 0.2544 (0.2638)	loss 1.5480 (1.3825)	grad_norm 4.8652 (4.9827)	loss_scale 512.0000 (304.0799)	mem 9231MB
[2024-07-04 01:33:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:06:08 lr 0.000009	 wd 0.0000	time 0.2495 (0.2630)	loss 1.3804 (1.3806)	grad_norm 3.8502 (4.9453)	loss_scale 512.0000 (322.9646)	mem 9231MB
[2024-07-04 01:33:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:41 lr 0.000009	 wd 0.0000	time 0.2540 (0.2623)	loss 1.3412 (1.3798)	grad_norm 3.8317 (4.9212)	loss_scale 512.0000 (338.7044)	mem 9231MB
[2024-07-04 01:34:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:05:14 lr 0.000009	 wd 0.0000	time 0.2514 (0.2617)	loss 1.0401 (1.3808)	grad_norm 4.0809 (4.8984)	loss_scale 512.0000 (352.0246)	mem 9231MB
[2024-07-04 01:34:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:47 lr 0.000008	 wd 0.0000	time 0.2550 (0.2612)	loss 1.5432 (1.3824)	grad_norm 5.8778 (4.9050)	loss_scale 512.0000 (363.4433)	mem 9231MB
[2024-07-04 01:35:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:04:21 lr 0.000008	 wd 0.0000	time 0.2468 (0.2608)	loss 1.2430 (1.3830)	grad_norm 4.5716 (4.9909)	loss_scale 512.0000 (373.3404)	mem 9231MB
[2024-07-04 01:35:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:54 lr 0.000008	 wd 0.0000	time 0.2523 (0.2604)	loss 1.6019 (1.3829)	grad_norm 3.4668 (4.9854)	loss_scale 512.0000 (382.0012)	mem 9231MB
[2024-07-04 01:36:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:28 lr 0.000008	 wd 0.0000	time 0.2544 (0.2601)	loss 1.3175 (1.3821)	grad_norm 8.1815 (4.9937)	loss_scale 512.0000 (389.6437)	mem 9231MB
[2024-07-04 01:36:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:03:02 lr 0.000008	 wd 0.0000	time 0.2510 (0.2598)	loss 1.6840 (1.3819)	grad_norm 3.8505 (4.9799)	loss_scale 512.0000 (396.4375)	mem 9231MB
[2024-07-04 01:36:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:36 lr 0.000008	 wd 0.0000	time 0.2502 (0.2595)	loss 1.5707 (1.3811)	grad_norm 5.0910 (4.9988)	loss_scale 512.0000 (402.5166)	mem 9231MB
[2024-07-04 01:37:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:02:10 lr 0.000008	 wd 0.0000	time 0.2494 (0.2593)	loss 1.5039 (1.3799)	grad_norm 2.7926 (5.0009)	loss_scale 512.0000 (407.9880)	mem 9231MB
[2024-07-04 01:37:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:44 lr 0.000008	 wd 0.0000	time 0.2528 (0.2591)	loss 1.5104 (1.3806)	grad_norm 6.1087 (4.9931)	loss_scale 512.0000 (412.9386)	mem 9231MB
[2024-07-04 01:38:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:18 lr 0.000008	 wd 0.0000	time 0.2542 (0.2590)	loss 1.4910 (1.3794)	grad_norm 4.0819 (5.0008)	loss_scale 512.0000 (417.4393)	mem 9231MB
[2024-07-04 01:38:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:52 lr 0.000008	 wd 0.0000	time 0.2516 (0.2588)	loss 1.5998 (1.3797)	grad_norm 4.2919 (4.9814)	loss_scale 512.0000 (421.5489)	mem 9231MB
[2024-07-04 01:39:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:26 lr 0.000008	 wd 0.0000	time 0.2511 (0.2586)	loss 1.1141 (1.3792)	grad_norm 4.0949 (4.9616)	loss_scale 512.0000 (425.3161)	mem 9231MB
[2024-07-04 01:39:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.2505 (0.2584)	loss 1.0756 (1.3782)	grad_norm 4.9974 (4.9336)	loss_scale 512.0000 (428.7821)	mem 9231MB
[2024-07-04 01:39:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 22 training takes 0:10:51
[2024-07-04 01:39:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.481 (11.481)	Loss 0.4050 (0.4050)	Acc@1 93.555 (93.555)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-04 01:39:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.834 Acc@5 97.170
[2024-07-04 01:39:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-04 01:39:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.85%
[2024-07-04 01:40:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][0/2502]	eta 7:26:53 lr 0.000008	 wd 0.0000	time 10.7167 (10.7167)	loss 1.1481 (1.1481)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:40:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:14:25 lr 0.000008	 wd 0.0000	time 0.2501 (0.3605)	loss 1.4855 (1.4203)	grad_norm 2.7860 (4.6144)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:40:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:11:47 lr 0.000007	 wd 0.0000	time 0.2502 (0.3071)	loss 1.5907 (1.3983)	grad_norm 6.1739 (4.6818)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:41:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:10:37 lr 0.000007	 wd 0.0000	time 0.2497 (0.2893)	loss 1.3990 (1.3918)	grad_norm 3.9820 (4.7669)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:41:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:09:49 lr 0.000007	 wd 0.0000	time 0.2496 (0.2803)	loss 1.7154 (1.3867)	grad_norm 3.8328 (4.6810)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:42:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:09:10 lr 0.000007	 wd 0.0000	time 0.2488 (0.2749)	loss 1.6043 (1.3908)	grad_norm 8.5819 (4.6216)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:42:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:08:36 lr 0.000007	 wd 0.0000	time 0.2507 (0.2713)	loss 1.2010 (1.3912)	grad_norm 3.7401 (4.6173)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:43:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:08:04 lr 0.000007	 wd 0.0000	time 0.2495 (0.2689)	loss 1.5320 (1.3878)	grad_norm 4.6425 (4.6518)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:43:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:07:34 lr 0.000007	 wd 0.0000	time 0.2545 (0.2670)	loss 1.7373 (1.3851)	grad_norm 2.9521 (4.7156)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:43:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:07:05 lr 0.000007	 wd 0.0000	time 0.2496 (0.2656)	loss 1.6683 (1.3821)	grad_norm 4.0810 (4.7382)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:44:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:37 lr 0.000007	 wd 0.0000	time 0.2497 (0.2645)	loss 1.1095 (1.3814)	grad_norm 6.1602 (4.7487)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:44:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:06:09 lr 0.000007	 wd 0.0000	time 0.2504 (0.2636)	loss 0.8630 (1.3762)	grad_norm 4.6420 (4.7725)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:45:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:42 lr 0.000007	 wd 0.0000	time 0.2491 (0.2629)	loss 1.5708 (1.3782)	grad_norm 4.5245 (4.8852)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:45:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:05:15 lr 0.000007	 wd 0.0000	time 0.2550 (0.2622)	loss 1.5689 (1.3795)	grad_norm 5.7872 (4.8784)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:46:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:48 lr 0.000007	 wd 0.0000	time 0.2502 (0.2617)	loss 1.3617 (1.3790)	grad_norm 16.2660 (4.8579)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:46:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:04:21 lr 0.000006	 wd 0.0000	time 0.2501 (0.2612)	loss 1.2633 (1.3806)	grad_norm 4.7411 (4.8308)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:46:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:55 lr 0.000006	 wd 0.0000	time 0.2502 (0.2608)	loss 1.2434 (1.3803)	grad_norm 3.5643 (4.8237)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:47:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:28 lr 0.000006	 wd 0.0000	time 0.2527 (0.2605)	loss 1.4008 (1.3805)	grad_norm 4.5685 (4.8904)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:47:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:03:02 lr 0.000006	 wd 0.0000	time 0.2546 (0.2602)	loss 1.3714 (1.3799)	grad_norm 13.6041 (4.9102)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:48:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:36 lr 0.000006	 wd 0.0000	time 0.2478 (0.2599)	loss 1.2311 (1.3824)	grad_norm 9.5119 (4.9028)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:48:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:02:10 lr 0.000006	 wd 0.0000	time 0.2548 (0.2597)	loss 1.4050 (1.3812)	grad_norm 24.2785 (4.9405)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:49:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:44 lr 0.000006	 wd 0.0000	time 0.2505 (0.2595)	loss 1.7039 (1.3813)	grad_norm 6.8865 (4.9444)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:49:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:18 lr 0.000006	 wd 0.0000	time 0.2509 (0.2593)	loss 1.4924 (1.3787)	grad_norm 3.1720 (4.9575)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:49:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:52 lr 0.000006	 wd 0.0000	time 0.2505 (0.2591)	loss 1.5144 (1.3783)	grad_norm 3.6349 (4.9424)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 01:50:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:26 lr 0.000006	 wd 0.0000	time 0.2527 (0.2589)	loss 1.5606 (1.3790)	grad_norm 4.1841 (4.9807)	loss_scale 1024.0000 (531.1920)	mem 9231MB
[2024-07-04 01:50:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000006	 wd 0.0000	time 0.2503 (0.2587)	loss 1.5089 (1.3798)	grad_norm 5.1768 (5.0019)	loss_scale 1024.0000 (550.8964)	mem 9231MB
[2024-07-04 01:50:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 23 training takes 0:10:53
[2024-07-04 01:51:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.489 (11.489)	Loss 0.4055 (0.4055)	Acc@1 93.750 (93.750)	Acc@5 98.242 (98.242)	Mem 9231MB
[2024-07-04 01:51:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.850 Acc@5 97.148
[2024-07-04 01:51:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-04 01:51:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.85%
[2024-07-04 01:51:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth saving......
[2024-07-04 01:51:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth saved !!!
[2024-07-04 01:51:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][0/2502]	eta 7:26:18 lr 0.000006	 wd 0.0000	time 10.7029 (10.7029)	loss 1.6154 (1.6154)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:51:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:14:16 lr 0.000006	 wd 0.0000	time 0.2483 (0.3568)	loss 1.2175 (1.4166)	grad_norm 10.2309 (5.0740)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:52:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:11:42 lr 0.000006	 wd 0.0000	time 0.2486 (0.3052)	loss 1.6450 (1.4035)	grad_norm 3.6750 (5.1515)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:52:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:10:34 lr 0.000006	 wd 0.0000	time 0.2497 (0.2880)	loss 1.6496 (1.3918)	grad_norm 4.2561 (5.2760)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:53:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:09:47 lr 0.000005	 wd 0.0000	time 0.2493 (0.2794)	loss 1.5062 (1.3869)	grad_norm 3.3334 (5.2391)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:53:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:09:08 lr 0.000005	 wd 0.0000	time 0.2483 (0.2742)	loss 1.6301 (1.3886)	grad_norm 3.8179 (5.2217)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:54:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:08:34 lr 0.000005	 wd 0.0000	time 0.2496 (0.2708)	loss 1.4018 (1.3832)	grad_norm 4.9809 (5.0841)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:54:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:08:03 lr 0.000005	 wd 0.0000	time 0.2490 (0.2683)	loss 1.3175 (1.3848)	grad_norm 3.6721 (5.0102)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:54:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:07:33 lr 0.000005	 wd 0.0000	time 0.2497 (0.2665)	loss 1.4348 (1.3861)	grad_norm 5.0010 (4.9907)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:55:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:07:04 lr 0.000005	 wd 0.0000	time 0.2517 (0.2651)	loss 1.4945 (1.3839)	grad_norm 3.8556 (5.0183)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:55:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:36 lr 0.000005	 wd 0.0000	time 0.2496 (0.2641)	loss 1.3184 (1.3837)	grad_norm 3.2835 (5.1075)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:56:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:06:08 lr 0.000005	 wd 0.0000	time 0.2496 (0.2632)	loss 1.5175 (1.3820)	grad_norm 3.9829 (5.1114)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:56:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:41 lr 0.000005	 wd 0.0000	time 0.2499 (0.2625)	loss 1.1527 (1.3805)	grad_norm 4.5116 (5.0900)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:57:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:05:14 lr 0.000005	 wd 0.0000	time 0.2502 (0.2618)	loss 1.2859 (1.3814)	grad_norm 5.9965 (5.0968)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:57:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:47 lr 0.000005	 wd 0.0000	time 0.2511 (0.2613)	loss 1.2835 (1.3799)	grad_norm 4.4022 (5.0421)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:57:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:21 lr 0.000005	 wd 0.0000	time 0.2488 (0.2609)	loss 1.0148 (1.3786)	grad_norm 4.0328 (5.0318)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:58:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:54 lr 0.000005	 wd 0.0000	time 0.2521 (0.2605)	loss 1.4406 (1.3781)	grad_norm 3.7830 (5.0292)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:58:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:28 lr 0.000005	 wd 0.0000	time 0.2512 (0.2602)	loss 1.7433 (1.3801)	grad_norm 4.1675 (5.0061)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:59:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:03:02 lr 0.000005	 wd 0.0000	time 0.2503 (0.2599)	loss 1.2322 (1.3793)	grad_norm 7.0885 (5.0531)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:59:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:36 lr 0.000005	 wd 0.0000	time 0.2485 (0.2596)	loss 1.5160 (1.3805)	grad_norm 6.6126 (5.0414)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 01:59:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:02:10 lr 0.000004	 wd 0.0000	time 0.2524 (0.2594)	loss 1.5702 (1.3806)	grad_norm 3.7566 (5.0628)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:00:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:44 lr 0.000004	 wd 0.0000	time 0.2522 (0.2592)	loss 1.5662 (1.3789)	grad_norm 4.1528 (5.0588)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:00:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:18 lr 0.000004	 wd 0.0000	time 0.2507 (0.2591)	loss 1.2876 (1.3785)	grad_norm 4.4482 (5.0568)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:01:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:52 lr 0.000004	 wd 0.0000	time 0.2510 (0.2589)	loss 1.7345 (1.3781)	grad_norm 4.8236 (5.0317)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:01:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:26 lr 0.000004	 wd 0.0000	time 0.2508 (0.2587)	loss 1.6109 (1.3782)	grad_norm 4.1627 (5.0332)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:02:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000004	 wd 0.0000	time 0.2506 (0.2585)	loss 1.2735 (1.3787)	grad_norm 4.6564 (5.0532)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:02:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 24 training takes 0:10:53
[2024-07-04 02:02:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.384 (11.384)	Loss 0.4072 (0.4072)	Acc@1 93.359 (93.359)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-04 02:02:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.842 Acc@5 97.158
[2024-07-04 02:02:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-04 02:02:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.85%
[2024-07-04 02:02:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][0/2502]	eta 7:09:25 lr 0.000004	 wd 0.0000	time 10.2979 (10.2979)	loss 1.1243 (1.1243)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:03:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:14:21 lr 0.000004	 wd 0.0000	time 0.2519 (0.3585)	loss 1.3778 (1.3480)	grad_norm 4.8890 (4.4808)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:03:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:11:44 lr 0.000004	 wd 0.0000	time 0.2488 (0.3060)	loss 1.4780 (1.3698)	grad_norm 7.3410 (4.5021)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:04:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:10:35 lr 0.000004	 wd 0.0000	time 0.2483 (0.2885)	loss 1.0884 (1.3637)	grad_norm 3.0126 (4.5399)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:04:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:09:48 lr 0.000004	 wd 0.0000	time 0.2480 (0.2798)	loss 1.3025 (1.3780)	grad_norm 4.1703 (4.6106)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:04:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:09:09 lr 0.000004	 wd 0.0000	time 0.2529 (0.2746)	loss 1.4608 (1.3787)	grad_norm 3.7535 (4.7535)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:05:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:35 lr 0.000004	 wd 0.0000	time 0.2495 (0.2711)	loss 1.2219 (1.3811)	grad_norm 6.2943 (4.8037)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:05:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:08:04 lr 0.000004	 wd 0.0000	time 0.2497 (0.2687)	loss 1.2521 (1.3812)	grad_norm 4.9141 (4.8824)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:06:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:07:34 lr 0.000004	 wd 0.0000	time 0.2499 (0.2669)	loss 1.1022 (1.3815)	grad_norm 5.4211 (4.8982)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:06:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:07:05 lr 0.000004	 wd 0.0000	time 0.2505 (0.2654)	loss 1.4583 (1.3838)	grad_norm 6.1767 (4.9027)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:07:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:36 lr 0.000004	 wd 0.0000	time 0.2473 (0.2643)	loss 1.3724 (1.3849)	grad_norm 4.5368 (4.9259)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:07:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:06:09 lr 0.000004	 wd 0.0000	time 0.2487 (0.2634)	loss 1.3952 (1.3827)	grad_norm 5.5160 (4.9217)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:07:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:42 lr 0.000004	 wd 0.0000	time 0.2504 (0.2627)	loss 1.3660 (1.3841)	grad_norm 5.0596 (5.0246)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:08:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:05:14 lr 0.000003	 wd 0.0000	time 0.2498 (0.2621)	loss 1.5920 (1.3845)	grad_norm 4.0220 (5.0142)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:08:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:48 lr 0.000003	 wd 0.0000	time 0.2510 (0.2615)	loss 1.2283 (1.3855)	grad_norm 4.1749 (5.0380)	loss_scale 2048.0000 (1092.7052)	mem 9231MB
[2024-07-04 02:09:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:04:21 lr 0.000003	 wd 0.0000	time 0.2542 (0.2611)	loss 1.2740 (1.3846)	grad_norm 4.2244 (5.0308)	loss_scale 2048.0000 (1156.3491)	mem 9231MB
[2024-07-04 02:09:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:55 lr 0.000003	 wd 0.0000	time 0.2515 (0.2607)	loss 1.5592 (1.3846)	grad_norm 5.2276 (5.0372)	loss_scale 2048.0000 (1212.0425)	mem 9231MB
[2024-07-04 02:10:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:28 lr 0.000003	 wd 0.0000	time 0.2512 (0.2604)	loss 1.3557 (1.3845)	grad_norm 6.0066 (5.0247)	loss_scale 2048.0000 (1261.1875)	mem 9231MB
[2024-07-04 02:10:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:03:02 lr 0.000003	 wd 0.0000	time 0.2525 (0.2601)	loss 1.4563 (1.3835)	grad_norm 11.2336 (nan)	loss_scale 1024.0000 (1288.9550)	mem 9231MB
[2024-07-04 02:10:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:36 lr 0.000003	 wd 0.0000	time 0.2547 (0.2598)	loss 1.6611 (1.3839)	grad_norm 7.8731 (nan)	loss_scale 1024.0000 (1275.0174)	mem 9231MB
[2024-07-04 02:11:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:02:10 lr 0.000003	 wd 0.0000	time 0.2495 (0.2596)	loss 1.3232 (1.3835)	grad_norm 3.8203 (nan)	loss_scale 1024.0000 (1262.4728)	mem 9231MB
[2024-07-04 02:11:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:44 lr 0.000003	 wd 0.0000	time 0.2506 (0.2594)	loss 0.9200 (1.3839)	grad_norm 5.0279 (nan)	loss_scale 1024.0000 (1251.1223)	mem 9231MB
[2024-07-04 02:12:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:18 lr 0.000003	 wd 0.0000	time 0.2522 (0.2592)	loss 1.4560 (1.3828)	grad_norm 3.2350 (nan)	loss_scale 1024.0000 (1240.8033)	mem 9231MB
[2024-07-04 02:12:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:52 lr 0.000003	 wd 0.0000	time 0.2523 (0.2590)	loss 1.4748 (1.3813)	grad_norm 3.8749 (nan)	loss_scale 512.0000 (1210.9100)	mem 9231MB
[2024-07-04 02:13:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:26 lr 0.000003	 wd 0.0000	time 0.2539 (0.2589)	loss 1.4744 (1.3827)	grad_norm 4.0037 (nan)	loss_scale 512.0000 (1181.8009)	mem 9231MB
[2024-07-04 02:13:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.2499 (0.2587)	loss 1.5682 (1.3827)	grad_norm 5.4302 (nan)	loss_scale 512.0000 (1155.0196)	mem 9231MB
[2024-07-04 02:13:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 25 training takes 0:10:53
[2024-07-04 02:13:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.612 (11.612)	Loss 0.4072 (0.4072)	Acc@1 93.164 (93.164)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-04 02:14:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.852 Acc@5 97.168
[2024-07-04 02:14:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-04 02:14:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.85%
[2024-07-04 02:14:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth saving......
[2024-07-04 02:14:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth saved !!!
[2024-07-04 02:14:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][0/2502]	eta 7:36:49 lr 0.000003	 wd 0.0000	time 10.9550 (10.9550)	loss 1.2147 (1.2147)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:14:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:14:22 lr 0.000003	 wd 0.0000	time 0.2495 (0.3593)	loss 1.5167 (1.3743)	grad_norm 3.4876 (4.8184)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:15:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:11:45 lr 0.000003	 wd 0.0000	time 0.2482 (0.3064)	loss 1.4682 (1.4020)	grad_norm 4.7307 (5.0845)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:15:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:10:35 lr 0.000003	 wd 0.0000	time 0.2472 (0.2887)	loss 1.3714 (1.3951)	grad_norm 4.9153 (5.0695)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:15:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:09:48 lr 0.000003	 wd 0.0000	time 0.2494 (0.2799)	loss 1.7139 (1.3973)	grad_norm 3.2458 (4.9415)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:16:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:09:09 lr 0.000003	 wd 0.0000	time 0.2493 (0.2746)	loss 1.7071 (1.4040)	grad_norm 3.4129 (4.9962)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:16:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:08:35 lr 0.000003	 wd 0.0000	time 0.2478 (0.2711)	loss 1.2762 (1.3986)	grad_norm 6.5869 (5.0218)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:17:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:08:04 lr 0.000003	 wd 0.0000	time 0.2490 (0.2687)	loss 1.4684 (1.3927)	grad_norm 10.3559 (4.9301)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:17:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:07:34 lr 0.000002	 wd 0.0000	time 0.2487 (0.2669)	loss 1.4650 (1.3893)	grad_norm 3.3138 (4.9881)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:18:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:07:05 lr 0.000002	 wd 0.0000	time 0.2525 (0.2654)	loss 1.3930 (1.3910)	grad_norm 3.6770 (4.9439)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:18:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:36 lr 0.000002	 wd 0.0000	time 0.2542 (0.2643)	loss 1.5076 (1.3903)	grad_norm 4.2194 (4.9652)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:18:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:06:09 lr 0.000002	 wd 0.0000	time 0.2503 (0.2634)	loss 1.5322 (1.3923)	grad_norm 3.4259 (4.9798)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:19:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:41 lr 0.000002	 wd 0.0000	time 0.2524 (0.2627)	loss 1.1101 (1.3926)	grad_norm 3.6066 (4.9362)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:19:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:05:14 lr 0.000002	 wd 0.0000	time 0.2505 (0.2621)	loss 0.9890 (1.3903)	grad_norm 4.5972 (4.9748)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:20:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:48 lr 0.000002	 wd 0.0000	time 0.2505 (0.2615)	loss 1.8057 (1.3903)	grad_norm 7.7188 (5.0684)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:20:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:04:21 lr 0.000002	 wd 0.0000	time 0.2536 (0.2611)	loss 1.5762 (1.3889)	grad_norm 5.3039 (5.0139)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:21:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:55 lr 0.000002	 wd 0.0000	time 0.2508 (0.2607)	loss 1.4832 (1.3876)	grad_norm 5.3563 (5.0295)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:21:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:28 lr 0.000002	 wd 0.0000	time 0.2514 (0.2603)	loss 1.3632 (1.3880)	grad_norm 6.1644 (5.0113)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:21:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:03:02 lr 0.000002	 wd 0.0000	time 0.2500 (0.2601)	loss 1.5118 (1.3896)	grad_norm 6.5979 (5.0179)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:22:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:36 lr 0.000002	 wd 0.0000	time 0.2503 (0.2598)	loss 1.1173 (1.3878)	grad_norm 3.0513 (5.0271)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:22:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:02:10 lr 0.000002	 wd 0.0000	time 0.2546 (0.2595)	loss 1.2213 (1.3874)	grad_norm 3.7278 (5.0154)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:23:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:44 lr 0.000002	 wd 0.0000	time 0.2545 (0.2593)	loss 1.0143 (1.3859)	grad_norm 7.1531 (5.0072)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:23:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:18 lr 0.000002	 wd 0.0000	time 0.2533 (0.2591)	loss 0.9363 (1.3854)	grad_norm 4.6115 (5.0031)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:24:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:52 lr 0.000002	 wd 0.0000	time 0.2514 (0.2590)	loss 1.1064 (1.3843)	grad_norm 4.6689 (5.0198)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:24:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:26 lr 0.000002	 wd 0.0000	time 0.2496 (0.2588)	loss 1.1405 (1.3839)	grad_norm 5.3118 (5.0206)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:24:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.2497 (0.2586)	loss 1.0754 (1.3822)	grad_norm 4.7910 (5.0303)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:24:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 26 training takes 0:10:53
[2024-07-04 02:25:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.832 (11.832)	Loss 0.4055 (0.4055)	Acc@1 93.164 (93.164)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-04 02:25:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.868 Acc@5 97.170
[2024-07-04 02:25:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-04 02:25:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.87%
[2024-07-04 02:25:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth saving......
[2024-07-04 02:25:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_best.pth saved !!!
[2024-07-04 02:25:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][0/2502]	eta 7:05:27 lr 0.000002	 wd 0.0000	time 10.2028 (10.2028)	loss 0.9687 (0.9687)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:26:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:14:12 lr 0.000002	 wd 0.0000	time 0.2495 (0.3550)	loss 1.5032 (1.3986)	grad_norm 4.1223 (4.8547)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:26:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:11:40 lr 0.000002	 wd 0.0000	time 0.2490 (0.3043)	loss 1.5290 (1.3888)	grad_norm 4.8304 (5.0075)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:26:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:10:32 lr 0.000002	 wd 0.0000	time 0.2476 (0.2873)	loss 1.3510 (1.3823)	grad_norm 10.2598 (4.8515)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:27:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:09:46 lr 0.000002	 wd 0.0000	time 0.2465 (0.2788)	loss 1.3744 (1.3813)	grad_norm 3.4135 (4.8078)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:27:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:09:08 lr 0.000002	 wd 0.0000	time 0.2493 (0.2737)	loss 0.8596 (1.3747)	grad_norm 5.4049 (4.7961)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:28:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:34 lr 0.000002	 wd 0.0000	time 0.2497 (0.2704)	loss 1.4216 (1.3748)	grad_norm 3.5804 (4.8304)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:28:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:08:03 lr 0.000002	 wd 0.0000	time 0.2494 (0.2681)	loss 1.4516 (1.3800)	grad_norm 3.3261 (4.8380)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:29:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:33 lr 0.000002	 wd 0.0000	time 0.2510 (0.2663)	loss 1.6088 (1.3831)	grad_norm 4.3615 (4.8414)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:29:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:07:04 lr 0.000001	 wd 0.0000	time 0.2505 (0.2650)	loss 1.4713 (1.3879)	grad_norm 5.9877 (4.9217)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:29:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:36 lr 0.000001	 wd 0.0000	time 0.2491 (0.2639)	loss 1.4584 (1.3867)	grad_norm 3.6542 (4.8681)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:30:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:06:08 lr 0.000001	 wd 0.0000	time 0.2508 (0.2630)	loss 1.4169 (1.3873)	grad_norm 3.5917 (4.8396)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:30:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:41 lr 0.000001	 wd 0.0000	time 0.2453 (0.2623)	loss 1.5361 (1.3876)	grad_norm 10.4918 (4.8306)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:31:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:05:14 lr 0.000001	 wd 0.0000	time 0.2498 (0.2617)	loss 1.4609 (1.3859)	grad_norm 2.5629 (4.8373)	loss_scale 1024.0000 (549.7802)	mem 9231MB
[2024-07-04 02:31:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:47 lr 0.000001	 wd 0.0000	time 0.2499 (0.2612)	loss 1.3807 (1.3872)	grad_norm 4.1029 (4.8398)	loss_scale 1024.0000 (583.6288)	mem 9231MB
[2024-07-04 02:31:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:04:21 lr 0.000001	 wd 0.0000	time 0.2502 (0.2608)	loss 1.5495 (1.3870)	grad_norm 6.3120 (4.8219)	loss_scale 1024.0000 (612.9674)	mem 9231MB
[2024-07-04 02:32:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:54 lr 0.000001	 wd 0.0000	time 0.2507 (0.2604)	loss 1.5282 (1.3853)	grad_norm 6.6895 (4.8684)	loss_scale 1024.0000 (638.6408)	mem 9231MB
[2024-07-04 02:32:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:28 lr 0.000001	 wd 0.0000	time 0.2548 (0.2601)	loss 1.4270 (1.3835)	grad_norm 4.3812 (4.8614)	loss_scale 1024.0000 (661.2957)	mem 9231MB
[2024-07-04 02:33:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:03:02 lr 0.000001	 wd 0.0000	time 0.2490 (0.2598)	loss 1.4670 (1.3842)	grad_norm 4.6017 (4.8619)	loss_scale 1024.0000 (681.4348)	mem 9231MB
[2024-07-04 02:33:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:36 lr 0.000001	 wd 0.0000	time 0.2547 (0.2595)	loss 0.9710 (1.3854)	grad_norm 5.0440 (4.8460)	loss_scale 1024.0000 (699.4550)	mem 9231MB
[2024-07-04 02:34:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:02:10 lr 0.000001	 wd 0.0000	time 0.2520 (0.2593)	loss 0.9047 (1.3838)	grad_norm 3.9100 (4.8828)	loss_scale 1024.0000 (715.6742)	mem 9231MB
[2024-07-04 02:34:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:44 lr 0.000001	 wd 0.0000	time 0.2532 (0.2592)	loss 1.7963 (1.3827)	grad_norm 3.4211 (4.8738)	loss_scale 1024.0000 (730.3494)	mem 9231MB
[2024-07-04 02:34:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:18 lr 0.000001	 wd 0.0000	time 0.2526 (0.2590)	loss 1.0071 (1.3838)	grad_norm 10.8053 (4.8814)	loss_scale 1024.0000 (743.6910)	mem 9231MB
[2024-07-04 02:35:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:52 lr 0.000001	 wd 0.0000	time 0.2510 (0.2588)	loss 1.5388 (1.3842)	grad_norm 5.4960 (4.8676)	loss_scale 1024.0000 (755.8731)	mem 9231MB
[2024-07-04 02:35:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:26 lr 0.000001	 wd 0.0000	time 0.2505 (0.2587)	loss 1.2940 (1.3840)	grad_norm 6.6875 (4.8823)	loss_scale 1024.0000 (767.0404)	mem 9231MB
[2024-07-04 02:36:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.2490 (0.2585)	loss 1.5213 (1.3824)	grad_norm 8.4457 (4.8795)	loss_scale 1024.0000 (777.3147)	mem 9231MB
[2024-07-04 02:36:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 27 training takes 0:10:54
[2024-07-04 02:36:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.151 (11.151)	Loss 0.4060 (0.4060)	Acc@1 93.164 (93.164)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-04 02:36:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.856 Acc@5 97.170
[2024-07-04 02:36:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-04 02:36:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.87%
[2024-07-04 02:37:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][0/2502]	eta 7:15:36 lr 0.000001	 wd 0.0000	time 10.4464 (10.4464)	loss 1.3064 (1.3064)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:37:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:14:24 lr 0.000001	 wd 0.0000	time 0.2489 (0.3600)	loss 1.0116 (1.3627)	grad_norm 4.2973 (5.8274)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:37:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:11:46 lr 0.000001	 wd 0.0000	time 0.2465 (0.3068)	loss 1.1094 (1.3664)	grad_norm 3.8764 (5.3051)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:38:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:10:36 lr 0.000001	 wd 0.0000	time 0.2487 (0.2890)	loss 1.6660 (1.3812)	grad_norm 3.4603 (5.0319)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:38:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:09:48 lr 0.000001	 wd 0.0000	time 0.2512 (0.2801)	loss 1.5213 (1.3868)	grad_norm 5.2923 (4.9013)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:39:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:09:10 lr 0.000001	 wd 0.0000	time 0.2493 (0.2747)	loss 1.6129 (1.3875)	grad_norm 3.7558 (4.9185)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:39:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:35 lr 0.000001	 wd 0.0000	time 0.2570 (0.2712)	loss 1.4544 (1.3878)	grad_norm 3.6101 (4.8577)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:40:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:08:04 lr 0.000001	 wd 0.0000	time 0.2491 (0.2688)	loss 1.0600 (1.3906)	grad_norm 5.4256 (4.8911)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:40:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:34 lr 0.000001	 wd 0.0000	time 0.2482 (0.2670)	loss 1.6173 (1.3879)	grad_norm 5.4398 (4.8878)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:40:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:07:05 lr 0.000001	 wd 0.0000	time 0.2535 (0.2656)	loss 1.5087 (1.3883)	grad_norm 4.1543 (4.9047)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:41:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:37 lr 0.000001	 wd 0.0000	time 0.2512 (0.2644)	loss 1.4942 (1.3893)	grad_norm 2.8451 (4.9548)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:41:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:06:09 lr 0.000001	 wd 0.0000	time 0.2516 (0.2635)	loss 1.0808 (1.3879)	grad_norm 20.3890 (4.9894)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:42:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:42 lr 0.000001	 wd 0.0000	time 0.2496 (0.2628)	loss 1.1493 (1.3865)	grad_norm 8.4777 (4.9724)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:42:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:05:15 lr 0.000001	 wd 0.0000	time 0.2506 (0.2621)	loss 1.4601 (1.3835)	grad_norm 5.2543 (4.9723)	loss_scale 1024.0000 (1024.0000)	mem 9231MB
[2024-07-04 02:42:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:48 lr 0.000001	 wd 0.0000	time 0.2528 (0.2616)	loss 1.0033 (1.3843)	grad_norm 4.9738 (nan)	loss_scale 512.0000 (991.1092)	mem 9231MB
[2024-07-04 02:43:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:04:21 lr 0.000001	 wd 0.0000	time 0.2486 (0.2611)	loss 1.5248 (1.3813)	grad_norm 4.7408 (nan)	loss_scale 512.0000 (959.1899)	mem 9231MB
[2024-07-04 02:43:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:55 lr 0.000001	 wd 0.0000	time 0.2520 (0.2607)	loss 1.2378 (1.3810)	grad_norm 4.1337 (nan)	loss_scale 512.0000 (931.2580)	mem 9231MB
[2024-07-04 02:44:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:28 lr 0.000001	 wd 0.0000	time 0.2507 (0.2604)	loss 1.4945 (1.3822)	grad_norm 5.3156 (nan)	loss_scale 512.0000 (906.6102)	mem 9231MB
[2024-07-04 02:44:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:03:02 lr 0.000001	 wd 0.0000	time 0.2470 (0.2601)	loss 1.3954 (1.3812)	grad_norm 4.3505 (nan)	loss_scale 512.0000 (884.6996)	mem 9231MB
[2024-07-04 02:45:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:36 lr 0.000001	 wd 0.0000	time 0.2513 (0.2599)	loss 1.6512 (1.3801)	grad_norm 4.3953 (nan)	loss_scale 512.0000 (865.0942)	mem 9231MB
[2024-07-04 02:45:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:02:10 lr 0.000001	 wd 0.0000	time 0.2538 (0.2597)	loss 0.9032 (1.3794)	grad_norm 3.8622 (nan)	loss_scale 512.0000 (847.4483)	mem 9231MB
[2024-07-04 02:45:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:44 lr 0.000001	 wd 0.0000	time 0.2530 (0.2594)	loss 1.1813 (1.3795)	grad_norm 3.9599 (nan)	loss_scale 512.0000 (831.4822)	mem 9231MB
[2024-07-04 02:46:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:18 lr 0.000001	 wd 0.0000	time 0.2510 (0.2592)	loss 1.5226 (1.3784)	grad_norm 3.7012 (nan)	loss_scale 512.0000 (816.9668)	mem 9231MB
[2024-07-04 02:46:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:52 lr 0.000001	 wd 0.0000	time 0.2512 (0.2590)	loss 1.2561 (1.3787)	grad_norm 3.5772 (nan)	loss_scale 512.0000 (803.7132)	mem 9231MB
[2024-07-04 02:47:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:26 lr 0.000001	 wd 0.0000	time 0.2503 (0.2589)	loss 1.6247 (1.3776)	grad_norm 3.2334 (nan)	loss_scale 512.0000 (791.5635)	mem 9231MB
[2024-07-04 02:47:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.2500 (0.2587)	loss 1.2374 (1.3761)	grad_norm 3.4603 (nan)	loss_scale 512.0000 (780.3854)	mem 9231MB
[2024-07-04 02:47:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 28 training takes 0:10:53
[2024-07-04 02:47:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 10.948 (10.948)	Loss 0.4058 (0.4058)	Acc@1 93.164 (93.164)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-04 02:48:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.848 Acc@5 97.178
[2024-07-04 02:48:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-04 02:48:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.87%
[2024-07-04 02:48:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][0/2502]	eta 7:02:09 lr 0.000001	 wd 0.0000	time 10.1238 (10.1238)	loss 1.4658 (1.4658)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:48:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:14:22 lr 0.000001	 wd 0.0000	time 0.2492 (0.3589)	loss 1.5234 (1.3551)	grad_norm 6.3848 (5.0251)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:49:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:11:45 lr 0.000001	 wd 0.0000	time 0.2466 (0.3063)	loss 1.2004 (1.3716)	grad_norm 4.5306 (5.4807)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:49:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:10:35 lr 0.000001	 wd 0.0000	time 0.2492 (0.2886)	loss 1.5602 (1.3707)	grad_norm 5.2944 (5.2203)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:50:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:09:48 lr 0.000001	 wd 0.0000	time 0.2511 (0.2798)	loss 1.2429 (1.3763)	grad_norm 3.8031 (5.4515)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:50:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:09:09 lr 0.000001	 wd 0.0000	time 0.2487 (0.2745)	loss 0.9524 (1.3808)	grad_norm 3.5247 (5.2914)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:50:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:35 lr 0.000000	 wd 0.0000	time 0.2509 (0.2710)	loss 1.4097 (1.3860)	grad_norm 3.0404 (5.2220)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:51:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:08:03 lr 0.000000	 wd 0.0000	time 0.2486 (0.2686)	loss 1.6934 (1.3852)	grad_norm 7.3953 (5.1476)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:51:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:07:33 lr 0.000000	 wd 0.0000	time 0.2500 (0.2667)	loss 0.8929 (1.3845)	grad_norm 3.9595 (5.0869)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:52:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:07:05 lr 0.000000	 wd 0.0000	time 0.2509 (0.2653)	loss 1.3732 (1.3847)	grad_norm 5.1394 (5.1034)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:52:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:36 lr 0.000000	 wd 0.0000	time 0.2538 (0.2642)	loss 1.3699 (1.3831)	grad_norm 4.0823 (5.0675)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:53:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:06:09 lr 0.000000	 wd 0.0000	time 0.2490 (0.2633)	loss 1.3618 (1.3832)	grad_norm 3.7607 (5.0832)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:53:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:41 lr 0.000000	 wd 0.0000	time 0.2500 (0.2626)	loss 1.3854 (1.3802)	grad_norm 3.8754 (5.0713)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:53:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:05:14 lr 0.000000	 wd 0.0000	time 0.2494 (0.2619)	loss 1.5404 (1.3806)	grad_norm 11.9198 (5.0645)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:54:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:48 lr 0.000000	 wd 0.0000	time 0.2477 (0.2614)	loss 1.6125 (1.3779)	grad_norm 3.9634 (5.0430)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:54:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:04:21 lr 0.000000	 wd 0.0000	time 0.2516 (0.2610)	loss 1.3840 (1.3789)	grad_norm 6.3102 (5.0472)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:55:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:55 lr 0.000000	 wd 0.0000	time 0.2504 (0.2606)	loss 1.3636 (1.3807)	grad_norm 5.3008 (5.0536)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:55:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:28 lr 0.000000	 wd 0.0000	time 0.2512 (0.2602)	loss 1.1862 (1.3784)	grad_norm 6.5873 (5.0579)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:56:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:03:02 lr 0.000000	 wd 0.0000	time 0.2516 (0.2599)	loss 1.1757 (1.3804)	grad_norm 4.2294 (5.0472)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:56:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:36 lr 0.000000	 wd 0.0000	time 0.2573 (0.2597)	loss 1.3227 (1.3796)	grad_norm 4.0229 (5.0527)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:56:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:02:10 lr 0.000000	 wd 0.0000	time 0.2507 (0.2594)	loss 1.6086 (1.3793)	grad_norm 6.5296 (5.0461)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:57:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:44 lr 0.000000	 wd 0.0000	time 0.2531 (0.2592)	loss 1.4219 (1.3799)	grad_norm 3.3865 (5.0503)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:57:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:18 lr 0.000000	 wd 0.0000	time 0.2502 (0.2591)	loss 1.5006 (1.3816)	grad_norm 5.4517 (5.0618)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:58:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:52 lr 0.000000	 wd 0.0000	time 0.2533 (0.2589)	loss 1.5299 (1.3827)	grad_norm 9.4709 (5.0504)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:58:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.2512 (0.2587)	loss 1.5596 (1.3833)	grad_norm 5.4586 (5.0556)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:59:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000000	 wd 0.0000	time 0.2508 (0.2585)	loss 1.4644 (1.3827)	grad_norm 15.1709 (5.0497)	loss_scale 512.0000 (512.0000)	mem 9231MB
[2024-07-04 02:59:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 29 training takes 0:10:54
[2024-07-04 02:59:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_29.pth saving......
[2024-07-04 02:59:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_swin_base_patch4_22kto1k_finetune_seq_stage_process1/ckpt_epoch_29.pth saved !!!
[2024-07-04 02:59:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 11.000 (11.000)	Loss 0.4058 (0.4058)	Acc@1 93.359 (93.359)	Acc@5 98.438 (98.438)	Mem 9231MB
[2024-07-04 02:59:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 83.864 Acc@5 97.178
[2024-07-04 02:59:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-04 02:59:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 83.87%
[2024-07-04 02:59:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_sequence_stage_process1] (main.py 189): INFO Training time 5:38:08
