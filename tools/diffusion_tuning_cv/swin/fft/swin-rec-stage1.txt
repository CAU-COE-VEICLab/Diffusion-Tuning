[2024-07-02 09:50:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/config.json
[2024-07-02 09:50:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/swin-b/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    FINETUNE_MODE: stage1
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: swin_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    DEPTHS:
    - 3
    - 3
    - 9
    - 3
    DIMS:
    - 96
    - 192
    - 384
    - 768
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 4.0e-05
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.0e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 4.0e-08
  WEIGHT_DECAY: 1.0e-08

[2024-07-02 09:50:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/swin/diffusion_ft_swin_base_patch4_window7_224_22kto1k_finetune_process1_ab_embedding.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/swin-b/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-02 09:50:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 108): INFO Creating model:swin_diffusion_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding
[2024-07-02 09:50:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 110): INFO SwinTransformer_Diffusion_Finetune(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=128, window_size=(7, 7), num_heads=4
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=256, window_size=(7, 7), num_heads=8
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=512, window_size=(7, 7), num_heads=16
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1024, window_size=(7, 7), num_heads=32
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-02 09:50:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 113): INFO number of params: 3142136
[2024-07-02 09:50:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 116): INFO number of GFLOPs: 15.438473216
[2024-07-02 09:50:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 150): INFO no checkpoint found in pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding, ignoring auto resume
[2024-07-02 09:50:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/swin-b/ckpt_epoch_best.pth for fine-tuning......
[2024-07-02 09:50:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])
[2024-07-02 09:50:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/swin-b/ckpt_epoch_best.pth'
[2024-07-02 09:51:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 73.156 (73.156)	Loss 0.4207 (0.4207)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 1403MB
[2024-07-02 09:51:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.784 Acc@5 97.110
[2024-07-02 09:51:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 162): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-02 09:51:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 168): INFO Start training
[2024-07-02 09:51:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][0/2502]	eta 14:18:11 lr 0.000000	 wd 0.0000	time 20.5802 (20.5802)	loss 1.6343 (1.6343)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 8457MB
[2024-07-02 09:52:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:18:01 lr 0.000000	 wd 0.0000	time 0.5019 (0.4501)	loss 1.4455 (1.4194)	grad_norm 2.7254 (nan)	loss_scale 4096.0000 (6650.9307)	mem 8479MB
[2024-07-02 09:53:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:16:39 lr 0.000001	 wd 0.0000	time 0.2001 (0.4342)	loss 1.3103 (1.4019)	grad_norm 5.8716 (nan)	loss_scale 2048.0000 (4442.4279)	mem 8479MB
[2024-07-02 09:53:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:13:14 lr 0.000001	 wd 0.0000	time 0.2140 (0.3608)	loss 1.3177 (1.3825)	grad_norm 12.4386 (nan)	loss_scale 2048.0000 (3646.9369)	mem 8479MB
[2024-07-02 09:53:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:11:19 lr 0.000001	 wd 0.0000	time 0.2101 (0.3234)	loss 1.8627 (1.3845)	grad_norm 3.9803 (nan)	loss_scale 2048.0000 (3248.1995)	mem 8479MB
[2024-07-02 09:54:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:11:03 lr 0.000002	 wd 0.0000	time 0.7696 (0.3315)	loss 1.5906 (1.3850)	grad_norm 4.1052 (nan)	loss_scale 2048.0000 (3008.6387)	mem 8479MB
[2024-07-02 09:54:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:10:01 lr 0.000002	 wd 0.0000	time 0.2169 (0.3163)	loss 0.9965 (1.3895)	grad_norm 2.6410 (nan)	loss_scale 2048.0000 (2848.7987)	mem 8479MB
[2024-07-02 09:55:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:09:03 lr 0.000002	 wd 0.0000	time 0.2168 (0.3018)	loss 1.4833 (1.3874)	grad_norm 4.0782 (nan)	loss_scale 2048.0000 (2734.5621)	mem 8479MB
[2024-07-02 09:55:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:08:15 lr 0.000003	 wd 0.0000	time 0.2438 (0.2909)	loss 1.5931 (1.3875)	grad_norm 2.8225 (nan)	loss_scale 1024.0000 (2559.3608)	mem 8479MB
[2024-07-02 09:55:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:41 lr 0.000003	 wd 0.0000	time 0.2343 (0.2879)	loss 1.6022 (1.3826)	grad_norm 4.9646 (nan)	loss_scale 1024.0000 (2388.9545)	mem 8479MB
[2024-07-02 09:56:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:07:01 lr 0.000003	 wd 0.0000	time 0.2232 (0.2807)	loss 1.3898 (1.3821)	grad_norm 3.9385 (nan)	loss_scale 1024.0000 (2252.5954)	mem 8479MB
[2024-07-02 09:56:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:24 lr 0.000004	 wd 0.0000	time 0.2084 (0.2745)	loss 1.5296 (1.3826)	grad_norm 11.9935 (nan)	loss_scale 1024.0000 (2141.0064)	mem 8479MB
[2024-07-02 09:57:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:50 lr 0.000004	 wd 0.0000	time 0.2186 (0.2694)	loss 1.3464 (1.3859)	grad_norm 3.0176 (nan)	loss_scale 1024.0000 (2048.0000)	mem 8479MB
[2024-07-02 09:57:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:20 lr 0.000004	 wd 0.0000	time 0.2145 (0.2665)	loss 1.5404 (1.3878)	grad_norm 3.3582 (nan)	loss_scale 1024.0000 (1969.2913)	mem 8479MB
[2024-07-02 09:57:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:51 lr 0.000005	 wd 0.0000	time 0.1900 (0.2643)	loss 1.5808 (1.3887)	grad_norm 3.6766 (nan)	loss_scale 1024.0000 (1901.8187)	mem 8479MB
[2024-07-02 09:58:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:21 lr 0.000005	 wd 0.0000	time 0.2295 (0.2609)	loss 1.3825 (1.3882)	grad_norm 6.1029 (nan)	loss_scale 1024.0000 (1843.3364)	mem 8479MB
[2024-07-02 09:58:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:52 lr 0.000005	 wd 0.0000	time 0.1943 (0.2580)	loss 1.7720 (1.3891)	grad_norm 2.8998 (nan)	loss_scale 1024.0000 (1792.1599)	mem 8479MB
[2024-07-02 09:58:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:25 lr 0.000005	 wd 0.0000	time 0.2837 (0.2559)	loss 1.5937 (1.3886)	grad_norm 3.0864 (nan)	loss_scale 512.0000 (1722.9206)	mem 8479MB
[2024-07-02 09:59:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:02:59 lr 0.000006	 wd 0.0000	time 0.2193 (0.2560)	loss 1.2385 (1.3887)	grad_norm 3.6801 (nan)	loss_scale 512.0000 (1655.6846)	mem 8479MB
[2024-07-02 09:59:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:32 lr 0.000006	 wd 0.0000	time 0.1985 (0.2539)	loss 1.4547 (1.3880)	grad_norm 4.3729 (nan)	loss_scale 512.0000 (1595.5224)	mem 8479MB
[2024-07-02 10:00:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:06 lr 0.000006	 wd 0.0000	time 0.2357 (0.2521)	loss 1.5396 (1.3858)	grad_norm 5.3702 (nan)	loss_scale 512.0000 (1541.3733)	mem 8479MB
[2024-07-02 10:00:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:40 lr 0.000007	 wd 0.0000	time 0.2676 (0.2505)	loss 1.4113 (1.3871)	grad_norm 4.1685 (nan)	loss_scale 512.0000 (1492.3789)	mem 8479MB
[2024-07-02 10:00:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:15 lr 0.000007	 wd 0.0000	time 0.2331 (0.2500)	loss 1.5486 (1.3872)	grad_norm 12.1231 (nan)	loss_scale 512.0000 (1447.8364)	mem 8479MB
[2024-07-02 10:01:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:50 lr 0.000007	 wd 0.0000	time 0.2035 (0.2488)	loss 1.4217 (1.3859)	grad_norm 3.7116 (nan)	loss_scale 512.0000 (1407.1656)	mem 8479MB
[2024-07-02 10:01:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:25 lr 0.000008	 wd 0.0000	time 0.2321 (0.2474)	loss 1.4872 (1.3865)	grad_norm 3.4904 (nan)	loss_scale 512.0000 (1369.8825)	mem 8479MB
[2024-07-02 10:01:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1649 (0.2449)	loss 1.6143 (1.3868)	grad_norm 3.2383 (nan)	loss_scale 512.0000 (1335.5810)	mem 8479MB
[2024-07-02 10:01:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 0 training takes 0:10:17
[2024-07-02 10:01:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_0.pth saving......
[2024-07-02 10:01:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_0.pth saved !!!
[2024-07-02 10:02:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 51.862 (51.862)	Loss 0.4202 (0.4202)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 8479MB
[2024-07-02 10:03:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.758 Acc@5 97.146
[2024-07-02 10:03:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-02 10:03:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.76%
[2024-07-02 10:03:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saving......
[2024-07-02 10:03:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saved !!!
[2024-07-02 10:03:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][0/2502]	eta 11:43:23 lr 0.000008	 wd 0.0000	time 16.8678 (16.8678)	loss 1.2458 (1.2458)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:03:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:16:22 lr 0.000008	 wd 0.0000	time 0.3982 (0.4092)	loss 1.1891 (1.4164)	grad_norm 7.5247 (4.2256)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:04:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:14:23 lr 0.000009	 wd 0.0000	time 0.2197 (0.3753)	loss 1.4233 (1.4219)	grad_norm 2.8824 (4.0887)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:04:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:44 lr 0.000009	 wd 0.0000	time 0.1983 (0.3200)	loss 1.7312 (1.4079)	grad_norm 4.2632 (4.0605)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:04:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:10:14 lr 0.000009	 wd 0.0000	time 0.1933 (0.2922)	loss 0.9209 (1.3937)	grad_norm 2.9789 (4.0829)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:05:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:09:29 lr 0.000010	 wd 0.0000	time 0.4785 (0.2844)	loss 1.6840 (1.3916)	grad_norm 8.0229 (4.1922)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:05:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:09:15 lr 0.000010	 wd 0.0000	time 0.2126 (0.2923)	loss 1.3907 (1.3883)	grad_norm 4.9339 (4.1681)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:06:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:26 lr 0.000010	 wd 0.0000	time 0.2240 (0.2812)	loss 1.5228 (1.3865)	grad_norm 3.6629 (4.2328)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:06:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:42 lr 0.000011	 wd 0.0000	time 0.2131 (0.2720)	loss 1.5605 (1.3901)	grad_norm 2.6290 (4.2822)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:07:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:14 lr 0.000011	 wd 0.0000	time 0.4531 (0.2714)	loss 1.5650 (1.3886)	grad_norm 7.6670 (4.3640)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:07:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:49 lr 0.000011	 wd 0.0000	time 0.2112 (0.2730)	loss 1.4782 (1.3869)	grad_norm 4.6686 (4.3402)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:07:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:06:14 lr 0.000012	 wd 0.0000	time 0.1930 (0.2674)	loss 1.1349 (1.3872)	grad_norm 7.8685 (4.3438)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:08:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:42 lr 0.000012	 wd 0.0000	time 0.1951 (0.2628)	loss 1.4358 (1.3903)	grad_norm 4.4397 (4.3359)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:08:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:15 lr 0.000012	 wd 0.0000	time 0.3707 (0.2627)	loss 1.5275 (1.3918)	grad_norm 3.3479 (4.3499)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:09:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:50 lr 0.000012	 wd 0.0000	time 0.1878 (0.2640)	loss 1.4947 (1.3898)	grad_norm 4.4347 (4.3930)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:09:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:21 lr 0.000013	 wd 0.0000	time 0.1966 (0.2608)	loss 0.9746 (1.3882)	grad_norm 2.8835 (4.3629)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:09:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:52 lr 0.000013	 wd 0.0000	time 0.2057 (0.2577)	loss 0.9915 (1.3873)	grad_norm 3.9649 (4.3702)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:10:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:25 lr 0.000013	 wd 0.0000	time 0.2265 (0.2562)	loss 1.4273 (1.3874)	grad_norm 3.3979 (4.3829)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:10:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:59 lr 0.000014	 wd 0.0000	time 0.2387 (0.2560)	loss 1.3616 (1.3867)	grad_norm 5.4067 (4.3644)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:11:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:32 lr 0.000014	 wd 0.0000	time 0.2316 (0.2539)	loss 1.4160 (1.3878)	grad_norm 2.9855 (4.3600)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:11:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:06 lr 0.000014	 wd 0.0000	time 0.2252 (0.2519)	loss 1.4415 (1.3877)	grad_norm 8.3926 (4.3853)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:11:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:40 lr 0.000015	 wd 0.0000	time 0.2138 (0.2506)	loss 1.5728 (1.3887)	grad_norm 3.5788 (4.3683)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:12:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:15 lr 0.000015	 wd 0.0000	time 0.2170 (0.2504)	loss 1.0790 (1.3894)	grad_norm 3.5762 (4.3564)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:12:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:50 lr 0.000015	 wd 0.0000	time 0.2077 (0.2491)	loss 1.3964 (1.3898)	grad_norm 6.8444 (4.3609)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:12:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:25 lr 0.000016	 wd 0.0000	time 0.1951 (0.2477)	loss 1.5717 (1.3881)	grad_norm 3.0466 (4.3617)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:13:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1785 (0.2453)	loss 1.1268 (1.3896)	grad_norm 3.4205 (4.3600)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:13:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 1 training takes 0:10:18
[2024-07-02 10:14:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 47.122 (47.122)	Loss 0.4236 (0.4236)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 8479MB
[2024-07-02 10:14:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.760 Acc@5 97.098
[2024-07-02 10:14:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-02 10:14:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.76%
[2024-07-02 10:14:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saving......
[2024-07-02 10:14:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saved !!!
[2024-07-02 10:14:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][0/2502]	eta 11:23:31 lr 0.000016	 wd 0.0000	time 16.3914 (16.3914)	loss 1.4602 (1.4602)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:15:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:15:34 lr 0.000016	 wd 0.0000	time 0.2788 (0.3891)	loss 1.5096 (1.3667)	grad_norm 4.7506 (4.1605)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:15:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:13:47 lr 0.000017	 wd 0.0000	time 0.2085 (0.3594)	loss 1.5193 (1.3859)	grad_norm 3.3959 (4.4255)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:15:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:11:20 lr 0.000017	 wd 0.0000	time 0.1937 (0.3089)	loss 1.1874 (1.3904)	grad_norm 3.5816 (4.4225)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:16:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:09:56 lr 0.000017	 wd 0.0000	time 0.2015 (0.2837)	loss 1.5663 (1.3860)	grad_norm 4.7846 (4.4340)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:16:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:09:02 lr 0.000018	 wd 0.0000	time 0.2352 (0.2709)	loss 1.4507 (1.3882)	grad_norm 3.9600 (4.3746)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:17:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:56 lr 0.000018	 wd 0.0000	time 0.1877 (0.2821)	loss 1.3069 (1.3820)	grad_norm 3.2292 (4.3517)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:17:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:08:10 lr 0.000018	 wd 0.0000	time 0.2040 (0.2723)	loss 1.2515 (1.3854)	grad_norm 3.8026 (nan)	loss_scale 512.0000 (513.4608)	mem 8479MB
[2024-07-02 10:17:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:30 lr 0.000019	 wd 0.0000	time 0.2119 (0.2645)	loss 1.5929 (1.3837)	grad_norm 2.7517 (nan)	loss_scale 512.0000 (513.2784)	mem 8479MB
[2024-07-02 10:18:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:57 lr 0.000019	 wd 0.0000	time 0.2832 (0.2605)	loss 1.5285 (1.3888)	grad_norm 4.6117 (nan)	loss_scale 512.0000 (513.1365)	mem 8479MB
[2024-07-02 10:18:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:40 lr 0.000019	 wd 0.0000	time 0.2146 (0.2668)	loss 1.4987 (1.3906)	grad_norm 4.0840 (nan)	loss_scale 512.0000 (513.0230)	mem 8479MB
[2024-07-02 10:19:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:06:06 lr 0.000020	 wd 0.0000	time 0.2123 (0.2618)	loss 1.1963 (1.3911)	grad_norm 3.0004 (nan)	loss_scale 512.0000 (512.9301)	mem 8479MB
[2024-07-02 10:19:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:35 lr 0.000020	 wd 0.0000	time 0.2084 (0.2576)	loss 1.3464 (1.3902)	grad_norm 4.6371 (nan)	loss_scale 512.0000 (512.8526)	mem 8479MB
[2024-07-02 10:19:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:05:07 lr 0.000020	 wd 0.0000	time 0.2555 (0.2555)	loss 1.6721 (1.3929)	grad_norm 2.5229 (nan)	loss_scale 512.0000 (512.7871)	mem 8479MB
[2024-07-02 10:20:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:40 lr 0.000020	 wd 0.0000	time 0.2680 (0.2548)	loss 1.4123 (1.3934)	grad_norm 2.7855 (nan)	loss_scale 512.0000 (512.7309)	mem 8479MB
[2024-07-02 10:20:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:12 lr 0.000021	 wd 0.0000	time 0.2029 (0.2523)	loss 1.5468 (1.3914)	grad_norm 3.6698 (nan)	loss_scale 512.0000 (512.6822)	mem 8479MB
[2024-07-02 10:21:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:45 lr 0.000021	 wd 0.0000	time 0.1992 (0.2499)	loss 1.2755 (1.3918)	grad_norm 4.3356 (nan)	loss_scale 512.0000 (512.6396)	mem 8479MB
[2024-07-02 10:21:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:19 lr 0.000021	 wd 0.0000	time 0.2381 (0.2482)	loss 1.3423 (1.3907)	grad_norm 4.3275 (nan)	loss_scale 512.0000 (512.6020)	mem 8479MB
[2024-07-02 10:21:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:54 lr 0.000022	 wd 0.0000	time 0.2209 (0.2481)	loss 1.3572 (1.3905)	grad_norm 3.8983 (nan)	loss_scale 512.0000 (512.5686)	mem 8479MB
[2024-07-02 10:22:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:28 lr 0.000022	 wd 0.0000	time 0.2145 (0.2471)	loss 0.9800 (1.3889)	grad_norm 3.5093 (nan)	loss_scale 512.0000 (512.5387)	mem 8479MB
[2024-07-02 10:22:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:02:03 lr 0.000022	 wd 0.0000	time 0.2187 (0.2455)	loss 1.1956 (1.3866)	grad_norm 3.1087 (nan)	loss_scale 512.0000 (512.5117)	mem 8479MB
[2024-07-02 10:22:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:38 lr 0.000023	 wd 0.0000	time 0.2131 (0.2441)	loss 1.4518 (1.3868)	grad_norm 3.2964 (nan)	loss_scale 512.0000 (512.4874)	mem 8479MB
[2024-07-02 10:23:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:13 lr 0.000023	 wd 0.0000	time 0.2171 (0.2434)	loss 1.6263 (1.3865)	grad_norm 8.9339 (nan)	loss_scale 512.0000 (512.4652)	mem 8479MB
[2024-07-02 10:23:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:49 lr 0.000023	 wd 0.0000	time 0.2013 (0.2434)	loss 1.6961 (1.3868)	grad_norm 3.3844 (nan)	loss_scale 512.0000 (512.4450)	mem 8479MB
[2024-07-02 10:24:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:24 lr 0.000024	 wd 0.0000	time 0.2379 (0.2422)	loss 1.5225 (1.3860)	grad_norm 2.9196 (nan)	loss_scale 512.0000 (512.4265)	mem 8479MB
[2024-07-02 10:24:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1634 (0.2399)	loss 1.5550 (1.3861)	grad_norm 3.6451 (nan)	loss_scale 512.0000 (512.4094)	mem 8479MB
[2024-07-02 10:24:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 2 training takes 0:10:04
[2024-07-02 10:25:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 40.894 (40.894)	Loss 0.4197 (0.4197)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 8479MB
[2024-07-02 10:25:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.748 Acc@5 97.150
[2024-07-02 10:25:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-02 10:25:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.76%
[2024-07-02 10:25:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][0/2502]	eta 11:57:02 lr 0.000024	 wd 0.0000	time 17.1951 (17.1951)	loss 0.9939 (0.9939)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:25:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:15:16 lr 0.000024	 wd 0.0000	time 0.1726 (0.3817)	loss 1.4846 (1.3601)	grad_norm 8.1483 (4.3213)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:26:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:12:32 lr 0.000025	 wd 0.0000	time 0.6432 (0.3267)	loss 1.4249 (1.3760)	grad_norm 5.0698 (4.4667)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:26:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:12:15 lr 0.000025	 wd 0.0000	time 0.2117 (0.3338)	loss 1.5820 (1.3699)	grad_norm 3.0991 (5.1647)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:27:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:10:37 lr 0.000025	 wd 0.0000	time 0.1916 (0.3034)	loss 1.5564 (1.3730)	grad_norm 2.8883 (4.9411)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:27:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:09:28 lr 0.000026	 wd 0.0000	time 0.2090 (0.2841)	loss 1.4425 (1.3716)	grad_norm 3.4222 (4.8164)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:28:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:09:10 lr 0.000026	 wd 0.0000	time 0.4922 (0.2896)	loss 1.4235 (1.3723)	grad_norm 4.7015 (4.8367)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:28:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:08:29 lr 0.000026	 wd 0.0000	time 0.2153 (0.2827)	loss 1.7063 (1.3744)	grad_norm 5.5781 (4.8389)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:28:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:46 lr 0.000027	 wd 0.0000	time 0.2078 (0.2740)	loss 1.1109 (1.3749)	grad_norm 2.5531 (4.7909)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:29:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:07:07 lr 0.000027	 wd 0.0000	time 0.2546 (0.2670)	loss 1.4882 (1.3764)	grad_norm 4.0846 (4.7215)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:29:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:36 lr 0.000027	 wd 0.0000	time 0.2280 (0.2643)	loss 1.5185 (1.3793)	grad_norm 5.4946 (4.7219)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:30:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:06:07 lr 0.000028	 wd 0.0000	time 0.2072 (0.2619)	loss 1.4031 (1.3818)	grad_norm 4.3155 (4.6875)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:30:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:35 lr 0.000028	 wd 0.0000	time 0.2041 (0.2580)	loss 1.2323 (1.3801)	grad_norm 3.7068 (4.6631)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:30:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:05:06 lr 0.000028	 wd 0.0000	time 0.2179 (0.2546)	loss 1.3119 (1.3827)	grad_norm 3.4359 (4.6295)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:31:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:38 lr 0.000028	 wd 0.0000	time 0.2299 (0.2527)	loss 1.2788 (1.3833)	grad_norm 6.9501 (4.5999)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:31:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:12 lr 0.000029	 wd 0.0000	time 0.2262 (0.2520)	loss 1.4801 (1.3851)	grad_norm 3.5147 (4.5861)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:31:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:45 lr 0.000029	 wd 0.0000	time 0.2197 (0.2500)	loss 1.5376 (1.3839)	grad_norm 2.8034 (4.5973)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:32:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:18 lr 0.000029	 wd 0.0000	time 0.2238 (0.2479)	loss 1.1210 (1.3830)	grad_norm 3.7730 (4.6602)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:32:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:52 lr 0.000030	 wd 0.0000	time 0.2071 (0.2464)	loss 1.5480 (1.3833)	grad_norm 3.6382 (4.6486)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:33:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:28 lr 0.000030	 wd 0.0000	time 0.1996 (0.2472)	loss 1.5134 (1.3825)	grad_norm 3.7386 (4.6339)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:33:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:03 lr 0.000030	 wd 0.0000	time 0.2494 (0.2461)	loss 1.1745 (1.3832)	grad_norm 3.9405 (4.6187)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:33:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:38 lr 0.000031	 wd 0.0000	time 0.2068 (0.2447)	loss 1.1817 (1.3821)	grad_norm 2.9039 (4.6154)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:34:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:13 lr 0.000031	 wd 0.0000	time 0.2305 (0.2434)	loss 1.4117 (1.3829)	grad_norm 4.9954 (4.5965)	loss_scale 1024.0000 (531.5402)	mem 8479MB
[2024-07-02 10:34:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:49 lr 0.000031	 wd 0.0000	time 0.4457 (0.2431)	loss 1.5126 (1.3839)	grad_norm 3.1375 (4.5876)	loss_scale 1024.0000 (552.9422)	mem 8479MB
[2024-07-02 10:35:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:24 lr 0.000032	 wd 0.0000	time 0.2082 (0.2423)	loss 1.0081 (1.3831)	grad_norm 4.1623 (4.5743)	loss_scale 1024.0000 (572.5614)	mem 8479MB
[2024-07-02 10:35:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000032	 wd 0.0000	time 0.1709 (0.2401)	loss 1.4723 (1.3834)	grad_norm 4.8297 (4.5629)	loss_scale 1024.0000 (590.6118)	mem 8479MB
[2024-07-02 10:35:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 3 training takes 0:10:05
[2024-07-02 10:35:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 22.178 (22.178)	Loss 0.4175 (0.4175)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 8479MB
[2024-07-02 10:35:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.734 Acc@5 97.146
[2024-07-02 10:35:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.7%
[2024-07-02 10:35:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.76%
[2024-07-02 10:36:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][0/2502]	eta 1 day, 0:16:05 lr 0.000032	 wd 0.0000	time 34.9182 (34.9182)	loss 1.4247 (1.4247)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:36:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:22:28 lr 0.000032	 wd 0.0000	time 0.2208 (0.5616)	loss 1.2759 (1.4139)	grad_norm 5.0602 (4.0994)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:37:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:14:48 lr 0.000033	 wd 0.0000	time 0.2006 (0.3859)	loss 1.1416 (1.4019)	grad_norm 3.0474 (4.1302)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:37:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:12:11 lr 0.000033	 wd 0.0000	time 0.2299 (0.3321)	loss 1.1239 (1.4030)	grad_norm 3.2908 (4.2499)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:38:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:11:39 lr 0.000033	 wd 0.0000	time 0.1953 (0.3329)	loss 1.4519 (1.3926)	grad_norm 3.2880 (4.3177)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:38:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:10:17 lr 0.000034	 wd 0.0000	time 0.2123 (0.3085)	loss 1.4273 (1.3881)	grad_norm 3.1519 (4.3137)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:38:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:09:14 lr 0.000034	 wd 0.0000	time 0.2206 (0.2916)	loss 1.4404 (1.3831)	grad_norm 3.0818 (4.3142)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:39:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:08:29 lr 0.000034	 wd 0.0000	time 0.2121 (0.2826)	loss 1.2890 (1.3833)	grad_norm 2.9563 (4.3427)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:39:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:51 lr 0.000035	 wd 0.0000	time 0.2192 (0.2770)	loss 1.3565 (1.3843)	grad_norm 3.3752 (4.3527)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:40:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:07:13 lr 0.000035	 wd 0.0000	time 0.2180 (0.2705)	loss 1.4955 (1.3853)	grad_norm 4.6197 (4.3975)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:40:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:38 lr 0.000035	 wd 0.0000	time 0.1909 (0.2650)	loss 1.5539 (1.3859)	grad_norm 3.6003 (4.4308)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:40:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:06:05 lr 0.000036	 wd 0.0000	time 0.2140 (0.2604)	loss 1.5670 (1.3862)	grad_norm 4.4498 (4.4330)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:41:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:38 lr 0.000036	 wd 0.0000	time 0.2716 (0.2598)	loss 1.0708 (1.3855)	grad_norm 4.4696 (4.4117)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:41:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:05:08 lr 0.000036	 wd 0.0000	time 0.2548 (0.2566)	loss 1.5652 (1.3844)	grad_norm 4.7010 (4.4052)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:41:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:39 lr 0.000036	 wd 0.0000	time 0.2333 (0.2537)	loss 1.4741 (1.3846)	grad_norm 5.8018 (4.4240)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:42:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:11 lr 0.000037	 wd 0.0000	time 0.1990 (0.2509)	loss 1.3043 (1.3875)	grad_norm 3.8157 (4.4766)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:42:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:45 lr 0.000037	 wd 0.0000	time 0.2043 (0.2495)	loss 1.2066 (1.3869)	grad_norm 3.7829 (4.4685)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:43:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:19 lr 0.000037	 wd 0.0000	time 0.1970 (0.2491)	loss 1.5676 (1.3865)	grad_norm 4.7426 (4.4780)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:43:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:53 lr 0.000038	 wd 0.0000	time 0.2405 (0.2473)	loss 1.5693 (1.3861)	grad_norm 3.5556 (4.4588)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:43:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:27 lr 0.000038	 wd 0.0000	time 0.1978 (0.2457)	loss 1.5676 (1.3859)	grad_norm 3.2539 (4.4734)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:44:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:02:02 lr 0.000038	 wd 0.0000	time 0.3026 (0.2446)	loss 1.5784 (1.3861)	grad_norm 5.7437 (4.4689)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:44:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:38 lr 0.000039	 wd 0.0000	time 0.2250 (0.2451)	loss 1.3846 (1.3861)	grad_norm 8.6300 (4.4761)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:44:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:13 lr 0.000039	 wd 0.0000	time 0.1920 (0.2440)	loss 1.0045 (1.3832)	grad_norm 3.2622 (4.4718)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:45:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:49 lr 0.000039	 wd 0.0000	time 0.2253 (0.2427)	loss 1.3238 (1.3841)	grad_norm 4.6484 (4.4686)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:45:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:24 lr 0.000040	 wd 0.0000	time 0.2402 (0.2418)	loss 1.4627 (1.3836)	grad_norm 4.6694 (4.4787)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:45:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1719 (0.2402)	loss 0.9039 (1.3834)	grad_norm 2.5904 (4.4972)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:46:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 4 training takes 0:10:10
[2024-07-02 10:46:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 28.582 (28.582)	Loss 0.4207 (0.4207)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 8479MB
[2024-07-02 10:46:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.762 Acc@5 97.122
[2024-07-02 10:46:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-02 10:46:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.76%
[2024-07-02 10:46:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saving......
[2024-07-02 10:46:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saved !!!
[2024-07-02 10:47:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][0/2502]	eta 10:54:36 lr 0.000040	 wd 0.0000	time 15.6981 (15.6981)	loss 1.6005 (1.6005)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 10:47:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:18:06 lr 0.000040	 wd 0.0000	time 0.2012 (0.4524)	loss 1.3401 (1.3991)	grad_norm 4.5322 (inf)	loss_scale 512.0000 (851.6436)	mem 8479MB
[2024-07-02 10:47:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:12:51 lr 0.000040	 wd 0.0000	time 0.2062 (0.3350)	loss 1.4706 (1.4143)	grad_norm 3.8005 (inf)	loss_scale 512.0000 (682.6667)	mem 8479MB
[2024-07-02 10:48:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:46 lr 0.000040	 wd 0.0000	time 0.2312 (0.2936)	loss 1.6865 (1.4006)	grad_norm 3.1972 (inf)	loss_scale 512.0000 (625.9668)	mem 8479MB
[2024-07-02 10:48:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:31 lr 0.000040	 wd 0.0000	time 0.2165 (0.2720)	loss 1.1587 (1.4018)	grad_norm 4.6328 (inf)	loss_scale 512.0000 (597.5461)	mem 8479MB
[2024-07-02 10:49:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:08:51 lr 0.000040	 wd 0.0000	time 0.3551 (0.2655)	loss 1.6783 (1.3963)	grad_norm 3.6236 (inf)	loss_scale 512.0000 (580.4711)	mem 8479MB
[2024-07-02 10:49:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:35 lr 0.000040	 wd 0.0000	time 0.1822 (0.2710)	loss 1.5826 (1.3993)	grad_norm 3.1604 (inf)	loss_scale 512.0000 (569.0782)	mem 8479MB
[2024-07-02 10:49:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:53 lr 0.000040	 wd 0.0000	time 0.2256 (0.2627)	loss 1.4804 (1.3964)	grad_norm 3.4443 (inf)	loss_scale 512.0000 (560.9358)	mem 8479MB
[2024-07-02 10:50:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:16 lr 0.000040	 wd 0.0000	time 0.2252 (0.2563)	loss 1.0924 (1.3903)	grad_norm 3.5758 (inf)	loss_scale 512.0000 (554.8265)	mem 8479MB
[2024-07-02 10:50:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:50 lr 0.000040	 wd 0.0000	time 0.4675 (0.2562)	loss 0.8428 (1.3888)	grad_norm 2.7543 (inf)	loss_scale 512.0000 (550.0733)	mem 8479MB
[2024-07-02 10:51:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:34 lr 0.000040	 wd 0.0000	time 0.2183 (0.2623)	loss 1.4019 (1.3916)	grad_norm 2.4884 (inf)	loss_scale 512.0000 (546.2697)	mem 8479MB
[2024-07-02 10:51:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:06:01 lr 0.000040	 wd 0.0000	time 0.2225 (0.2579)	loss 1.5699 (1.3872)	grad_norm 2.4741 (inf)	loss_scale 512.0000 (543.1571)	mem 8479MB
[2024-07-02 10:51:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:30 lr 0.000040	 wd 0.0000	time 0.2030 (0.2539)	loss 1.5269 (1.3868)	grad_norm 8.3002 (inf)	loss_scale 512.0000 (540.5629)	mem 8479MB
[2024-07-02 10:52:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:05:03 lr 0.000040	 wd 0.0000	time 0.2266 (0.2523)	loss 1.5382 (1.3867)	grad_norm 2.6722 (inf)	loss_scale 512.0000 (538.3674)	mem 8479MB
[2024-07-02 10:52:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:36 lr 0.000040	 wd 0.0000	time 0.2464 (0.2513)	loss 1.5038 (1.3863)	grad_norm 2.5406 (inf)	loss_scale 512.0000 (536.4854)	mem 8479MB
[2024-07-02 10:53:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:04:09 lr 0.000040	 wd 0.0000	time 0.2042 (0.2489)	loss 1.3234 (1.3863)	grad_norm 2.7164 (inf)	loss_scale 512.0000 (534.8541)	mem 8479MB
[2024-07-02 10:53:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:42 lr 0.000040	 wd 0.0000	time 0.2198 (0.2469)	loss 1.4738 (1.3874)	grad_norm 4.4522 (inf)	loss_scale 512.0000 (533.4266)	mem 8479MB
[2024-07-02 10:53:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:16 lr 0.000040	 wd 0.0000	time 0.2128 (0.2454)	loss 1.4907 (1.3874)	grad_norm 4.4810 (inf)	loss_scale 512.0000 (532.1670)	mem 8479MB
[2024-07-02 10:54:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:52 lr 0.000040	 wd 0.0000	time 0.3503 (0.2459)	loss 1.0779 (1.3862)	grad_norm 10.1903 (inf)	loss_scale 512.0000 (531.0472)	mem 8479MB
[2024-07-02 10:54:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:27 lr 0.000040	 wd 0.0000	time 0.2158 (0.2446)	loss 1.5390 (1.3883)	grad_norm 3.4863 (inf)	loss_scale 512.0000 (530.0452)	mem 8479MB
[2024-07-02 10:54:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:02:02 lr 0.000040	 wd 0.0000	time 0.2241 (0.2432)	loss 1.4363 (1.3896)	grad_norm 4.3808 (inf)	loss_scale 512.0000 (529.1434)	mem 8479MB
[2024-07-02 10:55:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:37 lr 0.000040	 wd 0.0000	time 0.2420 (0.2421)	loss 1.6201 (1.3906)	grad_norm 8.5931 (inf)	loss_scale 512.0000 (528.3275)	mem 8479MB
[2024-07-02 10:55:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:13 lr 0.000040	 wd 0.0000	time 0.2413 (0.2422)	loss 1.3909 (1.3885)	grad_norm 3.0568 (inf)	loss_scale 512.0000 (527.5856)	mem 8479MB
[2024-07-02 10:56:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:48 lr 0.000040	 wd 0.0000	time 0.2054 (0.2418)	loss 0.9556 (1.3880)	grad_norm 3.4398 (inf)	loss_scale 512.0000 (526.9083)	mem 8479MB
[2024-07-02 10:56:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:24 lr 0.000040	 wd 0.0000	time 0.2158 (0.2408)	loss 1.6108 (1.3882)	grad_norm 4.8889 (inf)	loss_scale 512.0000 (526.2874)	mem 8479MB
[2024-07-02 10:56:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1647 (0.2387)	loss 1.5081 (1.3880)	grad_norm 3.2060 (inf)	loss_scale 512.0000 (525.7161)	mem 8479MB
[2024-07-02 10:56:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 5 training takes 0:10:01
[2024-07-02 10:57:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 41.571 (41.571)	Loss 0.4170 (0.4170)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 8479MB
[2024-07-02 10:57:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.780 Acc@5 97.126
[2024-07-02 10:57:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-02 10:57:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.78%
[2024-07-02 10:57:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saving......
[2024-07-02 10:57:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saved !!!
[2024-07-02 10:58:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][0/2502]	eta 11:16:11 lr 0.000040	 wd 0.0000	time 16.2157 (16.2157)	loss 1.7559 (1.7559)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:58:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:14:44 lr 0.000040	 wd 0.0000	time 0.2005 (0.3681)	loss 1.2825 (1.3732)	grad_norm 3.2882 (4.3414)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:58:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:13:48 lr 0.000040	 wd 0.0000	time 0.2977 (0.3598)	loss 1.4621 (1.3889)	grad_norm 3.2204 (4.5273)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:59:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:11:32 lr 0.000040	 wd 0.0000	time 0.2115 (0.3145)	loss 1.5780 (1.3960)	grad_norm 3.6691 (4.6744)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 10:59:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:10:06 lr 0.000040	 wd 0.0000	time 0.2197 (0.2884)	loss 1.4100 (1.3894)	grad_norm 4.9312 (4.6135)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:00:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:09:04 lr 0.000040	 wd 0.0000	time 0.2591 (0.2719)	loss 1.5450 (1.3870)	grad_norm 6.8631 (4.6128)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:00:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:08:27 lr 0.000040	 wd 0.0000	time 0.2218 (0.2666)	loss 1.5109 (1.3883)	grad_norm 3.5818 (4.5774)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:00:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:07:51 lr 0.000040	 wd 0.0000	time 0.2037 (0.2618)	loss 1.4268 (1.3890)	grad_norm 4.4703 (4.4980)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:01:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:15 lr 0.000040	 wd 0.0000	time 0.2200 (0.2557)	loss 1.1455 (1.3888)	grad_norm 4.0862 (4.4698)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:01:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:06:41 lr 0.000040	 wd 0.0000	time 0.2169 (0.2509)	loss 1.5685 (1.3906)	grad_norm 2.5335 (4.4954)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:01:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:13 lr 0.000040	 wd 0.0000	time 0.2287 (0.2486)	loss 1.3307 (1.3871)	grad_norm 5.8085 (4.5113)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:02:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:47 lr 0.000040	 wd 0.0000	time 0.1964 (0.2475)	loss 1.3371 (1.3846)	grad_norm 3.7181 (4.5964)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:02:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:18 lr 0.000040	 wd 0.0000	time 0.2072 (0.2449)	loss 1.1455 (1.3857)	grad_norm 3.2968 (4.5818)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:03:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:04:51 lr 0.000040	 wd 0.0000	time 0.2155 (0.2425)	loss 1.5552 (1.3844)	grad_norm 4.3539 (4.5689)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:03:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:25 lr 0.000040	 wd 0.0000	time 0.2458 (0.2408)	loss 1.7925 (1.3824)	grad_norm 5.0297 (4.5530)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:03:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:00 lr 0.000040	 wd 0.0000	time 0.1929 (0.2405)	loss 1.4723 (1.3845)	grad_norm 5.2684 (4.5674)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:04:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:36 lr 0.000040	 wd 0.0000	time 0.2107 (0.2398)	loss 1.4653 (1.3827)	grad_norm 5.0048 (4.5389)	loss_scale 1024.0000 (523.5128)	mem 8479MB
[2024-07-02 11:04:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:11 lr 0.000040	 wd 0.0000	time 0.2175 (0.2385)	loss 1.5510 (1.3826)	grad_norm 3.8642 (4.5569)	loss_scale 1024.0000 (552.9359)	mem 8479MB
[2024-07-02 11:04:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:46 lr 0.000040	 wd 0.0000	time 0.2062 (0.2371)	loss 1.1270 (1.3822)	grad_norm 2.9336 (4.5434)	loss_scale 1024.0000 (579.0916)	mem 8479MB
[2024-07-02 11:05:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:22 lr 0.000040	 wd 0.0000	time 0.2058 (0.2370)	loss 1.2104 (1.3823)	grad_norm 4.4289 (4.5517)	loss_scale 1024.0000 (602.4955)	mem 8479MB
[2024-07-02 11:05:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:01:59 lr 0.000039	 wd 0.0000	time 0.2059 (0.2374)	loss 1.1010 (1.3828)	grad_norm 3.4542 (4.5291)	loss_scale 1024.0000 (623.5602)	mem 8479MB
[2024-07-02 11:06:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:35 lr 0.000039	 wd 0.0000	time 0.2455 (0.2365)	loss 1.5521 (1.3820)	grad_norm 8.6019 (4.5529)	loss_scale 1024.0000 (642.6197)	mem 8479MB
[2024-07-02 11:06:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:11 lr 0.000039	 wd 0.0000	time 0.2220 (0.2355)	loss 1.2838 (1.3821)	grad_norm 3.2794 (4.5561)	loss_scale 1024.0000 (659.9473)	mem 8479MB
[2024-07-02 11:06:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:47 lr 0.000039	 wd 0.0000	time 0.2527 (0.2350)	loss 1.5445 (1.3826)	grad_norm 3.7989 (4.5644)	loss_scale 1024.0000 (675.7688)	mem 8479MB
[2024-07-02 11:07:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:24 lr 0.000039	 wd 0.0000	time 0.2391 (0.2354)	loss 1.1589 (1.3820)	grad_norm 3.7116 (4.5589)	loss_scale 1024.0000 (690.2724)	mem 8479MB
[2024-07-02 11:07:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1614 (0.2337)	loss 1.0235 (1.3824)	grad_norm 2.8339 (4.5427)	loss_scale 1024.0000 (703.6162)	mem 8479MB
[2024-07-02 11:07:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 6 training takes 0:09:49
[2024-07-02 11:07:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 22.787 (22.787)	Loss 0.4155 (0.4155)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 8479MB
[2024-07-02 11:08:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.766 Acc@5 97.114
[2024-07-02 11:08:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-02 11:08:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.78%
[2024-07-02 11:08:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][0/2502]	eta 1 day, 0:07:24 lr 0.000039	 wd 0.0000	time 34.7101 (34.7101)	loss 1.6971 (1.6971)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:09:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:22:32 lr 0.000039	 wd 0.0000	time 0.2125 (0.5629)	loss 1.3492 (1.3949)	grad_norm 4.3003 (3.8391)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:09:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:14:50 lr 0.000039	 wd 0.0000	time 0.2023 (0.3870)	loss 1.6119 (1.3754)	grad_norm 3.5473 (4.3399)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:09:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:12:04 lr 0.000039	 wd 0.0000	time 0.2224 (0.3289)	loss 1.3654 (1.3765)	grad_norm 4.2456 (4.5756)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:10:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:11:42 lr 0.000039	 wd 0.0000	time 0.2638 (0.3343)	loss 1.4408 (1.3805)	grad_norm 3.5885 (4.4902)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:10:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:10:21 lr 0.000039	 wd 0.0000	time 0.2112 (0.3105)	loss 1.5464 (1.3767)	grad_norm 3.6909 (4.6297)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:11:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:09:18 lr 0.000039	 wd 0.0000	time 0.2051 (0.2937)	loss 1.4092 (1.3799)	grad_norm 3.1060 (4.5670)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:11:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:08:28 lr 0.000039	 wd 0.0000	time 0.2130 (0.2824)	loss 1.3880 (1.3820)	grad_norm 3.3110 (4.5140)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:11:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:08:07 lr 0.000039	 wd 0.0000	time 0.2026 (0.2863)	loss 1.0458 (1.3839)	grad_norm 5.4778 (4.4569)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:12:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:07:26 lr 0.000039	 wd 0.0000	time 0.2279 (0.2784)	loss 1.1997 (1.3865)	grad_norm 3.4244 (4.4533)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:12:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:48 lr 0.000039	 wd 0.0000	time 0.1953 (0.2720)	loss 1.2705 (1.3834)	grad_norm 4.0230 (4.4754)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:13:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:06:14 lr 0.000039	 wd 0.0000	time 0.2544 (0.2670)	loss 1.3287 (1.3817)	grad_norm 6.3728 (4.4866)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:13:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:45 lr 0.000039	 wd 0.0000	time 0.2271 (0.2652)	loss 1.3491 (1.3787)	grad_norm 3.2807 (4.4633)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:13:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:05:15 lr 0.000039	 wd 0.0000	time 0.2083 (0.2622)	loss 1.4779 (1.3795)	grad_norm 2.7565 (4.4744)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:14:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:45 lr 0.000039	 wd 0.0000	time 0.2129 (0.2588)	loss 1.5849 (1.3801)	grad_norm 3.0899 (4.4582)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:14:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:16 lr 0.000039	 wd 0.0000	time 0.2073 (0.2558)	loss 1.4800 (1.3793)	grad_norm 4.4603 (4.4377)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:14:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:49 lr 0.000039	 wd 0.0000	time 0.2213 (0.2541)	loss 1.4885 (1.3804)	grad_norm 7.1913 (4.4382)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:15:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:23 lr 0.000039	 wd 0.0000	time 0.2236 (0.2539)	loss 1.5467 (1.3805)	grad_norm 5.9142 (4.4584)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:15:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:56 lr 0.000039	 wd 0.0000	time 0.2181 (0.2519)	loss 1.3540 (1.3801)	grad_norm 5.3109 (4.4506)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:16:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:30 lr 0.000039	 wd 0.0000	time 0.1902 (0.2501)	loss 1.3745 (1.3793)	grad_norm 6.2391 (4.4678)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:16:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:02:04 lr 0.000039	 wd 0.0000	time 0.2325 (0.2489)	loss 1.4708 (1.3802)	grad_norm 2.9237 (4.4489)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:16:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:40 lr 0.000039	 wd 0.0000	time 0.2418 (0.2493)	loss 1.6173 (1.3819)	grad_norm 4.5310 (4.4454)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:17:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:14 lr 0.000039	 wd 0.0000	time 0.2076 (0.2479)	loss 1.2734 (1.3803)	grad_norm 2.6482 (4.4527)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:17:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:49 lr 0.000039	 wd 0.0000	time 0.1926 (0.2464)	loss 1.5581 (1.3809)	grad_norm 4.4793 (4.4357)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:17:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:25 lr 0.000039	 wd 0.0000	time 0.1873 (0.2452)	loss 1.3692 (1.3805)	grad_norm 2.4963 (4.4523)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:18:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000039	 wd 0.0000	time 0.1704 (0.2432)	loss 1.3251 (1.3805)	grad_norm 3.6075 (4.4526)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:18:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 7 training takes 0:10:18
[2024-07-02 11:18:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 26.891 (26.891)	Loss 0.4155 (0.4155)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 8479MB
[2024-07-02 11:19:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.796 Acc@5 97.128
[2024-07-02 11:19:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-02 11:19:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.80%
[2024-07-02 11:19:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saving......
[2024-07-02 11:19:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saved !!!
[2024-07-02 11:19:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][0/2502]	eta 11:13:18 lr 0.000039	 wd 0.0000	time 16.1466 (16.1466)	loss 1.5432 (1.5432)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:19:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:17:18 lr 0.000039	 wd 0.0000	time 0.4890 (0.4325)	loss 1.5020 (1.4136)	grad_norm 3.4914 (4.4227)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:20:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:13:15 lr 0.000039	 wd 0.0000	time 0.2235 (0.3456)	loss 1.4457 (1.3852)	grad_norm 3.1947 (4.5400)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:20:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:11:02 lr 0.000038	 wd 0.0000	time 0.2180 (0.3009)	loss 1.4023 (1.3800)	grad_norm 5.5337 (4.4231)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:20:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:09:43 lr 0.000038	 wd 0.0000	time 0.2072 (0.2775)	loss 1.4871 (1.3775)	grad_norm 3.5247 (4.4440)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:21:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:09:07 lr 0.000038	 wd 0.0000	time 0.5148 (0.2735)	loss 1.5110 (1.3841)	grad_norm 10.7403 (4.6826)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:21:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:47 lr 0.000038	 wd 0.0000	time 0.1933 (0.2776)	loss 1.6016 (1.3880)	grad_norm 3.6273 (4.6290)	loss_scale 2048.0000 (1092.1531)	mem 8479MB
[2024-07-02 11:22:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:08:04 lr 0.000038	 wd 0.0000	time 0.2448 (0.2686)	loss 1.5582 (1.3879)	grad_norm 4.6241 (4.5338)	loss_scale 2048.0000 (1228.5078)	mem 8479MB
[2024-07-02 11:22:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:24 lr 0.000038	 wd 0.0000	time 0.2312 (0.2614)	loss 1.4703 (1.3870)	grad_norm 4.1788 (4.5408)	loss_scale 2048.0000 (1330.8165)	mem 8479MB
[2024-07-02 11:23:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:54 lr 0.000038	 wd 0.0000	time 0.1871 (0.2589)	loss 1.5805 (1.3879)	grad_norm 9.2211 (4.5529)	loss_scale 2048.0000 (1410.4151)	mem 8479MB
[2024-07-02 11:23:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:25 lr 0.000038	 wd 0.0000	time 0.2297 (0.2564)	loss 1.4695 (1.3856)	grad_norm 5.0609 (4.5381)	loss_scale 2048.0000 (1474.1099)	mem 8479MB
[2024-07-02 11:23:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:54 lr 0.000038	 wd 0.0000	time 0.2172 (0.2527)	loss 1.4956 (1.3822)	grad_norm 4.3264 (4.5189)	loss_scale 2048.0000 (1526.2343)	mem 8479MB
[2024-07-02 11:24:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:25 lr 0.000038	 wd 0.0000	time 0.2539 (0.2497)	loss 1.4501 (1.3812)	grad_norm 3.7240 (4.4628)	loss_scale 2048.0000 (1569.6786)	mem 8479MB
[2024-07-02 11:24:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:57 lr 0.000038	 wd 0.0000	time 0.2152 (0.2478)	loss 1.0848 (1.3791)	grad_norm 5.4363 (4.4842)	loss_scale 2048.0000 (1606.4443)	mem 8479MB
[2024-07-02 11:24:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:32 lr 0.000038	 wd 0.0000	time 0.2159 (0.2477)	loss 0.9743 (1.3801)	grad_norm 4.3580 (4.4380)	loss_scale 2048.0000 (1637.9615)	mem 8479MB
[2024-07-02 11:25:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:04:06 lr 0.000038	 wd 0.0000	time 0.2231 (0.2457)	loss 0.9627 (1.3765)	grad_norm 3.0300 (nan)	loss_scale 1024.0000 (1642.0839)	mem 8479MB
[2024-07-02 11:25:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:39 lr 0.000038	 wd 0.0000	time 0.2142 (0.2438)	loss 1.2908 (1.3737)	grad_norm 3.0036 (nan)	loss_scale 1024.0000 (1603.4778)	mem 8479MB
[2024-07-02 11:26:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:14 lr 0.000038	 wd 0.0000	time 0.2307 (0.2422)	loss 1.2484 (1.3751)	grad_norm 3.2604 (nan)	loss_scale 1024.0000 (1569.4109)	mem 8479MB
[2024-07-02 11:26:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:50 lr 0.000038	 wd 0.0000	time 0.1993 (0.2422)	loss 1.4711 (1.3770)	grad_norm 2.5033 (nan)	loss_scale 1024.0000 (1539.1272)	mem 8479MB
[2024-07-02 11:26:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:25 lr 0.000038	 wd 0.0000	time 0.1933 (0.2420)	loss 1.3100 (1.3775)	grad_norm 4.9858 (nan)	loss_scale 1024.0000 (1512.0295)	mem 8479MB
[2024-07-02 11:27:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:02:00 lr 0.000038	 wd 0.0000	time 0.1882 (0.2407)	loss 1.7443 (1.3795)	grad_norm 3.9736 (nan)	loss_scale 1024.0000 (1487.6402)	mem 8479MB
[2024-07-02 11:27:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:36 lr 0.000038	 wd 0.0000	time 0.2405 (0.2394)	loss 1.4074 (1.3794)	grad_norm 4.5774 (nan)	loss_scale 1024.0000 (1465.5726)	mem 8479MB
[2024-07-02 11:27:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:12 lr 0.000038	 wd 0.0000	time 0.2608 (0.2392)	loss 1.5202 (1.3783)	grad_norm 3.4035 (nan)	loss_scale 1024.0000 (1445.5102)	mem 8479MB
[2024-07-02 11:28:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:48 lr 0.000038	 wd 0.0000	time 0.2221 (0.2393)	loss 1.3847 (1.3788)	grad_norm 5.1714 (nan)	loss_scale 1024.0000 (1427.1917)	mem 8479MB
[2024-07-02 11:28:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:24 lr 0.000038	 wd 0.0000	time 0.2179 (0.2383)	loss 1.4401 (1.3806)	grad_norm 3.8072 (nan)	loss_scale 1024.0000 (1410.3990)	mem 8479MB
[2024-07-02 11:28:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000038	 wd 0.0000	time 0.1723 (0.2363)	loss 1.6177 (1.3818)	grad_norm 3.5647 (nan)	loss_scale 1024.0000 (1394.9492)	mem 8479MB
[2024-07-02 11:29:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 8 training takes 0:09:55
[2024-07-02 11:29:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 41.049 (41.049)	Loss 0.4111 (0.4111)	Acc@1 92.773 (92.773)	Acc@5 98.438 (98.438)	Mem 8479MB
[2024-07-02 11:29:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.778 Acc@5 97.096
[2024-07-02 11:29:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-02 11:29:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.80%
[2024-07-02 11:30:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][0/2502]	eta 11:58:50 lr 0.000038	 wd 0.0000	time 17.2383 (17.2383)	loss 1.3932 (1.3932)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:30:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:15:10 lr 0.000038	 wd 0.0000	time 0.2145 (0.3789)	loss 1.3030 (1.3537)	grad_norm 4.6483 (4.6257)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:30:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:11:32 lr 0.000037	 wd 0.0000	time 0.2516 (0.3008)	loss 1.5198 (1.3614)	grad_norm 3.0687 (4.5627)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:31:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:11:19 lr 0.000037	 wd 0.0000	time 0.2103 (0.3086)	loss 1.4333 (1.3725)	grad_norm 3.8641 (4.9011)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:31:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:56 lr 0.000037	 wd 0.0000	time 0.1886 (0.2837)	loss 1.5923 (1.3678)	grad_norm 4.6322 (4.7311)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:32:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:08:57 lr 0.000037	 wd 0.0000	time 0.1978 (0.2685)	loss 1.3759 (1.3725)	grad_norm 3.9687 (nan)	loss_scale 512.0000 (952.4631)	mem 8479MB
[2024-07-02 11:32:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:15 lr 0.000037	 wd 0.0000	time 0.2354 (0.2607)	loss 1.4375 (1.3662)	grad_norm 3.4869 (nan)	loss_scale 512.0000 (879.1747)	mem 8479MB
[2024-07-02 11:33:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:08:03 lr 0.000037	 wd 0.0000	time 0.1856 (0.2683)	loss 1.5699 (1.3663)	grad_norm 7.8587 (nan)	loss_scale 512.0000 (826.7960)	mem 8479MB
[2024-07-02 11:33:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:24 lr 0.000037	 wd 0.0000	time 0.1870 (0.2613)	loss 1.4427 (1.3713)	grad_norm 6.1204 (nan)	loss_scale 512.0000 (787.4956)	mem 8479MB
[2024-07-02 11:33:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:49 lr 0.000037	 wd 0.0000	time 0.2093 (0.2558)	loss 1.5518 (1.3684)	grad_norm 4.6085 (nan)	loss_scale 512.0000 (756.9190)	mem 8479MB
[2024-07-02 11:34:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:18 lr 0.000037	 wd 0.0000	time 0.2400 (0.2523)	loss 1.5641 (1.3708)	grad_norm 3.1337 (nan)	loss_scale 512.0000 (732.4515)	mem 8479MB
[2024-07-02 11:34:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:53 lr 0.000037	 wd 0.0000	time 0.2081 (0.2521)	loss 1.3457 (1.3744)	grad_norm 3.5937 (nan)	loss_scale 512.0000 (712.4287)	mem 8479MB
[2024-07-02 11:34:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:24 lr 0.000037	 wd 0.0000	time 0.1998 (0.2494)	loss 1.6539 (1.3770)	grad_norm 2.5422 (nan)	loss_scale 512.0000 (695.7402)	mem 8479MB
[2024-07-02 11:35:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:56 lr 0.000037	 wd 0.0000	time 0.2107 (0.2467)	loss 0.9950 (1.3745)	grad_norm 7.7654 (nan)	loss_scale 512.0000 (681.6172)	mem 8479MB
[2024-07-02 11:35:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:29 lr 0.000037	 wd 0.0000	time 0.2056 (0.2444)	loss 1.4178 (1.3768)	grad_norm 3.2077 (nan)	loss_scale 512.0000 (669.5103)	mem 8479MB
[2024-07-02 11:36:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:04:04 lr 0.000037	 wd 0.0000	time 0.1938 (0.2437)	loss 1.5628 (1.3792)	grad_norm 6.1579 (nan)	loss_scale 512.0000 (659.0167)	mem 8479MB
[2024-07-02 11:36:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:39 lr 0.000037	 wd 0.0000	time 0.2095 (0.2435)	loss 1.0303 (1.3788)	grad_norm 4.0949 (nan)	loss_scale 512.0000 (649.8339)	mem 8479MB
[2024-07-02 11:36:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:13 lr 0.000037	 wd 0.0000	time 0.2078 (0.2418)	loss 1.0613 (1.3802)	grad_norm 3.1861 (nan)	loss_scale 512.0000 (641.7307)	mem 8479MB
[2024-07-02 11:37:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:48 lr 0.000037	 wd 0.0000	time 0.2069 (0.2404)	loss 1.5277 (1.3808)	grad_norm 4.6518 (nan)	loss_scale 512.0000 (634.5275)	mem 8479MB
[2024-07-02 11:37:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:24 lr 0.000037	 wd 0.0000	time 0.2288 (0.2397)	loss 1.3845 (1.3800)	grad_norm 3.2435 (nan)	loss_scale 512.0000 (628.0821)	mem 8479MB
[2024-07-02 11:37:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:02:00 lr 0.000037	 wd 0.0000	time 0.2187 (0.2402)	loss 1.5386 (1.3792)	grad_norm 4.2351 (nan)	loss_scale 512.0000 (622.2809)	mem 8479MB
[2024-07-02 11:38:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:36 lr 0.000036	 wd 0.0000	time 0.2098 (0.2392)	loss 1.2177 (1.3799)	grad_norm 11.1616 (nan)	loss_scale 512.0000 (617.0319)	mem 8479MB
[2024-07-02 11:38:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:11 lr 0.000036	 wd 0.0000	time 0.2045 (0.2381)	loss 1.4716 (1.3814)	grad_norm 3.5511 (nan)	loss_scale 512.0000 (612.2599)	mem 8479MB
[2024-07-02 11:39:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:47 lr 0.000036	 wd 0.0000	time 0.2188 (0.2373)	loss 1.4496 (1.3819)	grad_norm 2.6845 (nan)	loss_scale 512.0000 (607.9027)	mem 8479MB
[2024-07-02 11:39:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:24 lr 0.000036	 wd 0.0000	time 0.2070 (0.2376)	loss 1.2822 (1.3818)	grad_norm 3.2247 (nan)	loss_scale 512.0000 (603.9084)	mem 8479MB
[2024-07-02 11:39:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000036	 wd 0.0000	time 0.1622 (0.2357)	loss 0.9183 (1.3826)	grad_norm 2.6810 (nan)	loss_scale 512.0000 (600.2335)	mem 8479MB
[2024-07-02 11:39:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 9 training takes 0:09:54
[2024-07-02 11:40:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 24.367 (24.367)	Loss 0.4072 (0.4072)	Acc@1 92.773 (92.773)	Acc@5 98.438 (98.438)	Mem 8479MB
[2024-07-02 11:40:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.794 Acc@5 97.154
[2024-07-02 11:40:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-02 11:40:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.80%
[2024-07-02 11:41:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][0/2502]	eta 1 day, 0:37:00 lr 0.000036	 wd 0.0000	time 35.4199 (35.4199)	loss 1.3110 (1.3110)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:41:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:22:27 lr 0.000036	 wd 0.0000	time 0.2214 (0.5610)	loss 1.2328 (1.3479)	grad_norm 4.8213 (3.9170)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:41:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:14:47 lr 0.000036	 wd 0.0000	time 0.1917 (0.3857)	loss 1.3952 (1.3745)	grad_norm 5.8688 (3.9386)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:42:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:11:59 lr 0.000036	 wd 0.0000	time 0.2034 (0.3269)	loss 0.9294 (1.3770)	grad_norm 5.0529 (4.0541)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:42:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:11:41 lr 0.000036	 wd 0.0000	time 0.2653 (0.3339)	loss 1.5948 (1.3821)	grad_norm 4.8224 (3.9784)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:43:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:10:25 lr 0.000036	 wd 0.0000	time 0.2241 (0.3124)	loss 1.5148 (1.3789)	grad_norm 2.4651 (4.0686)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:43:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:09:22 lr 0.000036	 wd 0.0000	time 0.1901 (0.2959)	loss 1.6232 (1.3778)	grad_norm 3.6107 (4.0599)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:43:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:08:31 lr 0.000036	 wd 0.0000	time 0.2494 (0.2841)	loss 1.4736 (1.3749)	grad_norm 5.0213 (4.1283)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:44:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:08:20 lr 0.000036	 wd 0.0000	time 0.2596 (0.2941)	loss 1.3159 (1.3759)	grad_norm 5.3753 (4.1679)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:44:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:07:37 lr 0.000036	 wd 0.0000	time 0.2297 (0.2856)	loss 1.5249 (1.3755)	grad_norm 5.0874 (4.1371)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:45:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:58 lr 0.000036	 wd 0.0000	time 0.2006 (0.2783)	loss 1.6174 (1.3734)	grad_norm 4.4804 (4.1822)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:45:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:06:22 lr 0.000036	 wd 0.0000	time 0.2064 (0.2727)	loss 1.3828 (1.3712)	grad_norm 3.4709 (4.2386)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:45:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:52 lr 0.000035	 wd 0.0000	time 0.2147 (0.2705)	loss 1.2820 (1.3717)	grad_norm 4.0056 (4.3608)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:46:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:05:20 lr 0.000035	 wd 0.0000	time 0.2125 (0.2667)	loss 1.5427 (1.3743)	grad_norm 4.0128 (4.3473)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:46:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:49 lr 0.000035	 wd 0.0000	time 0.1805 (0.2631)	loss 1.4895 (1.3764)	grad_norm 7.6806 (4.5071)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:46:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:04:20 lr 0.000035	 wd 0.0000	time 0.1917 (0.2598)	loss 1.3151 (1.3766)	grad_norm 3.1134 (4.5251)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:47:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:52 lr 0.000035	 wd 0.0000	time 0.2433 (0.2580)	loss 1.2393 (1.3777)	grad_norm 4.4637 (4.5275)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:47:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:26 lr 0.000035	 wd 0.0000	time 0.2276 (0.2571)	loss 1.4402 (1.3786)	grad_norm 2.8809 (4.5510)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:48:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:58 lr 0.000035	 wd 0.0000	time 0.1873 (0.2548)	loss 1.3617 (1.3786)	grad_norm 3.8085 (4.5349)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:48:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:32 lr 0.000035	 wd 0.0000	time 0.2170 (0.2527)	loss 1.4793 (1.3794)	grad_norm 5.7427 (4.5246)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 11:48:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:02:06 lr 0.000035	 wd 0.0000	time 0.2670 (0.2515)	loss 1.3362 (1.3795)	grad_norm 4.2084 (4.5562)	loss_scale 1024.0000 (530.4228)	mem 8479MB
[2024-07-02 11:49:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:41 lr 0.000035	 wd 0.0000	time 0.1880 (0.2513)	loss 1.4949 (1.3811)	grad_norm 3.8647 (4.5638)	loss_scale 1024.0000 (553.9153)	mem 8479MB
[2024-07-02 11:49:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:15 lr 0.000035	 wd 0.0000	time 0.2091 (0.2498)	loss 1.0048 (1.3816)	grad_norm 3.5985 (4.5940)	loss_scale 1024.0000 (575.2731)	mem 8479MB
[2024-07-02 11:49:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:50 lr 0.000035	 wd 0.0000	time 0.2131 (0.2484)	loss 1.4795 (1.3810)	grad_norm 3.9232 (4.5875)	loss_scale 1024.0000 (594.7744)	mem 8479MB
[2024-07-02 11:50:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:25 lr 0.000035	 wd 0.0000	time 0.2300 (0.2473)	loss 1.4686 (1.3811)	grad_norm 2.8303 (4.5725)	loss_scale 1024.0000 (612.6514)	mem 8479MB
[2024-07-02 11:50:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1607 (0.2452)	loss 1.5422 (1.3807)	grad_norm 4.3179 (4.5606)	loss_scale 1024.0000 (629.0988)	mem 8479MB
[2024-07-02 11:50:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 10 training takes 0:10:22
[2024-07-02 11:51:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 26.403 (26.403)	Loss 0.4099 (0.4099)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 8479MB
[2024-07-02 11:51:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.802 Acc@5 97.122
[2024-07-02 11:51:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-02 11:51:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.80%
[2024-07-02 11:51:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saving......
[2024-07-02 11:51:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saved !!!
[2024-07-02 11:51:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][0/2502]	eta 11:15:12 lr 0.000035	 wd 0.0000	time 16.1921 (16.1921)	loss 1.5888 (1.5888)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:52:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:17:04 lr 0.000035	 wd 0.0000	time 0.5598 (0.4267)	loss 1.3858 (1.3765)	grad_norm 3.2337 (4.3089)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:52:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:12:52 lr 0.000034	 wd 0.0000	time 0.2252 (0.3354)	loss 1.5703 (1.3807)	grad_norm 3.1849 (4.2783)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:52:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:10:46 lr 0.000034	 wd 0.0000	time 0.2009 (0.2938)	loss 1.2825 (1.3807)	grad_norm 2.3837 (4.2177)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:53:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:09:33 lr 0.000034	 wd 0.0000	time 0.2115 (0.2728)	loss 1.5144 (1.3859)	grad_norm 3.4573 (4.1801)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:53:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:08:49 lr 0.000034	 wd 0.0000	time 0.2033 (0.2645)	loss 1.3644 (1.3789)	grad_norm 5.1311 (4.2297)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:54:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:32 lr 0.000034	 wd 0.0000	time 0.2039 (0.2697)	loss 1.4346 (1.3767)	grad_norm 5.3902 (4.2381)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:54:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:07:50 lr 0.000034	 wd 0.0000	time 0.2084 (0.2612)	loss 1.4166 (1.3772)	grad_norm 7.2422 (4.3214)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:54:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:07:14 lr 0.000034	 wd 0.0000	time 0.2075 (0.2551)	loss 1.6923 (1.3802)	grad_norm 3.7818 (4.3159)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:55:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:06:44 lr 0.000034	 wd 0.0000	time 0.2600 (0.2523)	loss 1.5264 (1.3807)	grad_norm 3.2149 (4.3889)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:55:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:16 lr 0.000034	 wd 0.0000	time 0.2422 (0.2510)	loss 1.5015 (1.3805)	grad_norm 3.3720 (4.4491)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:56:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:47 lr 0.000034	 wd 0.0000	time 0.1814 (0.2477)	loss 1.4498 (1.3826)	grad_norm 3.5804 (4.4334)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:56:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:18 lr 0.000034	 wd 0.0000	time 0.2435 (0.2450)	loss 1.6277 (1.3832)	grad_norm 2.7615 (4.4759)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:56:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:04:51 lr 0.000034	 wd 0.0000	time 0.1927 (0.2427)	loss 1.0720 (1.3816)	grad_norm 2.6648 (4.4632)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:57:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:27 lr 0.000034	 wd 0.0000	time 0.3986 (0.2427)	loss 0.9872 (1.3815)	grad_norm 3.1296 (4.4804)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:57:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:04:01 lr 0.000034	 wd 0.0000	time 0.2084 (0.2413)	loss 1.4710 (1.3808)	grad_norm 12.1578 (4.4872)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:57:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:36 lr 0.000034	 wd 0.0000	time 0.1982 (0.2396)	loss 1.2918 (1.3820)	grad_norm 3.9448 (4.5298)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:58:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:10 lr 0.000033	 wd 0.0000	time 0.2286 (0.2380)	loss 1.3888 (1.3806)	grad_norm 4.8667 (4.5220)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:58:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:46 lr 0.000033	 wd 0.0000	time 0.2245 (0.2375)	loss 1.3376 (1.3822)	grad_norm 3.4190 (4.5123)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:59:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:23 lr 0.000033	 wd 0.0000	time 0.2022 (0.2381)	loss 1.5647 (1.3822)	grad_norm 3.7237 (4.5092)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:59:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:01:58 lr 0.000033	 wd 0.0000	time 0.2015 (0.2369)	loss 1.2187 (1.3818)	grad_norm 3.4959 (4.4984)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 11:59:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:34 lr 0.000033	 wd 0.0000	time 0.2197 (0.2358)	loss 1.4175 (1.3811)	grad_norm 6.0192 (4.4993)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:00:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:11 lr 0.000033	 wd 0.0000	time 0.2235 (0.2354)	loss 1.4180 (1.3825)	grad_norm 3.6977 (4.5009)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:00:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:47 lr 0.000033	 wd 0.0000	time 0.2055 (0.2356)	loss 1.5552 (1.3820)	grad_norm 3.9048 (inf)	loss_scale 512.0000 (1019.1047)	mem 8479MB
[2024-07-02 12:00:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:23 lr 0.000033	 wd 0.0000	time 0.2040 (0.2349)	loss 1.3823 (1.3812)	grad_norm 3.7426 (inf)	loss_scale 512.0000 (997.9842)	mem 8479MB
[2024-07-02 12:01:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000033	 wd 0.0000	time 0.1614 (0.2330)	loss 1.4235 (1.3812)	grad_norm 3.8150 (inf)	loss_scale 512.0000 (978.5526)	mem 8479MB
[2024-07-02 12:01:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 11 training takes 0:09:47
[2024-07-02 12:01:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 35.070 (35.070)	Loss 0.4141 (0.4141)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 8479MB
[2024-07-02 12:02:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.844 Acc@5 97.152
[2024-07-02 12:02:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-02 12:02:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.84%
[2024-07-02 12:02:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saving......
[2024-07-02 12:02:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saved !!!
[2024-07-02 12:02:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][0/2502]	eta 11:39:16 lr 0.000033	 wd 0.0000	time 16.7690 (16.7690)	loss 1.6453 (1.6453)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:02:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:14:58 lr 0.000033	 wd 0.0000	time 0.2132 (0.3739)	loss 1.5551 (1.3803)	grad_norm 3.4128 (4.0017)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:03:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:11:16 lr 0.000033	 wd 0.0000	time 0.2591 (0.2938)	loss 0.9083 (1.3847)	grad_norm 3.4567 (4.2386)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:03:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:11:28 lr 0.000033	 wd 0.0000	time 0.2589 (0.3125)	loss 1.3517 (1.3861)	grad_norm 3.6640 (4.5123)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:04:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:10:03 lr 0.000033	 wd 0.0000	time 0.1947 (0.2873)	loss 1.3396 (1.3797)	grad_norm 2.2984 (4.3446)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:04:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:09:04 lr 0.000032	 wd 0.0000	time 0.2143 (0.2720)	loss 1.1078 (1.3806)	grad_norm 2.4941 (4.4105)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:04:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:08:19 lr 0.000032	 wd 0.0000	time 0.2290 (0.2624)	loss 1.4019 (1.3778)	grad_norm 3.5680 (4.3705)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:05:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:08:04 lr 0.000032	 wd 0.0000	time 0.1968 (0.2691)	loss 1.4523 (1.3771)	grad_norm 3.5232 (4.3735)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:05:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:07:26 lr 0.000032	 wd 0.0000	time 0.2115 (0.2621)	loss 1.6938 (1.3863)	grad_norm 7.0903 (4.3621)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:06:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:50 lr 0.000032	 wd 0.0000	time 0.2262 (0.2565)	loss 1.0923 (1.3879)	grad_norm 3.9756 (4.3811)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:06:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:18 lr 0.000032	 wd 0.0000	time 0.1952 (0.2522)	loss 1.4648 (1.3862)	grad_norm 6.0551 (4.3968)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:06:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:58 lr 0.000032	 wd 0.0000	time 0.2011 (0.2560)	loss 1.5535 (1.3913)	grad_norm 3.9799 (4.3915)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:07:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:28 lr 0.000032	 wd 0.0000	time 0.2041 (0.2524)	loss 1.6328 (1.3895)	grad_norm 3.6025 (4.3949)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:07:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:05:00 lr 0.000032	 wd 0.0000	time 0.2243 (0.2496)	loss 1.5955 (1.3895)	grad_norm 4.4434 (4.4366)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:07:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:32 lr 0.000032	 wd 0.0000	time 0.2131 (0.2469)	loss 1.6292 (1.3895)	grad_norm 4.0380 (4.4821)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:08:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:04:06 lr 0.000032	 wd 0.0000	time 0.2164 (0.2461)	loss 1.5081 (1.3904)	grad_norm 4.5313 (4.4910)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:08:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:41 lr 0.000032	 wd 0.0000	time 0.2123 (0.2458)	loss 1.5244 (1.3888)	grad_norm 3.5928 (4.4952)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:09:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:15 lr 0.000031	 wd 0.0000	time 0.2070 (0.2440)	loss 1.4202 (1.3900)	grad_norm 6.3576 (4.4917)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:09:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:50 lr 0.000031	 wd 0.0000	time 0.1901 (0.2423)	loss 1.3758 (1.3909)	grad_norm 3.3389 (4.4835)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:09:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:25 lr 0.000031	 wd 0.0000	time 0.2178 (0.2414)	loss 1.3219 (1.3906)	grad_norm 5.7624 (4.4807)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:10:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:02:01 lr 0.000031	 wd 0.0000	time 0.2018 (0.2420)	loss 1.4230 (1.3900)	grad_norm 3.6004 (4.4836)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:10:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:36 lr 0.000031	 wd 0.0000	time 0.1955 (0.2409)	loss 1.5550 (1.3905)	grad_norm 4.4438 (4.4872)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:11:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:12 lr 0.000031	 wd 0.0000	time 0.2072 (0.2397)	loss 1.5297 (1.3913)	grad_norm 2.8975 (4.4906)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:11:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:48 lr 0.000031	 wd 0.0000	time 0.2273 (0.2389)	loss 1.3971 (1.3910)	grad_norm 3.9095 (4.4731)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:11:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:24 lr 0.000031	 wd 0.0000	time 0.2064 (0.2390)	loss 1.5626 (1.3907)	grad_norm 4.3913 (4.4760)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:12:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000031	 wd 0.0000	time 0.1787 (0.2371)	loss 1.1348 (1.3891)	grad_norm 3.1473 (4.4615)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:12:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 12 training takes 0:09:58
[2024-07-02 12:12:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 22.159 (22.159)	Loss 0.4153 (0.4153)	Acc@1 92.188 (92.188)	Acc@5 98.242 (98.242)	Mem 8479MB
[2024-07-02 12:12:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.832 Acc@5 97.130
[2024-07-02 12:12:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-02 12:12:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.84%
[2024-07-02 12:13:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][0/2502]	eta 19:00:42 lr 0.000031	 wd 0.0000	time 27.3552 (27.3552)	loss 1.3961 (1.3961)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:13:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:20:43 lr 0.000031	 wd 0.0000	time 0.1896 (0.5177)	loss 1.5042 (1.3847)	grad_norm 3.8921 (4.0666)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:13:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:14:01 lr 0.000031	 wd 0.0000	time 0.2157 (0.3654)	loss 1.6666 (1.3852)	grad_norm 3.9672 (4.0652)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:14:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:11:30 lr 0.000031	 wd 0.0000	time 0.2077 (0.3138)	loss 1.5253 (1.3911)	grad_norm 5.1082 (4.0223)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:14:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:10:16 lr 0.000030	 wd 0.0000	time 0.1953 (0.2932)	loss 1.4676 (1.3878)	grad_norm 6.4777 (4.0434)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:15:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:09:46 lr 0.000030	 wd 0.0000	time 0.2016 (0.2929)	loss 1.5208 (1.3824)	grad_norm 12.8108 (4.1448)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:15:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:50 lr 0.000030	 wd 0.0000	time 0.2159 (0.2788)	loss 1.5199 (1.3868)	grad_norm 3.8818 (4.1851)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:15:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:08:05 lr 0.000030	 wd 0.0000	time 0.2133 (0.2696)	loss 1.7343 (1.3825)	grad_norm 3.7758 (4.1768)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:16:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:29 lr 0.000030	 wd 0.0000	time 0.2322 (0.2641)	loss 1.5381 (1.3857)	grad_norm 5.8737 (4.2393)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:16:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:07:09 lr 0.000030	 wd 0.0000	time 0.1905 (0.2682)	loss 1.6675 (1.3812)	grad_norm 4.2281 (4.2731)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:17:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:34 lr 0.000030	 wd 0.0000	time 0.1928 (0.2625)	loss 1.5419 (1.3841)	grad_norm 3.4061 (4.2511)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:17:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:06:01 lr 0.000030	 wd 0.0000	time 0.1892 (0.2578)	loss 1.4892 (1.3861)	grad_norm 3.9149 (4.2446)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:17:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:31 lr 0.000030	 wd 0.0000	time 0.2512 (0.2550)	loss 1.6836 (1.3835)	grad_norm 4.5042 (4.2900)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:18:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:05:05 lr 0.000030	 wd 0.0000	time 0.1961 (0.2540)	loss 1.5707 (1.3826)	grad_norm 3.3910 (4.2768)	loss_scale 1024.0000 (522.2321)	mem 8479MB
[2024-07-02 12:18:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:37 lr 0.000030	 wd 0.0000	time 0.2130 (0.2514)	loss 1.6674 (1.3833)	grad_norm 3.6053 (4.2756)	loss_scale 1024.0000 (558.0471)	mem 8479MB
[2024-07-02 12:18:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:04:09 lr 0.000030	 wd 0.0000	time 0.1982 (0.2489)	loss 1.5977 (1.3827)	grad_norm 3.7289 (4.2808)	loss_scale 1024.0000 (589.0899)	mem 8479MB
[2024-07-02 12:19:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:42 lr 0.000029	 wd 0.0000	time 0.2290 (0.2467)	loss 1.5147 (1.3825)	grad_norm 3.7084 (4.2570)	loss_scale 1024.0000 (616.2548)	mem 8479MB
[2024-07-02 12:19:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:17 lr 0.000029	 wd 0.0000	time 0.2362 (0.2457)	loss 0.8916 (1.3800)	grad_norm 5.2314 (4.2547)	loss_scale 1024.0000 (640.2257)	mem 8479MB
[2024-07-02 12:20:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:52 lr 0.000029	 wd 0.0000	time 0.2451 (0.2458)	loss 1.4516 (1.3815)	grad_norm 5.2512 (4.2589)	loss_scale 1024.0000 (661.5347)	mem 8479MB
[2024-07-02 12:20:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:26 lr 0.000029	 wd 0.0000	time 0.1881 (0.2442)	loss 1.1825 (1.3817)	grad_norm 5.5248 (4.2543)	loss_scale 1024.0000 (680.6018)	mem 8479MB
[2024-07-02 12:20:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:02:01 lr 0.000029	 wd 0.0000	time 0.2084 (0.2427)	loss 1.4126 (1.3821)	grad_norm 4.0702 (4.2611)	loss_scale 1024.0000 (697.7631)	mem 8479MB
[2024-07-02 12:21:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:37 lr 0.000029	 wd 0.0000	time 0.2591 (0.2421)	loss 1.1685 (1.3816)	grad_norm 12.4192 (4.2526)	loss_scale 1024.0000 (713.2908)	mem 8479MB
[2024-07-02 12:21:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:13 lr 0.000029	 wd 0.0000	time 0.2187 (0.2420)	loss 1.5635 (1.3835)	grad_norm 3.3573 (4.2458)	loss_scale 1024.0000 (727.4075)	mem 8479MB
[2024-07-02 12:21:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:48 lr 0.000029	 wd 0.0000	time 0.2013 (0.2409)	loss 1.3955 (1.3826)	grad_norm 3.8841 (4.2490)	loss_scale 1024.0000 (740.2973)	mem 8479MB
[2024-07-02 12:22:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:24 lr 0.000029	 wd 0.0000	time 0.2176 (0.2398)	loss 1.5098 (1.3833)	grad_norm 3.7835 (4.2770)	loss_scale 1024.0000 (752.1133)	mem 8479MB
[2024-07-02 12:22:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000029	 wd 0.0000	time 0.1733 (0.2377)	loss 1.4901 (1.3828)	grad_norm 3.4270 (4.2961)	loss_scale 1024.0000 (762.9844)	mem 8479MB
[2024-07-02 12:22:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 13 training takes 0:09:59
[2024-07-02 12:23:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 39.285 (39.285)	Loss 0.4138 (0.4138)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 8479MB
[2024-07-02 12:23:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.780 Acc@5 97.152
[2024-07-02 12:23:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-02 12:23:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.84%
[2024-07-02 12:23:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][0/2502]	eta 10:14:38 lr 0.000029	 wd 0.0000	time 14.7397 (14.7397)	loss 1.5507 (1.5507)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:24:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:15:02 lr 0.000029	 wd 0.0000	time 0.2334 (0.3758)	loss 1.5519 (1.3824)	grad_norm 3.0642 (4.2973)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:24:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:13:06 lr 0.000028	 wd 0.0000	time 0.2016 (0.3415)	loss 1.2588 (1.4054)	grad_norm 3.4963 (4.6315)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:25:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:10:54 lr 0.000028	 wd 0.0000	time 0.1999 (0.2974)	loss 1.1892 (1.3948)	grad_norm 4.6119 (4.6060)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:25:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:09:38 lr 0.000028	 wd 0.0000	time 0.1953 (0.2753)	loss 1.2607 (1.3818)	grad_norm 3.4096 (4.7084)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:25:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:08:44 lr 0.000028	 wd 0.0000	time 0.1949 (0.2622)	loss 1.4294 (1.3831)	grad_norm 4.3478 (4.7206)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:26:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:08:34 lr 0.000028	 wd 0.0000	time 0.2364 (0.2706)	loss 1.6239 (1.3871)	grad_norm 4.9246 (4.7464)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:26:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:52 lr 0.000028	 wd 0.0000	time 0.2212 (0.2622)	loss 1.3630 (1.3835)	grad_norm 4.0164 (4.7389)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:27:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:15 lr 0.000028	 wd 0.0000	time 0.1919 (0.2559)	loss 1.3451 (1.3800)	grad_norm 3.0461 (4.6511)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:27:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:42 lr 0.000028	 wd 0.0000	time 0.2080 (0.2511)	loss 1.6064 (1.3782)	grad_norm 4.3646 (4.5859)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:27:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:06:29 lr 0.000028	 wd 0.0000	time 0.2693 (0.2594)	loss 1.1582 (1.3764)	grad_norm 4.5710 (4.5996)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:28:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:59 lr 0.000028	 wd 0.0000	time 0.2009 (0.2568)	loss 1.4218 (1.3739)	grad_norm 3.2252 (4.5709)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:28:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:29 lr 0.000028	 wd 0.0000	time 0.2288 (0.2530)	loss 1.5032 (1.3741)	grad_norm 2.9502 (4.5387)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:29:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:05:00 lr 0.000027	 wd 0.0000	time 0.2293 (0.2497)	loss 1.2462 (1.3755)	grad_norm 4.9424 (4.5415)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:29:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:33 lr 0.000027	 wd 0.0000	time 0.2462 (0.2485)	loss 1.5154 (1.3746)	grad_norm 5.4209 (4.5357)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:29:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:04:08 lr 0.000027	 wd 0.0000	time 0.2203 (0.2479)	loss 1.3663 (1.3753)	grad_norm 3.1173 (4.5143)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:30:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:41 lr 0.000027	 wd 0.0000	time 0.2103 (0.2459)	loss 1.3779 (1.3761)	grad_norm 9.6111 (4.5036)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:30:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:15 lr 0.000027	 wd 0.0000	time 0.2089 (0.2440)	loss 1.2517 (1.3763)	grad_norm 4.3678 (4.4937)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:30:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:50 lr 0.000027	 wd 0.0000	time 0.2222 (0.2429)	loss 1.3151 (1.3756)	grad_norm 9.5017 (4.4979)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:31:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:26 lr 0.000027	 wd 0.0000	time 0.1899 (0.2434)	loss 1.4311 (1.3756)	grad_norm 3.6241 (4.4923)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:31:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:02:01 lr 0.000027	 wd 0.0000	time 0.2017 (0.2421)	loss 1.0793 (1.3771)	grad_norm 4.3033 (4.4940)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:32:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:36 lr 0.000027	 wd 0.0000	time 0.2147 (0.2408)	loss 1.6923 (1.3762)	grad_norm 5.3469 (4.4890)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:32:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:12 lr 0.000027	 wd 0.0000	time 0.2160 (0.2401)	loss 1.2719 (1.3765)	grad_norm 2.8537 (4.5361)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:32:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:48 lr 0.000027	 wd 0.0000	time 0.2806 (0.2402)	loss 1.3793 (1.3773)	grad_norm 5.8949 (4.5256)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:33:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:24 lr 0.000026	 wd 0.0000	time 0.1887 (0.2394)	loss 1.2901 (1.3783)	grad_norm 4.8719 (4.5100)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:33:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1631 (0.2373)	loss 1.3811 (1.3775)	grad_norm 4.9141 (4.4933)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:33:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 14 training takes 0:09:57
[2024-07-02 12:34:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 26.356 (26.356)	Loss 0.4146 (0.4146)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 8479MB
[2024-07-02 12:34:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.850 Acc@5 97.162
[2024-07-02 12:34:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-02 12:34:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.85%
[2024-07-02 12:34:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saving......
[2024-07-02 12:34:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saved !!!
[2024-07-02 12:34:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][0/2502]	eta 11:40:48 lr 0.000026	 wd 0.0000	time 16.8059 (16.8059)	loss 1.4169 (1.4169)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:34:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:15:32 lr 0.000026	 wd 0.0000	time 0.2323 (0.3883)	loss 1.0845 (1.3676)	grad_norm 2.9640 (4.2522)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:35:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:11:29 lr 0.000026	 wd 0.0000	time 0.2001 (0.2996)	loss 1.5388 (1.3789)	grad_norm 3.1536 (4.2541)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 12:35:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:10:09 lr 0.000026	 wd 0.0000	time 0.2339 (0.2766)	loss 1.3845 (1.3661)	grad_norm 2.7519 (4.3635)	loss_scale 2048.0000 (1126.0598)	mem 8479MB
[2024-07-02 12:36:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:09:44 lr 0.000026	 wd 0.0000	time 1.2020 (0.2782)	loss 1.3847 (1.3697)	grad_norm 5.0271 (4.3125)	loss_scale 2048.0000 (1355.9701)	mem 8479MB
[2024-07-02 12:36:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:08:50 lr 0.000026	 wd 0.0000	time 0.2082 (0.2652)	loss 0.9214 (1.3647)	grad_norm 4.1395 (inf)	loss_scale 1024.0000 (1412.3433)	mem 8479MB
[2024-07-02 12:36:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:08:08 lr 0.000026	 wd 0.0000	time 0.2048 (0.2566)	loss 0.9087 (1.3677)	grad_norm 3.0415 (inf)	loss_scale 1024.0000 (1347.7271)	mem 8479MB
[2024-07-02 12:37:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:34 lr 0.000026	 wd 0.0000	time 0.2984 (0.2525)	loss 1.1606 (1.3715)	grad_norm 3.7293 (inf)	loss_scale 1024.0000 (1301.5464)	mem 8479MB
[2024-07-02 12:37:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:07:28 lr 0.000026	 wd 0.0000	time 0.1977 (0.2636)	loss 1.5650 (1.3727)	grad_norm 3.8900 (inf)	loss_scale 1024.0000 (1266.8964)	mem 8479MB
[2024-07-02 12:38:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:52 lr 0.000025	 wd 0.0000	time 0.2272 (0.2578)	loss 1.1960 (1.3721)	grad_norm 3.6598 (inf)	loss_scale 1024.0000 (1239.9378)	mem 8479MB
[2024-07-02 12:38:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:06:20 lr 0.000025	 wd 0.0000	time 0.1766 (0.2530)	loss 1.3811 (1.3723)	grad_norm 3.5350 (inf)	loss_scale 1024.0000 (1218.3656)	mem 8479MB
[2024-07-02 12:38:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:51 lr 0.000025	 wd 0.0000	time 0.2112 (0.2506)	loss 1.3603 (1.3692)	grad_norm 2.6095 (inf)	loss_scale 1024.0000 (1200.7121)	mem 8479MB
[2024-07-02 12:39:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:25 lr 0.000025	 wd 0.0000	time 0.2600 (0.2502)	loss 1.6140 (1.3694)	grad_norm 3.5878 (inf)	loss_scale 1024.0000 (1185.9983)	mem 8479MB
[2024-07-02 12:39:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:04:57 lr 0.000025	 wd 0.0000	time 0.1987 (0.2478)	loss 1.3750 (1.3682)	grad_norm 2.7514 (inf)	loss_scale 1024.0000 (1173.5465)	mem 8479MB
[2024-07-02 12:40:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:30 lr 0.000025	 wd 0.0000	time 0.1842 (0.2453)	loss 1.3497 (1.3691)	grad_norm 8.3507 (inf)	loss_scale 1024.0000 (1162.8722)	mem 8479MB
[2024-07-02 12:40:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:04:04 lr 0.000025	 wd 0.0000	time 0.2022 (0.2435)	loss 1.6624 (1.3686)	grad_norm 3.3227 (inf)	loss_scale 1024.0000 (1153.6203)	mem 8479MB
[2024-07-02 12:40:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:39 lr 0.000025	 wd 0.0000	time 0.1933 (0.2436)	loss 1.2426 (1.3709)	grad_norm 7.9616 (inf)	loss_scale 1024.0000 (1145.5240)	mem 8479MB
[2024-07-02 12:41:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:14 lr 0.000025	 wd 0.0000	time 0.1955 (0.2424)	loss 1.5719 (1.3713)	grad_norm 4.1680 (inf)	loss_scale 1024.0000 (1138.3798)	mem 8479MB
[2024-07-02 12:41:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:49 lr 0.000025	 wd 0.0000	time 0.2188 (0.2410)	loss 1.0725 (1.3710)	grad_norm 2.8390 (inf)	loss_scale 512.0000 (1115.5403)	mem 8479MB
[2024-07-02 12:41:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:24 lr 0.000024	 wd 0.0000	time 0.2188 (0.2396)	loss 1.6795 (1.3723)	grad_norm 2.6042 (inf)	loss_scale 512.0000 (1083.7917)	mem 8479MB
[2024-07-02 12:42:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:02:00 lr 0.000024	 wd 0.0000	time 0.2159 (0.2392)	loss 1.7855 (1.3751)	grad_norm 3.9439 (inf)	loss_scale 512.0000 (1055.2164)	mem 8479MB
[2024-07-02 12:42:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:36 lr 0.000024	 wd 0.0000	time 0.2088 (0.2399)	loss 1.6339 (1.3758)	grad_norm 5.2142 (inf)	loss_scale 512.0000 (1029.3613)	mem 8479MB
[2024-07-02 12:43:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:12 lr 0.000024	 wd 0.0000	time 0.2201 (0.2388)	loss 0.9554 (1.3769)	grad_norm 5.0134 (inf)	loss_scale 512.0000 (1005.8555)	mem 8479MB
[2024-07-02 12:43:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:48 lr 0.000024	 wd 0.0000	time 0.2073 (0.2377)	loss 1.5594 (1.3771)	grad_norm 11.8479 (inf)	loss_scale 512.0000 (984.3929)	mem 8479MB
[2024-07-02 12:43:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:24 lr 0.000024	 wd 0.0000	time 0.2520 (0.2373)	loss 1.2158 (1.3762)	grad_norm 4.4615 (inf)	loss_scale 512.0000 (964.7180)	mem 8479MB
[2024-07-02 12:44:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000024	 wd 0.0000	time 0.1625 (0.2359)	loss 1.4323 (1.3765)	grad_norm 2.8764 (inf)	loss_scale 512.0000 (946.6166)	mem 8479MB
[2024-07-02 12:44:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 15 training takes 0:09:56
[2024-07-02 12:44:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_15.pth saving......
[2024-07-02 12:44:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_15.pth saved !!!
[2024-07-02 12:44:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 19.066 (19.066)	Loss 0.4150 (0.4150)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 8479MB
[2024-07-02 12:44:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.890 Acc@5 97.152
[2024-07-02 12:44:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-02 12:44:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.89%
[2024-07-02 12:44:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saving......
[2024-07-02 12:44:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saved !!!
[2024-07-02 12:45:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][0/2502]	eta 15:28:50 lr 0.000024	 wd 0.0000	time 22.2743 (22.2743)	loss 1.2227 (1.2227)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:45:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:18:13 lr 0.000024	 wd 0.0000	time 0.2140 (0.4554)	loss 1.5423 (1.3853)	grad_norm 5.0179 (4.3435)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:45:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:13:08 lr 0.000024	 wd 0.0000	time 0.2132 (0.3426)	loss 1.3572 (1.3911)	grad_norm 3.2912 (4.3836)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:46:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:10:56 lr 0.000024	 wd 0.0000	time 0.2235 (0.2981)	loss 1.3827 (1.3990)	grad_norm 3.7610 (4.2537)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:46:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:09:40 lr 0.000024	 wd 0.0000	time 0.1837 (0.2760)	loss 1.2394 (1.3936)	grad_norm 4.1500 (4.3488)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:47:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:08:53 lr 0.000023	 wd 0.0000	time 0.2768 (0.2666)	loss 1.4491 (1.4013)	grad_norm 7.0757 (4.3353)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:47:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:38 lr 0.000023	 wd 0.0000	time 0.2175 (0.2724)	loss 1.0948 (1.3924)	grad_norm 7.8820 (4.2728)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:47:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:54 lr 0.000023	 wd 0.0000	time 0.2340 (0.2635)	loss 1.3318 (1.3933)	grad_norm 4.1234 (4.2738)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:48:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:07:17 lr 0.000023	 wd 0.0000	time 0.2116 (0.2570)	loss 1.3756 (1.3870)	grad_norm 2.5558 (4.2731)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:48:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:46 lr 0.000023	 wd 0.0000	time 0.2302 (0.2539)	loss 1.3281 (1.3858)	grad_norm 3.3971 (4.2881)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:49:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:06:29 lr 0.000023	 wd 0.0000	time 0.2279 (0.2594)	loss 1.4747 (1.3859)	grad_norm 3.9648 (4.2959)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:49:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:57 lr 0.000023	 wd 0.0000	time 0.2310 (0.2551)	loss 1.3399 (1.3882)	grad_norm 3.8953 (4.2816)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:49:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:27 lr 0.000023	 wd 0.0000	time 0.2159 (0.2517)	loss 1.5459 (1.3876)	grad_norm 3.3469 (4.2673)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:50:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:05:00 lr 0.000023	 wd 0.0000	time 0.2502 (0.2496)	loss 1.0753 (1.3878)	grad_norm 3.8838 (4.2781)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:50:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:34 lr 0.000023	 wd 0.0000	time 0.2141 (0.2489)	loss 1.3242 (1.3853)	grad_norm 2.7862 (4.3016)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:51:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:04:07 lr 0.000022	 wd 0.0000	time 0.1970 (0.2470)	loss 1.4245 (1.3826)	grad_norm 2.2910 (4.2863)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:51:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:40 lr 0.000022	 wd 0.0000	time 0.1885 (0.2449)	loss 1.4709 (1.3820)	grad_norm 7.4821 (4.2712)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:51:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:15 lr 0.000022	 wd 0.0000	time 0.2639 (0.2432)	loss 1.1046 (1.3802)	grad_norm 5.3832 (4.2897)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:52:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:51 lr 0.000022	 wd 0.0000	time 0.2052 (0.2438)	loss 1.1507 (1.3792)	grad_norm 3.6170 (4.3277)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:52:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:26 lr 0.000022	 wd 0.0000	time 0.2407 (0.2431)	loss 1.2951 (1.3786)	grad_norm 3.1927 (4.3351)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:52:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:02:01 lr 0.000022	 wd 0.0000	time 0.2370 (0.2419)	loss 1.5885 (1.3785)	grad_norm 3.4600 (4.3348)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:53:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:36 lr 0.000022	 wd 0.0000	time 0.2363 (0.2405)	loss 1.4792 (1.3781)	grad_norm 3.2632 (4.3264)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:53:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:12 lr 0.000022	 wd 0.0000	time 0.2000 (0.2402)	loss 1.3677 (1.3788)	grad_norm 3.5957 (4.3111)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:54:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:48 lr 0.000022	 wd 0.0000	time 0.2261 (0.2404)	loss 1.2847 (1.3791)	grad_norm 4.1032 (4.3106)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:54:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:24 lr 0.000022	 wd 0.0000	time 0.2035 (0.2395)	loss 1.3946 (1.3790)	grad_norm 6.8618 (4.3110)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:54:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1608 (0.2374)	loss 1.4233 (1.3786)	grad_norm 5.0785 (4.3168)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:54:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 16 training takes 0:09:58
[2024-07-02 12:55:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 43.535 (43.535)	Loss 0.4167 (0.4167)	Acc@1 93.164 (93.164)	Acc@5 98.438 (98.438)	Mem 8479MB
[2024-07-02 12:55:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.832 Acc@5 97.156
[2024-07-02 12:55:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-02 12:55:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.89%
[2024-07-02 12:56:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][0/2502]	eta 11:46:33 lr 0.000021	 wd 0.0000	time 16.9439 (16.9439)	loss 1.4905 (1.4905)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:56:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:15:05 lr 0.000021	 wd 0.0000	time 0.2020 (0.3771)	loss 1.5851 (1.3578)	grad_norm 4.1534 (4.4302)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:56:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:12:07 lr 0.000021	 wd 0.0000	time 0.4580 (0.3158)	loss 1.5599 (1.3724)	grad_norm 3.4063 (4.6620)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:57:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:11:32 lr 0.000021	 wd 0.0000	time 0.1979 (0.3145)	loss 1.4062 (1.3690)	grad_norm 5.8338 (4.4753)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:57:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:10:07 lr 0.000021	 wd 0.0000	time 0.2020 (0.2891)	loss 1.1503 (1.3678)	grad_norm 14.4623 (4.3979)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:58:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:09:06 lr 0.000021	 wd 0.0000	time 0.1999 (0.2728)	loss 1.3959 (1.3652)	grad_norm 4.1283 (4.4047)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:58:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:29 lr 0.000021	 wd 0.0000	time 0.4118 (0.2678)	loss 1.1750 (1.3708)	grad_norm 3.7268 (4.3670)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:58:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:08:12 lr 0.000021	 wd 0.0000	time 0.2049 (0.2733)	loss 1.3542 (1.3752)	grad_norm 3.8030 (4.3337)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 12:59:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:07:31 lr 0.000021	 wd 0.0000	time 0.1886 (0.2655)	loss 1.3665 (1.3785)	grad_norm 4.7686 (4.4427)	loss_scale 1024.0000 (551.6305)	mem 8479MB
[2024-07-02 12:59:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:55 lr 0.000021	 wd 0.0000	time 0.2068 (0.2592)	loss 1.4840 (1.3812)	grad_norm 3.6694 (4.5009)	loss_scale 1024.0000 (604.0577)	mem 8479MB
[2024-07-02 13:00:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:25 lr 0.000020	 wd 0.0000	time 0.2188 (0.2569)	loss 1.5527 (1.3789)	grad_norm 11.2673 (4.5437)	loss_scale 1024.0000 (646.0100)	mem 8479MB
[2024-07-02 13:00:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:06:02 lr 0.000020	 wd 0.0000	time 0.2040 (0.2584)	loss 1.1920 (1.3772)	grad_norm 2.0945 (4.5087)	loss_scale 1024.0000 (680.3415)	mem 8479MB
[2024-07-02 13:00:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:31 lr 0.000020	 wd 0.0000	time 0.2289 (0.2544)	loss 1.4615 (1.3796)	grad_norm 4.2818 (4.4855)	loss_scale 1024.0000 (708.9559)	mem 8479MB
[2024-07-02 13:01:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:05:02 lr 0.000020	 wd 0.0000	time 0.1980 (0.2514)	loss 1.2803 (1.3795)	grad_norm 3.0917 (4.4518)	loss_scale 1024.0000 (733.1714)	mem 8479MB
[2024-07-02 13:01:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:34 lr 0.000020	 wd 0.0000	time 0.2450 (0.2495)	loss 1.5546 (1.3799)	grad_norm 3.9844 (4.4509)	loss_scale 1024.0000 (753.9300)	mem 8479MB
[2024-07-02 13:01:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:04:09 lr 0.000020	 wd 0.0000	time 0.1865 (0.2495)	loss 1.5206 (1.3807)	grad_norm 6.0621 (4.4351)	loss_scale 1024.0000 (771.9227)	mem 8479MB
[2024-07-02 13:02:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:43 lr 0.000020	 wd 0.0000	time 0.2041 (0.2476)	loss 1.4498 (1.3820)	grad_norm 4.7012 (4.4197)	loss_scale 1024.0000 (787.6677)	mem 8479MB
[2024-07-02 13:02:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:17 lr 0.000020	 wd 0.0000	time 0.2182 (0.2457)	loss 1.6394 (1.3836)	grad_norm 4.3507 (4.4311)	loss_scale 1024.0000 (801.5614)	mem 8479MB
[2024-07-02 13:03:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:51 lr 0.000020	 wd 0.0000	time 0.2551 (0.2443)	loss 1.4389 (1.3841)	grad_norm 5.2551 (4.4365)	loss_scale 1024.0000 (813.9123)	mem 8479MB
[2024-07-02 13:03:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:27 lr 0.000020	 wd 0.0000	time 0.1757 (0.2449)	loss 1.2544 (1.3847)	grad_norm 3.5697 (4.4904)	loss_scale 1024.0000 (824.9637)	mem 8479MB
[2024-07-02 13:03:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:02:02 lr 0.000019	 wd 0.0000	time 0.2365 (0.2441)	loss 1.4567 (1.3823)	grad_norm 6.5214 (4.4827)	loss_scale 1024.0000 (834.9105)	mem 8479MB
[2024-07-02 13:04:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:37 lr 0.000019	 wd 0.0000	time 0.2018 (0.2427)	loss 1.5481 (1.3822)	grad_norm 24.5532 (4.4796)	loss_scale 1024.0000 (843.9105)	mem 8479MB
[2024-07-02 13:04:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:12 lr 0.000019	 wd 0.0000	time 0.2275 (0.2414)	loss 1.3145 (1.3826)	grad_norm 4.7467 (4.5143)	loss_scale 1024.0000 (852.0927)	mem 8479MB
[2024-07-02 13:04:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:48 lr 0.000019	 wd 0.0000	time 0.2271 (0.2409)	loss 1.6035 (1.3816)	grad_norm 3.6882 (4.4950)	loss_scale 1024.0000 (859.5637)	mem 8479MB
[2024-07-02 13:05:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:24 lr 0.000019	 wd 0.0000	time 0.2015 (0.2406)	loss 1.4676 (1.3797)	grad_norm 3.3230 (4.4936)	loss_scale 1024.0000 (866.4123)	mem 8479MB
[2024-07-02 13:05:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000019	 wd 0.0000	time 0.1636 (0.2385)	loss 1.3706 (1.3804)	grad_norm 3.6756 (4.4955)	loss_scale 1024.0000 (872.7133)	mem 8479MB
[2024-07-02 13:05:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 17 training takes 0:10:01
[2024-07-02 13:06:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 20.961 (20.961)	Loss 0.4141 (0.4141)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 8479MB
[2024-07-02 13:06:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.870 Acc@5 97.138
[2024-07-02 13:06:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-02 13:06:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.89%
[2024-07-02 13:06:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][0/2502]	eta 1 day, 1:05:41 lr 0.000019	 wd 0.0000	time 36.1077 (36.1077)	loss 1.6370 (1.6370)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:07:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:22:55 lr 0.000019	 wd 0.0000	time 0.2023 (0.5725)	loss 1.5971 (1.4231)	grad_norm 11.8782 (nan)	loss_scale 512.0000 (638.7327)	mem 8479MB
[2024-07-02 13:07:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:15:05 lr 0.000019	 wd 0.0000	time 0.2189 (0.3932)	loss 1.5846 (1.3964)	grad_norm 5.2053 (nan)	loss_scale 512.0000 (575.6816)	mem 8479MB
[2024-07-02 13:07:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:12:17 lr 0.000019	 wd 0.0000	time 0.1947 (0.3349)	loss 1.6040 (1.3929)	grad_norm 4.1781 (nan)	loss_scale 512.0000 (554.5249)	mem 8479MB
[2024-07-02 13:08:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:11:37 lr 0.000019	 wd 0.0000	time 0.2359 (0.3319)	loss 1.4303 (1.3888)	grad_norm 3.6627 (nan)	loss_scale 512.0000 (543.9202)	mem 8479MB
[2024-07-02 13:08:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:10:15 lr 0.000018	 wd 0.0000	time 0.1833 (0.3075)	loss 1.2562 (1.3821)	grad_norm 4.9118 (nan)	loss_scale 512.0000 (537.5489)	mem 8479MB
[2024-07-02 13:09:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:09:13 lr 0.000018	 wd 0.0000	time 0.2049 (0.2910)	loss 1.6003 (1.3807)	grad_norm 3.2834 (nan)	loss_scale 512.0000 (533.2978)	mem 8479MB
[2024-07-02 13:09:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:08:25 lr 0.000018	 wd 0.0000	time 0.2504 (0.2807)	loss 1.6047 (1.3819)	grad_norm 3.0027 (nan)	loss_scale 512.0000 (530.2596)	mem 8479MB
[2024-07-02 13:10:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:57 lr 0.000018	 wd 0.0000	time 0.2060 (0.2807)	loss 1.1480 (1.3789)	grad_norm 3.6109 (nan)	loss_scale 512.0000 (527.9800)	mem 8479MB
[2024-07-02 13:10:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:07:17 lr 0.000018	 wd 0.0000	time 0.2069 (0.2731)	loss 1.4092 (1.3755)	grad_norm 3.8465 (nan)	loss_scale 512.0000 (526.2064)	mem 8479MB
[2024-07-02 13:10:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:41 lr 0.000018	 wd 0.0000	time 0.2033 (0.2673)	loss 1.1552 (1.3795)	grad_norm 10.1010 (nan)	loss_scale 512.0000 (524.7872)	mem 8479MB
[2024-07-02 13:11:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:06:07 lr 0.000018	 wd 0.0000	time 0.2186 (0.2624)	loss 1.3207 (1.3787)	grad_norm 4.2670 (nan)	loss_scale 512.0000 (523.6258)	mem 8479MB
[2024-07-02 13:11:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:47 lr 0.000018	 wd 0.0000	time 0.2632 (0.2672)	loss 1.5422 (1.3790)	grad_norm 4.1234 (nan)	loss_scale 512.0000 (522.6578)	mem 8479MB
[2024-07-02 13:12:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:05:16 lr 0.000018	 wd 0.0000	time 0.1953 (0.2632)	loss 1.5835 (1.3800)	grad_norm 7.7076 (nan)	loss_scale 512.0000 (521.8386)	mem 8479MB
[2024-07-02 13:12:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:45 lr 0.000018	 wd 0.0000	time 0.1942 (0.2595)	loss 1.2324 (1.3793)	grad_norm 4.8258 (nan)	loss_scale 512.0000 (521.1363)	mem 8479MB
[2024-07-02 13:12:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:04:16 lr 0.000017	 wd 0.0000	time 0.2062 (0.2563)	loss 1.5722 (1.3777)	grad_norm 6.5987 (nan)	loss_scale 512.0000 (520.5276)	mem 8479MB
[2024-07-02 13:13:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:50 lr 0.000017	 wd 0.0000	time 0.2176 (0.2553)	loss 1.6157 (1.3775)	grad_norm 6.9883 (nan)	loss_scale 512.0000 (519.9950)	mem 8479MB
[2024-07-02 13:13:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:24 lr 0.000017	 wd 0.0000	time 0.2025 (0.2544)	loss 1.4962 (1.3765)	grad_norm 5.6413 (nan)	loss_scale 512.0000 (519.5250)	mem 8479MB
[2024-07-02 13:13:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:57 lr 0.000017	 wd 0.0000	time 0.2463 (0.2522)	loss 1.3666 (1.3779)	grad_norm 2.5397 (nan)	loss_scale 512.0000 (519.1072)	mem 8479MB
[2024-07-02 13:14:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:30 lr 0.000017	 wd 0.0000	time 0.2133 (0.2502)	loss 1.6170 (1.3780)	grad_norm 2.6606 (nan)	loss_scale 512.0000 (518.7333)	mem 8479MB
[2024-07-02 13:14:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:02:05 lr 0.000017	 wd 0.0000	time 0.2272 (0.2492)	loss 1.4773 (1.3801)	grad_norm 3.2962 (nan)	loss_scale 512.0000 (518.3968)	mem 8479MB
[2024-07-02 13:15:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:40 lr 0.000017	 wd 0.0000	time 0.2051 (0.2492)	loss 1.4060 (1.3795)	grad_norm 2.8944 (nan)	loss_scale 512.0000 (518.0923)	mem 8479MB
[2024-07-02 13:15:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:14 lr 0.000017	 wd 0.0000	time 0.2071 (0.2476)	loss 1.4716 (1.3794)	grad_norm 3.1167 (nan)	loss_scale 512.0000 (517.8155)	mem 8479MB
[2024-07-02 13:15:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:49 lr 0.000017	 wd 0.0000	time 0.2143 (0.2462)	loss 1.4692 (1.3793)	grad_norm 5.4945 (nan)	loss_scale 512.0000 (517.5628)	mem 8479MB
[2024-07-02 13:16:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:24 lr 0.000017	 wd 0.0000	time 0.2493 (0.2451)	loss 1.5702 (1.3808)	grad_norm 8.0333 (nan)	loss_scale 512.0000 (517.3311)	mem 8479MB
[2024-07-02 13:16:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000016	 wd 0.0000	time 0.1643 (0.2430)	loss 1.5359 (1.3805)	grad_norm 4.7299 (nan)	loss_scale 512.0000 (517.1180)	mem 8479MB
[2024-07-02 13:16:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 18 training takes 0:10:18
[2024-07-02 13:17:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 26.584 (26.584)	Loss 0.4143 (0.4143)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 8479MB
[2024-07-02 13:17:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.864 Acc@5 97.176
[2024-07-02 13:17:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-02 13:17:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.89%
[2024-07-02 13:17:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][0/2502]	eta 10:13:18 lr 0.000016	 wd 0.0000	time 14.7076 (14.7076)	loss 1.5222 (1.5222)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:18:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:17:31 lr 0.000016	 wd 0.0000	time 0.2265 (0.4378)	loss 1.1311 (1.3853)	grad_norm 5.3898 (4.3571)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:18:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:12:29 lr 0.000016	 wd 0.0000	time 0.2061 (0.3258)	loss 1.5423 (1.3839)	grad_norm 3.2269 (4.4178)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:18:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:10:33 lr 0.000016	 wd 0.0000	time 0.2217 (0.2877)	loss 1.3765 (1.3954)	grad_norm 4.6507 (4.4691)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:19:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:09:23 lr 0.000016	 wd 0.0000	time 0.2235 (0.2682)	loss 1.5939 (1.3947)	grad_norm 3.6437 (4.5138)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:19:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:08:41 lr 0.000016	 wd 0.0000	time 0.2542 (0.2604)	loss 1.6596 (1.3919)	grad_norm 4.1329 (4.4670)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:19:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:23 lr 0.000016	 wd 0.0000	time 0.2283 (0.2650)	loss 1.5698 (1.3878)	grad_norm 6.4508 (4.4016)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:20:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:07:42 lr 0.000016	 wd 0.0000	time 0.1973 (0.2568)	loss 1.6916 (1.3897)	grad_norm 4.3370 (4.4205)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:20:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:07:07 lr 0.000016	 wd 0.0000	time 0.2262 (0.2514)	loss 1.3467 (1.3865)	grad_norm 3.6791 (4.3884)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:21:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:06:38 lr 0.000016	 wd 0.0000	time 0.2790 (0.2487)	loss 1.4572 (1.3880)	grad_norm 4.3114 (4.4172)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:21:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:14 lr 0.000016	 wd 0.0000	time 0.2044 (0.2492)	loss 1.5627 (1.3906)	grad_norm 4.4382 (4.4900)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:21:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:45 lr 0.000015	 wd 0.0000	time 0.2007 (0.2462)	loss 0.9118 (1.3888)	grad_norm 3.1615 (4.4462)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:22:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:16 lr 0.000015	 wd 0.0000	time 0.2148 (0.2435)	loss 1.1502 (1.3862)	grad_norm 4.9270 (4.4558)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:22:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:04:50 lr 0.000015	 wd 0.0000	time 0.2435 (0.2415)	loss 1.5018 (1.3863)	grad_norm 15.8327 (4.4270)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:22:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:26 lr 0.000015	 wd 0.0000	time 0.2269 (0.2423)	loss 1.4632 (1.3878)	grad_norm 3.6584 (4.4303)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:23:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:04:01 lr 0.000015	 wd 0.0000	time 0.2122 (0.2409)	loss 1.2552 (1.3877)	grad_norm 4.0527 (4.4279)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:23:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:35 lr 0.000015	 wd 0.0000	time 0.2167 (0.2392)	loss 1.4282 (1.3883)	grad_norm 14.9460 (4.4115)	loss_scale 1024.0000 (536.9444)	mem 8479MB
[2024-07-02 13:24:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:10 lr 0.000015	 wd 0.0000	time 0.2253 (0.2376)	loss 1.5499 (1.3889)	grad_norm 3.8621 (4.4003)	loss_scale 1024.0000 (565.5779)	mem 8479MB
[2024-07-02 13:24:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:46 lr 0.000015	 wd 0.0000	time 0.2662 (0.2373)	loss 1.3589 (1.3889)	grad_norm 3.1815 (4.3881)	loss_scale 1024.0000 (591.0316)	mem 8479MB
[2024-07-02 13:24:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:23 lr 0.000015	 wd 0.0000	time 0.2183 (0.2380)	loss 1.3344 (1.3894)	grad_norm 6.7396 (4.4028)	loss_scale 1024.0000 (613.8075)	mem 8479MB
[2024-07-02 13:25:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:58 lr 0.000015	 wd 0.0000	time 0.2064 (0.2369)	loss 1.0431 (1.3888)	grad_norm 4.2173 (4.3842)	loss_scale 1024.0000 (634.3068)	mem 8479MB
[2024-07-02 13:25:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:34 lr 0.000014	 wd 0.0000	time 0.1915 (0.2359)	loss 1.2155 (1.3880)	grad_norm 3.4433 (4.3851)	loss_scale 1024.0000 (652.8548)	mem 8479MB
[2024-07-02 13:25:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:11 lr 0.000014	 wd 0.0000	time 0.2231 (0.2355)	loss 1.5311 (1.3862)	grad_norm 3.2616 (4.3877)	loss_scale 1024.0000 (669.7174)	mem 8479MB
[2024-07-02 13:26:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:47 lr 0.000014	 wd 0.0000	time 0.2271 (0.2358)	loss 1.4245 (1.3856)	grad_norm 3.5538 (4.3748)	loss_scale 1024.0000 (685.1143)	mem 8479MB
[2024-07-02 13:26:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:23 lr 0.000014	 wd 0.0000	time 0.1870 (0.2349)	loss 1.5970 (1.3865)	grad_norm 4.4721 (4.3628)	loss_scale 1024.0000 (699.2287)	mem 8479MB
[2024-07-02 13:27:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1731 (0.2331)	loss 1.2888 (1.3865)	grad_norm 4.4758 (4.3799)	loss_scale 1024.0000 (712.2143)	mem 8479MB
[2024-07-02 13:27:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 19 training takes 0:09:49
[2024-07-02 13:27:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 40.492 (40.492)	Loss 0.4136 (0.4136)	Acc@1 92.969 (92.969)	Acc@5 98.633 (98.633)	Mem 8479MB
[2024-07-02 13:28:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.842 Acc@5 97.162
[2024-07-02 13:28:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-02 13:28:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.89%
[2024-07-02 13:28:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][0/2502]	eta 11:03:13 lr 0.000014	 wd 0.0000	time 15.9048 (15.9048)	loss 1.1036 (1.1036)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:28:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:15:03 lr 0.000014	 wd 0.0000	time 0.1856 (0.3762)	loss 1.7357 (1.3828)	grad_norm 3.4896 (4.5681)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:29:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:11:28 lr 0.000014	 wd 0.0000	time 0.2005 (0.2993)	loss 1.4410 (1.3891)	grad_norm 12.1605 (4.5671)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:29:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:11:36 lr 0.000014	 wd 0.0000	time 0.2050 (0.3165)	loss 1.4774 (1.3866)	grad_norm 4.2036 (4.3702)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:29:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:10:08 lr 0.000014	 wd 0.0000	time 0.1991 (0.2896)	loss 1.5547 (1.3929)	grad_norm 2.1504 (4.5416)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:30:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:09:07 lr 0.000014	 wd 0.0000	time 0.1823 (0.2734)	loss 1.3959 (1.3920)	grad_norm 4.2649 (4.6913)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:30:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:08:23 lr 0.000014	 wd 0.0000	time 0.2308 (0.2649)	loss 1.4962 (1.3877)	grad_norm 9.8202 (4.6547)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:31:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:08:10 lr 0.000013	 wd 0.0000	time 0.2098 (0.2720)	loss 1.4723 (1.3929)	grad_norm 2.9115 (4.6485)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:31:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:07:29 lr 0.000013	 wd 0.0000	time 0.1980 (0.2643)	loss 1.2895 (1.3899)	grad_norm 7.0501 (4.5768)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:31:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:53 lr 0.000013	 wd 0.0000	time 0.2194 (0.2584)	loss 1.6587 (1.3928)	grad_norm 3.0434 (4.5901)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:32:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:23 lr 0.000013	 wd 0.0000	time 0.2476 (0.2552)	loss 1.3940 (1.3923)	grad_norm 3.5266 (4.5634)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:32:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:06:03 lr 0.000013	 wd 0.0000	time 0.2293 (0.2592)	loss 1.4439 (1.3893)	grad_norm 4.6819 (4.5180)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:33:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:32 lr 0.000013	 wd 0.0000	time 0.2116 (0.2554)	loss 1.4454 (1.3865)	grad_norm 7.4644 (4.5794)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:33:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:05:03 lr 0.000013	 wd 0.0000	time 0.2044 (0.2522)	loss 1.2266 (1.3829)	grad_norm 6.6153 (4.6633)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:33:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:35 lr 0.000013	 wd 0.0000	time 0.2831 (0.2498)	loss 1.3790 (1.3847)	grad_norm 3.2257 (4.6412)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:34:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:04:10 lr 0.000013	 wd 0.0000	time 0.1997 (0.2497)	loss 1.2893 (1.3862)	grad_norm 9.9820 (4.6037)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:34:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:43 lr 0.000013	 wd 0.0000	time 0.1944 (0.2477)	loss 1.6006 (1.3868)	grad_norm 7.4989 (4.6376)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:35:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:17 lr 0.000012	 wd 0.0000	time 0.2187 (0.2458)	loss 1.5816 (1.3862)	grad_norm 4.5335 (4.6161)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:35:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:51 lr 0.000012	 wd 0.0000	time 0.1961 (0.2440)	loss 1.3311 (1.3850)	grad_norm 3.5243 (4.6666)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:35:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:26 lr 0.000012	 wd 0.0000	time 0.3634 (0.2436)	loss 1.6663 (1.3859)	grad_norm 2.5820 (4.6258)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:36:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:02:02 lr 0.000012	 wd 0.0000	time 0.2511 (0.2435)	loss 1.5209 (1.3851)	grad_norm 3.7172 (4.6035)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:36:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:37 lr 0.000012	 wd 0.0000	time 0.2169 (0.2423)	loss 1.4114 (1.3858)	grad_norm 4.2307 (4.6173)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:36:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:12 lr 0.000012	 wd 0.0000	time 0.2027 (0.2409)	loss 1.3451 (1.3871)	grad_norm 2.7065 (4.6116)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:37:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:48 lr 0.000012	 wd 0.0000	time 0.2201 (0.2404)	loss 1.3198 (1.3874)	grad_norm 3.6040 (4.5858)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:37:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:24 lr 0.000012	 wd 0.0000	time 0.1997 (0.2405)	loss 1.2898 (1.3879)	grad_norm 2.8713 (4.5851)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:37:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000012	 wd 0.0000	time 0.1615 (0.2383)	loss 1.5113 (1.3886)	grad_norm 2.8016 (4.5899)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:38:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 20 training takes 0:10:04
[2024-07-02 13:38:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 19.183 (19.183)	Loss 0.4163 (0.4163)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 8479MB
[2024-07-02 13:38:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.876 Acc@5 97.186
[2024-07-02 13:38:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-02 13:38:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.89%
[2024-07-02 13:39:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][0/2502]	eta 1 day, 3:07:41 lr 0.000012	 wd 0.0000	time 39.0334 (39.0334)	loss 1.6113 (1.6113)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:39:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:23:53 lr 0.000012	 wd 0.0000	time 0.1978 (0.5969)	loss 1.6223 (1.4233)	grad_norm 2.8789 (4.1346)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:40:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:15:27 lr 0.000012	 wd 0.0000	time 0.2166 (0.4029)	loss 0.9940 (1.3931)	grad_norm 3.1056 (4.3774)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:40:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:12:59 lr 0.000012	 wd 0.0000	time 0.3796 (0.3540)	loss 1.4177 (1.3835)	grad_norm 3.6679 (4.3662)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:41:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:11:53 lr 0.000011	 wd 0.0000	time 0.2250 (0.3395)	loss 1.3755 (1.3859)	grad_norm 3.9972 (4.3452)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:41:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:10:27 lr 0.000011	 wd 0.0000	time 0.2084 (0.3137)	loss 1.3418 (1.3852)	grad_norm 3.5472 (4.3481)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 13:41:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:09:23 lr 0.000011	 wd 0.0000	time 0.2068 (0.2963)	loss 1.2816 (1.3867)	grad_norm 3.1422 (4.2839)	loss_scale 2048.0000 (1163.7138)	mem 8479MB
[2024-07-02 13:42:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:08:40 lr 0.000011	 wd 0.0000	time 0.2955 (0.2888)	loss 1.3003 (1.3808)	grad_norm 3.6991 (4.2191)	loss_scale 2048.0000 (1289.8602)	mem 8479MB
[2024-07-02 13:42:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:08:12 lr 0.000011	 wd 0.0000	time 0.2156 (0.2896)	loss 1.3024 (1.3792)	grad_norm 3.0426 (nan)	loss_scale 1024.0000 (1256.6692)	mem 8479MB
[2024-07-02 13:42:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:07:30 lr 0.000011	 wd 0.0000	time 0.2008 (0.2810)	loss 1.6129 (1.3782)	grad_norm 4.6773 (nan)	loss_scale 1024.0000 (1230.8457)	mem 8479MB
[2024-07-02 13:43:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:51 lr 0.000011	 wd 0.0000	time 0.1951 (0.2739)	loss 1.1050 (1.3771)	grad_norm 2.7082 (nan)	loss_scale 1024.0000 (1210.1818)	mem 8479MB
[2024-07-02 13:43:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:06:18 lr 0.000011	 wd 0.0000	time 0.2393 (0.2699)	loss 1.4402 (1.3774)	grad_norm 3.8150 (nan)	loss_scale 1024.0000 (1193.2716)	mem 8479MB
[2024-07-02 13:44:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:49 lr 0.000011	 wd 0.0000	time 0.2055 (0.2686)	loss 1.4671 (1.3778)	grad_norm 3.2573 (nan)	loss_scale 1024.0000 (1179.1774)	mem 8479MB
[2024-07-02 13:44:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:05:18 lr 0.000011	 wd 0.0000	time 0.1901 (0.2646)	loss 1.5525 (1.3772)	grad_norm 3.7739 (nan)	loss_scale 1024.0000 (1167.2498)	mem 8479MB
[2024-07-02 13:44:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:47 lr 0.000011	 wd 0.0000	time 0.2089 (0.2610)	loss 1.3797 (1.3777)	grad_norm 3.6835 (nan)	loss_scale 1024.0000 (1157.0250)	mem 8479MB
[2024-07-02 13:45:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:04:18 lr 0.000010	 wd 0.0000	time 0.2487 (0.2584)	loss 1.7233 (1.3773)	grad_norm 3.6644 (nan)	loss_scale 1024.0000 (1148.1626)	mem 8479MB
[2024-07-02 13:45:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:52 lr 0.000010	 wd 0.0000	time 0.2417 (0.2579)	loss 1.3102 (1.3767)	grad_norm 3.7003 (nan)	loss_scale 1024.0000 (1140.4072)	mem 8479MB
[2024-07-02 13:45:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:25 lr 0.000010	 wd 0.0000	time 0.2136 (0.2558)	loss 1.5193 (1.3772)	grad_norm 3.4539 (nan)	loss_scale 512.0000 (1106.4738)	mem 8479MB
[2024-07-02 13:46:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:58 lr 0.000010	 wd 0.0000	time 0.2199 (0.2537)	loss 1.1054 (1.3782)	grad_norm 4.2890 (nan)	loss_scale 512.0000 (1073.4659)	mem 8479MB
[2024-07-02 13:46:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:31 lr 0.000010	 wd 0.0000	time 0.2250 (0.2517)	loss 1.0789 (1.3765)	grad_norm 4.4819 (nan)	loss_scale 512.0000 (1043.9306)	mem 8479MB
[2024-07-02 13:47:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:02:06 lr 0.000010	 wd 0.0000	time 0.3465 (0.2511)	loss 1.4239 (1.3762)	grad_norm 3.1650 (nan)	loss_scale 512.0000 (1017.3473)	mem 8479MB
[2024-07-02 13:47:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:40 lr 0.000010	 wd 0.0000	time 0.2118 (0.2502)	loss 1.1972 (1.3779)	grad_norm 4.7673 (nan)	loss_scale 512.0000 (993.2946)	mem 8479MB
[2024-07-02 13:47:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:15 lr 0.000010	 wd 0.0000	time 0.2074 (0.2488)	loss 1.6559 (1.3761)	grad_norm 3.7255 (nan)	loss_scale 512.0000 (971.4275)	mem 8479MB
[2024-07-02 13:48:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:49 lr 0.000010	 wd 0.0000	time 0.1953 (0.2473)	loss 1.6499 (1.3752)	grad_norm 3.4734 (nan)	loss_scale 512.0000 (951.4611)	mem 8479MB
[2024-07-02 13:48:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:25 lr 0.000010	 wd 0.0000	time 0.2173 (0.2465)	loss 1.3789 (1.3766)	grad_norm 2.6718 (nan)	loss_scale 512.0000 (933.1579)	mem 8479MB
[2024-07-02 13:48:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1648 (0.2447)	loss 1.4731 (1.3760)	grad_norm 4.1060 (nan)	loss_scale 512.0000 (916.3183)	mem 8479MB
[2024-07-02 13:49:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 21 training takes 0:10:24
[2024-07-02 13:49:29 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 20.542 (20.542)	Loss 0.4150 (0.4150)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 8479MB
[2024-07-02 13:49:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.822 Acc@5 97.150
[2024-07-02 13:49:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.8%
[2024-07-02 13:49:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.89%
[2024-07-02 13:50:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][0/2502]	eta 18:09:41 lr 0.000010	 wd 0.0000	time 26.1316 (26.1316)	loss 1.2573 (1.2573)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:50:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:20:19 lr 0.000010	 wd 0.0000	time 0.2042 (0.5079)	loss 1.3918 (1.4002)	grad_norm 4.7505 (4.5120)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:51:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:13:47 lr 0.000009	 wd 0.0000	time 0.2190 (0.3596)	loss 1.0423 (1.3884)	grad_norm 9.1463 (4.4552)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:51:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:11:22 lr 0.000009	 wd 0.0000	time 0.2106 (0.3100)	loss 1.5262 (1.3910)	grad_norm 4.7013 (4.4867)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:51:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:10:05 lr 0.000009	 wd 0.0000	time 0.2357 (0.2882)	loss 1.3823 (1.3949)	grad_norm 3.3680 (4.4761)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:52:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:09:55 lr 0.000009	 wd 0.0000	time 0.1999 (0.2976)	loss 1.0296 (1.3933)	grad_norm 3.3377 (4.6380)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:52:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:58 lr 0.000009	 wd 0.0000	time 0.2604 (0.2833)	loss 1.4830 (1.3934)	grad_norm 4.5659 (4.6850)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:52:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:08:10 lr 0.000009	 wd 0.0000	time 0.1919 (0.2724)	loss 0.9259 (1.3870)	grad_norm 3.9893 (4.6568)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:53:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:07:37 lr 0.000009	 wd 0.0000	time 0.4133 (0.2690)	loss 1.3304 (1.3826)	grad_norm 2.8674 (4.6040)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:54:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:07:27 lr 0.000009	 wd 0.0000	time 0.2107 (0.2796)	loss 1.3417 (1.3801)	grad_norm 3.6137 (4.5756)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:54:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:49 lr 0.000009	 wd 0.0000	time 0.2049 (0.2728)	loss 1.5455 (1.3819)	grad_norm 4.7054 (4.5668)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:54:42 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:06:14 lr 0.000009	 wd 0.0000	time 0.1910 (0.2670)	loss 1.4047 (1.3801)	grad_norm 4.5689 (4.5146)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:55:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:44 lr 0.000009	 wd 0.0000	time 0.2435 (0.2644)	loss 1.3493 (1.3794)	grad_norm 3.8200 (4.5166)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:55:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:05:15 lr 0.000009	 wd 0.0000	time 0.2232 (0.2626)	loss 1.0328 (1.3803)	grad_norm 4.4942 (4.4976)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:55:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:45 lr 0.000008	 wd 0.0000	time 0.2044 (0.2592)	loss 1.5551 (1.3820)	grad_norm 3.1745 (4.4981)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:56:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:04:16 lr 0.000008	 wd 0.0000	time 0.1870 (0.2562)	loss 1.2400 (1.3826)	grad_norm 3.0784 (4.4950)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:56:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:49 lr 0.000008	 wd 0.0000	time 0.2375 (0.2541)	loss 1.5965 (1.3825)	grad_norm 3.4922 (4.4810)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:56:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:23 lr 0.000008	 wd 0.0000	time 0.2208 (0.2534)	loss 1.3176 (1.3817)	grad_norm 4.0810 (4.4984)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:57:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:56 lr 0.000008	 wd 0.0000	time 0.2097 (0.2514)	loss 1.6849 (1.3814)	grad_norm 4.3421 (4.4909)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:57:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:30 lr 0.000008	 wd 0.0000	time 0.2155 (0.2495)	loss 1.5598 (1.3805)	grad_norm 3.7320 (4.4740)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:58:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:02:04 lr 0.000008	 wd 0.0000	time 0.2292 (0.2479)	loss 1.5074 (1.3793)	grad_norm 3.8707 (4.5282)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:58:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:39 lr 0.000008	 wd 0.0000	time 0.2138 (0.2483)	loss 1.5089 (1.3799)	grad_norm 4.0898 (4.5068)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:58:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:14 lr 0.000008	 wd 0.0000	time 0.2008 (0.2474)	loss 1.4960 (1.3788)	grad_norm 3.8313 (4.4910)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:59:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:49 lr 0.000008	 wd 0.0000	time 0.1992 (0.2460)	loss 1.5944 (1.3789)	grad_norm 2.7830 (4.4971)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:59:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:24 lr 0.000008	 wd 0.0000	time 0.2076 (0.2446)	loss 1.1256 (1.3785)	grad_norm 4.4137 (4.5005)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 13:59:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1668 (0.2426)	loss 1.0750 (1.3775)	grad_norm 2.9163 (4.4799)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:00:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 22 training takes 0:10:15
[2024-07-02 14:00:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 33.064 (33.064)	Loss 0.4170 (0.4170)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 8479MB
[2024-07-02 14:00:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.882 Acc@5 97.156
[2024-07-02 14:00:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-02 14:00:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.89%
[2024-07-02 14:01:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][0/2502]	eta 11:30:09 lr 0.000008	 wd 0.0000	time 16.5505 (16.5505)	loss 1.1537 (1.1537)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:01:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:19:07 lr 0.000008	 wd 0.0000	time 0.2448 (0.4778)	loss 1.4886 (1.4209)	grad_norm 4.4999 (4.1632)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:02:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:13:14 lr 0.000007	 wd 0.0000	time 0.1912 (0.3450)	loss 1.5900 (1.3978)	grad_norm 3.4443 (4.2396)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:02:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:11:01 lr 0.000007	 wd 0.0000	time 0.2113 (0.3006)	loss 1.3941 (1.3912)	grad_norm 5.2792 (4.5811)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:02:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:09:43 lr 0.000007	 wd 0.0000	time 0.2041 (0.2775)	loss 1.7238 (1.3857)	grad_norm 9.0105 (4.6451)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:03:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:09:31 lr 0.000007	 wd 0.0000	time 0.2048 (0.2856)	loss 1.6046 (1.3899)	grad_norm 5.1348 (4.5875)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:03:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:08:42 lr 0.000007	 wd 0.0000	time 0.2005 (0.2745)	loss 1.2030 (1.3904)	grad_norm 4.6440 (4.4993)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:04:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:58 lr 0.000007	 wd 0.0000	time 0.2170 (0.2653)	loss 1.5265 (1.3870)	grad_norm 3.2686 (4.4953)	loss_scale 1024.0000 (580.6562)	mem 8479MB
[2024-07-02 14:04:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:07:20 lr 0.000007	 wd 0.0000	time 0.2120 (0.2587)	loss 1.7262 (1.3843)	grad_norm 3.1132 (nan)	loss_scale 512.0000 (577.1985)	mem 8479MB
[2024-07-02 14:04:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:07:14 lr 0.000007	 wd 0.0000	time 0.3295 (0.2709)	loss 1.6770 (1.3813)	grad_norm 4.8226 (nan)	loss_scale 512.0000 (569.9623)	mem 8479MB
[2024-07-02 14:05:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:41 lr 0.000007	 wd 0.0000	time 0.2053 (0.2676)	loss 1.1176 (1.3806)	grad_norm 13.6152 (nan)	loss_scale 512.0000 (564.1718)	mem 8479MB
[2024-07-02 14:05:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:06:07 lr 0.000007	 wd 0.0000	time 0.2159 (0.2624)	loss 0.8623 (1.3754)	grad_norm 2.9001 (nan)	loss_scale 512.0000 (559.4332)	mem 8479MB
[2024-07-02 14:06:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:36 lr 0.000007	 wd 0.0000	time 0.2071 (0.2583)	loss 1.5764 (1.3773)	grad_norm 2.7592 (nan)	loss_scale 512.0000 (555.4838)	mem 8479MB
[2024-07-02 14:06:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:05:09 lr 0.000007	 wd 0.0000	time 0.1993 (0.2577)	loss 1.5672 (1.3786)	grad_norm 3.4416 (nan)	loss_scale 512.0000 (552.1414)	mem 8479MB
[2024-07-02 14:06:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:41 lr 0.000007	 wd 0.0000	time 0.2008 (0.2554)	loss 1.3536 (1.3782)	grad_norm 5.5766 (nan)	loss_scale 512.0000 (549.2762)	mem 8479MB
[2024-07-02 14:07:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:04:13 lr 0.000006	 wd 0.0000	time 0.2079 (0.2526)	loss 1.2833 (1.3799)	grad_norm 5.5405 (nan)	loss_scale 512.0000 (546.7928)	mem 8479MB
[2024-07-02 14:07:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:45 lr 0.000006	 wd 0.0000	time 0.2041 (0.2501)	loss 1.2542 (1.3796)	grad_norm 3.3783 (nan)	loss_scale 512.0000 (544.6196)	mem 8479MB
[2024-07-02 14:07:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:19 lr 0.000006	 wd 0.0000	time 0.2205 (0.2491)	loss 1.4029 (1.3798)	grad_norm 4.1587 (nan)	loss_scale 512.0000 (542.7019)	mem 8479MB
[2024-07-02 14:08:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:54 lr 0.000006	 wd 0.0000	time 0.2128 (0.2492)	loss 1.3833 (1.3792)	grad_norm 3.0958 (nan)	loss_scale 512.0000 (540.9972)	mem 8479MB
[2024-07-02 14:08:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:29 lr 0.000006	 wd 0.0000	time 0.2032 (0.2476)	loss 1.2359 (1.3817)	grad_norm 3.9153 (nan)	loss_scale 512.0000 (539.4719)	mem 8479MB
[2024-07-02 14:09:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:02:03 lr 0.000006	 wd 0.0000	time 0.2067 (0.2459)	loss 1.4008 (1.3804)	grad_norm 3.7929 (nan)	loss_scale 512.0000 (538.0990)	mem 8479MB
[2024-07-02 14:09:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:38 lr 0.000006	 wd 0.0000	time 0.2353 (0.2450)	loss 1.6970 (1.3806)	grad_norm 2.9661 (nan)	loss_scale 512.0000 (536.8567)	mem 8479MB
[2024-07-02 14:09:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:14 lr 0.000006	 wd 0.0000	time 0.1990 (0.2451)	loss 1.4870 (1.3780)	grad_norm 4.8289 (nan)	loss_scale 512.0000 (535.7274)	mem 8479MB
[2024-07-02 14:10:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:49 lr 0.000006	 wd 0.0000	time 0.2002 (0.2440)	loss 1.5155 (1.3777)	grad_norm 5.3019 (nan)	loss_scale 512.0000 (534.6962)	mem 8479MB
[2024-07-02 14:10:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:24 lr 0.000006	 wd 0.0000	time 0.1909 (0.2427)	loss 1.5598 (1.3784)	grad_norm 3.1763 (nan)	loss_scale 512.0000 (533.7509)	mem 8479MB
[2024-07-02 14:10:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000006	 wd 0.0000	time 0.1806 (0.2405)	loss 1.5207 (1.3793)	grad_norm 4.1687 (nan)	loss_scale 512.0000 (532.8812)	mem 8479MB
[2024-07-02 14:11:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 23 training takes 0:10:10
[2024-07-02 14:11:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 36.493 (36.493)	Loss 0.4150 (0.4150)	Acc@1 92.969 (92.969)	Acc@5 98.633 (98.633)	Mem 8479MB
[2024-07-02 14:12:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.880 Acc@5 97.172
[2024-07-02 14:12:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-02 14:12:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.89%
[2024-07-02 14:12:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][0/2502]	eta 11:39:32 lr 0.000006	 wd 0.0000	time 16.7756 (16.7756)	loss 1.6071 (1.6071)	grad_norm 0.0000 (0.0000)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:12:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:15:38 lr 0.000006	 wd 0.0000	time 0.2647 (0.3909)	loss 1.2333 (1.4166)	grad_norm 3.4767 (4.6827)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:13:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:13:29 lr 0.000006	 wd 0.0000	time 0.1944 (0.3517)	loss 1.6531 (1.4030)	grad_norm 3.9979 (4.4229)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:13:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:11:11 lr 0.000006	 wd 0.0000	time 0.2051 (0.3048)	loss 1.6520 (1.3911)	grad_norm 3.7718 (4.5325)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:13:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:09:51 lr 0.000005	 wd 0.0000	time 0.2197 (0.2813)	loss 1.4973 (1.3859)	grad_norm 4.1302 (4.4898)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:14:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:08:56 lr 0.000005	 wd 0.0000	time 0.2212 (0.2681)	loss 1.6271 (1.3877)	grad_norm 6.1583 (4.5094)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:14:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:08:52 lr 0.000005	 wd 0.0000	time 0.2309 (0.2802)	loss 1.3942 (1.3826)	grad_norm 3.7271 (4.4267)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:15:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:08:07 lr 0.000005	 wd 0.0000	time 0.2158 (0.2705)	loss 1.3096 (1.3843)	grad_norm 3.1852 (4.4544)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:15:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:07:27 lr 0.000005	 wd 0.0000	time 0.1969 (0.2630)	loss 1.4336 (1.3857)	grad_norm 3.8644 (4.5064)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:15:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:06:53 lr 0.000005	 wd 0.0000	time 0.2534 (0.2584)	loss 1.4849 (1.3833)	grad_norm 4.4799 (4.5233)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:16:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:26 lr 0.000005	 wd 0.0000	time 0.2017 (0.2573)	loss 1.3201 (1.3831)	grad_norm 4.5859 (4.4806)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:16:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:05:55 lr 0.000005	 wd 0.0000	time 0.2032 (0.2536)	loss 1.5087 (1.3813)	grad_norm 5.6306 (4.4822)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:17:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:25 lr 0.000005	 wd 0.0000	time 0.2278 (0.2504)	loss 1.1625 (1.3798)	grad_norm 5.0668 (4.4469)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:17:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:04:57 lr 0.000005	 wd 0.0000	time 0.2281 (0.2477)	loss 1.2904 (1.3806)	grad_norm 16.7409 (4.4417)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:17:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:34 lr 0.000005	 wd 0.0000	time 1.7401 (0.2488)	loss 1.2711 (1.3790)	grad_norm 4.3812 (4.4169)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:18:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:07 lr 0.000005	 wd 0.0000	time 0.1836 (0.2473)	loss 1.0072 (1.3778)	grad_norm 14.2039 (4.4176)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:18:34 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:41 lr 0.000005	 wd 0.0000	time 0.2110 (0.2452)	loss 1.4345 (1.3772)	grad_norm 5.3430 (4.3978)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:18:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:15 lr 0.000005	 wd 0.0000	time 0.2019 (0.2433)	loss 1.7380 (1.3794)	grad_norm 6.8630 (4.4030)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:19:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:50 lr 0.000005	 wd 0.0000	time 0.2281 (0.2426)	loss 1.2250 (1.3786)	grad_norm 4.8367 (4.4178)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:19:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:26 lr 0.000005	 wd 0.0000	time 0.2213 (0.2430)	loss 1.5049 (1.3799)	grad_norm 2.8387 (4.4149)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:20:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:02:01 lr 0.000004	 wd 0.0000	time 0.1972 (0.2416)	loss 1.5817 (1.3799)	grad_norm 6.4436 (4.4040)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:20:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:36 lr 0.000004	 wd 0.0000	time 0.1949 (0.2402)	loss 1.5560 (1.3783)	grad_norm 4.6194 (4.3919)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:20:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:12 lr 0.000004	 wd 0.0000	time 0.2457 (0.2395)	loss 1.2955 (1.3778)	grad_norm 2.8568 (4.3976)	loss_scale 512.0000 (512.0000)	mem 8479MB
[2024-07-02 14:21:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:48 lr 0.000004	 wd 0.0000	time 0.1903 (0.2398)	loss 1.7354 (1.3773)	grad_norm 4.5031 (4.4156)	loss_scale 1024.0000 (532.9161)	mem 8479MB
[2024-07-02 14:21:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:24 lr 0.000004	 wd 0.0000	time 0.2113 (0.2388)	loss 1.5988 (1.3775)	grad_norm 3.1762 (4.4050)	loss_scale 1024.0000 (553.3694)	mem 8479MB
[2024-07-02 14:21:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000004	 wd 0.0000	time 0.1707 (0.2369)	loss 1.2571 (1.3779)	grad_norm 3.1616 (4.3994)	loss_scale 1024.0000 (572.1871)	mem 8479MB
[2024-07-02 14:22:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 24 training takes 0:10:00
[2024-07-02 14:22:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 38.520 (38.520)	Loss 0.4148 (0.4148)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 8479MB
[2024-07-02 14:22:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.912 Acc@5 97.162
[2024-07-02 14:22:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-02 14:22:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.91%
[2024-07-02 14:22:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saving......
[2024-07-02 14:23:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saved !!!
[2024-07-02 14:23:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][0/2502]	eta 10:54:58 lr 0.000004	 wd 0.0000	time 15.7067 (15.7067)	loss 1.1135 (1.1135)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:23:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:14:33 lr 0.000004	 wd 0.0000	time 0.1950 (0.3636)	loss 1.3653 (1.3484)	grad_norm 3.4440 (4.0511)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:24:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:11:36 lr 0.000004	 wd 0.0000	time 0.4126 (0.3026)	loss 1.4690 (1.3690)	grad_norm 2.2960 (4.4373)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:24:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:11:51 lr 0.000004	 wd 0.0000	time 0.2320 (0.3231)	loss 1.0791 (1.3638)	grad_norm 3.1443 (4.4739)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:24:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:10:20 lr 0.000004	 wd 0.0000	time 0.2248 (0.2951)	loss 1.3112 (1.3779)	grad_norm 3.9739 (4.6983)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:25:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:09:15 lr 0.000004	 wd 0.0000	time 0.2019 (0.2776)	loss 1.4686 (1.3786)	grad_norm 3.8874 (4.6840)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:25:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:33 lr 0.000004	 wd 0.0000	time 0.2419 (0.2700)	loss 1.2228 (1.3811)	grad_norm 4.0879 (4.6685)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:26:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:08:06 lr 0.000004	 wd 0.0000	time 0.2070 (0.2699)	loss 1.2395 (1.3809)	grad_norm 4.6562 (5.0164)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:26:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:07:26 lr 0.000004	 wd 0.0000	time 0.2111 (0.2624)	loss 1.1089 (1.3812)	grad_norm 3.6510 (4.9137)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:26:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:06:51 lr 0.000004	 wd 0.0000	time 0.2036 (0.2570)	loss 1.4534 (1.3834)	grad_norm 3.9051 (4.8077)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:27:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:21 lr 0.000004	 wd 0.0000	time 0.2233 (0.2541)	loss 1.3538 (1.3845)	grad_norm 3.9927 (4.7590)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:27:39 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:54 lr 0.000004	 wd 0.0000	time 0.2657 (0.2531)	loss 1.3942 (1.3823)	grad_norm 4.0995 (4.7277)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:28:01 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:25 lr 0.000004	 wd 0.0000	time 0.2004 (0.2501)	loss 1.3559 (1.3836)	grad_norm 2.9896 (4.6991)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:28:22 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:04:57 lr 0.000003	 wd 0.0000	time 0.1911 (0.2472)	loss 1.5953 (1.3839)	grad_norm 3.2991 (4.6766)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:28:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:29 lr 0.000003	 wd 0.0000	time 0.2103 (0.2448)	loss 1.2196 (1.3849)	grad_norm 2.6833 (4.6527)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:29:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:04:05 lr 0.000003	 wd 0.0000	time 0.2115 (0.2449)	loss 1.2716 (1.3841)	grad_norm 3.2371 (4.6642)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:29:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:39 lr 0.000003	 wd 0.0000	time 0.2133 (0.2436)	loss 1.5575 (1.3841)	grad_norm 3.6484 (4.6408)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:29:52 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:13 lr 0.000003	 wd 0.0000	time 0.2229 (0.2418)	loss 1.3430 (1.3839)	grad_norm 8.5710 (4.6497)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:30:13 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:48 lr 0.000003	 wd 0.0000	time 0.2223 (0.2402)	loss 1.4622 (1.3830)	grad_norm 3.3614 (4.6671)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:30:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:24 lr 0.000003	 wd 0.0000	time 0.2175 (0.2401)	loss 1.6504 (1.3833)	grad_norm 3.7950 (4.6321)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:31:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:02:00 lr 0.000003	 wd 0.0000	time 0.1952 (0.2404)	loss 1.3268 (1.3828)	grad_norm 3.4928 (4.6176)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:31:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:36 lr 0.000003	 wd 0.0000	time 0.2103 (0.2393)	loss 0.9203 (1.3833)	grad_norm 5.0028 (4.6044)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:31:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:11 lr 0.000003	 wd 0.0000	time 0.2076 (0.2382)	loss 1.4382 (1.3822)	grad_norm 3.8954 (4.5767)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:32:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:47 lr 0.000003	 wd 0.0000	time 0.2086 (0.2376)	loss 1.4628 (1.3807)	grad_norm 5.6341 (4.5523)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:32:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:24 lr 0.000003	 wd 0.0000	time 0.3145 (0.2376)	loss 1.4741 (1.3821)	grad_norm 4.5871 (4.5855)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:32:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1647 (0.2356)	loss 1.5555 (1.3822)	grad_norm 3.7145 (4.5691)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:32:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 25 training takes 0:09:58
[2024-07-02 14:33:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 19.312 (19.312)	Loss 0.4150 (0.4150)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 8479MB
[2024-07-02 14:33:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.906 Acc@5 97.172
[2024-07-02 14:33:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-02 14:33:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.91%
[2024-07-02 14:34:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][0/2502]	eta 1 day, 1:58:11 lr 0.000003	 wd 0.0000	time 37.3665 (37.3665)	loss 1.2093 (1.2093)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:34:36 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:23:37 lr 0.000003	 wd 0.0000	time 0.1955 (0.5901)	loss 1.5132 (1.3744)	grad_norm 17.6716 (4.2891)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:34:57 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:15:20 lr 0.000003	 wd 0.0000	time 0.2099 (0.3998)	loss 1.4699 (1.4020)	grad_norm 4.1463 (4.7779)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:35:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:12:28 lr 0.000003	 wd 0.0000	time 0.2165 (0.3400)	loss 1.3610 (1.3945)	grad_norm 2.5991 (4.5731)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:35:51 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:11:46 lr 0.000003	 wd 0.0000	time 0.2128 (0.3363)	loss 1.7125 (1.3968)	grad_norm 4.1829 (4.5283)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:36:12 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:10:22 lr 0.000003	 wd 0.0000	time 0.2215 (0.3107)	loss 1.7050 (1.4035)	grad_norm 5.7411 (4.7018)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:36:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:09:19 lr 0.000003	 wd 0.0000	time 0.1908 (0.2939)	loss 1.2890 (1.3979)	grad_norm 3.5217 (4.6215)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:36:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:08:31 lr 0.000003	 wd 0.0000	time 0.2252 (0.2838)	loss 1.4661 (1.3920)	grad_norm 2.7837 (4.5712)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:37:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:08:08 lr 0.000002	 wd 0.0000	time 0.2223 (0.2871)	loss 1.4685 (1.3886)	grad_norm 2.5532 (4.5415)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:37:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:07:26 lr 0.000002	 wd 0.0000	time 0.1935 (0.2786)	loss 1.3923 (1.3904)	grad_norm 2.6149 (4.5091)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:38:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:48 lr 0.000002	 wd 0.0000	time 0.2290 (0.2720)	loss 1.5046 (1.3898)	grad_norm 3.6022 (4.5319)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:38:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:06:15 lr 0.000002	 wd 0.0000	time 0.2306 (0.2677)	loss 1.5338 (1.3917)	grad_norm 3.4718 (4.5510)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:39:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:53 lr 0.000002	 wd 0.0000	time 0.2024 (0.2716)	loss 1.1041 (1.3919)	grad_norm 3.3557 (4.5138)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:39:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:05:20 lr 0.000002	 wd 0.0000	time 0.2036 (0.2669)	loss 0.9900 (1.3896)	grad_norm 4.3365 (4.4911)	loss_scale 2048.0000 (1101.1345)	mem 8479MB
[2024-07-02 14:39:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:49 lr 0.000002	 wd 0.0000	time 0.1857 (0.2631)	loss 1.8206 (1.3896)	grad_norm 10.2379 (4.4994)	loss_scale 2048.0000 (1168.7195)	mem 8479MB
[2024-07-02 14:40:07 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:04:20 lr 0.000002	 wd 0.0000	time 0.2468 (0.2603)	loss 1.5721 (1.3881)	grad_norm 3.6350 (4.4782)	loss_scale 2048.0000 (1227.2991)	mem 8479MB
[2024-07-02 14:40:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:54 lr 0.000002	 wd 0.0000	time 0.2305 (0.2595)	loss 1.4897 (1.3868)	grad_norm 4.1088 (4.4750)	loss_scale 2048.0000 (1278.5609)	mem 8479MB
[2024-07-02 14:40:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:26 lr 0.000002	 wd 0.0000	time 0.2085 (0.2573)	loss 1.3772 (1.3873)	grad_norm 5.4489 (4.4568)	loss_scale 2048.0000 (1323.7954)	mem 8479MB
[2024-07-02 14:41:16 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:59 lr 0.000002	 wd 0.0000	time 0.2144 (0.2550)	loss 1.5084 (1.3889)	grad_norm 3.2628 (4.4387)	loss_scale 2048.0000 (1364.0067)	mem 8479MB
[2024-07-02 14:41:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:32 lr 0.000002	 wd 0.0000	time 0.2117 (0.2530)	loss 1.1353 (1.3872)	grad_norm 3.7194 (4.4705)	loss_scale 2048.0000 (1399.9874)	mem 8479MB
[2024-07-02 14:42:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:02:07 lr 0.000002	 wd 0.0000	time 0.2180 (0.2531)	loss 1.2236 (1.3868)	grad_norm 5.8374 (4.4569)	loss_scale 2048.0000 (1432.3718)	mem 8479MB
[2024-07-02 14:42:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:41 lr 0.000002	 wd 0.0000	time 0.1944 (0.2520)	loss 1.0257 (1.3852)	grad_norm 12.9136 (4.4633)	loss_scale 2048.0000 (1461.6735)	mem 8479MB
[2024-07-02 14:42:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:15 lr 0.000002	 wd 0.0000	time 0.2291 (0.2504)	loss 0.9315 (1.3848)	grad_norm 4.2915 (4.4469)	loss_scale 2048.0000 (1488.3126)	mem 8479MB
[2024-07-02 14:43:09 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:50 lr 0.000002	 wd 0.0000	time 0.2153 (0.2488)	loss 1.1140 (1.3837)	grad_norm 3.3699 (4.4402)	loss_scale 2048.0000 (1512.6362)	mem 8479MB
[2024-07-02 14:43:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:25 lr 0.000002	 wd 0.0000	time 0.2121 (0.2481)	loss 1.1446 (1.3833)	grad_norm 4.5818 (4.4481)	loss_scale 2048.0000 (1534.9338)	mem 8479MB
[2024-07-02 14:43:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1636 (0.2467)	loss 1.0739 (1.3816)	grad_norm 4.5355 (4.4433)	loss_scale 2048.0000 (1555.4482)	mem 8479MB
[2024-07-02 14:44:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 26 training takes 0:10:28
[2024-07-02 14:44:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 23.001 (23.001)	Loss 0.4143 (0.4143)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 8479MB
[2024-07-02 14:44:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.904 Acc@5 97.148
[2024-07-02 14:44:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-02 14:44:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.91%
[2024-07-02 14:45:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][0/2502]	eta 22:10:59 lr 0.000002	 wd 0.0000	time 31.9185 (31.9185)	loss 0.9674 (0.9674)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 8479MB
[2024-07-02 14:45:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:21:40 lr 0.000002	 wd 0.0000	time 0.2138 (0.5413)	loss 1.4987 (1.4000)	grad_norm 3.8647 (4.5040)	loss_scale 2048.0000 (2048.0000)	mem 8479MB
[2024-07-02 14:46:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:14:25 lr 0.000002	 wd 0.0000	time 0.2077 (0.3760)	loss 1.5438 (1.3886)	grad_norm 5.7707 (4.3952)	loss_scale 2048.0000 (2048.0000)	mem 8479MB
[2024-07-02 14:46:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:11:45 lr 0.000002	 wd 0.0000	time 0.1892 (0.3203)	loss 1.3361 (1.3820)	grad_norm 7.4747 (4.3532)	loss_scale 2048.0000 (2048.0000)	mem 8479MB
[2024-07-02 14:46:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:10:39 lr 0.000002	 wd 0.0000	time 0.3633 (0.3041)	loss 1.3730 (1.3806)	grad_norm 2.5934 (4.3687)	loss_scale 2048.0000 (2048.0000)	mem 8479MB
[2024-07-02 14:47:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:10:08 lr 0.000002	 wd 0.0000	time 0.2109 (0.3042)	loss 0.8618 (1.3740)	grad_norm 4.6620 (4.4082)	loss_scale 2048.0000 (2048.0000)	mem 8479MB
[2024-07-02 14:47:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:09:09 lr 0.000002	 wd 0.0000	time 0.1998 (0.2887)	loss 1.4325 (1.3742)	grad_norm 3.6780 (4.3229)	loss_scale 2048.0000 (2048.0000)	mem 8479MB
[2024-07-02 14:48:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:08:19 lr 0.000002	 wd 0.0000	time 0.2246 (0.2770)	loss 1.4491 (1.3794)	grad_norm 4.2211 (inf)	loss_scale 1024.0000 (1942.8245)	mem 8479MB
[2024-07-02 14:48:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:42 lr 0.000002	 wd 0.0000	time 0.2195 (0.2719)	loss 1.5988 (1.3824)	grad_norm 5.9122 (inf)	loss_scale 1024.0000 (1828.1149)	mem 8479MB
[2024-07-02 14:48:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:07:10 lr 0.000001	 wd 0.0000	time 0.2095 (0.2687)	loss 1.4763 (1.3873)	grad_norm 3.1576 (inf)	loss_scale 1024.0000 (1738.8679)	mem 8479MB
[2024-07-02 14:49:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:35 lr 0.000001	 wd 0.0000	time 0.1913 (0.2631)	loss 1.4514 (1.3861)	grad_norm 3.3196 (inf)	loss_scale 1024.0000 (1667.4525)	mem 8479MB
[2024-07-02 14:49:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:06:02 lr 0.000001	 wd 0.0000	time 0.2029 (0.2585)	loss 1.4142 (1.3868)	grad_norm 3.6166 (inf)	loss_scale 1024.0000 (1609.0100)	mem 8479MB
[2024-07-02 14:49:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:33 lr 0.000001	 wd 0.0000	time 0.2489 (0.2560)	loss 1.5598 (1.3870)	grad_norm 4.1631 (inf)	loss_scale 1024.0000 (1560.2998)	mem 8479MB
[2024-07-02 14:50:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:05:07 lr 0.000001	 wd 0.0000	time 0.2320 (0.2560)	loss 1.4673 (1.3855)	grad_norm 2.8274 (inf)	loss_scale 1024.0000 (1519.0776)	mem 8479MB
[2024-07-02 14:50:41 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:39 lr 0.000001	 wd 0.0000	time 0.1949 (0.2532)	loss 1.3801 (1.3868)	grad_norm 7.3465 (inf)	loss_scale 1024.0000 (1483.7402)	mem 8479MB
[2024-07-02 14:51:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:04:11 lr 0.000001	 wd 0.0000	time 0.2031 (0.2507)	loss 1.5423 (1.3866)	grad_norm 12.2078 (inf)	loss_scale 1024.0000 (1453.1113)	mem 8479MB
[2024-07-02 14:51:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:44 lr 0.000001	 wd 0.0000	time 0.2834 (0.2487)	loss 1.5238 (1.3850)	grad_norm 3.6723 (inf)	loss_scale 1024.0000 (1426.3086)	mem 8479MB
[2024-07-02 14:51:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:19 lr 0.000001	 wd 0.0000	time 0.1847 (0.2485)	loss 1.4193 (1.3832)	grad_norm 3.9646 (inf)	loss_scale 1024.0000 (1402.6573)	mem 8479MB
[2024-07-02 14:52:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:53 lr 0.000001	 wd 0.0000	time 0.2225 (0.2472)	loss 1.4670 (1.3838)	grad_norm 7.7005 (inf)	loss_scale 1024.0000 (1381.6324)	mem 8479MB
[2024-07-02 14:52:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:27 lr 0.000001	 wd 0.0000	time 0.2129 (0.2456)	loss 0.9781 (1.3849)	grad_norm 4.8124 (inf)	loss_scale 1024.0000 (1362.8196)	mem 8479MB
[2024-07-02 14:52:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:02:02 lr 0.000001	 wd 0.0000	time 0.2120 (0.2441)	loss 0.8920 (1.3833)	grad_norm 6.5199 (inf)	loss_scale 1024.0000 (1345.8871)	mem 8479MB
[2024-07-02 14:53:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:37 lr 0.000001	 wd 0.0000	time 0.2358 (0.2434)	loss 1.8081 (1.3822)	grad_norm 3.5865 (inf)	loss_scale 1024.0000 (1330.5664)	mem 8479MB
[2024-07-02 14:53:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:13 lr 0.000001	 wd 0.0000	time 0.2074 (0.2438)	loss 1.0112 (1.3833)	grad_norm 3.6505 (inf)	loss_scale 1024.0000 (1316.6379)	mem 8479MB
[2024-07-02 14:54:04 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:48 lr 0.000001	 wd 0.0000	time 0.2449 (0.2426)	loss 1.5624 (1.3838)	grad_norm 3.9844 (inf)	loss_scale 1024.0000 (1303.9200)	mem 8479MB
[2024-07-02 14:54:26 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:24 lr 0.000001	 wd 0.0000	time 0.2208 (0.2414)	loss 1.2891 (1.3835)	grad_norm 4.5753 (inf)	loss_scale 1024.0000 (1292.2616)	mem 8479MB
[2024-07-02 14:54:45 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1820 (0.2393)	loss 1.5260 (1.3820)	grad_norm 3.0365 (inf)	loss_scale 1024.0000 (1281.5354)	mem 8479MB
[2024-07-02 14:54:53 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 27 training takes 0:10:06
[2024-07-02 14:55:28 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 35.409 (35.409)	Loss 0.4146 (0.4146)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 8479MB
[2024-07-02 14:55:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.910 Acc@5 97.166
[2024-07-02 14:55:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-02 14:55:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.91%
[2024-07-02 14:56:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][0/2502]	eta 10:55:31 lr 0.000001	 wd 0.0000	time 15.7199 (15.7199)	loss 1.3002 (1.3002)	grad_norm 0.0000 (0.0000)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:56:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:18:09 lr 0.000001	 wd 0.0000	time 0.5892 (0.4534)	loss 1.0145 (1.3633)	grad_norm 4.1051 (4.3548)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:56:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:13:44 lr 0.000001	 wd 0.0000	time 0.2108 (0.3583)	loss 1.1037 (1.3663)	grad_norm 3.0878 (4.3699)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:57:20 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:11:19 lr 0.000001	 wd 0.0000	time 0.1933 (0.3088)	loss 1.6622 (1.3814)	grad_norm 2.9311 (4.2608)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:57:40 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:09:56 lr 0.000001	 wd 0.0000	time 0.2018 (0.2836)	loss 1.5264 (1.3867)	grad_norm 2.5141 (4.3414)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:58:06 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:09:16 lr 0.000001	 wd 0.0000	time 0.3650 (0.2778)	loss 1.6038 (1.3870)	grad_norm 9.4906 (4.3940)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:58:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:46 lr 0.000001	 wd 0.0000	time 0.2088 (0.2766)	loss 1.4479 (1.3872)	grad_norm 5.0897 (4.4929)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:58:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:08:01 lr 0.000001	 wd 0.0000	time 0.2049 (0.2671)	loss 1.0648 (1.3902)	grad_norm 3.1419 (4.4682)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:59:15 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:23 lr 0.000001	 wd 0.0000	time 0.1975 (0.2604)	loss 1.6140 (1.3874)	grad_norm 2.3969 (4.4448)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 14:59:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:51 lr 0.000001	 wd 0.0000	time 0.2436 (0.2568)	loss 1.5190 (1.3876)	grad_norm 3.6311 (4.4623)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 15:00:03 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:23 lr 0.000001	 wd 0.0000	time 0.2500 (0.2555)	loss 1.4873 (1.3886)	grad_norm 3.7652 (4.4435)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 15:00:24 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:53 lr 0.000001	 wd 0.0000	time 0.2023 (0.2521)	loss 1.0736 (1.3872)	grad_norm 4.7097 (4.4325)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 15:00:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:23 lr 0.000001	 wd 0.0000	time 0.2029 (0.2488)	loss 1.1562 (1.3858)	grad_norm 3.9582 (4.4223)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 15:01:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:04:56 lr 0.000001	 wd 0.0000	time 0.2336 (0.2467)	loss 1.4639 (1.3828)	grad_norm 4.6000 (4.4220)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 15:01:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:32 lr 0.000001	 wd 0.0000	time 0.2024 (0.2475)	loss 1.0075 (1.3835)	grad_norm 6.5340 (4.4216)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 15:01:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:04:06 lr 0.000001	 wd 0.0000	time 0.2156 (0.2456)	loss 1.5203 (1.3806)	grad_norm 3.1918 (4.4306)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 15:02:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:39 lr 0.000001	 wd 0.0000	time 0.2154 (0.2437)	loss 1.2408 (1.3803)	grad_norm 4.9249 (4.4606)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 15:02:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:14 lr 0.000001	 wd 0.0000	time 0.1892 (0.2420)	loss 1.5049 (1.3817)	grad_norm 3.9794 (4.4398)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 15:03:02 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:49 lr 0.000001	 wd 0.0000	time 0.1598 (0.2415)	loss 1.4051 (1.3807)	grad_norm 3.3311 (4.4299)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 15:03:27 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:25 lr 0.000001	 wd 0.0000	time 0.2084 (0.2423)	loss 1.6625 (1.3795)	grad_norm 4.0536 (4.4407)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 15:03:49 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:02:00 lr 0.000001	 wd 0.0000	time 0.2172 (0.2410)	loss 0.9040 (1.3787)	grad_norm 2.9265 (4.4218)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 15:04:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:36 lr 0.000001	 wd 0.0000	time 0.2029 (0.2396)	loss 1.1905 (1.3789)	grad_norm 2.8897 (4.4094)	loss_scale 1024.0000 (1024.0000)	mem 8479MB
[2024-07-02 15:04:33 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:12 lr 0.000001	 wd 0.0000	time 0.2202 (0.2392)	loss 1.5127 (1.3778)	grad_norm 3.8052 (4.3945)	loss_scale 2048.0000 (1058.4280)	mem 8479MB
[2024-07-02 15:04:58 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:48 lr 0.000001	 wd 0.0000	time 0.2340 (0.2394)	loss 1.2609 (1.3782)	grad_norm 4.2168 (4.3850)	loss_scale 2048.0000 (1101.4342)	mem 8479MB
[2024-07-02 15:05:19 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:24 lr 0.000001	 wd 0.0000	time 0.2100 (0.2385)	loss 1.6411 (1.3772)	grad_norm 2.5509 (4.4052)	loss_scale 2048.0000 (1140.8580)	mem 8479MB
[2024-07-02 15:05:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1634 (0.2365)	loss 1.2341 (1.3757)	grad_norm 4.7271 (4.3934)	loss_scale 2048.0000 (1177.1291)	mem 8479MB
[2024-07-02 15:05:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 28 training takes 0:09:59
[2024-07-02 15:06:23 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 37.412 (37.412)	Loss 0.4150 (0.4150)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 8479MB
[2024-07-02 15:06:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.930 Acc@5 97.164
[2024-07-02 15:06:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-02 15:06:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.93%
[2024-07-02 15:06:43 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 160): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saving......
[2024-07-02 15:06:44 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 162): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_best.pth saved !!!
[2024-07-02 15:07:00 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][0/2502]	eta 11:07:00 lr 0.000001	 wd 0.0000	time 15.9954 (15.9954)	loss 1.4702 (1.4702)	grad_norm 0.0000 (0.0000)	loss_scale 2048.0000 (2048.0000)	mem 8479MB
[2024-07-02 15:07:21 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:14:41 lr 0.000001	 wd 0.0000	time 0.2240 (0.3671)	loss 1.5300 (1.3551)	grad_norm 2.7736 (4.0032)	loss_scale 2048.0000 (2048.0000)	mem 8479MB
[2024-07-02 15:07:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:11:49 lr 0.000001	 wd 0.0000	time 0.3870 (0.3081)	loss 1.1998 (1.3706)	grad_norm 3.7004 (4.5402)	loss_scale 2048.0000 (2048.0000)	mem 8479MB
[2024-07-02 15:08:14 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:10:56 lr 0.000001	 wd 0.0000	time 0.2080 (0.2982)	loss 1.5638 (1.3695)	grad_norm 3.6832 (4.3949)	loss_scale 2048.0000 (2048.0000)	mem 8479MB
[2024-07-02 15:08:35 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:09:40 lr 0.000001	 wd 0.0000	time 0.2332 (0.2764)	loss 1.2314 (1.3750)	grad_norm 6.6762 (4.2991)	loss_scale 2048.0000 (2048.0000)	mem 8479MB
[2024-07-02 15:08:56 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:08:45 lr 0.000001	 wd 0.0000	time 0.2256 (0.2625)	loss 0.9574 (1.3800)	grad_norm 3.1150 (inf)	loss_scale 1024.0000 (2031.6487)	mem 8479MB
[2024-07-02 15:09:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:07 lr 0.000000	 wd 0.0000	time 0.2807 (0.2565)	loss 1.4186 (1.3852)	grad_norm 3.0544 (inf)	loss_scale 1024.0000 (1863.9867)	mem 8479MB
[2024-07-02 15:09:50 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:58 lr 0.000000	 wd 0.0000	time 0.2143 (0.2656)	loss 1.6865 (1.3846)	grad_norm 5.2003 (inf)	loss_scale 1024.0000 (1744.1598)	mem 8479MB
[2024-07-02 15:10:11 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:07:20 lr 0.000000	 wd 0.0000	time 0.2068 (0.2586)	loss 0.8893 (1.3838)	grad_norm 2.5490 (inf)	loss_scale 1024.0000 (1654.2522)	mem 8479MB
[2024-07-02 15:10:32 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:06:45 lr 0.000000	 wd 0.0000	time 0.1901 (0.2533)	loss 1.3701 (1.3841)	grad_norm inf (inf)	loss_scale 512.0000 (1583.1654)	mem 8479MB
[2024-07-02 15:10:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:17 lr 0.000000	 wd 0.0000	time 0.2312 (0.2510)	loss 1.3690 (1.3825)	grad_norm 3.8369 (inf)	loss_scale 512.0000 (1476.1558)	mem 8479MB
[2024-07-02 15:11:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:58 lr 0.000000	 wd 0.0000	time 0.1946 (0.2554)	loss 1.3696 (1.3827)	grad_norm 4.5237 (inf)	loss_scale 512.0000 (1388.5849)	mem 8479MB
[2024-07-02 15:11:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:27 lr 0.000000	 wd 0.0000	time 0.2299 (0.2515)	loss 1.3996 (1.3797)	grad_norm 3.5285 (inf)	loss_scale 512.0000 (1315.5970)	mem 8479MB
[2024-07-02 15:12:08 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:04:59 lr 0.000000	 wd 0.0000	time 0.1892 (0.2489)	loss 1.5388 (1.3801)	grad_norm 4.2187 (inf)	loss_scale 512.0000 (1253.8294)	mem 8479MB
[2024-07-02 15:12:30 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:32 lr 0.000000	 wd 0.0000	time 0.2364 (0.2470)	loss 1.6243 (1.3774)	grad_norm 6.7517 (inf)	loss_scale 512.0000 (1200.8794)	mem 8479MB
[2024-07-02 15:12:55 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:04:07 lr 0.000000	 wd 0.0000	time 0.2958 (0.2469)	loss 1.3824 (1.3784)	grad_norm 7.4819 (inf)	loss_scale 512.0000 (1154.9847)	mem 8479MB
[2024-07-02 15:13:17 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:41 lr 0.000000	 wd 0.0000	time 0.1913 (0.2452)	loss 1.3668 (1.3801)	grad_norm 5.0442 (inf)	loss_scale 512.0000 (1114.8232)	mem 8479MB
[2024-07-02 15:13:38 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:15 lr 0.000000	 wd 0.0000	time 0.1986 (0.2433)	loss 1.1868 (1.3779)	grad_norm 3.1534 (inf)	loss_scale 512.0000 (1079.3839)	mem 8479MB
[2024-07-02 15:13:59 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:49 lr 0.000000	 wd 0.0000	time 0.2540 (0.2418)	loss 1.1774 (1.3798)	grad_norm 4.1252 (inf)	loss_scale 512.0000 (1047.8801)	mem 8479MB
[2024-07-02 15:14:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:25 lr 0.000000	 wd 0.0000	time 0.2139 (0.2423)	loss 1.3243 (1.3790)	grad_norm 3.8214 (inf)	loss_scale 512.0000 (1019.6907)	mem 8479MB
[2024-07-02 15:14:48 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:02:01 lr 0.000000	 wd 0.0000	time 0.2002 (0.2419)	loss 1.6048 (1.3787)	grad_norm 4.2400 (inf)	loss_scale 512.0000 (994.3188)	mem 8479MB
[2024-07-02 15:15:10 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:36 lr 0.000000	 wd 0.0000	time 0.2045 (0.2407)	loss 1.4148 (1.3794)	grad_norm 3.7601 (inf)	loss_scale 512.0000 (971.3622)	mem 8479MB
[2024-07-02 15:15:31 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:12 lr 0.000000	 wd 0.0000	time 0.1958 (0.2394)	loss 1.5119 (1.3811)	grad_norm 5.2463 (inf)	loss_scale 512.0000 (950.4916)	mem 8479MB
[2024-07-02 15:15:54 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:48 lr 0.000000	 wd 0.0000	time 0.2470 (0.2391)	loss 1.5349 (1.3822)	grad_norm 4.4300 (inf)	loss_scale 512.0000 (931.4350)	mem 8479MB
[2024-07-02 15:16:18 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.3067 (0.2392)	loss 1.5646 (1.3829)	grad_norm 6.1210 (inf)	loss_scale 512.0000 (913.9658)	mem 8479MB
[2024-07-02 15:16:37 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000000	 wd 0.0000	time 0.1612 (0.2373)	loss 1.4656 (1.3823)	grad_norm 3.5863 (inf)	loss_scale 512.0000 (897.8936)	mem 8479MB
[2024-07-02 15:16:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 249): INFO EPOCH 29 training takes 0:10:01
[2024-07-02 15:16:46 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 145): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_29.pth saving......
[2024-07-02 15:16:47 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (utils.py 147): INFO pretrain/vcnu_finetune/swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding/diffusion_ft_swin_b_22kto1k_finetune_process1_ab_embedding_ftembedding/ckpt_epoch_29.pth saved !!!
[2024-07-02 15:17:05 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 289): INFO Test: [0/98]	Time 18.332 (18.332)	Loss 0.4148 (0.4148)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 8479MB
[2024-07-02 15:17:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 296): INFO  * Acc@1 83.922 Acc@5 97.168
[2024-07-02 15:17:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.9%
[2024-07-02 15:17:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 182): INFO Max accuracy: 83.93%
[2024-07-02 15:17:25 swin_diffusion_finetune_base_patch4_window7_224_22kto1k_finetune_process1_abembedding_have_embedding] (main.py 189): INFO Training time 5:25:46
