[2024-07-12 09:20:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 366): INFO Full config saved to pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/config.json
[2024-07-12 09:20:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process0/diffusion_ft_convnext_b_22kto1k_sequence_crosslayer0/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: convnext_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    DEPTHS:
    - 3
    - 3
    - 27
    - 3
    DIMS:
    - 128
    - 256
    - 512
    - 1024
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: part1
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_convnext_b_22kto1k_step_crosslayer1
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 0.0001
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 0.8
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.0e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 1.0e-08

[2024-07-12 09:20:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/convnext/diffusion_ft_convnext_base_224_22kto1k_step_crosslayer_process1.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process0/diffusion_ft_convnext_b_22kto1k_sequence_crosslayer0/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/vcnu_finetune", "tag": "diffusion_ft_convnext_b_22kto1k_step_crosslayer1", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-12 09:20:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 108): INFO Creating model:convnext_diffusion_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1
[2024-07-12 09:20:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 110): INFO ConvNeXt_Diffusion_Finetune(
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (3): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (4): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (5): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (6): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (7): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (8): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (9): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (10): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (11): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (12): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (13): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (14): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (15): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (16): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (17): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (18): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (19): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (20): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (21): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (22): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (23): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (24): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (25): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (26): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-12 09:20:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 113): INFO number of params: 40564328
[2024-07-12 09:20:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 150): INFO no checkpoint found in pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1, ignoring auto resume
[2024-07-12 09:20:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process0/diffusion_ft_convnext_b_22kto1k_sequence_crosslayer0/ckpt_epoch_best.pth for fine-tuning......
[2024-07-12 09:20:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 127): WARNING <All keys matched successfully>
[2024-07-12 09:20:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process0/diffusion_ft_convnext_b_22kto1k_sequence_crosslayer0/ckpt_epoch_best.pth'
[2024-07-12 09:21:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 57.386 (57.386)	Loss 0.3623 (0.3623)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 3241MB
[2024-07-12 09:21:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.604 Acc@5 97.592
[2024-07-12 09:21:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 162): INFO Accuracy of the network on the 50000 test images: 85.6%
[2024-07-12 09:21:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 168): INFO Start training
[2024-07-12 09:22:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][0/2502]	eta 1 day, 3:05:54 lr 0.000100	 wd 0.0000	time 38.9906 (38.9906)	loss 0.7739 (0.7739)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 9463MB
[2024-07-12 09:22:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:25:03 lr 0.000100	 wd 0.0000	time 0.2187 (0.6260)	loss 0.8345 (0.8064)	grad_norm 2.6171 (nan)	loss_scale 16384.0000 (22386.0594)	mem 9463MB
[2024-07-12 09:22:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:16:33 lr 0.000100	 wd 0.0000	time 0.2189 (0.4315)	loss 0.8062 (0.8142)	grad_norm 2.3767 (nan)	loss_scale 8192.0000 (18829.3731)	mem 9463MB
[2024-07-12 09:23:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:13:29 lr 0.000100	 wd 0.0000	time 0.2325 (0.3676)	loss 0.7788 (0.8174)	grad_norm 2.5139 (nan)	loss_scale 8192.0000 (15295.3621)	mem 9463MB
[2024-07-12 09:23:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:12:25 lr 0.000100	 wd 0.0000	time 0.2212 (0.3545)	loss 1.1113 (0.8197)	grad_norm 2.0549 (nan)	loss_scale 8192.0000 (13523.9501)	mem 9463MB
[2024-07-12 09:24:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:11:02 lr 0.000100	 wd 0.0000	time 0.2440 (0.3307)	loss 0.6904 (0.8195)	grad_norm 2.9422 (nan)	loss_scale 8192.0000 (12459.6886)	mem 9463MB
[2024-07-12 09:24:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:58 lr 0.000100	 wd 0.0000	time 0.2167 (0.3148)	loss 0.7197 (0.8188)	grad_norm 1.9795 (nan)	loss_scale 8192.0000 (11749.5907)	mem 9463MB
[2024-07-12 09:25:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:09:09 lr 0.000100	 wd 0.0000	time 0.2963 (0.3049)	loss 0.8560 (0.8189)	grad_norm 3.5260 (nan)	loss_scale 8192.0000 (11242.0884)	mem 9463MB
[2024-07-12 09:25:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:08:38 lr 0.000100	 wd 0.0000	time 0.2314 (0.3044)	loss 0.8540 (0.8181)	grad_norm 1.9795 (nan)	loss_scale 8192.0000 (10861.3034)	mem 9463MB
[2024-07-12 09:25:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:55 lr 0.000100	 wd 0.0000	time 0.2433 (0.2968)	loss 0.7944 (0.8176)	grad_norm 3.4137 (nan)	loss_scale 8192.0000 (10565.0433)	mem 9463MB
[2024-07-12 09:26:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:07:16 lr 0.000100	 wd 0.0000	time 0.2387 (0.2908)	loss 0.8906 (0.8175)	grad_norm 2.2653 (nan)	loss_scale 8192.0000 (10327.9760)	mem 9463MB
[2024-07-12 09:26:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:41 lr 0.000100	 wd 0.0000	time 0.2209 (0.2866)	loss 0.7222 (0.8172)	grad_norm 3.5933 (nan)	loss_scale 8192.0000 (10133.9728)	mem 9463MB
[2024-07-12 09:27:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:06:10 lr 0.000100	 wd 0.0000	time 0.2178 (0.2842)	loss 0.7866 (0.8173)	grad_norm 1.6652 (nan)	loss_scale 8192.0000 (9972.2764)	mem 9463MB
[2024-07-12 09:27:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:37 lr 0.000100	 wd 0.0000	time 0.2141 (0.2808)	loss 0.7026 (0.8181)	grad_norm 1.8682 (nan)	loss_scale 8192.0000 (9835.4374)	mem 9463MB
[2024-07-12 09:27:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:05:06 lr 0.000100	 wd 0.0000	time 0.2372 (0.2778)	loss 0.8252 (0.8177)	grad_norm 2.3750 (nan)	loss_scale 8192.0000 (9718.1328)	mem 9463MB
[2024-07-12 09:28:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:36 lr 0.000100	 wd 0.0000	time 0.2171 (0.2756)	loss 0.8794 (0.8176)	grad_norm 2.0446 (nan)	loss_scale 8192.0000 (9616.4584)	mem 9463MB
[2024-07-12 09:28:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:04:08 lr 0.000100	 wd 0.0000	time 0.2222 (0.2751)	loss 0.8848 (0.8172)	grad_norm 2.2789 (nan)	loss_scale 8192.0000 (9527.4853)	mem 9463MB
[2024-07-12 09:29:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:38 lr 0.000100	 wd 0.0000	time 0.2430 (0.2731)	loss 0.7222 (0.8169)	grad_norm 2.2341 (nan)	loss_scale 8192.0000 (9448.9735)	mem 9463MB
[2024-07-12 09:29:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:03:10 lr 0.000100	 wd 0.0000	time 0.2060 (0.2713)	loss 0.7651 (0.8166)	grad_norm 2.0973 (nan)	loss_scale 8192.0000 (9379.1805)	mem 9463MB
[2024-07-12 09:30:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:42 lr 0.000100	 wd 0.0000	time 0.2157 (0.2705)	loss 0.7710 (0.8160)	grad_norm 1.4449 (nan)	loss_scale 8192.0000 (9316.7301)	mem 9463MB
[2024-07-12 09:30:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:15 lr 0.000100	 wd 0.0000	time 0.2559 (0.2696)	loss 0.8765 (0.8163)	grad_norm 1.7919 (nan)	loss_scale 8192.0000 (9260.5217)	mem 9463MB
[2024-07-12 09:30:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:47 lr 0.000100	 wd 0.0000	time 0.2399 (0.2681)	loss 0.7412 (0.8165)	grad_norm 1.9296 (nan)	loss_scale 8192.0000 (9209.6640)	mem 9463MB
[2024-07-12 09:31:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:20 lr 0.000100	 wd 0.0000	time 0.2237 (0.2668)	loss 0.8501 (0.8161)	grad_norm 1.7973 (nan)	loss_scale 8192.0000 (9163.4275)	mem 9463MB
[2024-07-12 09:31:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:53 lr 0.000100	 wd 0.0000	time 0.2388 (0.2663)	loss 0.9297 (0.8157)	grad_norm 2.2283 (nan)	loss_scale 8192.0000 (9121.2099)	mem 9463MB
[2024-07-12 09:32:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:27 lr 0.000100	 wd 0.0000	time 0.2529 (0.2657)	loss 0.7456 (0.8156)	grad_norm 1.9529 (nan)	loss_scale 8192.0000 (9082.5090)	mem 9463MB
[2024-07-12 09:32:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000100	 wd 0.0000	time 0.2185 (0.2643)	loss 0.8999 (0.8153)	grad_norm 1.9033 (nan)	loss_scale 8192.0000 (9046.9028)	mem 9463MB
[2024-07-12 09:32:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 0 training takes 0:11:05
[2024-07-12 09:32:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 145): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_0.pth saving......
[2024-07-12 09:32:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 147): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_0.pth saved !!!
[2024-07-12 09:33:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 60.623 (60.623)	Loss 0.3701 (0.3701)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 09:33:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.340 Acc@5 97.566
[2024-07-12 09:33:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-12 09:33:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.34%
[2024-07-12 09:33:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 160): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_best.pth saving......
[2024-07-12 09:33:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 162): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_best.pth saved !!!
[2024-07-12 09:34:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][0/2502]	eta 10:22:16 lr 0.000100	 wd 0.0000	time 14.9228 (14.9228)	loss 0.8125 (0.8125)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:34:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:15:35 lr 0.000100	 wd 0.0000	time 0.2513 (0.3896)	loss 0.7314 (0.8093)	grad_norm 2.7281 (1.8955)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:35:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:14:15 lr 0.000100	 wd 0.0000	time 0.2287 (0.3718)	loss 0.9097 (0.8142)	grad_norm 2.4781 (1.9091)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:35:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:58 lr 0.000100	 wd 0.0000	time 0.2127 (0.3261)	loss 0.8848 (0.8108)	grad_norm 1.6248 (1.9462)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:35:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:10:37 lr 0.000100	 wd 0.0000	time 0.2159 (0.3032)	loss 0.6938 (0.8128)	grad_norm 1.8559 (1.9397)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:36:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:09:42 lr 0.000100	 wd 0.0000	time 0.2660 (0.2910)	loss 0.8467 (0.8107)	grad_norm 1.8734 (1.9320)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:36:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:09:27 lr 0.000100	 wd 0.0000	time 0.2280 (0.2984)	loss 0.8628 (0.8118)	grad_norm 1.5698 (1.9259)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:37:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:42 lr 0.000100	 wd 0.0000	time 0.2329 (0.2897)	loss 0.7236 (0.8115)	grad_norm 1.9141 (1.9404)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:37:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:08:01 lr 0.000100	 wd 0.0000	time 0.2193 (0.2828)	loss 0.6953 (0.8115)	grad_norm 2.0692 (1.9401)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:38:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:41 lr 0.000099	 wd 0.0000	time 0.8487 (0.2883)	loss 0.8599 (0.8111)	grad_norm 1.9886 (1.9433)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:38:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:07:05 lr 0.000099	 wd 0.0000	time 0.2338 (0.2835)	loss 0.7925 (0.8100)	grad_norm 1.7799 (1.9587)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:38:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:06:31 lr 0.000099	 wd 0.0000	time 0.2257 (0.2793)	loss 0.9570 (0.8099)	grad_norm 2.2405 (1.9555)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:39:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:59 lr 0.000099	 wd 0.0000	time 0.2313 (0.2758)	loss 0.8364 (0.8096)	grad_norm 2.0546 (1.9532)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:39:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:29 lr 0.000099	 wd 0.0000	time 0.2190 (0.2742)	loss 0.8745 (0.8101)	grad_norm 2.0020 (1.9480)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:40:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:59 lr 0.000099	 wd 0.0000	time 0.2337 (0.2720)	loss 0.8022 (0.8106)	grad_norm 1.6019 (1.9394)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:40:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:30 lr 0.000099	 wd 0.0000	time 0.2276 (0.2699)	loss 0.8379 (0.8107)	grad_norm 2.1368 (1.9352)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:41:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:04:01 lr 0.000099	 wd 0.0000	time 0.2298 (0.2680)	loss 0.9092 (0.8112)	grad_norm 1.9539 (1.9355)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:41:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:34 lr 0.000099	 wd 0.0000	time 0.2205 (0.2677)	loss 0.7163 (0.8111)	grad_norm 1.6226 (1.9305)	loss_scale 16384.0000 (8269.0558)	mem 9463MB
[2024-07-12 09:41:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:03:07 lr 0.000099	 wd 0.0000	time 0.2201 (0.2667)	loss 0.9746 (0.8115)	grad_norm 1.6411 (1.9312)	loss_scale 16384.0000 (8719.6358)	mem 9463MB
[2024-07-12 09:42:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:39 lr 0.000099	 wd 0.0000	time 0.2329 (0.2652)	loss 0.8018 (0.8118)	grad_norm 1.8912 (1.9297)	loss_scale 16384.0000 (9122.8112)	mem 9463MB
[2024-07-12 09:42:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:12 lr 0.000099	 wd 0.0000	time 0.2214 (0.2640)	loss 0.6899 (0.8111)	grad_norm 2.0472 (1.9312)	loss_scale 16384.0000 (9485.6892)	mem 9463MB
[2024-07-12 09:43:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:46 lr 0.000099	 wd 0.0000	time 0.2138 (0.2644)	loss 0.7881 (0.8113)	grad_norm 2.0472 (1.9300)	loss_scale 16384.0000 (9814.0238)	mem 9463MB
[2024-07-12 09:43:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:19 lr 0.000099	 wd 0.0000	time 0.2099 (0.2634)	loss 0.6802 (0.8110)	grad_norm 1.8115 (1.9316)	loss_scale 16384.0000 (10112.5234)	mem 9463MB
[2024-07-12 09:43:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:52 lr 0.000099	 wd 0.0000	time 0.2185 (0.2624)	loss 0.9663 (0.8111)	grad_norm 2.1063 (1.9305)	loss_scale 16384.0000 (10385.0778)	mem 9463MB
[2024-07-12 09:44:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:26 lr 0.000099	 wd 0.0000	time 0.2194 (0.2615)	loss 0.8496 (0.8108)	grad_norm 1.7380 (1.9328)	loss_scale 16384.0000 (10634.9288)	mem 9463MB
[2024-07-12 09:44:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000099	 wd 0.0000	time 0.2102 (0.2603)	loss 0.9873 (0.8109)	grad_norm 1.5260 (1.9306)	loss_scale 16384.0000 (10864.7997)	mem 9463MB
[2024-07-12 09:44:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 1 training takes 0:11:01
[2024-07-12 09:45:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 30.135 (30.135)	Loss 0.3647 (0.3647)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 09:45:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.340 Acc@5 97.584
[2024-07-12 09:45:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-12 09:45:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.34%
[2024-07-12 09:45:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][0/2502]	eta 12:04:48 lr 0.000099	 wd 0.0000	time 17.3817 (17.3817)	loss 0.7671 (0.7671)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:46:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:17:16 lr 0.000099	 wd 0.0000	time 0.2337 (0.4314)	loss 0.8086 (0.8052)	grad_norm 1.8400 (1.9007)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:46:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:12:48 lr 0.000099	 wd 0.0000	time 0.2187 (0.3340)	loss 0.8164 (0.7983)	grad_norm 1.5828 (1.9013)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:47:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:11:02 lr 0.000099	 wd 0.0000	time 0.2209 (0.3007)	loss 0.8647 (0.7985)	grad_norm 1.7917 (1.9091)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:47:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:09:57 lr 0.000099	 wd 0.0000	time 0.2305 (0.2844)	loss 0.7236 (0.7997)	grad_norm 1.9551 (1.8875)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:47:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:09:14 lr 0.000099	 wd 0.0000	time 0.2055 (0.2771)	loss 0.9980 (0.7980)	grad_norm 1.6407 (1.8617)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:48:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:34 lr 0.000099	 wd 0.0000	time 0.2078 (0.2704)	loss 0.8491 (0.7990)	grad_norm 1.6953 (1.8710)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:48:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:07:58 lr 0.000099	 wd 0.0000	time 0.2156 (0.2657)	loss 0.9761 (0.7991)	grad_norm 1.8660 (1.8958)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:49:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:26 lr 0.000099	 wd 0.0000	time 0.2365 (0.2621)	loss 0.6948 (0.7979)	grad_norm 1.6601 (1.8830)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:49:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:59 lr 0.000098	 wd 0.0000	time 0.2247 (0.2621)	loss 0.7749 (0.7989)	grad_norm 1.8802 (1.8895)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:49:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:30 lr 0.000098	 wd 0.0000	time 0.2232 (0.2600)	loss 0.7769 (0.7993)	grad_norm 1.9045 (1.8918)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:50:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:06:01 lr 0.000098	 wd 0.0000	time 0.2057 (0.2580)	loss 0.7568 (0.7991)	grad_norm 1.6985 (1.8880)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:50:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:33 lr 0.000098	 wd 0.0000	time 0.2262 (0.2563)	loss 0.9639 (0.7986)	grad_norm 1.8937 (1.8825)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:51:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:05:08 lr 0.000098	 wd 0.0000	time 0.2255 (0.2570)	loss 0.8628 (0.7993)	grad_norm 1.9222 (1.8835)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:51:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:42 lr 0.000098	 wd 0.0000	time 0.2335 (0.2559)	loss 0.8110 (0.7999)	grad_norm 1.7513 (1.8886)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:51:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:15 lr 0.000098	 wd 0.0000	time 0.2189 (0.2548)	loss 0.7471 (0.7999)	grad_norm 1.6408 (1.8879)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:52:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:48 lr 0.000098	 wd 0.0000	time 0.2386 (0.2537)	loss 0.7969 (0.8000)	grad_norm 2.0623 (1.8832)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:52:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:23 lr 0.000098	 wd 0.0000	time 0.2238 (0.2543)	loss 0.8911 (0.8003)	grad_norm 2.1958 (1.8807)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:53:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:58 lr 0.000098	 wd 0.0000	time 0.2395 (0.2538)	loss 0.6895 (0.7999)	grad_norm 1.8307 (1.8824)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:53:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:32 lr 0.000098	 wd 0.0000	time 0.2222 (0.2531)	loss 0.7222 (0.8005)	grad_norm 2.0939 (1.8845)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 09:53:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:02:06 lr 0.000098	 wd 0.0000	time 0.2062 (0.2524)	loss 0.8101 (0.8001)	grad_norm 1.3565 (inf)	loss_scale 8192.0000 (16031.9200)	mem 9463MB
[2024-07-12 09:54:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:41 lr 0.000098	 wd 0.0000	time 0.5647 (0.2533)	loss 0.8906 (0.8004)	grad_norm 1.6287 (inf)	loss_scale 8192.0000 (15658.7682)	mem 9463MB
[2024-07-12 09:54:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:16 lr 0.000098	 wd 0.0000	time 0.2193 (0.2532)	loss 0.7544 (0.8003)	grad_norm 1.7409 (inf)	loss_scale 8192.0000 (15319.5239)	mem 9463MB
[2024-07-12 09:55:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:51 lr 0.000098	 wd 0.0000	time 0.2159 (0.2526)	loss 0.8862 (0.8002)	grad_norm 2.1086 (inf)	loss_scale 8192.0000 (15009.7662)	mem 9463MB
[2024-07-12 09:55:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:25 lr 0.000098	 wd 0.0000	time 0.2183 (0.2521)	loss 1.0391 (0.8004)	grad_norm 2.1352 (inf)	loss_scale 8192.0000 (14725.8109)	mem 9463MB
[2024-07-12 09:56:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000098	 wd 0.0000	time 0.2165 (0.2513)	loss 0.7700 (0.8009)	grad_norm 1.6784 (inf)	loss_scale 8192.0000 (14464.5630)	mem 9463MB
[2024-07-12 09:56:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 2 training takes 0:10:38
[2024-07-12 09:56:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 26.822 (26.822)	Loss 0.3574 (0.3574)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 09:56:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.420 Acc@5 97.564
[2024-07-12 09:56:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-12 09:56:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.42%
[2024-07-12 09:56:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 160): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_best.pth saving......
[2024-07-12 09:56:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 162): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_best.pth saved !!!
[2024-07-12 09:57:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][0/2502]	eta 10:19:25 lr 0.000098	 wd 0.0000	time 14.8541 (14.8541)	loss 0.7090 (0.7090)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:57:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:15:33 lr 0.000098	 wd 0.0000	time 0.2152 (0.3888)	loss 0.7544 (0.7922)	grad_norm 2.0590 (1.8918)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:57:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:12:12 lr 0.000097	 wd 0.0000	time 0.2296 (0.3182)	loss 0.8003 (0.7938)	grad_norm 1.5421 (1.8490)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:58:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:10:40 lr 0.000097	 wd 0.0000	time 0.2242 (0.2911)	loss 0.9097 (0.7966)	grad_norm 1.7488 (1.8375)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:58:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:09:42 lr 0.000097	 wd 0.0000	time 0.2308 (0.2769)	loss 0.8066 (0.7966)	grad_norm 1.4691 (1.8781)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:59:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:09:02 lr 0.000097	 wd 0.0000	time 0.2630 (0.2708)	loss 0.7827 (0.7965)	grad_norm 2.1036 (1.8720)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:59:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:08:26 lr 0.000097	 wd 0.0000	time 0.2468 (0.2662)	loss 0.7305 (0.7957)	grad_norm 2.4056 (1.8639)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 09:59:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:07:52 lr 0.000097	 wd 0.0000	time 0.2072 (0.2621)	loss 0.9189 (0.7962)	grad_norm 2.1747 (1.8558)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:00:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:20 lr 0.000097	 wd 0.0000	time 0.2270 (0.2586)	loss 0.8735 (0.7971)	grad_norm 2.0245 (1.8604)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:00:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:06:53 lr 0.000097	 wd 0.0000	time 0.2388 (0.2582)	loss 0.8774 (0.7972)	grad_norm 2.0220 (1.8589)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:01:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:27 lr 0.000097	 wd 0.0000	time 0.2205 (0.2580)	loss 0.8838 (0.7980)	grad_norm 1.7917 (1.8544)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:01:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:05:59 lr 0.000097	 wd 0.0000	time 0.2244 (0.2564)	loss 0.7549 (0.7994)	grad_norm 2.3336 (1.8509)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:01:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:31 lr 0.000097	 wd 0.0000	time 0.2297 (0.2548)	loss 0.8735 (0.7997)	grad_norm 1.4979 (1.8490)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:02:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:05:05 lr 0.000097	 wd 0.0000	time 0.2458 (0.2539)	loss 0.9238 (0.7998)	grad_norm 1.8009 (1.8455)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:02:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:40 lr 0.000097	 wd 0.0000	time 0.2124 (0.2542)	loss 0.7417 (0.8002)	grad_norm 2.2412 (1.8526)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:03:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:13 lr 0.000097	 wd 0.0000	time 0.2153 (0.2533)	loss 0.7051 (0.8007)	grad_norm 1.6700 (1.8525)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:03:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:47 lr 0.000096	 wd 0.0000	time 0.2335 (0.2524)	loss 0.7642 (0.8006)	grad_norm 1.7617 (1.8516)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:04:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:21 lr 0.000096	 wd 0.0000	time 0.2325 (0.2519)	loss 0.7900 (0.8005)	grad_norm 1.8110 (1.8562)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:04:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:57 lr 0.000096	 wd 0.0000	time 0.2251 (0.2529)	loss 0.8779 (0.8001)	grad_norm 2.1112 (1.8639)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:04:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:31 lr 0.000096	 wd 0.0000	time 0.2258 (0.2523)	loss 0.8047 (0.8000)	grad_norm 1.9013 (1.8638)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:05:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:06 lr 0.000096	 wd 0.0000	time 0.2148 (0.2516)	loss 0.8057 (0.8000)	grad_norm 1.8085 (1.8577)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:05:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:41 lr 0.000096	 wd 0.0000	time 0.2235 (0.2522)	loss 0.7422 (0.7999)	grad_norm 1.7353 (1.8561)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:06:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:16 lr 0.000096	 wd 0.0000	time 0.2355 (0.2520)	loss 0.8350 (0.7997)	grad_norm 2.3022 (1.8517)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:06:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:50 lr 0.000096	 wd 0.0000	time 0.2162 (0.2515)	loss 0.8237 (0.7997)	grad_norm 2.1092 (1.8543)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:06:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:25 lr 0.000096	 wd 0.0000	time 0.2059 (0.2510)	loss 0.7651 (0.7994)	grad_norm 1.9730 (1.8572)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:07:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000096	 wd 0.0000	time 0.2164 (0.2503)	loss 0.8931 (0.7994)	grad_norm 1.8802 (1.8602)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:07:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 3 training takes 0:10:35
[2024-07-12 10:07:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 28.072 (28.072)	Loss 0.3713 (0.3713)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 10:08:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.384 Acc@5 97.530
[2024-07-12 10:08:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-12 10:08:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.42%
[2024-07-12 10:08:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][0/2502]	eta 10:53:44 lr 0.000096	 wd 0.0000	time 15.6772 (15.6772)	loss 0.7993 (0.7993)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:08:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:16:21 lr 0.000096	 wd 0.0000	time 0.3124 (0.4086)	loss 0.7056 (0.7905)	grad_norm 1.7574 (1.8698)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:09:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:13:01 lr 0.000096	 wd 0.0000	time 0.2148 (0.3396)	loss 0.8965 (0.7958)	grad_norm 1.5632 (1.8250)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:09:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:11:12 lr 0.000095	 wd 0.0000	time 0.2353 (0.3055)	loss 0.7915 (0.7960)	grad_norm 2.2174 (1.8145)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:10:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:10:04 lr 0.000095	 wd 0.0000	time 0.2071 (0.2877)	loss 0.8745 (0.7937)	grad_norm 1.4866 (1.7962)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:10:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:09:17 lr 0.000095	 wd 0.0000	time 0.2375 (0.2785)	loss 0.8887 (0.7942)	grad_norm 2.2677 (1.8085)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:10:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:08:36 lr 0.000095	 wd 0.0000	time 0.2276 (0.2716)	loss 0.7812 (0.7955)	grad_norm 1.8445 (1.8078)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:11:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:08:01 lr 0.000095	 wd 0.0000	time 0.2312 (0.2669)	loss 0.9160 (0.7940)	grad_norm 1.9234 (1.8345)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:11:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:27 lr 0.000095	 wd 0.0000	time 0.2188 (0.2630)	loss 0.7036 (0.7932)	grad_norm 1.7937 (1.8275)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:12:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:06:57 lr 0.000095	 wd 0.0000	time 0.2396 (0.2609)	loss 0.7983 (0.7937)	grad_norm 1.8177 (1.8241)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:12:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:29 lr 0.000095	 wd 0.0000	time 0.2279 (0.2593)	loss 0.7876 (0.7937)	grad_norm 2.1098 (1.8222)	loss_scale 16384.0000 (8928.5435)	mem 9463MB
[2024-07-12 10:12:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:06:00 lr 0.000095	 wd 0.0000	time 0.2259 (0.2574)	loss 0.8296 (0.7942)	grad_norm 1.5479 (1.8235)	loss_scale 16384.0000 (9605.6966)	mem 9463MB
[2024-07-12 10:13:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:32 lr 0.000095	 wd 0.0000	time 0.2199 (0.2557)	loss 0.7378 (0.7944)	grad_norm 1.4795 (1.8244)	loss_scale 16384.0000 (10170.0849)	mem 9463MB
[2024-07-12 10:13:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:05:06 lr 0.000095	 wd 0.0000	time 0.2423 (0.2548)	loss 0.6870 (0.7937)	grad_norm 2.3919 (1.8342)	loss_scale 16384.0000 (10647.7110)	mem 9463MB
[2024-07-12 10:14:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:40 lr 0.000094	 wd 0.0000	time 0.2188 (0.2548)	loss 0.7642 (0.7932)	grad_norm 2.1311 (1.8397)	loss_scale 16384.0000 (11057.1535)	mem 9463MB
[2024-07-12 10:14:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:14 lr 0.000094	 wd 0.0000	time 0.2684 (0.2538)	loss 0.7251 (0.7933)	grad_norm 1.4923 (1.8384)	loss_scale 16384.0000 (11412.0400)	mem 9463MB
[2024-07-12 10:14:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:48 lr 0.000094	 wd 0.0000	time 0.2287 (0.2528)	loss 0.8232 (0.7936)	grad_norm 1.7846 (1.8344)	loss_scale 16384.0000 (11722.5934)	mem 9463MB
[2024-07-12 10:15:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:22 lr 0.000094	 wd 0.0000	time 0.2435 (0.2523)	loss 0.8530 (0.7942)	grad_norm 1.6637 (1.8348)	loss_scale 16384.0000 (11996.6326)	mem 9463MB
[2024-07-12 10:15:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:57 lr 0.000094	 wd 0.0000	time 0.2166 (0.2528)	loss 0.8120 (0.7948)	grad_norm 3.0801 (inf)	loss_scale 8192.0000 (12121.9767)	mem 9463MB
[2024-07-12 10:16:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:31 lr 0.000094	 wd 0.0000	time 0.2069 (0.2522)	loss 0.7314 (0.7944)	grad_norm 1.5739 (inf)	loss_scale 8192.0000 (11915.2446)	mem 9463MB
[2024-07-12 10:16:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:02:06 lr 0.000094	 wd 0.0000	time 0.2279 (0.2515)	loss 0.7002 (0.7940)	grad_norm 1.8181 (inf)	loss_scale 8192.0000 (11729.1754)	mem 9463MB
[2024-07-12 10:16:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:40 lr 0.000094	 wd 0.0000	time 0.2214 (0.2511)	loss 0.7642 (0.7942)	grad_norm 2.3121 (inf)	loss_scale 8192.0000 (11560.8187)	mem 9463MB
[2024-07-12 10:17:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:16 lr 0.000094	 wd 0.0000	time 0.2123 (0.2517)	loss 0.8174 (0.7940)	grad_norm 1.7547 (inf)	loss_scale 8192.0000 (11407.7601)	mem 9463MB
[2024-07-12 10:17:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:50 lr 0.000094	 wd 0.0000	time 0.2049 (0.2512)	loss 0.7329 (0.7945)	grad_norm 2.5626 (inf)	loss_scale 8192.0000 (11268.0052)	mem 9463MB
[2024-07-12 10:18:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:25 lr 0.000093	 wd 0.0000	time 0.2202 (0.2507)	loss 0.7114 (0.7946)	grad_norm 1.4094 (inf)	loss_scale 8192.0000 (11139.8917)	mem 9463MB
[2024-07-12 10:18:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000093	 wd 0.0000	time 0.2150 (0.2500)	loss 0.7036 (0.7945)	grad_norm 2.1355 (inf)	loss_scale 8192.0000 (11022.0232)	mem 9463MB
[2024-07-12 10:18:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 4 training takes 0:10:32
[2024-07-12 10:19:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 28.697 (28.697)	Loss 0.3679 (0.3679)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 10:19:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.466 Acc@5 97.496
[2024-07-12 10:19:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-12 10:19:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.47%
[2024-07-12 10:19:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 160): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_best.pth saving......
[2024-07-12 10:19:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 162): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_best.pth saved !!!
[2024-07-12 10:19:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][0/2502]	eta 9:34:45 lr 0.000093	 wd 0.0000	time 13.7833 (13.7833)	loss 0.9214 (0.9214)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:20:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:15:14 lr 0.000093	 wd 0.0000	time 0.2786 (0.3808)	loss 0.7358 (0.7897)	grad_norm 1.5465 (1.7537)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:20:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:12:42 lr 0.000093	 wd 0.0000	time 0.2099 (0.3312)	loss 0.7490 (0.7941)	grad_norm 1.9020 (1.7931)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:20:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:58 lr 0.000093	 wd 0.0000	time 0.2106 (0.2989)	loss 0.7793 (0.7910)	grad_norm 1.6733 (1.8318)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:21:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:53 lr 0.000093	 wd 0.0000	time 0.2136 (0.2826)	loss 0.7031 (0.7897)	grad_norm 1.7039 (1.8457)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:21:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:09:08 lr 0.000093	 wd 0.0000	time 0.2245 (0.2740)	loss 0.8223 (0.7897)	grad_norm 1.9222 (1.8496)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:22:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:31 lr 0.000093	 wd 0.0000	time 0.2202 (0.2690)	loss 1.0127 (0.7918)	grad_norm 2.0383 (1.8490)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:22:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:56 lr 0.000093	 wd 0.0000	time 0.2119 (0.2646)	loss 0.8325 (0.7915)	grad_norm 1.7859 (1.8496)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:22:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:24 lr 0.000093	 wd 0.0000	time 0.2238 (0.2612)	loss 0.8516 (0.7923)	grad_norm 2.8070 (1.8398)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:23:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:54 lr 0.000092	 wd 0.0000	time 0.2176 (0.2590)	loss 0.7710 (0.7924)	grad_norm 2.1664 (1.8489)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:23:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:27 lr 0.000092	 wd 0.0000	time 0.2297 (0.2582)	loss 0.7153 (0.7923)	grad_norm 2.0340 (1.8557)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:24:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:59 lr 0.000092	 wd 0.0000	time 0.2339 (0.2566)	loss 0.7075 (0.7926)	grad_norm 1.5543 (1.8547)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:24:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:32 lr 0.000092	 wd 0.0000	time 0.2188 (0.2550)	loss 0.8960 (0.7927)	grad_norm 1.5721 (1.8598)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:24:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:05:05 lr 0.000092	 wd 0.0000	time 0.2171 (0.2540)	loss 0.7642 (0.7923)	grad_norm 1.8439 (1.8613)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:25:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:40 lr 0.000092	 wd 0.0000	time 0.2301 (0.2547)	loss 0.8540 (0.7919)	grad_norm 2.0591 (1.8601)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:25:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:04:14 lr 0.000092	 wd 0.0000	time 0.2255 (0.2537)	loss 0.8501 (0.7918)	grad_norm 1.5717 (1.8484)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:26:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:48 lr 0.000092	 wd 0.0000	time 0.2332 (0.2529)	loss 0.7173 (0.7912)	grad_norm 1.6536 (1.8405)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:26:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:22 lr 0.000092	 wd 0.0000	time 0.2219 (0.2521)	loss 0.7852 (0.7911)	grad_norm 1.4972 (1.8366)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:26:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:57 lr 0.000091	 wd 0.0000	time 0.2339 (0.2530)	loss 0.7739 (0.7910)	grad_norm 1.5264 (1.8362)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:27:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:31 lr 0.000091	 wd 0.0000	time 0.2290 (0.2524)	loss 0.9390 (0.7914)	grad_norm 1.6091 (1.8332)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:27:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:02:06 lr 0.000091	 wd 0.0000	time 0.2204 (0.2521)	loss 0.9253 (0.7914)	grad_norm 1.9323 (1.8404)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:28:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:41 lr 0.000091	 wd 0.0000	time 0.2438 (0.2517)	loss 0.8022 (0.7906)	grad_norm 2.0914 (1.8395)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:28:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:16 lr 0.000091	 wd 0.0000	time 0.2280 (0.2524)	loss 0.8247 (0.7906)	grad_norm 1.3459 (1.8357)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:29:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:50 lr 0.000091	 wd 0.0000	time 0.2160 (0.2519)	loss 0.6738 (0.7903)	grad_norm 1.8478 (1.8403)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:29:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:25 lr 0.000091	 wd 0.0000	time 0.2427 (0.2514)	loss 0.8237 (0.7903)	grad_norm 1.8731 (1.8394)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:29:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000091	 wd 0.0000	time 0.2125 (0.2507)	loss 0.7896 (0.7905)	grad_norm 2.2794 (1.8410)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:29:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 5 training takes 0:10:31
[2024-07-12 10:30:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 33.673 (33.673)	Loss 0.3618 (0.3618)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 10:30:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.298 Acc@5 97.540
[2024-07-12 10:30:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-12 10:30:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.47%
[2024-07-12 10:30:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][0/2502]	eta 11:42:24 lr 0.000091	 wd 0.0000	time 16.8444 (16.8444)	loss 0.8232 (0.8232)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:31:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:16:11 lr 0.000090	 wd 0.0000	time 0.2764 (0.4043)	loss 0.7324 (0.7875)	grad_norm 2.1921 (1.8850)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:31:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:12:35 lr 0.000090	 wd 0.0000	time 0.2322 (0.3281)	loss 0.7046 (0.7868)	grad_norm 1.5642 (1.8269)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:32:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:10:53 lr 0.000090	 wd 0.0000	time 0.2286 (0.2968)	loss 0.8193 (0.7887)	grad_norm 1.6178 (1.8146)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:32:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:09:51 lr 0.000090	 wd 0.0000	time 0.2368 (0.2813)	loss 0.7769 (0.7877)	grad_norm 1.5242 (1.8253)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:32:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:09:05 lr 0.000090	 wd 0.0000	time 0.2504 (0.2726)	loss 0.8599 (0.7862)	grad_norm 1.6897 (1.8232)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:33:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:08:29 lr 0.000090	 wd 0.0000	time 0.2187 (0.2677)	loss 0.8262 (0.7861)	grad_norm 2.3076 (1.8300)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:33:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:07:55 lr 0.000090	 wd 0.0000	time 0.2322 (0.2638)	loss 0.8218 (0.7882)	grad_norm 1.5536 (1.8152)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:34:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:23 lr 0.000090	 wd 0.0000	time 0.2074 (0.2605)	loss 0.7329 (0.7898)	grad_norm 1.8644 (1.8075)	loss_scale 16384.0000 (8498.8165)	mem 9463MB
[2024-07-12 10:34:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:06:53 lr 0.000089	 wd 0.0000	time 0.2443 (0.2584)	loss 0.7900 (0.7898)	grad_norm 1.8191 (1.8171)	loss_scale 16384.0000 (9373.9756)	mem 9463MB
[2024-07-12 10:35:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:36 lr 0.000089	 wd 0.0000	time 0.2157 (0.2640)	loss 0.7808 (0.7902)	grad_norm 1.7922 (1.8152)	loss_scale 16384.0000 (10074.2777)	mem 9463MB
[2024-07-12 10:35:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:06:06 lr 0.000089	 wd 0.0000	time 0.2267 (0.2614)	loss 0.7129 (0.7895)	grad_norm 1.6468 (1.8124)	loss_scale 16384.0000 (10647.3678)	mem 9463MB
[2024-07-12 10:35:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:37 lr 0.000089	 wd 0.0000	time 0.2072 (0.2593)	loss 0.6377 (0.7899)	grad_norm 1.4138 (1.8259)	loss_scale 16384.0000 (11125.0225)	mem 9463MB
[2024-07-12 10:36:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:05:10 lr 0.000089	 wd 0.0000	time 0.2373 (0.2579)	loss 0.7412 (0.7908)	grad_norm 1.4646 (1.8199)	loss_scale 16384.0000 (11529.2483)	mem 9463MB
[2024-07-12 10:36:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:47 lr 0.000089	 wd 0.0000	time 0.2176 (0.2609)	loss 0.9941 (0.7893)	grad_norm 2.1939 (1.8127)	loss_scale 16384.0000 (11875.7687)	mem 9463MB
[2024-07-12 10:37:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:19 lr 0.000089	 wd 0.0000	time 0.2239 (0.2593)	loss 0.6567 (0.7891)	grad_norm 1.8612 (1.8113)	loss_scale 16384.0000 (12176.1173)	mem 9463MB
[2024-07-12 10:37:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:52 lr 0.000089	 wd 0.0000	time 0.2309 (0.2581)	loss 0.8545 (0.7889)	grad_norm 1.3631 (1.8133)	loss_scale 16384.0000 (12438.9457)	mem 9463MB
[2024-07-12 10:37:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:26 lr 0.000088	 wd 0.0000	time 0.2450 (0.2572)	loss 0.9165 (0.7878)	grad_norm 1.5596 (1.8160)	loss_scale 16384.0000 (12670.8713)	mem 9463MB
[2024-07-12 10:38:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:03:00 lr 0.000088	 wd 0.0000	time 0.2168 (0.2573)	loss 0.7002 (0.7870)	grad_norm 1.6128 (1.8182)	loss_scale 16384.0000 (12877.0416)	mem 9463MB
[2024-07-12 10:38:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:34 lr 0.000088	 wd 0.0000	time 0.2355 (0.2565)	loss 0.8682 (0.7869)	grad_norm 2.0926 (1.8170)	loss_scale 16384.0000 (13061.5213)	mem 9463MB
[2024-07-12 10:39:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:02:08 lr 0.000088	 wd 0.0000	time 0.2196 (0.2557)	loss 0.9663 (0.7879)	grad_norm 2.0637 (inf)	loss_scale 8192.0000 (13022.8646)	mem 9463MB
[2024-07-12 10:39:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:42 lr 0.000088	 wd 0.0000	time 0.2265 (0.2550)	loss 0.8232 (0.7880)	grad_norm 1.8057 (inf)	loss_scale 8192.0000 (12792.9329)	mem 9463MB
[2024-07-12 10:40:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:17 lr 0.000088	 wd 0.0000	time 0.2471 (0.2553)	loss 0.8315 (0.7883)	grad_norm 2.8470 (inf)	loss_scale 8192.0000 (12583.8946)	mem 9463MB
[2024-07-12 10:40:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:51 lr 0.000088	 wd 0.0000	time 0.2066 (0.2546)	loss 0.8188 (0.7882)	grad_norm 1.4503 (inf)	loss_scale 8192.0000 (12393.0256)	mem 9463MB
[2024-07-12 10:40:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:25 lr 0.000087	 wd 0.0000	time 0.2098 (0.2539)	loss 0.8110 (0.7878)	grad_norm 1.7593 (inf)	loss_scale 8192.0000 (12218.0558)	mem 9463MB
[2024-07-12 10:41:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000087	 wd 0.0000	time 0.2049 (0.2531)	loss 0.7378 (0.7875)	grad_norm 1.4620 (inf)	loss_scale 8192.0000 (12057.0780)	mem 9463MB
[2024-07-12 10:41:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 6 training takes 0:10:38
[2024-07-12 10:41:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 28.707 (28.707)	Loss 0.3623 (0.3623)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 10:41:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.338 Acc@5 97.464
[2024-07-12 10:41:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-12 10:41:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.47%
[2024-07-12 10:42:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][0/2502]	eta 11:19:38 lr 0.000087	 wd 0.0000	time 16.2983 (16.2983)	loss 0.8428 (0.8428)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:42:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:15:59 lr 0.000087	 wd 0.0000	time 0.2249 (0.3995)	loss 0.9492 (0.7936)	grad_norm 2.1351 (1.8379)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:43:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:12:20 lr 0.000087	 wd 0.0000	time 0.2099 (0.3216)	loss 0.7881 (0.7837)	grad_norm 2.6692 (1.8520)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:43:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:10:44 lr 0.000087	 wd 0.0000	time 0.2146 (0.2926)	loss 0.7837 (0.7827)	grad_norm 2.7866 (1.8615)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:43:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:09:44 lr 0.000087	 wd 0.0000	time 0.2194 (0.2781)	loss 0.8511 (0.7819)	grad_norm 1.7300 (1.8440)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:44:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:09:01 lr 0.000087	 wd 0.0000	time 0.2661 (0.2703)	loss 0.7119 (0.7821)	grad_norm 1.7131 (1.8245)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:44:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:50 lr 0.000086	 wd 0.0000	time 0.2480 (0.2790)	loss 0.7734 (0.7830)	grad_norm 1.5540 (1.8281)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:45:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:08:11 lr 0.000086	 wd 0.0000	time 0.2341 (0.2730)	loss 0.7129 (0.7817)	grad_norm 1.5841 (1.8349)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:45:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:07:36 lr 0.000086	 wd 0.0000	time 0.2320 (0.2683)	loss 0.7485 (0.7820)	grad_norm 1.7852 (1.8331)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:45:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:07:06 lr 0.000086	 wd 0.0000	time 0.3002 (0.2664)	loss 0.6387 (0.7825)	grad_norm 1.8393 (1.8231)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:46:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:47 lr 0.000086	 wd 0.0000	time 0.2190 (0.2710)	loss 0.7490 (0.7830)	grad_norm 2.1554 (1.8131)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:46:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:06:15 lr 0.000086	 wd 0.0000	time 0.2159 (0.2679)	loss 0.7681 (0.7825)	grad_norm 1.6380 (1.8101)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:47:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:45 lr 0.000086	 wd 0.0000	time 0.2055 (0.2652)	loss 0.6826 (0.7831)	grad_norm 2.0005 (1.8145)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:47:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:05:16 lr 0.000085	 wd 0.0000	time 0.2160 (0.2637)	loss 0.8022 (0.7829)	grad_norm 1.6489 (1.8117)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:48:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:49 lr 0.000085	 wd 0.0000	time 0.2220 (0.2626)	loss 0.8018 (0.7836)	grad_norm 2.1851 (1.8116)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:48:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:21 lr 0.000085	 wd 0.0000	time 0.2258 (0.2611)	loss 0.7246 (0.7832)	grad_norm 1.6368 (1.8136)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:48:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:54 lr 0.000085	 wd 0.0000	time 0.2045 (0.2597)	loss 0.8354 (0.7838)	grad_norm 1.9505 (1.8080)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:49:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:27 lr 0.000085	 wd 0.0000	time 0.2237 (0.2587)	loss 0.7285 (0.7837)	grad_norm 1.6993 (1.8029)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:49:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:03:01 lr 0.000085	 wd 0.0000	time 0.2155 (0.2590)	loss 0.7290 (0.7829)	grad_norm 2.3212 (1.8053)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:50:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:35 lr 0.000085	 wd 0.0000	time 0.2058 (0.2580)	loss 0.8999 (0.7838)	grad_norm 1.8385 (1.8002)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:50:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:02:09 lr 0.000084	 wd 0.0000	time 0.2337 (0.2572)	loss 0.7051 (0.7835)	grad_norm 2.0290 (1.8056)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:50:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:43 lr 0.000084	 wd 0.0000	time 1.8806 (0.2574)	loss 0.7891 (0.7837)	grad_norm 1.7766 (1.8064)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:51:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:17 lr 0.000084	 wd 0.0000	time 0.2306 (0.2571)	loss 0.7563 (0.7833)	grad_norm 1.8987 (1.8120)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:51:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:51 lr 0.000084	 wd 0.0000	time 0.2173 (0.2564)	loss 0.7983 (0.7832)	grad_norm 2.0649 (1.8107)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:52:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:26 lr 0.000084	 wd 0.0000	time 0.2210 (0.2557)	loss 0.7319 (0.7838)	grad_norm 1.8922 (1.8114)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:52:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000084	 wd 0.0000	time 0.2111 (0.2548)	loss 0.7202 (0.7843)	grad_norm 1.7015 (1.8183)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:52:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 7 training takes 0:10:45
[2024-07-12 10:53:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 27.856 (27.856)	Loss 0.3540 (0.3540)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 10:53:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.318 Acc@5 97.530
[2024-07-12 10:53:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-12 10:53:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.47%
[2024-07-12 10:53:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][0/2502]	eta 10:31:07 lr 0.000084	 wd 0.0000	time 15.1350 (15.1350)	loss 0.8735 (0.8735)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:54:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:16:26 lr 0.000083	 wd 0.0000	time 0.2897 (0.4108)	loss 0.7856 (0.7897)	grad_norm 1.8785 (1.8952)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:54:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:13:17 lr 0.000083	 wd 0.0000	time 0.2104 (0.3466)	loss 0.7358 (0.7833)	grad_norm 2.0022 (1.8534)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:54:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:11:22 lr 0.000083	 wd 0.0000	time 0.2247 (0.3098)	loss 0.8506 (0.7791)	grad_norm 1.6168 (1.8159)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:55:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:10:12 lr 0.000083	 wd 0.0000	time 0.2210 (0.2913)	loss 0.8481 (0.7799)	grad_norm 1.6028 (1.8096)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:55:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:09:37 lr 0.000083	 wd 0.0000	time 0.3977 (0.2885)	loss 0.8115 (0.7814)	grad_norm 1.6421 (1.8237)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:56:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:09:08 lr 0.000083	 wd 0.0000	time 0.2148 (0.2885)	loss 0.6890 (0.7812)	grad_norm 1.7818 (1.8270)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:56:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:08:26 lr 0.000083	 wd 0.0000	time 0.2184 (0.2809)	loss 0.9087 (0.7794)	grad_norm 1.9983 (1.8199)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:57:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:48 lr 0.000082	 wd 0.0000	time 0.2265 (0.2752)	loss 0.8716 (0.7803)	grad_norm 1.5752 (1.8194)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:57:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:07:18 lr 0.000082	 wd 0.0000	time 0.2270 (0.2734)	loss 0.8496 (0.7797)	grad_norm 1.6115 (1.8246)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 10:57:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:45 lr 0.000082	 wd 0.0000	time 0.2198 (0.2702)	loss 0.8022 (0.7808)	grad_norm 1.6241 (inf)	loss_scale 8192.0000 (8241.1029)	mem 9463MB
[2024-07-12 10:58:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:06:14 lr 0.000082	 wd 0.0000	time 0.2483 (0.2672)	loss 0.7832 (0.7810)	grad_norm 1.5955 (inf)	loss_scale 8192.0000 (8236.6431)	mem 9463MB
[2024-07-12 10:58:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:44 lr 0.000082	 wd 0.0000	time 0.2383 (0.2647)	loss 0.8398 (0.7814)	grad_norm 1.5304 (inf)	loss_scale 8192.0000 (8232.9259)	mem 9463MB
[2024-07-12 10:59:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:05:17 lr 0.000082	 wd 0.0000	time 0.2195 (0.2637)	loss 0.7427 (0.7820)	grad_norm 1.6464 (inf)	loss_scale 8192.0000 (8229.7802)	mem 9463MB
[2024-07-12 10:59:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:49 lr 0.000081	 wd 0.0000	time 0.2294 (0.2624)	loss 0.7588 (0.7825)	grad_norm 1.6906 (inf)	loss_scale 8192.0000 (8227.0835)	mem 9463MB
[2024-07-12 10:59:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:04:21 lr 0.000081	 wd 0.0000	time 0.2266 (0.2609)	loss 0.6890 (0.7827)	grad_norm 1.9195 (inf)	loss_scale 8192.0000 (8224.7462)	mem 9463MB
[2024-07-12 11:00:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:54 lr 0.000081	 wd 0.0000	time 0.2246 (0.2595)	loss 0.7764 (0.7828)	grad_norm 1.5112 (inf)	loss_scale 8192.0000 (8222.7008)	mem 9463MB
[2024-07-12 11:00:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:27 lr 0.000081	 wd 0.0000	time 0.2058 (0.2592)	loss 0.7134 (0.7832)	grad_norm 1.9436 (inf)	loss_scale 8192.0000 (8220.8959)	mem 9463MB
[2024-07-12 11:01:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:03:01 lr 0.000081	 wd 0.0000	time 0.2055 (0.2588)	loss 0.7373 (0.7839)	grad_norm 1.4493 (inf)	loss_scale 8192.0000 (8219.2915)	mem 9463MB
[2024-07-12 11:01:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:35 lr 0.000081	 wd 0.0000	time 0.2279 (0.2578)	loss 0.7056 (0.7832)	grad_norm 1.6674 (inf)	loss_scale 8192.0000 (8217.8559)	mem 9463MB
[2024-07-12 11:01:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:02:09 lr 0.000080	 wd 0.0000	time 0.2308 (0.2570)	loss 0.7866 (0.7830)	grad_norm 1.6797 (inf)	loss_scale 8192.0000 (8216.5637)	mem 9463MB
[2024-07-12 11:02:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:43 lr 0.000080	 wd 0.0000	time 0.2241 (0.2572)	loss 0.8599 (0.7831)	grad_norm 1.5745 (inf)	loss_scale 8192.0000 (8215.3946)	mem 9463MB
[2024-07-12 11:02:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:17 lr 0.000080	 wd 0.0000	time 0.2289 (0.2567)	loss 0.8135 (0.7831)	grad_norm 2.1342 (inf)	loss_scale 8192.0000 (8214.3317)	mem 9463MB
[2024-07-12 11:03:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:51 lr 0.000080	 wd 0.0000	time 0.2364 (0.2560)	loss 0.8271 (0.7829)	grad_norm 1.5666 (inf)	loss_scale 8192.0000 (8213.3611)	mem 9463MB
[2024-07-12 11:03:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:26 lr 0.000080	 wd 0.0000	time 0.2283 (0.2553)	loss 0.8306 (0.7828)	grad_norm 1.6408 (inf)	loss_scale 8192.0000 (8212.4715)	mem 9463MB
[2024-07-12 11:04:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000080	 wd 0.0000	time 0.2183 (0.2545)	loss 0.8604 (0.7829)	grad_norm 2.3072 (inf)	loss_scale 8192.0000 (8211.6529)	mem 9463MB
[2024-07-12 11:04:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 8 training takes 0:10:45
[2024-07-12 11:04:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 23.695 (23.695)	Loss 0.3728 (0.3728)	Acc@1 91.406 (91.406)	Acc@5 98.438 (98.438)	Mem 9463MB
[2024-07-12 11:04:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.352 Acc@5 97.482
[2024-07-12 11:04:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-12 11:04:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.47%
[2024-07-12 11:05:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][0/2502]	eta 11:01:38 lr 0.000080	 wd 0.0000	time 15.8666 (15.8666)	loss 0.6738 (0.6738)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:05:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:15:59 lr 0.000079	 wd 0.0000	time 0.2436 (0.3994)	loss 0.7935 (0.7741)	grad_norm 1.5686 (1.7894)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:05:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:12:24 lr 0.000079	 wd 0.0000	time 0.2124 (0.3236)	loss 0.6870 (0.7727)	grad_norm 3.5889 (1.8199)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:06:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:48 lr 0.000079	 wd 0.0000	time 0.2286 (0.2943)	loss 0.8447 (0.7791)	grad_norm 1.8306 (1.8277)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:06:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:46 lr 0.000079	 wd 0.0000	time 0.2088 (0.2791)	loss 0.7144 (0.7782)	grad_norm 1.4977 (1.8137)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:07:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:09:06 lr 0.000079	 wd 0.0000	time 0.3033 (0.2729)	loss 0.6895 (0.7768)	grad_norm 2.5968 (1.7999)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:07:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:54 lr 0.000079	 wd 0.0000	time 0.2144 (0.2812)	loss 0.7573 (0.7753)	grad_norm 1.6209 (1.8090)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:07:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:08:15 lr 0.000078	 wd 0.0000	time 0.2173 (0.2748)	loss 0.8154 (0.7765)	grad_norm 1.8168 (1.8089)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:08:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:39 lr 0.000078	 wd 0.0000	time 0.2282 (0.2699)	loss 0.9126 (0.7768)	grad_norm 1.4381 (1.8192)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:08:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:07:07 lr 0.000078	 wd 0.0000	time 0.2666 (0.2669)	loss 0.8931 (0.7779)	grad_norm 1.6863 (1.8089)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:09:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:38 lr 0.000078	 wd 0.0000	time 0.2233 (0.2652)	loss 0.7764 (0.7778)	grad_norm 2.0422 (1.8185)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:09:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:06:08 lr 0.000078	 wd 0.0000	time 0.2310 (0.2628)	loss 0.8237 (0.7775)	grad_norm 1.7372 (1.8181)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:09:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:39 lr 0.000078	 wd 0.0000	time 0.2353 (0.2607)	loss 0.7935 (0.7788)	grad_norm 1.7498 (1.8130)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:10:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:05:11 lr 0.000077	 wd 0.0000	time 0.3214 (0.2595)	loss 0.8057 (0.7791)	grad_norm 1.9301 (1.8044)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:10:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:46 lr 0.000077	 wd 0.0000	time 0.2411 (0.2597)	loss 0.8574 (0.7794)	grad_norm 1.5350 (1.7985)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:11:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:04:18 lr 0.000077	 wd 0.0000	time 0.2255 (0.2583)	loss 0.7246 (0.7803)	grad_norm 1.8985 (1.7932)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:11:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:51 lr 0.000077	 wd 0.0000	time 0.2314 (0.2571)	loss 0.7559 (0.7792)	grad_norm 1.8594 (1.7964)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:12:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:25 lr 0.000077	 wd 0.0000	time 0.2174 (0.2564)	loss 0.7427 (0.7793)	grad_norm 2.2932 (1.8013)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:12:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:59 lr 0.000077	 wd 0.0000	time 0.2258 (0.2564)	loss 0.7607 (0.7796)	grad_norm 1.7724 (1.8045)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:12:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:33 lr 0.000076	 wd 0.0000	time 0.2344 (0.2555)	loss 0.7485 (0.7800)	grad_norm 1.6403 (1.8060)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:13:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:02:07 lr 0.000076	 wd 0.0000	time 0.2203 (0.2548)	loss 0.7427 (0.7806)	grad_norm 1.5909 (1.8117)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:13:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:42 lr 0.000076	 wd 0.0000	time 0.2338 (0.2553)	loss 0.7793 (0.7805)	grad_norm 1.7411 (1.8152)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:14:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:16 lr 0.000076	 wd 0.0000	time 0.2330 (0.2550)	loss 0.6191 (0.7802)	grad_norm 1.8175 (1.8158)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:14:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:51 lr 0.000076	 wd 0.0000	time 0.2236 (0.2543)	loss 0.7656 (0.7800)	grad_norm 1.7028 (1.8151)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:14:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:25 lr 0.000075	 wd 0.0000	time 0.2379 (0.2537)	loss 0.8604 (0.7802)	grad_norm 1.7288 (1.8169)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:15:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000075	 wd 0.0000	time 0.2143 (0.2529)	loss 0.8315 (0.7806)	grad_norm 2.2007 (1.8142)	loss_scale 16384.0000 (8355.7745)	mem 9463MB
[2024-07-12 11:15:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 9 training takes 0:10:42
[2024-07-12 11:15:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 24.155 (24.155)	Loss 0.3745 (0.3745)	Acc@1 91.211 (91.211)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 11:16:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.284 Acc@5 97.478
[2024-07-12 11:16:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-12 11:16:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.47%
[2024-07-12 11:16:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][0/2502]	eta 11:31:15 lr 0.000075	 wd 0.0000	time 16.5768 (16.5768)	loss 0.8325 (0.8325)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:16:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:16:14 lr 0.000075	 wd 0.0000	time 0.2332 (0.4057)	loss 0.8818 (0.7877)	grad_norm 1.8741 (1.8992)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:17:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:12:57 lr 0.000075	 wd 0.0000	time 0.2273 (0.3378)	loss 0.7646 (0.7836)	grad_norm 1.9374 (1.9354)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:17:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:11:08 lr 0.000075	 wd 0.0000	time 0.2315 (0.3038)	loss 0.7407 (0.7824)	grad_norm 1.4680 (1.8884)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:17:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:10:02 lr 0.000075	 wd 0.0000	time 0.2397 (0.2865)	loss 0.7515 (0.7828)	grad_norm 1.6751 (1.8688)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:18:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:09:15 lr 0.000074	 wd 0.0000	time 0.2111 (0.2774)	loss 0.7266 (0.7840)	grad_norm 1.5011 (1.8826)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:18:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:35 lr 0.000074	 wd 0.0000	time 0.2057 (0.2708)	loss 0.7153 (0.7835)	grad_norm 1.9684 (1.8864)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:19:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:59 lr 0.000074	 wd 0.0000	time 0.2138 (0.2658)	loss 0.7129 (0.7812)	grad_norm 1.7753 (1.8790)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:19:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:07:26 lr 0.000074	 wd 0.0000	time 0.2200 (0.2623)	loss 0.7329 (0.7822)	grad_norm 1.7466 (1.8641)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:19:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:57 lr 0.000074	 wd 0.0000	time 0.2609 (0.2604)	loss 0.6875 (0.7813)	grad_norm 1.8546 (1.8693)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:20:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:30 lr 0.000073	 wd 0.0000	time 0.2660 (0.2603)	loss 0.9336 (0.7812)	grad_norm 1.7928 (1.8665)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:20:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:06:02 lr 0.000073	 wd 0.0000	time 0.2121 (0.2583)	loss 0.8213 (0.7805)	grad_norm 2.2741 (1.8701)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:21:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:34 lr 0.000073	 wd 0.0000	time 0.2275 (0.2565)	loss 0.8740 (0.7802)	grad_norm 1.4062 (1.8665)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:21:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:05:07 lr 0.000073	 wd 0.0000	time 0.2252 (0.2555)	loss 0.7339 (0.7801)	grad_norm 2.0787 (1.8690)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:22:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:41 lr 0.000073	 wd 0.0000	time 0.2106 (0.2557)	loss 0.7891 (0.7802)	grad_norm 2.0888 (1.8659)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:22:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:04:15 lr 0.000073	 wd 0.0000	time 0.2287 (0.2547)	loss 0.7710 (0.7802)	grad_norm 2.4262 (1.8628)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:22:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:48 lr 0.000072	 wd 0.0000	time 0.2270 (0.2537)	loss 0.6396 (0.7797)	grad_norm 1.8041 (1.8621)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:23:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:22 lr 0.000072	 wd 0.0000	time 0.2385 (0.2531)	loss 0.7319 (0.7795)	grad_norm 2.5839 (1.8618)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:23:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:58 lr 0.000072	 wd 0.0000	time 0.2104 (0.2538)	loss 0.8789 (0.7795)	grad_norm 2.3725 (1.8681)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 11:24:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:32 lr 0.000072	 wd 0.0000	time 0.2417 (0.2531)	loss 0.8633 (0.7809)	grad_norm 1.5666 (inf)	loss_scale 8192.0000 (16056.4924)	mem 9463MB
[2024-07-12 11:24:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:02:06 lr 0.000072	 wd 0.0000	time 0.2246 (0.2525)	loss 0.9614 (0.7812)	grad_norm 1.5784 (inf)	loss_scale 8192.0000 (15663.4643)	mem 9463MB
[2024-07-12 11:24:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:41 lr 0.000071	 wd 0.0000	time 0.2200 (0.2520)	loss 0.7393 (0.7815)	grad_norm 1.7859 (inf)	loss_scale 8192.0000 (15307.8496)	mem 9463MB
[2024-07-12 11:25:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:16 lr 0.000071	 wd 0.0000	time 0.2250 (0.2523)	loss 0.8037 (0.7819)	grad_norm 1.5900 (inf)	loss_scale 8192.0000 (14984.5488)	mem 9463MB
[2024-07-12 11:25:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:50 lr 0.000071	 wd 0.0000	time 0.2213 (0.2518)	loss 0.8311 (0.7820)	grad_norm 1.6142 (inf)	loss_scale 8192.0000 (14689.3490)	mem 9463MB
[2024-07-12 11:26:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:25 lr 0.000071	 wd 0.0000	time 0.2136 (0.2513)	loss 0.8618 (0.7821)	grad_norm 1.8896 (inf)	loss_scale 8192.0000 (14418.7389)	mem 9463MB
[2024-07-12 11:26:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000071	 wd 0.0000	time 0.2092 (0.2506)	loss 0.6978 (0.7817)	grad_norm 1.8093 (inf)	loss_scale 8192.0000 (14169.7689)	mem 9463MB
[2024-07-12 11:26:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 10 training takes 0:10:32
[2024-07-12 11:27:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 30.547 (30.547)	Loss 0.3774 (0.3774)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 11:27:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.370 Acc@5 97.484
[2024-07-12 11:27:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-12 11:27:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.47%
[2024-07-12 11:27:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][0/2502]	eta 11:05:29 lr 0.000071	 wd 0.0000	time 15.9589 (15.9589)	loss 0.7310 (0.7310)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:27:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:16:05 lr 0.000070	 wd 0.0000	time 0.2601 (0.4018)	loss 0.7334 (0.7785)	grad_norm 1.9368 (1.8352)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:28:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:13:41 lr 0.000070	 wd 0.0000	time 0.2174 (0.3567)	loss 0.7759 (0.7776)	grad_norm 1.7049 (1.8704)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:28:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:11:35 lr 0.000070	 wd 0.0000	time 0.2050 (0.3161)	loss 0.7671 (0.7760)	grad_norm 2.0944 (1.8476)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:29:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:10:21 lr 0.000070	 wd 0.0000	time 0.2077 (0.2959)	loss 0.7119 (0.7734)	grad_norm 2.2281 (1.8545)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:29:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:09:30 lr 0.000070	 wd 0.0000	time 0.2372 (0.2850)	loss 0.7676 (0.7720)	grad_norm 2.0607 (1.8473)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:30:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:48 lr 0.000069	 wd 0.0000	time 0.2382 (0.2779)	loss 0.7769 (0.7724)	grad_norm 2.1480 (1.8361)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:30:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:08:10 lr 0.000069	 wd 0.0000	time 0.2310 (0.2724)	loss 0.7729 (0.7728)	grad_norm 2.5063 (1.8283)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:30:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:07:36 lr 0.000069	 wd 0.0000	time 0.2115 (0.2680)	loss 0.8535 (0.7738)	grad_norm 1.7253 (1.8345)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:31:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:07:04 lr 0.000069	 wd 0.0000	time 0.2455 (0.2651)	loss 0.7549 (0.7761)	grad_norm 2.0677 (1.8264)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:31:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:36 lr 0.000069	 wd 0.0000	time 0.2116 (0.2643)	loss 0.7651 (0.7768)	grad_norm 1.7345 (1.8249)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:32:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:06:07 lr 0.000069	 wd 0.0000	time 0.2207 (0.2620)	loss 0.7915 (0.7763)	grad_norm 1.7385 (1.8228)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:32:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:38 lr 0.000068	 wd 0.0000	time 0.2239 (0.2599)	loss 0.8379 (0.7764)	grad_norm 2.5349 (1.8321)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:32:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:05:10 lr 0.000068	 wd 0.0000	time 0.2417 (0.2586)	loss 0.7134 (0.7770)	grad_norm 1.6433 (1.8381)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:33:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:45 lr 0.000068	 wd 0.0000	time 0.2446 (0.2588)	loss 0.7881 (0.7769)	grad_norm 1.5388 (1.8269)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:33:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:04:18 lr 0.000068	 wd 0.0000	time 0.2244 (0.2576)	loss 0.7925 (0.7765)	grad_norm 1.8121 (1.8252)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:34:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:51 lr 0.000068	 wd 0.0000	time 0.2288 (0.2564)	loss 0.7114 (0.7767)	grad_norm 1.9893 (1.8295)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:34:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:24 lr 0.000067	 wd 0.0000	time 0.2290 (0.2555)	loss 0.7729 (0.7764)	grad_norm 1.8486 (1.8304)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:34:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:59 lr 0.000067	 wd 0.0000	time 0.2372 (0.2560)	loss 0.7456 (0.7772)	grad_norm 2.1532 (1.8300)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:35:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:33 lr 0.000067	 wd 0.0000	time 0.2470 (0.2554)	loss 0.7207 (0.7778)	grad_norm 1.5979 (1.8310)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:35:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:02:07 lr 0.000067	 wd 0.0000	time 0.2228 (0.2546)	loss 0.6240 (0.7778)	grad_norm 1.8679 (1.8399)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:36:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:42 lr 0.000067	 wd 0.0000	time 0.2304 (0.2540)	loss 0.8379 (0.7774)	grad_norm 1.5864 (1.8350)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:36:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:16 lr 0.000066	 wd 0.0000	time 0.2180 (0.2546)	loss 0.8716 (0.7778)	grad_norm 3.1128 (1.8400)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:37:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:51 lr 0.000066	 wd 0.0000	time 0.2281 (0.2540)	loss 0.7778 (0.7779)	grad_norm 2.6962 (1.8383)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:37:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:25 lr 0.000066	 wd 0.0000	time 0.2188 (0.2534)	loss 0.7808 (0.7776)	grad_norm 2.0619 (1.8396)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:37:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000066	 wd 0.0000	time 0.3819 (0.2526)	loss 0.7529 (0.7775)	grad_norm 1.7666 (1.8388)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:37:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 11 training takes 0:10:37
[2024-07-12 11:39:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 68.577 (68.577)	Loss 0.3667 (0.3667)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 11:39:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.328 Acc@5 97.444
[2024-07-12 11:39:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-12 11:39:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.47%
[2024-07-12 11:39:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][0/2502]	eta 1 day, 2:55:31 lr 0.000066	 wd 0.0000	time 38.7416 (38.7416)	loss 0.7109 (0.7109)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:40:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:25:07 lr 0.000066	 wd 0.0000	time 0.2077 (0.6278)	loss 0.7397 (0.7764)	grad_norm 2.0922 (1.7936)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:40:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:16:33 lr 0.000065	 wd 0.0000	time 0.2335 (0.4318)	loss 0.7603 (0.7746)	grad_norm 1.3978 (1.8007)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:41:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:14:02 lr 0.000065	 wd 0.0000	time 0.2315 (0.3827)	loss 0.7168 (0.7808)	grad_norm 2.3589 (1.8202)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:41:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:12:07 lr 0.000065	 wd 0.0000	time 0.2250 (0.3461)	loss 0.7397 (0.7794)	grad_norm 1.5088 (1.8396)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:41:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:10:48 lr 0.000065	 wd 0.0000	time 0.2282 (0.3239)	loss 0.8267 (0.7811)	grad_norm 1.7424 (1.8314)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:42:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:09:48 lr 0.000065	 wd 0.0000	time 0.2216 (0.3092)	loss 0.8281 (0.7785)	grad_norm 1.8541 (1.8229)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:42:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:09:14 lr 0.000064	 wd 0.0000	time 0.2163 (0.3077)	loss 0.7344 (0.7798)	grad_norm 1.6191 (1.8304)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:43:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:08:28 lr 0.000064	 wd 0.0000	time 0.2247 (0.2990)	loss 0.9927 (0.7791)	grad_norm 1.4657 (1.8196)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 11:43:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:07:47 lr 0.000064	 wd 0.0000	time 0.2309 (0.2919)	loss 0.8975 (0.7791)	grad_norm 1.6205 (inf)	loss_scale 8192.0000 (8573.8690)	mem 9463MB
[2024-07-12 11:44:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:07:10 lr 0.000064	 wd 0.0000	time 0.2272 (0.2865)	loss 0.6982 (0.7791)	grad_norm 1.8625 (inf)	loss_scale 8192.0000 (8535.7203)	mem 9463MB
[2024-07-12 11:44:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:06:37 lr 0.000064	 wd 0.0000	time 0.2470 (0.2837)	loss 0.7368 (0.7802)	grad_norm 1.5639 (inf)	loss_scale 8192.0000 (8504.5014)	mem 9463MB
[2024-07-12 11:44:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:06:04 lr 0.000063	 wd 0.0000	time 0.2401 (0.2801)	loss 0.8359 (0.7803)	grad_norm 1.9947 (inf)	loss_scale 8192.0000 (8478.4813)	mem 9463MB
[2024-07-12 11:45:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:05:32 lr 0.000063	 wd 0.0000	time 0.2197 (0.2769)	loss 0.7803 (0.7806)	grad_norm 2.0692 (inf)	loss_scale 8192.0000 (8456.4612)	mem 9463MB
[2024-07-12 11:45:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:05:02 lr 0.000063	 wd 0.0000	time 0.2191 (0.2742)	loss 0.9253 (0.7813)	grad_norm 3.3237 (inf)	loss_scale 8192.0000 (8437.5846)	mem 9463MB
[2024-07-12 11:46:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:04:33 lr 0.000063	 wd 0.0000	time 0.2053 (0.2732)	loss 0.8071 (0.7817)	grad_norm 1.4616 (inf)	loss_scale 8192.0000 (8421.2232)	mem 9463MB
[2024-07-12 11:46:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:04:04 lr 0.000063	 wd 0.0000	time 0.2235 (0.2715)	loss 0.7988 (0.7808)	grad_norm 1.9701 (inf)	loss_scale 8192.0000 (8406.9057)	mem 9463MB
[2024-07-12 11:46:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:36 lr 0.000062	 wd 0.0000	time 0.2270 (0.2696)	loss 0.8706 (0.7808)	grad_norm 1.9576 (inf)	loss_scale 8192.0000 (8394.2716)	mem 9463MB
[2024-07-12 11:47:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:03:08 lr 0.000062	 wd 0.0000	time 0.2397 (0.2679)	loss 0.6387 (0.7808)	grad_norm 1.8242 (inf)	loss_scale 8192.0000 (8383.0405)	mem 9463MB
[2024-07-12 11:47:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:41 lr 0.000062	 wd 0.0000	time 0.2630 (0.2675)	loss 0.7617 (0.7811)	grad_norm 1.8128 (inf)	loss_scale 8192.0000 (8372.9911)	mem 9463MB
[2024-07-12 11:48:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:02:13 lr 0.000062	 wd 0.0000	time 0.2192 (0.2666)	loss 0.7153 (0.7811)	grad_norm 1.4909 (inf)	loss_scale 8192.0000 (8363.9460)	mem 9463MB
[2024-07-12 11:48:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:46 lr 0.000062	 wd 0.0000	time 0.2101 (0.2653)	loss 0.8379 (0.7814)	grad_norm 1.7692 (inf)	loss_scale 8192.0000 (8355.7620)	mem 9463MB
[2024-07-12 11:48:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:19 lr 0.000061	 wd 0.0000	time 0.2229 (0.2642)	loss 0.8979 (0.7813)	grad_norm 2.6138 (inf)	loss_scale 8192.0000 (8348.3217)	mem 9463MB
[2024-07-12 11:49:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:53 lr 0.000061	 wd 0.0000	time 0.2172 (0.2639)	loss 0.7129 (0.7813)	grad_norm 2.3495 (inf)	loss_scale 8192.0000 (8341.5280)	mem 9463MB
[2024-07-12 11:49:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:26 lr 0.000061	 wd 0.0000	time 0.2207 (0.2631)	loss 0.7407 (0.7810)	grad_norm 2.2308 (inf)	loss_scale 8192.0000 (8335.3003)	mem 9463MB
[2024-07-12 11:50:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000061	 wd 0.0000	time 0.2109 (0.2619)	loss 0.7461 (0.7811)	grad_norm 1.6729 (inf)	loss_scale 4096.0000 (8270.6118)	mem 9463MB
[2024-07-12 11:50:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 12 training takes 0:10:59
[2024-07-12 11:50:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 34.725 (34.725)	Loss 0.3767 (0.3767)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 11:51:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.374 Acc@5 97.500
[2024-07-12 11:51:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-12 11:51:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.47%
[2024-07-12 11:51:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][0/2502]	eta 10:43:20 lr 0.000061	 wd 0.0000	time 15.4277 (15.4277)	loss 0.6401 (0.6401)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:51:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:15:49 lr 0.000061	 wd 0.0000	time 0.2193 (0.3951)	loss 0.7075 (0.7788)	grad_norm 2.5223 (1.8023)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:52:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:12:09 lr 0.000060	 wd 0.0000	time 0.2477 (0.3169)	loss 0.6611 (0.7737)	grad_norm 2.0015 (1.8231)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:52:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:11:41 lr 0.000060	 wd 0.0000	time 0.2240 (0.3184)	loss 0.7686 (0.7709)	grad_norm 1.9526 (1.8257)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:53:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:10:25 lr 0.000060	 wd 0.0000	time 0.2216 (0.2976)	loss 0.8257 (0.7740)	grad_norm 1.8471 (1.8093)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:53:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:09:30 lr 0.000060	 wd 0.0000	time 0.2205 (0.2850)	loss 0.8086 (0.7731)	grad_norm 1.8818 (1.8508)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:53:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:47 lr 0.000060	 wd 0.0000	time 0.2381 (0.2774)	loss 0.7920 (0.7721)	grad_norm 2.0636 (1.8587)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:54:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:08:12 lr 0.000059	 wd 0.0000	time 0.2448 (0.2733)	loss 0.7305 (0.7729)	grad_norm 1.9104 (1.8662)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:54:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:37 lr 0.000059	 wd 0.0000	time 0.2367 (0.2689)	loss 0.7593 (0.7731)	grad_norm 1.3411 (1.8621)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:55:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:07:05 lr 0.000059	 wd 0.0000	time 0.2131 (0.2653)	loss 0.7417 (0.7748)	grad_norm 1.9421 (1.8615)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:55:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:34 lr 0.000059	 wd 0.0000	time 0.2356 (0.2629)	loss 0.7554 (0.7768)	grad_norm 1.6876 (1.8536)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:55:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:06:11 lr 0.000059	 wd 0.0000	time 0.2161 (0.2646)	loss 0.7812 (0.7766)	grad_norm 2.1989 (1.8469)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:56:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:41 lr 0.000058	 wd 0.0000	time 0.2147 (0.2623)	loss 0.8433 (0.7765)	grad_norm 1.4316 (1.8499)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:56:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:05:13 lr 0.000058	 wd 0.0000	time 0.2203 (0.2604)	loss 0.8267 (0.7768)	grad_norm 1.9419 (1.8559)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:57:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:45 lr 0.000058	 wd 0.0000	time 0.2115 (0.2592)	loss 0.8286 (0.7759)	grad_norm 1.8106 (1.8565)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:57:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:04:19 lr 0.000058	 wd 0.0000	time 0.2120 (0.2589)	loss 0.7129 (0.7769)	grad_norm 1.7748 (1.8548)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:58:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:52 lr 0.000058	 wd 0.0000	time 0.2261 (0.2577)	loss 0.6357 (0.7771)	grad_norm 1.3739 (1.8545)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:58:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:25 lr 0.000057	 wd 0.0000	time 0.2237 (0.2565)	loss 0.7656 (0.7779)	grad_norm 1.7850 (1.8523)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:58:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:59 lr 0.000057	 wd 0.0000	time 0.2168 (0.2557)	loss 0.7544 (0.7785)	grad_norm 1.5888 (1.8548)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:59:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:34 lr 0.000057	 wd 0.0000	time 0.2109 (0.2564)	loss 0.6821 (0.7782)	grad_norm 1.7108 (1.8544)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 11:59:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:02:08 lr 0.000057	 wd 0.0000	time 0.2362 (0.2558)	loss 0.7993 (0.7779)	grad_norm 2.0123 (1.8597)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:00:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:42 lr 0.000057	 wd 0.0000	time 0.2136 (0.2549)	loss 0.7778 (0.7780)	grad_norm 1.9715 (1.8558)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:00:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:16 lr 0.000056	 wd 0.0000	time 0.2220 (0.2544)	loss 0.7217 (0.7777)	grad_norm 2.0890 (1.8514)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:00:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:51 lr 0.000056	 wd 0.0000	time 0.2196 (0.2548)	loss 0.8257 (0.7779)	grad_norm 1.8025 (1.8615)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:01:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:25 lr 0.000056	 wd 0.0000	time 0.2336 (0.2543)	loss 0.7505 (0.7780)	grad_norm 1.5806 (1.8603)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:01:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000056	 wd 0.0000	time 0.2134 (0.2534)	loss 0.7344 (0.7779)	grad_norm 1.7879 (1.8616)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:01:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 13 training takes 0:10:37
[2024-07-12 12:02:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 33.461 (33.461)	Loss 0.3784 (0.3784)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 12:02:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.408 Acc@5 97.510
[2024-07-12 12:02:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-12 12:02:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.47%
[2024-07-12 12:02:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][0/2502]	eta 10:57:13 lr 0.000056	 wd 0.0000	time 15.7607 (15.7607)	loss 0.7339 (0.7339)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:03:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:15:39 lr 0.000055	 wd 0.0000	time 0.2045 (0.3912)	loss 0.7485 (0.7768)	grad_norm 1.4568 (1.8736)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:03:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:12:06 lr 0.000055	 wd 0.0000	time 0.2644 (0.3157)	loss 0.7529 (0.7739)	grad_norm 1.8716 (1.8428)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:04:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:10:47 lr 0.000055	 wd 0.0000	time 0.2173 (0.2942)	loss 0.8594 (0.7756)	grad_norm 1.7514 (1.8407)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:04:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:09:47 lr 0.000055	 wd 0.0000	time 0.2257 (0.2797)	loss 0.8857 (0.7765)	grad_norm 1.7030 (1.8257)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:04:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:09:02 lr 0.000055	 wd 0.0000	time 0.2073 (0.2708)	loss 0.7910 (0.7748)	grad_norm 2.0020 (1.8349)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:05:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:08:24 lr 0.000054	 wd 0.0000	time 0.2244 (0.2653)	loss 0.7578 (0.7768)	grad_norm 1.6362 (1.8513)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:05:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:57 lr 0.000054	 wd 0.0000	time 0.2155 (0.2650)	loss 0.6914 (0.7781)	grad_norm 1.5152 (1.8444)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:06:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:24 lr 0.000054	 wd 0.0000	time 0.2221 (0.2615)	loss 0.7749 (0.7768)	grad_norm 2.0306 (1.8367)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:06:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:54 lr 0.000054	 wd 0.0000	time 0.2294 (0.2587)	loss 0.8052 (0.7766)	grad_norm 1.5846 (1.8354)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:06:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:06:25 lr 0.000054	 wd 0.0000	time 0.2492 (0.2568)	loss 0.8716 (0.7763)	grad_norm 1.9854 (1.8335)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:07:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:06:00 lr 0.000053	 wd 0.0000	time 0.2302 (0.2571)	loss 0.7129 (0.7767)	grad_norm 2.1246 (1.8336)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:07:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:32 lr 0.000053	 wd 0.0000	time 0.2492 (0.2557)	loss 0.8184 (0.7769)	grad_norm 1.9438 (1.8370)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:08:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:05:05 lr 0.000053	 wd 0.0000	time 0.2324 (0.2543)	loss 0.7964 (0.7766)	grad_norm 1.4531 (1.8364)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:08:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:39 lr 0.000053	 wd 0.0000	time 0.2256 (0.2533)	loss 0.8062 (0.7757)	grad_norm 1.7490 (1.8379)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:08:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:04:14 lr 0.000053	 wd 0.0000	time 0.2095 (0.2536)	loss 0.8228 (0.7756)	grad_norm 2.2612 (1.8429)	loss_scale 8192.0000 (4205.1539)	mem 9463MB
[2024-07-12 12:09:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:48 lr 0.000052	 wd 0.0000	time 0.2319 (0.2529)	loss 0.8389 (0.7763)	grad_norm 1.8160 (1.8434)	loss_scale 8192.0000 (4454.1761)	mem 9463MB
[2024-07-12 12:09:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:22 lr 0.000052	 wd 0.0000	time 0.2202 (0.2520)	loss 0.8442 (0.7763)	grad_norm 1.7242 (1.8459)	loss_scale 8192.0000 (4673.9189)	mem 9463MB
[2024-07-12 12:10:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:56 lr 0.000052	 wd 0.0000	time 0.2417 (0.2514)	loss 0.8853 (0.7763)	grad_norm 1.9115 (1.8451)	loss_scale 8192.0000 (4869.2593)	mem 9463MB
[2024-07-12 12:10:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:31 lr 0.000052	 wd 0.0000	time 0.2386 (0.2523)	loss 0.7275 (0.7764)	grad_norm 1.9486 (1.8446)	loss_scale 8192.0000 (5044.0484)	mem 9463MB
[2024-07-12 12:10:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:02:06 lr 0.000052	 wd 0.0000	time 0.2218 (0.2519)	loss 0.7861 (0.7765)	grad_norm 2.3854 (1.8436)	loss_scale 8192.0000 (5201.3673)	mem 9463MB
[2024-07-12 12:11:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:41 lr 0.000051	 wd 0.0000	time 0.2207 (0.2513)	loss 0.7402 (0.7770)	grad_norm 1.6239 (1.8494)	loss_scale 8192.0000 (5343.7106)	mem 9463MB
[2024-07-12 12:11:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:15 lr 0.000051	 wd 0.0000	time 0.2280 (0.2508)	loss 0.7188 (0.7774)	grad_norm 1.5794 (1.8501)	loss_scale 8192.0000 (5473.1195)	mem 9463MB
[2024-07-12 12:12:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:50 lr 0.000051	 wd 0.0000	time 0.2803 (0.2515)	loss 0.8701 (0.7777)	grad_norm 2.0665 (1.8487)	loss_scale 8192.0000 (5591.2803)	mem 9463MB
[2024-07-12 12:12:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:25 lr 0.000051	 wd 0.0000	time 0.2419 (0.2511)	loss 0.7427 (0.7778)	grad_norm 1.7742 (1.8481)	loss_scale 8192.0000 (5699.5985)	mem 9463MB
[2024-07-12 12:12:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000051	 wd 0.0000	time 0.2147 (0.2503)	loss 0.7822 (0.7781)	grad_norm 1.8195 (1.8498)	loss_scale 8192.0000 (5799.2547)	mem 9463MB
[2024-07-12 12:13:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 14 training takes 0:10:30
[2024-07-12 12:13:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 36.405 (36.405)	Loss 0.3687 (0.3687)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 12:13:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.452 Acc@5 97.484
[2024-07-12 12:13:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-12 12:13:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.47%
[2024-07-12 12:14:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][0/2502]	eta 11:14:26 lr 0.000051	 wd 0.0000	time 16.1735 (16.1735)	loss 0.7012 (0.7012)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:14:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:15:51 lr 0.000050	 wd 0.0000	time 0.2270 (0.3961)	loss 0.8374 (0.8160)	grad_norm 2.0913 (2.1194)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:14:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:12:11 lr 0.000050	 wd 0.0000	time 0.2155 (0.3177)	loss 1.0508 (0.8239)	grad_norm 2.3678 (2.0573)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:15:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:11:41 lr 0.000050	 wd 0.0000	time 0.2237 (0.3187)	loss 0.7241 (0.8235)	grad_norm 1.6030 (2.0521)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:15:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:10:25 lr 0.000050	 wd 0.0000	time 0.2311 (0.2976)	loss 0.6396 (0.8234)	grad_norm 1.8140 (2.0220)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:16:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:09:30 lr 0.000049	 wd 0.0000	time 0.2219 (0.2849)	loss 0.7646 (0.8231)	grad_norm 2.6467 (2.0005)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:16:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:08:47 lr 0.000049	 wd 0.0000	time 0.2290 (0.2776)	loss 0.7090 (0.8230)	grad_norm 1.5136 (1.9835)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:17:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:08:12 lr 0.000049	 wd 0.0000	time 0.2368 (0.2732)	loss 0.8125 (0.8217)	grad_norm 1.7474 (1.9687)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:17:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:07:37 lr 0.000049	 wd 0.0000	time 0.2544 (0.2687)	loss 0.7896 (0.8207)	grad_norm 1.9464 (1.9632)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:17:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:07:04 lr 0.000049	 wd 0.0000	time 0.2202 (0.2650)	loss 0.8042 (0.8205)	grad_norm 1.7453 (1.9607)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:18:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:06:34 lr 0.000048	 wd 0.0000	time 0.2132 (0.2627)	loss 0.7900 (0.8210)	grad_norm 2.2772 (1.9609)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:18:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:06:07 lr 0.000048	 wd 0.0000	time 0.2577 (0.2624)	loss 0.8892 (0.8196)	grad_norm 2.2755 (1.9647)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:19:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:38 lr 0.000048	 wd 0.0000	time 0.2227 (0.2604)	loss 0.7026 (0.8191)	grad_norm 1.4374 (1.9643)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:19:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:05:10 lr 0.000048	 wd 0.0000	time 0.2417 (0.2586)	loss 0.8833 (0.8193)	grad_norm 2.2692 (1.9609)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:19:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:43 lr 0.000048	 wd 0.0000	time 0.2618 (0.2575)	loss 0.8218 (0.8192)	grad_norm 1.8600 (1.9603)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:20:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:04:17 lr 0.000047	 wd 0.0000	time 0.2616 (0.2574)	loss 0.8062 (0.8187)	grad_norm 2.3306 (1.9506)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:20:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:51 lr 0.000047	 wd 0.0000	time 0.2295 (0.2563)	loss 0.8862 (0.8185)	grad_norm 1.9429 (1.9465)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:21:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:24 lr 0.000047	 wd 0.0000	time 0.2118 (0.2553)	loss 0.8755 (0.8180)	grad_norm 1.5941 (1.9443)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:21:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:58 lr 0.000047	 wd 0.0000	time 0.2438 (0.2546)	loss 0.8550 (0.8192)	grad_norm 1.7647 (1.9461)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:21:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:33 lr 0.000047	 wd 0.0000	time 0.2669 (0.2550)	loss 0.8530 (0.8191)	grad_norm 1.5745 (1.9420)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:22:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:02:07 lr 0.000046	 wd 0.0000	time 0.2177 (0.2544)	loss 0.9028 (0.8192)	grad_norm 2.0996 (1.9437)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:22:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:41 lr 0.000046	 wd 0.0000	time 0.2135 (0.2537)	loss 0.8574 (0.8191)	grad_norm 1.6829 (1.9401)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:23:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:16 lr 0.000046	 wd 0.0000	time 0.2279 (0.2532)	loss 0.8071 (0.8194)	grad_norm 1.6403 (1.9356)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:23:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:51 lr 0.000046	 wd 0.0000	time 0.2391 (0.2533)	loss 0.9209 (0.8189)	grad_norm 2.4252 (1.9339)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:23:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:25 lr 0.000046	 wd 0.0000	time 0.2198 (0.2528)	loss 0.7861 (0.8188)	grad_norm 1.6570 (1.9325)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:24:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000045	 wd 0.0000	time 0.2123 (0.2519)	loss 1.0547 (0.8190)	grad_norm 1.7875 (1.9299)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:24:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 15 training takes 0:10:34
[2024-07-12 12:24:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 145): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_15.pth saving......
[2024-07-12 12:24:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 147): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_15.pth saved !!!
[2024-07-12 12:25:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 36.423 (36.423)	Loss 0.3687 (0.3687)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 12:25:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.460 Acc@5 97.546
[2024-07-12 12:25:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-12 12:25:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.47%
[2024-07-12 12:25:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][0/2502]	eta 11:04:52 lr 0.000045	 wd 0.0000	time 15.9441 (15.9441)	loss 0.7759 (0.7759)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:25:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:15:40 lr 0.000045	 wd 0.0000	time 0.2153 (0.3915)	loss 0.9531 (0.8235)	grad_norm 1.9894 (1.9237)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:26:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:12:10 lr 0.000045	 wd 0.0000	time 0.2577 (0.3173)	loss 0.8389 (0.8237)	grad_norm 2.0020 (1.9244)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:26:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:11:32 lr 0.000045	 wd 0.0000	time 0.2327 (0.3143)	loss 0.8267 (0.8220)	grad_norm 1.7677 (1.9009)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:27:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:10:18 lr 0.000045	 wd 0.0000	time 0.2416 (0.2943)	loss 0.8911 (0.8199)	grad_norm 1.5424 (1.8841)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:27:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:09:25 lr 0.000044	 wd 0.0000	time 0.2203 (0.2823)	loss 0.7334 (0.8180)	grad_norm 2.1664 (1.8934)	loss_scale 16384.0000 (8911.4571)	mem 9463MB
[2024-07-12 12:28:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:49 lr 0.000044	 wd 0.0000	time 0.3382 (0.2786)	loss 0.7871 (0.8190)	grad_norm 2.1759 (1.8988)	loss_scale 16384.0000 (10154.8087)	mem 9463MB
[2024-07-12 12:28:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:08:24 lr 0.000044	 wd 0.0000	time 0.2056 (0.2800)	loss 0.8359 (0.8186)	grad_norm 1.6245 (1.8926)	loss_scale 16384.0000 (11043.4237)	mem 9463MB
[2024-07-12 12:28:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:07:47 lr 0.000044	 wd 0.0000	time 0.2123 (0.2746)	loss 0.9482 (0.8182)	grad_norm 2.2642 (1.8918)	loss_scale 16384.0000 (11710.1623)	mem 9463MB
[2024-07-12 12:29:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:07:13 lr 0.000043	 wd 0.0000	time 0.2173 (0.2703)	loss 0.7959 (0.8200)	grad_norm 2.9428 (1.8888)	loss_scale 16384.0000 (12228.9012)	mem 9463MB
[2024-07-12 12:29:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:06:42 lr 0.000043	 wd 0.0000	time 0.2187 (0.2679)	loss 0.7842 (0.8211)	grad_norm 2.2398 (1.8806)	loss_scale 16384.0000 (12643.9960)	mem 9463MB
[2024-07-12 12:30:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:06:14 lr 0.000043	 wd 0.0000	time 0.2051 (0.2668)	loss 0.7349 (0.8199)	grad_norm 1.6685 (1.8800)	loss_scale 16384.0000 (12983.6876)	mem 9463MB
[2024-07-12 12:30:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:44 lr 0.000043	 wd 0.0000	time 0.2394 (0.2644)	loss 0.8892 (0.8207)	grad_norm 1.4921 (1.8876)	loss_scale 16384.0000 (13266.8110)	mem 9463MB
[2024-07-12 12:30:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:05:15 lr 0.000043	 wd 0.0000	time 0.2424 (0.2624)	loss 0.8125 (0.8188)	grad_norm 2.2855 (1.8925)	loss_scale 16384.0000 (13506.4105)	mem 9463MB
[2024-07-12 12:31:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:47 lr 0.000042	 wd 0.0000	time 0.4492 (0.2612)	loss 0.7979 (0.8181)	grad_norm 1.6450 (1.8935)	loss_scale 16384.0000 (13711.8059)	mem 9463MB
[2024-07-12 12:31:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:04:21 lr 0.000042	 wd 0.0000	time 0.2130 (0.2611)	loss 0.8369 (0.8177)	grad_norm 1.8266 (1.8930)	loss_scale 16384.0000 (13889.8334)	mem 9463MB
[2024-07-12 12:32:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:54 lr 0.000042	 wd 0.0000	time 0.2050 (0.2598)	loss 0.8125 (0.8177)	grad_norm 1.6982 (1.8927)	loss_scale 16384.0000 (14045.6215)	mem 9463MB
[2024-07-12 12:32:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:27 lr 0.000042	 wd 0.0000	time 0.2057 (0.2585)	loss 0.6904 (0.8185)	grad_norm 1.6124 (inf)	loss_scale 8192.0000 (14125.3004)	mem 9463MB
[2024-07-12 12:33:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:03:01 lr 0.000042	 wd 0.0000	time 0.2072 (0.2585)	loss 0.8491 (0.8189)	grad_norm 1.4435 (inf)	loss_scale 8192.0000 (13795.8556)	mem 9463MB
[2024-07-12 12:33:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:35 lr 0.000041	 wd 0.0000	time 0.2281 (0.2579)	loss 0.9302 (0.8193)	grad_norm 1.8815 (inf)	loss_scale 8192.0000 (13501.0710)	mem 9463MB
[2024-07-12 12:33:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:02:09 lr 0.000041	 wd 0.0000	time 0.2174 (0.2571)	loss 0.7344 (0.8188)	grad_norm 1.5757 (inf)	loss_scale 8192.0000 (13235.7501)	mem 9463MB
[2024-07-12 12:34:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:43 lr 0.000041	 wd 0.0000	time 0.2422 (0.2563)	loss 0.7422 (0.8187)	grad_norm 1.6900 (inf)	loss_scale 8192.0000 (12995.6859)	mem 9463MB
[2024-07-12 12:34:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:17 lr 0.000041	 wd 0.0000	time 0.2182 (0.2562)	loss 0.7603 (0.8188)	grad_norm 1.7306 (inf)	loss_scale 8192.0000 (12777.4357)	mem 9463MB
[2024-07-12 12:35:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:51 lr 0.000041	 wd 0.0000	time 0.2192 (0.2559)	loss 0.8491 (0.8187)	grad_norm 1.6924 (inf)	loss_scale 8192.0000 (12578.1556)	mem 9463MB
[2024-07-12 12:35:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:26 lr 0.000040	 wd 0.0000	time 0.2127 (0.2552)	loss 0.7554 (0.8183)	grad_norm 1.7594 (inf)	loss_scale 8192.0000 (12395.4752)	mem 9463MB
[2024-07-12 12:35:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.2168 (0.2542)	loss 0.8330 (0.8179)	grad_norm 1.7061 (inf)	loss_scale 8192.0000 (12227.4034)	mem 9463MB
[2024-07-12 12:35:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 16 training takes 0:10:40
[2024-07-12 12:36:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 36.104 (36.104)	Loss 0.3616 (0.3616)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 12:36:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.516 Acc@5 97.578
[2024-07-12 12:36:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-12 12:36:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-12 12:36:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 160): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_best.pth saving......
[2024-07-12 12:36:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 162): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_best.pth saved !!!
[2024-07-12 12:37:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][0/2502]	eta 11:02:27 lr 0.000040	 wd 0.0000	time 15.8862 (15.8862)	loss 0.7358 (0.7358)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:37:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:15:35 lr 0.000040	 wd 0.0000	time 0.2519 (0.3893)	loss 0.8804 (0.8122)	grad_norm 1.5911 (1.8972)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:37:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:12:11 lr 0.000040	 wd 0.0000	time 0.2262 (0.3179)	loss 0.9634 (0.8209)	grad_norm 1.9130 (1.8660)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:38:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:49 lr 0.000040	 wd 0.0000	time 0.2108 (0.2950)	loss 0.8794 (0.8208)	grad_norm 1.6233 (1.8644)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:38:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:09:49 lr 0.000039	 wd 0.0000	time 0.2256 (0.2802)	loss 0.7617 (0.8143)	grad_norm 1.7199 (1.8614)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:39:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:09:02 lr 0.000039	 wd 0.0000	time 0.2252 (0.2712)	loss 0.7515 (0.8157)	grad_norm 1.9377 (1.8786)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:39:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:27 lr 0.000039	 wd 0.0000	time 0.2162 (0.2670)	loss 0.8516 (0.8171)	grad_norm 2.1199 (1.8726)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:39:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:55 lr 0.000039	 wd 0.0000	time 0.2407 (0.2641)	loss 0.7505 (0.8163)	grad_norm 1.5935 (1.8780)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:40:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:07:23 lr 0.000039	 wd 0.0000	time 0.2206 (0.2607)	loss 0.7334 (0.8165)	grad_norm 1.7447 (1.8924)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:40:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:53 lr 0.000038	 wd 0.0000	time 0.2211 (0.2580)	loss 0.7998 (0.8168)	grad_norm 1.6127 (1.8985)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:41:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:25 lr 0.000038	 wd 0.0000	time 0.2349 (0.2567)	loss 0.8652 (0.8165)	grad_norm 2.1536 (1.8963)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:41:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:59 lr 0.000038	 wd 0.0000	time 0.2350 (0.2561)	loss 0.8999 (0.8176)	grad_norm 1.8157 (1.8975)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:41:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:31 lr 0.000038	 wd 0.0000	time 0.2156 (0.2546)	loss 0.8994 (0.8181)	grad_norm 1.6195 (1.8908)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:42:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:05:04 lr 0.000038	 wd 0.0000	time 0.2200 (0.2533)	loss 0.9614 (0.8171)	grad_norm 1.5476 (1.8908)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:42:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:38 lr 0.000037	 wd 0.0000	time 0.2229 (0.2526)	loss 0.7407 (0.8176)	grad_norm 1.6782 (1.8946)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:43:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:04:13 lr 0.000037	 wd 0.0000	time 0.2488 (0.2529)	loss 0.7969 (0.8177)	grad_norm 2.1047 (1.8997)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:43:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:47 lr 0.000037	 wd 0.0000	time 0.2171 (0.2521)	loss 0.7192 (0.8173)	grad_norm 1.9810 (1.9022)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:43:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:21 lr 0.000037	 wd 0.0000	time 0.2250 (0.2513)	loss 0.9546 (0.8170)	grad_norm 2.1176 (1.9063)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:44:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:56 lr 0.000037	 wd 0.0000	time 0.2379 (0.2508)	loss 0.7632 (0.8170)	grad_norm 1.6811 (1.9021)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:44:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:31 lr 0.000036	 wd 0.0000	time 0.2463 (0.2516)	loss 0.7598 (0.8172)	grad_norm 2.1048 (1.8987)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 12:45:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:02:06 lr 0.000036	 wd 0.0000	time 0.2159 (0.2510)	loss 0.7915 (0.8166)	grad_norm 2.1498 (inf)	loss_scale 4096.0000 (8171.5302)	mem 9463MB
[2024-07-12 12:45:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:40 lr 0.000036	 wd 0.0000	time 0.2171 (0.2505)	loss 0.7632 (0.8166)	grad_norm 1.9408 (inf)	loss_scale 4096.0000 (7977.5497)	mem 9463MB
[2024-07-12 12:45:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:15 lr 0.000036	 wd 0.0000	time 0.2341 (0.2501)	loss 0.8047 (0.8165)	grad_norm 1.5661 (inf)	loss_scale 4096.0000 (7801.1958)	mem 9463MB
[2024-07-12 12:46:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:50 lr 0.000036	 wd 0.0000	time 0.2353 (0.2504)	loss 0.7798 (0.8163)	grad_norm 1.8441 (inf)	loss_scale 4096.0000 (7640.1704)	mem 9463MB
[2024-07-12 12:46:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:25 lr 0.000035	 wd 0.0000	time 0.2360 (0.2500)	loss 0.7109 (0.8171)	grad_norm 1.7052 (inf)	loss_scale 4096.0000 (7492.5581)	mem 9463MB
[2024-07-12 12:47:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.2176 (0.2493)	loss 0.9829 (0.8174)	grad_norm 1.8930 (inf)	loss_scale 4096.0000 (7356.7501)	mem 9463MB
[2024-07-12 12:47:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 17 training takes 0:10:27
[2024-07-12 12:47:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 39.121 (39.121)	Loss 0.3638 (0.3638)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 12:48:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.510 Acc@5 97.542
[2024-07-12 12:48:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-12 12:48:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-12 12:48:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][0/2502]	eta 10:42:46 lr 0.000035	 wd 0.0000	time 15.4142 (15.4142)	loss 0.8594 (0.8594)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:48:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:15:41 lr 0.000035	 wd 0.0000	time 0.2314 (0.3920)	loss 0.7759 (0.8108)	grad_norm 2.2875 (1.9595)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:49:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:12:30 lr 0.000035	 wd 0.0000	time 0.2551 (0.3261)	loss 0.9199 (0.8094)	grad_norm 1.9545 (1.9160)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:49:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:11:16 lr 0.000035	 wd 0.0000	time 0.2220 (0.3071)	loss 0.8853 (0.8137)	grad_norm 1.9630 (1.8954)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:50:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:10:07 lr 0.000034	 wd 0.0000	time 0.2288 (0.2892)	loss 0.8735 (0.8162)	grad_norm 1.8192 (1.9009)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:50:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:09:17 lr 0.000034	 wd 0.0000	time 0.2054 (0.2785)	loss 0.7651 (0.8171)	grad_norm 1.9134 (1.8894)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:50:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:08:39 lr 0.000034	 wd 0.0000	time 0.3075 (0.2730)	loss 0.7305 (0.8160)	grad_norm 1.8929 (1.8783)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:51:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:08:04 lr 0.000034	 wd 0.0000	time 0.2352 (0.2691)	loss 0.9297 (0.8145)	grad_norm 1.5062 (1.8633)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:51:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:31 lr 0.000034	 wd 0.0000	time 0.2094 (0.2651)	loss 0.8428 (0.8119)	grad_norm 1.7209 (1.8606)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:52:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:06:59 lr 0.000033	 wd 0.0000	time 0.2219 (0.2620)	loss 0.8491 (0.8120)	grad_norm 2.0640 (1.8665)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:52:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:30 lr 0.000033	 wd 0.0000	time 0.2397 (0.2603)	loss 0.7598 (0.8119)	grad_norm 1.7849 (1.8657)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:52:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:06:03 lr 0.000033	 wd 0.0000	time 0.2119 (0.2596)	loss 0.7769 (0.8129)	grad_norm 1.6228 (1.8714)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:53:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:35 lr 0.000033	 wd 0.0000	time 0.2321 (0.2579)	loss 1.1064 (0.8123)	grad_norm 1.8728 (1.8745)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:53:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:05:08 lr 0.000033	 wd 0.0000	time 0.2372 (0.2564)	loss 0.7080 (0.8129)	grad_norm 1.5192 (1.8676)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:54:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:41 lr 0.000032	 wd 0.0000	time 0.2115 (0.2553)	loss 0.7681 (0.8120)	grad_norm 1.8070 (1.8693)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:54:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:04:15 lr 0.000032	 wd 0.0000	time 0.2118 (0.2553)	loss 0.7354 (0.8123)	grad_norm 3.7746 (1.8695)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:54:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:49 lr 0.000032	 wd 0.0000	time 0.2328 (0.2544)	loss 0.8115 (0.8121)	grad_norm 2.2434 (1.8687)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:55:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:23 lr 0.000032	 wd 0.0000	time 0.2292 (0.2535)	loss 0.9385 (0.8122)	grad_norm 1.5330 (1.8725)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:55:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:57 lr 0.000032	 wd 0.0000	time 0.2795 (0.2530)	loss 0.8496 (0.8123)	grad_norm 1.5781 (1.8705)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:56:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:32 lr 0.000032	 wd 0.0000	time 0.2258 (0.2538)	loss 0.9639 (0.8124)	grad_norm 1.8819 (1.8691)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:56:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:02:07 lr 0.000031	 wd 0.0000	time 0.2210 (0.2531)	loss 0.9331 (0.8131)	grad_norm 1.9511 (1.8702)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:56:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:41 lr 0.000031	 wd 0.0000	time 0.2153 (0.2525)	loss 0.7134 (0.8130)	grad_norm 1.8866 (1.8774)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:57:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:16 lr 0.000031	 wd 0.0000	time 0.2177 (0.2524)	loss 0.7012 (0.8135)	grad_norm 1.8225 (1.8778)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:57:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:50 lr 0.000031	 wd 0.0000	time 0.2278 (0.2523)	loss 0.7588 (0.8138)	grad_norm 1.9828 (1.8844)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:58:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:25 lr 0.000031	 wd 0.0000	time 0.2341 (0.2519)	loss 0.8247 (0.8135)	grad_norm 2.4227 (1.8841)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:58:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000030	 wd 0.0000	time 0.2115 (0.2510)	loss 0.8315 (0.8138)	grad_norm 1.6613 (1.8874)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 12:58:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 18 training takes 0:10:32
[2024-07-12 12:59:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 34.705 (34.705)	Loss 0.3672 (0.3672)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 12:59:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.544 Acc@5 97.528
[2024-07-12 12:59:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-12 12:59:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.54%
[2024-07-12 12:59:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 160): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_best.pth saving......
[2024-07-12 12:59:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 162): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_best.pth saved !!!
[2024-07-12 12:59:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][0/2502]	eta 10:34:17 lr 0.000030	 wd 0.0000	time 15.2110 (15.2110)	loss 0.7749 (0.7749)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 13:00:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:15:32 lr 0.000030	 wd 0.0000	time 0.2249 (0.3884)	loss 0.9580 (0.8243)	grad_norm 2.3060 (1.9175)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 13:00:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:13:16 lr 0.000030	 wd 0.0000	time 0.2320 (0.3462)	loss 0.6870 (0.8240)	grad_norm 2.0071 (1.8828)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 13:01:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:11:22 lr 0.000030	 wd 0.0000	time 0.2335 (0.3102)	loss 0.7749 (0.8215)	grad_norm 1.8429 (1.8768)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 13:01:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:10:11 lr 0.000030	 wd 0.0000	time 0.2153 (0.2910)	loss 0.8682 (0.8185)	grad_norm 1.5898 (1.8797)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 13:01:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:09:19 lr 0.000029	 wd 0.0000	time 0.2595 (0.2796)	loss 0.8511 (0.8160)	grad_norm 1.4990 (1.8915)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 13:02:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:41 lr 0.000029	 wd 0.0000	time 0.2199 (0.2743)	loss 0.7700 (0.8157)	grad_norm 1.7215 (1.8776)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 13:02:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:08:06 lr 0.000029	 wd 0.0000	time 0.2194 (0.2699)	loss 0.8765 (0.8156)	grad_norm 3.1525 (1.8881)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 13:02:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:07:32 lr 0.000029	 wd 0.0000	time 0.2350 (0.2659)	loss 0.7212 (0.8146)	grad_norm 1.6574 (1.8916)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 13:03:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:07:00 lr 0.000029	 wd 0.0000	time 0.2390 (0.2627)	loss 0.7412 (0.8131)	grad_norm 1.9592 (1.8858)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 13:03:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:34 lr 0.000028	 wd 0.0000	time 0.2102 (0.2629)	loss 0.7373 (0.8128)	grad_norm 2.5783 (1.8882)	loss_scale 8192.0000 (4153.2867)	mem 9463MB
[2024-07-12 13:04:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:06:05 lr 0.000028	 wd 0.0000	time 0.2158 (0.2609)	loss 0.9253 (0.8131)	grad_norm 1.9181 (1.8905)	loss_scale 8192.0000 (4520.1090)	mem 9463MB
[2024-07-12 13:04:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:37 lr 0.000028	 wd 0.0000	time 0.2284 (0.2591)	loss 0.8315 (0.8129)	grad_norm 1.6593 (1.8949)	loss_scale 8192.0000 (4825.8451)	mem 9463MB
[2024-07-12 13:05:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:05:09 lr 0.000028	 wd 0.0000	time 0.2421 (0.2576)	loss 0.6802 (0.8135)	grad_norm 1.6489 (1.8929)	loss_scale 8192.0000 (5084.5811)	mem 9463MB
[2024-07-12 13:05:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:44 lr 0.000028	 wd 0.0000	time 0.2218 (0.2578)	loss 0.7412 (0.8140)	grad_norm 1.4463 (1.8940)	loss_scale 8192.0000 (5306.3812)	mem 9463MB
[2024-07-12 13:05:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:04:17 lr 0.000028	 wd 0.0000	time 0.2459 (0.2568)	loss 0.8540 (0.8146)	grad_norm 1.7364 (1.8968)	loss_scale 8192.0000 (5498.6276)	mem 9463MB
[2024-07-12 13:06:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:50 lr 0.000027	 wd 0.0000	time 0.2312 (0.2557)	loss 0.7676 (0.8146)	grad_norm 1.5458 (1.8984)	loss_scale 8192.0000 (5666.8582)	mem 9463MB
[2024-07-12 13:06:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:24 lr 0.000027	 wd 0.0000	time 0.2376 (0.2548)	loss 0.7065 (0.8142)	grad_norm 2.3482 (1.8974)	loss_scale 8192.0000 (5815.3086)	mem 9463MB
[2024-07-12 13:07:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:59 lr 0.000027	 wd 0.0000	time 1.1467 (0.2554)	loss 0.7021 (0.8145)	grad_norm 1.7585 (1.8959)	loss_scale 8192.0000 (5947.2737)	mem 9463MB
[2024-07-12 13:07:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:33 lr 0.000027	 wd 0.0000	time 0.2443 (0.2552)	loss 0.8013 (0.8143)	grad_norm 2.8426 (1.8960)	loss_scale 8192.0000 (6065.3551)	mem 9463MB
[2024-07-12 13:07:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:02:07 lr 0.000027	 wd 0.0000	time 0.2147 (0.2547)	loss 0.8794 (0.8134)	grad_norm 1.5851 (1.8977)	loss_scale 8192.0000 (6171.6342)	mem 9463MB
[2024-07-12 13:08:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:42 lr 0.000026	 wd 0.0000	time 0.2084 (0.2540)	loss 0.9492 (0.8131)	grad_norm 1.7089 (1.8956)	loss_scale 8192.0000 (6267.7963)	mem 9463MB
[2024-07-12 13:08:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:16 lr 0.000026	 wd 0.0000	time 0.2069 (0.2545)	loss 0.8247 (0.8129)	grad_norm 2.2285 (1.8955)	loss_scale 8192.0000 (6355.2204)	mem 9463MB
[2024-07-12 13:09:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:51 lr 0.000026	 wd 0.0000	time 0.2094 (0.2541)	loss 0.8696 (0.8131)	grad_norm 1.4068 (1.8921)	loss_scale 8192.0000 (6435.0456)	mem 9463MB
[2024-07-12 13:09:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:25 lr 0.000026	 wd 0.0000	time 0.2319 (0.2535)	loss 0.9917 (0.8129)	grad_norm 2.3229 (1.8923)	loss_scale 8192.0000 (6508.2216)	mem 9463MB
[2024-07-12 13:09:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.2214 (0.2526)	loss 0.7314 (0.8126)	grad_norm 1.8110 (1.8951)	loss_scale 8192.0000 (6575.5458)	mem 9463MB
[2024-07-12 13:10:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 19 training takes 0:10:37
[2024-07-12 13:10:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 38.256 (38.256)	Loss 0.3640 (0.3640)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 9463MB
[2024-07-12 13:10:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.510 Acc@5 97.588
[2024-07-12 13:10:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-12 13:10:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.54%
[2024-07-12 13:11:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][0/2502]	eta 10:54:41 lr 0.000026	 wd 0.0000	time 15.7000 (15.7000)	loss 0.9312 (0.9312)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:11:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:15:54 lr 0.000026	 wd 0.0000	time 0.2713 (0.3974)	loss 0.8525 (0.8200)	grad_norm 2.1725 (1.8951)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:12:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:12:31 lr 0.000025	 wd 0.0000	time 0.2136 (0.3264)	loss 0.9038 (0.8155)	grad_norm 1.5270 (1.8621)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:12:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:10:52 lr 0.000025	 wd 0.0000	time 0.2293 (0.2961)	loss 0.7427 (0.8141)	grad_norm 1.8810 (1.8700)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:12:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:09:50 lr 0.000025	 wd 0.0000	time 0.2057 (0.2809)	loss 0.6919 (0.8107)	grad_norm 1.8492 (1.8922)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:13:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:09:04 lr 0.000025	 wd 0.0000	time 0.2364 (0.2721)	loss 0.8486 (0.8112)	grad_norm 1.6812 (1.9011)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:13:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:08:30 lr 0.000025	 wd 0.0000	time 0.2058 (0.2683)	loss 0.7627 (0.8114)	grad_norm 2.0913 (1.9079)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:14:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:54 lr 0.000025	 wd 0.0000	time 0.2222 (0.2635)	loss 0.7261 (0.8116)	grad_norm 1.5856 (1.9019)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:14:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:07:22 lr 0.000024	 wd 0.0000	time 0.2218 (0.2602)	loss 0.8179 (0.8122)	grad_norm 2.1064 (1.8892)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:14:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:53 lr 0.000024	 wd 0.0000	time 0.2427 (0.2579)	loss 0.9429 (0.8118)	grad_norm 2.2412 (1.8844)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:15:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:26 lr 0.000024	 wd 0.0000	time 0.2047 (0.2570)	loss 0.7759 (0.8132)	grad_norm 1.6304 (1.8849)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:15:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:58 lr 0.000024	 wd 0.0000	time 0.2184 (0.2556)	loss 0.7368 (0.8131)	grad_norm 2.4376 (1.8846)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:16:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:30 lr 0.000024	 wd 0.0000	time 0.2206 (0.2541)	loss 0.7104 (0.8128)	grad_norm 2.0178 (1.8763)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:16:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:05:04 lr 0.000023	 wd 0.0000	time 0.2190 (0.2529)	loss 0.7573 (0.8118)	grad_norm 2.3176 (1.8779)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:16:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:39 lr 0.000023	 wd 0.0000	time 0.2381 (0.2535)	loss 0.7998 (0.8119)	grad_norm 2.2612 (1.8767)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:17:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:04:13 lr 0.000023	 wd 0.0000	time 0.2174 (0.2527)	loss 0.9102 (0.8115)	grad_norm 2.2157 (1.8772)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:17:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:47 lr 0.000023	 wd 0.0000	time 0.2189 (0.2519)	loss 0.8438 (0.8105)	grad_norm 1.5149 (1.8771)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:18:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:21 lr 0.000023	 wd 0.0000	time 0.2042 (0.2512)	loss 1.0059 (0.8104)	grad_norm 1.7178 (1.8775)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:18:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:56 lr 0.000023	 wd 0.0000	time 0.2092 (0.2513)	loss 0.8398 (0.8104)	grad_norm 2.2096 (1.8814)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:18:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:31 lr 0.000022	 wd 0.0000	time 0.2130 (0.2511)	loss 0.8184 (0.8105)	grad_norm 2.2770 (1.8781)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:19:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:02:05 lr 0.000022	 wd 0.0000	time 0.2272 (0.2505)	loss 0.8521 (0.8104)	grad_norm 1.9608 (1.8801)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:19:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:40 lr 0.000022	 wd 0.0000	time 0.2359 (0.2500)	loss 0.8457 (0.8105)	grad_norm 2.1018 (1.8814)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:20:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:15 lr 0.000022	 wd 0.0000	time 0.2352 (0.2507)	loss 0.8008 (0.8103)	grad_norm 1.8658 (1.8826)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:20:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:50 lr 0.000022	 wd 0.0000	time 0.2298 (0.2505)	loss 0.7949 (0.8106)	grad_norm 1.4959 (1.8858)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:20:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:25 lr 0.000022	 wd 0.0000	time 0.2200 (0.2501)	loss 0.7739 (0.8109)	grad_norm 2.0779 (1.8832)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:21:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.2146 (0.2493)	loss 0.7891 (0.8108)	grad_norm 1.8858 (1.8873)	loss_scale 16384.0000 (8244.4078)	mem 9463MB
[2024-07-12 13:21:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 20 training takes 0:10:30
[2024-07-12 13:21:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 32.728 (32.728)	Loss 0.3667 (0.3667)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 9463MB
[2024-07-12 13:22:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.430 Acc@5 97.568
[2024-07-12 13:22:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-12 13:22:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.54%
[2024-07-12 13:22:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][0/2502]	eta 11:15:57 lr 0.000021	 wd 0.0000	time 16.2102 (16.2102)	loss 0.8799 (0.8799)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 13:22:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:15:51 lr 0.000021	 wd 0.0000	time 0.2212 (0.3960)	loss 0.7861 (0.8122)	grad_norm 1.7178 (1.9827)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 13:23:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:13:38 lr 0.000021	 wd 0.0000	time 0.2225 (0.3556)	loss 0.8267 (0.8148)	grad_norm 1.8395 (1.9620)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 13:23:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:11:34 lr 0.000021	 wd 0.0000	time 0.2266 (0.3156)	loss 0.7607 (0.8075)	grad_norm 1.6936 (1.9215)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 13:24:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:10:20 lr 0.000021	 wd 0.0000	time 0.2192 (0.2954)	loss 0.7188 (0.8059)	grad_norm 1.8520 (1.9205)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 13:24:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:09:28 lr 0.000021	 wd 0.0000	time 0.2227 (0.2838)	loss 0.9380 (0.8081)	grad_norm 1.8418 (1.9089)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 13:25:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:09:07 lr 0.000020	 wd 0.0000	time 0.2167 (0.2881)	loss 0.8521 (0.8077)	grad_norm 1.7410 (1.9123)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 13:25:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:08:25 lr 0.000020	 wd 0.0000	time 0.2055 (0.2806)	loss 0.7837 (0.8075)	grad_norm 3.1463 (1.9139)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 13:25:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:48 lr 0.000020	 wd 0.0000	time 0.2330 (0.2750)	loss 0.8140 (0.8072)	grad_norm 1.6585 (1.9132)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 13:26:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:07:14 lr 0.000020	 wd 0.0000	time 0.2239 (0.2715)	loss 0.8003 (0.8071)	grad_norm 1.7737 (1.9073)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 13:26:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:44 lr 0.000020	 wd 0.0000	time 0.2348 (0.2696)	loss 0.7451 (0.8061)	grad_norm 2.0915 (1.9065)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 13:27:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:06:14 lr 0.000020	 wd 0.0000	time 0.2377 (0.2668)	loss 0.7671 (0.8069)	grad_norm 1.3690 (1.9078)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 13:27:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:44 lr 0.000019	 wd 0.0000	time 0.2272 (0.2643)	loss 0.8560 (0.8065)	grad_norm 1.9499 (1.9028)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 13:27:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:05:15 lr 0.000019	 wd 0.0000	time 0.2148 (0.2628)	loss 0.9131 (0.8063)	grad_norm 1.6054 (1.9012)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 13:28:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:48 lr 0.000019	 wd 0.0000	time 0.2395 (0.2617)	loss 0.7363 (0.8065)	grad_norm 1.7775 (1.9037)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 13:28:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:04:20 lr 0.000019	 wd 0.0000	time 0.2208 (0.2602)	loss 0.7886 (0.8063)	grad_norm 1.8635 (1.9034)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 13:29:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:53 lr 0.000019	 wd 0.0000	time 0.2181 (0.2588)	loss 0.7778 (0.8056)	grad_norm 2.1003 (inf)	loss_scale 8192.0000 (15964.4222)	mem 9463MB
[2024-07-12 13:29:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:26 lr 0.000019	 wd 0.0000	time 0.2233 (0.2578)	loss 0.7920 (0.8052)	grad_norm 1.7844 (inf)	loss_scale 8192.0000 (15507.4897)	mem 9463MB
[2024-07-12 13:29:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:03:01 lr 0.000018	 wd 0.0000	time 0.2261 (0.2581)	loss 0.8242 (0.8048)	grad_norm 2.4437 (inf)	loss_scale 8192.0000 (15101.2993)	mem 9463MB
[2024-07-12 13:30:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:34 lr 0.000018	 wd 0.0000	time 0.2150 (0.2574)	loss 0.7007 (0.8045)	grad_norm 2.1856 (inf)	loss_scale 8192.0000 (14737.8432)	mem 9463MB
[2024-07-12 13:30:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:02:08 lr 0.000018	 wd 0.0000	time 0.2095 (0.2566)	loss 0.7705 (0.8049)	grad_norm 1.5534 (inf)	loss_scale 8192.0000 (14410.7146)	mem 9463MB
[2024-07-12 13:31:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:42 lr 0.000018	 wd 0.0000	time 0.2303 (0.2559)	loss 0.8149 (0.8050)	grad_norm 1.9389 (inf)	loss_scale 8192.0000 (14114.7263)	mem 9463MB
[2024-07-12 13:31:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:17 lr 0.000018	 wd 0.0000	time 0.2305 (0.2566)	loss 0.6807 (0.8050)	grad_norm 1.6408 (inf)	loss_scale 8192.0000 (13845.6338)	mem 9463MB
[2024-07-12 13:32:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:51 lr 0.000018	 wd 0.0000	time 0.2342 (0.2560)	loss 0.8726 (0.8056)	grad_norm 2.3567 (inf)	loss_scale 8192.0000 (13599.9305)	mem 9463MB
[2024-07-12 13:32:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:26 lr 0.000018	 wd 0.0000	time 0.2105 (0.2553)	loss 0.8115 (0.8058)	grad_norm 1.4903 (inf)	loss_scale 8192.0000 (13374.6939)	mem 9463MB
[2024-07-12 13:32:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000017	 wd 0.0000	time 0.2143 (0.2543)	loss 0.8604 (0.8062)	grad_norm 1.4590 (inf)	loss_scale 8192.0000 (13167.4690)	mem 9463MB
[2024-07-12 13:32:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 21 training takes 0:10:42
[2024-07-12 13:33:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 31.798 (31.798)	Loss 0.3638 (0.3638)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 13:33:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.446 Acc@5 97.558
[2024-07-12 13:33:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-12 13:33:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.54%
[2024-07-12 13:34:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][0/2502]	eta 11:16:33 lr 0.000017	 wd 0.0000	time 16.2243 (16.2243)	loss 0.8550 (0.8550)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:34:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:16:04 lr 0.000017	 wd 0.0000	time 0.2268 (0.4014)	loss 0.8945 (0.8181)	grad_norm 1.3856 (1.9710)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:34:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:12:30 lr 0.000017	 wd 0.0000	time 0.2414 (0.3258)	loss 0.6821 (0.8163)	grad_norm 2.0336 (1.9209)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:35:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:10:50 lr 0.000017	 wd 0.0000	time 0.2162 (0.2953)	loss 0.8867 (0.8123)	grad_norm 2.4171 (1.9361)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:35:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:09:48 lr 0.000017	 wd 0.0000	time 0.2311 (0.2801)	loss 0.8667 (0.8139)	grad_norm 1.5908 (1.9111)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:36:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:09:03 lr 0.000017	 wd 0.0000	time 0.2078 (0.2717)	loss 0.9189 (0.8154)	grad_norm 1.9364 (1.9109)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:36:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:27 lr 0.000016	 wd 0.0000	time 0.2350 (0.2668)	loss 0.9668 (0.8156)	grad_norm 2.4539 (1.9063)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:36:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:53 lr 0.000016	 wd 0.0000	time 0.2172 (0.2627)	loss 0.8047 (0.8162)	grad_norm 1.8807 (1.9023)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:37:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:07:21 lr 0.000016	 wd 0.0000	time 0.2244 (0.2594)	loss 0.7578 (0.8165)	grad_norm 1.7714 (1.9077)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:37:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:52 lr 0.000016	 wd 0.0000	time 0.2435 (0.2576)	loss 0.8369 (0.8152)	grad_norm 1.7050 (1.9002)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:38:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:27 lr 0.000016	 wd 0.0000	time 0.2226 (0.2579)	loss 0.6909 (0.8157)	grad_norm 2.0206 (1.9024)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:38:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:59 lr 0.000016	 wd 0.0000	time 0.2191 (0.2561)	loss 0.7549 (0.8158)	grad_norm 1.5943 (1.9125)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:38:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:31 lr 0.000016	 wd 0.0000	time 0.2594 (0.2544)	loss 0.8159 (0.8158)	grad_norm 1.7223 (1.9124)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:39:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:05:04 lr 0.000015	 wd 0.0000	time 0.2418 (0.2534)	loss 0.7808 (0.8150)	grad_norm 2.4130 (1.9027)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:39:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:39 lr 0.000015	 wd 0.0000	time 0.2133 (0.2538)	loss 0.7910 (0.8148)	grad_norm 2.0822 (1.9025)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:40:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:04:13 lr 0.000015	 wd 0.0000	time 0.2332 (0.2529)	loss 0.6191 (0.8149)	grad_norm 1.9499 (1.9018)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:40:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:47 lr 0.000015	 wd 0.0000	time 0.2183 (0.2520)	loss 0.9072 (0.8148)	grad_norm 1.3949 (1.8996)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:40:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:21 lr 0.000015	 wd 0.0000	time 0.2176 (0.2512)	loss 0.6807 (0.8138)	grad_norm 1.6932 (1.8965)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:41:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:56 lr 0.000015	 wd 0.0000	time 0.2348 (0.2518)	loss 0.9458 (0.8129)	grad_norm 1.9219 (1.8944)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:41:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:31 lr 0.000015	 wd 0.0000	time 0.2179 (0.2512)	loss 0.8530 (0.8133)	grad_norm 1.9505 (1.8984)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:42:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:02:05 lr 0.000014	 wd 0.0000	time 0.2740 (0.2507)	loss 0.7988 (0.8133)	grad_norm 1.9415 (1.8978)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:42:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:40 lr 0.000014	 wd 0.0000	time 0.2259 (0.2503)	loss 0.7495 (0.8132)	grad_norm 2.0704 (1.8984)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:42:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:15 lr 0.000014	 wd 0.0000	time 0.2546 (0.2514)	loss 0.6670 (0.8125)	grad_norm 1.7131 (1.8997)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:43:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:50 lr 0.000014	 wd 0.0000	time 0.2100 (0.2510)	loss 0.8032 (0.8120)	grad_norm 2.8571 (1.9010)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:43:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:25 lr 0.000014	 wd 0.0000	time 0.2329 (0.2505)	loss 0.7617 (0.8125)	grad_norm 1.9631 (1.8983)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:44:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.2111 (0.2497)	loss 0.7485 (0.8123)	grad_norm 1.7670 (1.8962)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:44:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 22 training takes 0:10:35
[2024-07-12 13:45:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 64.702 (64.702)	Loss 0.3621 (0.3621)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 13:45:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.518 Acc@5 97.572
[2024-07-12 13:45:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-12 13:45:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.54%
[2024-07-12 13:46:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][0/2502]	eta 1 day, 1:54:02 lr 0.000014	 wd 0.0000	time 37.2673 (37.2673)	loss 0.8306 (0.8306)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:46:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:24:27 lr 0.000014	 wd 0.0000	time 0.2310 (0.6110)	loss 0.8716 (0.8053)	grad_norm 2.1383 (1.9520)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:47:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:16:16 lr 0.000013	 wd 0.0000	time 0.2163 (0.4241)	loss 0.7314 (0.8027)	grad_norm 2.0431 (1.9551)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:47:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:13:25 lr 0.000013	 wd 0.0000	time 0.2283 (0.3656)	loss 0.7744 (0.8045)	grad_norm 2.1166 (1.9346)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:48:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:11:40 lr 0.000013	 wd 0.0000	time 0.2263 (0.3332)	loss 0.8848 (0.8080)	grad_norm 2.1475 (1.9270)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:48:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:10:28 lr 0.000013	 wd 0.0000	time 0.2100 (0.3137)	loss 0.9053 (0.8108)	grad_norm 2.1964 (1.9262)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:48:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:09:31 lr 0.000013	 wd 0.0000	time 0.2138 (0.3006)	loss 0.9717 (0.8107)	grad_norm 3.1313 (1.9217)	loss_scale 16384.0000 (9364.2329)	mem 9463MB
[2024-07-12 13:49:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:08:48 lr 0.000013	 wd 0.0000	time 0.2080 (0.2932)	loss 0.8862 (0.8118)	grad_norm 1.8522 (1.9257)	loss_scale 16384.0000 (10365.6262)	mem 9463MB
[2024-07-12 13:49:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:08:08 lr 0.000013	 wd 0.0000	time 0.2322 (0.2868)	loss 0.7432 (0.8101)	grad_norm 1.5614 (1.9157)	loss_scale 16384.0000 (11116.9838)	mem 9463MB
[2024-07-12 13:49:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:07:30 lr 0.000012	 wd 0.0000	time 0.2060 (0.2814)	loss 1.0020 (0.8090)	grad_norm 2.2207 (1.9155)	loss_scale 16384.0000 (11701.5583)	mem 9463MB
[2024-07-12 13:50:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:55 lr 0.000012	 wd 0.0000	time 0.2194 (0.2768)	loss 0.7324 (0.8100)	grad_norm 2.1884 (1.9133)	loss_scale 16384.0000 (12169.3347)	mem 9463MB
[2024-07-12 13:50:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:06:24 lr 0.000012	 wd 0.0000	time 0.2218 (0.2744)	loss 0.7759 (0.8086)	grad_norm 1.9944 (1.9070)	loss_scale 16384.0000 (12552.1381)	mem 9463MB
[2024-07-12 13:51:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:53 lr 0.000012	 wd 0.0000	time 0.2324 (0.2719)	loss 0.7837 (0.8087)	grad_norm 2.0832 (1.9100)	loss_scale 16384.0000 (12871.1940)	mem 9463MB
[2024-07-12 13:51:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:05:23 lr 0.000012	 wd 0.0000	time 0.2063 (0.2693)	loss 0.8828 (0.8077)	grad_norm 1.9760 (1.9042)	loss_scale 16384.0000 (13141.2022)	mem 9463MB
[2024-07-12 13:52:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:54 lr 0.000012	 wd 0.0000	time 0.2064 (0.2671)	loss 0.8467 (0.8074)	grad_norm 1.9927 (1.9077)	loss_scale 16384.0000 (13372.6652)	mem 9463MB
[2024-07-12 13:52:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:04:27 lr 0.000012	 wd 0.0000	time 0.2045 (0.2672)	loss 0.9092 (0.8069)	grad_norm 3.1355 (1.9065)	loss_scale 16384.0000 (13573.2871)	mem 9463MB
[2024-07-12 13:52:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:59 lr 0.000012	 wd 0.0000	time 0.2369 (0.2657)	loss 0.7817 (0.8069)	grad_norm 2.2167 (1.9045)	loss_scale 16384.0000 (13748.8470)	mem 9463MB
[2024-07-12 13:53:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:31 lr 0.000011	 wd 0.0000	time 0.2075 (0.2641)	loss 0.6880 (0.8070)	grad_norm 1.7820 (1.9050)	loss_scale 16384.0000 (13903.7648)	mem 9463MB
[2024-07-12 13:53:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:03:04 lr 0.000011	 wd 0.0000	time 0.2304 (0.2627)	loss 0.8750 (0.8073)	grad_norm 1.6938 (1.9054)	loss_scale 16384.0000 (14041.4792)	mem 9463MB
[2024-07-12 13:54:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:38 lr 0.000011	 wd 0.0000	time 0.2209 (0.2630)	loss 0.7437 (0.8071)	grad_norm 1.9451 (1.9041)	loss_scale 16384.0000 (14164.7049)	mem 9463MB
[2024-07-12 13:54:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:02:11 lr 0.000011	 wd 0.0000	time 0.2252 (0.2621)	loss 0.8696 (0.8065)	grad_norm 2.3499 (1.9030)	loss_scale 16384.0000 (14275.6142)	mem 9463MB
[2024-07-12 13:54:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:44 lr 0.000011	 wd 0.0000	time 0.2263 (0.2610)	loss 0.8394 (0.8069)	grad_norm 2.6815 (1.9038)	loss_scale 16384.0000 (14375.9657)	mem 9463MB
[2024-07-12 13:55:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:18 lr 0.000011	 wd 0.0000	time 0.2487 (0.2601)	loss 0.8408 (0.8069)	grad_norm 1.5578 (1.9063)	loss_scale 16384.0000 (14467.1985)	mem 9463MB
[2024-07-12 13:55:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:52 lr 0.000011	 wd 0.0000	time 0.2260 (0.2601)	loss 0.8506 (0.8071)	grad_norm 1.9705 (inf)	loss_scale 8192.0000 (14287.0474)	mem 9463MB
[2024-07-12 13:56:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:26 lr 0.000011	 wd 0.0000	time 0.2381 (0.2596)	loss 0.8125 (0.8071)	grad_norm 1.9405 (inf)	loss_scale 8192.0000 (14033.1928)	mem 9463MB
[2024-07-12 13:56:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.2095 (0.2585)	loss 0.8325 (0.8068)	grad_norm 1.8839 (inf)	loss_scale 8192.0000 (13799.6385)	mem 9463MB
[2024-07-12 13:56:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 23 training takes 0:10:53
[2024-07-12 13:57:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 39.909 (39.909)	Loss 0.3650 (0.3650)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 13:57:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.496 Acc@5 97.570
[2024-07-12 13:57:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-12 13:57:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.54%
[2024-07-12 13:57:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][0/2502]	eta 10:44:20 lr 0.000010	 wd 0.0000	time 15.4517 (15.4517)	loss 0.7388 (0.7388)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:58:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:15:42 lr 0.000010	 wd 0.0000	time 0.2242 (0.3926)	loss 0.8496 (0.7966)	grad_norm 2.0221 (1.9381)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:58:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:12:33 lr 0.000010	 wd 0.0000	time 0.4266 (0.3275)	loss 0.8677 (0.8035)	grad_norm 1.4882 (1.9008)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:59:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:11:43 lr 0.000010	 wd 0.0000	time 0.2287 (0.3194)	loss 0.7754 (0.8026)	grad_norm 1.8201 (1.8880)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 13:59:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:10:27 lr 0.000010	 wd 0.0000	time 0.2227 (0.2984)	loss 0.8247 (0.8030)	grad_norm 1.5364 (1.8797)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:00:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:09:32 lr 0.000010	 wd 0.0000	time 0.2152 (0.2858)	loss 0.7764 (0.8041)	grad_norm 2.0258 (1.8993)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:00:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:08:54 lr 0.000010	 wd 0.0000	time 0.2738 (0.2809)	loss 0.7241 (0.8041)	grad_norm 1.8521 (1.8919)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:00:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:08:23 lr 0.000010	 wd 0.0000	time 0.2374 (0.2795)	loss 0.7275 (0.8041)	grad_norm 1.7357 (1.8960)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:01:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:07:46 lr 0.000010	 wd 0.0000	time 0.2086 (0.2741)	loss 0.7305 (0.8051)	grad_norm 1.7083 (1.8906)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:01:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:07:12 lr 0.000009	 wd 0.0000	time 0.2124 (0.2699)	loss 0.8696 (0.8053)	grad_norm 2.0712 (1.8874)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:02:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:50 lr 0.000009	 wd 0.0000	time 0.2406 (0.2732)	loss 0.8735 (0.8069)	grad_norm 1.7971 (1.8923)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:02:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:06:18 lr 0.000009	 wd 0.0000	time 0.2366 (0.2699)	loss 0.7407 (0.8051)	grad_norm 1.7378 (1.8880)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:02:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:47 lr 0.000009	 wd 0.0000	time 0.2277 (0.2672)	loss 0.6992 (0.8048)	grad_norm 2.0082 (1.8928)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:03:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:05:18 lr 0.000009	 wd 0.0000	time 0.2459 (0.2649)	loss 0.8755 (0.8057)	grad_norm 1.7886 (1.8940)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:03:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:51 lr 0.000009	 wd 0.0000	time 0.3165 (0.2641)	loss 0.8511 (0.8061)	grad_norm 2.1592 (1.8893)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:04:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:23 lr 0.000009	 wd 0.0000	time 0.2158 (0.2629)	loss 0.6743 (0.8065)	grad_norm 1.8007 (1.8833)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:04:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:55 lr 0.000009	 wd 0.0000	time 0.2154 (0.2615)	loss 0.7827 (0.8064)	grad_norm 2.0782 (1.8799)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:05:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:28 lr 0.000008	 wd 0.0000	time 0.2212 (0.2601)	loss 0.8232 (0.8070)	grad_norm 1.5649 (1.8794)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:05:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:03:02 lr 0.000008	 wd 0.0000	time 0.2308 (0.2600)	loss 0.7495 (0.8065)	grad_norm 2.2382 (1.8779)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:05:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:36 lr 0.000008	 wd 0.0000	time 0.2257 (0.2593)	loss 0.6011 (0.8068)	grad_norm 1.9180 (1.8796)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:06:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:02:09 lr 0.000008	 wd 0.0000	time 0.2064 (0.2583)	loss 0.8784 (0.8062)	grad_norm 2.1070 (1.8832)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:06:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:43 lr 0.000008	 wd 0.0000	time 0.2085 (0.2574)	loss 0.7583 (0.8057)	grad_norm 2.2409 (1.8840)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:07:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:17 lr 0.000008	 wd 0.0000	time 0.4040 (0.2576)	loss 0.8477 (0.8054)	grad_norm 2.0222 (1.8875)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:07:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:52 lr 0.000008	 wd 0.0000	time 0.2066 (0.2575)	loss 0.9058 (0.8057)	grad_norm 1.9033 (1.8884)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:07:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:26 lr 0.000008	 wd 0.0000	time 0.2060 (0.2567)	loss 0.9438 (0.8057)	grad_norm 1.6084 (1.8860)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:08:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.2180 (0.2557)	loss 0.9067 (0.8059)	grad_norm 1.6338 (1.8852)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:08:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 24 training takes 0:10:49
[2024-07-12 14:09:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 36.797 (36.797)	Loss 0.3660 (0.3660)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 14:09:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.574 Acc@5 97.562
[2024-07-12 14:09:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.6%
[2024-07-12 14:09:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.57%
[2024-07-12 14:09:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 160): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_best.pth saving......
[2024-07-12 14:09:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 162): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_best.pth saved !!!
[2024-07-12 14:09:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][0/2502]	eta 11:11:28 lr 0.000008	 wd 0.0000	time 16.1027 (16.1027)	loss 0.7817 (0.7817)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:10:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:16:09 lr 0.000008	 wd 0.0000	time 0.2842 (0.4035)	loss 0.8511 (0.8028)	grad_norm 1.8697 (1.8990)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:10:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:13:05 lr 0.000007	 wd 0.0000	time 0.2234 (0.3412)	loss 0.7437 (0.8035)	grad_norm 1.6573 (1.9201)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:10:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:11:13 lr 0.000007	 wd 0.0000	time 0.2234 (0.3058)	loss 0.8643 (0.8056)	grad_norm 1.6968 (1.9085)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:11:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:10:05 lr 0.000007	 wd 0.0000	time 0.2230 (0.2880)	loss 0.8647 (0.8039)	grad_norm 2.0557 (1.9056)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:11:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:09:18 lr 0.000007	 wd 0.0000	time 0.2216 (0.2790)	loss 0.7563 (0.8049)	grad_norm 1.6112 (1.8965)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:12:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:38 lr 0.000007	 wd 0.0000	time 0.2222 (0.2725)	loss 0.8237 (0.8059)	grad_norm 1.6418 (1.9027)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:12:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:08:02 lr 0.000007	 wd 0.0000	time 0.2177 (0.2675)	loss 0.8071 (0.8049)	grad_norm 1.8812 (1.8967)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:12:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:07:28 lr 0.000007	 wd 0.0000	time 0.2302 (0.2636)	loss 0.8560 (0.8046)	grad_norm 2.0191 (1.8991)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:13:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:06:58 lr 0.000007	 wd 0.0000	time 0.2518 (0.2615)	loss 0.7705 (0.8041)	grad_norm 1.5892 (1.9005)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:13:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:31 lr 0.000007	 wd 0.0000	time 0.2499 (0.2608)	loss 0.9019 (0.8038)	grad_norm 2.0602 (1.9001)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:14:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:06:02 lr 0.000007	 wd 0.0000	time 0.2268 (0.2588)	loss 0.7563 (0.8034)	grad_norm 1.7252 (1.8990)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:14:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:34 lr 0.000006	 wd 0.0000	time 0.2068 (0.2570)	loss 1.0107 (0.8045)	grad_norm 1.9549 (1.8964)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:14:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:05:07 lr 0.000006	 wd 0.0000	time 0.2331 (0.2560)	loss 0.7930 (0.8045)	grad_norm 1.4069 (1.8952)	loss_scale 16384.0000 (8683.1422)	mem 9463MB
[2024-07-12 14:15:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:42 lr 0.000006	 wd 0.0000	time 0.2317 (0.2562)	loss 0.7993 (0.8043)	grad_norm 1.8278 (1.8946)	loss_scale 16384.0000 (9232.8108)	mem 9463MB
[2024-07-12 14:15:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:04:15 lr 0.000006	 wd 0.0000	time 0.2347 (0.2550)	loss 0.8525 (0.8045)	grad_norm 1.6159 (1.8958)	loss_scale 16384.0000 (9709.2392)	mem 9463MB
[2024-07-12 14:16:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:49 lr 0.000006	 wd 0.0000	time 0.2270 (0.2539)	loss 0.8457 (0.8041)	grad_norm 1.7024 (1.8924)	loss_scale 16384.0000 (10126.1512)	mem 9463MB
[2024-07-12 14:16:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:23 lr 0.000006	 wd 0.0000	time 0.2238 (0.2532)	loss 0.7959 (0.8036)	grad_norm 2.0516 (1.8908)	loss_scale 16384.0000 (10494.0435)	mem 9463MB
[2024-07-12 14:17:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:58 lr 0.000006	 wd 0.0000	time 0.2248 (0.2540)	loss 0.9976 (0.8044)	grad_norm 2.3480 (1.8855)	loss_scale 16384.0000 (10821.0816)	mem 9463MB
[2024-07-12 14:17:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:32 lr 0.000006	 wd 0.0000	time 0.2265 (0.2533)	loss 1.1260 (0.8048)	grad_norm 1.6433 (1.8899)	loss_scale 16384.0000 (11113.7128)	mem 9463MB
[2024-07-12 14:17:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:02:06 lr 0.000006	 wd 0.0000	time 0.2324 (0.2527)	loss 0.8457 (0.8047)	grad_norm 1.9226 (1.8888)	loss_scale 16384.0000 (11377.0955)	mem 9463MB
[2024-07-12 14:18:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:41 lr 0.000006	 wd 0.0000	time 0.2242 (0.2522)	loss 0.8438 (0.8048)	grad_norm 1.3780 (1.8876)	loss_scale 16384.0000 (11615.4060)	mem 9463MB
[2024-07-12 14:18:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:16 lr 0.000006	 wd 0.0000	time 0.2566 (0.2530)	loss 0.7119 (0.8041)	grad_norm 2.0912 (1.8872)	loss_scale 16384.0000 (11832.0618)	mem 9463MB
[2024-07-12 14:19:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:51 lr 0.000005	 wd 0.0000	time 0.2299 (0.2525)	loss 0.7695 (0.8039)	grad_norm 1.3202 (1.8902)	loss_scale 16384.0000 (12029.8861)	mem 9463MB
[2024-07-12 14:19:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:25 lr 0.000005	 wd 0.0000	time 0.2329 (0.2519)	loss 0.7866 (0.8037)	grad_norm 1.7864 (1.8897)	loss_scale 16384.0000 (12211.2320)	mem 9463MB
[2024-07-12 14:19:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000005	 wd 0.0000	time 0.2131 (0.2512)	loss 0.7588 (0.8034)	grad_norm 1.8654 (1.8873)	loss_scale 16384.0000 (12378.0760)	mem 9463MB
[2024-07-12 14:20:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 25 training takes 0:10:43
[2024-07-12 14:21:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 60.321 (60.321)	Loss 0.3645 (0.3645)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 14:21:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.560 Acc@5 97.570
[2024-07-12 14:21:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.6%
[2024-07-12 14:21:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.57%
[2024-07-12 14:22:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][0/2502]	eta 23:21:33 lr 0.000005	 wd 0.0000	time 33.6106 (33.6106)	loss 0.7656 (0.7656)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9463MB
[2024-07-12 14:22:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:23:08 lr 0.000005	 wd 0.0000	time 0.2201 (0.5780)	loss 0.9058 (0.8060)	grad_norm 1.8999 (inf)	loss_scale 8192.0000 (16059.5644)	mem 9463MB
[2024-07-12 14:22:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:15:42 lr 0.000005	 wd 0.0000	time 0.2223 (0.4096)	loss 0.8257 (0.8046)	grad_norm 3.5685 (inf)	loss_scale 8192.0000 (12145.3532)	mem 9463MB
[2024-07-12 14:23:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:13:02 lr 0.000005	 wd 0.0000	time 0.2044 (0.3551)	loss 0.7534 (0.8053)	grad_norm 1.8417 (inf)	loss_scale 8192.0000 (10831.9468)	mem 9463MB
[2024-07-12 14:23:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:11:23 lr 0.000005	 wd 0.0000	time 0.2158 (0.3252)	loss 0.8472 (0.8038)	grad_norm 1.7374 (inf)	loss_scale 8192.0000 (10173.6060)	mem 9463MB
[2024-07-12 14:24:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:10:15 lr 0.000005	 wd 0.0000	time 0.2271 (0.3072)	loss 0.9370 (0.8049)	grad_norm 2.0416 (inf)	loss_scale 8192.0000 (9778.0758)	mem 9463MB
[2024-07-12 14:24:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:09:22 lr 0.000005	 wd 0.0000	time 0.2290 (0.2955)	loss 0.8071 (0.8050)	grad_norm 2.0315 (inf)	loss_scale 8192.0000 (9514.1697)	mem 9463MB
[2024-07-12 14:24:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:08:42 lr 0.000005	 wd 0.0000	time 0.2190 (0.2900)	loss 0.9731 (0.8038)	grad_norm 1.8887 (inf)	loss_scale 8192.0000 (9325.5578)	mem 9463MB
[2024-07-12 14:25:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:08:02 lr 0.000005	 wd 0.0000	time 0.2063 (0.2837)	loss 0.7661 (0.8036)	grad_norm 1.7396 (inf)	loss_scale 8192.0000 (9184.0400)	mem 9463MB
[2024-07-12 14:25:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:07:26 lr 0.000005	 wd 0.0000	time 0.2284 (0.2786)	loss 0.8320 (0.8030)	grad_norm 1.9516 (inf)	loss_scale 8192.0000 (9073.9356)	mem 9463MB
[2024-07-12 14:26:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:52 lr 0.000004	 wd 0.0000	time 0.2594 (0.2748)	loss 0.9253 (0.8034)	grad_norm 1.5940 (inf)	loss_scale 8192.0000 (8985.8302)	mem 9463MB
[2024-07-12 14:26:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:06:22 lr 0.000004	 wd 0.0000	time 0.2667 (0.2730)	loss 0.8086 (0.8030)	grad_norm 1.9334 (inf)	loss_scale 8192.0000 (8913.7293)	mem 9463MB
[2024-07-12 14:26:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:52 lr 0.000004	 wd 0.0000	time 0.2273 (0.2705)	loss 0.7207 (0.8038)	grad_norm 1.7800 (inf)	loss_scale 8192.0000 (8853.6353)	mem 9463MB
[2024-07-12 14:27:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:05:22 lr 0.000004	 wd 0.0000	time 0.2364 (0.2681)	loss 0.7471 (0.8038)	grad_norm 1.9757 (inf)	loss_scale 8192.0000 (8802.7794)	mem 9463MB
[2024-07-12 14:27:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:53 lr 0.000004	 wd 0.0000	time 0.2234 (0.2661)	loss 0.8867 (0.8041)	grad_norm 1.8432 (inf)	loss_scale 8192.0000 (8759.1834)	mem 9463MB
[2024-07-12 14:28:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:04:25 lr 0.000004	 wd 0.0000	time 0.2573 (0.2653)	loss 0.7412 (0.8045)	grad_norm 1.9058 (inf)	loss_scale 8192.0000 (8721.3964)	mem 9463MB
[2024-07-12 14:28:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:58 lr 0.000004	 wd 0.0000	time 0.2119 (0.2639)	loss 0.7285 (0.8035)	grad_norm 2.1195 (inf)	loss_scale 8192.0000 (8688.3298)	mem 9463MB
[2024-07-12 14:28:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:30 lr 0.000004	 wd 0.0000	time 0.2290 (0.2625)	loss 0.7207 (0.8030)	grad_norm 2.5645 (inf)	loss_scale 8192.0000 (8659.1511)	mem 9463MB
[2024-07-12 14:29:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:03:03 lr 0.000004	 wd 0.0000	time 0.2240 (0.2612)	loss 0.7749 (0.8030)	grad_norm 1.5465 (inf)	loss_scale 8192.0000 (8633.2127)	mem 9463MB
[2024-07-12 14:29:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:37 lr 0.000004	 wd 0.0000	time 0.2203 (0.2615)	loss 0.7168 (0.8030)	grad_norm 2.0780 (inf)	loss_scale 8192.0000 (8610.0032)	mem 9463MB
[2024-07-12 14:30:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:02:10 lr 0.000004	 wd 0.0000	time 0.2192 (0.2608)	loss 0.8096 (0.8030)	grad_norm 1.6074 (inf)	loss_scale 8192.0000 (8589.1134)	mem 9463MB
[2024-07-12 14:30:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:44 lr 0.000004	 wd 0.0000	time 0.2221 (0.2598)	loss 0.8394 (0.8032)	grad_norm 1.6868 (inf)	loss_scale 8192.0000 (8570.2123)	mem 9463MB
[2024-07-12 14:31:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:18 lr 0.000004	 wd 0.0000	time 0.2165 (0.2590)	loss 0.7866 (0.8032)	grad_norm 1.7562 (inf)	loss_scale 8192.0000 (8553.0286)	mem 9463MB
[2024-07-12 14:31:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:52 lr 0.000004	 wd 0.0000	time 0.2320 (0.2589)	loss 0.7554 (0.8035)	grad_norm 1.8903 (inf)	loss_scale 8192.0000 (8537.3385)	mem 9463MB
[2024-07-12 14:31:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:26 lr 0.000003	 wd 0.0000	time 0.2200 (0.2583)	loss 0.8145 (0.8038)	grad_norm 1.7184 (inf)	loss_scale 8192.0000 (8522.9554)	mem 9463MB
[2024-07-12 14:32:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.2079 (0.2572)	loss 0.7329 (0.8044)	grad_norm 2.9232 (inf)	loss_scale 8192.0000 (8509.7225)	mem 9463MB
[2024-07-12 14:32:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 26 training takes 0:10:50
[2024-07-12 14:32:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 35.527 (35.527)	Loss 0.3652 (0.3652)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 14:33:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.588 Acc@5 97.572
[2024-07-12 14:33:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.6%
[2024-07-12 14:33:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.59%
[2024-07-12 14:33:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 160): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_best.pth saving......
[2024-07-12 14:33:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 162): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_best.pth saved !!!
[2024-07-12 14:33:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][0/2502]	eta 10:04:57 lr 0.000003	 wd 0.0000	time 14.5075 (14.5075)	loss 0.7339 (0.7339)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:33:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:15:10 lr 0.000003	 wd 0.0000	time 0.2173 (0.3793)	loss 0.8340 (0.8062)	grad_norm 1.9668 (1.8858)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:34:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:11:59 lr 0.000003	 wd 0.0000	time 0.2568 (0.3125)	loss 0.8145 (0.8044)	grad_norm 1.8455 (1.9067)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:34:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:11:08 lr 0.000003	 wd 0.0000	time 0.2417 (0.3036)	loss 0.7998 (0.7996)	grad_norm 1.7833 (1.9093)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:35:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:10:02 lr 0.000003	 wd 0.0000	time 0.2136 (0.2865)	loss 0.7959 (0.7998)	grad_norm 1.6481 (1.8856)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:35:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:09:12 lr 0.000003	 wd 0.0000	time 0.2296 (0.2761)	loss 0.7324 (0.7976)	grad_norm 1.6271 (1.8725)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:36:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:36 lr 0.000003	 wd 0.0000	time 0.2776 (0.2718)	loss 0.7388 (0.8006)	grad_norm 1.8458 (inf)	loss_scale 4096.0000 (8123.8469)	mem 9463MB
[2024-07-12 14:36:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:08:12 lr 0.000003	 wd 0.0000	time 0.2188 (0.2735)	loss 0.8203 (0.8027)	grad_norm 2.0636 (inf)	loss_scale 4096.0000 (7549.2611)	mem 9463MB
[2024-07-12 14:36:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:37 lr 0.000003	 wd 0.0000	time 0.2426 (0.2689)	loss 0.8647 (0.8012)	grad_norm 1.7843 (inf)	loss_scale 4096.0000 (7118.1423)	mem 9463MB
[2024-07-12 14:37:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:07:05 lr 0.000003	 wd 0.0000	time 0.2186 (0.2653)	loss 0.7710 (0.8031)	grad_norm 1.9761 (inf)	loss_scale 4096.0000 (6782.7214)	mem 9463MB
[2024-07-12 14:37:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:35 lr 0.000003	 wd 0.0000	time 0.2221 (0.2635)	loss 0.9165 (0.8021)	grad_norm 2.0266 (inf)	loss_scale 4096.0000 (6514.3177)	mem 9463MB
[2024-07-12 14:38:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:06:08 lr 0.000003	 wd 0.0000	time 0.2171 (0.2628)	loss 0.7246 (0.8027)	grad_norm 2.7117 (inf)	loss_scale 4096.0000 (6294.6703)	mem 9463MB
[2024-07-12 14:38:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:39 lr 0.000003	 wd 0.0000	time 0.2383 (0.2608)	loss 0.7769 (0.8022)	grad_norm 1.9862 (inf)	loss_scale 4096.0000 (6111.6003)	mem 9463MB
[2024-07-12 14:38:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:05:11 lr 0.000003	 wd 0.0000	time 0.2498 (0.2590)	loss 0.8228 (0.8022)	grad_norm 2.1251 (inf)	loss_scale 4096.0000 (5956.6733)	mem 9463MB
[2024-07-12 14:39:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:44 lr 0.000003	 wd 0.0000	time 0.2293 (0.2580)	loss 0.7124 (0.8023)	grad_norm 1.8958 (inf)	loss_scale 4096.0000 (5823.8630)	mem 9463MB
[2024-07-12 14:39:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:04:18 lr 0.000003	 wd 0.0000	time 0.2313 (0.2580)	loss 0.8477 (0.8028)	grad_norm 1.9982 (inf)	loss_scale 4096.0000 (5708.7488)	mem 9463MB
[2024-07-12 14:40:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:51 lr 0.000003	 wd 0.0000	time 0.2215 (0.2568)	loss 0.7817 (0.8034)	grad_norm 1.6554 (inf)	loss_scale 4096.0000 (5608.0150)	mem 9463MB
[2024-07-12 14:40:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:25 lr 0.000002	 wd 0.0000	time 0.2052 (0.2557)	loss 0.8940 (0.8030)	grad_norm 1.7435 (inf)	loss_scale 4096.0000 (5519.1252)	mem 9463MB
[2024-07-12 14:40:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:59 lr 0.000002	 wd 0.0000	time 0.2136 (0.2550)	loss 0.7710 (0.8030)	grad_norm 1.9408 (inf)	loss_scale 4096.0000 (5440.1066)	mem 9463MB
[2024-07-12 14:41:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:33 lr 0.000002	 wd 0.0000	time 0.2147 (0.2556)	loss 0.8599 (0.8030)	grad_norm 1.6487 (inf)	loss_scale 4096.0000 (5369.4014)	mem 9463MB
[2024-07-12 14:41:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:02:07 lr 0.000002	 wd 0.0000	time 0.2066 (0.2550)	loss 0.6743 (0.8028)	grad_norm 1.8791 (inf)	loss_scale 4096.0000 (5305.7631)	mem 9463MB
[2024-07-12 14:42:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:42 lr 0.000002	 wd 0.0000	time 0.2218 (0.2542)	loss 0.9531 (0.8040)	grad_norm 2.0577 (inf)	loss_scale 4096.0000 (5248.1828)	mem 9463MB
[2024-07-12 14:42:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:16 lr 0.000002	 wd 0.0000	time 0.4602 (0.2544)	loss 0.7368 (0.8039)	grad_norm 1.7847 (inf)	loss_scale 4096.0000 (5195.8346)	mem 9463MB
[2024-07-12 14:43:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:51 lr 0.000002	 wd 0.0000	time 0.2315 (0.2541)	loss 0.8457 (0.8042)	grad_norm 1.7064 (inf)	loss_scale 4096.0000 (5148.0365)	mem 9463MB
[2024-07-12 14:43:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:25 lr 0.000002	 wd 0.0000	time 0.2303 (0.2536)	loss 0.8335 (0.8041)	grad_norm 1.8297 (inf)	loss_scale 4096.0000 (5104.2199)	mem 9463MB
[2024-07-12 14:43:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.2086 (0.2527)	loss 0.7163 (0.8045)	grad_norm 1.6223 (inf)	loss_scale 4096.0000 (5063.9072)	mem 9463MB
[2024-07-12 14:43:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 27 training takes 0:10:40
[2024-07-12 14:44:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 35.553 (35.553)	Loss 0.3638 (0.3638)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 14:44:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.580 Acc@5 97.574
[2024-07-12 14:44:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.6%
[2024-07-12 14:44:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.59%
[2024-07-12 14:45:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][0/2502]	eta 11:03:28 lr 0.000002	 wd 0.0000	time 15.9107 (15.9107)	loss 0.8013 (0.8013)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:45:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:15:53 lr 0.000002	 wd 0.0000	time 0.2123 (0.3971)	loss 0.8223 (0.8126)	grad_norm 1.8947 (1.8424)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:46:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:13:56 lr 0.000002	 wd 0.0000	time 0.2061 (0.3632)	loss 0.8940 (0.8073)	grad_norm 2.6194 (1.8335)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:46:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:11:46 lr 0.000002	 wd 0.0000	time 0.2068 (0.3208)	loss 0.8384 (0.8076)	grad_norm 1.3337 (1.8313)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:46:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:10:29 lr 0.000002	 wd 0.0000	time 0.2211 (0.2994)	loss 0.7139 (0.8059)	grad_norm 1.7101 (1.8398)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:47:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:09:36 lr 0.000002	 wd 0.0000	time 0.2277 (0.2879)	loss 0.9390 (0.8069)	grad_norm 1.7534 (1.8451)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:47:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:52 lr 0.000002	 wd 0.0000	time 0.2056 (0.2798)	loss 0.8062 (0.8063)	grad_norm 1.4618 (1.8467)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:48:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:08:13 lr 0.000002	 wd 0.0000	time 0.2189 (0.2737)	loss 0.7627 (0.8049)	grad_norm 2.2808 (1.8601)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:48:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:38 lr 0.000002	 wd 0.0000	time 0.2451 (0.2694)	loss 0.7925 (0.8040)	grad_norm 1.9684 (1.8662)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:48:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:07:06 lr 0.000002	 wd 0.0000	time 0.2436 (0.2663)	loss 0.8530 (0.8027)	grad_norm 2.4788 (1.8632)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:49:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:37 lr 0.000002	 wd 0.0000	time 0.2196 (0.2646)	loss 0.8726 (0.8022)	grad_norm 1.6988 (1.8658)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:49:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:06:07 lr 0.000002	 wd 0.0000	time 0.2281 (0.2624)	loss 0.7769 (0.8019)	grad_norm 2.1239 (1.8580)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:50:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:38 lr 0.000002	 wd 0.0000	time 0.2049 (0.2602)	loss 0.8916 (0.8011)	grad_norm 2.2844 (1.8605)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:50:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:05:11 lr 0.000002	 wd 0.0000	time 0.2626 (0.2589)	loss 0.7407 (0.8010)	grad_norm 1.7892 (1.8600)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:50:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:45 lr 0.000002	 wd 0.0000	time 0.2107 (0.2591)	loss 0.7554 (0.8010)	grad_norm 1.8696 (1.8601)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:51:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:04:18 lr 0.000002	 wd 0.0000	time 0.2048 (0.2580)	loss 0.7832 (0.8010)	grad_norm 1.6009 (1.8646)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:51:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:51 lr 0.000002	 wd 0.0000	time 0.2186 (0.2568)	loss 0.7070 (0.8014)	grad_norm 1.6848 (1.8676)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:52:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:25 lr 0.000001	 wd 0.0000	time 0.2182 (0.2559)	loss 0.6982 (0.8016)	grad_norm 1.7291 (1.8670)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:52:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:03:00 lr 0.000001	 wd 0.0000	time 0.2341 (0.2566)	loss 0.6929 (0.8017)	grad_norm 2.4842 (1.8698)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:53:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:33 lr 0.000001	 wd 0.0000	time 0.2541 (0.2558)	loss 0.8433 (0.8019)	grad_norm 1.5563 (1.8722)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:53:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:02:08 lr 0.000001	 wd 0.0000	time 0.2397 (0.2550)	loss 0.7896 (0.8018)	grad_norm 1.7078 (1.8709)	loss_scale 4096.0000 (4096.0000)	mem 9463MB
[2024-07-12 14:53:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:42 lr 0.000001	 wd 0.0000	time 0.2278 (0.2544)	loss 0.8716 (0.8021)	grad_norm 1.9090 (1.8688)	loss_scale 8192.0000 (4119.3946)	mem 9463MB
[2024-07-12 14:54:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:17 lr 0.000001	 wd 0.0000	time 0.2489 (0.2550)	loss 0.9141 (0.8021)	grad_norm 1.6865 (1.8703)	loss_scale 8192.0000 (4304.4289)	mem 9463MB
[2024-07-12 14:54:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:51 lr 0.000001	 wd 0.0000	time 0.2240 (0.2544)	loss 0.7651 (0.8025)	grad_norm 2.4109 (1.8723)	loss_scale 8192.0000 (4473.3803)	mem 9463MB
[2024-07-12 14:55:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:25 lr 0.000001	 wd 0.0000	time 0.2219 (0.2538)	loss 0.8628 (0.8027)	grad_norm 2.2426 (1.8690)	loss_scale 8192.0000 (4628.2582)	mem 9463MB
[2024-07-12 14:55:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.2199 (0.2529)	loss 0.7793 (0.8032)	grad_norm 1.8998 (1.8688)	loss_scale 8192.0000 (4770.7509)	mem 9463MB
[2024-07-12 14:55:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 28 training takes 0:10:41
[2024-07-12 14:56:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 37.024 (37.024)	Loss 0.3638 (0.3638)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 14:56:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.580 Acc@5 97.576
[2024-07-12 14:56:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.6%
[2024-07-12 14:56:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.59%
[2024-07-12 14:56:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][0/2502]	eta 11:46:14 lr 0.000001	 wd 0.0000	time 16.9363 (16.9363)	loss 0.7788 (0.7788)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:57:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:16:50 lr 0.000001	 wd 0.0000	time 0.2133 (0.4206)	loss 0.8833 (0.8052)	grad_norm 1.9067 (1.7824)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:57:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:12:36 lr 0.000001	 wd 0.0000	time 0.2238 (0.3287)	loss 0.7720 (0.8127)	grad_norm 1.6579 (1.8244)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:58:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:10:55 lr 0.000001	 wd 0.0000	time 0.2145 (0.2975)	loss 0.8018 (0.8078)	grad_norm 2.6590 (1.8496)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:58:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:09:52 lr 0.000001	 wd 0.0000	time 0.2255 (0.2818)	loss 0.7197 (0.8088)	grad_norm 1.9424 (1.8534)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:58:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:09:08 lr 0.000001	 wd 0.0000	time 0.3308 (0.2741)	loss 0.7725 (0.8074)	grad_norm 1.6833 (1.8708)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:59:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:30 lr 0.000001	 wd 0.0000	time 0.2240 (0.2685)	loss 0.7583 (0.8047)	grad_norm 1.4978 (1.8633)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 14:59:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:56 lr 0.000001	 wd 0.0000	time 0.2307 (0.2642)	loss 0.9272 (0.8035)	grad_norm 1.6323 (1.8505)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:00:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:07:23 lr 0.000001	 wd 0.0000	time 0.2247 (0.2607)	loss 0.6924 (0.8054)	grad_norm 1.8553 (1.8519)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:00:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:06:55 lr 0.000001	 wd 0.0000	time 0.2291 (0.2592)	loss 0.8291 (0.8047)	grad_norm 1.9467 (1.8522)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:00:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:28 lr 0.000001	 wd 0.0000	time 0.2313 (0.2589)	loss 0.7183 (0.8041)	grad_norm 1.4613 (1.8506)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:01:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:06:00 lr 0.000001	 wd 0.0000	time 0.2261 (0.2571)	loss 0.8027 (0.8047)	grad_norm 1.9022 (1.8476)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:01:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:32 lr 0.000001	 wd 0.0000	time 0.2463 (0.2555)	loss 0.7671 (0.8036)	grad_norm 1.7327 (1.8486)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:02:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:05:07 lr 0.000001	 wd 0.0000	time 0.2046 (0.2562)	loss 0.7212 (0.8047)	grad_norm 1.8325 (1.8487)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:02:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:41 lr 0.000001	 wd 0.0000	time 0.2205 (0.2555)	loss 0.9077 (0.8051)	grad_norm 1.6679 (1.8475)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:02:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:04:14 lr 0.000001	 wd 0.0000	time 0.2088 (0.2544)	loss 0.7363 (0.8046)	grad_norm 1.7235 (1.8455)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:03:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:48 lr 0.000001	 wd 0.0000	time 0.2273 (0.2535)	loss 0.7881 (0.8044)	grad_norm 1.7615 (1.8497)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:03:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:23 lr 0.000001	 wd 0.0000	time 0.2097 (0.2538)	loss 1.0049 (0.8050)	grad_norm 1.6258 (1.8529)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:04:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:57 lr 0.000001	 wd 0.0000	time 0.2270 (0.2536)	loss 0.6821 (0.8053)	grad_norm 1.6134 (1.8551)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:04:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:32 lr 0.000001	 wd 0.0000	time 0.2235 (0.2528)	loss 0.7505 (0.8060)	grad_norm 1.8665 (1.8549)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:04:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:02:06 lr 0.000001	 wd 0.0000	time 0.2350 (0.2522)	loss 0.8555 (0.8060)	grad_norm 1.6927 (1.8552)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:05:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:41 lr 0.000001	 wd 0.0000	time 0.2116 (0.2526)	loss 0.8306 (0.8060)	grad_norm 1.7827 (1.8534)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:05:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:16 lr 0.000001	 wd 0.0000	time 0.2373 (0.2526)	loss 0.9551 (0.8056)	grad_norm 1.5206 (1.8529)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:06:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:50 lr 0.000001	 wd 0.0000	time 0.2115 (0.2521)	loss 0.7881 (0.8055)	grad_norm 1.8167 (1.8536)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:06:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:25 lr 0.000001	 wd 0.0000	time 0.2344 (0.2516)	loss 0.7866 (0.8057)	grad_norm 1.8402 (1.8501)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:06:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.2160 (0.2508)	loss 0.9521 (0.8056)	grad_norm 1.5703 (1.8498)	loss_scale 8192.0000 (8192.0000)	mem 9463MB
[2024-07-12 15:07:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 29 training takes 0:10:41
[2024-07-12 15:07:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 145): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_29.pth saving......
[2024-07-12 15:07:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 147): INFO pretrain/vcnu_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_convnext_b_22kto1k_step_crosslayer1/ckpt_epoch_29.pth saved !!!
[2024-07-12 15:07:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 22.771 (22.771)	Loss 0.3633 (0.3633)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 9463MB
[2024-07-12 15:07:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.574 Acc@5 97.574
[2024-07-12 15:07:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.6%
[2024-07-12 15:07:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.59%
[2024-07-12 15:07:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 189): INFO Training time 5:46:26
