[2024-07-29 08:52:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 366): INFO Full config saved to pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune/diffusion_ft_conv_b_sequence_stage3/config.json
[2024-07-29 08:52:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: convnext_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 27
    - 3
    DIMS:
    - 128
    - 256
    - 512
    - 1024
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: sequence_stage2
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune/diffusion_ft_conv_b_sequence_stage3
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_conv_b_sequence_stage3
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 0.0001
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: false
  EPOCHS: 30
  LAYER_DECAY: 0.8
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.0e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 1.0e-08

[2024-07-29 08:52:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/diffusion_finetune/convnext/convnext/diffusion_ft_convnext_base_224_22kto1k_sequence_stage_process3.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/diffusion-ft", "tag": "diffusion_ft_conv_b_sequence_stage3", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-29 08:53:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 108): INFO Creating model:convnext_diffusion_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune
[2024-07-29 08:53:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 110): INFO ConvNeXt_Diffusion_Finetune(
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (3): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (4): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (5): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (6): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (7): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (8): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (9): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (10): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (11): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (12): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (13): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (14): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (15): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (16): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (17): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (18): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (19): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (20): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (21): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (22): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (23): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (24): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (25): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (26): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-29 08:53:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 113): INFO number of params: 88591464
[2024-07-29 08:53:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 150): INFO no checkpoint found in pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune/diffusion_ft_conv_b_sequence_stage3, ignoring auto resume
[2024-07-29 08:53:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth for fine-tuning......
[2024-07-29 08:53:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (utils.py 127): WARNING <All keys matched successfully>
[2024-07-29 08:53:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth'
[2024-07-29 08:54:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 72.059 (72.059)	Loss 0.3613 (0.3613)	Acc@1 91.797 (91.797)	Acc@5 98.438 (98.438)	Mem 3484MB
[2024-07-29 08:54:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 85.606 Acc@5 97.588
[2024-07-29 08:54:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 162): INFO Accuracy of the network on the 50000 test images: 85.6%
[2024-07-29 08:54:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 168): INFO Start training
[2024-07-29 08:55:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][0/2502]	eta 13:30:19 lr 0.000100	 wd 0.0000	time 19.4321 (19.4321)	loss 0.7329 (0.7329)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 11634MB
[2024-07-29 08:55:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:21:01 lr 0.000100	 wd 0.0000	time 0.3018 (0.5253)	loss 0.7910 (0.7657)	grad_norm 1.8317 (nan)	loss_scale 16384.0000 (17195.0891)	mem 11634MB
[2024-07-29 08:56:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:16:24 lr 0.000100	 wd 0.0000	time 0.2869 (0.4278)	loss 0.7266 (0.7780)	grad_norm 2.7495 (nan)	loss_scale 16384.0000 (16791.5622)	mem 11634MB
[2024-07-29 08:56:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:14:28 lr 0.000100	 wd 0.0000	time 0.2980 (0.3944)	loss 0.7588 (0.7828)	grad_norm 2.3107 (nan)	loss_scale 16384.0000 (16656.1595)	mem 11634MB
[2024-07-29 08:57:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:13:14 lr 0.000100	 wd 0.0000	time 0.2927 (0.3778)	loss 1.0342 (0.7851)	grad_norm 2.7083 (nan)	loss_scale 16384.0000 (16588.2893)	mem 11634MB
[2024-07-29 08:57:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:12:16 lr 0.000100	 wd 0.0000	time 0.3152 (0.3680)	loss 0.7100 (0.7855)	grad_norm 3.1860 (nan)	loss_scale 16384.0000 (16547.5130)	mem 11634MB
[2024-07-29 08:58:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:11:26 lr 0.000100	 wd 0.0000	time 0.3174 (0.3611)	loss 0.6860 (0.7864)	grad_norm 1.7106 (nan)	loss_scale 16384.0000 (16520.3062)	mem 11634MB
[2024-07-29 08:58:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:10:42 lr 0.000100	 wd 0.0000	time 0.3030 (0.3566)	loss 0.8242 (0.7879)	grad_norm 3.3695 (nan)	loss_scale 16384.0000 (16500.8616)	mem 11634MB
[2024-07-29 08:59:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:10:01 lr 0.000100	 wd 0.0000	time 0.3047 (0.3536)	loss 0.7827 (0.7877)	grad_norm 1.8605 (nan)	loss_scale 16384.0000 (16486.2722)	mem 11634MB
[2024-07-29 08:59:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:09:21 lr 0.000100	 wd 0.0000	time 0.3148 (0.3508)	loss 0.7690 (0.7876)	grad_norm 1.7786 (nan)	loss_scale 16384.0000 (16474.9212)	mem 11634MB
[2024-07-29 09:00:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:08:43 lr 0.000100	 wd 0.0000	time 0.3039 (0.3486)	loss 0.8916 (0.7881)	grad_norm 1.8846 (nan)	loss_scale 16384.0000 (16465.8382)	mem 11634MB
[2024-07-29 09:02:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:09:46 lr 0.000100	 wd 0.0000	time 0.3259 (0.4182)	loss 0.7012 (0.7886)	grad_norm 1.7099 (nan)	loss_scale 16384.0000 (16458.4051)	mem 11634MB
[2024-07-29 09:02:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:08:55 lr 0.000100	 wd 0.0000	time 0.3279 (0.4111)	loss 0.7505 (0.7892)	grad_norm 1.4671 (nan)	loss_scale 16384.0000 (16452.2098)	mem 11634MB
[2024-07-29 09:03:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:08:06 lr 0.000100	 wd 0.0000	time 0.3395 (0.4047)	loss 0.6743 (0.7903)	grad_norm 2.0365 (nan)	loss_scale 16384.0000 (16446.9669)	mem 11634MB
[2024-07-29 09:04:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:07:20 lr 0.000100	 wd 0.0000	time 0.2838 (0.3994)	loss 0.7827 (0.7903)	grad_norm 2.1481 (nan)	loss_scale 16384.0000 (16442.4725)	mem 11634MB
[2024-07-29 09:04:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:06:35 lr 0.000100	 wd 0.0000	time 0.3025 (0.3947)	loss 0.8501 (0.7904)	grad_norm 2.1016 (nan)	loss_scale 16384.0000 (16438.5769)	mem 11634MB
[2024-07-29 09:05:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:05:52 lr 0.000100	 wd 0.0000	time 0.2987 (0.3904)	loss 0.8389 (0.7900)	grad_norm 1.8490 (nan)	loss_scale 16384.0000 (16435.1680)	mem 11634MB
[2024-07-29 09:05:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:05:10 lr 0.000100	 wd 0.0000	time 0.2927 (0.3873)	loss 0.6797 (0.7900)	grad_norm 2.0269 (nan)	loss_scale 16384.0000 (16432.1599)	mem 11634MB
[2024-07-29 09:06:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:04:29 lr 0.000100	 wd 0.0000	time 0.2926 (0.3841)	loss 0.7949 (0.7901)	grad_norm 1.8252 (nan)	loss_scale 16384.0000 (16429.4858)	mem 11634MB
[2024-07-29 09:06:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:03:49 lr 0.000100	 wd 0.0000	time 0.3140 (0.3812)	loss 0.7642 (0.7900)	grad_norm 1.5245 (nan)	loss_scale 16384.0000 (16427.0931)	mem 11634MB
[2024-07-29 09:07:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:03:16 lr 0.000100	 wd 0.0000	time 0.2969 (0.3922)	loss 0.8452 (0.7906)	grad_norm 2.1776 (nan)	loss_scale 16384.0000 (16424.9395)	mem 11634MB
[2024-07-29 09:08:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:02:38 lr 0.000100	 wd 0.0000	time 0.2991 (0.3948)	loss 0.7217 (0.7909)	grad_norm 1.9940 (nan)	loss_scale 16384.0000 (16422.9910)	mem 11634MB
[2024-07-29 09:10:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:02:09 lr 0.000100	 wd 0.0000	time 0.3076 (0.4298)	loss 0.8267 (0.7907)	grad_norm 1.6706 (nan)	loss_scale 16384.0000 (16421.2194)	mem 11634MB
[2024-07-29 09:11:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:01:25 lr 0.000100	 wd 0.0000	time 0.2825 (0.4256)	loss 0.9185 (0.7905)	grad_norm 1.7918 (nan)	loss_scale 16384.0000 (16419.6019)	mem 11634MB
[2024-07-29 09:11:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:43 lr 0.000100	 wd 0.0000	time 0.2768 (0.4216)	loss 0.7393 (0.7906)	grad_norm 2.0193 (nan)	loss_scale 16384.0000 (16418.1191)	mem 11634MB
[2024-07-29 09:12:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000100	 wd 0.0000	time 0.3134 (0.4179)	loss 0.8652 (0.7905)	grad_norm 1.9774 (nan)	loss_scale 16384.0000 (16416.7549)	mem 11634MB
[2024-07-29 09:12:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 0 training takes 0:17:35
[2024-07-29 09:12:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune/diffusion_ft_conv_b_sequence_stage3/ckpt_epoch_0.pth saving......
[2024-07-29 09:12:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune/diffusion_ft_conv_b_sequence_stage3/ckpt_epoch_0.pth saved !!!
[2024-07-29 09:13:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 46.180 (46.180)	Loss 0.3662 (0.3662)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 11634MB
[2024-07-29 09:13:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 85.050 Acc@5 97.474
[2024-07-29 09:13:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-29 09:13:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.05%
[2024-07-29 09:13:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune/diffusion_ft_conv_b_sequence_stage3/ckpt_epoch_best.pth saving......
[2024-07-29 09:13:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune/diffusion_ft_conv_b_sequence_stage3/ckpt_epoch_best.pth saved !!!
[2024-07-29 09:13:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][0/2502]	eta 23:15:26 lr 0.000100	 wd 0.0000	time 33.4638 (33.4638)	loss 0.8022 (0.8022)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:14:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:26:35 lr 0.000100	 wd 0.0000	time 0.3104 (0.6640)	loss 0.6855 (0.7868)	grad_norm 1.5176 (1.8971)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:14:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:19:04 lr 0.000100	 wd 0.0000	time 0.3170 (0.4973)	loss 0.9062 (0.7914)	grad_norm 1.8323 (1.9248)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:15:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:16:12 lr 0.000100	 wd 0.0000	time 0.3130 (0.4417)	loss 0.8779 (0.7885)	grad_norm 2.0780 (1.9260)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:16:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:14:28 lr 0.000100	 wd 0.0000	time 0.3043 (0.4130)	loss 0.7061 (0.7906)	grad_norm 2.0196 (1.9149)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:16:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:13:12 lr 0.000100	 wd 0.0000	time 0.3195 (0.3958)	loss 0.8257 (0.7893)	grad_norm 2.5390 (1.9300)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:17:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:12:11 lr 0.000100	 wd 0.0000	time 0.3272 (0.3844)	loss 0.8179 (0.7900)	grad_norm 1.9416 (1.9171)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:17:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:11:18 lr 0.000100	 wd 0.0000	time 0.2978 (0.3764)	loss 0.6758 (0.7896)	grad_norm 2.3427 (1.9313)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:18:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:10:30 lr 0.000100	 wd 0.0000	time 0.2980 (0.3702)	loss 0.7007 (0.7898)	grad_norm 1.9313 (1.9288)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:18:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:09:45 lr 0.000099	 wd 0.0000	time 0.3133 (0.3656)	loss 0.8340 (0.7899)	grad_norm 2.1390 (1.9201)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:19:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:09:03 lr 0.000099	 wd 0.0000	time 0.3007 (0.3618)	loss 0.7788 (0.7891)	grad_norm 1.7539 (1.9276)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:19:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:08:22 lr 0.000099	 wd 0.0000	time 0.3038 (0.3586)	loss 0.9097 (0.7894)	grad_norm 2.2254 (1.9261)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:20:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:07:43 lr 0.000099	 wd 0.0000	time 0.2956 (0.3563)	loss 0.8242 (0.7892)	grad_norm 1.7169 (1.9278)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:21:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:07:05 lr 0.000099	 wd 0.0000	time 0.2909 (0.3541)	loss 0.8525 (0.7896)	grad_norm 1.6548 (1.9253)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:21:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:06:28 lr 0.000099	 wd 0.0000	time 0.3593 (0.3522)	loss 0.8218 (0.7904)	grad_norm 1.8542 (1.9323)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:22:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:06:26 lr 0.000099	 wd 0.0000	time 0.4859 (0.3858)	loss 0.8193 (0.7907)	grad_norm 1.8902 (1.9353)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:24:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:06:01 lr 0.000099	 wd 0.0000	time 0.3150 (0.4010)	loss 0.9009 (0.7914)	grad_norm 1.7471 (inf)	loss_scale 16384.0000 (16568.2049)	mem 11634MB
[2024-07-29 09:24:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:05:18 lr 0.000099	 wd 0.0000	time 0.3142 (0.3970)	loss 0.6943 (0.7912)	grad_norm 1.5163 (inf)	loss_scale 16384.0000 (16557.3757)	mem 11634MB
[2024-07-29 09:25:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:04:36 lr 0.000099	 wd 0.0000	time 0.3019 (0.3932)	loss 0.8950 (0.7919)	grad_norm 1.8666 (inf)	loss_scale 16384.0000 (16547.7490)	mem 11634MB
[2024-07-29 09:25:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:03:54 lr 0.000099	 wd 0.0000	time 0.2763 (0.3899)	loss 0.8120 (0.7926)	grad_norm 2.2910 (inf)	loss_scale 16384.0000 (16539.1352)	mem 11634MB
[2024-07-29 09:26:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:03:14 lr 0.000099	 wd 0.0000	time 0.2781 (0.3869)	loss 0.6826 (0.7920)	grad_norm 1.8244 (inf)	loss_scale 16384.0000 (16531.3823)	mem 11634MB
[2024-07-29 09:26:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:02:34 lr 0.000099	 wd 0.0000	time 0.3892 (0.3845)	loss 0.7598 (0.7922)	grad_norm 2.0336 (inf)	loss_scale 16384.0000 (16524.3674)	mem 11634MB
[2024-07-29 09:27:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:55 lr 0.000099	 wd 0.0000	time 0.3151 (0.3822)	loss 0.6333 (0.7919)	grad_norm 1.5320 (inf)	loss_scale 16384.0000 (16517.9900)	mem 11634MB
[2024-07-29 09:27:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:01:16 lr 0.000099	 wd 0.0000	time 0.2997 (0.3799)	loss 0.9111 (0.7920)	grad_norm 1.9529 (inf)	loss_scale 16384.0000 (16512.1669)	mem 11634MB
[2024-07-29 09:28:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:39 lr 0.000099	 wd 0.0000	time 0.3307 (0.3867)	loss 0.8359 (0.7920)	grad_norm 1.6525 (inf)	loss_scale 16384.0000 (16506.8288)	mem 11634MB
[2024-07-29 09:29:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000099	 wd 0.0000	time 0.3019 (0.3848)	loss 0.9570 (0.7922)	grad_norm 1.6362 (inf)	loss_scale 16384.0000 (16501.9176)	mem 11634MB
[2024-07-29 09:29:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 1 training takes 0:16:10
[2024-07-29 09:31:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 91.664 (91.664)	Loss 0.3843 (0.3843)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 11634MB
[2024-07-29 09:31:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 84.894 Acc@5 97.364
[2024-07-29 09:31:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-29 09:31:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.05%
[2024-07-29 09:32:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][0/2502]	eta 1 day, 10:03:47 lr 0.000099	 wd 0.0000	time 49.0120 (49.0120)	loss 0.6938 (0.6938)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:32:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:32:36 lr 0.000099	 wd 0.0000	time 0.3164 (0.8145)	loss 0.7412 (0.7851)	grad_norm 2.5819 (1.9953)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:33:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:21:57 lr 0.000099	 wd 0.0000	time 0.3088 (0.5723)	loss 0.7646 (0.7797)	grad_norm 1.3710 (1.9300)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:33:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:18:01 lr 0.000099	 wd 0.0000	time 0.3172 (0.4909)	loss 0.8413 (0.7799)	grad_norm 1.6723 (1.9317)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:34:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:15:45 lr 0.000099	 wd 0.0000	time 0.2879 (0.4498)	loss 0.7090 (0.7807)	grad_norm 1.8136 (1.9123)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:34:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:14:11 lr 0.000099	 wd 0.0000	time 0.2982 (0.4252)	loss 0.9800 (0.7796)	grad_norm 1.9878 (1.9013)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:35:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:12:58 lr 0.000099	 wd 0.0000	time 0.3396 (0.4091)	loss 0.8193 (0.7794)	grad_norm 2.1836 (1.9026)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:35:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:11:56 lr 0.000099	 wd 0.0000	time 0.3103 (0.3974)	loss 0.9727 (0.7799)	grad_norm 2.1910 (1.9127)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:36:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:11:01 lr 0.000099	 wd 0.0000	time 0.3249 (0.3888)	loss 0.6382 (0.7790)	grad_norm 1.7970 (1.9111)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:37:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:10:11 lr 0.000098	 wd 0.0000	time 0.3050 (0.3819)	loss 0.7456 (0.7798)	grad_norm 2.3434 (1.9112)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:37:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:09:25 lr 0.000098	 wd 0.0000	time 0.2917 (0.3763)	loss 0.7910 (0.7802)	grad_norm 2.2085 (1.9161)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:38:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:08:41 lr 0.000098	 wd 0.0000	time 0.2982 (0.3719)	loss 0.7510 (0.7803)	grad_norm 1.8386 (1.9215)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:39:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:09:06 lr 0.000098	 wd 0.0000	time 0.3626 (0.4198)	loss 0.9214 (0.7798)	grad_norm 1.9279 (1.9209)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:40:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:08:24 lr 0.000098	 wd 0.0000	time 0.3037 (0.4199)	loss 0.8105 (0.7808)	grad_norm 2.0847 (1.9331)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:40:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:07:35 lr 0.000098	 wd 0.0000	time 0.3076 (0.4134)	loss 0.8174 (0.7812)	grad_norm 1.8503 (1.9374)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:41:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:06:48 lr 0.000098	 wd 0.0000	time 0.3017 (0.4077)	loss 0.7490 (0.7815)	grad_norm 1.6005 (1.9369)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:42:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:06:03 lr 0.000098	 wd 0.0000	time 0.3178 (0.4028)	loss 0.7910 (0.7819)	grad_norm 1.6662 (1.9324)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:42:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:05:19 lr 0.000098	 wd 0.0000	time 0.2783 (0.3985)	loss 0.8560 (0.7822)	grad_norm 1.6385 (1.9286)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:43:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:04:37 lr 0.000098	 wd 0.0000	time 0.2961 (0.3950)	loss 0.7070 (0.7817)	grad_norm 1.8920 (1.9259)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:43:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:03:55 lr 0.000098	 wd 0.0000	time 0.2941 (0.3917)	loss 0.6978 (0.7823)	grad_norm 2.3800 (1.9355)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:44:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:03:15 lr 0.000098	 wd 0.0000	time 0.3398 (0.3886)	loss 0.7764 (0.7821)	grad_norm 1.6557 (1.9360)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:45:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:02:38 lr 0.000098	 wd 0.0000	time 0.2981 (0.3942)	loss 0.8569 (0.7825)	grad_norm 1.7937 (1.9348)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:45:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:59 lr 0.000098	 wd 0.0000	time 0.3452 (0.3947)	loss 0.7588 (0.7825)	grad_norm 2.0729 (1.9320)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:47:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:01:22 lr 0.000098	 wd 0.0000	time 0.2836 (0.4099)	loss 0.8730 (0.7825)	grad_norm 1.6000 (1.9297)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:48:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:42 lr 0.000098	 wd 0.0000	time 0.3315 (0.4209)	loss 1.0312 (0.7827)	grad_norm 1.8674 (1.9291)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:48:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000098	 wd 0.0000	time 0.3121 (0.4172)	loss 0.7637 (0.7832)	grad_norm 1.9541 (1.9278)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:48:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 2 training takes 0:17:27
[2024-07-29 09:49:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 21.948 (21.948)	Loss 0.3713 (0.3713)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 11634MB
[2024-07-29 09:49:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 84.958 Acc@5 97.390
[2024-07-29 09:49:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-29 09:49:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.05%
[2024-07-29 09:49:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][0/2502]	eta 1 day, 1:08:43 lr 0.000098	 wd 0.0000	time 36.1805 (36.1805)	loss 0.6938 (0.6938)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:50:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:27:21 lr 0.000098	 wd 0.0000	time 0.3071 (0.6833)	loss 0.7769 (0.7768)	grad_norm 1.9181 (1.8491)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:51:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:19:24 lr 0.000097	 wd 0.0000	time 0.3354 (0.5059)	loss 0.7822 (0.7777)	grad_norm 2.0458 (1.9053)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:51:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:16:24 lr 0.000097	 wd 0.0000	time 0.3075 (0.4469)	loss 0.9067 (0.7792)	grad_norm 1.9599 (1.9150)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:52:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:14:36 lr 0.000097	 wd 0.0000	time 0.3107 (0.4170)	loss 0.8066 (0.7786)	grad_norm 1.7044 (1.9152)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:52:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:13:18 lr 0.000097	 wd 0.0000	time 0.3139 (0.3990)	loss 0.7930 (0.7780)	grad_norm 1.8970 (1.9055)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 09:53:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:12:16 lr 0.000097	 wd 0.0000	time 0.3047 (0.3870)	loss 0.6914 (0.7773)	grad_norm 2.2635 (inf)	loss_scale 16384.0000 (17910.6290)	mem 11634MB
[2024-07-29 09:53:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:11:21 lr 0.000097	 wd 0.0000	time 0.3015 (0.3784)	loss 0.8955 (0.7779)	grad_norm 1.9665 (inf)	loss_scale 16384.0000 (17692.8502)	mem 11634MB
[2024-07-29 09:54:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:10:33 lr 0.000097	 wd 0.0000	time 0.3198 (0.3720)	loss 0.8208 (0.7786)	grad_norm 1.6452 (inf)	loss_scale 16384.0000 (17529.4482)	mem 11634MB
[2024-07-29 09:55:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:11:06 lr 0.000097	 wd 0.0000	time 0.9495 (0.4158)	loss 0.8647 (0.7788)	grad_norm 1.8218 (inf)	loss_scale 16384.0000 (17402.3174)	mem 11634MB
[2024-07-29 09:56:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:11:02 lr 0.000097	 wd 0.0000	time 0.2820 (0.4409)	loss 0.8770 (0.7798)	grad_norm 1.8912 (inf)	loss_scale 16384.0000 (17300.5874)	mem 11634MB
[2024-07-29 09:57:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:10:03 lr 0.000097	 wd 0.0000	time 0.3426 (0.4308)	loss 0.7329 (0.7813)	grad_norm 2.3898 (inf)	loss_scale 16384.0000 (17217.3370)	mem 11634MB
[2024-07-29 09:57:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:09:10 lr 0.000097	 wd 0.0000	time 0.3324 (0.4225)	loss 0.8833 (0.7821)	grad_norm 2.0480 (inf)	loss_scale 16384.0000 (17147.9500)	mem 11634MB
[2024-07-29 09:58:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:08:18 lr 0.000097	 wd 0.0000	time 0.2922 (0.4151)	loss 0.8857 (0.7823)	grad_norm 2.2449 (inf)	loss_scale 16384.0000 (17089.2298)	mem 11634MB
[2024-07-29 09:58:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:07:30 lr 0.000097	 wd 0.0000	time 0.2973 (0.4088)	loss 0.7476 (0.7828)	grad_norm 2.4889 (inf)	loss_scale 16384.0000 (17038.8922)	mem 11634MB
[2024-07-29 09:59:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:06:44 lr 0.000097	 wd 0.0000	time 0.2952 (0.4036)	loss 0.6831 (0.7834)	grad_norm 2.0559 (inf)	loss_scale 16384.0000 (16995.2618)	mem 11634MB
[2024-07-29 09:59:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:06:00 lr 0.000096	 wd 0.0000	time 0.2807 (0.3992)	loss 0.7349 (0.7833)	grad_norm 1.9957 (inf)	loss_scale 16384.0000 (16957.0818)	mem 11634MB
[2024-07-29 10:00:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:05:16 lr 0.000096	 wd 0.0000	time 0.3065 (0.3952)	loss 0.7749 (0.7837)	grad_norm 2.2414 (inf)	loss_scale 16384.0000 (16923.3909)	mem 11634MB
[2024-07-29 10:01:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:04:38 lr 0.000096	 wd 0.0000	time 0.3216 (0.3960)	loss 0.8267 (0.7833)	grad_norm 1.5977 (inf)	loss_scale 16384.0000 (16893.4414)	mem 11634MB
[2024-07-29 10:02:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:04:11 lr 0.000096	 wd 0.0000	time 0.4451 (0.4185)	loss 0.7910 (0.7834)	grad_norm 2.0306 (inf)	loss_scale 16384.0000 (16866.6428)	mem 11634MB
[2024-07-29 10:03:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:03:29 lr 0.000096	 wd 0.0000	time 0.2762 (0.4174)	loss 0.7773 (0.7835)	grad_norm 1.6905 (inf)	loss_scale 16384.0000 (16842.5227)	mem 11634MB
[2024-07-29 10:03:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:02:46 lr 0.000096	 wd 0.0000	time 0.3019 (0.4133)	loss 0.7480 (0.7836)	grad_norm 1.6183 (inf)	loss_scale 16384.0000 (16820.6987)	mem 11634MB
[2024-07-29 10:04:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:02:03 lr 0.000096	 wd 0.0000	time 0.2938 (0.4095)	loss 0.8574 (0.7837)	grad_norm 1.5874 (inf)	loss_scale 16384.0000 (16800.8578)	mem 11634MB
[2024-07-29 10:04:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:01:22 lr 0.000096	 wd 0.0000	time 0.3290 (0.4062)	loss 0.8325 (0.7837)	grad_norm 1.9463 (inf)	loss_scale 16384.0000 (16782.7414)	mem 11634MB
[2024-07-29 10:05:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:41 lr 0.000096	 wd 0.0000	time 0.3194 (0.4030)	loss 0.7520 (0.7835)	grad_norm 2.0667 (inf)	loss_scale 16384.0000 (16766.1341)	mem 11634MB
[2024-07-29 10:05:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000096	 wd 0.0000	time 0.3089 (0.4000)	loss 0.8540 (0.7836)	grad_norm 1.8951 (inf)	loss_scale 16384.0000 (16750.8549)	mem 11634MB
[2024-07-29 10:06:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 3 training takes 0:16:50
[2024-07-29 10:06:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 30.661 (30.661)	Loss 0.3948 (0.3948)	Acc@1 92.773 (92.773)	Acc@5 98.438 (98.438)	Mem 11634MB
[2024-07-29 10:06:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 84.938 Acc@5 97.384
[2024-07-29 10:06:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-29 10:06:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.05%
[2024-07-29 10:07:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][0/2502]	eta 10:51:49 lr 0.000096	 wd 0.0000	time 15.6312 (15.6312)	loss 0.7983 (0.7983)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:07:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:19:23 lr 0.000096	 wd 0.0000	time 0.3291 (0.4843)	loss 0.6660 (0.7751)	grad_norm 1.6673 (1.8393)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:08:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:15:34 lr 0.000096	 wd 0.0000	time 0.2707 (0.4060)	loss 0.8931 (0.7810)	grad_norm 1.6975 (1.8680)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:08:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:13:57 lr 0.000095	 wd 0.0000	time 0.3233 (0.3802)	loss 0.8120 (0.7805)	grad_norm 2.2072 (1.8679)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:09:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:12:51 lr 0.000095	 wd 0.0000	time 0.2960 (0.3669)	loss 0.8579 (0.7773)	grad_norm 1.7714 (1.8687)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:09:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:11:58 lr 0.000095	 wd 0.0000	time 0.3016 (0.3589)	loss 0.8584 (0.7770)	grad_norm 1.9148 (1.8749)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:10:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:11:12 lr 0.000095	 wd 0.0000	time 0.3165 (0.3536)	loss 0.7427 (0.7788)	grad_norm 2.0510 (1.8847)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:10:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:10:31 lr 0.000095	 wd 0.0000	time 0.3145 (0.3503)	loss 0.8892 (0.7772)	grad_norm 1.9571 (1.9013)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:11:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:09:51 lr 0.000095	 wd 0.0000	time 0.3031 (0.3474)	loss 0.6846 (0.7767)	grad_norm 2.5063 (1.9020)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:12:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:09:12 lr 0.000095	 wd 0.0000	time 0.2924 (0.3452)	loss 0.7705 (0.7770)	grad_norm 1.9925 (1.9105)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:12:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:08:47 lr 0.000095	 wd 0.0000	time 0.3798 (0.3515)	loss 0.7598 (0.7771)	grad_norm 1.9761 (1.9157)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:13:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:08:34 lr 0.000095	 wd 0.0000	time 0.3132 (0.3668)	loss 0.7974 (0.7780)	grad_norm 2.0144 (1.9223)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:14:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:08:34 lr 0.000095	 wd 0.0000	time 0.7926 (0.3950)	loss 0.6885 (0.7781)	grad_norm 1.6728 (1.9172)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:15:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:08:22 lr 0.000095	 wd 0.0000	time 0.3214 (0.4183)	loss 0.6738 (0.7773)	grad_norm 2.5046 (1.9178)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:16:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:07:33 lr 0.000094	 wd 0.0000	time 0.3021 (0.4118)	loss 0.7607 (0.7768)	grad_norm 2.1038 (1.9231)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:17:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:06:46 lr 0.000094	 wd 0.0000	time 0.2789 (0.4061)	loss 0.7295 (0.7771)	grad_norm 1.9292 (1.9238)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:17:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:06:01 lr 0.000094	 wd 0.0000	time 0.3010 (0.4013)	loss 0.8252 (0.7776)	grad_norm 2.1648 (1.9263)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:18:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:05:18 lr 0.000094	 wd 0.0000	time 0.2889 (0.3970)	loss 0.8022 (0.7781)	grad_norm 1.8321 (1.9288)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:18:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:04:36 lr 0.000094	 wd 0.0000	time 0.3091 (0.3932)	loss 0.8198 (0.7789)	grad_norm 2.2581 (1.9361)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:19:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:03:54 lr 0.000094	 wd 0.0000	time 0.3064 (0.3903)	loss 0.7563 (0.7784)	grad_norm 1.8742 (1.9364)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:19:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:03:14 lr 0.000094	 wd 0.0000	time 0.3192 (0.3872)	loss 0.6836 (0.7781)	grad_norm 1.8519 (1.9329)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:20:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:02:34 lr 0.000094	 wd 0.0000	time 0.2963 (0.3844)	loss 0.7349 (0.7785)	grad_norm 2.0022 (inf)	loss_scale 16384.0000 (16586.7530)	mem 11634MB
[2024-07-29 10:21:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:58 lr 0.000094	 wd 0.0000	time 0.2847 (0.3935)	loss 0.8125 (0.7785)	grad_norm 1.7526 (inf)	loss_scale 16384.0000 (16577.5411)	mem 11634MB
[2024-07-29 10:21:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:01:19 lr 0.000094	 wd 0.0000	time 0.3511 (0.3933)	loss 0.7192 (0.7790)	grad_norm 1.7791 (inf)	loss_scale 16384.0000 (16569.1299)	mem 11634MB
[2024-07-29 10:23:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:42 lr 0.000093	 wd 0.0000	time 0.4645 (0.4138)	loss 0.7021 (0.7792)	grad_norm 1.5547 (inf)	loss_scale 16384.0000 (16561.4194)	mem 11634MB
[2024-07-29 10:24:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000093	 wd 0.0000	time 0.3029 (0.4111)	loss 0.6973 (0.7793)	grad_norm 1.8900 (inf)	loss_scale 16384.0000 (16554.3255)	mem 11634MB
[2024-07-29 10:24:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 4 training takes 0:17:18
[2024-07-29 10:24:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 32.466 (32.466)	Loss 0.3752 (0.3752)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 11634MB
[2024-07-29 10:24:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 84.968 Acc@5 97.380
[2024-07-29 10:24:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-29 10:24:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.05%
[2024-07-29 10:25:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][0/2502]	eta 11:35:07 lr 0.000093	 wd 0.0000	time 16.6697 (16.6697)	loss 0.9136 (0.9136)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:25:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:19:45 lr 0.000093	 wd 0.0000	time 0.3066 (0.4934)	loss 0.6963 (0.7718)	grad_norm 1.6749 (1.9263)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:26:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:15:42 lr 0.000093	 wd 0.0000	time 0.3039 (0.4096)	loss 0.7310 (0.7756)	grad_norm 1.8943 (1.9288)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:26:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:14:01 lr 0.000093	 wd 0.0000	time 0.2674 (0.3820)	loss 0.7651 (0.7731)	grad_norm 1.9507 (1.9468)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:27:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:12:53 lr 0.000093	 wd 0.0000	time 0.3195 (0.3682)	loss 0.6841 (0.7722)	grad_norm 1.6750 (1.9503)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:27:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:12:00 lr 0.000093	 wd 0.0000	time 0.3054 (0.3598)	loss 0.8027 (0.7728)	grad_norm 2.3589 (1.9573)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:28:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:11:13 lr 0.000093	 wd 0.0000	time 0.2735 (0.3540)	loss 1.0234 (0.7747)	grad_norm 2.0928 (1.9660)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:29:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:10:31 lr 0.000093	 wd 0.0000	time 0.3078 (0.3503)	loss 0.8154 (0.7751)	grad_norm 1.8922 (1.9507)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:29:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:09:51 lr 0.000093	 wd 0.0000	time 0.2990 (0.3474)	loss 0.8857 (0.7759)	grad_norm 2.1175 (1.9484)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:30:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:09:12 lr 0.000092	 wd 0.0000	time 0.2968 (0.3451)	loss 0.7305 (0.7759)	grad_norm 2.0117 (1.9460)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:31:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:09:25 lr 0.000092	 wd 0.0000	time 2.0745 (0.3767)	loss 0.7583 (0.7761)	grad_norm 2.0469 (1.9515)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:32:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:09:21 lr 0.000092	 wd 0.0000	time 0.3106 (0.4006)	loss 0.6899 (0.7766)	grad_norm 1.8908 (1.9552)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:32:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:08:33 lr 0.000092	 wd 0.0000	time 0.3199 (0.3943)	loss 0.8921 (0.7770)	grad_norm 1.6021 (1.9505)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:33:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:07:47 lr 0.000092	 wd 0.0000	time 0.3309 (0.3893)	loss 0.7344 (0.7769)	grad_norm 1.7716 (1.9497)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:33:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:07:04 lr 0.000092	 wd 0.0000	time 0.3015 (0.3849)	loss 0.8306 (0.7767)	grad_norm 1.9259 (1.9521)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:34:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:06:21 lr 0.000092	 wd 0.0000	time 0.2998 (0.3810)	loss 0.8457 (0.7768)	grad_norm 1.7757 (1.9450)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:35:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:05:40 lr 0.000092	 wd 0.0000	time 0.3099 (0.3777)	loss 0.7432 (0.7764)	grad_norm 1.6048 (1.9463)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:35:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:05:00 lr 0.000092	 wd 0.0000	time 0.2975 (0.3749)	loss 0.8140 (0.7766)	grad_norm 1.9811 (1.9411)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 10:36:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:04:21 lr 0.000091	 wd 0.0000	time 0.3234 (0.3724)	loss 0.7231 (0.7766)	grad_norm 2.1863 (inf)	loss_scale 8192.0000 (15938.2388)	mem 11634MB
[2024-07-29 10:36:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:03:42 lr 0.000091	 wd 0.0000	time 0.3245 (0.3701)	loss 0.8623 (0.7770)	grad_norm 1.7195 (inf)	loss_scale 8192.0000 (15530.7564)	mem 11634MB
[2024-07-29 10:37:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:03:09 lr 0.000091	 wd 0.0000	time 0.3146 (0.3784)	loss 0.9126 (0.7768)	grad_norm 1.9083 (inf)	loss_scale 8192.0000 (15164.0020)	mem 11634MB
[2024-07-29 10:38:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:02:32 lr 0.000091	 wd 0.0000	time 0.3009 (0.3791)	loss 0.7822 (0.7762)	grad_norm 1.7836 (inf)	loss_scale 8192.0000 (14832.1599)	mem 11634MB
[2024-07-29 10:39:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:02:01 lr 0.000091	 wd 0.0000	time 0.3763 (0.4007)	loss 0.7480 (0.7763)	grad_norm 1.7473 (inf)	loss_scale 8192.0000 (14530.4716)	mem 11634MB
[2024-07-29 10:40:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:01:22 lr 0.000091	 wd 0.0000	time 0.2869 (0.4077)	loss 0.6470 (0.7761)	grad_norm 1.8909 (inf)	loss_scale 8192.0000 (14255.0056)	mem 11634MB
[2024-07-29 10:41:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:41 lr 0.000091	 wd 0.0000	time 0.3209 (0.4045)	loss 0.7876 (0.7760)	grad_norm 1.8625 (inf)	loss_scale 8192.0000 (14002.4856)	mem 11634MB
[2024-07-29 10:41:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000091	 wd 0.0000	time 0.3020 (0.4013)	loss 0.7690 (0.7763)	grad_norm 1.6112 (inf)	loss_scale 8192.0000 (13770.1591)	mem 11634MB
[2024-07-29 10:41:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 5 training takes 0:16:48
[2024-07-29 10:42:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 37.063 (37.063)	Loss 0.3608 (0.3608)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 11634MB
[2024-07-29 10:42:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 84.824 Acc@5 97.330
[2024-07-29 10:42:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 10:42:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.05%
[2024-07-29 10:42:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][0/2502]	eta 11:19:40 lr 0.000091	 wd 0.0000	time 16.2993 (16.2993)	loss 0.8076 (0.8076)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:43:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:19:29 lr 0.000090	 wd 0.0000	time 0.3073 (0.4867)	loss 0.7290 (0.7728)	grad_norm 2.0174 (1.9429)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:43:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:15:39 lr 0.000090	 wd 0.0000	time 0.3072 (0.4080)	loss 0.6958 (0.7720)	grad_norm 1.7606 (1.9130)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:44:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:13:59 lr 0.000090	 wd 0.0000	time 0.2795 (0.3812)	loss 0.8120 (0.7737)	grad_norm 1.6082 (1.9192)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:44:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:12:52 lr 0.000090	 wd 0.0000	time 0.3169 (0.3673)	loss 0.7671 (0.7732)	grad_norm 1.6602 (1.9066)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:45:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:11:59 lr 0.000090	 wd 0.0000	time 0.3001 (0.3595)	loss 0.8418 (0.7711)	grad_norm 1.8355 (1.9075)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:46:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:11:13 lr 0.000090	 wd 0.0000	time 0.3223 (0.3542)	loss 0.8486 (0.7711)	grad_norm 2.2876 (1.9080)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:46:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:10:31 lr 0.000090	 wd 0.0000	time 0.3084 (0.3502)	loss 0.8452 (0.7733)	grad_norm 2.1494 (1.9130)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:47:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:09:52 lr 0.000090	 wd 0.0000	time 0.3016 (0.3480)	loss 0.7188 (0.7741)	grad_norm 1.7199 (1.9154)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:47:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:09:13 lr 0.000089	 wd 0.0000	time 0.2958 (0.3456)	loss 0.8027 (0.7738)	grad_norm 1.7256 (1.9235)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:48:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:08:36 lr 0.000089	 wd 0.0000	time 0.3129 (0.3437)	loss 0.7930 (0.7746)	grad_norm 2.2092 (1.9230)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:49:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:09:07 lr 0.000089	 wd 0.0000	time 0.4839 (0.3906)	loss 0.7183 (0.7745)	grad_norm 1.6888 (1.9340)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:50:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:08:39 lr 0.000089	 wd 0.0000	time 0.3232 (0.3989)	loss 0.6172 (0.7745)	grad_norm 1.9657 (1.9453)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:51:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:07:52 lr 0.000089	 wd 0.0000	time 0.2989 (0.3934)	loss 0.7188 (0.7755)	grad_norm 1.7567 (1.9432)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:51:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:07:08 lr 0.000089	 wd 0.0000	time 0.3110 (0.3888)	loss 0.9805 (0.7745)	grad_norm 2.4368 (1.9413)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:52:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:06:25 lr 0.000089	 wd 0.0000	time 0.3092 (0.3846)	loss 0.6309 (0.7744)	grad_norm 1.8672 (1.9439)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:52:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:05:43 lr 0.000089	 wd 0.0000	time 0.3046 (0.3811)	loss 0.8608 (0.7742)	grad_norm 1.7823 (1.9409)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:53:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:05:03 lr 0.000088	 wd 0.0000	time 0.2877 (0.3779)	loss 0.8784 (0.7732)	grad_norm 1.7120 (1.9408)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:53:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:04:23 lr 0.000088	 wd 0.0000	time 0.3126 (0.3753)	loss 0.7017 (0.7726)	grad_norm 1.7322 (1.9448)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:54:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:03:44 lr 0.000088	 wd 0.0000	time 0.2926 (0.3729)	loss 0.8413 (0.7728)	grad_norm 2.5223 (1.9434)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:54:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:03:06 lr 0.000088	 wd 0.0000	time 0.2787 (0.3708)	loss 0.9565 (0.7737)	grad_norm 2.0764 (1.9464)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:56:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:02:37 lr 0.000088	 wd 0.0000	time 0.5579 (0.3907)	loss 0.7920 (0.7740)	grad_norm 2.3743 (1.9481)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:57:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:02:03 lr 0.000088	 wd 0.0000	time 0.5937 (0.4082)	loss 0.7920 (0.7746)	grad_norm 2.3994 (1.9500)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:58:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:01:23 lr 0.000088	 wd 0.0000	time 0.2967 (0.4145)	loss 0.7705 (0.7745)	grad_norm 2.0388 (1.9500)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:58:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:41 lr 0.000087	 wd 0.0000	time 0.2781 (0.4109)	loss 0.7949 (0.7743)	grad_norm 1.9184 (1.9491)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:59:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000087	 wd 0.0000	time 0.3017 (0.4075)	loss 0.6890 (0.7740)	grad_norm 1.6208 (1.9503)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 10:59:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 6 training takes 0:17:03
[2024-07-29 11:00:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 36.998 (36.998)	Loss 0.3860 (0.3860)	Acc@1 90.820 (90.820)	Acc@5 98.438 (98.438)	Mem 11634MB
[2024-07-29 11:00:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 84.894 Acc@5 97.366
[2024-07-29 11:00:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-29 11:00:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.05%
[2024-07-29 11:00:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][0/2502]	eta 11:08:24 lr 0.000087	 wd 0.0000	time 16.0288 (16.0288)	loss 0.8213 (0.8213)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 11:01:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:19:18 lr 0.000087	 wd 0.0000	time 0.2702 (0.4824)	loss 0.9229 (0.7776)	grad_norm 1.5687 (2.0344)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 11:01:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:15:35 lr 0.000087	 wd 0.0000	time 0.3263 (0.4064)	loss 0.7920 (0.7682)	grad_norm 2.0555 (1.9990)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 11:02:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:13:57 lr 0.000087	 wd 0.0000	time 0.3072 (0.3802)	loss 0.7417 (0.7675)	grad_norm 2.4729 (1.9711)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 11:02:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:12:50 lr 0.000087	 wd 0.0000	time 0.2944 (0.3667)	loss 0.8584 (0.7667)	grad_norm 1.8503 (1.9691)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 11:03:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:11:58 lr 0.000087	 wd 0.0000	time 0.3105 (0.3586)	loss 0.7202 (0.7672)	grad_norm 1.9011 (1.9599)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 11:03:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:11:11 lr 0.000086	 wd 0.0000	time 0.3176 (0.3531)	loss 0.7524 (0.7678)	grad_norm 1.8358 (1.9530)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 11:04:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:10:30 lr 0.000086	 wd 0.0000	time 0.3112 (0.3496)	loss 0.6504 (0.7671)	grad_norm 1.6906 (1.9494)	loss_scale 16384.0000 (8215.3723)	mem 11634MB
[2024-07-29 11:05:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:09:51 lr 0.000086	 wd 0.0000	time 0.2987 (0.3473)	loss 0.7778 (0.7677)	grad_norm 2.0183 (1.9552)	loss_scale 16384.0000 (9235.1760)	mem 11634MB
[2024-07-29 11:05:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:09:12 lr 0.000086	 wd 0.0000	time 0.2819 (0.3450)	loss 0.6450 (0.7688)	grad_norm 1.8667 (1.9557)	loss_scale 16384.0000 (10028.6082)	mem 11634MB
[2024-07-29 11:06:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:08:35 lr 0.000086	 wd 0.0000	time 0.3116 (0.3431)	loss 0.7612 (0.7696)	grad_norm 1.6754 (1.9444)	loss_scale 16384.0000 (10663.5125)	mem 11634MB
[2024-07-29 11:07:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:08:52 lr 0.000086	 wd 0.0000	time 0.5428 (0.3796)	loss 0.7720 (0.7689)	grad_norm 1.7859 (1.9484)	loss_scale 16384.0000 (11183.0845)	mem 11634MB
[2024-07-29 11:08:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:08:42 lr 0.000086	 wd 0.0000	time 0.2976 (0.4013)	loss 0.6777 (0.7697)	grad_norm 1.5992 (1.9510)	loss_scale 16384.0000 (11616.1332)	mem 11634MB
[2024-07-29 11:09:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:07:55 lr 0.000085	 wd 0.0000	time 0.2883 (0.3958)	loss 0.7935 (0.7696)	grad_norm 2.1347 (1.9533)	loss_scale 16384.0000 (11982.6103)	mem 11634MB
[2024-07-29 11:09:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:07:10 lr 0.000085	 wd 0.0000	time 0.3071 (0.3910)	loss 0.7842 (0.7703)	grad_norm 2.3342 (1.9525)	loss_scale 16384.0000 (12296.7709)	mem 11634MB
[2024-07-29 11:10:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:06:27 lr 0.000085	 wd 0.0000	time 0.3098 (0.3870)	loss 0.6929 (0.7698)	grad_norm 2.1172 (1.9508)	loss_scale 16384.0000 (12569.0713)	mem 11634MB
[2024-07-29 11:10:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:05:45 lr 0.000085	 wd 0.0000	time 0.2793 (0.3832)	loss 0.8252 (0.7702)	grad_norm 1.8544 (1.9505)	loss_scale 16384.0000 (12807.3554)	mem 11634MB
[2024-07-29 11:11:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:05:04 lr 0.000085	 wd 0.0000	time 0.3016 (0.3801)	loss 0.7300 (0.7701)	grad_norm 1.7191 (1.9505)	loss_scale 16384.0000 (13017.6226)	mem 11634MB
[2024-07-29 11:11:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:04:25 lr 0.000085	 wd 0.0000	time 0.3058 (0.3776)	loss 0.7227 (0.7694)	grad_norm 2.3285 (1.9511)	loss_scale 16384.0000 (13204.5397)	mem 11634MB
[2024-07-29 11:12:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:03:45 lr 0.000085	 wd 0.0000	time 0.2783 (0.3749)	loss 0.8682 (0.7700)	grad_norm 2.3215 (1.9507)	loss_scale 16384.0000 (13371.7917)	mem 11634MB
[2024-07-29 11:12:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:03:06 lr 0.000084	 wd 0.0000	time 0.3133 (0.3725)	loss 0.6943 (0.7700)	grad_norm 1.9274 (1.9570)	loss_scale 16384.0000 (13522.3268)	mem 11634MB
[2024-07-29 11:14:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:02:37 lr 0.000084	 wd 0.0000	time 0.8661 (0.3919)	loss 0.7622 (0.7702)	grad_norm 2.0204 (1.9617)	loss_scale 16384.0000 (13658.5321)	mem 11634MB
[2024-07-29 11:14:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:58 lr 0.000084	 wd 0.0000	time 0.3021 (0.3923)	loss 0.7793 (0.7702)	grad_norm 1.7651 (1.9679)	loss_scale 16384.0000 (13782.3607)	mem 11634MB
[2024-07-29 11:15:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:01:18 lr 0.000084	 wd 0.0000	time 0.2941 (0.3896)	loss 0.7632 (0.7701)	grad_norm 2.1096 (1.9669)	loss_scale 16384.0000 (13895.4263)	mem 11634MB
[2024-07-29 11:15:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:39 lr 0.000084	 wd 0.0000	time 0.3030 (0.3871)	loss 0.7080 (0.7707)	grad_norm 1.8335 (1.9667)	loss_scale 16384.0000 (13999.0737)	mem 11634MB
[2024-07-29 11:16:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000084	 wd 0.0000	time 0.3100 (0.3846)	loss 0.7080 (0.7712)	grad_norm 1.6928 (1.9645)	loss_scale 16384.0000 (14094.4326)	mem 11634MB
[2024-07-29 11:16:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 7 training takes 0:16:11
[2024-07-29 11:17:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 25.908 (25.908)	Loss 0.3667 (0.3667)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 11634MB
[2024-07-29 11:17:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 84.834 Acc@5 97.346
[2024-07-29 11:17:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 11:17:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.05%
[2024-07-29 11:17:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][0/2502]	eta 10:26:49 lr 0.000084	 wd 0.0000	time 15.0317 (15.0317)	loss 0.9033 (0.9033)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:18:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:19:18 lr 0.000083	 wd 0.0000	time 0.3358 (0.4823)	loss 0.7217 (0.7751)	grad_norm 2.5416 (2.0035)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:18:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:15:31 lr 0.000083	 wd 0.0000	time 0.2870 (0.4046)	loss 0.6992 (0.7680)	grad_norm 1.9221 (1.9707)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:19:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:13:52 lr 0.000083	 wd 0.0000	time 0.2990 (0.3782)	loss 0.8027 (0.7663)	grad_norm 1.9236 (1.9864)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:19:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:12:48 lr 0.000083	 wd 0.0000	time 0.3219 (0.3656)	loss 0.7925 (0.7662)	grad_norm 1.8511 (1.9856)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:20:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:11:56 lr 0.000083	 wd 0.0000	time 0.3074 (0.3577)	loss 0.7788 (0.7677)	grad_norm 1.8570 (1.9843)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:20:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:11:10 lr 0.000083	 wd 0.0000	time 0.2829 (0.3523)	loss 0.7051 (0.7676)	grad_norm 1.8354 (1.9781)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:21:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:10:28 lr 0.000083	 wd 0.0000	time 0.2973 (0.3490)	loss 0.9170 (0.7665)	grad_norm 1.7907 (1.9846)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:21:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:09:49 lr 0.000082	 wd 0.0000	time 0.3070 (0.3463)	loss 0.8213 (0.7672)	grad_norm 1.8612 (1.9887)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:22:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:09:11 lr 0.000082	 wd 0.0000	time 0.3111 (0.3444)	loss 0.8042 (0.7664)	grad_norm 1.7637 (1.9774)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:23:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:09:04 lr 0.000082	 wd 0.0000	time 0.4215 (0.3623)	loss 0.8301 (0.7674)	grad_norm 1.6252 (1.9681)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:24:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:09:20 lr 0.000082	 wd 0.0000	time 0.2946 (0.3995)	loss 0.7607 (0.7679)	grad_norm 1.8539 (1.9694)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:25:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:08:32 lr 0.000082	 wd 0.0000	time 0.3157 (0.3938)	loss 0.8291 (0.7684)	grad_norm 2.0002 (1.9647)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:25:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:07:47 lr 0.000082	 wd 0.0000	time 0.3028 (0.3888)	loss 0.7554 (0.7690)	grad_norm 2.0177 (1.9645)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:26:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:07:03 lr 0.000081	 wd 0.0000	time 0.3173 (0.3845)	loss 0.7642 (0.7699)	grad_norm 2.5093 (1.9663)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:26:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:06:21 lr 0.000081	 wd 0.0000	time 0.3120 (0.3807)	loss 0.6689 (0.7700)	grad_norm 1.9157 (1.9680)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:27:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:05:40 lr 0.000081	 wd 0.0000	time 0.3156 (0.3773)	loss 0.8164 (0.7701)	grad_norm 1.7542 (1.9707)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:27:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:05:00 lr 0.000081	 wd 0.0000	time 0.2953 (0.3747)	loss 0.7212 (0.7705)	grad_norm 1.8080 (1.9721)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:28:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:04:21 lr 0.000081	 wd 0.0000	time 0.3313 (0.3721)	loss 0.6953 (0.7711)	grad_norm 2.8859 (1.9786)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:28:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:03:42 lr 0.000081	 wd 0.0000	time 0.3390 (0.3698)	loss 0.7168 (0.7707)	grad_norm 1.7363 (1.9765)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:29:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:03:08 lr 0.000080	 wd 0.0000	time 0.3052 (0.3749)	loss 0.7983 (0.7708)	grad_norm 1.9187 (1.9802)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:30:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:02:30 lr 0.000080	 wd 0.0000	time 0.3672 (0.3755)	loss 0.8403 (0.7710)	grad_norm 1.9776 (1.9813)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:31:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:57 lr 0.000080	 wd 0.0000	time 0.3645 (0.3892)	loss 0.8159 (0.7712)	grad_norm 1.8296 (1.9801)	loss_scale 32768.0000 (16413.7756)	mem 11634MB
[2024-07-29 11:32:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:01:20 lr 0.000080	 wd 0.0000	time 0.3484 (0.3991)	loss 0.7852 (0.7710)	grad_norm 2.1204 (1.9803)	loss_scale 32768.0000 (17124.5198)	mem 11634MB
[2024-07-29 11:33:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:40 lr 0.000080	 wd 0.0000	time 0.2750 (0.3983)	loss 0.8125 (0.7709)	grad_norm 2.5818 (inf)	loss_scale 16384.0000 (17107.3253)	mem 11634MB
[2024-07-29 11:33:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000080	 wd 0.0000	time 0.2856 (0.3955)	loss 0.8413 (0.7711)	grad_norm 2.2210 (inf)	loss_scale 16384.0000 (17078.4038)	mem 11634MB
[2024-07-29 11:33:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 8 training takes 0:16:33
[2024-07-29 11:34:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 37.754 (37.754)	Loss 0.3921 (0.3921)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 11634MB
[2024-07-29 11:34:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 85.040 Acc@5 97.326
[2024-07-29 11:34:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-29 11:34:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.05%
[2024-07-29 11:34:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][0/2502]	eta 11:11:38 lr 0.000080	 wd 0.0000	time 16.1067 (16.1067)	loss 0.6572 (0.6572)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:35:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:19:22 lr 0.000079	 wd 0.0000	time 0.3102 (0.4838)	loss 0.7656 (0.7602)	grad_norm 1.8133 (1.9765)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:36:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:15:36 lr 0.000079	 wd 0.0000	time 0.2878 (0.4067)	loss 0.6826 (0.7583)	grad_norm 1.9049 (1.9327)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:36:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:13:57 lr 0.000079	 wd 0.0000	time 0.2997 (0.3804)	loss 0.8389 (0.7645)	grad_norm 1.9891 (1.9386)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:37:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:12:51 lr 0.000079	 wd 0.0000	time 0.2865 (0.3670)	loss 0.7236 (0.7641)	grad_norm 1.6970 (1.9213)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:37:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:11:58 lr 0.000079	 wd 0.0000	time 0.2937 (0.3590)	loss 0.6743 (0.7628)	grad_norm 1.9712 (1.9168)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:38:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:11:12 lr 0.000079	 wd 0.0000	time 0.2981 (0.3535)	loss 0.7314 (0.7611)	grad_norm 1.8708 (1.9215)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:38:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:10:29 lr 0.000078	 wd 0.0000	time 0.3219 (0.3496)	loss 0.8208 (0.7619)	grad_norm 1.7357 (1.9208)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:39:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:09:50 lr 0.000078	 wd 0.0000	time 0.3059 (0.3467)	loss 0.8975 (0.7624)	grad_norm 1.8276 (1.9296)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:39:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:09:11 lr 0.000078	 wd 0.0000	time 0.3013 (0.3445)	loss 0.9023 (0.7637)	grad_norm 1.8553 (1.9330)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:40:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:08:34 lr 0.000078	 wd 0.0000	time 0.3144 (0.3428)	loss 0.7598 (0.7638)	grad_norm 1.8273 (1.9336)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:41:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:08:15 lr 0.000078	 wd 0.0000	time 0.4030 (0.3538)	loss 0.8306 (0.7635)	grad_norm 1.9797 (1.9355)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:42:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:08:06 lr 0.000078	 wd 0.0000	time 0.3826 (0.3738)	loss 0.7812 (0.7649)	grad_norm 1.5357 (1.9328)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:43:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:07:43 lr 0.000077	 wd 0.0000	time 0.3116 (0.3860)	loss 0.7705 (0.7654)	grad_norm 1.8740 (1.9364)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:43:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:07:00 lr 0.000077	 wd 0.0000	time 0.3031 (0.3818)	loss 0.8418 (0.7658)	grad_norm 1.8248 (1.9355)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:44:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:06:19 lr 0.000077	 wd 0.0000	time 0.3155 (0.3784)	loss 0.7231 (0.7667)	grad_norm 1.8740 (1.9409)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:44:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:05:38 lr 0.000077	 wd 0.0000	time 0.3037 (0.3752)	loss 0.7480 (0.7656)	grad_norm 1.8639 (1.9410)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:45:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:04:58 lr 0.000077	 wd 0.0000	time 0.2997 (0.3724)	loss 0.7402 (0.7659)	grad_norm 1.9737 (1.9492)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:45:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:04:19 lr 0.000077	 wd 0.0000	time 0.3266 (0.3700)	loss 0.7593 (0.7661)	grad_norm 1.8601 (1.9525)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:46:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:03:41 lr 0.000076	 wd 0.0000	time 0.2955 (0.3680)	loss 0.7490 (0.7666)	grad_norm 1.8739 (1.9515)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:46:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:03:03 lr 0.000076	 wd 0.0000	time 0.2957 (0.3660)	loss 0.7197 (0.7672)	grad_norm 1.7797 (1.9520)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:47:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:02:26 lr 0.000076	 wd 0.0000	time 0.5653 (0.3644)	loss 0.7769 (0.7676)	grad_norm 2.0245 (1.9541)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:48:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:51 lr 0.000076	 wd 0.0000	time 1.2769 (0.3705)	loss 0.6104 (0.7674)	grad_norm 2.3460 (1.9593)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:48:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:01:14 lr 0.000076	 wd 0.0000	time 0.2990 (0.3700)	loss 0.7339 (0.7675)	grad_norm 1.8071 (1.9602)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:50:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:40 lr 0.000075	 wd 0.0000	time 0.3419 (0.3957)	loss 0.8628 (0.7681)	grad_norm 1.7603 (1.9595)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:51:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000075	 wd 0.0000	time 0.3049 (0.3959)	loss 0.8252 (0.7685)	grad_norm 1.8915 (1.9592)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:51:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 9 training takes 0:16:34
[2024-07-29 11:51:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 20.364 (20.364)	Loss 0.3923 (0.3923)	Acc@1 91.211 (91.211)	Acc@5 98.242 (98.242)	Mem 11634MB
[2024-07-29 11:51:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 84.832 Acc@5 97.326
[2024-07-29 11:51:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 11:51:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.05%
[2024-07-29 11:52:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][0/2502]	eta 15:38:05 lr 0.000075	 wd 0.0000	time 22.4963 (22.4963)	loss 0.8379 (0.8379)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:52:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:22:19 lr 0.000075	 wd 0.0000	time 0.3083 (0.5577)	loss 0.8345 (0.7758)	grad_norm 1.6177 (1.9783)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:53:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:16:56 lr 0.000075	 wd 0.0000	time 0.3140 (0.4418)	loss 0.7383 (0.7702)	grad_norm 2.0063 (1.9745)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:53:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:14:55 lr 0.000075	 wd 0.0000	time 0.2992 (0.4067)	loss 0.7393 (0.7693)	grad_norm 1.6734 (1.9816)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:54:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:13:34 lr 0.000075	 wd 0.0000	time 0.3340 (0.3873)	loss 0.7490 (0.7694)	grad_norm 2.3924 (1.9934)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:54:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:12:31 lr 0.000074	 wd 0.0000	time 0.3032 (0.3752)	loss 0.7041 (0.7705)	grad_norm 1.8502 (1.9989)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:55:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:11:38 lr 0.000074	 wd 0.0000	time 0.2940 (0.3671)	loss 0.7148 (0.7699)	grad_norm 2.0100 (2.0074)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:55:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:10:51 lr 0.000074	 wd 0.0000	time 0.3084 (0.3615)	loss 0.6982 (0.7677)	grad_norm 2.1890 (1.9983)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 11:56:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:10:07 lr 0.000074	 wd 0.0000	time 0.2989 (0.3569)	loss 0.7305 (0.7687)	grad_norm 1.9672 (inf)	loss_scale 8192.0000 (15668.0949)	mem 11634MB
[2024-07-29 11:57:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:09:26 lr 0.000074	 wd 0.0000	time 0.2871 (0.3535)	loss 0.6958 (0.7679)	grad_norm 1.6587 (inf)	loss_scale 8192.0000 (14838.3396)	mem 11634MB
[2024-07-29 11:58:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:09:34 lr 0.000073	 wd 0.0000	time 0.4398 (0.3823)	loss 0.8774 (0.7680)	grad_norm 1.9663 (inf)	loss_scale 8192.0000 (14174.3696)	mem 11634MB
[2024-07-29 11:58:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:09:06 lr 0.000073	 wd 0.0000	time 0.3698 (0.3900)	loss 0.8315 (0.7674)	grad_norm 1.9433 (inf)	loss_scale 8192.0000 (13631.0118)	mem 11634MB
[2024-07-29 11:59:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:08:20 lr 0.000073	 wd 0.0000	time 0.2946 (0.3847)	loss 0.8926 (0.7673)	grad_norm 1.7431 (inf)	loss_scale 8192.0000 (13178.1382)	mem 11634MB
[2024-07-29 11:59:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:07:37 lr 0.000073	 wd 0.0000	time 0.3413 (0.3804)	loss 0.7500 (0.7673)	grad_norm 1.9209 (inf)	loss_scale 8192.0000 (12794.8839)	mem 11634MB
[2024-07-29 12:00:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:06:55 lr 0.000073	 wd 0.0000	time 0.3125 (0.3768)	loss 0.7461 (0.7673)	grad_norm 2.2560 (inf)	loss_scale 8192.0000 (12466.3412)	mem 11634MB
[2024-07-29 12:01:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:06:14 lr 0.000073	 wd 0.0000	time 0.3132 (0.3736)	loss 0.7725 (0.7673)	grad_norm 1.9006 (inf)	loss_scale 8192.0000 (12181.5750)	mem 11634MB
[2024-07-29 12:01:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:05:34 lr 0.000072	 wd 0.0000	time 0.3146 (0.3706)	loss 0.6357 (0.7669)	grad_norm 2.1004 (inf)	loss_scale 8192.0000 (11932.3823)	mem 11634MB
[2024-07-29 12:02:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:04:55 lr 0.000072	 wd 0.0000	time 0.3019 (0.3683)	loss 0.7275 (0.7667)	grad_norm 2.1237 (inf)	loss_scale 8192.0000 (11712.4891)	mem 11634MB
[2024-07-29 12:02:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:04:16 lr 0.000072	 wd 0.0000	time 0.3194 (0.3661)	loss 0.8677 (0.7669)	grad_norm 1.9172 (inf)	loss_scale 8192.0000 (11517.0150)	mem 11634MB
[2024-07-29 12:03:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:03:39 lr 0.000072	 wd 0.0000	time 0.3143 (0.3642)	loss 0.8525 (0.7682)	grad_norm 1.9213 (inf)	loss_scale 8192.0000 (11342.1063)	mem 11634MB
[2024-07-29 12:04:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:03:09 lr 0.000072	 wd 0.0000	time 0.3239 (0.3782)	loss 0.9771 (0.7687)	grad_norm 2.3469 (inf)	loss_scale 8192.0000 (11184.6797)	mem 11634MB
[2024-07-29 12:04:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:02:31 lr 0.000071	 wd 0.0000	time 0.2943 (0.3778)	loss 0.7324 (0.7689)	grad_norm 2.0462 (inf)	loss_scale 8192.0000 (11042.2389)	mem 11634MB
[2024-07-29 12:06:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:02:00 lr 0.000071	 wd 0.0000	time 0.6376 (0.3974)	loss 0.8110 (0.7692)	grad_norm 2.1479 (inf)	loss_scale 8192.0000 (10912.7415)	mem 11634MB
[2024-07-29 12:07:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:01:21 lr 0.000071	 wd 0.0000	time 0.2987 (0.4037)	loss 0.8086 (0.7694)	grad_norm 1.8350 (inf)	loss_scale 8192.0000 (10794.4998)	mem 11634MB
[2024-07-29 12:07:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:40 lr 0.000071	 wd 0.0000	time 0.3093 (0.4005)	loss 0.8750 (0.7694)	grad_norm 1.6993 (inf)	loss_scale 8192.0000 (10686.1075)	mem 11634MB
[2024-07-29 12:08:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000071	 wd 0.0000	time 0.2993 (0.3975)	loss 0.6685 (0.7691)	grad_norm 1.8190 (inf)	loss_scale 8192.0000 (10586.3830)	mem 11634MB
[2024-07-29 12:08:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 10 training takes 0:16:39
[2024-07-29 12:09:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 37.069 (37.069)	Loss 0.4192 (0.4192)	Acc@1 91.602 (91.602)	Acc@5 98.438 (98.438)	Mem 11634MB
[2024-07-29 12:09:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 84.820 Acc@5 97.282
[2024-07-29 12:09:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 12:09:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.05%
[2024-07-29 12:09:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][0/2502]	eta 11:17:58 lr 0.000071	 wd 0.0000	time 16.2584 (16.2584)	loss 0.6982 (0.6982)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:10:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:19:30 lr 0.000070	 wd 0.0000	time 0.3109 (0.4875)	loss 0.7080 (0.7634)	grad_norm 1.8606 (1.9553)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:10:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:15:40 lr 0.000070	 wd 0.0000	time 0.3032 (0.4085)	loss 0.7773 (0.7660)	grad_norm 1.7769 (1.9524)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:11:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:13:59 lr 0.000070	 wd 0.0000	time 0.3101 (0.3814)	loss 0.7222 (0.7634)	grad_norm 2.2557 (1.9571)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:11:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:12:52 lr 0.000070	 wd 0.0000	time 0.3085 (0.3676)	loss 0.6826 (0.7611)	grad_norm 1.7585 (1.9576)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:12:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:12:00 lr 0.000070	 wd 0.0000	time 0.2837 (0.3597)	loss 0.7808 (0.7599)	grad_norm 1.9989 (1.9629)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:12:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:11:13 lr 0.000069	 wd 0.0000	time 0.3303 (0.3543)	loss 0.8110 (0.7606)	grad_norm 3.3042 (1.9756)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:13:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:10:31 lr 0.000069	 wd 0.0000	time 0.3069 (0.3503)	loss 0.7432 (0.7611)	grad_norm 2.0617 (1.9877)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:13:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:09:51 lr 0.000069	 wd 0.0000	time 0.2936 (0.3476)	loss 0.8271 (0.7620)	grad_norm 1.6993 (1.9830)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:14:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:09:13 lr 0.000069	 wd 0.0000	time 0.3000 (0.3453)	loss 0.7983 (0.7640)	grad_norm 2.2908 (1.9746)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:14:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:08:35 lr 0.000069	 wd 0.0000	time 0.3125 (0.3434)	loss 0.7485 (0.7646)	grad_norm 1.8702 (1.9772)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:16:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:08:39 lr 0.000069	 wd 0.0000	time 0.4455 (0.3705)	loss 0.7974 (0.7643)	grad_norm 1.9134 (1.9772)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:17:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:08:30 lr 0.000068	 wd 0.0000	time 0.2719 (0.3921)	loss 0.8232 (0.7645)	grad_norm 2.2039 (1.9737)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:17:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:07:45 lr 0.000068	 wd 0.0000	time 0.2894 (0.3871)	loss 0.6919 (0.7652)	grad_norm 1.9445 (1.9755)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:18:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:07:01 lr 0.000068	 wd 0.0000	time 0.2928 (0.3828)	loss 0.7642 (0.7653)	grad_norm 2.1969 (1.9782)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:18:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:06:19 lr 0.000068	 wd 0.0000	time 0.3004 (0.3792)	loss 0.7681 (0.7648)	grad_norm 2.1522 (1.9794)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:19:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:05:39 lr 0.000068	 wd 0.0000	time 0.3140 (0.3759)	loss 0.7158 (0.7649)	grad_norm 2.2820 (1.9860)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:19:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:04:59 lr 0.000067	 wd 0.0000	time 0.3349 (0.3731)	loss 0.7617 (0.7647)	grad_norm 1.8842 (1.9840)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:20:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:04:20 lr 0.000067	 wd 0.0000	time 0.2870 (0.3710)	loss 0.7539 (0.7654)	grad_norm 2.2433 (1.9819)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:20:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:03:41 lr 0.000067	 wd 0.0000	time 0.3118 (0.3688)	loss 0.7290 (0.7662)	grad_norm 1.9298 (1.9812)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:21:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:03:04 lr 0.000067	 wd 0.0000	time 0.3105 (0.3667)	loss 0.6074 (0.7661)	grad_norm 2.2225 (1.9797)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:22:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:02:32 lr 0.000067	 wd 0.0000	time 0.3277 (0.3803)	loss 0.8901 (0.7659)	grad_norm 2.1279 (1.9798)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:23:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:54 lr 0.000066	 wd 0.0000	time 0.3160 (0.3791)	loss 0.8555 (0.7662)	grad_norm 2.2572 (1.9820)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:24:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:01:19 lr 0.000066	 wd 0.0000	time 0.2943 (0.3918)	loss 0.7334 (0.7664)	grad_norm 2.3917 (1.9846)	loss_scale 16384.0000 (8448.3338)	mem 11634MB
[2024-07-29 12:24:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:39 lr 0.000066	 wd 0.0000	time 0.3388 (0.3899)	loss 0.7974 (0.7663)	grad_norm 1.9072 (1.9866)	loss_scale 16384.0000 (8778.8488)	mem 11634MB
[2024-07-29 12:25:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000066	 wd 0.0000	time 0.2958 (0.4001)	loss 0.7183 (0.7663)	grad_norm 2.0827 (1.9871)	loss_scale 16384.0000 (9082.9332)	mem 11634MB
[2024-07-29 12:25:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 11 training takes 0:16:46
[2024-07-29 12:26:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 58.388 (58.388)	Loss 0.3997 (0.3997)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 11634MB
[2024-07-29 12:27:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 84.804 Acc@5 97.276
[2024-07-29 12:27:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 12:27:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.05%
[2024-07-29 12:27:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][0/2502]	eta 11:52:24 lr 0.000066	 wd 0.0000	time 17.0842 (17.0842)	loss 0.7124 (0.7124)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 12:28:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:19:44 lr 0.000066	 wd 0.0000	time 0.2961 (0.4932)	loss 0.7393 (0.7667)	grad_norm 1.8961 (1.9913)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 12:28:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:15:47 lr 0.000065	 wd 0.0000	time 0.3165 (0.4117)	loss 0.7759 (0.7630)	grad_norm 1.7700 (2.0028)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 12:29:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:14:03 lr 0.000065	 wd 0.0000	time 0.2816 (0.3833)	loss 0.7222 (0.7695)	grad_norm 2.2879 (2.0136)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 12:29:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:12:55 lr 0.000065	 wd 0.0000	time 0.2787 (0.3691)	loss 0.7417 (0.7680)	grad_norm 1.7786 (1.9957)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 12:30:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:12:02 lr 0.000065	 wd 0.0000	time 0.2999 (0.3609)	loss 0.8081 (0.7695)	grad_norm 1.8505 (1.9996)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 12:30:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:11:15 lr 0.000065	 wd 0.0000	time 0.2757 (0.3553)	loss 0.8179 (0.7669)	grad_norm 2.0660 (1.9971)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 12:31:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:10:33 lr 0.000064	 wd 0.0000	time 0.2730 (0.3514)	loss 0.7559 (0.7678)	grad_norm 2.3563 (2.0108)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 12:31:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:09:53 lr 0.000064	 wd 0.0000	time 0.3080 (0.3485)	loss 1.0010 (0.7674)	grad_norm 1.8720 (2.0095)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 12:32:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:09:14 lr 0.000064	 wd 0.0000	time 0.2992 (0.3463)	loss 0.8833 (0.7673)	grad_norm 1.5482 (2.0052)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 12:32:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:08:37 lr 0.000064	 wd 0.0000	time 0.2936 (0.3443)	loss 0.6963 (0.7671)	grad_norm 2.1819 (inf)	loss_scale 8192.0000 (15614.7213)	mem 11634MB
[2024-07-29 12:33:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:08:24 lr 0.000064	 wd 0.0000	time 0.3081 (0.3597)	loss 0.7285 (0.7684)	grad_norm 1.9227 (inf)	loss_scale 8192.0000 (14940.5413)	mem 11634MB
[2024-07-29 12:34:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:07:53 lr 0.000063	 wd 0.0000	time 0.3170 (0.3638)	loss 0.8428 (0.7684)	grad_norm 2.4365 (inf)	loss_scale 8192.0000 (14378.6311)	mem 11634MB
[2024-07-29 12:35:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:07:40 lr 0.000063	 wd 0.0000	time 0.2898 (0.3830)	loss 0.7559 (0.7689)	grad_norm 2.0400 (inf)	loss_scale 8192.0000 (13903.1022)	mem 11634MB
[2024-07-29 12:36:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:07:00 lr 0.000063	 wd 0.0000	time 0.2756 (0.3812)	loss 0.9268 (0.7699)	grad_norm 1.8243 (inf)	loss_scale 8192.0000 (13495.4575)	mem 11634MB
[2024-07-29 12:36:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:06:32 lr 0.000063	 wd 0.0000	time 0.2867 (0.3921)	loss 0.7983 (0.7702)	grad_norm 2.0013 (inf)	loss_scale 8192.0000 (13142.1292)	mem 11634MB
[2024-07-29 12:37:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:05:51 lr 0.000063	 wd 0.0000	time 0.3196 (0.3900)	loss 0.7632 (0.7694)	grad_norm 1.9554 (inf)	loss_scale 8192.0000 (12832.9394)	mem 11634MB
[2024-07-29 12:38:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:05:19 lr 0.000062	 wd 0.0000	time 0.2996 (0.3983)	loss 0.8418 (0.7692)	grad_norm 1.8490 (inf)	loss_scale 8192.0000 (12560.1035)	mem 11634MB
[2024-07-29 12:39:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:04:38 lr 0.000062	 wd 0.0000	time 0.3162 (0.3966)	loss 0.6455 (0.7691)	grad_norm 2.3475 (inf)	loss_scale 8192.0000 (12317.5658)	mem 11634MB
[2024-07-29 12:40:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:04:06 lr 0.000062	 wd 0.0000	time 0.5859 (0.4095)	loss 0.7676 (0.7693)	grad_norm 1.7094 (inf)	loss_scale 8192.0000 (12100.5450)	mem 11634MB
[2024-07-29 12:40:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:03:24 lr 0.000062	 wd 0.0000	time 0.3012 (0.4070)	loss 0.6895 (0.7692)	grad_norm 1.7437 (inf)	loss_scale 8192.0000 (11905.2154)	mem 11634MB
[2024-07-29 12:41:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:02:45 lr 0.000062	 wd 0.0000	time 0.4185 (0.4117)	loss 0.8223 (0.7695)	grad_norm 2.2895 (inf)	loss_scale 8192.0000 (11728.4798)	mem 11634MB
[2024-07-29 12:42:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:02:04 lr 0.000061	 wd 0.0000	time 0.3067 (0.4132)	loss 0.8979 (0.7697)	grad_norm 1.5834 (inf)	loss_scale 8192.0000 (11567.8037)	mem 11634MB
[2024-07-29 12:43:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:01:23 lr 0.000061	 wd 0.0000	time 0.2796 (0.4130)	loss 0.7080 (0.7697)	grad_norm 1.8378 (inf)	loss_scale 8192.0000 (11421.0934)	mem 11634MB
[2024-07-29 12:43:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:41 lr 0.000061	 wd 0.0000	time 0.3410 (0.4094)	loss 0.7080 (0.7693)	grad_norm 1.7746 (inf)	loss_scale 8192.0000 (11286.6039)	mem 11634MB
[2024-07-29 12:44:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000061	 wd 0.0000	time 0.3231 (0.4061)	loss 0.7686 (0.7694)	grad_norm 2.1511 (inf)	loss_scale 8192.0000 (11162.8693)	mem 11634MB
[2024-07-29 12:44:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 12 training takes 0:17:00
[2024-07-29 12:44:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 36.798 (36.798)	Loss 0.4136 (0.4136)	Acc@1 91.016 (91.016)	Acc@5 98.633 (98.633)	Mem 11634MB
[2024-07-29 12:45:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 84.968 Acc@5 97.224
[2024-07-29 12:45:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-29 12:45:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.05%
[2024-07-29 12:45:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][0/2502]	eta 11:27:59 lr 0.000061	 wd 0.0000	time 16.4986 (16.4986)	loss 0.6543 (0.6543)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:45:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:19:35 lr 0.000061	 wd 0.0000	time 0.3179 (0.4893)	loss 0.6953 (0.7697)	grad_norm 2.1990 (1.9653)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:46:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:15:45 lr 0.000060	 wd 0.0000	time 0.2990 (0.4108)	loss 0.6597 (0.7624)	grad_norm 1.9876 (1.9423)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:46:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:14:02 lr 0.000060	 wd 0.0000	time 0.2667 (0.3826)	loss 0.7329 (0.7600)	grad_norm 2.0508 (1.9531)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:47:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:12:55 lr 0.000060	 wd 0.0000	time 0.3112 (0.3689)	loss 0.8198 (0.7634)	grad_norm 2.3327 (1.9762)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:48:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:12:02 lr 0.000060	 wd 0.0000	time 0.2946 (0.3608)	loss 0.7861 (0.7628)	grad_norm 1.8754 (1.9941)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:48:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:11:15 lr 0.000060	 wd 0.0000	time 0.3082 (0.3552)	loss 0.7100 (0.7612)	grad_norm 1.7398 (1.9944)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:49:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:10:32 lr 0.000059	 wd 0.0000	time 0.3032 (0.3509)	loss 0.7075 (0.7615)	grad_norm 2.2817 (1.9952)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 12:49:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:09:52 lr 0.000059	 wd 0.0000	time 0.3186 (0.3482)	loss 0.7798 (0.7617)	grad_norm 1.8511 (inf)	loss_scale 4096.0000 (7885.1835)	mem 11634MB
[2024-07-29 12:50:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:09:14 lr 0.000059	 wd 0.0000	time 0.3091 (0.3459)	loss 0.7417 (0.7631)	grad_norm 2.2322 (inf)	loss_scale 4096.0000 (7464.6304)	mem 11634MB
[2024-07-29 12:50:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:08:36 lr 0.000059	 wd 0.0000	time 0.2941 (0.3440)	loss 0.7715 (0.7649)	grad_norm 2.0392 (inf)	loss_scale 4096.0000 (7128.1039)	mem 11634MB
[2024-07-29 12:51:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:08:28 lr 0.000059	 wd 0.0000	time 0.4425 (0.3628)	loss 0.7651 (0.7649)	grad_norm 1.9876 (inf)	loss_scale 4096.0000 (6852.7084)	mem 11634MB
[2024-07-29 12:52:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:07:56 lr 0.000058	 wd 0.0000	time 0.3236 (0.3656)	loss 0.8325 (0.7647)	grad_norm 2.0711 (inf)	loss_scale 4096.0000 (6623.1740)	mem 11634MB
[2024-07-29 12:53:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:07:45 lr 0.000058	 wd 0.0000	time 0.3632 (0.3869)	loss 0.8418 (0.7651)	grad_norm 2.2330 (inf)	loss_scale 4096.0000 (6428.9254)	mem 11634MB
[2024-07-29 12:53:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:07:04 lr 0.000058	 wd 0.0000	time 0.3089 (0.3849)	loss 0.7729 (0.7644)	grad_norm 1.9478 (inf)	loss_scale 4096.0000 (6262.4069)	mem 11634MB
[2024-07-29 12:54:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:06:26 lr 0.000058	 wd 0.0000	time 0.2909 (0.3859)	loss 0.6836 (0.7654)	grad_norm 2.1354 (inf)	loss_scale 4096.0000 (6118.0759)	mem 11634MB
[2024-07-29 12:55:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:05:44 lr 0.000058	 wd 0.0000	time 0.3000 (0.3823)	loss 0.6118 (0.7658)	grad_norm 1.8717 (inf)	loss_scale 4096.0000 (5991.7751)	mem 11634MB
[2024-07-29 12:55:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:05:04 lr 0.000057	 wd 0.0000	time 0.3067 (0.3791)	loss 0.7588 (0.7665)	grad_norm 2.5775 (inf)	loss_scale 4096.0000 (5880.3245)	mem 11634MB
[2024-07-29 12:56:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:04:24 lr 0.000057	 wd 0.0000	time 0.3152 (0.3766)	loss 0.7505 (0.7672)	grad_norm 1.7870 (inf)	loss_scale 4096.0000 (5781.2504)	mem 11634MB
[2024-07-29 12:56:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:03:45 lr 0.000057	 wd 0.0000	time 0.2869 (0.3741)	loss 0.6729 (0.7671)	grad_norm 2.2151 (inf)	loss_scale 4096.0000 (5692.5997)	mem 11634MB
[2024-07-29 12:57:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:03:06 lr 0.000057	 wd 0.0000	time 0.2887 (0.3718)	loss 0.7861 (0.7668)	grad_norm 1.8545 (inf)	loss_scale 4096.0000 (5612.8096)	mem 11634MB
[2024-07-29 12:57:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:02:28 lr 0.000057	 wd 0.0000	time 0.2676 (0.3701)	loss 0.7573 (0.7670)	grad_norm 1.8262 (inf)	loss_scale 4096.0000 (5540.6149)	mem 11634MB
[2024-07-29 12:58:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:51 lr 0.000056	 wd 0.0000	time 0.2949 (0.3683)	loss 0.6709 (0.7665)	grad_norm 2.1476 (inf)	loss_scale 4096.0000 (5474.9805)	mem 11634MB
[2024-07-29 12:59:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:01:14 lr 0.000056	 wd 0.0000	time 0.3041 (0.3666)	loss 0.8057 (0.7668)	grad_norm 1.7892 (inf)	loss_scale 4096.0000 (5415.0508)	mem 11634MB
[2024-07-29 13:00:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:38 lr 0.000056	 wd 0.0000	time 0.3538 (0.3757)	loss 0.7070 (0.7668)	grad_norm 1.8551 (inf)	loss_scale 4096.0000 (5360.1133)	mem 11634MB
[2024-07-29 13:00:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000056	 wd 0.0000	time 0.2938 (0.3744)	loss 0.7456 (0.7669)	grad_norm 1.6584 (inf)	loss_scale 4096.0000 (5309.5690)	mem 11634MB
[2024-07-29 13:00:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 13 training takes 0:15:42
[2024-07-29 13:02:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 80.492 (80.492)	Loss 0.4102 (0.4102)	Acc@1 91.406 (91.406)	Acc@5 98.438 (98.438)	Mem 11634MB
[2024-07-29 13:02:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 85.006 Acc@5 97.284
[2024-07-29 13:02:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-29 13:02:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.05%
[2024-07-29 13:03:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][0/2502]	eta 1 day, 3:31:28 lr 0.000056	 wd 0.0000	time 39.6038 (39.6038)	loss 0.7012 (0.7012)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:03:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:28:37 lr 0.000055	 wd 0.0000	time 0.2826 (0.7151)	loss 0.7578 (0.7639)	grad_norm 1.9281 (2.0095)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:04:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:20:03 lr 0.000055	 wd 0.0000	time 0.3044 (0.5230)	loss 0.7227 (0.7599)	grad_norm 1.9539 (2.0099)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:04:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:16:48 lr 0.000055	 wd 0.0000	time 0.3133 (0.4578)	loss 0.8330 (0.7633)	grad_norm 1.8860 (2.0095)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:05:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:14:53 lr 0.000055	 wd 0.0000	time 0.3130 (0.4251)	loss 0.9399 (0.7637)	grad_norm 1.8686 (1.9949)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:05:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:13:31 lr 0.000055	 wd 0.0000	time 0.2903 (0.4055)	loss 0.7910 (0.7624)	grad_norm 1.8305 (1.9934)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:06:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:12:26 lr 0.000054	 wd 0.0000	time 0.3251 (0.3926)	loss 0.7354 (0.7641)	grad_norm 1.8428 (2.0046)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:06:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:11:30 lr 0.000054	 wd 0.0000	time 0.3301 (0.3831)	loss 0.6953 (0.7658)	grad_norm 1.5753 (2.0014)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:07:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:10:40 lr 0.000054	 wd 0.0000	time 0.3101 (0.3762)	loss 0.7627 (0.7647)	grad_norm 1.8109 (1.9971)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:07:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:09:54 lr 0.000054	 wd 0.0000	time 0.2931 (0.3711)	loss 0.8428 (0.7640)	grad_norm 2.0413 (1.9946)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:08:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:09:11 lr 0.000054	 wd 0.0000	time 0.3127 (0.3669)	loss 0.9087 (0.7636)	grad_norm 2.4282 (1.9996)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:09:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:08:29 lr 0.000053	 wd 0.0000	time 0.2952 (0.3633)	loss 0.6934 (0.7641)	grad_norm 1.9303 (2.0039)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:09:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:08:14 lr 0.000053	 wd 0.0000	time 0.6296 (0.3800)	loss 0.7505 (0.7644)	grad_norm 2.1247 (2.0052)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:10:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:07:39 lr 0.000053	 wd 0.0000	time 0.4989 (0.3822)	loss 0.7935 (0.7643)	grad_norm 1.5398 (2.0018)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:11:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:07:18 lr 0.000053	 wd 0.0000	time 0.2888 (0.3980)	loss 0.7749 (0.7635)	grad_norm 2.0533 (2.0016)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:12:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:06:35 lr 0.000053	 wd 0.0000	time 0.3980 (0.3943)	loss 0.8037 (0.7639)	grad_norm 2.3862 (2.0072)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:13:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:06:07 lr 0.000052	 wd 0.0000	time 0.3329 (0.4079)	loss 0.8208 (0.7643)	grad_norm 1.7182 (2.0098)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:13:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:05:23 lr 0.000052	 wd 0.0000	time 0.2999 (0.4040)	loss 0.8354 (0.7645)	grad_norm 1.9310 (2.0139)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:14:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:04:49 lr 0.000052	 wd 0.0000	time 0.3773 (0.4117)	loss 0.8745 (0.7647)	grad_norm 2.2924 (2.0155)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:15:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:04:06 lr 0.000052	 wd 0.0000	time 0.2998 (0.4097)	loss 0.7329 (0.7649)	grad_norm 1.7701 (2.0136)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:16:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:03:31 lr 0.000052	 wd 0.0000	time 0.3400 (0.4204)	loss 0.7764 (0.7650)	grad_norm 2.3691 (2.0178)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:16:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:02:47 lr 0.000051	 wd 0.0000	time 0.3023 (0.4171)	loss 0.7236 (0.7654)	grad_norm 1.6911 (2.0197)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:17:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:02:08 lr 0.000051	 wd 0.0000	time 0.3455 (0.4256)	loss 0.7007 (0.7660)	grad_norm 2.0401 (2.0205)	loss_scale 4096.0000 (4096.0000)	mem 11634MB
[2024-07-29 13:18:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:01:25 lr 0.000051	 wd 0.0000	time 0.3041 (0.4222)	loss 0.7949 (0.7662)	grad_norm 2.1661 (2.0218)	loss_scale 8192.0000 (4206.3659)	mem 11634MB
[2024-07-29 13:19:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:42 lr 0.000051	 wd 0.0000	time 0.3195 (0.4212)	loss 0.7178 (0.7665)	grad_norm 2.0652 (2.0210)	loss_scale 8192.0000 (4372.3648)	mem 11634MB
[2024-07-29 13:19:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000051	 wd 0.0000	time 0.3040 (0.4174)	loss 0.7622 (0.7666)	grad_norm 1.9867 (2.0196)	loss_scale 8192.0000 (4525.0892)	mem 11634MB
[2024-07-29 13:19:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 14 training takes 0:17:31
[2024-07-29 13:20:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 33.405 (33.405)	Loss 0.3877 (0.3877)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 11634MB
[2024-07-29 13:20:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 85.032 Acc@5 97.334
[2024-07-29 13:20:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-29 13:20:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.05%
[2024-07-29 13:20:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][0/2502]	eta 10:42:55 lr 0.000051	 wd 0.0000	time 15.4180 (15.4180)	loss 0.6641 (0.6641)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:21:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:19:30 lr 0.000050	 wd 0.0000	time 0.3069 (0.4872)	loss 0.8037 (0.7576)	grad_norm 2.1867 (2.0482)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:22:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:15:42 lr 0.000050	 wd 0.0000	time 0.3196 (0.4092)	loss 0.9634 (0.7669)	grad_norm 2.0456 (2.0400)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:22:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:14:00 lr 0.000050	 wd 0.0000	time 0.2985 (0.3816)	loss 0.6738 (0.7667)	grad_norm 1.7215 (2.0342)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:23:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:12:53 lr 0.000050	 wd 0.0000	time 0.3159 (0.3680)	loss 0.6172 (0.7670)	grad_norm 1.8185 (2.0439)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:23:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:12:00 lr 0.000049	 wd 0.0000	time 0.2982 (0.3601)	loss 0.7109 (0.7665)	grad_norm 2.1485 (2.0319)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:24:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:11:13 lr 0.000049	 wd 0.0000	time 0.2947 (0.3543)	loss 0.6689 (0.7671)	grad_norm 1.7709 (2.0170)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:24:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:10:31 lr 0.000049	 wd 0.0000	time 0.2736 (0.3502)	loss 0.8003 (0.7667)	grad_norm 1.8777 (2.0107)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:25:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:09:51 lr 0.000049	 wd 0.0000	time 0.3018 (0.3473)	loss 0.7246 (0.7660)	grad_norm 1.8159 (2.0030)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:25:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:09:12 lr 0.000049	 wd 0.0000	time 0.2972 (0.3452)	loss 0.7476 (0.7657)	grad_norm 2.0321 (2.0040)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:26:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:08:35 lr 0.000048	 wd 0.0000	time 0.2790 (0.3434)	loss 0.7471 (0.7657)	grad_norm 2.1036 (2.0002)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:27:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:07:59 lr 0.000048	 wd 0.0000	time 0.3228 (0.3420)	loss 0.8159 (0.7652)	grad_norm 2.3220 (2.0030)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:27:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:07:50 lr 0.000048	 wd 0.0000	time 0.3267 (0.3616)	loss 0.6738 (0.7648)	grad_norm 1.8086 (2.0084)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:28:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:07:13 lr 0.000048	 wd 0.0000	time 0.3603 (0.3611)	loss 0.8164 (0.7650)	grad_norm 1.8248 (2.0092)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:29:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:06:56 lr 0.000048	 wd 0.0000	time 0.2704 (0.3779)	loss 0.8091 (0.7649)	grad_norm 2.1588 (2.0103)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:30:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:06:15 lr 0.000047	 wd 0.0000	time 0.3278 (0.3752)	loss 0.7827 (0.7647)	grad_norm 1.9300 (2.0070)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:31:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:05:49 lr 0.000047	 wd 0.0000	time 0.3311 (0.3873)	loss 0.8154 (0.7646)	grad_norm 2.1262 (2.0119)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:31:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:05:09 lr 0.000047	 wd 0.0000	time 0.3089 (0.3856)	loss 0.7993 (0.7642)	grad_norm 1.9094 (2.0074)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:32:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:04:38 lr 0.000047	 wd 0.0000	time 0.3333 (0.3971)	loss 0.8042 (0.7654)	grad_norm 2.2633 (2.0108)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:33:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:03:57 lr 0.000047	 wd 0.0000	time 0.3124 (0.3950)	loss 0.7817 (0.7655)	grad_norm 2.2388 (2.0121)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:34:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:03:21 lr 0.000046	 wd 0.0000	time 0.3200 (0.4016)	loss 0.8379 (0.7655)	grad_norm 2.2399 (2.0135)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:34:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:02:40 lr 0.000046	 wd 0.0000	time 0.3400 (0.4001)	loss 0.7930 (0.7655)	grad_norm 1.8753 (2.0145)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:35:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:02:03 lr 0.000046	 wd 0.0000	time 0.2926 (0.4097)	loss 0.7725 (0.7658)	grad_norm 2.1820 (2.0133)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:36:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:01:22 lr 0.000046	 wd 0.0000	time 0.4430 (0.4076)	loss 0.8960 (0.7655)	grad_norm 2.1767 (2.0121)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:37:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:42 lr 0.000046	 wd 0.0000	time 0.3390 (0.4170)	loss 0.7427 (0.7657)	grad_norm 2.1941 (2.0126)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:38:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000045	 wd 0.0000	time 0.3090 (0.4144)	loss 0.9604 (0.7660)	grad_norm 1.8394 (2.0132)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:38:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 15 training takes 0:17:26
[2024-07-29 13:38:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune/diffusion_ft_conv_b_sequence_stage3/ckpt_epoch_15.pth saving......
[2024-07-29 13:38:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune/diffusion_ft_conv_b_sequence_stage3/ckpt_epoch_15.pth saved !!!
[2024-07-29 13:38:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 38.172 (38.172)	Loss 0.3938 (0.3938)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 11634MB
[2024-07-29 13:39:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 84.938 Acc@5 97.300
[2024-07-29 13:39:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-29 13:39:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.05%
[2024-07-29 13:39:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][0/2502]	eta 10:50:59 lr 0.000045	 wd 0.0000	time 15.6112 (15.6112)	loss 0.7559 (0.7559)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:39:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:19:27 lr 0.000045	 wd 0.0000	time 0.3082 (0.4861)	loss 0.8950 (0.7722)	grad_norm 1.9214 (1.9971)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:40:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:15:37 lr 0.000045	 wd 0.0000	time 0.2682 (0.4073)	loss 0.7974 (0.7740)	grad_norm 2.0171 (2.0052)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:41:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:13:57 lr 0.000045	 wd 0.0000	time 0.2975 (0.3805)	loss 0.7988 (0.7703)	grad_norm 1.7305 (2.0103)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:41:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:12:51 lr 0.000045	 wd 0.0000	time 0.3062 (0.3672)	loss 0.8335 (0.7687)	grad_norm 1.8641 (2.0026)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:42:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:11:58 lr 0.000044	 wd 0.0000	time 0.3095 (0.3591)	loss 0.7026 (0.7663)	grad_norm 2.3253 (2.0129)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:42:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:11:12 lr 0.000044	 wd 0.0000	time 0.3069 (0.3537)	loss 0.7466 (0.7680)	grad_norm 2.7561 (2.0407)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:43:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:10:31 lr 0.000044	 wd 0.0000	time 0.2989 (0.3503)	loss 0.7651 (0.7679)	grad_norm 1.9019 (2.0371)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:43:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:09:51 lr 0.000044	 wd 0.0000	time 0.3046 (0.3474)	loss 0.9155 (0.7677)	grad_norm 2.8074 (2.0386)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:44:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:09:12 lr 0.000043	 wd 0.0000	time 0.3084 (0.3451)	loss 0.7349 (0.7691)	grad_norm 2.8929 (2.0436)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:44:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:08:35 lr 0.000043	 wd 0.0000	time 0.2974 (0.3431)	loss 0.7085 (0.7701)	grad_norm 1.9616 (2.0388)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:45:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:07:59 lr 0.000043	 wd 0.0000	time 0.2892 (0.3418)	loss 0.6763 (0.7693)	grad_norm 1.9224 (2.0368)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:45:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:07:23 lr 0.000043	 wd 0.0000	time 0.2845 (0.3404)	loss 0.7969 (0.7700)	grad_norm 1.8119 (2.0380)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 13:46:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:06:48 lr 0.000043	 wd 0.0000	time 0.2941 (0.3395)	loss 0.7505 (0.7683)	grad_norm 2.3087 (2.0399)	loss_scale 16384.0000 (8607.5819)	mem 11634MB
[2024-07-29 13:47:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:06:30 lr 0.000042	 wd 0.0000	time 0.3377 (0.3540)	loss 0.7744 (0.7679)	grad_norm 1.9677 (2.0418)	loss_scale 16384.0000 (9162.6438)	mem 11634MB
[2024-07-29 13:48:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:05:55 lr 0.000042	 wd 0.0000	time 0.3636 (0.3548)	loss 0.7998 (0.7677)	grad_norm 2.3038 (2.0414)	loss_scale 16384.0000 (9643.7468)	mem 11634MB
[2024-07-29 13:49:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:05:53 lr 0.000042	 wd 0.0000	time 0.3021 (0.3925)	loss 0.7695 (0.7678)	grad_norm 2.1338 (2.0407)	loss_scale 16384.0000 (10064.7495)	mem 11634MB
[2024-07-29 13:50:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:05:16 lr 0.000042	 wd 0.0000	time 0.3139 (0.3943)	loss 0.6489 (0.7686)	grad_norm 1.9315 (2.0394)	loss_scale 16384.0000 (10436.2516)	mem 11634MB
[2024-07-29 13:50:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:04:34 lr 0.000042	 wd 0.0000	time 0.3077 (0.3906)	loss 0.7900 (0.7689)	grad_norm 1.9484 (2.0406)	loss_scale 16384.0000 (10766.4986)	mem 11634MB
[2024-07-29 13:51:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:03:53 lr 0.000041	 wd 0.0000	time 0.3082 (0.3874)	loss 0.8545 (0.7693)	grad_norm 2.4891 (2.0439)	loss_scale 16384.0000 (11062.0011)	mem 11634MB
[2024-07-29 13:51:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:03:13 lr 0.000041	 wd 0.0000	time 0.3310 (0.3849)	loss 0.6953 (0.7688)	grad_norm 1.6150 (2.0435)	loss_scale 16384.0000 (11327.9680)	mem 11634MB
[2024-07-29 13:52:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:02:33 lr 0.000041	 wd 0.0000	time 0.3136 (0.3823)	loss 0.7061 (0.7688)	grad_norm 1.7799 (2.0407)	loss_scale 16384.0000 (11568.6168)	mem 11634MB
[2024-07-29 13:53:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:54 lr 0.000041	 wd 0.0000	time 0.3017 (0.3798)	loss 0.7231 (0.7690)	grad_norm 1.9749 (2.0422)	loss_scale 16384.0000 (11787.3985)	mem 11634MB
[2024-07-29 13:53:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:01:16 lr 0.000041	 wd 0.0000	time 0.3191 (0.3780)	loss 0.7993 (0.7690)	grad_norm 1.8239 (2.0437)	loss_scale 16384.0000 (11987.1638)	mem 11634MB
[2024-07-29 13:54:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:38 lr 0.000040	 wd 0.0000	time 0.2810 (0.3760)	loss 0.7334 (0.7686)	grad_norm 1.9399 (2.0441)	loss_scale 16384.0000 (12170.2890)	mem 11634MB
[2024-07-29 13:54:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.3020 (0.3741)	loss 0.7603 (0.7683)	grad_norm 2.1155 (2.0457)	loss_scale 16384.0000 (12338.7701)	mem 11634MB
[2024-07-29 13:54:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 16 training takes 0:15:46
[2024-07-29 13:55:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 52.768 (52.768)	Loss 0.3972 (0.3972)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 11634MB
[2024-07-29 13:56:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 84.926 Acc@5 97.334
[2024-07-29 13:56:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-29 13:56:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.05%
[2024-07-29 13:56:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][0/2502]	eta 1 day, 4:19:39 lr 0.000040	 wd 0.0000	time 40.7591 (40.7591)	loss 0.7153 (0.7153)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 13:57:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:29:38 lr 0.000040	 wd 0.0000	time 0.3058 (0.7404)	loss 0.8276 (0.7653)	grad_norm 1.7384 (2.0317)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 13:57:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:20:30 lr 0.000040	 wd 0.0000	time 0.2951 (0.5346)	loss 0.8481 (0.7720)	grad_norm 2.2859 (2.0155)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 13:58:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:17:06 lr 0.000040	 wd 0.0000	time 0.3075 (0.4661)	loss 0.8003 (0.7719)	grad_norm 2.1313 (2.0258)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 13:59:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:15:05 lr 0.000039	 wd 0.0000	time 0.3029 (0.4309)	loss 0.7388 (0.7662)	grad_norm 1.8753 (2.0442)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 13:59:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:13:41 lr 0.000039	 wd 0.0000	time 0.3073 (0.4101)	loss 0.7305 (0.7671)	grad_norm 1.6726 (2.0499)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:00:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:12:33 lr 0.000039	 wd 0.0000	time 0.2997 (0.3963)	loss 0.8237 (0.7681)	grad_norm 2.2970 (2.0477)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:00:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:11:36 lr 0.000039	 wd 0.0000	time 0.3021 (0.3863)	loss 0.6929 (0.7671)	grad_norm 1.8713 (2.0511)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:01:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:10:44 lr 0.000039	 wd 0.0000	time 0.2992 (0.3788)	loss 0.6982 (0.7675)	grad_norm 2.1325 (2.0528)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:01:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:09:58 lr 0.000038	 wd 0.0000	time 0.3245 (0.3735)	loss 0.7231 (0.7682)	grad_norm 1.9337 (2.0557)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:02:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:09:13 lr 0.000038	 wd 0.0000	time 0.2914 (0.3687)	loss 0.8418 (0.7680)	grad_norm 2.3573 (2.0583)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:02:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:08:31 lr 0.000038	 wd 0.0000	time 0.3003 (0.3647)	loss 0.8218 (0.7689)	grad_norm 2.0067 (2.0589)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:03:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:07:51 lr 0.000038	 wd 0.0000	time 0.2889 (0.3620)	loss 0.8330 (0.7695)	grad_norm 2.2521 (2.0573)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:03:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:07:11 lr 0.000038	 wd 0.0000	time 0.2723 (0.3593)	loss 0.9028 (0.7685)	grad_norm 2.6664 (2.0639)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:04:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:06:33 lr 0.000037	 wd 0.0000	time 0.2733 (0.3570)	loss 0.7324 (0.7690)	grad_norm 1.9867 (2.0662)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:05:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:06:19 lr 0.000037	 wd 0.0000	time 0.3054 (0.3785)	loss 0.7393 (0.7694)	grad_norm 1.8287 (2.0663)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:06:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:05:40 lr 0.000037	 wd 0.0000	time 0.5496 (0.3774)	loss 0.6943 (0.7692)	grad_norm 2.5077 (2.0689)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:06:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:05:03 lr 0.000037	 wd 0.0000	time 0.3025 (0.3785)	loss 0.9307 (0.7690)	grad_norm 1.8316 (2.0673)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:07:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:04:23 lr 0.000037	 wd 0.0000	time 0.3100 (0.3757)	loss 0.6753 (0.7693)	grad_norm 2.0064 (2.0667)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:07:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:03:44 lr 0.000036	 wd 0.0000	time 0.3054 (0.3734)	loss 0.7358 (0.7694)	grad_norm 2.1318 (2.0637)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:08:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:03:06 lr 0.000036	 wd 0.0000	time 0.3066 (0.3713)	loss 0.7256 (0.7689)	grad_norm 2.2101 (2.0630)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:09:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:02:28 lr 0.000036	 wd 0.0000	time 0.3180 (0.3693)	loss 0.7285 (0.7688)	grad_norm 2.1762 (2.0615)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:09:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:51 lr 0.000036	 wd 0.0000	time 0.4877 (0.3695)	loss 0.7573 (0.7689)	grad_norm 2.0606 (2.0641)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:10:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:01:16 lr 0.000036	 wd 0.0000	time 0.3043 (0.3797)	loss 0.7559 (0.7687)	grad_norm 2.4370 (2.0621)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:12:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:40 lr 0.000035	 wd 0.0000	time 0.6806 (0.3976)	loss 0.6938 (0.7696)	grad_norm 2.2153 (2.0589)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:12:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.2869 (0.4016)	loss 0.9478 (0.7700)	grad_norm 2.0302 (2.0616)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:13:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 17 training takes 0:16:59
[2024-07-29 14:13:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 30.605 (30.605)	Loss 0.3931 (0.3931)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 11634MB
[2024-07-29 14:13:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 85.106 Acc@5 97.280
[2024-07-29 14:13:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-29 14:13:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.11%
[2024-07-29 14:13:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune/diffusion_ft_conv_b_sequence_stage3/ckpt_epoch_best.pth saving......
[2024-07-29 14:13:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune/diffusion_ft_conv_b_sequence_stage3/ckpt_epoch_best.pth saved !!!
[2024-07-29 14:14:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][0/2502]	eta 20:37:09 lr 0.000035	 wd 0.0000	time 29.6681 (29.6681)	loss 0.8296 (0.8296)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:15:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:24:39 lr 0.000035	 wd 0.0000	time 0.2833 (0.6160)	loss 0.7363 (0.7640)	grad_norm 2.1819 (2.1326)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:15:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:18:07 lr 0.000035	 wd 0.0000	time 0.3047 (0.4724)	loss 0.8301 (0.7626)	grad_norm 2.1282 (2.1227)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:16:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:15:34 lr 0.000035	 wd 0.0000	time 0.2964 (0.4246)	loss 0.8447 (0.7663)	grad_norm 1.9737 (inf)	loss_scale 16384.0000 (17363.7741)	mem 11634MB
[2024-07-29 14:16:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:14:01 lr 0.000034	 wd 0.0000	time 0.3163 (0.4001)	loss 0.7427 (0.7683)	grad_norm 1.9395 (inf)	loss_scale 16384.0000 (17119.4414)	mem 11634MB
[2024-07-29 14:17:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:12:51 lr 0.000034	 wd 0.0000	time 0.2987 (0.3852)	loss 0.7090 (0.7689)	grad_norm 2.0045 (inf)	loss_scale 16384.0000 (16972.6467)	mem 11634MB
[2024-07-29 14:17:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:11:54 lr 0.000034	 wd 0.0000	time 0.2992 (0.3755)	loss 0.7100 (0.7684)	grad_norm 1.9917 (inf)	loss_scale 16384.0000 (16874.7022)	mem 11634MB
[2024-07-29 14:18:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:11:04 lr 0.000034	 wd 0.0000	time 0.3206 (0.3685)	loss 0.8550 (0.7672)	grad_norm 2.0647 (inf)	loss_scale 16384.0000 (16804.7019)	mem 11634MB
[2024-07-29 14:18:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:10:18 lr 0.000034	 wd 0.0000	time 0.3138 (0.3632)	loss 0.7959 (0.7652)	grad_norm 1.9316 (inf)	loss_scale 16384.0000 (16752.1798)	mem 11634MB
[2024-07-29 14:19:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:09:35 lr 0.000033	 wd 0.0000	time 0.2906 (0.3592)	loss 0.8047 (0.7654)	grad_norm 2.3467 (inf)	loss_scale 16384.0000 (16711.3163)	mem 11634MB
[2024-07-29 14:19:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:08:54 lr 0.000033	 wd 0.0000	time 0.2784 (0.3559)	loss 0.7256 (0.7655)	grad_norm 2.6692 (inf)	loss_scale 16384.0000 (16678.6174)	mem 11634MB
[2024-07-29 14:20:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:08:15 lr 0.000033	 wd 0.0000	time 0.3055 (0.3531)	loss 0.7197 (0.7665)	grad_norm 2.0727 (inf)	loss_scale 16384.0000 (16651.8583)	mem 11634MB
[2024-07-29 14:21:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:07:37 lr 0.000033	 wd 0.0000	time 0.3217 (0.3514)	loss 1.0078 (0.7661)	grad_norm 1.8091 (inf)	loss_scale 16384.0000 (16629.5554)	mem 11634MB
[2024-07-29 14:22:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:07:28 lr 0.000033	 wd 0.0000	time 0.3119 (0.3734)	loss 0.6558 (0.7664)	grad_norm 1.8357 (inf)	loss_scale 16384.0000 (16610.6810)	mem 11634MB
[2024-07-29 14:23:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:07:16 lr 0.000032	 wd 0.0000	time 0.3169 (0.3963)	loss 0.7051 (0.7654)	grad_norm 2.1930 (inf)	loss_scale 16384.0000 (16594.5011)	mem 11634MB
[2024-07-29 14:24:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:06:54 lr 0.000032	 wd 0.0000	time 0.3221 (0.4138)	loss 0.6987 (0.7657)	grad_norm 3.0474 (inf)	loss_scale 16384.0000 (16580.4770)	mem 11634MB
[2024-07-29 14:24:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:06:08 lr 0.000032	 wd 0.0000	time 0.3195 (0.4085)	loss 0.7983 (0.7657)	grad_norm 2.0718 (inf)	loss_scale 16384.0000 (16568.2049)	mem 11634MB
[2024-07-29 14:25:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:05:23 lr 0.000032	 wd 0.0000	time 0.3072 (0.4037)	loss 0.8896 (0.7658)	grad_norm 1.9150 (inf)	loss_scale 16384.0000 (16557.3757)	mem 11634MB
[2024-07-29 14:25:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:04:40 lr 0.000032	 wd 0.0000	time 0.3204 (0.3995)	loss 0.8086 (0.7659)	grad_norm 1.8034 (inf)	loss_scale 16384.0000 (16547.7490)	mem 11634MB
[2024-07-29 14:26:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:03:58 lr 0.000032	 wd 0.0000	time 0.2855 (0.3958)	loss 0.8872 (0.7660)	grad_norm 1.7428 (inf)	loss_scale 16384.0000 (16539.1352)	mem 11634MB
[2024-07-29 14:27:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:03:17 lr 0.000031	 wd 0.0000	time 0.2971 (0.3926)	loss 0.8857 (0.7668)	grad_norm 2.0739 (inf)	loss_scale 16384.0000 (16531.3823)	mem 11634MB
[2024-07-29 14:27:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:02:36 lr 0.000031	 wd 0.0000	time 0.3098 (0.3899)	loss 0.6963 (0.7667)	grad_norm 1.9357 (inf)	loss_scale 16384.0000 (16524.3674)	mem 11634MB
[2024-07-29 14:28:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:56 lr 0.000031	 wd 0.0000	time 0.3167 (0.3871)	loss 0.6753 (0.7671)	grad_norm 2.0006 (inf)	loss_scale 16384.0000 (16517.9900)	mem 11634MB
[2024-07-29 14:28:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:01:17 lr 0.000031	 wd 0.0000	time 0.2864 (0.3845)	loss 0.7026 (0.7674)	grad_norm 2.0911 (inf)	loss_scale 16384.0000 (16512.1669)	mem 11634MB
[2024-07-29 14:29:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:39 lr 0.000031	 wd 0.0000	time 0.3151 (0.3907)	loss 0.7764 (0.7671)	grad_norm 2.1719 (inf)	loss_scale 16384.0000 (16506.8288)	mem 11634MB
[2024-07-29 14:30:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000030	 wd 0.0000	time 0.3121 (0.3884)	loss 0.7646 (0.7675)	grad_norm 2.0160 (inf)	loss_scale 16384.0000 (16501.9176)	mem 11634MB
[2024-07-29 14:30:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 18 training takes 0:16:24
[2024-07-29 14:32:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 98.884 (98.884)	Loss 0.3989 (0.3989)	Acc@1 91.602 (91.602)	Acc@5 98.438 (98.438)	Mem 11634MB
[2024-07-29 14:32:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 84.924 Acc@5 97.288
[2024-07-29 14:32:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-29 14:32:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.11%
[2024-07-29 14:32:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][0/2502]	eta 22:15:40 lr 0.000030	 wd 0.0000	time 32.0305 (32.0305)	loss 0.7500 (0.7500)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 14:33:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:25:40 lr 0.000030	 wd 0.0000	time 0.3032 (0.6414)	loss 0.9204 (0.7760)	grad_norm 2.0898 (inf)	loss_scale 8192.0000 (15410.6931)	mem 11634MB
[2024-07-29 14:34:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:18:37 lr 0.000030	 wd 0.0000	time 0.2931 (0.4856)	loss 0.6562 (0.7778)	grad_norm 2.5235 (inf)	loss_scale 8192.0000 (11819.3035)	mem 11634MB
[2024-07-29 14:34:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:15:57 lr 0.000030	 wd 0.0000	time 0.2760 (0.4349)	loss 0.6953 (0.7758)	grad_norm 1.7072 (inf)	loss_scale 8192.0000 (10614.2193)	mem 11634MB
[2024-07-29 14:35:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:14:17 lr 0.000030	 wd 0.0000	time 0.3067 (0.4079)	loss 0.8047 (0.7728)	grad_norm 1.7423 (inf)	loss_scale 8192.0000 (10010.1746)	mem 11634MB
[2024-07-29 14:35:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:13:05 lr 0.000029	 wd 0.0000	time 0.2985 (0.3922)	loss 0.7983 (0.7700)	grad_norm 1.8934 (inf)	loss_scale 8192.0000 (9647.2655)	mem 11634MB
[2024-07-29 14:36:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:12:04 lr 0.000029	 wd 0.0000	time 0.3136 (0.3812)	loss 0.7285 (0.7702)	grad_norm 1.9180 (inf)	loss_scale 8192.0000 (9405.1248)	mem 11634MB
[2024-07-29 14:36:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:11:12 lr 0.000029	 wd 0.0000	time 0.2744 (0.3731)	loss 0.8037 (0.7702)	grad_norm 2.2606 (inf)	loss_scale 8192.0000 (9232.0685)	mem 11634MB
[2024-07-29 14:37:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:10:25 lr 0.000029	 wd 0.0000	time 0.3567 (0.3677)	loss 0.6729 (0.7696)	grad_norm 2.0612 (inf)	loss_scale 8192.0000 (9102.2222)	mem 11634MB
[2024-07-29 14:37:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:09:41 lr 0.000029	 wd 0.0000	time 0.3071 (0.3630)	loss 0.6768 (0.7685)	grad_norm 2.4975 (inf)	loss_scale 8192.0000 (9001.1987)	mem 11634MB
[2024-07-29 14:38:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:09:00 lr 0.000028	 wd 0.0000	time 0.3072 (0.3596)	loss 0.6558 (0.7684)	grad_norm 2.5388 (inf)	loss_scale 8192.0000 (8920.3596)	mem 11634MB
[2024-07-29 14:38:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:08:20 lr 0.000028	 wd 0.0000	time 0.3010 (0.3566)	loss 0.8564 (0.7690)	grad_norm 2.0500 (inf)	loss_scale 8192.0000 (8854.2053)	mem 11634MB
[2024-07-29 14:39:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:07:41 lr 0.000028	 wd 0.0000	time 0.3089 (0.3545)	loss 0.7559 (0.7688)	grad_norm 1.8186 (inf)	loss_scale 8192.0000 (8799.0674)	mem 11634MB
[2024-07-29 14:40:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:07:03 lr 0.000028	 wd 0.0000	time 0.3245 (0.3523)	loss 0.6362 (0.7697)	grad_norm 2.1910 (inf)	loss_scale 8192.0000 (8752.4058)	mem 11634MB
[2024-07-29 14:40:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:06:26 lr 0.000028	 wd 0.0000	time 0.3956 (0.3507)	loss 0.6895 (0.7701)	grad_norm 2.1662 (inf)	loss_scale 8192.0000 (8712.4054)	mem 11634MB
[2024-07-29 14:41:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:06:06 lr 0.000028	 wd 0.0000	time 0.3302 (0.3661)	loss 0.8135 (0.7705)	grad_norm 2.4214 (inf)	loss_scale 8192.0000 (8677.7348)	mem 11634MB
[2024-07-29 14:42:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:05:47 lr 0.000027	 wd 0.0000	time 0.6902 (0.3851)	loss 0.7178 (0.7706)	grad_norm 2.1056 (inf)	loss_scale 8192.0000 (8647.3954)	mem 11634MB
[2024-07-29 14:43:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:05:19 lr 0.000027	 wd 0.0000	time 0.3433 (0.3979)	loss 0.6562 (0.7703)	grad_norm 2.0316 (inf)	loss_scale 8192.0000 (8620.6232)	mem 11634MB
[2024-07-29 14:44:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:04:39 lr 0.000027	 wd 0.0000	time 0.3135 (0.3977)	loss 0.6768 (0.7705)	grad_norm 1.9461 (inf)	loss_scale 8192.0000 (8596.8240)	mem 11634MB
[2024-07-29 14:44:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:03:57 lr 0.000027	 wd 0.0000	time 0.2875 (0.3941)	loss 0.7935 (0.7703)	grad_norm 2.1736 (inf)	loss_scale 8192.0000 (8575.5287)	mem 11634MB
[2024-07-29 14:45:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:03:16 lr 0.000027	 wd 0.0000	time 0.3268 (0.3909)	loss 0.8154 (0.7697)	grad_norm 1.9914 (inf)	loss_scale 8192.0000 (8556.3618)	mem 11634MB
[2024-07-29 14:46:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:02:36 lr 0.000026	 wd 0.0000	time 0.3081 (0.3883)	loss 0.8560 (0.7695)	grad_norm 2.1181 (inf)	loss_scale 8192.0000 (8539.0195)	mem 11634MB
[2024-07-29 14:46:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:56 lr 0.000026	 wd 0.0000	time 0.3004 (0.3856)	loss 0.7896 (0.7695)	grad_norm 2.1253 (inf)	loss_scale 8192.0000 (8523.2531)	mem 11634MB
[2024-07-29 14:47:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:01:17 lr 0.000026	 wd 0.0000	time 0.2832 (0.3832)	loss 0.8472 (0.7698)	grad_norm 1.5663 (inf)	loss_scale 8192.0000 (8508.8570)	mem 11634MB
[2024-07-29 14:47:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:38 lr 0.000026	 wd 0.0000	time 0.3094 (0.3811)	loss 0.9419 (0.7698)	grad_norm 2.5717 (inf)	loss_scale 8192.0000 (8495.6601)	mem 11634MB
[2024-07-29 14:48:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.3128 (0.3789)	loss 0.6826 (0.7696)	grad_norm 1.6829 (inf)	loss_scale 8192.0000 (8483.5186)	mem 11634MB
[2024-07-29 14:48:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 19 training takes 0:15:55
[2024-07-29 14:48:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 33.787 (33.787)	Loss 0.3997 (0.3997)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 11634MB
[2024-07-29 14:49:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 85.064 Acc@5 97.336
[2024-07-29 14:49:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-29 14:49:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.11%
[2024-07-29 14:49:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][0/2502]	eta 11:11:31 lr 0.000026	 wd 0.0000	time 16.1036 (16.1036)	loss 0.8555 (0.8555)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 14:50:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:19:21 lr 0.000026	 wd 0.0000	time 0.3021 (0.4838)	loss 0.7681 (0.7724)	grad_norm 2.3765 (2.1760)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 14:50:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:15:36 lr 0.000025	 wd 0.0000	time 0.3066 (0.4066)	loss 0.8091 (0.7722)	grad_norm 1.6986 (2.1099)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 14:51:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:13:55 lr 0.000025	 wd 0.0000	time 0.2892 (0.3796)	loss 0.7061 (0.7710)	grad_norm 2.1747 (2.0961)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 14:51:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:12:50 lr 0.000025	 wd 0.0000	time 0.3014 (0.3665)	loss 0.7002 (0.7685)	grad_norm 2.2247 (2.1007)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 14:52:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:11:58 lr 0.000025	 wd 0.0000	time 0.3062 (0.3586)	loss 0.8076 (0.7690)	grad_norm 2.0247 (2.1001)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 14:52:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:11:11 lr 0.000025	 wd 0.0000	time 0.3001 (0.3532)	loss 0.7480 (0.7688)	grad_norm 2.1561 (2.0960)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 14:53:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:10:29 lr 0.000025	 wd 0.0000	time 0.3141 (0.3496)	loss 0.6812 (0.7692)	grad_norm 2.0270 (2.0908)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 14:53:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:09:50 lr 0.000024	 wd 0.0000	time 0.3282 (0.3471)	loss 0.7715 (0.7704)	grad_norm 1.7613 (2.0853)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 14:54:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:09:12 lr 0.000024	 wd 0.0000	time 0.2874 (0.3448)	loss 0.9165 (0.7700)	grad_norm 2.6144 (2.0820)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 14:54:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:08:35 lr 0.000024	 wd 0.0000	time 0.2970 (0.3430)	loss 0.7085 (0.7714)	grad_norm 2.2854 (2.0771)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 14:56:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:08:53 lr 0.000024	 wd 0.0000	time 0.4613 (0.3805)	loss 0.7017 (0.7713)	grad_norm 2.0710 (2.0786)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 14:57:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:08:45 lr 0.000024	 wd 0.0000	time 0.3256 (0.4035)	loss 0.6567 (0.7708)	grad_norm 2.1815 (2.0726)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 14:57:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:07:57 lr 0.000023	 wd 0.0000	time 0.3035 (0.3976)	loss 0.7358 (0.7700)	grad_norm 2.2081 (2.0763)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 14:58:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:07:12 lr 0.000023	 wd 0.0000	time 0.2963 (0.3927)	loss 0.7559 (0.7701)	grad_norm 2.3979 (2.0797)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 14:58:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:06:29 lr 0.000023	 wd 0.0000	time 0.3032 (0.3886)	loss 0.8188 (0.7697)	grad_norm 2.7505 (2.0755)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 14:59:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:05:47 lr 0.000023	 wd 0.0000	time 0.2945 (0.3847)	loss 0.8359 (0.7687)	grad_norm 1.6808 (2.0730)	loss_scale 16384.0000 (8263.6352)	mem 11634MB
[2024-07-29 15:00:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:05:05 lr 0.000023	 wd 0.0000	time 0.3065 (0.3814)	loss 0.9502 (0.7687)	grad_norm 1.6052 (2.0723)	loss_scale 16384.0000 (8741.0229)	mem 11634MB
[2024-07-29 15:00:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:04:25 lr 0.000023	 wd 0.0000	time 0.3033 (0.3787)	loss 0.7686 (0.7686)	grad_norm 1.9617 (2.0726)	loss_scale 16384.0000 (9165.3970)	mem 11634MB
[2024-07-29 15:01:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:03:46 lr 0.000022	 wd 0.0000	time 0.2933 (0.3761)	loss 0.7754 (0.7685)	grad_norm 2.2717 (2.0704)	loss_scale 16384.0000 (9545.1236)	mem 11634MB
[2024-07-29 15:01:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:03:07 lr 0.000022	 wd 0.0000	time 0.3183 (0.3737)	loss 0.8325 (0.7685)	grad_norm 2.2222 (2.0732)	loss_scale 16384.0000 (9886.8966)	mem 11634MB
[2024-07-29 15:02:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:02:34 lr 0.000022	 wd 0.0000	time 0.3421 (0.3837)	loss 0.8291 (0.7689)	grad_norm 2.0179 (2.0756)	loss_scale 16384.0000 (10196.1352)	mem 11634MB
[2024-07-29 15:03:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:55 lr 0.000022	 wd 0.0000	time 0.3224 (0.3835)	loss 0.7876 (0.7688)	grad_norm 2.4870 (2.0749)	loss_scale 16384.0000 (10477.2740)	mem 11634MB
[2024-07-29 15:04:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:01:20 lr 0.000022	 wd 0.0000	time 0.2679 (0.3972)	loss 0.7466 (0.7690)	grad_norm 1.9956 (2.0770)	loss_scale 16384.0000 (10733.9765)	mem 11634MB
[2024-07-29 15:05:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:40 lr 0.000022	 wd 0.0000	time 1.1861 (0.3964)	loss 0.7427 (0.7694)	grad_norm 1.9651 (2.0790)	loss_scale 16384.0000 (10969.2961)	mem 11634MB
[2024-07-29 15:06:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.3145 (0.4129)	loss 0.7593 (0.7692)	grad_norm 1.6997 (2.0792)	loss_scale 16384.0000 (11185.7977)	mem 11634MB
[2024-07-29 15:06:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 20 training takes 0:17:22
[2024-07-29 15:07:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 38.979 (38.979)	Loss 0.3994 (0.3994)	Acc@1 91.016 (91.016)	Acc@5 98.633 (98.633)	Mem 11634MB
[2024-07-29 15:07:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 84.976 Acc@5 97.308
[2024-07-29 15:07:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-29 15:07:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.11%
[2024-07-29 15:07:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][0/2502]	eta 11:23:36 lr 0.000021	 wd 0.0000	time 16.3934 (16.3934)	loss 0.8164 (0.8164)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:08:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:19:32 lr 0.000021	 wd 0.0000	time 0.3124 (0.4879)	loss 0.7349 (0.7709)	grad_norm 2.0458 (2.0710)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:08:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:15:36 lr 0.000021	 wd 0.0000	time 0.2667 (0.4068)	loss 0.7900 (0.7741)	grad_norm 1.9988 (2.0640)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:09:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:13:56 lr 0.000021	 wd 0.0000	time 0.3162 (0.3797)	loss 0.7383 (0.7672)	grad_norm 1.8725 (2.0639)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:10:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:12:51 lr 0.000021	 wd 0.0000	time 0.2860 (0.3670)	loss 0.6777 (0.7660)	grad_norm 2.1064 (2.0632)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:10:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:11:57 lr 0.000021	 wd 0.0000	time 0.2987 (0.3586)	loss 0.9097 (0.7678)	grad_norm 2.0859 (2.0706)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:11:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:11:11 lr 0.000020	 wd 0.0000	time 0.2894 (0.3532)	loss 0.8604 (0.7683)	grad_norm 1.9565 (2.0666)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:11:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:10:29 lr 0.000020	 wd 0.0000	time 0.2982 (0.3495)	loss 0.7661 (0.7679)	grad_norm 2.4566 (2.0737)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:12:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:09:49 lr 0.000020	 wd 0.0000	time 0.3100 (0.3465)	loss 0.7803 (0.7675)	grad_norm 1.8797 (2.0661)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:12:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:09:11 lr 0.000020	 wd 0.0000	time 0.2728 (0.3440)	loss 0.7778 (0.7671)	grad_norm 1.8328 (2.0724)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:13:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:08:33 lr 0.000020	 wd 0.0000	time 0.3162 (0.3422)	loss 0.7207 (0.7664)	grad_norm 2.3373 (inf)	loss_scale 8192.0000 (16203.9560)	mem 11634MB
[2024-07-29 15:13:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:07:58 lr 0.000020	 wd 0.0000	time 0.2729 (0.3411)	loss 0.7227 (0.7674)	grad_norm 1.9295 (inf)	loss_scale 8192.0000 (15476.2579)	mem 11634MB
[2024-07-29 15:14:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:07:22 lr 0.000019	 wd 0.0000	time 0.2946 (0.3398)	loss 0.8159 (0.7673)	grad_norm 1.9348 (inf)	loss_scale 8192.0000 (14869.7419)	mem 11634MB
[2024-07-29 15:14:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:06:47 lr 0.000019	 wd 0.0000	time 0.3036 (0.3391)	loss 0.8892 (0.7672)	grad_norm 1.7408 (inf)	loss_scale 8192.0000 (14356.4643)	mem 11634MB
[2024-07-29 15:15:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:06:31 lr 0.000019	 wd 0.0000	time 0.4048 (0.3551)	loss 0.7168 (0.7674)	grad_norm 2.6144 (inf)	loss_scale 8192.0000 (13916.4597)	mem 11634MB
[2024-07-29 15:16:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:05:56 lr 0.000019	 wd 0.0000	time 0.4704 (0.3554)	loss 0.7783 (0.7673)	grad_norm 1.8983 (inf)	loss_scale 8192.0000 (13535.0833)	mem 11634MB
[2024-07-29 15:17:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:05:45 lr 0.000019	 wd 0.0000	time 0.2936 (0.3829)	loss 0.7524 (0.7667)	grad_norm 2.1269 (inf)	loss_scale 8192.0000 (13201.3492)	mem 11634MB
[2024-07-29 15:18:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:05:07 lr 0.000019	 wd 0.0000	time 0.2787 (0.3830)	loss 0.7559 (0.7665)	grad_norm 2.1356 (inf)	loss_scale 8192.0000 (12906.8548)	mem 11634MB
[2024-07-29 15:18:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:04:26 lr 0.000018	 wd 0.0000	time 0.2986 (0.3800)	loss 0.7983 (0.7661)	grad_norm 2.4851 (inf)	loss_scale 8192.0000 (12645.0639)	mem 11634MB
[2024-07-29 15:19:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:03:47 lr 0.000018	 wd 0.0000	time 0.3008 (0.3774)	loss 0.6895 (0.7659)	grad_norm 2.2319 (inf)	loss_scale 8192.0000 (12410.8154)	mem 11634MB
[2024-07-29 15:20:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:03:08 lr 0.000018	 wd 0.0000	time 0.3300 (0.3754)	loss 0.7749 (0.7661)	grad_norm 1.8977 (inf)	loss_scale 8192.0000 (12199.9800)	mem 11634MB
[2024-07-29 15:20:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:02:30 lr 0.000018	 wd 0.0000	time 0.3350 (0.3732)	loss 0.7886 (0.7663)	grad_norm 2.1391 (inf)	loss_scale 8192.0000 (12009.2147)	mem 11634MB
[2024-07-29 15:21:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:52 lr 0.000018	 wd 0.0000	time 0.3015 (0.3712)	loss 0.6499 (0.7664)	grad_norm 2.0436 (inf)	loss_scale 8192.0000 (11835.7837)	mem 11634MB
[2024-07-29 15:21:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:01:14 lr 0.000018	 wd 0.0000	time 0.3068 (0.3697)	loss 0.8228 (0.7671)	grad_norm 2.3506 (inf)	loss_scale 8192.0000 (11677.4272)	mem 11634MB
[2024-07-29 15:22:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:37 lr 0.000018	 wd 0.0000	time 0.3011 (0.3680)	loss 0.7539 (0.7673)	grad_norm 2.1637 (inf)	loss_scale 8192.0000 (11532.2616)	mem 11634MB
[2024-07-29 15:22:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000017	 wd 0.0000	time 0.3286 (0.3665)	loss 0.8125 (0.7677)	grad_norm 1.8943 (inf)	loss_scale 8192.0000 (11398.7045)	mem 11634MB
[2024-07-29 15:23:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 21 training takes 0:15:25
[2024-07-29 15:24:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 73.249 (73.249)	Loss 0.4019 (0.4019)	Acc@1 91.016 (91.016)	Acc@5 98.828 (98.828)	Mem 11634MB
[2024-07-29 15:24:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 85.110 Acc@5 97.294
[2024-07-29 15:24:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-29 15:24:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.11%
[2024-07-29 15:24:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune/diffusion_ft_conv_b_sequence_stage3/ckpt_epoch_best.pth saving......
[2024-07-29 15:24:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune/diffusion_ft_conv_b_sequence_stage3/ckpt_epoch_best.pth saved !!!
[2024-07-29 15:25:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][0/2502]	eta 23:01:50 lr 0.000017	 wd 0.0000	time 33.1378 (33.1378)	loss 0.8237 (0.8237)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:25:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:26:04 lr 0.000017	 wd 0.0000	time 0.3077 (0.6512)	loss 0.8594 (0.7805)	grad_norm 1.7306 (2.0883)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:26:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:18:47 lr 0.000017	 wd 0.0000	time 0.2998 (0.4896)	loss 0.6387 (0.7771)	grad_norm 2.1593 (2.0772)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:26:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:15:59 lr 0.000017	 wd 0.0000	time 0.2748 (0.4355)	loss 0.8423 (0.7738)	grad_norm 2.3108 (2.1137)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:27:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:14:17 lr 0.000017	 wd 0.0000	time 0.3011 (0.4080)	loss 0.8462 (0.7750)	grad_norm 2.0002 (2.0948)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:27:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:13:04 lr 0.000017	 wd 0.0000	time 0.2763 (0.3919)	loss 0.8540 (0.7767)	grad_norm 1.8409 (2.0924)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:28:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:12:05 lr 0.000016	 wd 0.0000	time 0.3011 (0.3814)	loss 0.8818 (0.7761)	grad_norm 2.2288 (2.0864)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:28:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:11:13 lr 0.000016	 wd 0.0000	time 0.2962 (0.3735)	loss 0.7505 (0.7765)	grad_norm 1.8298 (2.0821)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:29:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:10:25 lr 0.000016	 wd 0.0000	time 0.3291 (0.3677)	loss 0.6890 (0.7770)	grad_norm 2.1991 (2.0838)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:30:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:09:41 lr 0.000016	 wd 0.0000	time 0.3125 (0.3633)	loss 0.7817 (0.7756)	grad_norm 1.9052 (2.0925)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:30:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:08:59 lr 0.000016	 wd 0.0000	time 0.3037 (0.3595)	loss 0.6831 (0.7764)	grad_norm 2.8262 (2.0930)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:31:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:08:19 lr 0.000016	 wd 0.0000	time 0.3113 (0.3565)	loss 0.6953 (0.7764)	grad_norm 2.2883 (2.1051)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:32:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:08:19 lr 0.000016	 wd 0.0000	time 0.5156 (0.3836)	loss 0.7856 (0.7766)	grad_norm 2.2534 (2.1018)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:33:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:07:57 lr 0.000015	 wd 0.0000	time 0.2993 (0.3976)	loss 0.7266 (0.7764)	grad_norm 2.5707 (2.0963)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:33:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:07:12 lr 0.000015	 wd 0.0000	time 0.2785 (0.3926)	loss 0.7490 (0.7762)	grad_norm 2.0497 (2.0967)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:34:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:06:29 lr 0.000015	 wd 0.0000	time 0.3171 (0.3884)	loss 0.6255 (0.7765)	grad_norm 1.9710 (2.0955)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:34:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:05:46 lr 0.000015	 wd 0.0000	time 0.3173 (0.3845)	loss 0.8804 (0.7766)	grad_norm 1.8511 (2.0932)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:35:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:05:05 lr 0.000015	 wd 0.0000	time 0.3003 (0.3813)	loss 0.6636 (0.7757)	grad_norm 1.9122 (2.0950)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:35:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:04:25 lr 0.000015	 wd 0.0000	time 0.2871 (0.3783)	loss 0.9072 (0.7752)	grad_norm 1.8382 (2.0998)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:36:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:03:46 lr 0.000015	 wd 0.0000	time 0.2709 (0.3759)	loss 0.8218 (0.7756)	grad_norm 2.0038 (2.1021)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:37:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:03:07 lr 0.000014	 wd 0.0000	time 0.3214 (0.3736)	loss 0.7598 (0.7756)	grad_norm 2.0395 (2.1005)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:37:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:02:29 lr 0.000014	 wd 0.0000	time 0.3050 (0.3714)	loss 0.7598 (0.7756)	grad_norm 1.8971 (2.1055)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:38:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:54 lr 0.000014	 wd 0.0000	time 0.3372 (0.3783)	loss 0.6538 (0.7750)	grad_norm 1.8863 (2.1054)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:39:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:01:16 lr 0.000014	 wd 0.0000	time 0.2914 (0.3788)	loss 0.7456 (0.7746)	grad_norm 2.4231 (2.1044)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:40:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:40 lr 0.000014	 wd 0.0000	time 0.3817 (0.4003)	loss 0.7417 (0.7751)	grad_norm 2.1630 (2.1012)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 15:41:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.3056 (0.3985)	loss 0.7549 (0.7749)	grad_norm 2.1540 (2.0988)	loss_scale 16384.0000 (8270.6118)	mem 11634MB
[2024-07-29 15:41:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 22 training takes 0:16:51
[2024-07-29 15:41:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 31.251 (31.251)	Loss 0.3977 (0.3977)	Acc@1 91.211 (91.211)	Acc@5 98.633 (98.633)	Mem 11634MB
[2024-07-29 15:42:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 85.090 Acc@5 97.310
[2024-07-29 15:42:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-29 15:42:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.11%
[2024-07-29 15:42:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][0/2502]	eta 21:46:52 lr 0.000014	 wd 0.0000	time 31.3400 (31.3400)	loss 0.7793 (0.7793)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:43:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:26:01 lr 0.000014	 wd 0.0000	time 0.3032 (0.6502)	loss 0.8398 (0.7675)	grad_norm 1.9835 (2.0925)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:43:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:18:46 lr 0.000013	 wd 0.0000	time 0.2843 (0.4895)	loss 0.7202 (0.7680)	grad_norm 2.0989 (2.0765)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:44:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:16:01 lr 0.000013	 wd 0.0000	time 0.2987 (0.4369)	loss 0.7588 (0.7695)	grad_norm 1.8900 (2.0784)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:45:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:14:20 lr 0.000013	 wd 0.0000	time 0.2956 (0.4093)	loss 0.8965 (0.7721)	grad_norm 2.0283 (2.0837)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:45:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:13:05 lr 0.000013	 wd 0.0000	time 0.3118 (0.3926)	loss 0.8877 (0.7742)	grad_norm 2.5218 (2.0955)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:46:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:12:07 lr 0.000013	 wd 0.0000	time 0.3049 (0.3823)	loss 0.9019 (0.7751)	grad_norm 2.9896 (2.0906)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:46:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:11:14 lr 0.000013	 wd 0.0000	time 0.3081 (0.3741)	loss 0.8467 (0.7762)	grad_norm 2.0330 (2.0858)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:47:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:10:26 lr 0.000013	 wd 0.0000	time 0.3035 (0.3683)	loss 0.7178 (0.7744)	grad_norm 1.9941 (2.0824)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:47:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:09:52 lr 0.000012	 wd 0.0000	time 0.3855 (0.3701)	loss 0.9683 (0.7736)	grad_norm 2.1290 (2.0838)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:48:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:09:51 lr 0.000012	 wd 0.0000	time 0.2940 (0.3937)	loss 0.6763 (0.7746)	grad_norm 2.5255 (2.0798)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:49:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:09:14 lr 0.000012	 wd 0.0000	time 0.2988 (0.3956)	loss 0.7534 (0.7736)	grad_norm 2.1299 (2.0778)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:50:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:08:27 lr 0.000012	 wd 0.0000	time 0.3081 (0.3899)	loss 0.7568 (0.7738)	grad_norm 2.7017 (2.0794)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:50:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:07:42 lr 0.000012	 wd 0.0000	time 0.3136 (0.3850)	loss 0.8252 (0.7727)	grad_norm 2.0879 (2.0749)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:51:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:06:59 lr 0.000012	 wd 0.0000	time 0.3017 (0.3810)	loss 0.7964 (0.7725)	grad_norm 2.1298 (2.0794)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:51:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:06:18 lr 0.000012	 wd 0.0000	time 0.2996 (0.3774)	loss 0.8579 (0.7718)	grad_norm 2.5120 (2.0794)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:52:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:05:37 lr 0.000012	 wd 0.0000	time 0.3033 (0.3744)	loss 0.7715 (0.7720)	grad_norm 2.2099 (2.0767)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:52:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:04:58 lr 0.000011	 wd 0.0000	time 0.2721 (0.3718)	loss 0.6782 (0.7721)	grad_norm 1.9583 (2.0809)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:53:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:04:19 lr 0.000011	 wd 0.0000	time 0.2831 (0.3692)	loss 0.8364 (0.7725)	grad_norm 2.0527 (2.0823)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:53:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:03:40 lr 0.000011	 wd 0.0000	time 0.3178 (0.3670)	loss 0.7456 (0.7725)	grad_norm 2.0554 (2.0841)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:54:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:03:07 lr 0.000011	 wd 0.0000	time 0.2932 (0.3743)	loss 0.8657 (0.7720)	grad_norm 2.2097 (2.0846)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:55:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:02:30 lr 0.000011	 wd 0.0000	time 0.3096 (0.3747)	loss 0.7959 (0.7725)	grad_norm 2.1286 (2.0851)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:56:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:02:00 lr 0.000011	 wd 0.0000	time 0.5294 (0.4002)	loss 0.8306 (0.7723)	grad_norm 1.7486 (2.0872)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:57:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:01:22 lr 0.000011	 wd 0.0000	time 0.3074 (0.4072)	loss 0.8555 (0.7725)	grad_norm 2.2297 (2.0887)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:58:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:41 lr 0.000011	 wd 0.0000	time 0.2706 (0.4040)	loss 0.7964 (0.7724)	grad_norm 2.0419 (2.0880)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:59:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.3242 (0.4009)	loss 0.8281 (0.7721)	grad_norm 1.8054 (2.0886)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 15:59:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 23 training takes 0:16:53
[2024-07-29 15:59:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 31.168 (31.168)	Loss 0.4028 (0.4028)	Acc@1 91.211 (91.211)	Acc@5 98.633 (98.633)	Mem 11634MB
[2024-07-29 16:00:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 85.106 Acc@5 97.316
[2024-07-29 16:00:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-29 16:00:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.11%
[2024-07-29 16:00:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][0/2502]	eta 11:42:57 lr 0.000010	 wd 0.0000	time 16.8576 (16.8576)	loss 0.7261 (0.7261)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 16:00:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:19:42 lr 0.000010	 wd 0.0000	time 0.3169 (0.4923)	loss 0.8242 (0.7611)	grad_norm 1.8325 (2.0817)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 16:01:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:15:41 lr 0.000010	 wd 0.0000	time 0.3002 (0.4089)	loss 0.8027 (0.7703)	grad_norm 2.2067 (2.0811)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 16:01:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:14:00 lr 0.000010	 wd 0.0000	time 0.3100 (0.3815)	loss 0.7266 (0.7686)	grad_norm 2.0303 (2.0695)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 16:02:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:12:53 lr 0.000010	 wd 0.0000	time 0.2777 (0.3678)	loss 0.7930 (0.7687)	grad_norm 2.1333 (2.0552)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 16:03:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:11:58 lr 0.000010	 wd 0.0000	time 0.2785 (0.3591)	loss 0.7476 (0.7694)	grad_norm 2.5736 (2.0629)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 16:03:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:11:12 lr 0.000010	 wd 0.0000	time 0.3134 (0.3534)	loss 0.7148 (0.7694)	grad_norm 2.3853 (2.0605)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 16:04:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:10:30 lr 0.000010	 wd 0.0000	time 0.2992 (0.3497)	loss 0.7251 (0.7697)	grad_norm 1.8003 (2.0641)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 16:04:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:09:50 lr 0.000010	 wd 0.0000	time 0.3034 (0.3469)	loss 0.6914 (0.7705)	grad_norm 1.8795 (2.0657)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 16:05:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:09:12 lr 0.000009	 wd 0.0000	time 0.2923 (0.3447)	loss 0.7935 (0.7710)	grad_norm 1.9852 (2.0651)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 16:05:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:08:35 lr 0.000009	 wd 0.0000	time 0.2862 (0.3433)	loss 0.8394 (0.7725)	grad_norm 1.9491 (2.0708)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 16:06:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:07:59 lr 0.000009	 wd 0.0000	time 0.2812 (0.3419)	loss 0.6924 (0.7709)	grad_norm 2.1693 (2.0678)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 16:06:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:07:23 lr 0.000009	 wd 0.0000	time 0.2817 (0.3405)	loss 0.6699 (0.7706)	grad_norm 2.3615 (2.0673)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 16:07:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:07:14 lr 0.000009	 wd 0.0000	time 0.4614 (0.3617)	loss 0.8447 (0.7717)	grad_norm 2.1594 (2.0739)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 16:08:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:06:43 lr 0.000009	 wd 0.0000	time 0.2914 (0.3665)	loss 0.8613 (0.7721)	grad_norm 1.9024 (2.0712)	loss_scale 16384.0000 (16384.0000)	mem 11634MB
[2024-07-29 16:09:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:06:09 lr 0.000009	 wd 0.0000	time 0.3028 (0.3690)	loss 0.6729 (0.7725)	grad_norm 1.8288 (inf)	loss_scale 8192.0000 (16078.3691)	mem 11634MB
[2024-07-29 16:09:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:05:30 lr 0.000009	 wd 0.0000	time 0.2864 (0.3664)	loss 0.7485 (0.7724)	grad_norm 2.5909 (inf)	loss_scale 8192.0000 (15585.7789)	mem 11634MB
[2024-07-29 16:10:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:04:52 lr 0.000008	 wd 0.0000	time 0.3090 (0.3642)	loss 0.8091 (0.7730)	grad_norm 1.8581 (inf)	loss_scale 8192.0000 (15151.1064)	mem 11634MB
[2024-07-29 16:10:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:04:14 lr 0.000008	 wd 0.0000	time 0.3081 (0.3626)	loss 0.7363 (0.7725)	grad_norm 2.2845 (inf)	loss_scale 8192.0000 (14764.7041)	mem 11634MB
[2024-07-29 16:11:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:03:37 lr 0.000008	 wd 0.0000	time 0.3021 (0.3608)	loss 0.6001 (0.7729)	grad_norm 1.8652 (inf)	loss_scale 8192.0000 (14418.9542)	mem 11634MB
[2024-07-29 16:11:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:03:00 lr 0.000008	 wd 0.0000	time 0.3274 (0.3592)	loss 0.8662 (0.7725)	grad_norm 2.5172 (inf)	loss_scale 8192.0000 (14107.7621)	mem 11634MB
[2024-07-29 16:12:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:02:24 lr 0.000008	 wd 0.0000	time 0.3108 (0.3583)	loss 0.7534 (0.7720)	grad_norm 2.3747 (inf)	loss_scale 8192.0000 (13826.1932)	mem 11634MB
[2024-07-29 16:13:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:47 lr 0.000008	 wd 0.0000	time 0.3124 (0.3570)	loss 0.8052 (0.7718)	grad_norm 2.0019 (inf)	loss_scale 8192.0000 (13570.2099)	mem 11634MB
[2024-07-29 16:13:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:01:11 lr 0.000008	 wd 0.0000	time 0.3168 (0.3558)	loss 0.8433 (0.7720)	grad_norm 2.0320 (inf)	loss_scale 8192.0000 (13336.4763)	mem 11634MB
[2024-07-29 16:14:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:36 lr 0.000008	 wd 0.0000	time 0.2836 (0.3612)	loss 0.8389 (0.7722)	grad_norm 1.9831 (inf)	loss_scale 8192.0000 (13122.2124)	mem 11634MB
[2024-07-29 16:15:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.3084 (0.3614)	loss 0.8545 (0.7725)	grad_norm 2.2010 (inf)	loss_scale 8192.0000 (12925.0828)	mem 11634MB
[2024-07-29 16:15:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 24 training takes 0:15:12
[2024-07-29 16:16:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 72.795 (72.795)	Loss 0.4001 (0.4001)	Acc@1 90.820 (90.820)	Acc@5 98.633 (98.633)	Mem 11634MB
[2024-07-29 16:16:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 85.156 Acc@5 97.324
[2024-07-29 16:16:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-29 16:16:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.16%
[2024-07-29 16:16:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune/diffusion_ft_conv_b_sequence_stage3/ckpt_epoch_best.pth saving......
[2024-07-29 16:16:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune/diffusion_ft_conv_b_sequence_stage3/ckpt_epoch_best.pth saved !!!
[2024-07-29 16:17:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][0/2502]	eta 1 day, 2:02:49 lr 0.000008	 wd 0.0000	time 37.4779 (37.4779)	loss 0.7646 (0.7646)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:18:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:27:44 lr 0.000008	 wd 0.0000	time 0.3011 (0.6932)	loss 0.8042 (0.7747)	grad_norm 2.1154 (2.0920)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:18:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:19:38 lr 0.000007	 wd 0.0000	time 0.3290 (0.5119)	loss 0.7134 (0.7758)	grad_norm 2.1336 (2.1095)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:19:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:16:31 lr 0.000007	 wd 0.0000	time 0.3017 (0.4504)	loss 0.8301 (0.7777)	grad_norm 2.3632 (2.0949)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:19:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:14:42 lr 0.000007	 wd 0.0000	time 0.3014 (0.4197)	loss 0.8354 (0.7761)	grad_norm 1.9273 (2.1052)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:20:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:13:23 lr 0.000007	 wd 0.0000	time 0.2825 (0.4011)	loss 0.7651 (0.7762)	grad_norm 2.0467 (2.1002)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:20:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:12:19 lr 0.000007	 wd 0.0000	time 0.2832 (0.3887)	loss 0.7568 (0.7765)	grad_norm 1.9965 (2.1024)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:21:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:11:24 lr 0.000007	 wd 0.0000	time 0.2901 (0.3796)	loss 0.8179 (0.7762)	grad_norm 1.8663 (2.0930)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:21:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:10:34 lr 0.000007	 wd 0.0000	time 0.3143 (0.3728)	loss 0.8237 (0.7759)	grad_norm 1.9248 (2.0894)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:22:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:09:49 lr 0.000007	 wd 0.0000	time 0.2653 (0.3681)	loss 0.7363 (0.7756)	grad_norm 1.8840 (2.0891)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:22:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:09:06 lr 0.000007	 wd 0.0000	time 0.2810 (0.3639)	loss 0.8657 (0.7757)	grad_norm 1.8423 (2.0883)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:23:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:08:25 lr 0.000007	 wd 0.0000	time 0.3146 (0.3604)	loss 0.7090 (0.7757)	grad_norm 1.8985 (2.0897)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:25:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:08:49 lr 0.000006	 wd 0.0000	time 0.6182 (0.4070)	loss 0.9658 (0.7769)	grad_norm 2.3410 (2.0842)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:25:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:08:21 lr 0.000006	 wd 0.0000	time 0.2882 (0.4172)	loss 0.7856 (0.7772)	grad_norm 1.8547 (2.0815)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:26:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:07:32 lr 0.000006	 wd 0.0000	time 0.2997 (0.4107)	loss 0.7764 (0.7770)	grad_norm 1.6582 (2.0780)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:27:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:06:46 lr 0.000006	 wd 0.0000	time 0.3463 (0.4054)	loss 0.8125 (0.7770)	grad_norm 2.0138 (2.0780)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:27:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:06:01 lr 0.000006	 wd 0.0000	time 0.2991 (0.4005)	loss 0.7930 (0.7764)	grad_norm 1.7799 (2.0735)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:28:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:05:17 lr 0.000006	 wd 0.0000	time 0.2956 (0.3961)	loss 0.7456 (0.7762)	grad_norm 2.2068 (2.0744)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:28:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:04:35 lr 0.000006	 wd 0.0000	time 0.3006 (0.3925)	loss 0.9712 (0.7771)	grad_norm 2.8413 (2.0703)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:29:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:03:54 lr 0.000006	 wd 0.0000	time 0.2976 (0.3892)	loss 1.0127 (0.7773)	grad_norm 2.0515 (2.0738)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:29:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:03:13 lr 0.000006	 wd 0.0000	time 0.2854 (0.3862)	loss 0.7998 (0.7771)	grad_norm 1.9280 (2.0736)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:30:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:02:35 lr 0.000006	 wd 0.0000	time 0.6755 (0.3861)	loss 0.8311 (0.7771)	grad_norm 1.7065 (2.0736)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:31:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:02:01 lr 0.000006	 wd 0.0000	time 0.3113 (0.4030)	loss 0.6836 (0.7764)	grad_norm 2.0050 (2.0693)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:32:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:01:21 lr 0.000005	 wd 0.0000	time 0.2900 (0.4024)	loss 0.7637 (0.7761)	grad_norm 1.7183 (2.0684)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:32:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:40 lr 0.000005	 wd 0.0000	time 0.2874 (0.3993)	loss 0.7646 (0.7759)	grad_norm 1.6524 (2.0671)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:33:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000005	 wd 0.0000	time 0.3045 (0.3964)	loss 0.6973 (0.7755)	grad_norm 1.9935 (2.0674)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:33:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 249): INFO EPOCH 25 training takes 0:16:42
[2024-07-29 16:34:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 289): INFO Test: [0/98]	Time 30.345 (30.345)	Loss 0.4004 (0.4004)	Acc@1 90.820 (90.820)	Acc@5 98.633 (98.633)	Mem 11634MB
[2024-07-29 16:34:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 296): INFO  * Acc@1 85.140 Acc@5 97.356
[2024-07-29 16:34:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-29 16:34:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 182): INFO Max accuracy: 85.16%
[2024-07-29 16:34:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [26/30][0/2502]	eta 11:21:43 lr 0.000005	 wd 0.0000	time 16.3482 (16.3482)	loss 0.7832 (0.7832)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:35:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:19:28 lr 0.000005	 wd 0.0000	time 0.3137 (0.4865)	loss 0.8750 (0.7791)	grad_norm 1.9491 (2.0610)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:35:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:15:36 lr 0.000005	 wd 0.0000	time 0.3118 (0.4069)	loss 0.7822 (0.7789)	grad_norm 3.4048 (2.1211)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:36:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:13:55 lr 0.000005	 wd 0.0000	time 0.2836 (0.3794)	loss 0.7227 (0.7787)	grad_norm 1.8848 (2.0949)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:36:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:12:50 lr 0.000005	 wd 0.0000	time 0.3175 (0.3666)	loss 0.7939 (0.7768)	grad_norm 1.7872 (2.0757)	loss_scale 8192.0000 (8192.0000)	mem 11634MB
[2024-07-29 16:37:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:11:58 lr 0.000005	 wd 0.0000	time 0.3012 (0.3588)	loss 0.8691 (0.7778)	grad_norm 1.9665 (2.0608)	loss_scale 16384.0000 (9173.0778)	mem 11634MB
[2024-07-29 16:37:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:11:11 lr 0.000005	 wd 0.0000	time 0.3222 (0.3531)	loss 0.7544 (0.7779)	grad_norm 2.3954 (2.0644)	loss_scale 16384.0000 (10372.8985)	mem 11634MB
[2024-07-29 16:38:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:10:30 lr 0.000005	 wd 0.0000	time 0.3134 (0.3498)	loss 0.9053 (0.7769)	grad_norm 1.7811 (2.0642)	loss_scale 16384.0000 (11230.4023)	mem 11634MB
[2024-07-29 16:39:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:09:50 lr 0.000005	 wd 0.0000	time 0.2817 (0.3471)	loss 0.7705 (0.7765)	grad_norm 2.0243 (2.0657)	loss_scale 16384.0000 (11873.7978)	mem 11634MB
[2024-07-29 16:39:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process3-full-finetune] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:09:12 lr 0.000005	 wd 0.0000	time 0.3060 (0.3448)	loss 0.8115 (0.7762)	grad_norm 1.6561 (2.0631)	loss_scale 16384.0000 (12374.3751)	mem 11634MB
