[2024-07-26 14:48:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 366): INFO Full config saved to pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/config.json
[2024-07-26 14:48:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: convnext_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 27
    - 3
    DIMS:
    - 128
    - 256
    - 512
    - 1024
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: stage2
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_conv_b_step_stage2
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 0.0001
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 0.8
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.0e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 1.0e-08

[2024-07-26 14:48:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/diffusion_finetune/convnext/convnext/diffusion_ft_convnext_base_224_22kto1k_step_stage_process2.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/diffusion-ft", "tag": "diffusion_ft_conv_b_step_stage2", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-26 14:48:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 108): INFO Creating model:convnext_diffusion_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2
[2024-07-26 14:48:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 110): INFO ConvNeXt_Diffusion_Finetune(
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (3): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (4): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (5): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (6): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (7): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (8): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (9): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (10): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (11): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (12): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (13): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (14): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (15): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (16): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (17): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (18): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (19): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (20): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (21): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (22): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (23): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (24): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (25): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (26): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-26 14:48:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 113): INFO number of params: 60557672
[2024-07-26 14:48:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 150): INFO no checkpoint found in pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2, ignoring auto resume
[2024-07-26 14:48:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth for fine-tuning......
[2024-07-26 14:48:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 127): WARNING <All keys matched successfully>
[2024-07-26 14:48:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth'
[2024-07-26 14:49:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 73.077 (73.077)	Loss 0.3645 (0.3645)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 3372MB
[2024-07-26 14:50:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.018 Acc@5 97.508
[2024-07-26 14:50:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 162): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-26 14:50:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 168): INFO Start training
[2024-07-26 14:50:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][0/2502]	eta 16:03:56 lr 0.000100	 wd 0.0000	time 23.1163 (23.1163)	loss 0.8330 (0.8330)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 9944MB
[2024-07-26 14:51:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:20:02 lr 0.000100	 wd 0.0000	time 0.2705 (0.5005)	loss 0.8945 (0.8742)	grad_norm 2.6699 (nan)	loss_scale 32768.0000 (33092.4356)	mem 9944MB
[2024-07-26 14:51:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:16:25 lr 0.000100	 wd 0.0000	time 0.2429 (0.4281)	loss 0.8979 (0.8859)	grad_norm 2.0725 (nan)	loss_scale 32768.0000 (32931.0249)	mem 9944MB
[2024-07-26 14:52:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:13:43 lr 0.000100	 wd 0.0000	time 0.2438 (0.3738)	loss 0.8550 (0.8914)	grad_norm 1.5706 (nan)	loss_scale 32768.0000 (32876.8638)	mem 9944MB
[2024-07-26 14:52:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:12:07 lr 0.000100	 wd 0.0000	time 0.2702 (0.3462)	loss 1.1934 (0.8943)	grad_norm 2.3158 (nan)	loss_scale 32768.0000 (32849.7157)	mem 9944MB
[2024-07-26 14:53:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:11:05 lr 0.000100	 wd 0.0000	time 0.3907 (0.3322)	loss 0.7725 (0.8950)	grad_norm 2.0099 (nan)	loss_scale 32768.0000 (32833.4052)	mem 9944MB
[2024-07-26 14:53:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:10:12 lr 0.000100	 wd 0.0000	time 0.2417 (0.3221)	loss 0.8359 (0.8951)	grad_norm 1.6075 (nan)	loss_scale 32768.0000 (32822.5225)	mem 9944MB
[2024-07-26 14:54:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:09:25 lr 0.000100	 wd 0.0000	time 0.2341 (0.3138)	loss 0.9448 (0.8960)	grad_norm 2.6303 (nan)	loss_scale 32768.0000 (32814.7447)	mem 9944MB
[2024-07-26 14:54:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:08:44 lr 0.000100	 wd 0.0000	time 0.2238 (0.3080)	loss 0.9180 (0.8950)	grad_norm 2.1004 (nan)	loss_scale 32768.0000 (32808.9089)	mem 9944MB
[2024-07-26 14:54:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:08:11 lr 0.000100	 wd 0.0000	time 0.2559 (0.3071)	loss 0.9365 (0.8939)	grad_norm 1.8910 (nan)	loss_scale 32768.0000 (32804.3685)	mem 9944MB
[2024-07-26 14:55:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:07:35 lr 0.000100	 wd 0.0000	time 0.2289 (0.3032)	loss 0.9790 (0.8943)	grad_norm 2.0238 (nan)	loss_scale 32768.0000 (32800.7353)	mem 9944MB
[2024-07-26 14:55:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:07:00 lr 0.000100	 wd 0.0000	time 0.2538 (0.2999)	loss 0.8296 (0.8945)	grad_norm 2.4938 (nan)	loss_scale 16384.0000 (32053.7112)	mem 9944MB
[2024-07-26 14:56:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:06:27 lr 0.000100	 wd 0.0000	time 0.2620 (0.2975)	loss 0.8604 (0.8946)	grad_norm 1.4894 (nan)	loss_scale 16384.0000 (30748.9892)	mem 9944MB
[2024-07-26 14:56:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:55 lr 0.000100	 wd 0.0000	time 0.2553 (0.2961)	loss 0.7329 (0.8955)	grad_norm 1.5574 (nan)	loss_scale 16384.0000 (29644.8394)	mem 9944MB
[2024-07-26 14:57:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:05:24 lr 0.000100	 wd 0.0000	time 0.2599 (0.2941)	loss 0.9082 (0.8955)	grad_norm 3.5308 (nan)	loss_scale 16384.0000 (28698.3126)	mem 9944MB
[2024-07-26 14:57:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:52 lr 0.000100	 wd 0.0000	time 0.2459 (0.2923)	loss 0.9521 (0.8957)	grad_norm 1.8723 (nan)	loss_scale 16384.0000 (27877.9054)	mem 9944MB
[2024-07-26 14:58:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:04:23 lr 0.000100	 wd 0.0000	time 0.2976 (0.2921)	loss 0.9800 (0.8952)	grad_norm 1.8566 (nan)	loss_scale 16384.0000 (27159.9850)	mem 9944MB
[2024-07-26 14:58:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:53 lr 0.000100	 wd 0.0000	time 0.2184 (0.2908)	loss 0.7964 (0.8951)	grad_norm 1.8422 (nan)	loss_scale 16384.0000 (26526.4762)	mem 9944MB
[2024-07-26 14:59:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:03:23 lr 0.000100	 wd 0.0000	time 0.2447 (0.2894)	loss 0.8789 (0.8948)	grad_norm 2.7567 (nan)	loss_scale 16384.0000 (25963.3182)	mem 9944MB
[2024-07-26 14:59:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:53 lr 0.000100	 wd 0.0000	time 0.2514 (0.2883)	loss 0.8677 (0.8944)	grad_norm 1.6964 (nan)	loss_scale 16384.0000 (25459.4087)	mem 9944MB
[2024-07-26 15:00:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:37 lr 0.000100	 wd 0.0000	time 0.4781 (0.3136)	loss 0.9517 (0.8949)	grad_norm 1.6416 (nan)	loss_scale 16384.0000 (25005.8651)	mem 9944MB
[2024-07-26 15:01:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:02:08 lr 0.000100	 wd 0.0000	time 0.2650 (0.3192)	loss 0.8384 (0.8953)	grad_norm 2.1564 (nan)	loss_scale 16384.0000 (24595.4955)	mem 9944MB
[2024-07-26 15:01:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:35 lr 0.000100	 wd 0.0000	time 0.2428 (0.3168)	loss 0.9106 (0.8949)	grad_norm 1.7731 (nan)	loss_scale 16384.0000 (24222.4153)	mem 9944MB
[2024-07-26 15:02:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:01:03 lr 0.000100	 wd 0.0000	time 0.2595 (0.3147)	loss 1.0146 (0.8947)	grad_norm 1.3529 (nan)	loss_scale 16384.0000 (23881.7627)	mem 9944MB
[2024-07-26 15:02:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:31 lr 0.000100	 wd 0.0000	time 0.2423 (0.3132)	loss 0.8315 (0.8947)	grad_norm 2.0817 (nan)	loss_scale 16384.0000 (23569.4860)	mem 9944MB
[2024-07-26 15:03:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000100	 wd 0.0000	time 0.2170 (0.3114)	loss 1.0166 (0.8944)	grad_norm 1.6939 (nan)	loss_scale 16384.0000 (23282.1815)	mem 9944MB
[2024-07-26 15:03:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 0 training takes 0:13:04
[2024-07-26 15:03:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_0.pth saving......
[2024-07-26 15:03:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_0.pth saved !!!
[2024-07-26 15:04:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 39.150 (39.150)	Loss 0.3611 (0.3611)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 9944MB
[2024-07-26 15:04:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.918 Acc@5 97.540
[2024-07-26 15:04:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-26 15:04:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.92%
[2024-07-26 15:04:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saving......
[2024-07-26 15:04:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-26 15:04:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][0/2502]	eta 14:00:28 lr 0.000100	 wd 0.0000	time 20.1552 (20.1552)	loss 0.8789 (0.8789)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:05:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:18:28 lr 0.000100	 wd 0.0000	time 0.2486 (0.4613)	loss 0.7856 (0.8823)	grad_norm 1.4369 (1.9607)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:05:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:13:58 lr 0.000100	 wd 0.0000	time 0.2514 (0.3643)	loss 1.0186 (0.8893)	grad_norm 1.9862 (1.9331)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:06:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:13:05 lr 0.000100	 wd 0.0000	time 0.2485 (0.3565)	loss 1.0137 (0.8861)	grad_norm 1.4058 (1.9287)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:06:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:11:40 lr 0.000100	 wd 0.0000	time 0.2526 (0.3335)	loss 0.7773 (0.8878)	grad_norm 2.0888 (1.9094)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:07:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:10:39 lr 0.000100	 wd 0.0000	time 0.2433 (0.3196)	loss 0.8940 (0.8858)	grad_norm 1.7871 (1.9238)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:07:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:09:51 lr 0.000100	 wd 0.0000	time 0.2364 (0.3111)	loss 0.9595 (0.8866)	grad_norm 1.6835 (1.9198)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:08:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:09:09 lr 0.000100	 wd 0.0000	time 0.2456 (0.3047)	loss 0.7690 (0.8862)	grad_norm 1.6300 (1.9110)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:08:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:08:30 lr 0.000100	 wd 0.0000	time 0.2430 (0.2997)	loss 0.7793 (0.8871)	grad_norm 1.6495 (1.9143)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:09:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:54 lr 0.000099	 wd 0.0000	time 0.2212 (0.2961)	loss 0.9556 (0.8871)	grad_norm 2.3274 (1.9131)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:09:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:07:21 lr 0.000099	 wd 0.0000	time 0.2578 (0.2942)	loss 0.8965 (0.8867)	grad_norm 1.6313 (1.9247)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:09:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:06:49 lr 0.000099	 wd 0.0000	time 0.2457 (0.2919)	loss 1.0205 (0.8870)	grad_norm 2.3873 (1.9234)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:10:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:06:17 lr 0.000099	 wd 0.0000	time 0.2219 (0.2897)	loss 0.8901 (0.8869)	grad_norm 1.6385 (1.9220)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:10:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:46 lr 0.000099	 wd 0.0000	time 0.2341 (0.2880)	loss 0.9448 (0.8877)	grad_norm 1.5320 (1.9193)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:11:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:05:16 lr 0.000099	 wd 0.0000	time 0.2469 (0.2874)	loss 0.8726 (0.8882)	grad_norm 1.8189 (1.9177)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:11:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:46 lr 0.000099	 wd 0.0000	time 0.2530 (0.2860)	loss 0.9404 (0.8883)	grad_norm 1.4240 (1.9118)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:12:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:04:16 lr 0.000099	 wd 0.0000	time 0.2525 (0.2848)	loss 0.9834 (0.8889)	grad_norm 2.0503 (1.9119)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:12:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:52 lr 0.000099	 wd 0.0000	time 0.5631 (0.2898)	loss 0.7598 (0.8887)	grad_norm 2.0120 (1.9182)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:13:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:03:30 lr 0.000099	 wd 0.0000	time 0.2430 (0.3005)	loss 1.0488 (0.8892)	grad_norm 1.6730 (1.9190)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:14:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:03:00 lr 0.000099	 wd 0.0000	time 0.4498 (0.3004)	loss 0.8833 (0.8898)	grad_norm 1.6929 (1.9155)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:15:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:46 lr 0.000099	 wd 0.0000	time 0.2831 (0.3320)	loss 0.7847 (0.8893)	grad_norm 1.4745 (1.9191)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:16:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:02:13 lr 0.000099	 wd 0.0000	time 0.2522 (0.3327)	loss 0.8364 (0.8894)	grad_norm 1.6489 (1.9191)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:16:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:39 lr 0.000099	 wd 0.0000	time 0.2602 (0.3297)	loss 0.7051 (0.8894)	grad_norm 1.6611 (1.9202)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:17:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:01:06 lr 0.000099	 wd 0.0000	time 0.2191 (0.3271)	loss 1.0723 (0.8899)	grad_norm 1.2770 (1.9193)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:17:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:33 lr 0.000099	 wd 0.0000	time 0.2671 (0.3251)	loss 0.9307 (0.8896)	grad_norm 1.8341 (1.9272)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:18:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000099	 wd 0.0000	time 0.2320 (0.3226)	loss 1.0664 (0.8898)	grad_norm 1.7668 (1.9239)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:18:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 1 training takes 0:13:31
[2024-07-26 15:18:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 25.246 (25.246)	Loss 0.3701 (0.3701)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 15:18:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.080 Acc@5 97.498
[2024-07-26 15:18:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-26 15:18:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.08%
[2024-07-26 15:18:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saving......
[2024-07-26 15:18:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-26 15:19:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][0/2502]	eta 20:42:59 lr 0.000099	 wd 0.0000	time 29.8081 (29.8081)	loss 0.7920 (0.7920)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:19:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:22:16 lr 0.000099	 wd 0.0000	time 0.2614 (0.5564)	loss 0.8926 (0.8817)	grad_norm 1.6838 (1.9083)	loss_scale 32768.0000 (25143.7624)	mem 9944MB
[2024-07-26 15:20:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:15:45 lr 0.000099	 wd 0.0000	time 0.2486 (0.4106)	loss 0.8726 (0.8759)	grad_norm 1.6557 (1.9278)	loss_scale 32768.0000 (28936.9154)	mem 9944MB
[2024-07-26 15:20:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:13:24 lr 0.000099	 wd 0.0000	time 0.2373 (0.3654)	loss 0.9390 (0.8769)	grad_norm 1.9001 (1.9236)	loss_scale 32768.0000 (30209.7010)	mem 9944MB
[2024-07-26 15:21:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:12:05 lr 0.000099	 wd 0.0000	time 0.2468 (0.3453)	loss 0.7832 (0.8765)	grad_norm 1.6625 (1.9215)	loss_scale 32768.0000 (30847.6808)	mem 9944MB
[2024-07-26 15:21:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:10:58 lr 0.000099	 wd 0.0000	time 0.2416 (0.3290)	loss 1.0615 (0.8749)	grad_norm 2.0519 (1.9471)	loss_scale 32768.0000 (31230.9780)	mem 9944MB
[2024-07-26 15:22:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:10:05 lr 0.000099	 wd 0.0000	time 0.2416 (0.3183)	loss 0.9097 (0.8758)	grad_norm 2.4140 (1.9440)	loss_scale 32768.0000 (31486.7221)	mem 9944MB
[2024-07-26 15:22:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:09:22 lr 0.000099	 wd 0.0000	time 0.2498 (0.3121)	loss 0.9937 (0.8762)	grad_norm 2.1222 (1.9407)	loss_scale 32768.0000 (31669.5007)	mem 9944MB
[2024-07-26 15:22:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:08:41 lr 0.000099	 wd 0.0000	time 0.2206 (0.3062)	loss 0.7783 (0.8753)	grad_norm 2.1655 (inf)	loss_scale 16384.0000 (30293.0137)	mem 9944MB
[2024-07-26 15:23:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:08:03 lr 0.000098	 wd 0.0000	time 0.2352 (0.3017)	loss 0.8486 (0.8763)	grad_norm 1.3989 (inf)	loss_scale 16384.0000 (28749.2830)	mem 9944MB
[2024-07-26 15:23:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:07:28 lr 0.000098	 wd 0.0000	time 0.2430 (0.2984)	loss 0.8062 (0.8768)	grad_norm 1.8932 (inf)	loss_scale 16384.0000 (27513.9900)	mem 9944MB
[2024-07-26 15:24:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:06:56 lr 0.000098	 wd 0.0000	time 0.2374 (0.2970)	loss 0.8662 (0.8767)	grad_norm 1.4986 (inf)	loss_scale 16384.0000 (26503.0917)	mem 9944MB
[2024-07-26 15:24:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:06:23 lr 0.000098	 wd 0.0000	time 0.2307 (0.2945)	loss 1.0312 (0.8760)	grad_norm 1.6126 (inf)	loss_scale 16384.0000 (25660.5362)	mem 9944MB
[2024-07-26 15:25:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:05:51 lr 0.000098	 wd 0.0000	time 0.2218 (0.2923)	loss 0.9209 (0.8770)	grad_norm 1.4808 (inf)	loss_scale 16384.0000 (24947.5050)	mem 9944MB
[2024-07-26 15:25:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:05:20 lr 0.000098	 wd 0.0000	time 0.2570 (0.2909)	loss 0.8867 (0.8772)	grad_norm 1.8761 (inf)	loss_scale 16384.0000 (24336.2627)	mem 9944MB
[2024-07-26 15:26:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:50 lr 0.000098	 wd 0.0000	time 0.2298 (0.2897)	loss 0.8486 (0.8771)	grad_norm 1.6434 (inf)	loss_scale 16384.0000 (23806.4650)	mem 9944MB
[2024-07-26 15:26:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:04:20 lr 0.000098	 wd 0.0000	time 0.2366 (0.2883)	loss 0.8823 (0.8774)	grad_norm 1.3718 (inf)	loss_scale 16384.0000 (23342.8507)	mem 9944MB
[2024-07-26 15:26:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:50 lr 0.000098	 wd 0.0000	time 0.2669 (0.2870)	loss 0.9253 (0.8779)	grad_norm 1.5602 (inf)	loss_scale 16384.0000 (22933.7472)	mem 9944MB
[2024-07-26 15:27:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:03:30 lr 0.000098	 wd 0.0000	time 0.2517 (0.2994)	loss 0.7891 (0.8775)	grad_norm 1.4806 (inf)	loss_scale 16384.0000 (22570.0744)	mem 9944MB
[2024-07-26 15:28:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:03:01 lr 0.000098	 wd 0.0000	time 0.2919 (0.3009)	loss 0.7979 (0.8782)	grad_norm 1.5543 (inf)	loss_scale 16384.0000 (22244.6628)	mem 9944MB
[2024-07-26 15:29:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:02:41 lr 0.000098	 wd 0.0000	time 0.3665 (0.3219)	loss 0.8623 (0.8780)	grad_norm 2.3570 (inf)	loss_scale 16384.0000 (21951.7761)	mem 9944MB
[2024-07-26 15:30:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:02:15 lr 0.000098	 wd 0.0000	time 0.2225 (0.3376)	loss 1.0068 (0.8785)	grad_norm 1.4349 (inf)	loss_scale 16384.0000 (21686.7701)	mem 9944MB
[2024-07-26 15:31:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:41 lr 0.000098	 wd 0.0000	time 0.2321 (0.3344)	loss 0.8179 (0.8784)	grad_norm 2.4105 (inf)	loss_scale 16384.0000 (21445.8446)	mem 9944MB
[2024-07-26 15:31:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:01:06 lr 0.000098	 wd 0.0000	time 0.2667 (0.3315)	loss 0.9678 (0.8782)	grad_norm 1.7165 (inf)	loss_scale 16384.0000 (21225.8601)	mem 9944MB
[2024-07-26 15:32:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:33 lr 0.000098	 wd 0.0000	time 0.2469 (0.3289)	loss 1.1035 (0.8785)	grad_norm 1.8722 (inf)	loss_scale 16384.0000 (21024.1999)	mem 9944MB
[2024-07-26 15:32:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000098	 wd 0.0000	time 0.2311 (0.3265)	loss 0.8335 (0.8788)	grad_norm 1.7081 (inf)	loss_scale 16384.0000 (20838.6661)	mem 9944MB
[2024-07-26 15:32:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 2 training takes 0:13:44
[2024-07-26 15:33:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 26.168 (26.168)	Loss 0.3547 (0.3547)	Acc@1 92.969 (92.969)	Acc@5 98.828 (98.828)	Mem 9944MB
[2024-07-26 15:33:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.102 Acc@5 97.530
[2024-07-26 15:33:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-26 15:33:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.10%
[2024-07-26 15:33:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saving......
[2024-07-26 15:33:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-26 15:33:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][0/2502]	eta 15:01:56 lr 0.000098	 wd 0.0000	time 21.6293 (21.6293)	loss 0.7700 (0.7700)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:34:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:20:02 lr 0.000098	 wd 0.0000	time 0.2305 (0.5005)	loss 0.8315 (0.8707)	grad_norm 1.5018 (1.9326)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:34:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:14:41 lr 0.000097	 wd 0.0000	time 0.2324 (0.3828)	loss 0.8525 (0.8710)	grad_norm 1.4557 (1.9010)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:34:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:12:35 lr 0.000097	 wd 0.0000	time 0.2594 (0.3433)	loss 0.9873 (0.8728)	grad_norm 1.4572 (1.8823)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:35:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:11:24 lr 0.000097	 wd 0.0000	time 0.2587 (0.3258)	loss 0.8931 (0.8729)	grad_norm 1.8332 (1.8993)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:35:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:10:27 lr 0.000097	 wd 0.0000	time 0.2654 (0.3135)	loss 0.8564 (0.8723)	grad_norm 1.9513 (1.9336)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:36:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:09:40 lr 0.000097	 wd 0.0000	time 0.2374 (0.3052)	loss 0.8032 (0.8719)	grad_norm 1.7855 (1.9590)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:36:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:08:59 lr 0.000097	 wd 0.0000	time 0.2313 (0.2995)	loss 1.0479 (0.8724)	grad_norm 2.6523 (1.9515)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:37:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:08:25 lr 0.000097	 wd 0.0000	time 0.2880 (0.2971)	loss 0.9629 (0.8736)	grad_norm 1.6974 (1.9344)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:37:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:07:50 lr 0.000097	 wd 0.0000	time 0.2557 (0.2937)	loss 0.9590 (0.8739)	grad_norm 1.6676 (1.9214)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:38:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:07:16 lr 0.000097	 wd 0.0000	time 0.2355 (0.2908)	loss 0.9717 (0.8753)	grad_norm 1.7902 (1.9116)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:38:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:06:45 lr 0.000097	 wd 0.0000	time 0.2276 (0.2890)	loss 0.8735 (0.8766)	grad_norm 2.1928 (1.9107)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:39:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:06:14 lr 0.000097	 wd 0.0000	time 0.2499 (0.2878)	loss 0.9526 (0.8770)	grad_norm 1.8348 (1.9097)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:39:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:05:43 lr 0.000097	 wd 0.0000	time 0.2497 (0.2862)	loss 0.9985 (0.8773)	grad_norm 2.8014 (1.9127)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:39:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:05:13 lr 0.000097	 wd 0.0000	time 0.2386 (0.2845)	loss 0.8174 (0.8778)	grad_norm 2.5608 (1.9052)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:40:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:58 lr 0.000097	 wd 0.0000	time 0.6935 (0.2977)	loss 0.7622 (0.8783)	grad_norm 1.5066 (1.9121)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:41:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:04:38 lr 0.000096	 wd 0.0000	time 0.2888 (0.3090)	loss 0.8213 (0.8778)	grad_norm 1.7415 (1.9195)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:42:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:04:10 lr 0.000096	 wd 0.0000	time 0.2423 (0.3122)	loss 0.8716 (0.8777)	grad_norm 1.3860 (1.9226)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:42:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:03:37 lr 0.000096	 wd 0.0000	time 0.2201 (0.3097)	loss 0.9785 (0.8774)	grad_norm 1.4401 (1.9213)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:42:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:03:05 lr 0.000096	 wd 0.0000	time 0.2306 (0.3076)	loss 0.8652 (0.8772)	grad_norm 1.7576 (1.9219)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:43:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:33 lr 0.000096	 wd 0.0000	time 0.2538 (0.3058)	loss 0.8706 (0.8774)	grad_norm 1.6606 (1.9252)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:43:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:02:02 lr 0.000096	 wd 0.0000	time 0.2640 (0.3047)	loss 0.8188 (0.8774)	grad_norm 1.6044 (1.9249)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:44:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:31 lr 0.000096	 wd 0.0000	time 0.2353 (0.3031)	loss 0.9048 (0.8773)	grad_norm 1.3695 (1.9213)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:44:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:01:00 lr 0.000096	 wd 0.0000	time 0.2535 (0.3015)	loss 0.9248 (0.8774)	grad_norm 1.4557 (1.9192)	loss_scale 32768.0000 (16925.1491)	mem 9944MB
[2024-07-26 15:45:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:30 lr 0.000096	 wd 0.0000	time 0.2331 (0.3008)	loss 0.9106 (0.8771)	grad_norm 1.7941 (1.9180)	loss_scale 32768.0000 (17584.9929)	mem 9944MB
[2024-07-26 15:45:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000096	 wd 0.0000	time 0.2424 (0.2995)	loss 0.9668 (0.8774)	grad_norm 1.4608 (inf)	loss_scale 16384.0000 (17602.4822)	mem 9944MB
[2024-07-26 15:45:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 3 training takes 0:12:34
[2024-07-26 15:46:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 23.374 (23.374)	Loss 0.3696 (0.3696)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 15:46:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.104 Acc@5 97.510
[2024-07-26 15:46:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-26 15:46:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.10%
[2024-07-26 15:46:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saving......
[2024-07-26 15:46:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-26 15:46:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][0/2502]	eta 18:33:46 lr 0.000096	 wd 0.0000	time 26.7091 (26.7091)	loss 0.8892 (0.8892)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:47:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:21:19 lr 0.000096	 wd 0.0000	time 0.2241 (0.5329)	loss 0.7842 (0.8632)	grad_norm 2.0670 (1.8805)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:47:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:15:16 lr 0.000096	 wd 0.0000	time 0.2400 (0.3983)	loss 0.9692 (0.8715)	grad_norm 1.4916 (1.8659)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:48:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:13:00 lr 0.000095	 wd 0.0000	time 0.2439 (0.3546)	loss 0.8394 (0.8722)	grad_norm 1.7916 (1.8853)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:48:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:11:40 lr 0.000095	 wd 0.0000	time 0.2710 (0.3331)	loss 0.9126 (0.8683)	grad_norm 1.6961 (1.8922)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:49:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:10:38 lr 0.000095	 wd 0.0000	time 0.2506 (0.3190)	loss 0.9556 (0.8682)	grad_norm 1.5001 (1.8751)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:49:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:09:49 lr 0.000095	 wd 0.0000	time 0.2496 (0.3098)	loss 0.8130 (0.8704)	grad_norm 1.9936 (1.8799)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:49:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:09:07 lr 0.000095	 wd 0.0000	time 0.2459 (0.3038)	loss 1.0352 (0.8691)	grad_norm 2.0112 (1.8896)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:50:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:08:30 lr 0.000095	 wd 0.0000	time 0.2402 (0.2999)	loss 0.8008 (0.8682)	grad_norm 1.4253 (1.8950)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:50:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:07:53 lr 0.000095	 wd 0.0000	time 0.2384 (0.2959)	loss 0.9180 (0.8690)	grad_norm 1.7170 (1.9056)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:51:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:07:19 lr 0.000095	 wd 0.0000	time 0.2192 (0.2927)	loss 0.8516 (0.8691)	grad_norm 1.9206 (1.9158)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:51:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:06:48 lr 0.000095	 wd 0.0000	time 0.2168 (0.2913)	loss 0.9282 (0.8697)	grad_norm 1.7386 (1.9026)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:52:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:06:17 lr 0.000095	 wd 0.0000	time 0.2520 (0.2896)	loss 0.7588 (0.8702)	grad_norm 1.9084 (1.9030)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:52:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:05:46 lr 0.000095	 wd 0.0000	time 0.2202 (0.2881)	loss 0.7168 (0.8696)	grad_norm 1.8756 (1.9111)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:53:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:05:15 lr 0.000094	 wd 0.0000	time 0.2485 (0.2866)	loss 0.8535 (0.8687)	grad_norm 3.2320 (1.9106)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:53:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:46 lr 0.000094	 wd 0.0000	time 0.2351 (0.2861)	loss 0.7817 (0.8690)	grad_norm 1.6897 (1.9061)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:54:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:04:17 lr 0.000094	 wd 0.0000	time 0.2565 (0.2850)	loss 0.9028 (0.8694)	grad_norm 1.5223 (1.9031)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:54:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:47 lr 0.000094	 wd 0.0000	time 0.2659 (0.2839)	loss 0.8809 (0.8699)	grad_norm 1.4643 (1.9031)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:55:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:03:23 lr 0.000094	 wd 0.0000	time 1.7645 (0.2900)	loss 0.9507 (0.8710)	grad_norm 2.0618 (1.9076)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:56:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:03:02 lr 0.000094	 wd 0.0000	time 0.2541 (0.3026)	loss 0.8281 (0.8704)	grad_norm 1.5248 (1.9018)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:56:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:02:38 lr 0.000094	 wd 0.0000	time 0.7008 (0.3160)	loss 0.7783 (0.8701)	grad_norm 1.7454 (1.8951)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:58:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:02:13 lr 0.000094	 wd 0.0000	time 0.2770 (0.3313)	loss 0.7939 (0.8702)	grad_norm 3.5461 (1.8947)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:58:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:40 lr 0.000094	 wd 0.0000	time 0.2247 (0.3319)	loss 0.8911 (0.8700)	grad_norm 2.2327 (1.8967)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:59:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:01:06 lr 0.000094	 wd 0.0000	time 0.2208 (0.3291)	loss 0.8564 (0.8705)	grad_norm 2.4333 (1.8998)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:59:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:33 lr 0.000093	 wd 0.0000	time 0.2735 (0.3265)	loss 0.7974 (0.8707)	grad_norm 1.8270 (1.9020)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 15:59:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000093	 wd 0.0000	time 0.2460 (0.3239)	loss 0.7505 (0.8707)	grad_norm 1.9662 (1.9001)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:00:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 4 training takes 0:13:39
[2024-07-26 16:00:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 29.395 (29.395)	Loss 0.3640 (0.3640)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 9944MB
[2024-07-26 16:00:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.264 Acc@5 97.540
[2024-07-26 16:00:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-26 16:00:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.26%
[2024-07-26 16:00:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saving......
[2024-07-26 16:00:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-26 16:01:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][0/2502]	eta 11:27:57 lr 0.000093	 wd 0.0000	time 16.4977 (16.4977)	loss 1.0254 (1.0254)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:01:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:17:17 lr 0.000093	 wd 0.0000	time 0.2402 (0.4319)	loss 0.7915 (0.8605)	grad_norm 1.5447 (1.8985)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:01:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:13:21 lr 0.000093	 wd 0.0000	time 0.2451 (0.3481)	loss 0.7979 (0.8675)	grad_norm 1.9606 (1.8869)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:02:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:11:44 lr 0.000093	 wd 0.0000	time 0.2542 (0.3200)	loss 0.8179 (0.8660)	grad_norm 1.6250 (1.8976)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:02:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:10:43 lr 0.000093	 wd 0.0000	time 0.2645 (0.3061)	loss 0.7524 (0.8646)	grad_norm 1.7535 (1.9033)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:03:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:09:56 lr 0.000093	 wd 0.0000	time 0.2401 (0.2979)	loss 0.8911 (0.8647)	grad_norm 1.9253 (1.9379)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:03:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:09:15 lr 0.000093	 wd 0.0000	time 0.2438 (0.2922)	loss 1.1230 (0.8677)	grad_norm 1.7697 (1.9316)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:04:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:08:39 lr 0.000093	 wd 0.0000	time 0.2337 (0.2882)	loss 0.8750 (0.8674)	grad_norm 2.2651 (1.9510)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:04:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:08:05 lr 0.000093	 wd 0.0000	time 0.2720 (0.2855)	loss 0.9385 (0.8682)	grad_norm 1.6288 (1.9410)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:05:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:07:35 lr 0.000092	 wd 0.0000	time 0.2462 (0.2842)	loss 0.8208 (0.8679)	grad_norm 1.8816 (1.9334)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:05:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:07:04 lr 0.000092	 wd 0.0000	time 0.2374 (0.2824)	loss 0.7832 (0.8681)	grad_norm 2.2799 (1.9303)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:05:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:06:33 lr 0.000092	 wd 0.0000	time 0.2428 (0.2809)	loss 0.7939 (0.8689)	grad_norm 1.7925 (1.9295)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:06:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:06:05 lr 0.000092	 wd 0.0000	time 0.2561 (0.2804)	loss 1.0312 (0.8692)	grad_norm 1.5221 (1.9353)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:06:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:05:35 lr 0.000092	 wd 0.0000	time 0.2700 (0.2795)	loss 0.8604 (0.8690)	grad_norm 1.4364 (1.9319)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:07:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:05:06 lr 0.000092	 wd 0.0000	time 0.2541 (0.2784)	loss 0.8945 (0.8683)	grad_norm 1.9614 (1.9265)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:07:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:04:38 lr 0.000092	 wd 0.0000	time 0.2571 (0.2777)	loss 0.9082 (0.8681)	grad_norm 1.7125 (1.9264)	loss_scale 32768.0000 (17410.0466)	mem 9944MB
[2024-07-26 16:08:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:04:35 lr 0.000092	 wd 0.0000	time 0.4561 (0.3057)	loss 0.8247 (0.8677)	grad_norm 1.5352 (1.9262)	loss_scale 32768.0000 (18369.3192)	mem 9944MB
[2024-07-26 16:09:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:04:10 lr 0.000092	 wd 0.0000	time 0.2295 (0.3126)	loss 0.9297 (0.8678)	grad_norm 1.9205 (1.9247)	loss_scale 32768.0000 (19215.8025)	mem 9944MB
[2024-07-26 16:10:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:03:37 lr 0.000091	 wd 0.0000	time 0.2601 (0.3101)	loss 0.8452 (0.8677)	grad_norm 1.7173 (1.9146)	loss_scale 32768.0000 (19968.2843)	mem 9944MB
[2024-07-26 16:10:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:03:05 lr 0.000091	 wd 0.0000	time 0.2360 (0.3079)	loss 1.0078 (0.8680)	grad_norm 1.7316 (1.9111)	loss_scale 32768.0000 (20641.5992)	mem 9944MB
[2024-07-26 16:11:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:02:33 lr 0.000091	 wd 0.0000	time 0.2530 (0.3060)	loss 1.0234 (0.8678)	grad_norm 1.6725 (1.9068)	loss_scale 32768.0000 (21247.6162)	mem 9944MB
[2024-07-26 16:11:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:02:02 lr 0.000091	 wd 0.0000	time 0.2447 (0.3050)	loss 0.8921 (0.8669)	grad_norm 1.7874 (1.9047)	loss_scale 32768.0000 (21795.9448)	mem 9944MB
[2024-07-26 16:11:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:31 lr 0.000091	 wd 0.0000	time 0.2588 (0.3034)	loss 0.8843 (0.8670)	grad_norm 1.7162 (1.8984)	loss_scale 32768.0000 (22294.4480)	mem 9944MB
[2024-07-26 16:12:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:01:00 lr 0.000091	 wd 0.0000	time 0.2465 (0.3018)	loss 0.7271 (0.8664)	grad_norm 2.0430 (1.8984)	loss_scale 32768.0000 (22749.6219)	mem 9944MB
[2024-07-26 16:12:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:30 lr 0.000091	 wd 0.0000	time 0.2196 (0.3007)	loss 0.8882 (0.8662)	grad_norm 1.7822 (1.8983)	loss_scale 32768.0000 (23166.8805)	mem 9944MB
[2024-07-26 16:13:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000091	 wd 0.0000	time 0.2384 (0.2995)	loss 0.8647 (0.8664)	grad_norm 1.8387 (inf)	loss_scale 16384.0000 (23275.6305)	mem 9944MB
[2024-07-26 16:13:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 5 training takes 0:12:34
[2024-07-26 16:13:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 20.922 (20.922)	Loss 0.3625 (0.3625)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 9944MB
[2024-07-26 16:13:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.160 Acc@5 97.566
[2024-07-26 16:13:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-26 16:13:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.26%
[2024-07-26 16:14:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][0/2502]	eta 16:04:37 lr 0.000091	 wd 0.0000	time 23.1326 (23.1326)	loss 0.9365 (0.9365)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:14:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:20:00 lr 0.000090	 wd 0.0000	time 0.2435 (0.4997)	loss 0.8130 (0.8627)	grad_norm 1.8181 (2.1415)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:15:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:14:40 lr 0.000090	 wd 0.0000	time 0.2361 (0.3823)	loss 0.7646 (0.8595)	grad_norm 1.3785 (1.9828)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:15:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:12:35 lr 0.000090	 wd 0.0000	time 0.2292 (0.3429)	loss 0.9097 (0.8609)	grad_norm 2.0519 (1.9813)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:16:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:11:22 lr 0.000090	 wd 0.0000	time 0.2423 (0.3247)	loss 0.8462 (0.8611)	grad_norm 1.5969 (1.9408)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:16:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:10:25 lr 0.000090	 wd 0.0000	time 0.2370 (0.3124)	loss 0.9082 (0.8593)	grad_norm 1.5837 (1.9226)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:16:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:09:38 lr 0.000090	 wd 0.0000	time 0.2334 (0.3041)	loss 0.9614 (0.8593)	grad_norm 1.7942 (1.9147)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:17:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:08:57 lr 0.000090	 wd 0.0000	time 0.2327 (0.2985)	loss 0.9307 (0.8610)	grad_norm 1.9323 (1.8811)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:17:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:08:22 lr 0.000090	 wd 0.0000	time 0.2351 (0.2952)	loss 0.8184 (0.8624)	grad_norm 1.9497 (1.8760)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:18:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:07:48 lr 0.000089	 wd 0.0000	time 0.2273 (0.2921)	loss 0.8608 (0.8623)	grad_norm 1.2510 (1.8795)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:18:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:07:14 lr 0.000089	 wd 0.0000	time 0.2391 (0.2893)	loss 0.8203 (0.8632)	grad_norm 1.9466 (1.8821)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:19:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:06:42 lr 0.000089	 wd 0.0000	time 0.2278 (0.2873)	loss 0.7642 (0.8625)	grad_norm 2.1785 (1.8813)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:19:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:06:12 lr 0.000089	 wd 0.0000	time 0.2645 (0.2863)	loss 0.7119 (0.8629)	grad_norm 1.9505 (1.8791)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:20:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:05:42 lr 0.000089	 wd 0.0000	time 0.2500 (0.2848)	loss 0.8740 (0.8641)	grad_norm 1.7494 (1.8903)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:20:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:05:12 lr 0.000089	 wd 0.0000	time 0.2432 (0.2836)	loss 1.0830 (0.8625)	grad_norm 2.5289 (1.8827)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:21:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:53 lr 0.000089	 wd 0.0000	time 0.2394 (0.2926)	loss 0.7168 (0.8624)	grad_norm 1.3847 (1.8779)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:21:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:04:25 lr 0.000089	 wd 0.0000	time 0.2201 (0.2945)	loss 0.9043 (0.8622)	grad_norm 1.4739 (1.8769)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:22:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:57 lr 0.000088	 wd 0.0000	time 0.2776 (0.2959)	loss 0.9653 (0.8611)	grad_norm 2.2350 (1.8880)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:23:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:03:51 lr 0.000088	 wd 0.0000	time 0.2268 (0.3303)	loss 0.7373 (0.8606)	grad_norm 1.8757 (1.8873)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:24:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:03:18 lr 0.000088	 wd 0.0000	time 0.2539 (0.3300)	loss 0.9561 (0.8606)	grad_norm 2.0343 (1.8802)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:24:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:02:44 lr 0.000088	 wd 0.0000	time 0.2534 (0.3269)	loss 1.0537 (0.8616)	grad_norm 1.6386 (1.8878)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:25:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:02:10 lr 0.000088	 wd 0.0000	time 0.2453 (0.3240)	loss 0.8823 (0.8619)	grad_norm 1.8900 (1.8874)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:25:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:37 lr 0.000088	 wd 0.0000	time 0.2369 (0.3216)	loss 0.9282 (0.8623)	grad_norm 2.0649 (1.8860)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:26:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:01:04 lr 0.000088	 wd 0.0000	time 0.2628 (0.3197)	loss 0.8677 (0.8622)	grad_norm 2.2185 (1.8832)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:26:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:32 lr 0.000087	 wd 0.0000	time 0.2555 (0.3176)	loss 0.8638 (0.8618)	grad_norm 1.9980 (1.8820)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:27:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000087	 wd 0.0000	time 0.2312 (0.3153)	loss 0.7622 (0.8614)	grad_norm 1.5650 (1.8828)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:27:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 6 training takes 0:13:13
[2024-07-26 16:27:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 34.331 (34.331)	Loss 0.3606 (0.3606)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 16:27:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.248 Acc@5 97.538
[2024-07-26 16:27:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-26 16:27:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.26%
[2024-07-26 16:28:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][0/2502]	eta 11:50:52 lr 0.000087	 wd 0.0000	time 17.0472 (17.0472)	loss 0.9639 (0.9639)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:28:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:17:12 lr 0.000087	 wd 0.0000	time 0.2592 (0.4298)	loss 1.0195 (0.8653)	grad_norm 1.9451 (1.8497)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:29:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:13:29 lr 0.000087	 wd 0.0000	time 0.2300 (0.3516)	loss 0.8823 (0.8531)	grad_norm 2.1257 (1.8690)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:29:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:11:50 lr 0.000087	 wd 0.0000	time 0.2447 (0.3226)	loss 0.8491 (0.8527)	grad_norm 2.3640 (1.8573)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:29:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:10:47 lr 0.000087	 wd 0.0000	time 0.2532 (0.3082)	loss 0.9233 (0.8535)	grad_norm 1.6842 (1.8757)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:30:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:09:59 lr 0.000087	 wd 0.0000	time 0.2285 (0.2995)	loss 0.7905 (0.8540)	grad_norm 1.7405 (1.8683)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:30:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:09:21 lr 0.000086	 wd 0.0000	time 0.2159 (0.2954)	loss 0.7954 (0.8545)	grad_norm 1.5560 (1.8631)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:31:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:08:45 lr 0.000086	 wd 0.0000	time 0.2434 (0.2914)	loss 0.7739 (0.8539)	grad_norm 1.6136 (1.8616)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:31:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:08:10 lr 0.000086	 wd 0.0000	time 0.2461 (0.2880)	loss 0.8237 (0.8544)	grad_norm 2.5661 (1.8573)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:32:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:07:37 lr 0.000086	 wd 0.0000	time 0.2466 (0.2859)	loss 0.7051 (0.8548)	grad_norm 1.8547 (1.8553)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:32:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:07:07 lr 0.000086	 wd 0.0000	time 0.2339 (0.2846)	loss 0.8252 (0.8556)	grad_norm 1.8960 (1.8622)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:33:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:06:36 lr 0.000086	 wd 0.0000	time 0.2395 (0.2829)	loss 0.8096 (0.8546)	grad_norm 1.4360 (1.8816)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:33:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:06:06 lr 0.000086	 wd 0.0000	time 0.2224 (0.2815)	loss 0.7505 (0.8553)	grad_norm 1.8113 (1.8738)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:33:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:05:37 lr 0.000085	 wd 0.0000	time 0.2573 (0.2809)	loss 0.9102 (0.8551)	grad_norm 1.8935 (1.8777)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:34:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:05:08 lr 0.000085	 wd 0.0000	time 0.2162 (0.2802)	loss 0.8828 (0.8562)	grad_norm 1.8553 (1.8748)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:34:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:39 lr 0.000085	 wd 0.0000	time 0.2421 (0.2793)	loss 0.7852 (0.8555)	grad_norm 1.9736 (1.8742)	loss_scale 32768.0000 (16886.1079)	mem 9944MB
[2024-07-26 16:35:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:04:11 lr 0.000085	 wd 0.0000	time 0.2604 (0.2786)	loss 0.8901 (0.8562)	grad_norm 1.5783 (1.8767)	loss_scale 32768.0000 (17878.1062)	mem 9944MB
[2024-07-26 16:36:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:53 lr 0.000085	 wd 0.0000	time 0.2345 (0.2912)	loss 0.8081 (0.8560)	grad_norm 1.4271 (1.8719)	loss_scale 32768.0000 (18753.4674)	mem 9944MB
[2024-07-26 16:36:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:03:27 lr 0.000085	 wd 0.0000	time 0.2576 (0.2949)	loss 0.8145 (0.8552)	grad_norm 1.8307 (1.8705)	loss_scale 32768.0000 (19531.6202)	mem 9944MB
[2024-07-26 16:37:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:03:09 lr 0.000085	 wd 0.0000	time 0.3040 (0.3150)	loss 0.9858 (0.8562)	grad_norm 2.0443 (1.8716)	loss_scale 32768.0000 (20227.9053)	mem 9944MB
[2024-07-26 16:38:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:02:39 lr 0.000084	 wd 0.0000	time 0.2374 (0.3174)	loss 0.7793 (0.8559)	grad_norm 1.8775 (1.8787)	loss_scale 32768.0000 (20854.5967)	mem 9944MB
[2024-07-26 16:39:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:02:08 lr 0.000084	 wd 0.0000	time 0.2632 (0.3190)	loss 0.9072 (0.8564)	grad_norm 2.2701 (1.8823)	loss_scale 32768.0000 (21421.6316)	mem 9944MB
[2024-07-26 16:39:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:35 lr 0.000084	 wd 0.0000	time 0.2534 (0.3166)	loss 0.8071 (0.8561)	grad_norm 1.9209 (1.8932)	loss_scale 32768.0000 (21937.1413)	mem 9944MB
[2024-07-26 16:39:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:01:03 lr 0.000084	 wd 0.0000	time 0.2302 (0.3145)	loss 0.8691 (0.8560)	grad_norm 1.3472 (1.8901)	loss_scale 32768.0000 (22407.8435)	mem 9944MB
[2024-07-26 16:40:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:31 lr 0.000084	 wd 0.0000	time 0.2464 (0.3126)	loss 0.7964 (0.8566)	grad_norm 2.1325 (1.8935)	loss_scale 32768.0000 (22839.3369)	mem 9944MB
[2024-07-26 16:40:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000084	 wd 0.0000	time 0.2329 (0.3108)	loss 0.8110 (0.8571)	grad_norm 1.5740 (1.8923)	loss_scale 32768.0000 (23236.3247)	mem 9944MB
[2024-07-26 16:40:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 7 training takes 0:13:03
[2024-07-26 16:41:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 20.847 (20.847)	Loss 0.3601 (0.3601)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 9944MB
[2024-07-26 16:41:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.238 Acc@5 97.604
[2024-07-26 16:41:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-26 16:41:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.26%
[2024-07-26 16:41:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][0/2502]	eta 15:00:31 lr 0.000084	 wd 0.0000	time 21.5952 (21.5952)	loss 0.9546 (0.9546)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 16:42:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:19:12 lr 0.000083	 wd 0.0000	time 0.2300 (0.4799)	loss 0.8208 (0.8611)	grad_norm 1.6810 (1.8244)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 16:42:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:14:17 lr 0.000083	 wd 0.0000	time 0.2752 (0.3724)	loss 0.7964 (0.8537)	grad_norm 1.7882 (1.8283)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 16:43:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:12:20 lr 0.000083	 wd 0.0000	time 0.2289 (0.3364)	loss 0.8862 (0.8494)	grad_norm 1.8936 (1.8420)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 16:43:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:11:11 lr 0.000083	 wd 0.0000	time 0.2392 (0.3195)	loss 0.9224 (0.8493)	grad_norm 1.7155 (1.8284)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 16:44:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:10:17 lr 0.000083	 wd 0.0000	time 0.2267 (0.3085)	loss 0.8965 (0.8512)	grad_norm 1.9695 (1.8510)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 16:44:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:09:32 lr 0.000083	 wd 0.0000	time 0.2515 (0.3011)	loss 0.7344 (0.8515)	grad_norm 2.4591 (1.8726)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 16:44:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:08:53 lr 0.000083	 wd 0.0000	time 0.2419 (0.2959)	loss 0.9761 (0.8502)	grad_norm 1.8345 (inf)	loss_scale 16384.0000 (30898.2140)	mem 9944MB
[2024-07-26 16:45:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:08:18 lr 0.000082	 wd 0.0000	time 0.2371 (0.2927)	loss 0.9409 (0.8513)	grad_norm 2.2685 (inf)	loss_scale 16384.0000 (29086.2022)	mem 9944MB
[2024-07-26 16:45:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:07:44 lr 0.000082	 wd 0.0000	time 0.2469 (0.2901)	loss 0.9312 (0.8509)	grad_norm 1.7613 (inf)	loss_scale 16384.0000 (27676.4129)	mem 9944MB
[2024-07-26 16:46:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:07:12 lr 0.000082	 wd 0.0000	time 0.2544 (0.2878)	loss 0.9062 (0.8522)	grad_norm 1.3753 (inf)	loss_scale 16384.0000 (26548.2997)	mem 9944MB
[2024-07-26 16:46:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:06:40 lr 0.000082	 wd 0.0000	time 0.2417 (0.2859)	loss 0.8242 (0.8526)	grad_norm 1.8288 (inf)	loss_scale 16384.0000 (25625.1117)	mem 9944MB
[2024-07-26 16:47:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:06:11 lr 0.000082	 wd 0.0000	time 0.2475 (0.2852)	loss 0.8882 (0.8532)	grad_norm 1.6138 (inf)	loss_scale 16384.0000 (24855.6603)	mem 9944MB
[2024-07-26 16:47:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:05:41 lr 0.000082	 wd 0.0000	time 0.2517 (0.2837)	loss 0.8032 (0.8538)	grad_norm 2.0135 (inf)	loss_scale 16384.0000 (24204.4950)	mem 9944MB
[2024-07-26 16:48:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:05:11 lr 0.000081	 wd 0.0000	time 0.2423 (0.2825)	loss 0.8208 (0.8547)	grad_norm 1.5303 (inf)	loss_scale 16384.0000 (23646.2869)	mem 9944MB
[2024-07-26 16:48:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:04:42 lr 0.000081	 wd 0.0000	time 0.2537 (0.2815)	loss 0.7505 (0.8547)	grad_norm 1.9766 (inf)	loss_scale 16384.0000 (23162.4570)	mem 9944MB
[2024-07-26 16:49:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:04:23 lr 0.000081	 wd 0.0000	time 0.2537 (0.2919)	loss 0.9355 (0.8546)	grad_norm 2.0160 (inf)	loss_scale 16384.0000 (22739.0681)	mem 9944MB
[2024-07-26 16:49:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:57 lr 0.000081	 wd 0.0000	time 0.2259 (0.2961)	loss 0.7646 (0.8551)	grad_norm 1.8824 (inf)	loss_scale 16384.0000 (22365.4603)	mem 9944MB
[2024-07-26 16:51:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:03:48 lr 0.000081	 wd 0.0000	time 0.5099 (0.3250)	loss 0.7920 (0.8558)	grad_norm 2.0588 (inf)	loss_scale 16384.0000 (22033.3415)	mem 9944MB
[2024-07-26 16:51:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:03:18 lr 0.000081	 wd 0.0000	time 0.2578 (0.3299)	loss 0.7705 (0.8551)	grad_norm 1.9054 (inf)	loss_scale 16384.0000 (21736.1641)	mem 9944MB
[2024-07-26 16:52:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:02:44 lr 0.000080	 wd 0.0000	time 0.2238 (0.3269)	loss 0.9258 (0.8550)	grad_norm 1.7312 (inf)	loss_scale 16384.0000 (21468.6897)	mem 9944MB
[2024-07-26 16:52:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:02:10 lr 0.000080	 wd 0.0000	time 0.2779 (0.3241)	loss 0.9663 (0.8552)	grad_norm 2.1185 (inf)	loss_scale 16384.0000 (21226.6768)	mem 9944MB
[2024-07-26 16:53:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:37 lr 0.000080	 wd 0.0000	time 0.2225 (0.3216)	loss 0.9243 (0.8553)	grad_norm 1.7578 (inf)	loss_scale 16384.0000 (21006.6552)	mem 9944MB
[2024-07-26 16:53:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:01:04 lr 0.000080	 wd 0.0000	time 0.2449 (0.3199)	loss 0.9087 (0.8550)	grad_norm 1.8915 (inf)	loss_scale 16384.0000 (20805.7575)	mem 9944MB
[2024-07-26 16:54:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:32 lr 0.000080	 wd 0.0000	time 0.2447 (0.3177)	loss 0.8892 (0.8549)	grad_norm 2.3285 (inf)	loss_scale 16384.0000 (20621.5943)	mem 9944MB
[2024-07-26 16:54:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000080	 wd 0.0000	time 0.2371 (0.3154)	loss 0.9624 (0.8551)	grad_norm 2.4107 (inf)	loss_scale 16384.0000 (20452.1583)	mem 9944MB
[2024-07-26 16:54:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 8 training takes 0:13:13
[2024-07-26 16:55:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 36.277 (36.277)	Loss 0.3608 (0.3608)	Acc@1 92.383 (92.383)	Acc@5 98.242 (98.242)	Mem 9944MB
[2024-07-26 16:55:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.366 Acc@5 97.604
[2024-07-26 16:55:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-26 16:55:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.37%
[2024-07-26 16:55:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saving......
[2024-07-26 16:55:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-26 16:55:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][0/2502]	eta 10:12:45 lr 0.000080	 wd 0.0000	time 14.6945 (14.6945)	loss 0.7388 (0.7388)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:56:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:16:16 lr 0.000079	 wd 0.0000	time 0.2241 (0.4066)	loss 0.8384 (0.8443)	grad_norm 1.6777 (1.8516)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:56:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:13:09 lr 0.000079	 wd 0.0000	time 0.2436 (0.3431)	loss 0.7583 (0.8419)	grad_norm 1.8669 (1.8303)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:57:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:11:39 lr 0.000079	 wd 0.0000	time 0.2489 (0.3175)	loss 0.9175 (0.8483)	grad_norm 1.6984 (1.8333)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:57:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:10:39 lr 0.000079	 wd 0.0000	time 0.2292 (0.3041)	loss 0.7441 (0.8467)	grad_norm 2.1230 (1.8232)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:58:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:09:53 lr 0.000079	 wd 0.0000	time 0.2446 (0.2964)	loss 0.7456 (0.8454)	grad_norm 1.6470 (1.8314)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:58:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:09:16 lr 0.000079	 wd 0.0000	time 0.2704 (0.2923)	loss 0.8013 (0.8439)	grad_norm 1.7307 (1.8284)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:58:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:08:39 lr 0.000078	 wd 0.0000	time 0.2189 (0.2885)	loss 0.9399 (0.8449)	grad_norm 2.4008 (1.8202)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:59:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:08:06 lr 0.000078	 wd 0.0000	time 0.2403 (0.2856)	loss 0.9966 (0.8451)	grad_norm 1.5553 (1.8344)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 16:59:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:07:34 lr 0.000078	 wd 0.0000	time 0.2437 (0.2837)	loss 0.9468 (0.8462)	grad_norm 1.3982 (1.8351)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:00:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:07:04 lr 0.000078	 wd 0.0000	time 0.2200 (0.2826)	loss 0.8296 (0.8469)	grad_norm 1.7518 (1.8338)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:00:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:06:34 lr 0.000078	 wd 0.0000	time 0.2379 (0.2811)	loss 0.9126 (0.8463)	grad_norm 2.1940 (1.8438)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:01:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:06:04 lr 0.000078	 wd 0.0000	time 0.2414 (0.2796)	loss 0.8770 (0.8476)	grad_norm 1.9290 (1.8420)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:01:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:05:35 lr 0.000077	 wd 0.0000	time 0.2809 (0.2791)	loss 0.8335 (0.8478)	grad_norm 1.3918 (1.8535)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:02:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:05:06 lr 0.000077	 wd 0.0000	time 0.2296 (0.2784)	loss 0.9014 (0.8482)	grad_norm 1.4884 (1.8573)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:02:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:04:38 lr 0.000077	 wd 0.0000	time 0.2608 (0.2777)	loss 0.8154 (0.8493)	grad_norm 1.9062 (1.8561)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:02:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:04:09 lr 0.000077	 wd 0.0000	time 0.2349 (0.2770)	loss 0.8125 (0.8480)	grad_norm 1.7063 (1.8566)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:03:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:55 lr 0.000077	 wd 0.0000	time 0.2529 (0.2937)	loss 0.8193 (0.8479)	grad_norm 2.1262 (1.8541)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:04:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:03:26 lr 0.000077	 wd 0.0000	time 0.2689 (0.2937)	loss 0.8662 (0.8482)	grad_norm 1.2610 (1.8523)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:05:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:03:07 lr 0.000076	 wd 0.0000	time 0.3182 (0.3109)	loss 0.8589 (0.8486)	grad_norm 1.8377 (1.8515)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:06:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:02:39 lr 0.000076	 wd 0.0000	time 0.2183 (0.3173)	loss 0.7983 (0.8494)	grad_norm 1.9094 (1.8502)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:06:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:02:07 lr 0.000076	 wd 0.0000	time 0.2195 (0.3179)	loss 0.8125 (0.8495)	grad_norm 1.7151 (1.8494)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:07:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:35 lr 0.000076	 wd 0.0000	time 0.2506 (0.3156)	loss 0.6626 (0.8492)	grad_norm 2.5567 (inf)	loss_scale 16384.0000 (16592.4289)	mem 9944MB
[2024-07-26 17:07:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:01:03 lr 0.000076	 wd 0.0000	time 0.2205 (0.3136)	loss 0.8262 (0.8490)	grad_norm 2.7232 (inf)	loss_scale 16384.0000 (16583.3707)	mem 9944MB
[2024-07-26 17:08:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:31 lr 0.000075	 wd 0.0000	time 0.2413 (0.3117)	loss 0.9111 (0.8495)	grad_norm 1.4214 (inf)	loss_scale 16384.0000 (16575.0671)	mem 9944MB
[2024-07-26 17:08:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000075	 wd 0.0000	time 0.2323 (0.3100)	loss 0.8442 (0.8498)	grad_norm 1.9353 (inf)	loss_scale 16384.0000 (16567.4274)	mem 9944MB
[2024-07-26 17:08:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 9 training takes 0:13:01
[2024-07-26 17:08:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 21.216 (21.216)	Loss 0.3574 (0.3574)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 9944MB
[2024-07-26 17:09:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.234 Acc@5 97.554
[2024-07-26 17:09:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-26 17:09:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.37%
[2024-07-26 17:09:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][0/2502]	eta 14:10:12 lr 0.000075	 wd 0.0000	time 20.3888 (20.3888)	loss 0.9155 (0.9155)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:09:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:18:43 lr 0.000075	 wd 0.0000	time 0.2289 (0.4678)	loss 0.9448 (0.8604)	grad_norm 1.8851 (1.9459)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:10:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:14:05 lr 0.000075	 wd 0.0000	time 0.2517 (0.3674)	loss 0.8369 (0.8527)	grad_norm 2.2196 (1.8602)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:10:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:12:13 lr 0.000075	 wd 0.0000	time 0.2417 (0.3333)	loss 0.8428 (0.8500)	grad_norm 1.9179 (1.8570)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:11:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:11:05 lr 0.000075	 wd 0.0000	time 0.2535 (0.3166)	loss 0.8345 (0.8491)	grad_norm 1.8413 (1.8494)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:11:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:10:13 lr 0.000074	 wd 0.0000	time 0.2201 (0.3066)	loss 0.7837 (0.8508)	grad_norm 2.2596 (1.8583)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:12:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:09:29 lr 0.000074	 wd 0.0000	time 0.2405 (0.2994)	loss 0.7974 (0.8505)	grad_norm 1.7211 (1.8716)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:12:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:08:50 lr 0.000074	 wd 0.0000	time 0.2551 (0.2943)	loss 0.7632 (0.8479)	grad_norm 2.2919 (1.8716)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:13:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:08:16 lr 0.000074	 wd 0.0000	time 0.2257 (0.2918)	loss 0.8022 (0.8488)	grad_norm 1.7807 (1.8730)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:13:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:07:43 lr 0.000074	 wd 0.0000	time 0.2546 (0.2893)	loss 0.7666 (0.8482)	grad_norm 1.6043 (1.8657)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:13:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:07:10 lr 0.000073	 wd 0.0000	time 0.2577 (0.2869)	loss 0.9473 (0.8475)	grad_norm 1.5860 (1.8542)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:14:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:06:39 lr 0.000073	 wd 0.0000	time 0.3037 (0.2851)	loss 0.9268 (0.8470)	grad_norm 1.5523 (1.8550)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:14:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:06:09 lr 0.000073	 wd 0.0000	time 0.2438 (0.2841)	loss 0.9692 (0.8465)	grad_norm 1.7132 (1.8497)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:15:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:05:39 lr 0.000073	 wd 0.0000	time 0.2162 (0.2829)	loss 0.8130 (0.8464)	grad_norm 1.8328 (1.8466)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:15:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:05:10 lr 0.000073	 wd 0.0000	time 0.2346 (0.2817)	loss 0.8252 (0.8467)	grad_norm 1.8841 (1.8395)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:16:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:04:41 lr 0.000073	 wd 0.0000	time 0.2242 (0.2808)	loss 0.8584 (0.8467)	grad_norm 1.5474 (1.8343)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:17:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:04:40 lr 0.000072	 wd 0.0000	time 0.9217 (0.3115)	loss 0.6821 (0.8464)	grad_norm 1.8074 (1.8344)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:18:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:04:17 lr 0.000072	 wd 0.0000	time 0.2572 (0.3209)	loss 0.7998 (0.8463)	grad_norm 1.8503 (1.8452)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:18:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:03:43 lr 0.000072	 wd 0.0000	time 0.2632 (0.3179)	loss 0.9390 (0.8464)	grad_norm 2.0430 (1.8596)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:19:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:03:09 lr 0.000072	 wd 0.0000	time 0.2482 (0.3152)	loss 0.9233 (0.8479)	grad_norm 1.7097 (1.8610)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:19:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:02:37 lr 0.000072	 wd 0.0000	time 0.2685 (0.3140)	loss 1.0254 (0.8484)	grad_norm 3.1122 (1.8662)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:20:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:02:05 lr 0.000071	 wd 0.0000	time 0.2682 (0.3120)	loss 0.8477 (0.8485)	grad_norm 1.7150 (1.8650)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:20:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:33 lr 0.000071	 wd 0.0000	time 0.2404 (0.3100)	loss 0.8779 (0.8486)	grad_norm 1.6133 (1.8667)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:20:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:01:02 lr 0.000071	 wd 0.0000	time 0.2582 (0.3083)	loss 0.9131 (0.8485)	grad_norm 2.5105 (1.8652)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:21:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:31 lr 0.000071	 wd 0.0000	time 0.2439 (0.3071)	loss 0.9214 (0.8486)	grad_norm 2.0602 (1.8645)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:21:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000071	 wd 0.0000	time 0.2440 (0.3053)	loss 0.7412 (0.8481)	grad_norm 1.5542 (1.8646)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:21:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 10 training takes 0:12:48
[2024-07-26 17:22:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 20.297 (20.297)	Loss 0.3613 (0.3613)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 9944MB
[2024-07-26 17:22:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.414 Acc@5 97.580
[2024-07-26 17:22:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-26 17:22:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.41%
[2024-07-26 17:22:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saving......
[2024-07-26 17:22:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-26 17:22:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][0/2502]	eta 20:31:33 lr 0.000071	 wd 0.0000	time 29.5339 (29.5339)	loss 0.8193 (0.8193)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:23:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:22:12 lr 0.000070	 wd 0.0000	time 0.2256 (0.5547)	loss 0.7964 (0.8457)	grad_norm 1.8056 (1.7892)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:23:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:15:42 lr 0.000070	 wd 0.0000	time 0.2748 (0.4096)	loss 0.8418 (0.8456)	grad_norm 2.1678 (1.8519)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:24:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:13:33 lr 0.000070	 wd 0.0000	time 0.3203 (0.3694)	loss 0.8379 (0.8422)	grad_norm 2.2519 (1.8988)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:24:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:12:20 lr 0.000070	 wd 0.0000	time 0.2474 (0.3521)	loss 0.7876 (0.8387)	grad_norm 1.9705 (1.8669)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:25:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:11:09 lr 0.000070	 wd 0.0000	time 0.2371 (0.3344)	loss 0.8218 (0.8372)	grad_norm 2.1463 (1.8917)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:25:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:10:14 lr 0.000069	 wd 0.0000	time 0.2876 (0.3231)	loss 0.8970 (0.8377)	grad_norm 1.8025 (1.8798)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:26:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:09:31 lr 0.000069	 wd 0.0000	time 0.2178 (0.3171)	loss 0.8267 (0.8385)	grad_norm 2.2758 (1.8651)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:26:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:08:48 lr 0.000069	 wd 0.0000	time 0.2720 (0.3107)	loss 0.9248 (0.8394)	grad_norm 1.7763 (1.8661)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:27:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:08:09 lr 0.000069	 wd 0.0000	time 0.2432 (0.3054)	loss 0.8545 (0.8423)	grad_norm 1.8752 (1.8562)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:27:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:07:32 lr 0.000069	 wd 0.0000	time 0.2382 (0.3016)	loss 0.8247 (0.8428)	grad_norm 1.6173 (1.8548)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:27:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:06:59 lr 0.000069	 wd 0.0000	time 0.2407 (0.2991)	loss 0.8564 (0.8422)	grad_norm 1.6097 (1.8473)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:28:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:06:25 lr 0.000068	 wd 0.0000	time 0.2246 (0.2962)	loss 0.9341 (0.8420)	grad_norm 1.8835 (1.8478)	loss_scale 32768.0000 (17175.2340)	mem 9944MB
[2024-07-26 17:28:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:05:53 lr 0.000068	 wd 0.0000	time 0.2439 (0.2939)	loss 0.7896 (0.8425)	grad_norm 1.5416 (1.8491)	loss_scale 32768.0000 (18373.7556)	mem 9944MB
[2024-07-26 17:29:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:05:23 lr 0.000068	 wd 0.0000	time 0.3582 (0.2936)	loss 0.8145 (0.8427)	grad_norm 1.6716 (1.8437)	loss_scale 32768.0000 (19401.1820)	mem 9944MB
[2024-07-26 17:30:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:05:12 lr 0.000068	 wd 0.0000	time 0.2731 (0.3115)	loss 0.8169 (0.8421)	grad_norm 1.8042 (1.8384)	loss_scale 32768.0000 (20291.7095)	mem 9944MB
[2024-07-26 17:30:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:04:40 lr 0.000068	 wd 0.0000	time 0.3581 (0.3108)	loss 0.7227 (0.8421)	grad_norm 2.0258 (nan)	loss_scale 16384.0000 (20375.1056)	mem 9944MB
[2024-07-26 17:32:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:04:39 lr 0.000067	 wd 0.0000	time 0.2624 (0.3481)	loss 0.8608 (0.8416)	grad_norm 1.7203 (nan)	loss_scale 16384.0000 (20140.4727)	mem 9944MB
[2024-07-26 17:32:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:04:04 lr 0.000067	 wd 0.0000	time 0.2301 (0.3477)	loss 0.8130 (0.8425)	grad_norm 1.4909 (nan)	loss_scale 16384.0000 (19931.8956)	mem 9944MB
[2024-07-26 17:33:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:03:26 lr 0.000067	 wd 0.0000	time 0.2496 (0.3434)	loss 0.7935 (0.8430)	grad_norm 1.6830 (nan)	loss_scale 16384.0000 (19745.2625)	mem 9944MB
[2024-07-26 17:33:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:02:50 lr 0.000067	 wd 0.0000	time 0.2451 (0.3397)	loss 0.6548 (0.8428)	grad_norm 1.7591 (nan)	loss_scale 16384.0000 (19577.2834)	mem 9944MB
[2024-07-26 17:34:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:02:15 lr 0.000067	 wd 0.0000	time 0.2421 (0.3371)	loss 0.9380 (0.8425)	grad_norm 1.4657 (nan)	loss_scale 16384.0000 (19425.2946)	mem 9944MB
[2024-07-26 17:34:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:40 lr 0.000066	 wd 0.0000	time 0.2523 (0.3340)	loss 0.9219 (0.8429)	grad_norm 1.9149 (nan)	loss_scale 16384.0000 (19287.1168)	mem 9944MB
[2024-07-26 17:35:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:01:06 lr 0.000066	 wd 0.0000	time 0.2676 (0.3311)	loss 0.8286 (0.8429)	grad_norm 1.9303 (nan)	loss_scale 16384.0000 (19160.9492)	mem 9944MB
[2024-07-26 17:35:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:33 lr 0.000066	 wd 0.0000	time 0.2655 (0.3287)	loss 0.8296 (0.8426)	grad_norm 2.0069 (nan)	loss_scale 16384.0000 (19045.2911)	mem 9944MB
[2024-07-26 17:36:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000066	 wd 0.0000	time 0.2384 (0.3263)	loss 0.8218 (0.8426)	grad_norm 1.9221 (nan)	loss_scale 16384.0000 (18938.8820)	mem 9944MB
[2024-07-26 17:36:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 11 training takes 0:13:43
[2024-07-26 17:36:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 21.732 (21.732)	Loss 0.3572 (0.3572)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 17:36:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.280 Acc@5 97.616
[2024-07-26 17:36:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-26 17:36:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.41%
[2024-07-26 17:37:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][0/2502]	eta 15:37:10 lr 0.000066	 wd 0.0000	time 22.4742 (22.4742)	loss 0.7676 (0.7676)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:37:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:19:45 lr 0.000066	 wd 0.0000	time 0.2529 (0.4934)	loss 0.8223 (0.8372)	grad_norm 1.6888 (1.8117)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:38:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:14:33 lr 0.000065	 wd 0.0000	time 0.2519 (0.3795)	loss 0.8052 (0.8357)	grad_norm 1.4356 (1.8078)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:38:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:12:30 lr 0.000065	 wd 0.0000	time 0.2596 (0.3408)	loss 0.7773 (0.8431)	grad_norm 3.0697 (1.8033)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:38:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:11:18 lr 0.000065	 wd 0.0000	time 0.2536 (0.3227)	loss 0.8105 (0.8421)	grad_norm 1.7832 (1.8120)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:39:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:10:23 lr 0.000065	 wd 0.0000	time 0.2209 (0.3112)	loss 0.8774 (0.8429)	grad_norm 1.6437 (1.8287)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:39:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:09:37 lr 0.000065	 wd 0.0000	time 0.2492 (0.3034)	loss 0.8574 (0.8404)	grad_norm 1.4828 (1.8145)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:40:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:08:56 lr 0.000064	 wd 0.0000	time 0.2462 (0.2979)	loss 0.8628 (0.8418)	grad_norm 1.7219 (1.8314)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:40:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:08:21 lr 0.000064	 wd 0.0000	time 0.2561 (0.2944)	loss 1.0723 (0.8416)	grad_norm 1.9063 (1.8225)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:41:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:07:46 lr 0.000064	 wd 0.0000	time 0.2612 (0.2914)	loss 0.9692 (0.8414)	grad_norm 1.4033 (1.8083)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:41:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:07:13 lr 0.000064	 wd 0.0000	time 0.2380 (0.2888)	loss 0.8022 (0.8417)	grad_norm 1.6883 (1.8025)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:42:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:06:42 lr 0.000064	 wd 0.0000	time 0.2223 (0.2868)	loss 0.7949 (0.8433)	grad_norm 1.5944 (1.7983)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:42:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:06:12 lr 0.000063	 wd 0.0000	time 0.2336 (0.2858)	loss 0.8975 (0.8434)	grad_norm 2.4050 (1.8041)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:42:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:05:41 lr 0.000063	 wd 0.0000	time 0.2491 (0.2844)	loss 0.8193 (0.8437)	grad_norm 1.8486 (1.8048)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:43:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:05:11 lr 0.000063	 wd 0.0000	time 0.2553 (0.2831)	loss 1.0400 (0.8444)	grad_norm 2.0465 (1.8170)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:43:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:04:42 lr 0.000063	 wd 0.0000	time 0.2206 (0.2824)	loss 0.8604 (0.8445)	grad_norm 1.9143 (1.8171)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:44:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:04:24 lr 0.000063	 wd 0.0000	time 0.2928 (0.2928)	loss 0.8501 (0.8434)	grad_norm 1.9914 (1.8286)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:45:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:57 lr 0.000062	 wd 0.0000	time 0.2575 (0.2955)	loss 0.9165 (0.8432)	grad_norm 1.8290 (1.8242)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:46:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:03:36 lr 0.000062	 wd 0.0000	time 0.2536 (0.3085)	loss 0.6880 (0.8432)	grad_norm 2.3754 (1.8234)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:46:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:03:05 lr 0.000062	 wd 0.0000	time 0.3186 (0.3087)	loss 0.8120 (0.8434)	grad_norm 1.8008 (1.8214)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:47:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:02:34 lr 0.000062	 wd 0.0000	time 0.3356 (0.3074)	loss 0.8013 (0.8434)	grad_norm 2.8686 (1.8210)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:48:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:02:09 lr 0.000062	 wd 0.0000	time 0.2374 (0.3227)	loss 0.9214 (0.8439)	grad_norm 1.8953 (1.8190)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:48:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:37 lr 0.000061	 wd 0.0000	time 0.2485 (0.3213)	loss 0.9795 (0.8439)	grad_norm 1.2995 (1.8215)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:49:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:01:05 lr 0.000061	 wd 0.0000	time 0.2564 (0.3232)	loss 0.7886 (0.8437)	grad_norm 1.9679 (1.8309)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:49:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:32 lr 0.000061	 wd 0.0000	time 0.2633 (0.3209)	loss 0.7817 (0.8436)	grad_norm 1.6354 (1.8292)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:50:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000061	 wd 0.0000	time 0.2397 (0.3186)	loss 0.8110 (0.8436)	grad_norm 1.6149 (1.8276)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:50:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 12 training takes 0:13:21
[2024-07-26 17:50:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 37.887 (37.887)	Loss 0.3682 (0.3682)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 17:50:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.390 Acc@5 97.602
[2024-07-26 17:50:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-26 17:50:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.41%
[2024-07-26 17:51:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][0/2502]	eta 11:29:56 lr 0.000061	 wd 0.0000	time 16.5455 (16.5455)	loss 0.6963 (0.6963)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:51:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:17:02 lr 0.000061	 wd 0.0000	time 0.2558 (0.4256)	loss 0.7588 (0.8365)	grad_norm 1.9888 (1.7817)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:52:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:13:26 lr 0.000060	 wd 0.0000	time 0.2574 (0.3502)	loss 0.7104 (0.8325)	grad_norm 2.7889 (1.7693)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:52:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:11:48 lr 0.000060	 wd 0.0000	time 0.2687 (0.3216)	loss 0.8096 (0.8298)	grad_norm 1.8993 (1.7831)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:53:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:10:45 lr 0.000060	 wd 0.0000	time 0.2397 (0.3072)	loss 0.8838 (0.8342)	grad_norm 2.2850 (1.7897)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:53:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:09:57 lr 0.000060	 wd 0.0000	time 0.2805 (0.2986)	loss 0.8491 (0.8330)	grad_norm 1.7429 (1.7906)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 17:53:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:09:18 lr 0.000060	 wd 0.0000	time 0.2804 (0.2934)	loss 0.8408 (0.8314)	grad_norm 1.5964 (1.7956)	loss_scale 32768.0000 (18346.8087)	mem 9944MB
[2024-07-26 17:54:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:08:41 lr 0.000059	 wd 0.0000	time 0.2556 (0.2895)	loss 0.8076 (0.8317)	grad_norm 1.4840 (1.7989)	loss_scale 32768.0000 (20404.0399)	mem 9944MB
[2024-07-26 17:54:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:08:07 lr 0.000059	 wd 0.0000	time 0.2508 (0.2864)	loss 0.8462 (0.8318)	grad_norm 1.7504 (1.8033)	loss_scale 32768.0000 (21947.6055)	mem 9944MB
[2024-07-26 17:55:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:07:35 lr 0.000059	 wd 0.0000	time 0.2461 (0.2843)	loss 0.8096 (0.8335)	grad_norm 2.0922 (1.8031)	loss_scale 32768.0000 (23148.5372)	mem 9944MB
[2024-07-26 17:55:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:07:05 lr 0.000059	 wd 0.0000	time 0.2470 (0.2832)	loss 0.8604 (0.8360)	grad_norm 1.5548 (1.8000)	loss_scale 32768.0000 (24109.5225)	mem 9944MB
[2024-07-26 17:56:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:06:34 lr 0.000059	 wd 0.0000	time 0.2529 (0.2817)	loss 0.8281 (0.8359)	grad_norm 1.9120 (1.8016)	loss_scale 32768.0000 (24895.9419)	mem 9944MB
[2024-07-26 17:56:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:06:05 lr 0.000058	 wd 0.0000	time 0.2384 (0.2807)	loss 0.9077 (0.8354)	grad_norm 1.4487 (1.8087)	loss_scale 32768.0000 (25551.4005)	mem 9944MB
[2024-07-26 17:57:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:05:36 lr 0.000058	 wd 0.0000	time 0.2817 (0.2803)	loss 0.8887 (0.8356)	grad_norm 1.8518 (1.8093)	loss_scale 32768.0000 (26106.0968)	mem 9944MB
[2024-07-26 17:57:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:05:08 lr 0.000058	 wd 0.0000	time 0.2516 (0.2796)	loss 0.8647 (0.8347)	grad_norm 1.7630 (1.8110)	loss_scale 32768.0000 (26581.6074)	mem 9944MB
[2024-07-26 17:57:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:04:39 lr 0.000058	 wd 0.0000	time 0.2559 (0.2787)	loss 0.7695 (0.8358)	grad_norm 1.4597 (1.8084)	loss_scale 32768.0000 (26993.7588)	mem 9944MB
[2024-07-26 17:58:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:04:10 lr 0.000058	 wd 0.0000	time 0.2551 (0.2780)	loss 0.6699 (0.8363)	grad_norm 1.7736 (1.8070)	loss_scale 32768.0000 (27354.4235)	mem 9944MB
[2024-07-26 17:59:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:56 lr 0.000057	 wd 0.0000	time 0.2910 (0.2953)	loss 0.8174 (0.8372)	grad_norm 2.4099 (1.8082)	loss_scale 32768.0000 (27672.6820)	mem 9944MB
[2024-07-26 17:59:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:03:29 lr 0.000057	 wd 0.0000	time 0.2815 (0.2991)	loss 0.8296 (0.8380)	grad_norm 1.6220 (1.8109)	loss_scale 32768.0000 (27955.5980)	mem 9944MB
[2024-07-26 18:00:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:03:06 lr 0.000057	 wd 0.0000	time 0.2364 (0.3101)	loss 0.7549 (0.8375)	grad_norm 1.3891 (1.8107)	loss_scale 32768.0000 (28208.7491)	mem 9944MB
[2024-07-26 18:01:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:02:35 lr 0.000057	 wd 0.0000	time 0.2348 (0.3102)	loss 0.8608 (0.8371)	grad_norm 1.2347 (1.8080)	loss_scale 32768.0000 (28436.5977)	mem 9944MB
[2024-07-26 18:01:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:02:05 lr 0.000057	 wd 0.0000	time 0.2299 (0.3119)	loss 0.8159 (0.8375)	grad_norm 1.6300 (1.8071)	loss_scale 32768.0000 (28642.7568)	mem 9944MB
[2024-07-26 18:02:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:36 lr 0.000056	 wd 0.0000	time 0.2677 (0.3194)	loss 0.7866 (0.8372)	grad_norm 1.9829 (inf)	loss_scale 16384.0000 (28309.1104)	mem 9944MB
[2024-07-26 18:03:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:01:04 lr 0.000056	 wd 0.0000	time 0.2758 (0.3179)	loss 0.9043 (0.8373)	grad_norm 1.4440 (inf)	loss_scale 16384.0000 (27790.8527)	mem 9944MB
[2024-07-26 18:04:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:33 lr 0.000056	 wd 0.0000	time 0.2386 (0.3280)	loss 0.7842 (0.8374)	grad_norm 1.6702 (inf)	loss_scale 16384.0000 (27315.7651)	mem 9944MB
[2024-07-26 18:04:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000056	 wd 0.0000	time 0.2338 (0.3260)	loss 0.7749 (0.8374)	grad_norm 1.3610 (inf)	loss_scale 16384.0000 (26878.6693)	mem 9944MB
[2024-07-26 18:04:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 13 training takes 0:13:41
[2024-07-26 18:05:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 44.130 (44.130)	Loss 0.3694 (0.3694)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)	Mem 9944MB
[2024-07-26 18:05:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.464 Acc@5 97.590
[2024-07-26 18:05:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-26 18:05:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.46%
[2024-07-26 18:05:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saving......
[2024-07-26 18:05:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-26 18:05:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][0/2502]	eta 10:02:54 lr 0.000056	 wd 0.0000	time 14.4583 (14.4583)	loss 0.7822 (0.7822)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:06:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:16:47 lr 0.000055	 wd 0.0000	time 0.2693 (0.4196)	loss 0.8154 (0.8322)	grad_norm 1.4653 (1.8540)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:06:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:13:19 lr 0.000055	 wd 0.0000	time 0.2730 (0.3472)	loss 0.8037 (0.8283)	grad_norm 1.5773 (1.8404)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:07:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:11:44 lr 0.000055	 wd 0.0000	time 0.2570 (0.3197)	loss 0.8994 (0.8317)	grad_norm 1.4496 (1.8039)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:07:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:10:43 lr 0.000055	 wd 0.0000	time 0.2235 (0.3059)	loss 1.0088 (0.8326)	grad_norm 1.5528 (1.7930)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:08:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:09:55 lr 0.000055	 wd 0.0000	time 0.2216 (0.2977)	loss 0.8237 (0.8316)	grad_norm 1.7965 (1.7862)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:08:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:09:16 lr 0.000054	 wd 0.0000	time 0.2389 (0.2927)	loss 0.7920 (0.8337)	grad_norm 1.5035 (1.7693)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:08:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:08:40 lr 0.000054	 wd 0.0000	time 0.2529 (0.2891)	loss 0.7437 (0.8359)	grad_norm 1.4576 (1.7765)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:09:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:08:07 lr 0.000054	 wd 0.0000	time 0.2628 (0.2862)	loss 0.8193 (0.8340)	grad_norm 1.5327 (1.7702)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:09:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:07:35 lr 0.000054	 wd 0.0000	time 0.2148 (0.2844)	loss 0.9126 (0.8335)	grad_norm 1.8159 (1.7812)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:10:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:07:05 lr 0.000054	 wd 0.0000	time 0.2351 (0.2835)	loss 0.9536 (0.8331)	grad_norm 1.7619 (1.7880)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:10:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:06:35 lr 0.000053	 wd 0.0000	time 0.2384 (0.2818)	loss 0.7549 (0.8334)	grad_norm 1.3949 (1.7810)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:11:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:06:05 lr 0.000053	 wd 0.0000	time 0.2505 (0.2806)	loss 0.8760 (0.8338)	grad_norm 1.9188 (1.7753)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:11:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:05:36 lr 0.000053	 wd 0.0000	time 0.2374 (0.2802)	loss 0.9150 (0.8338)	grad_norm 1.4792 (1.7705)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:12:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:05:07 lr 0.000053	 wd 0.0000	time 0.2753 (0.2794)	loss 0.8784 (0.8330)	grad_norm 2.5236 (1.7702)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:12:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:04:38 lr 0.000053	 wd 0.0000	time 0.2203 (0.2784)	loss 0.9077 (0.8330)	grad_norm 2.6131 (1.7747)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:13:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:04:10 lr 0.000052	 wd 0.0000	time 0.2413 (0.2778)	loss 0.8750 (0.8336)	grad_norm 1.6877 (1.7736)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:13:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:53 lr 0.000052	 wd 0.0000	time 0.2562 (0.2907)	loss 0.9458 (0.8338)	grad_norm 1.6501 (1.7777)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:14:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:03:25 lr 0.000052	 wd 0.0000	time 0.2826 (0.2928)	loss 0.9351 (0.8339)	grad_norm 1.5701 (1.7746)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:15:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:03:04 lr 0.000052	 wd 0.0000	time 0.2578 (0.3062)	loss 0.8145 (0.8339)	grad_norm 2.1698 (1.7726)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:15:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:02:33 lr 0.000052	 wd 0.0000	time 0.2930 (0.3057)	loss 0.8711 (0.8340)	grad_norm 1.5446 (1.7748)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:16:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:02:02 lr 0.000051	 wd 0.0000	time 0.2296 (0.3044)	loss 0.8110 (0.8345)	grad_norm 1.3792 (1.7775)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:17:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:35 lr 0.000051	 wd 0.0000	time 0.2573 (0.3152)	loss 0.7598 (0.8352)	grad_norm 1.8952 (1.7813)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:17:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:01:03 lr 0.000051	 wd 0.0000	time 0.2700 (0.3138)	loss 0.9185 (0.8355)	grad_norm 2.6669 (1.7813)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:18:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:33 lr 0.000051	 wd 0.0000	time 0.2854 (0.3249)	loss 0.7939 (0.8357)	grad_norm 1.5353 (1.7832)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:19:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000051	 wd 0.0000	time 0.2327 (0.3228)	loss 0.8018 (0.8358)	grad_norm 1.4285 (1.7824)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:19:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 14 training takes 0:13:33
[2024-07-26 18:20:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 55.577 (55.577)	Loss 0.3647 (0.3647)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 18:20:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.516 Acc@5 97.602
[2024-07-26 18:20:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-26 18:20:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-26 18:20:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saving......
[2024-07-26 18:20:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-26 18:20:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][0/2502]	eta 10:44:45 lr 0.000051	 wd 0.0000	time 15.4617 (15.4617)	loss 0.7314 (0.7314)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:21:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:16:56 lr 0.000050	 wd 0.0000	time 0.2415 (0.4230)	loss 0.8530 (0.8273)	grad_norm 1.4873 (1.8101)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:21:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:13:23 lr 0.000050	 wd 0.0000	time 0.2229 (0.3490)	loss 1.0752 (0.8352)	grad_norm 1.5167 (1.8260)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:21:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:11:47 lr 0.000050	 wd 0.0000	time 0.2413 (0.3213)	loss 0.7500 (0.8360)	grad_norm 1.6927 (1.8303)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:22:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:10:44 lr 0.000050	 wd 0.0000	time 0.2475 (0.3068)	loss 0.6704 (0.8353)	grad_norm 1.7993 (1.8155)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:22:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:09:58 lr 0.000049	 wd 0.0000	time 0.2390 (0.2988)	loss 0.7837 (0.8352)	grad_norm 1.7739 (1.8202)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:23:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:09:17 lr 0.000049	 wd 0.0000	time 0.2526 (0.2932)	loss 0.7549 (0.8351)	grad_norm 1.9062 (1.8036)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:23:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:08:40 lr 0.000049	 wd 0.0000	time 0.2393 (0.2891)	loss 0.8320 (0.8342)	grad_norm 1.3659 (1.7936)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:24:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:08:06 lr 0.000049	 wd 0.0000	time 0.2461 (0.2861)	loss 0.7778 (0.8335)	grad_norm 1.6639 (1.7895)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:24:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:07:35 lr 0.000049	 wd 0.0000	time 0.2505 (0.2844)	loss 0.8091 (0.8336)	grad_norm 2.1698 (1.7941)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:25:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:07:04 lr 0.000048	 wd 0.0000	time 0.2542 (0.2827)	loss 0.7964 (0.8339)	grad_norm 1.5533 (1.7911)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:25:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:06:34 lr 0.000048	 wd 0.0000	time 0.2573 (0.2811)	loss 0.8955 (0.8328)	grad_norm 2.2015 (1.7911)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:25:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:06:04 lr 0.000048	 wd 0.0000	time 0.2431 (0.2799)	loss 0.7202 (0.8324)	grad_norm 1.7205 (1.7887)	loss_scale 32768.0000 (17393.5054)	mem 9944MB
[2024-07-26 18:26:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:05:36 lr 0.000048	 wd 0.0000	time 0.2394 (0.2799)	loss 0.8877 (0.8328)	grad_norm 1.8324 (1.7898)	loss_scale 32768.0000 (18575.2498)	mem 9944MB
[2024-07-26 18:26:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:05:07 lr 0.000048	 wd 0.0000	time 0.2368 (0.2792)	loss 0.8477 (0.8326)	grad_norm 1.7308 (1.7911)	loss_scale 32768.0000 (19588.2941)	mem 9944MB
[2024-07-26 18:27:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:04:38 lr 0.000047	 wd 0.0000	time 0.2303 (0.2782)	loss 0.8018 (0.8322)	grad_norm 2.0804 (1.7823)	loss_scale 32768.0000 (20466.3558)	mem 9944MB
[2024-07-26 18:27:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:04:10 lr 0.000047	 wd 0.0000	time 0.2517 (0.2777)	loss 0.8853 (0.8321)	grad_norm 2.1171 (1.7846)	loss_scale 32768.0000 (21234.7283)	mem 9944MB
[2024-07-26 18:28:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:43 lr 0.000047	 wd 0.0000	time 0.2594 (0.2783)	loss 0.8872 (0.8316)	grad_norm 1.3508 (1.7851)	loss_scale 32768.0000 (21912.7572)	mem 9944MB
[2024-07-26 18:28:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:03:14 lr 0.000047	 wd 0.0000	time 0.2331 (0.2778)	loss 0.8701 (0.8328)	grad_norm 1.7863 (1.7880)	loss_scale 32768.0000 (22515.4914)	mem 9944MB
[2024-07-26 18:29:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:46 lr 0.000047	 wd 0.0000	time 0.2477 (0.2773)	loss 0.8833 (0.8327)	grad_norm 1.7600 (1.7866)	loss_scale 32768.0000 (23054.8133)	mem 9944MB
[2024-07-26 18:29:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:02:22 lr 0.000046	 wd 0.0000	time 0.2564 (0.2844)	loss 0.9224 (0.8327)	grad_norm 1.9965 (1.7876)	loss_scale 32768.0000 (23540.2299)	mem 9944MB
[2024-07-26 18:30:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:55 lr 0.000046	 wd 0.0000	time 0.2431 (0.2861)	loss 0.8433 (0.8327)	grad_norm 1.7357 (1.7898)	loss_scale 32768.0000 (23979.4384)	mem 9944MB
[2024-07-26 18:30:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:26 lr 0.000046	 wd 0.0000	time 0.2534 (0.2862)	loss 0.8252 (0.8330)	grad_norm 1.6140 (1.7890)	loss_scale 32768.0000 (24378.7369)	mem 9944MB
[2024-07-26 18:31:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:01:00 lr 0.000046	 wd 0.0000	time 0.2894 (0.3003)	loss 0.9458 (0.8326)	grad_norm 1.5139 (1.7858)	loss_scale 32768.0000 (24743.3290)	mem 9944MB
[2024-07-26 18:32:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:30 lr 0.000046	 wd 0.0000	time 0.2699 (0.2998)	loss 0.8101 (0.8325)	grad_norm 1.6489 (1.7849)	loss_scale 32768.0000 (25077.5510)	mem 9944MB
[2024-07-26 18:32:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000045	 wd 0.0000	time 0.2285 (0.2986)	loss 1.0264 (0.8328)	grad_norm 1.7953 (1.7841)	loss_scale 32768.0000 (25385.0460)	mem 9944MB
[2024-07-26 18:33:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 15 training takes 0:12:41
[2024-07-26 18:33:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_15.pth saving......
[2024-07-26 18:33:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_15.pth saved !!!
[2024-07-26 18:34:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 57.090 (57.090)	Loss 0.3660 (0.3660)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 18:34:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.392 Acc@5 97.614
[2024-07-26 18:34:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-26 18:34:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-26 18:34:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][0/2502]	eta 14:46:24 lr 0.000045	 wd 0.0000	time 21.2569 (21.2569)	loss 0.7964 (0.7964)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:35:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:18:57 lr 0.000045	 wd 0.0000	time 0.2369 (0.4735)	loss 1.0020 (0.8373)	grad_norm 1.8209 (1.8783)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:35:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:14:12 lr 0.000045	 wd 0.0000	time 0.2315 (0.3701)	loss 0.8521 (0.8388)	grad_norm 1.6805 (1.8134)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:36:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:12:28 lr 0.000045	 wd 0.0000	time 0.2554 (0.3400)	loss 0.8159 (0.8364)	grad_norm 1.4206 (1.7869)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:36:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:11:15 lr 0.000045	 wd 0.0000	time 0.2139 (0.3213)	loss 0.8779 (0.8342)	grad_norm 1.5567 (1.7790)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:36:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:10:20 lr 0.000044	 wd 0.0000	time 0.2557 (0.3100)	loss 0.7671 (0.8317)	grad_norm 1.7849 (1.7777)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:37:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:09:35 lr 0.000044	 wd 0.0000	time 0.2631 (0.3025)	loss 0.8301 (0.8331)	grad_norm 1.6229 (1.7807)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:37:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:08:57 lr 0.000044	 wd 0.0000	time 0.2340 (0.2982)	loss 0.8408 (0.8325)	grad_norm 1.4854 (1.7594)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:38:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:08:20 lr 0.000044	 wd 0.0000	time 0.2408 (0.2941)	loss 0.9619 (0.8319)	grad_norm 2.3694 (1.7719)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:38:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:07:45 lr 0.000043	 wd 0.0000	time 0.2454 (0.2909)	loss 0.8018 (0.8338)	grad_norm 1.4889 (1.7761)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:39:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:07:13 lr 0.000043	 wd 0.0000	time 0.2426 (0.2887)	loss 0.7812 (0.8350)	grad_norm 1.6609 (1.7685)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:39:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:06:42 lr 0.000043	 wd 0.0000	time 0.2395 (0.2872)	loss 0.7441 (0.8341)	grad_norm 1.4752 (1.7791)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:40:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:06:11 lr 0.000043	 wd 0.0000	time 0.2664 (0.2855)	loss 0.9087 (0.8348)	grad_norm 1.3579 (1.7819)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:40:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:05:41 lr 0.000043	 wd 0.0000	time 0.2468 (0.2841)	loss 0.7930 (0.8330)	grad_norm 1.7215 (1.7828)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:40:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:05:12 lr 0.000042	 wd 0.0000	time 0.2706 (0.2835)	loss 0.8086 (0.8323)	grad_norm 1.4662 (1.7813)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:41:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:04:43 lr 0.000042	 wd 0.0000	time 0.2354 (0.2825)	loss 0.8667 (0.8320)	grad_norm 1.6098 (1.7789)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:41:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:04:14 lr 0.000042	 wd 0.0000	time 0.2418 (0.2816)	loss 0.8340 (0.8320)	grad_norm 1.8162 (1.7784)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:42:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:45 lr 0.000042	 wd 0.0000	time 0.2528 (0.2809)	loss 0.6987 (0.8327)	grad_norm 1.5661 (1.7819)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:43:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:03:24 lr 0.000042	 wd 0.0000	time 0.2655 (0.2907)	loss 0.8701 (0.8328)	grad_norm 1.3056 (1.7785)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:43:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:56 lr 0.000041	 wd 0.0000	time 0.2782 (0.2936)	loss 0.9370 (0.8332)	grad_norm 1.9768 (1.7791)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:44:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:02:33 lr 0.000041	 wd 0.0000	time 0.2463 (0.3066)	loss 0.7417 (0.8328)	grad_norm 1.5967 (1.7787)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:45:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:02:03 lr 0.000041	 wd 0.0000	time 0.2787 (0.3073)	loss 0.7485 (0.8326)	grad_norm 1.4256 (1.7750)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:45:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:32 lr 0.000041	 wd 0.0000	time 0.4579 (0.3068)	loss 0.7622 (0.8327)	grad_norm 1.6613 (1.7781)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 18:46:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:01:04 lr 0.000041	 wd 0.0000	time 0.2811 (0.3186)	loss 0.8501 (0.8327)	grad_norm 1.7756 (inf)	loss_scale 16384.0000 (32184.1286)	mem 9944MB
[2024-07-26 18:47:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:32 lr 0.000040	 wd 0.0000	time 0.2237 (0.3169)	loss 0.7505 (0.8322)	grad_norm 1.3698 (inf)	loss_scale 16384.0000 (31526.0641)	mem 9944MB
[2024-07-26 18:47:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.2403 (0.3158)	loss 0.8179 (0.8320)	grad_norm 1.5526 (inf)	loss_scale 16384.0000 (30920.6238)	mem 9944MB
[2024-07-26 18:47:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 16 training takes 0:13:24
[2024-07-26 18:48:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 58.689 (58.689)	Loss 0.3547 (0.3547)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 18:49:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.424 Acc@5 97.620
[2024-07-26 18:49:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-26 18:49:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-26 18:49:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][0/2502]	eta 12:18:43 lr 0.000040	 wd 0.0000	time 17.7151 (17.7151)	loss 0.7676 (0.7676)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:49:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:17:32 lr 0.000040	 wd 0.0000	time 0.2764 (0.4383)	loss 0.9062 (0.8270)	grad_norm 1.6187 (1.7619)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:50:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:13:46 lr 0.000040	 wd 0.0000	time 0.2753 (0.3592)	loss 0.9673 (0.8342)	grad_norm 1.8623 (1.7642)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:50:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:12:52 lr 0.000040	 wd 0.0000	time 0.2454 (0.3506)	loss 0.8623 (0.8340)	grad_norm 2.1862 (1.7816)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:51:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:11:31 lr 0.000039	 wd 0.0000	time 0.2438 (0.3290)	loss 0.7710 (0.8280)	grad_norm 1.7297 (1.7834)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:51:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:10:32 lr 0.000039	 wd 0.0000	time 0.2186 (0.3160)	loss 0.7661 (0.8296)	grad_norm 1.4047 (1.7711)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:52:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:09:45 lr 0.000039	 wd 0.0000	time 0.2584 (0.3079)	loss 0.8647 (0.8305)	grad_norm 1.5755 (1.7709)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:52:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:09:03 lr 0.000039	 wd 0.0000	time 0.2402 (0.3018)	loss 0.7393 (0.8293)	grad_norm 1.3640 (1.7764)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:53:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:08:27 lr 0.000039	 wd 0.0000	time 0.2691 (0.2979)	loss 0.7368 (0.8294)	grad_norm 1.3588 (1.7810)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:53:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:07:51 lr 0.000038	 wd 0.0000	time 0.2615 (0.2943)	loss 0.7964 (0.8299)	grad_norm 1.7692 (1.7896)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:54:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:07:19 lr 0.000038	 wd 0.0000	time 0.2445 (0.2924)	loss 0.8838 (0.8296)	grad_norm 2.1415 (1.7811)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:54:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:06:46 lr 0.000038	 wd 0.0000	time 0.2661 (0.2901)	loss 0.8906 (0.8310)	grad_norm 1.7837 (1.7721)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:54:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:06:15 lr 0.000038	 wd 0.0000	time 0.2569 (0.2881)	loss 0.8999 (0.8315)	grad_norm 1.7652 (1.7673)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:55:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:05:44 lr 0.000038	 wd 0.0000	time 0.2397 (0.2870)	loss 0.9775 (0.8305)	grad_norm 1.4427 (1.7653)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:55:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:05:15 lr 0.000037	 wd 0.0000	time 0.2739 (0.2862)	loss 0.7798 (0.8311)	grad_norm 1.6016 (1.7692)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:56:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:04:45 lr 0.000037	 wd 0.0000	time 0.2578 (0.2849)	loss 0.8135 (0.8313)	grad_norm 1.5946 (1.7670)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:56:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:04:16 lr 0.000037	 wd 0.0000	time 0.2442 (0.2839)	loss 0.7412 (0.8309)	grad_norm 2.7062 (1.7708)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:57:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:57 lr 0.000037	 wd 0.0000	time 0.2814 (0.2958)	loss 1.0137 (0.8307)	grad_norm 1.6556 (1.7692)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:58:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:03:27 lr 0.000037	 wd 0.0000	time 0.2915 (0.2960)	loss 0.7847 (0.8310)	grad_norm 1.7554 (1.7676)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:58:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:57 lr 0.000036	 wd 0.0000	time 0.3832 (0.2952)	loss 0.7700 (0.8311)	grad_norm 1.7182 (1.7650)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 18:59:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:02:34 lr 0.000036	 wd 0.0000	time 0.3022 (0.3081)	loss 0.8091 (0.8306)	grad_norm 2.3265 (1.7604)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:00:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:02:03 lr 0.000036	 wd 0.0000	time 0.2588 (0.3079)	loss 0.7930 (0.8306)	grad_norm 2.7839 (1.7599)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:00:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:35 lr 0.000036	 wd 0.0000	time 0.2680 (0.3177)	loss 0.8301 (0.8307)	grad_norm 1.4174 (1.7632)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:01:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:01:03 lr 0.000036	 wd 0.0000	time 0.2730 (0.3165)	loss 0.8076 (0.8304)	grad_norm 1.7667 (1.7594)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:01:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:32 lr 0.000035	 wd 0.0000	time 0.4691 (0.3152)	loss 0.7295 (0.8312)	grad_norm 2.3094 (1.7557)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:02:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.2428 (0.3234)	loss 0.9917 (0.8316)	grad_norm 2.0407 (1.7542)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:02:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 17 training takes 0:13:35
[2024-07-26 19:03:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 60.357 (60.357)	Loss 0.3604 (0.3604)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 19:04:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.502 Acc@5 97.606
[2024-07-26 19:04:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-26 19:04:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-26 19:04:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][0/2502]	eta 12:05:15 lr 0.000035	 wd 0.0000	time 17.3921 (17.3921)	loss 0.8853 (0.8853)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:04:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:17:24 lr 0.000035	 wd 0.0000	time 0.2254 (0.4348)	loss 0.8145 (0.8230)	grad_norm 1.6272 (1.8040)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:05:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:13:42 lr 0.000035	 wd 0.0000	time 0.2222 (0.3574)	loss 0.9141 (0.8206)	grad_norm 1.3448 (1.7628)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:05:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:11:59 lr 0.000035	 wd 0.0000	time 0.2622 (0.3266)	loss 0.9028 (0.8254)	grad_norm 1.7281 (1.7208)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:06:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:10:53 lr 0.000034	 wd 0.0000	time 0.2450 (0.3110)	loss 0.8306 (0.8285)	grad_norm 1.6194 (1.7277)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:06:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:10:04 lr 0.000034	 wd 0.0000	time 0.2319 (0.3019)	loss 0.7524 (0.8291)	grad_norm 1.6447 (1.7354)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:07:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:09:23 lr 0.000034	 wd 0.0000	time 0.2367 (0.2962)	loss 0.7397 (0.8284)	grad_norm 2.0377 (1.7285)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:07:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:08:45 lr 0.000034	 wd 0.0000	time 0.2603 (0.2917)	loss 0.9736 (0.8276)	grad_norm 1.7576 (1.7506)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:07:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:08:10 lr 0.000034	 wd 0.0000	time 0.2524 (0.2880)	loss 0.8599 (0.8253)	grad_norm 1.7936 (1.7443)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:08:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:07:37 lr 0.000033	 wd 0.0000	time 0.2737 (0.2857)	loss 0.8789 (0.8253)	grad_norm 2.4173 (1.7361)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:08:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:07:07 lr 0.000033	 wd 0.0000	time 0.2173 (0.2847)	loss 0.7666 (0.8252)	grad_norm 1.8064 (1.7357)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:09:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:06:36 lr 0.000033	 wd 0.0000	time 0.2490 (0.2830)	loss 0.7881 (0.8262)	grad_norm 1.3291 (1.7336)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:09:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:06:06 lr 0.000033	 wd 0.0000	time 0.2811 (0.2817)	loss 1.1074 (0.8260)	grad_norm 1.5019 (1.7254)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:10:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:05:38 lr 0.000033	 wd 0.0000	time 0.2197 (0.2813)	loss 0.7104 (0.8267)	grad_norm 1.5604 (1.7204)	loss_scale 32768.0000 (17467.0315)	mem 9944MB
[2024-07-26 19:10:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:05:08 lr 0.000032	 wd 0.0000	time 0.2363 (0.2804)	loss 0.7822 (0.8256)	grad_norm 1.8603 (1.7241)	loss_scale 32768.0000 (18559.1777)	mem 9944MB
[2024-07-26 19:11:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:04:39 lr 0.000032	 wd 0.0000	time 0.2733 (0.2794)	loss 0.7734 (0.8257)	grad_norm 2.0993 (inf)	loss_scale 16384.0000 (19243.8321)	mem 9944MB
[2024-07-26 19:11:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:04:11 lr 0.000032	 wd 0.0000	time 0.2716 (0.2787)	loss 0.8218 (0.8258)	grad_norm 1.8634 (inf)	loss_scale 16384.0000 (19065.2042)	mem 9944MB
[2024-07-26 19:12:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:52 lr 0.000032	 wd 0.0000	time 0.2767 (0.2905)	loss 0.9639 (0.8258)	grad_norm 1.5398 (inf)	loss_scale 16384.0000 (18907.5791)	mem 9944MB
[2024-07-26 19:12:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:03:26 lr 0.000032	 wd 0.0000	time 0.2422 (0.2939)	loss 0.8955 (0.8260)	grad_norm 1.5317 (inf)	loss_scale 16384.0000 (18767.4581)	mem 9944MB
[2024-07-26 19:14:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:03:12 lr 0.000032	 wd 0.0000	time 0.4457 (0.3194)	loss 0.9819 (0.8260)	grad_norm 1.5266 (inf)	loss_scale 16384.0000 (18642.0789)	mem 9944MB
[2024-07-26 19:15:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:02:43 lr 0.000031	 wd 0.0000	time 0.2459 (0.3263)	loss 0.9707 (0.8269)	grad_norm 1.5134 (inf)	loss_scale 16384.0000 (18529.2314)	mem 9944MB
[2024-07-26 19:15:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:02:10 lr 0.000031	 wd 0.0000	time 0.2156 (0.3235)	loss 0.7388 (0.8268)	grad_norm 1.6955 (inf)	loss_scale 16384.0000 (18427.1261)	mem 9944MB
[2024-07-26 19:15:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:36 lr 0.000031	 wd 0.0000	time 0.2533 (0.3210)	loss 0.7148 (0.8273)	grad_norm 1.5132 (inf)	loss_scale 16384.0000 (18334.2990)	mem 9944MB
[2024-07-26 19:16:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:01:04 lr 0.000031	 wd 0.0000	time 0.2257 (0.3188)	loss 0.7729 (0.8275)	grad_norm 1.6774 (inf)	loss_scale 16384.0000 (18249.5402)	mem 9944MB
[2024-07-26 19:16:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:32 lr 0.000031	 wd 0.0000	time 0.2557 (0.3171)	loss 0.8604 (0.8273)	grad_norm 1.7844 (inf)	loss_scale 16384.0000 (18171.8417)	mem 9944MB
[2024-07-26 19:17:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000030	 wd 0.0000	time 0.2343 (0.3149)	loss 0.8223 (0.8276)	grad_norm 1.6395 (inf)	loss_scale 16384.0000 (18100.3567)	mem 9944MB
[2024-07-26 19:17:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 18 training takes 0:13:15
[2024-07-26 19:17:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 18.170 (18.170)	Loss 0.3621 (0.3621)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 19:17:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.500 Acc@5 97.586
[2024-07-26 19:17:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-26 19:17:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-26 19:18:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][0/2502]	eta 21:24:52 lr 0.000030	 wd 0.0000	time 30.8122 (30.8122)	loss 0.7788 (0.7788)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:18:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:23:11 lr 0.000030	 wd 0.0000	time 0.2471 (0.5792)	loss 0.9854 (0.8350)	grad_norm 1.7814 (1.7590)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:19:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:16:10 lr 0.000030	 wd 0.0000	time 0.2488 (0.4218)	loss 0.7280 (0.8353)	grad_norm 1.7105 (1.7232)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:19:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:13:36 lr 0.000030	 wd 0.0000	time 0.2306 (0.3709)	loss 0.7915 (0.8330)	grad_norm 1.5157 (1.7050)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:20:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:12:03 lr 0.000030	 wd 0.0000	time 0.2298 (0.3442)	loss 0.8916 (0.8310)	grad_norm 1.3338 (1.6945)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:20:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:10:56 lr 0.000029	 wd 0.0000	time 0.2386 (0.3281)	loss 0.8579 (0.8290)	grad_norm 1.5451 (1.6853)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:21:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:10:04 lr 0.000029	 wd 0.0000	time 0.2495 (0.3177)	loss 0.7891 (0.8293)	grad_norm 1.7259 (1.6862)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:21:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:09:23 lr 0.000029	 wd 0.0000	time 0.2190 (0.3127)	loss 0.8501 (0.8296)	grad_norm 1.4621 (1.6813)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:22:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:08:42 lr 0.000029	 wd 0.0000	time 0.2386 (0.3068)	loss 0.7285 (0.8286)	grad_norm 1.7445 (1.6943)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:22:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:08:03 lr 0.000029	 wd 0.0000	time 0.2372 (0.3021)	loss 0.7378 (0.8273)	grad_norm 1.8418 (1.6910)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:22:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:07:28 lr 0.000028	 wd 0.0000	time 0.2567 (0.2986)	loss 0.7153 (0.8271)	grad_norm 2.0141 (1.6951)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:23:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:06:55 lr 0.000028	 wd 0.0000	time 0.2364 (0.2963)	loss 0.9136 (0.8274)	grad_norm 1.8100 (1.6936)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:23:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:06:22 lr 0.000028	 wd 0.0000	time 0.2360 (0.2939)	loss 0.8159 (0.8272)	grad_norm 1.4867 (1.7041)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:24:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:05:50 lr 0.000028	 wd 0.0000	time 0.2586 (0.2919)	loss 0.6851 (0.8277)	grad_norm 2.0835 (1.7069)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:25:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:05:45 lr 0.000028	 wd 0.0000	time 0.3543 (0.3137)	loss 0.7666 (0.8282)	grad_norm 1.5522 (1.7087)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:26:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:05:38 lr 0.000028	 wd 0.0000	time 0.2275 (0.3379)	loss 0.8657 (0.8286)	grad_norm 1.5270 (1.7066)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:26:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:05:00 lr 0.000027	 wd 0.0000	time 0.2539 (0.3336)	loss 0.7632 (0.8286)	grad_norm 1.5484 (1.7084)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:27:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:04:24 lr 0.000027	 wd 0.0000	time 0.2556 (0.3296)	loss 0.7241 (0.8284)	grad_norm 1.7632 (1.7104)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:27:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:03:48 lr 0.000027	 wd 0.0000	time 0.2450 (0.3261)	loss 0.7075 (0.8287)	grad_norm 1.7784 (1.7099)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:28:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:03:15 lr 0.000027	 wd 0.0000	time 0.2329 (0.3244)	loss 0.8345 (0.8282)	grad_norm 1.7945 (1.7146)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:28:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:02:41 lr 0.000027	 wd 0.0000	time 0.2695 (0.3217)	loss 0.8809 (0.8274)	grad_norm 1.8863 (1.7160)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:29:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:02:08 lr 0.000026	 wd 0.0000	time 0.2878 (0.3191)	loss 0.9844 (0.8271)	grad_norm 1.7765 (1.7129)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:29:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:35 lr 0.000026	 wd 0.0000	time 0.2890 (0.3172)	loss 0.8320 (0.8269)	grad_norm 2.0385 (1.7140)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:30:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:01:03 lr 0.000026	 wd 0.0000	time 0.2608 (0.3153)	loss 0.8916 (0.8273)	grad_norm 1.4032 (1.7101)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:30:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:31 lr 0.000026	 wd 0.0000	time 0.2383 (0.3134)	loss 1.0244 (0.8271)	grad_norm 1.8877 (1.7123)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:30:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.2395 (0.3113)	loss 0.7520 (0.8268)	grad_norm 1.4801 (1.7132)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:31:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 19 training takes 0:13:08
[2024-07-26 19:32:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 77.069 (77.069)	Loss 0.3584 (0.3584)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 19:32:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.510 Acc@5 97.608
[2024-07-26 19:32:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-26 19:32:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-26 19:33:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][0/2502]	eta 19:40:01 lr 0.000026	 wd 0.0000	time 28.2981 (28.2981)	loss 0.9463 (0.9463)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:33:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:22:08 lr 0.000026	 wd 0.0000	time 0.2422 (0.5532)	loss 0.8477 (0.8320)	grad_norm 1.7869 (1.7126)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:34:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:15:46 lr 0.000025	 wd 0.0000	time 0.2548 (0.4112)	loss 0.9312 (0.8293)	grad_norm 1.7528 (1.7022)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:34:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:13:23 lr 0.000025	 wd 0.0000	time 0.2514 (0.3648)	loss 0.7627 (0.8284)	grad_norm 1.6088 (1.6865)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:35:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:11:53 lr 0.000025	 wd 0.0000	time 0.2496 (0.3393)	loss 0.7290 (0.8246)	grad_norm 1.4811 (1.6865)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 19:35:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:10:49 lr 0.000025	 wd 0.0000	time 0.2487 (0.3243)	loss 0.8647 (0.8249)	grad_norm 1.4643 (1.6900)	loss_scale 32768.0000 (17299.6727)	mem 9944MB
[2024-07-26 19:35:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:09:58 lr 0.000025	 wd 0.0000	time 0.2665 (0.3148)	loss 0.7822 (0.8244)	grad_norm 1.6358 (1.6928)	loss_scale 32768.0000 (19873.4376)	mem 9944MB
[2024-07-26 19:36:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:09:16 lr 0.000025	 wd 0.0000	time 0.2232 (0.3088)	loss 0.7314 (0.8243)	grad_norm 1.5269 (1.7019)	loss_scale 32768.0000 (21712.8902)	mem 9944MB
[2024-07-26 19:36:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:08:36 lr 0.000024	 wd 0.0000	time 0.2425 (0.3036)	loss 0.8213 (0.8252)	grad_norm 1.8256 (1.7023)	loss_scale 32768.0000 (23093.0537)	mem 9944MB
[2024-07-26 19:37:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:07:59 lr 0.000024	 wd 0.0000	time 0.2184 (0.2993)	loss 0.9604 (0.8249)	grad_norm 2.1550 (1.6961)	loss_scale 32768.0000 (24166.8546)	mem 9944MB
[2024-07-26 19:37:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:07:25 lr 0.000024	 wd 0.0000	time 0.2281 (0.2964)	loss 0.7744 (0.8266)	grad_norm 1.5399 (1.6933)	loss_scale 32768.0000 (25026.1099)	mem 9944MB
[2024-07-26 19:38:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:06:52 lr 0.000024	 wd 0.0000	time 0.2719 (0.2940)	loss 0.7417 (0.8261)	grad_norm 1.7271 (1.6888)	loss_scale 32768.0000 (25729.2788)	mem 9944MB
[2024-07-26 19:38:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:06:19 lr 0.000024	 wd 0.0000	time 0.2377 (0.2916)	loss 0.7095 (0.8257)	grad_norm 1.9468 (1.6907)	loss_scale 32768.0000 (26315.3505)	mem 9944MB
[2024-07-26 19:39:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:05:48 lr 0.000023	 wd 0.0000	time 0.2639 (0.2898)	loss 0.7612 (0.8246)	grad_norm 1.6075 (1.6868)	loss_scale 32768.0000 (26811.3267)	mem 9944MB
[2024-07-26 19:39:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:05:18 lr 0.000023	 wd 0.0000	time 0.2551 (0.2889)	loss 0.8491 (0.8247)	grad_norm 1.9302 (1.6841)	loss_scale 32768.0000 (27236.4996)	mem 9944MB
[2024-07-26 19:40:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:04:48 lr 0.000023	 wd 0.0000	time 0.2244 (0.2876)	loss 0.8882 (0.8243)	grad_norm 1.5295 (1.6787)	loss_scale 32768.0000 (27605.0207)	mem 9944MB
[2024-07-26 19:40:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:04:18 lr 0.000023	 wd 0.0000	time 0.2670 (0.2861)	loss 0.8672 (0.8233)	grad_norm 1.4981 (1.6789)	loss_scale 32768.0000 (27927.5053)	mem 9944MB
[2024-07-26 19:40:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:48 lr 0.000023	 wd 0.0000	time 0.2589 (0.2851)	loss 1.0518 (0.8233)	grad_norm 1.3829 (1.6789)	loss_scale 32768.0000 (28212.0729)	mem 9944MB
[2024-07-26 19:41:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:03:28 lr 0.000023	 wd 0.0000	time 0.2938 (0.2964)	loss 0.8271 (0.8233)	grad_norm 2.0575 (1.6800)	loss_scale 32768.0000 (28465.0394)	mem 9944MB
[2024-07-26 19:42:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:58 lr 0.000022	 wd 0.0000	time 0.2398 (0.2970)	loss 0.8276 (0.8233)	grad_norm 1.5178 (1.6808)	loss_scale 32768.0000 (28691.3919)	mem 9944MB
[2024-07-26 19:43:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:02:46 lr 0.000022	 wd 0.0000	time 0.2504 (0.3308)	loss 0.8862 (0.8231)	grad_norm 2.4208 (1.6843)	loss_scale 32768.0000 (28895.1204)	mem 9944MB
[2024-07-26 19:44:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:02:13 lr 0.000022	 wd 0.0000	time 0.2469 (0.3326)	loss 0.8569 (0.8234)	grad_norm 1.6319 (1.6855)	loss_scale 32768.0000 (29079.4555)	mem 9944MB
[2024-07-26 19:44:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:39 lr 0.000022	 wd 0.0000	time 0.2362 (0.3296)	loss 0.8491 (0.8230)	grad_norm 1.6338 (1.6847)	loss_scale 32768.0000 (29247.0404)	mem 9944MB
[2024-07-26 19:45:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:01:06 lr 0.000022	 wd 0.0000	time 0.2523 (0.3268)	loss 0.7949 (0.8234)	grad_norm 1.3567 (1.6877)	loss_scale 32768.0000 (29400.0591)	mem 9944MB
[2024-07-26 19:45:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:33 lr 0.000022	 wd 0.0000	time 0.2374 (0.3246)	loss 0.7974 (0.8239)	grad_norm 1.8333 (1.6886)	loss_scale 32768.0000 (29540.3315)	mem 9944MB
[2024-07-26 19:46:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.2481 (0.3223)	loss 0.7954 (0.8237)	grad_norm 1.2625 (1.6900)	loss_scale 32768.0000 (29669.3866)	mem 9944MB
[2024-07-26 19:46:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 20 training takes 0:13:36
[2024-07-26 19:46:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 20.083 (20.083)	Loss 0.3621 (0.3621)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 19:47:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.540 Acc@5 97.634
[2024-07-26 19:47:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-26 19:47:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.54%
[2024-07-26 19:47:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saving......
[2024-07-26 19:47:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-26 19:47:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][0/2502]	eta 20:10:38 lr 0.000021	 wd 0.0000	time 29.0323 (29.0323)	loss 0.8657 (0.8657)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:48:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:22:01 lr 0.000021	 wd 0.0000	time 0.2208 (0.5501)	loss 0.8052 (0.8256)	grad_norm 1.6672 (1.6650)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:48:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:15:39 lr 0.000021	 wd 0.0000	time 0.2660 (0.4080)	loss 0.8188 (0.8292)	grad_norm 1.7489 (1.6746)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:48:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:13:16 lr 0.000021	 wd 0.0000	time 0.2265 (0.3618)	loss 0.7891 (0.8215)	grad_norm 1.3362 (1.6992)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:49:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:11:52 lr 0.000021	 wd 0.0000	time 0.2589 (0.3388)	loss 0.7231 (0.8203)	grad_norm 1.7037 (1.6873)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:49:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:10:48 lr 0.000021	 wd 0.0000	time 0.2415 (0.3238)	loss 0.9404 (0.8219)	grad_norm 1.8749 (1.6862)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:50:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:09:56 lr 0.000020	 wd 0.0000	time 0.2555 (0.3136)	loss 0.8828 (0.8220)	grad_norm 1.5653 (1.6847)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:50:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:09:14 lr 0.000020	 wd 0.0000	time 0.3119 (0.3078)	loss 0.8037 (0.8222)	grad_norm 1.7414 (1.6918)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:51:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:08:35 lr 0.000020	 wd 0.0000	time 0.2528 (0.3031)	loss 0.8320 (0.8218)	grad_norm 1.5411 (1.6788)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:51:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:07:58 lr 0.000020	 wd 0.0000	time 0.2572 (0.2989)	loss 0.8057 (0.8216)	grad_norm 1.7058 (1.6851)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:52:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:07:24 lr 0.000020	 wd 0.0000	time 0.2407 (0.2956)	loss 0.7627 (0.8205)	grad_norm 2.0072 (1.6829)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:52:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:06:51 lr 0.000020	 wd 0.0000	time 0.2703 (0.2937)	loss 0.7871 (0.8212)	grad_norm 1.4748 (1.6767)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:52:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:06:19 lr 0.000019	 wd 0.0000	time 0.2403 (0.2914)	loss 0.8818 (0.8211)	grad_norm 1.9375 (1.6751)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:53:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:05:47 lr 0.000019	 wd 0.0000	time 0.2652 (0.2893)	loss 0.9106 (0.8208)	grad_norm 1.3720 (1.6757)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:53:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:05:17 lr 0.000019	 wd 0.0000	time 0.2485 (0.2877)	loss 0.7524 (0.8209)	grad_norm 2.1122 (1.6767)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:55:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:05:24 lr 0.000019	 wd 0.0000	time 0.2504 (0.3242)	loss 0.8149 (0.8208)	grad_norm 1.7277 (1.6787)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:55:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:04:54 lr 0.000019	 wd 0.0000	time 0.2352 (0.3266)	loss 0.8105 (0.8201)	grad_norm 1.6449 (1.6806)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:56:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:04:19 lr 0.000019	 wd 0.0000	time 0.2295 (0.3230)	loss 0.7969 (0.8197)	grad_norm 1.6211 (1.6808)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:56:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:03:44 lr 0.000018	 wd 0.0000	time 0.2414 (0.3198)	loss 0.8110 (0.8191)	grad_norm 1.8942 (1.6839)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:57:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:03:11 lr 0.000018	 wd 0.0000	time 0.2433 (0.3173)	loss 0.7197 (0.8188)	grad_norm 2.1623 (1.6873)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 19:57:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:02:38 lr 0.000018	 wd 0.0000	time 0.2280 (0.3159)	loss 0.7915 (0.8191)	grad_norm 1.7035 (nan)	loss_scale 32768.0000 (32800.7516)	mem 9944MB
[2024-07-26 19:58:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:02:06 lr 0.000018	 wd 0.0000	time 0.2704 (0.3136)	loss 0.8296 (0.8192)	grad_norm 2.0255 (nan)	loss_scale 32768.0000 (32799.1928)	mem 9944MB
[2024-07-26 19:58:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:34 lr 0.000018	 wd 0.0000	time 0.2180 (0.3115)	loss 0.6724 (0.8192)	grad_norm 1.4460 (nan)	loss_scale 32768.0000 (32797.7756)	mem 9944MB
[2024-07-26 19:58:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:01:02 lr 0.000018	 wd 0.0000	time 0.2356 (0.3099)	loss 0.8950 (0.8200)	grad_norm 1.8759 (nan)	loss_scale 32768.0000 (32796.4815)	mem 9944MB
[2024-07-26 19:59:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:31 lr 0.000018	 wd 0.0000	time 0.2508 (0.3082)	loss 0.8115 (0.8201)	grad_norm 1.4634 (nan)	loss_scale 32768.0000 (32795.2953)	mem 9944MB
[2024-07-26 19:59:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000017	 wd 0.0000	time 0.2349 (0.3063)	loss 0.8433 (0.8204)	grad_norm 1.1512 (nan)	loss_scale 32768.0000 (32794.2039)	mem 9944MB
[2024-07-26 19:59:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 21 training takes 0:12:53
[2024-07-26 20:00:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 34.203 (34.203)	Loss 0.3579 (0.3579)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 20:00:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.504 Acc@5 97.612
[2024-07-26 20:00:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-26 20:00:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.54%
[2024-07-26 20:01:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][0/2502]	eta 11:22:14 lr 0.000017	 wd 0.0000	time 16.3606 (16.3606)	loss 0.8560 (0.8560)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:01:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:17:02 lr 0.000017	 wd 0.0000	time 0.2262 (0.4255)	loss 0.9258 (0.8326)	grad_norm 1.3541 (1.6924)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:02:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:13:20 lr 0.000017	 wd 0.0000	time 0.2416 (0.3479)	loss 0.7080 (0.8297)	grad_norm 1.4139 (1.6593)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:02:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:11:45 lr 0.000017	 wd 0.0000	time 0.2431 (0.3205)	loss 0.9019 (0.8254)	grad_norm 2.2536 (1.6964)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:02:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:10:44 lr 0.000017	 wd 0.0000	time 0.2329 (0.3067)	loss 0.8726 (0.8267)	grad_norm 1.5053 (1.6811)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:03:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:09:56 lr 0.000017	 wd 0.0000	time 0.2489 (0.2981)	loss 0.9111 (0.8283)	grad_norm 2.0291 (1.6865)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:03:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:09:17 lr 0.000016	 wd 0.0000	time 0.2611 (0.2931)	loss 0.9839 (0.8286)	grad_norm 1.3416 (1.6804)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:04:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:08:41 lr 0.000016	 wd 0.0000	time 0.2753 (0.2896)	loss 0.8110 (0.8289)	grad_norm 1.3484 (1.6764)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:04:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:08:07 lr 0.000016	 wd 0.0000	time 0.2487 (0.2864)	loss 0.7534 (0.8294)	grad_norm 1.6460 (1.6741)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:05:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:07:36 lr 0.000016	 wd 0.0000	time 0.2603 (0.2848)	loss 0.8037 (0.8282)	grad_norm 1.3230 (1.6742)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:05:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:07:06 lr 0.000016	 wd 0.0000	time 0.2157 (0.2838)	loss 0.7368 (0.8290)	grad_norm 1.8114 (1.6755)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:06:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:06:35 lr 0.000016	 wd 0.0000	time 0.2273 (0.2821)	loss 0.7539 (0.8291)	grad_norm 1.6286 (1.6789)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:06:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:06:05 lr 0.000016	 wd 0.0000	time 0.2288 (0.2808)	loss 0.8325 (0.8292)	grad_norm 1.5343 (1.6758)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:06:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:05:36 lr 0.000015	 wd 0.0000	time 0.2571 (0.2798)	loss 0.7983 (0.8289)	grad_norm 1.5720 (1.6663)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:07:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:05:08 lr 0.000015	 wd 0.0000	time 0.2317 (0.2797)	loss 0.8315 (0.8288)	grad_norm 1.8336 (1.6635)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:07:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:04:39 lr 0.000015	 wd 0.0000	time 0.2489 (0.2788)	loss 0.6255 (0.8289)	grad_norm 1.5851 (1.6598)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:08:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:04:10 lr 0.000015	 wd 0.0000	time 0.2566 (0.2780)	loss 0.9321 (0.8288)	grad_norm 1.6047 (1.6567)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:09:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:56 lr 0.000015	 wd 0.0000	time 0.2521 (0.2951)	loss 0.6968 (0.8278)	grad_norm 1.5835 (1.6571)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:09:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:03:27 lr 0.000015	 wd 0.0000	time 0.2784 (0.2951)	loss 0.9946 (0.8269)	grad_norm 1.7420 (1.6559)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:10:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:03:06 lr 0.000015	 wd 0.0000	time 0.4229 (0.3103)	loss 0.8999 (0.8273)	grad_norm 1.5023 (1.6596)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:11:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:02:39 lr 0.000014	 wd 0.0000	time 0.2629 (0.3179)	loss 0.8267 (0.8272)	grad_norm 1.5144 (1.6584)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:12:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:02:08 lr 0.000014	 wd 0.0000	time 0.2401 (0.3187)	loss 0.7798 (0.8272)	grad_norm 1.8368 (1.6624)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:12:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:35 lr 0.000014	 wd 0.0000	time 0.2329 (0.3164)	loss 0.6777 (0.8265)	grad_norm 1.5018 (1.6614)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:12:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:01:03 lr 0.000014	 wd 0.0000	time 0.2479 (0.3143)	loss 0.8208 (0.8262)	grad_norm 1.7668 (1.6625)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:13:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:31 lr 0.000014	 wd 0.0000	time 0.2568 (0.3125)	loss 0.7949 (0.8266)	grad_norm 1.5462 (1.6622)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:13:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.2547 (0.3111)	loss 0.7881 (0.8265)	grad_norm 1.5866 (1.6592)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:14:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 22 training takes 0:13:10
[2024-07-26 20:14:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 20.697 (20.697)	Loss 0.3567 (0.3567)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 20:14:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.506 Acc@5 97.622
[2024-07-26 20:14:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-26 20:14:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.54%
[2024-07-26 20:15:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][0/2502]	eta 20:48:46 lr 0.000014	 wd 0.0000	time 29.9465 (29.9465)	loss 0.8521 (0.8521)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:15:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:22:34 lr 0.000014	 wd 0.0000	time 0.2790 (0.5641)	loss 0.8862 (0.8198)	grad_norm 1.5107 (1.6691)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:16:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:15:55 lr 0.000013	 wd 0.0000	time 0.2374 (0.4149)	loss 0.7515 (0.8171)	grad_norm 1.7674 (1.6082)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:16:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:13:25 lr 0.000013	 wd 0.0000	time 0.2294 (0.3659)	loss 0.7710 (0.8179)	grad_norm 1.7823 (1.6341)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:16:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:11:56 lr 0.000013	 wd 0.0000	time 0.2186 (0.3411)	loss 0.9414 (0.8212)	grad_norm 1.6871 (1.6357)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:17:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:10:52 lr 0.000013	 wd 0.0000	time 0.2348 (0.3258)	loss 0.9336 (0.8241)	grad_norm 1.7338 (1.6469)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:17:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:09:59 lr 0.000013	 wd 0.0000	time 0.2498 (0.3154)	loss 0.9370 (0.8243)	grad_norm 1.9898 (1.6540)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:18:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:09:15 lr 0.000013	 wd 0.0000	time 0.2421 (0.3084)	loss 0.8770 (0.8253)	grad_norm 1.4324 (1.6616)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:18:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:08:37 lr 0.000013	 wd 0.0000	time 0.2357 (0.3038)	loss 0.7852 (0.8236)	grad_norm 1.5866 (1.6572)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:19:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:07:59 lr 0.000012	 wd 0.0000	time 0.2462 (0.2996)	loss 1.0479 (0.8229)	grad_norm 1.5997 (1.6585)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:19:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:07:24 lr 0.000012	 wd 0.0000	time 0.2424 (0.2961)	loss 0.7144 (0.8239)	grad_norm 1.9182 (nan)	loss_scale 32768.0000 (32833.4705)	mem 9944MB
[2024-07-26 20:20:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:06:53 lr 0.000012	 wd 0.0000	time 0.2440 (0.2952)	loss 0.7974 (0.8226)	grad_norm 1.8761 (nan)	loss_scale 32768.0000 (32827.5241)	mem 9944MB
[2024-07-26 20:20:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:06:21 lr 0.000012	 wd 0.0000	time 0.2648 (0.2930)	loss 0.7891 (0.8229)	grad_norm 2.1307 (nan)	loss_scale 32768.0000 (32822.5679)	mem 9944MB
[2024-07-26 20:21:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:05:49 lr 0.000012	 wd 0.0000	time 0.2341 (0.2910)	loss 0.8652 (0.8217)	grad_norm 1.5731 (nan)	loss_scale 32768.0000 (32818.3736)	mem 9944MB
[2024-07-26 20:21:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:05:18 lr 0.000012	 wd 0.0000	time 0.2667 (0.2893)	loss 0.8623 (0.8213)	grad_norm 2.0753 (nan)	loss_scale 16384.0000 (32276.8308)	mem 9944MB
[2024-07-26 20:22:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:05:01 lr 0.000012	 wd 0.0000	time 0.2414 (0.3011)	loss 0.9062 (0.8207)	grad_norm 2.0788 (nan)	loss_scale 16384.0000 (31218.0147)	mem 9944MB
[2024-07-26 20:22:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:04:37 lr 0.000012	 wd 0.0000	time 0.2385 (0.3078)	loss 0.7915 (0.8208)	grad_norm 2.2362 (nan)	loss_scale 16384.0000 (30291.4678)	mem 9944MB
[2024-07-26 20:24:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:04:33 lr 0.000011	 wd 0.0000	time 8.2779 (0.3407)	loss 0.6987 (0.8212)	grad_norm 1.5160 (nan)	loss_scale 16384.0000 (29473.8624)	mem 9944MB
[2024-07-26 20:24:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:03:59 lr 0.000011	 wd 0.0000	time 0.2510 (0.3413)	loss 0.8716 (0.8214)	grad_norm 1.5102 (nan)	loss_scale 16384.0000 (28747.0516)	mem 9944MB
[2024-07-26 20:25:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:03:23 lr 0.000011	 wd 0.0000	time 0.2385 (0.3374)	loss 0.7544 (0.8213)	grad_norm 1.4594 (nan)	loss_scale 16384.0000 (28096.7070)	mem 9944MB
[2024-07-26 20:25:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:02:47 lr 0.000011	 wd 0.0000	time 0.2473 (0.3340)	loss 0.9023 (0.8206)	grad_norm 1.8632 (nan)	loss_scale 16384.0000 (27511.3643)	mem 9944MB
[2024-07-26 20:26:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:02:13 lr 0.000011	 wd 0.0000	time 0.2343 (0.3309)	loss 0.8394 (0.8210)	grad_norm 2.2400 (nan)	loss_scale 16384.0000 (26981.7420)	mem 9944MB
[2024-07-26 20:26:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:39 lr 0.000011	 wd 0.0000	time 0.2533 (0.3290)	loss 0.8608 (0.8208)	grad_norm 1.5152 (nan)	loss_scale 16384.0000 (26500.2453)	mem 9944MB
[2024-07-26 20:27:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:01:05 lr 0.000011	 wd 0.0000	time 0.2445 (0.3263)	loss 0.8857 (0.8210)	grad_norm 1.7336 (nan)	loss_scale 16384.0000 (26060.5997)	mem 9944MB
[2024-07-26 20:27:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:33 lr 0.000011	 wd 0.0000	time 0.2238 (0.3237)	loss 0.8408 (0.8209)	grad_norm 1.6369 (nan)	loss_scale 16384.0000 (25657.5760)	mem 9944MB
[2024-07-26 20:28:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.2399 (0.3213)	loss 0.8481 (0.8207)	grad_norm 1.4577 (nan)	loss_scale 16384.0000 (25286.7813)	mem 9944MB
[2024-07-26 20:28:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 23 training takes 0:13:39
[2024-07-26 20:28:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 28.349 (28.349)	Loss 0.3591 (0.3591)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 20:29:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.602 Acc@5 97.600
[2024-07-26 20:29:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.6%
[2024-07-26 20:29:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.60%
[2024-07-26 20:29:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saving......
[2024-07-26 20:29:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-26 20:29:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][0/2502]	eta 13:41:37 lr 0.000010	 wd 0.0000	time 19.7031 (19.7031)	loss 0.7646 (0.7646)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:29:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:18:30 lr 0.000010	 wd 0.0000	time 0.2604 (0.4623)	loss 0.8779 (0.8112)	grad_norm 1.6701 (1.6839)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:30:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:13:57 lr 0.000010	 wd 0.0000	time 0.2438 (0.3637)	loss 0.8604 (0.8183)	grad_norm 1.3345 (1.6698)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:30:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:12:08 lr 0.000010	 wd 0.0000	time 0.2477 (0.3310)	loss 0.7969 (0.8170)	grad_norm 1.7001 (1.6567)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:31:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:11:03 lr 0.000010	 wd 0.0000	time 0.2171 (0.3157)	loss 0.8516 (0.8169)	grad_norm 1.5734 (1.6558)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:31:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:10:11 lr 0.000010	 wd 0.0000	time 0.2359 (0.3054)	loss 0.8008 (0.8181)	grad_norm 2.8545 (1.6618)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:32:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:09:28 lr 0.000010	 wd 0.0000	time 0.2593 (0.2987)	loss 0.7725 (0.8176)	grad_norm 1.3294 (1.6429)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:32:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:08:49 lr 0.000010	 wd 0.0000	time 0.2673 (0.2938)	loss 0.7612 (0.8180)	grad_norm 1.6525 (1.6376)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:33:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:08:15 lr 0.000010	 wd 0.0000	time 0.3136 (0.2910)	loss 0.7402 (0.8192)	grad_norm 1.4799 (1.6399)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:33:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:07:41 lr 0.000009	 wd 0.0000	time 0.2250 (0.2882)	loss 0.8584 (0.8198)	grad_norm 1.5805 (1.6378)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:33:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:07:09 lr 0.000009	 wd 0.0000	time 0.2553 (0.2861)	loss 0.8638 (0.8211)	grad_norm 1.6153 (1.6391)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:34:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:06:38 lr 0.000009	 wd 0.0000	time 0.2483 (0.2843)	loss 0.7485 (0.8196)	grad_norm 1.7758 (1.6341)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:34:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:06:09 lr 0.000009	 wd 0.0000	time 0.2548 (0.2837)	loss 0.7246 (0.8191)	grad_norm 1.7391 (1.6330)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:35:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:05:39 lr 0.000009	 wd 0.0000	time 0.2546 (0.2824)	loss 0.8843 (0.8201)	grad_norm 1.5596 (1.6397)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:35:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:05:09 lr 0.000009	 wd 0.0000	time 0.2432 (0.2812)	loss 0.8789 (0.8204)	grad_norm 1.6748 (1.6344)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:36:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:40 lr 0.000009	 wd 0.0000	time 0.2620 (0.2804)	loss 0.7148 (0.8207)	grad_norm 1.6594 (1.6283)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:37:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:04:38 lr 0.000009	 wd 0.0000	time 0.4747 (0.3084)	loss 0.7930 (0.8206)	grad_norm 1.6705 (1.6280)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:38:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:04:17 lr 0.000008	 wd 0.0000	time 0.2522 (0.3216)	loss 0.8477 (0.8211)	grad_norm 1.5435 (1.6294)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:38:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:03:43 lr 0.000008	 wd 0.0000	time 0.2439 (0.3186)	loss 0.7583 (0.8207)	grad_norm 1.6575 (1.6294)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:39:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:03:10 lr 0.000008	 wd 0.0000	time 0.2365 (0.3159)	loss 0.6245 (0.8211)	grad_norm 1.5574 (1.6349)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:39:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:02:37 lr 0.000008	 wd 0.0000	time 0.2482 (0.3141)	loss 0.8428 (0.8207)	grad_norm 1.7967 (1.6360)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:40:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:02:05 lr 0.000008	 wd 0.0000	time 0.2814 (0.3119)	loss 0.8179 (0.8202)	grad_norm 1.5917 (1.6338)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:40:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:33 lr 0.000008	 wd 0.0000	time 0.2470 (0.3099)	loss 0.8740 (0.8199)	grad_norm 1.8306 (1.6332)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:40:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:01:02 lr 0.000008	 wd 0.0000	time 0.2221 (0.3081)	loss 0.9204 (0.8201)	grad_norm 1.7692 (1.6317)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:41:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:31 lr 0.000008	 wd 0.0000	time 0.2397 (0.3072)	loss 0.9463 (0.8203)	grad_norm 1.3216 (1.6267)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:41:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.2426 (0.3054)	loss 0.9233 (0.8204)	grad_norm 1.8203 (1.6276)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:42:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 24 training takes 0:12:52
[2024-07-26 20:42:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 21.649 (21.649)	Loss 0.3584 (0.3584)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 20:42:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.598 Acc@5 97.592
[2024-07-26 20:42:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.6%
[2024-07-26 20:42:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.60%
[2024-07-26 20:43:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][0/2502]	eta 16:49:33 lr 0.000008	 wd 0.0000	time 24.2100 (24.2100)	loss 0.7827 (0.7827)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:43:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:20:07 lr 0.000008	 wd 0.0000	time 0.2673 (0.5028)	loss 0.8491 (0.8158)	grad_norm 1.7804 (1.6665)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:43:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:14:44 lr 0.000007	 wd 0.0000	time 0.2376 (0.3843)	loss 0.7554 (0.8174)	grad_norm 1.4116 (1.6573)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:44:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:12:44 lr 0.000007	 wd 0.0000	time 0.2436 (0.3472)	loss 0.8438 (0.8188)	grad_norm 1.6713 (1.6368)	loss_scale 16384.0000 (16384.0000)	mem 9944MB
[2024-07-26 20:44:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:11:25 lr 0.000007	 wd 0.0000	time 0.2342 (0.3263)	loss 0.8589 (0.8179)	grad_norm 1.4798 (1.6349)	loss_scale 32768.0000 (18426.8928)	mem 9944MB
[2024-07-26 20:45:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:10:28 lr 0.000007	 wd 0.0000	time 0.2404 (0.3137)	loss 0.7778 (0.8184)	grad_norm 1.5121 (1.6259)	loss_scale 32768.0000 (21289.3892)	mem 9944MB
[2024-07-26 20:45:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:09:41 lr 0.000007	 wd 0.0000	time 0.2272 (0.3057)	loss 0.8301 (0.8191)	grad_norm 1.5005 (1.6254)	loss_scale 32768.0000 (23199.3078)	mem 9944MB
[2024-07-26 20:46:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:09:02 lr 0.000007	 wd 0.0000	time 0.2378 (0.3011)	loss 0.8457 (0.8181)	grad_norm 1.5038 (1.6181)	loss_scale 32768.0000 (24564.3138)	mem 9944MB
[2024-07-26 20:46:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:08:25 lr 0.000007	 wd 0.0000	time 0.2204 (0.2967)	loss 0.8765 (0.8180)	grad_norm 1.7251 (1.6222)	loss_scale 32768.0000 (25588.4944)	mem 9944MB
[2024-07-26 20:47:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:07:49 lr 0.000007	 wd 0.0000	time 0.2561 (0.2932)	loss 0.7896 (0.8177)	grad_norm 1.5522 (1.6221)	loss_scale 32768.0000 (26385.3319)	mem 9944MB
[2024-07-26 20:47:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:07:16 lr 0.000007	 wd 0.0000	time 0.2470 (0.2907)	loss 0.9277 (0.8177)	grad_norm 1.3179 (1.6273)	loss_scale 32768.0000 (27022.9610)	mem 9944MB
[2024-07-26 20:48:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:06:47 lr 0.000007	 wd 0.0000	time 0.2564 (0.2907)	loss 0.7666 (0.8173)	grad_norm 1.4788 (1.6280)	loss_scale 32768.0000 (27544.7629)	mem 9944MB
[2024-07-26 20:48:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:06:15 lr 0.000006	 wd 0.0000	time 0.2561 (0.2887)	loss 1.0059 (0.8186)	grad_norm 1.3120 (1.6211)	loss_scale 32768.0000 (27979.6703)	mem 9944MB
[2024-07-26 20:48:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:05:44 lr 0.000006	 wd 0.0000	time 0.2361 (0.2868)	loss 0.8022 (0.8189)	grad_norm 1.3432 (1.6195)	loss_scale 32768.0000 (28347.7202)	mem 9944MB
[2024-07-26 20:49:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:05:15 lr 0.000006	 wd 0.0000	time 0.2505 (0.2863)	loss 0.8232 (0.8185)	grad_norm 1.4659 (1.6161)	loss_scale 32768.0000 (28663.2291)	mem 9944MB
[2024-07-26 20:49:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:04:45 lr 0.000006	 wd 0.0000	time 0.2518 (0.2850)	loss 0.8486 (0.8188)	grad_norm 1.5156 (1.6143)	loss_scale 32768.0000 (28936.6982)	mem 9944MB
[2024-07-26 20:50:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:04:15 lr 0.000006	 wd 0.0000	time 0.2342 (0.2838)	loss 0.8237 (0.8181)	grad_norm 1.5277 (1.6146)	loss_scale 32768.0000 (29176.0050)	mem 9944MB
[2024-07-26 20:50:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:46 lr 0.000006	 wd 0.0000	time 0.2465 (0.2828)	loss 0.7959 (0.8176)	grad_norm 1.7703 (1.6162)	loss_scale 32768.0000 (29387.1746)	mem 9944MB
[2024-07-26 20:51:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:03:28 lr 0.000006	 wd 0.0000	time 0.2797 (0.2966)	loss 1.0039 (0.8184)	grad_norm 1.5495 (1.6127)	loss_scale 32768.0000 (29574.8939)	mem 9944MB
[2024-07-26 20:52:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:03:00 lr 0.000006	 wd 0.0000	time 0.2405 (0.2992)	loss 1.1162 (0.8187)	grad_norm 1.2783 (1.6144)	loss_scale 32768.0000 (29742.8638)	mem 9944MB
[2024-07-26 20:53:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:02:46 lr 0.000006	 wd 0.0000	time 0.2633 (0.3311)	loss 0.8677 (0.8185)	grad_norm 1.5412 (1.6144)	loss_scale 32768.0000 (29894.0450)	mem 9944MB
[2024-07-26 20:54:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:02:13 lr 0.000006	 wd 0.0000	time 0.2302 (0.3320)	loss 0.8516 (0.8185)	grad_norm 1.4537 (1.6157)	loss_scale 32768.0000 (30030.8348)	mem 9944MB
[2024-07-26 20:54:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:39 lr 0.000006	 wd 0.0000	time 0.2459 (0.3290)	loss 0.7212 (0.8178)	grad_norm 1.8660 (1.6142)	loss_scale 32768.0000 (30155.1949)	mem 9944MB
[2024-07-26 20:55:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:01:05 lr 0.000005	 wd 0.0000	time 0.2522 (0.3263)	loss 0.7988 (0.8176)	grad_norm 1.4198 (1.6159)	loss_scale 32768.0000 (30268.7458)	mem 9944MB
[2024-07-26 20:55:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:33 lr 0.000005	 wd 0.0000	time 0.2310 (0.3240)	loss 0.7993 (0.8175)	grad_norm 1.4727 (1.6165)	loss_scale 32768.0000 (30372.8380)	mem 9944MB
[2024-07-26 20:56:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000005	 wd 0.0000	time 0.2354 (0.3219)	loss 0.7563 (0.8172)	grad_norm 1.7684 (1.6171)	loss_scale 32768.0000 (30468.6062)	mem 9944MB
[2024-07-26 20:56:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 25 training takes 0:13:36
[2024-07-26 20:56:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 24.240 (24.240)	Loss 0.3569 (0.3569)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 20:57:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.616 Acc@5 97.642
[2024-07-26 20:57:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.6%
[2024-07-26 20:57:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.62%
[2024-07-26 20:57:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saving......
[2024-07-26 20:57:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-26 20:57:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][0/2502]	eta 19:37:03 lr 0.000005	 wd 0.0000	time 28.2267 (28.2267)	loss 0.8022 (0.8022)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:57:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:22:01 lr 0.000005	 wd 0.0000	time 0.2584 (0.5500)	loss 0.9409 (0.8200)	grad_norm 1.3148 (1.6063)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:58:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:15:38 lr 0.000005	 wd 0.0000	time 0.2320 (0.4075)	loss 0.8330 (0.8200)	grad_norm 1.6990 (1.5985)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:58:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:13:14 lr 0.000005	 wd 0.0000	time 0.2347 (0.3607)	loss 0.7607 (0.8204)	grad_norm 1.7396 (1.5870)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:59:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:11:53 lr 0.000005	 wd 0.0000	time 0.2233 (0.3396)	loss 0.8726 (0.8190)	grad_norm 1.4467 (1.5879)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 20:59:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:10:49 lr 0.000005	 wd 0.0000	time 0.2489 (0.3243)	loss 0.9077 (0.8201)	grad_norm 1.4824 (1.5955)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:00:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:09:57 lr 0.000005	 wd 0.0000	time 0.2563 (0.3143)	loss 0.8047 (0.8201)	grad_norm 1.5575 (1.5934)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:00:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:09:15 lr 0.000005	 wd 0.0000	time 0.2456 (0.3085)	loss 1.0049 (0.8192)	grad_norm 1.4121 (1.5910)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:01:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:08:36 lr 0.000005	 wd 0.0000	time 0.2249 (0.3036)	loss 0.7900 (0.8190)	grad_norm 1.5908 (1.5926)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:01:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:07:59 lr 0.000005	 wd 0.0000	time 0.2479 (0.2994)	loss 0.8364 (0.8183)	grad_norm 1.5385 (1.5900)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:01:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:07:24 lr 0.000004	 wd 0.0000	time 0.2302 (0.2961)	loss 0.9521 (0.8183)	grad_norm 1.3510 (1.5912)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:02:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:06:52 lr 0.000004	 wd 0.0000	time 0.2362 (0.2943)	loss 0.8447 (0.8179)	grad_norm 1.4204 (1.5873)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:02:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:06:20 lr 0.000004	 wd 0.0000	time 0.2471 (0.2920)	loss 0.7402 (0.8185)	grad_norm 1.5334 (1.5834)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:03:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:05:48 lr 0.000004	 wd 0.0000	time 0.2698 (0.2900)	loss 0.7480 (0.8185)	grad_norm 1.7379 (1.5821)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:03:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:05:17 lr 0.000004	 wd 0.0000	time 0.2515 (0.2885)	loss 0.8945 (0.8188)	grad_norm 1.8079 (1.5829)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:04:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:04:48 lr 0.000004	 wd 0.0000	time 0.2523 (0.2884)	loss 0.7490 (0.8188)	grad_norm 1.5241 (1.5791)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:04:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:04:18 lr 0.000004	 wd 0.0000	time 0.2398 (0.2870)	loss 0.7432 (0.8178)	grad_norm 1.5776 (1.5826)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:05:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:49 lr 0.000004	 wd 0.0000	time 0.2184 (0.2859)	loss 0.7476 (0.8171)	grad_norm 1.7032 (1.5814)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:05:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:03:27 lr 0.000004	 wd 0.0000	time 0.2680 (0.2949)	loss 0.8345 (0.8171)	grad_norm 1.5809 (1.5810)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:06:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:58 lr 0.000004	 wd 0.0000	time 0.2273 (0.2967)	loss 0.7261 (0.8172)	grad_norm 1.7163 (nan)	loss_scale 32768.0000 (32802.4745)	mem 9944MB
[2024-07-26 21:06:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:02:28 lr 0.000004	 wd 0.0000	time 0.2361 (0.2961)	loss 0.8574 (0.8172)	grad_norm 1.2946 (nan)	loss_scale 32768.0000 (32800.7516)	mem 9944MB
[2024-07-26 21:08:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:02:12 lr 0.000004	 wd 0.0000	time 0.2484 (0.3286)	loss 0.8447 (0.8173)	grad_norm 1.4407 (nan)	loss_scale 32768.0000 (32799.1928)	mem 9944MB
[2024-07-26 21:09:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:39 lr 0.000004	 wd 0.0000	time 0.2515 (0.3293)	loss 0.8262 (0.8173)	grad_norm 1.5033 (nan)	loss_scale 32768.0000 (32797.7756)	mem 9944MB
[2024-07-26 21:09:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:01:05 lr 0.000004	 wd 0.0000	time 0.2504 (0.3266)	loss 0.7563 (0.8176)	grad_norm 1.6927 (nan)	loss_scale 32768.0000 (32796.4815)	mem 9944MB
[2024-07-26 21:10:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:33 lr 0.000003	 wd 0.0000	time 0.2553 (0.3242)	loss 0.8535 (0.8178)	grad_norm 2.0688 (nan)	loss_scale 32768.0000 (32795.2953)	mem 9944MB
[2024-07-26 21:10:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.2460 (0.3217)	loss 0.7358 (0.8185)	grad_norm 1.8990 (nan)	loss_scale 32768.0000 (32794.2039)	mem 9944MB
[2024-07-26 21:10:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 26 training takes 0:13:39
[2024-07-26 21:11:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 31.733 (31.733)	Loss 0.3584 (0.3584)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 21:11:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.628 Acc@5 97.618
[2024-07-26 21:11:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.6%
[2024-07-26 21:11:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.63%
[2024-07-26 21:11:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saving......
[2024-07-26 21:11:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-26 21:12:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][0/2502]	eta 20:23:13 lr 0.000003	 wd 0.0000	time 29.3338 (29.3338)	loss 0.7383 (0.7383)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:12:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:22:31 lr 0.000003	 wd 0.0000	time 0.2384 (0.5627)	loss 0.8301 (0.8188)	grad_norm 1.8418 (1.5917)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:12:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:15:52 lr 0.000003	 wd 0.0000	time 0.2635 (0.4139)	loss 0.8193 (0.8176)	grad_norm 1.4738 (1.6126)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:13:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:13:24 lr 0.000003	 wd 0.0000	time 0.2675 (0.3654)	loss 0.8213 (0.8146)	grad_norm 1.4747 (1.6245)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:13:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:11:58 lr 0.000003	 wd 0.0000	time 0.2536 (0.3417)	loss 0.8062 (0.8148)	grad_norm 1.2955 (1.6223)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:14:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:10:52 lr 0.000003	 wd 0.0000	time 0.2568 (0.3261)	loss 0.7417 (0.8127)	grad_norm 1.6391 (1.6053)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:14:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:10:00 lr 0.000003	 wd 0.0000	time 0.2491 (0.3157)	loss 0.7568 (0.8159)	grad_norm 1.5281 (1.5998)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:15:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:09:16 lr 0.000003	 wd 0.0000	time 0.2364 (0.3089)	loss 0.8359 (0.8175)	grad_norm 1.6026 (1.5901)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:15:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:08:38 lr 0.000003	 wd 0.0000	time 0.2479 (0.3048)	loss 0.8896 (0.8164)	grad_norm 1.4218 (1.5894)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:16:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:08:01 lr 0.000003	 wd 0.0000	time 0.2205 (0.3006)	loss 0.7900 (0.8184)	grad_norm 1.5916 (1.5854)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:16:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:07:26 lr 0.000003	 wd 0.0000	time 0.2549 (0.2971)	loss 0.9233 (0.8176)	grad_norm 1.6633 (1.5887)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:17:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:06:53 lr 0.000003	 wd 0.0000	time 0.2552 (0.2951)	loss 0.7363 (0.8177)	grad_norm 2.0674 (1.5866)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:17:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:06:21 lr 0.000003	 wd 0.0000	time 0.2541 (0.2931)	loss 0.7661 (0.8171)	grad_norm 1.5507 (1.5876)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:17:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:05:49 lr 0.000003	 wd 0.0000	time 0.2700 (0.2910)	loss 0.8394 (0.8171)	grad_norm 1.7032 (1.5869)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:18:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:05:18 lr 0.000003	 wd 0.0000	time 0.2277 (0.2892)	loss 0.7236 (0.8172)	grad_norm 1.6362 (1.5833)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:18:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:04:48 lr 0.000003	 wd 0.0000	time 0.2395 (0.2884)	loss 0.8335 (0.8176)	grad_norm 1.7697 (1.5811)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:19:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:04:18 lr 0.000003	 wd 0.0000	time 0.2683 (0.2871)	loss 0.7427 (0.8181)	grad_norm 1.6325 (1.5790)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:19:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:49 lr 0.000002	 wd 0.0000	time 0.2237 (0.2858)	loss 0.8979 (0.8177)	grad_norm 1.3210 (1.5774)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:20:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:03:20 lr 0.000002	 wd 0.0000	time 0.2490 (0.2851)	loss 0.7725 (0.8180)	grad_norm 1.4857 (1.5751)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:20:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:56 lr 0.000002	 wd 0.0000	time 0.4135 (0.2939)	loss 0.8687 (0.8178)	grad_norm 1.5775 (1.5760)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:21:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:02:27 lr 0.000002	 wd 0.0000	time 0.2506 (0.2945)	loss 0.7021 (0.8175)	grad_norm 1.5170 (1.5756)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:22:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:02:06 lr 0.000002	 wd 0.0000	time 0.5458 (0.3159)	loss 0.9976 (0.8187)	grad_norm 1.5456 (1.5770)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:23:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:36 lr 0.000002	 wd 0.0000	time 0.3235 (0.3211)	loss 0.7354 (0.8187)	grad_norm 1.3906 (1.5781)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:23:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:01:04 lr 0.000002	 wd 0.0000	time 0.2481 (0.3207)	loss 0.8652 (0.8191)	grad_norm 1.5035 (1.5785)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:24:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:32 lr 0.000002	 wd 0.0000	time 0.2653 (0.3185)	loss 0.8696 (0.8190)	grad_norm 1.2854 (1.5791)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:24:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.2591 (0.3163)	loss 0.7637 (0.8193)	grad_norm 1.5585 (1.5808)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:24:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 27 training takes 0:13:18
[2024-07-26 21:25:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 33.811 (33.811)	Loss 0.3584 (0.3584)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 9944MB
[2024-07-26 21:25:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.600 Acc@5 97.604
[2024-07-26 21:25:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.6%
[2024-07-26 21:25:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.63%
[2024-07-26 21:26:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][0/2502]	eta 10:27:24 lr 0.000002	 wd 0.0000	time 15.0459 (15.0459)	loss 0.8032 (0.8032)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:26:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:17:05 lr 0.000002	 wd 0.0000	time 0.2689 (0.4268)	loss 0.8721 (0.8307)	grad_norm 1.3490 (1.5523)	loss_scale 32768.0000 (32768.0000)	mem 9944MB
[2024-07-26 21:26:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:13:23 lr 0.000002	 wd 0.0000	time 0.2446 (0.3491)	loss 0.9023 (0.8245)	grad_norm 1.5352 (inf)	loss_scale 16384.0000 (31952.8756)	mem 9944MB
[2024-07-26 21:27:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:11:46 lr 0.000002	 wd 0.0000	time 0.2317 (0.3209)	loss 0.8608 (0.8246)	grad_norm 1.3392 (inf)	loss_scale 16384.0000 (26780.4917)	mem 9944MB
[2024-07-26 21:27:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:10:45 lr 0.000002	 wd 0.0000	time 0.2639 (0.3071)	loss 0.7061 (0.8220)	grad_norm 1.4016 (inf)	loss_scale 16384.0000 (24187.8504)	mem 9944MB
[2024-07-26 21:28:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:09:59 lr 0.000002	 wd 0.0000	time 0.2425 (0.2993)	loss 0.9268 (0.8221)	grad_norm 1.3859 (inf)	loss_scale 16384.0000 (22630.1956)	mem 9944MB
[2024-07-26 21:28:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:09:18 lr 0.000002	 wd 0.0000	time 0.2556 (0.2934)	loss 0.8325 (0.8211)	grad_norm 1.6438 (inf)	loss_scale 16384.0000 (21590.8952)	mem 9944MB
[2024-07-26 21:29:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:08:41 lr 0.000002	 wd 0.0000	time 0.2286 (0.2894)	loss 0.7954 (0.8199)	grad_norm 1.8088 (inf)	loss_scale 16384.0000 (20848.1141)	mem 9944MB
[2024-07-26 21:29:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:08:07 lr 0.000002	 wd 0.0000	time 0.2432 (0.2865)	loss 0.7954 (0.8191)	grad_norm 1.6477 (inf)	loss_scale 16384.0000 (20290.7965)	mem 9944MB
[2024-07-26 21:30:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:07:37 lr 0.000002	 wd 0.0000	time 0.2606 (0.2854)	loss 0.8721 (0.8177)	grad_norm 2.0114 (inf)	loss_scale 16384.0000 (19857.1898)	mem 9944MB
[2024-07-26 21:30:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:07:06 lr 0.000002	 wd 0.0000	time 0.2156 (0.2837)	loss 0.8818 (0.8174)	grad_norm 1.7553 (inf)	loss_scale 16384.0000 (19510.2178)	mem 9944MB
[2024-07-26 21:30:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:06:35 lr 0.000002	 wd 0.0000	time 0.2264 (0.2822)	loss 0.7729 (0.8170)	grad_norm 1.5134 (inf)	loss_scale 16384.0000 (19226.2743)	mem 9944MB
[2024-07-26 21:31:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:06:05 lr 0.000002	 wd 0.0000	time 0.2458 (0.2811)	loss 0.9126 (0.8162)	grad_norm 1.6192 (inf)	loss_scale 16384.0000 (18989.6153)	mem 9944MB
[2024-07-26 21:31:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:05:37 lr 0.000002	 wd 0.0000	time 0.2207 (0.2806)	loss 0.7495 (0.8161)	grad_norm 1.9466 (inf)	loss_scale 16384.0000 (18789.3374)	mem 9944MB
[2024-07-26 21:32:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:05:08 lr 0.000002	 wd 0.0000	time 0.2609 (0.2798)	loss 0.7715 (0.8161)	grad_norm 1.6262 (inf)	loss_scale 16384.0000 (18617.6502)	mem 9944MB
