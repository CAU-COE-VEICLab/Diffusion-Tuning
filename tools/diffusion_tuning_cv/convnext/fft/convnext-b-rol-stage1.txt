[2024-07-28 09:20:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 366): INFO Full config saved to pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/config.json
[2024-07-28 09:20:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: convnext_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 27
    - 3
    DIMS:
    - 128
    - 256
    - 512
    - 1024
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: sequence_stage1
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_conv_b_sequence_stage1
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 0.0001
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 0.8
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.0e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 1.0e-08

[2024-07-28 09:20:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/diffusion_finetune/convnext/convnext/diffusion_ft_convnext_base_224_22kto1k_sequence_stage_process1.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/diffusion-ft", "tag": "diffusion_ft_conv_b_sequence_stage1", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-28 09:20:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 108): INFO Creating model:convnext_diffusion_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1
[2024-07-28 09:20:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 110): INFO ConvNeXt_Diffusion_Finetune(
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (3): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (4): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (5): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (6): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (7): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (8): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (9): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (10): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (11): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (12): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (13): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (14): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (15): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (16): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (17): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (18): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (19): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (20): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (21): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (22): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (23): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (24): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (25): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (26): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-28 09:20:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 113): INFO number of params: 3723368
[2024-07-28 09:20:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 150): INFO no checkpoint found in pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1, ignoring auto resume
[2024-07-28 09:20:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth for fine-tuning......
[2024-07-28 09:20:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 127): WARNING <All keys matched successfully>
[2024-07-28 09:20:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth'
[2024-07-28 09:21:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 69.450 (69.450)	Loss 0.3643 (0.3643)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 3050MB
[2024-07-28 09:22:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.864 Acc@5 97.506
[2024-07-28 09:22:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 162): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-28 09:22:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 168): INFO Start training
[2024-07-28 09:22:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][0/2502]	eta 15:46:25 lr 0.000100	 wd 0.0000	time 22.6960 (22.6960)	loss 0.8496 (0.8496)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 9201MB
[2024-07-28 09:23:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:19:08 lr 0.000100	 wd 0.0000	time 0.2962 (0.4780)	loss 0.9341 (0.8888)	grad_norm 3.7233 (nan)	loss_scale 16384.0000 (20763.8812)	mem 9201MB
[2024-07-28 09:23:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:15:34 lr 0.000100	 wd 0.0000	time 0.2122 (0.4059)	loss 0.9282 (0.8996)	grad_norm 1.9964 (nan)	loss_scale 16384.0000 (18584.8358)	mem 9201MB
[2024-07-28 09:24:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:20 lr 0.000100	 wd 0.0000	time 0.1948 (0.3365)	loss 0.8711 (0.9043)	grad_norm 2.0681 (nan)	loss_scale 16384.0000 (17853.6611)	mem 9201MB
[2024-07-28 09:24:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:34 lr 0.000100	 wd 0.0000	time 0.1801 (0.3016)	loss 1.1865 (0.9070)	grad_norm 1.7579 (nan)	loss_scale 16384.0000 (17487.1621)	mem 9201MB
[2024-07-28 09:24:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:09:23 lr 0.000100	 wd 0.0000	time 0.2111 (0.2815)	loss 0.7754 (0.9073)	grad_norm 2.8347 (nan)	loss_scale 16384.0000 (17266.9701)	mem 9201MB
[2024-07-28 09:25:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:30 lr 0.000100	 wd 0.0000	time 0.1813 (0.2997)	loss 0.8638 (0.9070)	grad_norm 1.6329 (nan)	loss_scale 16384.0000 (17120.0532)	mem 9201MB
[2024-07-28 09:25:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:34 lr 0.000100	 wd 0.0000	time 0.1952 (0.2857)	loss 0.9639 (0.9075)	grad_norm 3.9650 (nan)	loss_scale 16384.0000 (17015.0528)	mem 9201MB
[2024-07-28 09:26:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:48 lr 0.000100	 wd 0.0000	time 0.1969 (0.2750)	loss 0.9243 (0.9068)	grad_norm 2.1338 (nan)	loss_scale 16384.0000 (16936.2697)	mem 9201MB
[2024-07-28 09:26:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:08 lr 0.000100	 wd 0.0000	time 0.2008 (0.2673)	loss 0.9429 (0.9058)	grad_norm 3.1907 (nan)	loss_scale 16384.0000 (16874.9745)	mem 9201MB
[2024-07-28 09:27:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:06:53 lr 0.000100	 wd 0.0000	time 0.2060 (0.2752)	loss 0.9751 (0.9059)	grad_norm 2.3465 (nan)	loss_scale 16384.0000 (16825.9261)	mem 9201MB
[2024-07-28 09:27:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:17 lr 0.000100	 wd 0.0000	time 0.1793 (0.2690)	loss 0.8184 (0.9058)	grad_norm 2.7749 (nan)	loss_scale 16384.0000 (16785.7875)	mem 9201MB
[2024-07-28 09:27:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:42 lr 0.000100	 wd 0.0000	time 0.1953 (0.2631)	loss 0.8813 (0.9061)	grad_norm 1.9985 (nan)	loss_scale 16384.0000 (16752.3331)	mem 9201MB
[2024-07-28 09:28:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:10 lr 0.000100	 wd 0.0000	time 0.2094 (0.2586)	loss 0.7476 (0.9070)	grad_norm 1.9096 (nan)	loss_scale 16384.0000 (16724.0215)	mem 9201MB
[2024-07-28 09:28:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:53 lr 0.000100	 wd 0.0000	time 0.1948 (0.2662)	loss 0.9492 (0.9068)	grad_norm 2.8733 (nan)	loss_scale 16384.0000 (16699.7516)	mem 9201MB
[2024-07-28 09:29:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:22 lr 0.000100	 wd 0.0000	time 0.1938 (0.2617)	loss 0.9805 (0.9071)	grad_norm 1.7537 (nan)	loss_scale 16384.0000 (16678.7155)	mem 9201MB
[2024-07-28 09:29:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:52 lr 0.000100	 wd 0.0000	time 0.1860 (0.2578)	loss 1.0186 (0.9064)	grad_norm 2.1872 (nan)	loss_scale 16384.0000 (16660.3073)	mem 9201MB
[2024-07-28 09:29:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:24 lr 0.000100	 wd 0.0000	time 0.1849 (0.2544)	loss 0.7852 (0.9064)	grad_norm 2.5489 (nan)	loss_scale 16384.0000 (16644.0635)	mem 9201MB
[2024-07-28 09:30:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:02:58 lr 0.000100	 wd 0.0000	time 0.1913 (0.2538)	loss 0.9072 (0.9060)	grad_norm 2.3305 (nan)	loss_scale 16384.0000 (16629.6235)	mem 9201MB
[2024-07-28 09:30:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:31 lr 0.000100	 wd 0.0000	time 0.1798 (0.2515)	loss 0.8882 (0.9058)	grad_norm 1.4665 (nan)	loss_scale 16384.0000 (16616.7028)	mem 9201MB
[2024-07-28 09:30:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:04 lr 0.000100	 wd 0.0000	time 0.1905 (0.2490)	loss 0.9463 (0.9064)	grad_norm 2.0938 (nan)	loss_scale 16384.0000 (16605.0735)	mem 9201MB
[2024-07-28 09:31:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:39 lr 0.000100	 wd 0.0000	time 0.1981 (0.2466)	loss 0.8701 (0.9068)	grad_norm 1.6583 (nan)	loss_scale 16384.0000 (16594.5512)	mem 9201MB
[2024-07-28 09:31:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:13 lr 0.000100	 wd 0.0000	time 0.1848 (0.2449)	loss 0.9546 (0.9066)	grad_norm 1.9294 (nan)	loss_scale 16384.0000 (16584.9850)	mem 9201MB
[2024-07-28 09:31:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:49 lr 0.000100	 wd 0.0000	time 0.1776 (0.2444)	loss 0.9956 (0.9063)	grad_norm 1.6160 (nan)	loss_scale 16384.0000 (16576.2503)	mem 9201MB
[2024-07-28 09:32:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:24 lr 0.000100	 wd 0.0000	time 0.2217 (0.2428)	loss 0.8486 (0.9063)	grad_norm 2.5414 (nan)	loss_scale 16384.0000 (16568.2432)	mem 9201MB
[2024-07-28 09:32:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000100	 wd 0.0000	time 0.1824 (0.2409)	loss 1.0234 (0.9060)	grad_norm 1.8608 (nan)	loss_scale 16384.0000 (16560.8764)	mem 9201MB
[2024-07-28 09:32:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 0 training takes 0:10:06
[2024-07-28 09:32:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_0.pth saving......
[2024-07-28 09:32:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_0.pth saved !!!
[2024-07-28 09:33:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 46.314 (46.314)	Loss 0.3687 (0.3687)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 9201MB
[2024-07-28 09:33:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.748 Acc@5 97.480
[2024-07-28 09:33:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-28 09:33:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.75%
[2024-07-28 09:33:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-28 09:33:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-28 09:33:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][0/2502]	eta 10:50:30 lr 0.000100	 wd 0.0000	time 15.5996 (15.5996)	loss 0.8813 (0.8813)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:34:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:14:02 lr 0.000100	 wd 0.0000	time 0.1913 (0.3509)	loss 0.8018 (0.9000)	grad_norm 1.8355 (1.9474)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:34:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:11:11 lr 0.000100	 wd 0.0000	time 0.3242 (0.2918)	loss 1.0312 (0.9061)	grad_norm 1.8058 (1.9574)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:35:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:12:17 lr 0.000100	 wd 0.0000	time 0.2081 (0.3347)	loss 0.9951 (0.9030)	grad_norm 1.7878 (1.9549)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:35:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:10:32 lr 0.000100	 wd 0.0000	time 0.1990 (0.3011)	loss 0.7803 (0.9050)	grad_norm 2.2509 (1.9656)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:35:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:09:21 lr 0.000100	 wd 0.0000	time 0.1933 (0.2804)	loss 0.9331 (0.9025)	grad_norm 1.8906 (1.9625)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:36:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:08:38 lr 0.000100	 wd 0.0000	time 0.3146 (0.2729)	loss 1.0010 (0.9042)	grad_norm 1.7713 (1.9695)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:36:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:20 lr 0.000100	 wd 0.0000	time 0.1857 (0.2780)	loss 0.8228 (0.9037)	grad_norm 1.9080 (inf)	loss_scale 8192.0000 (15355.6177)	mem 9201MB
[2024-07-28 09:37:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:36 lr 0.000100	 wd 0.0000	time 0.1871 (0.2680)	loss 0.8281 (0.9049)	grad_norm 2.1925 (inf)	loss_scale 8192.0000 (14461.2834)	mem 9201MB
[2024-07-28 09:37:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:06:56 lr 0.000099	 wd 0.0000	time 0.1924 (0.2600)	loss 0.9258 (0.9046)	grad_norm 2.0865 (inf)	loss_scale 8192.0000 (13765.4695)	mem 9201MB
[2024-07-28 09:37:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:25 lr 0.000099	 wd 0.0000	time 0.3599 (0.2566)	loss 0.9126 (0.9039)	grad_norm 1.9551 (inf)	loss_scale 8192.0000 (13208.6793)	mem 9201MB
[2024-07-28 09:38:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:06:11 lr 0.000099	 wd 0.0000	time 0.1871 (0.2651)	loss 1.0547 (0.9041)	grad_norm 1.8137 (inf)	loss_scale 8192.0000 (12753.0318)	mem 9201MB
[2024-07-28 09:38:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:37 lr 0.000099	 wd 0.0000	time 0.1914 (0.2596)	loss 0.9438 (0.9039)	grad_norm 1.7512 (inf)	loss_scale 8192.0000 (12373.2623)	mem 9201MB
[2024-07-28 09:39:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:06 lr 0.000099	 wd 0.0000	time 0.1889 (0.2549)	loss 0.9985 (0.9047)	grad_norm 2.0345 (inf)	loss_scale 8192.0000 (12051.8739)	mem 9201MB
[2024-07-28 09:39:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:36 lr 0.000099	 wd 0.0000	time 0.1853 (0.2512)	loss 0.8916 (0.9050)	grad_norm 2.0516 (inf)	loss_scale 8192.0000 (11776.3655)	mem 9201MB
[2024-07-28 09:39:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:09 lr 0.000099	 wd 0.0000	time 0.1928 (0.2495)	loss 0.9590 (0.9053)	grad_norm 1.7305 (inf)	loss_scale 8192.0000 (11537.5670)	mem 9201MB
[2024-07-28 09:40:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:42 lr 0.000099	 wd 0.0000	time 0.1832 (0.2468)	loss 0.9785 (0.9059)	grad_norm 1.8779 (inf)	loss_scale 8192.0000 (11328.5996)	mem 9201MB
[2024-07-28 09:40:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:15 lr 0.000099	 wd 0.0000	time 0.1828 (0.2441)	loss 0.7700 (0.9059)	grad_norm 1.7021 (inf)	loss_scale 8192.0000 (11144.2022)	mem 9201MB
[2024-07-28 09:40:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:49 lr 0.000099	 wd 0.0000	time 0.1978 (0.2418)	loss 1.0811 (0.9062)	grad_norm 1.7982 (inf)	loss_scale 8192.0000 (10980.2821)	mem 9201MB
[2024-07-28 09:41:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:24 lr 0.000099	 wd 0.0000	time 0.2071 (0.2402)	loss 0.8999 (0.9069)	grad_norm 2.4837 (inf)	loss_scale 8192.0000 (10833.6076)	mem 9201MB
[2024-07-28 09:41:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:00 lr 0.000099	 wd 0.0000	time 0.1811 (0.2401)	loss 0.8042 (0.9066)	grad_norm 1.5574 (inf)	loss_scale 8192.0000 (10701.5932)	mem 9201MB
[2024-07-28 09:41:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:35 lr 0.000099	 wd 0.0000	time 0.1835 (0.2383)	loss 0.8540 (0.9068)	grad_norm 2.1840 (inf)	loss_scale 8192.0000 (10582.1456)	mem 9201MB
[2024-07-28 09:42:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:11 lr 0.000099	 wd 0.0000	time 0.2046 (0.2364)	loss 0.7358 (0.9067)	grad_norm 1.9866 (inf)	loss_scale 8192.0000 (10473.5520)	mem 9201MB
[2024-07-28 09:42:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:47 lr 0.000099	 wd 0.0000	time 0.2560 (0.2351)	loss 1.1182 (0.9073)	grad_norm 2.3564 (inf)	loss_scale 8192.0000 (10374.3972)	mem 9201MB
[2024-07-28 09:43:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:23 lr 0.000099	 wd 0.0000	time 0.3263 (0.2349)	loss 0.9443 (0.9070)	grad_norm 1.7140 (inf)	loss_scale 8192.0000 (10283.5019)	mem 9201MB
[2024-07-28 09:43:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000099	 wd 0.0000	time 0.1823 (0.2336)	loss 1.0830 (0.9073)	grad_norm 1.4660 (inf)	loss_scale 8192.0000 (10199.8752)	mem 9201MB
[2024-07-28 09:43:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 1 training takes 0:09:49
[2024-07-28 09:43:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 25.883 (25.883)	Loss 0.3667 (0.3667)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 9201MB
[2024-07-28 09:44:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.796 Acc@5 97.446
[2024-07-28 09:44:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-28 09:44:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.80%
[2024-07-28 09:44:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-28 09:44:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-28 09:44:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][0/2502]	eta 1 day, 0:39:32 lr 0.000099	 wd 0.0000	time 35.4804 (35.4804)	loss 0.8228 (0.8228)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:45:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:21:59 lr 0.000099	 wd 0.0000	time 0.1952 (0.5493)	loss 0.9355 (0.9085)	grad_norm 1.9039 (1.9881)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:45:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:14:21 lr 0.000099	 wd 0.0000	time 0.1869 (0.3740)	loss 0.9131 (0.9008)	grad_norm 2.2315 (1.9491)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:45:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:11:33 lr 0.000099	 wd 0.0000	time 0.1958 (0.3149)	loss 0.9683 (0.9014)	grad_norm 1.7352 (1.9513)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:46:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:11:39 lr 0.000099	 wd 0.0000	time 0.1982 (0.3329)	loss 0.8164 (0.9006)	grad_norm 2.4340 (1.9536)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:46:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:10:16 lr 0.000099	 wd 0.0000	time 0.1917 (0.3079)	loss 1.0898 (0.8993)	grad_norm 1.7561 (1.9525)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:46:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:09:10 lr 0.000099	 wd 0.0000	time 0.1779 (0.2897)	loss 0.9507 (0.9003)	grad_norm 2.3774 (1.9547)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:47:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:08:18 lr 0.000099	 wd 0.0000	time 0.1822 (0.2767)	loss 0.9932 (0.9004)	grad_norm 1.7254 (1.9548)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:47:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:53 lr 0.000099	 wd 0.0000	time 0.2208 (0.2780)	loss 0.7891 (0.8995)	grad_norm 1.7438 (1.9620)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:48:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:07:11 lr 0.000098	 wd 0.0000	time 0.1860 (0.2695)	loss 0.8999 (0.9003)	grad_norm 2.1188 (1.9531)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:48:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:33 lr 0.000098	 wd 0.0000	time 0.1931 (0.2623)	loss 0.8330 (0.9006)	grad_norm 1.9664 (1.9515)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:48:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:59 lr 0.000098	 wd 0.0000	time 0.1783 (0.2564)	loss 0.9058 (0.9005)	grad_norm 1.6601 (1.9412)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:49:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:30 lr 0.000098	 wd 0.0000	time 0.3069 (0.2542)	loss 1.0830 (0.8998)	grad_norm 1.6794 (1.9400)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:49:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:05:12 lr 0.000098	 wd 0.0000	time 0.2137 (0.2602)	loss 0.9595 (0.9008)	grad_norm 1.5840 (1.9410)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:50:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:41 lr 0.000098	 wd 0.0000	time 0.2023 (0.2559)	loss 0.9175 (0.9011)	grad_norm 1.9534 (1.9381)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:50:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:12 lr 0.000098	 wd 0.0000	time 0.1830 (0.2520)	loss 0.8564 (0.9008)	grad_norm 1.5771 (1.9344)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:50:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:44 lr 0.000098	 wd 0.0000	time 0.2035 (0.2493)	loss 0.9048 (0.9009)	grad_norm 1.7640 (1.9296)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:51:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:19 lr 0.000098	 wd 0.0000	time 0.1855 (0.2482)	loss 0.9443 (0.9014)	grad_norm 1.9332 (1.9238)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:51:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:52 lr 0.000098	 wd 0.0000	time 0.2113 (0.2459)	loss 0.8208 (0.9010)	grad_norm 2.0434 (1.9223)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:51:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:26 lr 0.000098	 wd 0.0000	time 0.1847 (0.2436)	loss 0.8354 (0.9016)	grad_norm 1.9633 (1.9266)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:52:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:02:01 lr 0.000098	 wd 0.0000	time 0.1904 (0.2415)	loss 0.8867 (0.9012)	grad_norm 1.7252 (1.9272)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:52:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:36 lr 0.000098	 wd 0.0000	time 0.2079 (0.2399)	loss 0.9888 (0.9018)	grad_norm 1.7266 (1.9246)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 09:52:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:12 lr 0.000098	 wd 0.0000	time 0.1875 (0.2392)	loss 0.8735 (0.9015)	grad_norm 1.7087 (1.9233)	loss_scale 16384.0000 (8526.9750)	mem 9201MB
[2024-07-28 09:53:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:47 lr 0.000098	 wd 0.0000	time 0.1873 (0.2376)	loss 0.9829 (0.9014)	grad_norm 2.0898 (1.9221)	loss_scale 16384.0000 (8868.4363)	mem 9201MB
[2024-07-28 09:53:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:24 lr 0.000098	 wd 0.0000	time 0.1889 (0.2361)	loss 1.1162 (0.9014)	grad_norm 2.0291 (1.9222)	loss_scale 16384.0000 (9181.4544)	mem 9201MB
[2024-07-28 09:53:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000098	 wd 0.0000	time 0.1835 (0.2343)	loss 0.8721 (0.9017)	grad_norm 1.5627 (1.9196)	loss_scale 16384.0000 (9469.4410)	mem 9201MB
[2024-07-28 09:53:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 2 training takes 0:09:50
[2024-07-28 09:54:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 43.876 (43.876)	Loss 0.3604 (0.3604)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 09:54:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.776 Acc@5 97.462
[2024-07-28 09:54:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-28 09:54:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.80%
[2024-07-28 09:55:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][0/2502]	eta 11:47:40 lr 0.000098	 wd 0.0000	time 16.9704 (16.9704)	loss 0.7803 (0.7803)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:55:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:14:55 lr 0.000098	 wd 0.0000	time 0.2264 (0.3728)	loss 0.8486 (0.8999)	grad_norm 2.0675 (1.9451)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:56:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:13:52 lr 0.000097	 wd 0.0000	time 0.1999 (0.3618)	loss 0.9189 (0.9003)	grad_norm 1.5717 (1.9300)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:56:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:11:16 lr 0.000097	 wd 0.0000	time 0.1847 (0.3072)	loss 1.0088 (0.9021)	grad_norm 1.7442 (1.9277)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:56:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:09:48 lr 0.000097	 wd 0.0000	time 0.1772 (0.2801)	loss 0.9434 (0.9013)	grad_norm 1.6467 (1.9344)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:57:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:08:48 lr 0.000097	 wd 0.0000	time 0.1847 (0.2639)	loss 0.8989 (0.9006)	grad_norm 1.7547 (1.9039)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:57:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:09:01 lr 0.000097	 wd 0.0000	time 0.2318 (0.2848)	loss 0.8286 (0.9002)	grad_norm 2.6445 (1.8932)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:58:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:08:12 lr 0.000097	 wd 0.0000	time 0.1936 (0.2731)	loss 1.0957 (0.9006)	grad_norm 2.3806 (1.9020)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:58:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:29 lr 0.000097	 wd 0.0000	time 0.1857 (0.2640)	loss 0.9453 (0.9016)	grad_norm 1.7866 (1.8958)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:58:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:06:52 lr 0.000097	 wd 0.0000	time 0.1906 (0.2574)	loss 1.0225 (0.9021)	grad_norm 1.7731 (1.8960)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:59:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:33 lr 0.000097	 wd 0.0000	time 0.1858 (0.2622)	loss 0.9624 (0.9037)	grad_norm 2.0190 (1.8947)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:59:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:05:59 lr 0.000097	 wd 0.0000	time 0.1833 (0.2565)	loss 0.8711 (0.9047)	grad_norm 2.0786 (1.8961)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 09:59:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:27 lr 0.000097	 wd 0.0000	time 0.1833 (0.2515)	loss 0.9873 (0.9051)	grad_norm 1.4028 (1.8906)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:00:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:04:57 lr 0.000097	 wd 0.0000	time 0.2139 (0.2475)	loss 1.0176 (0.9057)	grad_norm 2.7801 (1.8897)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:00:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:40 lr 0.000097	 wd 0.0000	time 0.3112 (0.2549)	loss 0.8218 (0.9062)	grad_norm 1.7853 (1.8876)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:01:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:12 lr 0.000097	 wd 0.0000	time 0.1818 (0.2518)	loss 0.8281 (0.9067)	grad_norm 1.5643 (1.8894)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:01:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:44 lr 0.000096	 wd 0.0000	time 0.1826 (0.2484)	loss 0.8569 (0.9060)	grad_norm 1.8328 (1.8922)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:01:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:16 lr 0.000096	 wd 0.0000	time 0.1844 (0.2455)	loss 0.8828 (0.9059)	grad_norm 1.5674 (1.8913)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:02:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:50 lr 0.000096	 wd 0.0000	time 0.1979 (0.2434)	loss 1.0107 (0.9056)	grad_norm 1.9421 (1.8951)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:02:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:26 lr 0.000096	 wd 0.0000	time 0.1865 (0.2432)	loss 0.8970 (0.9055)	grad_norm 2.3556 (1.8961)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:02:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:01 lr 0.000096	 wd 0.0000	time 0.2044 (0.2413)	loss 0.9160 (0.9057)	grad_norm 2.2821 (1.8974)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:03:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:36 lr 0.000096	 wd 0.0000	time 0.1989 (0.2395)	loss 0.8335 (0.9056)	grad_norm 1.5227 (1.8966)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:03:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:11 lr 0.000096	 wd 0.0000	time 0.1884 (0.2379)	loss 0.8999 (0.9052)	grad_norm 1.7345 (1.8933)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:03:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:48 lr 0.000096	 wd 0.0000	time 0.1813 (0.2378)	loss 0.9385 (0.9053)	grad_norm 1.6738 (1.8928)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:04:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:24 lr 0.000096	 wd 0.0000	time 0.1831 (0.2367)	loss 0.9336 (0.9049)	grad_norm 2.5606 (1.8940)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:04:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000096	 wd 0.0000	time 0.1804 (0.2349)	loss 1.0234 (0.9050)	grad_norm 1.9160 (1.8935)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:04:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 3 training takes 0:09:51
[2024-07-28 10:05:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 33.287 (33.287)	Loss 0.3665 (0.3665)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 10:05:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.800 Acc@5 97.516
[2024-07-28 10:05:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-28 10:05:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.80%
[2024-07-28 10:05:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-28 10:05:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-28 10:06:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][0/2502]	eta 12:35:40 lr 0.000096	 wd 0.0000	time 18.1215 (18.1215)	loss 0.9360 (0.9360)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:06:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:15:01 lr 0.000096	 wd 0.0000	time 0.1860 (0.3755)	loss 0.8330 (0.8950)	grad_norm 1.7693 (1.8525)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:06:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:11:05 lr 0.000096	 wd 0.0000	time 0.1819 (0.2889)	loss 1.0000 (0.9028)	grad_norm 1.7675 (1.8332)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:07:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:12:02 lr 0.000095	 wd 0.0000	time 0.1968 (0.3280)	loss 0.8433 (0.9033)	grad_norm 1.8918 (1.8648)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:07:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:10:23 lr 0.000095	 wd 0.0000	time 0.1800 (0.2964)	loss 0.9321 (0.8992)	grad_norm 1.9359 (1.8511)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:08:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:09:13 lr 0.000095	 wd 0.0000	time 0.1859 (0.2767)	loss 0.9834 (0.8995)	grad_norm 2.5290 (1.8534)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:08:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:08:25 lr 0.000095	 wd 0.0000	time 0.1853 (0.2655)	loss 0.8535 (0.9019)	grad_norm 1.8839 (1.8493)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:08:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:08:00 lr 0.000095	 wd 0.0000	time 0.1833 (0.2664)	loss 1.0938 (0.9004)	grad_norm 1.9817 (1.8627)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:09:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:18 lr 0.000095	 wd 0.0000	time 0.1785 (0.2579)	loss 0.8149 (0.8997)	grad_norm 1.4921 (1.8614)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:09:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:06:42 lr 0.000095	 wd 0.0000	time 0.2009 (0.2511)	loss 0.9634 (0.9005)	grad_norm 1.6544 (1.8595)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:09:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:09 lr 0.000095	 wd 0.0000	time 0.2044 (0.2459)	loss 0.8506 (0.9007)	grad_norm 2.2738 (1.8649)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:10:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:06:00 lr 0.000095	 wd 0.0000	time 0.2496 (0.2570)	loss 1.0176 (0.9015)	grad_norm 1.4985 (1.8677)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:10:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:30 lr 0.000095	 wd 0.0000	time 0.1929 (0.2537)	loss 0.8477 (0.9016)	grad_norm 1.6738 (1.8610)	loss_scale 32768.0000 (17666.3447)	mem 9201MB
[2024-07-28 10:11:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:04:59 lr 0.000095	 wd 0.0000	time 0.1998 (0.2495)	loss 0.7695 (0.9007)	grad_norm 1.8520 (inf)	loss_scale 16384.0000 (18373.7556)	mem 9201MB
[2024-07-28 10:11:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:30 lr 0.000094	 wd 0.0000	time 0.2015 (0.2459)	loss 0.9023 (0.9001)	grad_norm 1.6997 (inf)	loss_scale 16384.0000 (18231.7316)	mem 9201MB
[2024-07-28 10:11:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:08 lr 0.000094	 wd 0.0000	time 0.2357 (0.2476)	loss 0.7876 (0.9005)	grad_norm 1.5819 (inf)	loss_scale 16384.0000 (18108.6316)	mem 9201MB
[2024-07-28 10:12:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:40 lr 0.000094	 wd 0.0000	time 0.1946 (0.2446)	loss 0.9512 (0.9009)	grad_norm 1.7012 (inf)	loss_scale 16384.0000 (18000.9094)	mem 9201MB
[2024-07-28 10:12:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:14 lr 0.000094	 wd 0.0000	time 0.2139 (0.2422)	loss 0.9263 (0.9013)	grad_norm 1.5618 (inf)	loss_scale 16384.0000 (17905.8530)	mem 9201MB
[2024-07-28 10:12:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:48 lr 0.000094	 wd 0.0000	time 0.1875 (0.2398)	loss 0.9907 (0.9023)	grad_norm 2.0542 (inf)	loss_scale 16384.0000 (17821.3526)	mem 9201MB
[2024-07-28 10:13:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:23 lr 0.000094	 wd 0.0000	time 0.2212 (0.2381)	loss 0.8506 (0.9020)	grad_norm 1.6535 (inf)	loss_scale 16384.0000 (17745.7422)	mem 9201MB
[2024-07-28 10:13:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:01:59 lr 0.000094	 wd 0.0000	time 0.2015 (0.2385)	loss 0.7788 (0.9015)	grad_norm 1.5097 (inf)	loss_scale 16384.0000 (17677.6892)	mem 9201MB
[2024-07-28 10:14:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:35 lr 0.000094	 wd 0.0000	time 0.2165 (0.2372)	loss 0.8096 (0.9015)	grad_norm 1.6733 (inf)	loss_scale 16384.0000 (17616.1142)	mem 9201MB
[2024-07-28 10:14:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:11 lr 0.000094	 wd 0.0000	time 0.2068 (0.2356)	loss 0.9082 (0.9013)	grad_norm 1.6276 (inf)	loss_scale 16384.0000 (17560.1345)	mem 9201MB
[2024-07-28 10:14:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:47 lr 0.000094	 wd 0.0000	time 0.2124 (0.2342)	loss 0.8838 (0.9015)	grad_norm 2.9683 (inf)	loss_scale 16384.0000 (17509.0204)	mem 9201MB
[2024-07-28 10:15:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:23 lr 0.000093	 wd 0.0000	time 0.2039 (0.2333)	loss 0.8281 (0.9016)	grad_norm 1.6912 (inf)	loss_scale 16384.0000 (17462.1641)	mem 9201MB
[2024-07-28 10:15:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000093	 wd 0.0000	time 0.1809 (0.2329)	loss 0.7896 (0.9017)	grad_norm 1.7922 (inf)	loss_scale 16384.0000 (17419.0548)	mem 9201MB
[2024-07-28 10:15:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 4 training takes 0:09:48
[2024-07-28 10:15:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 21.885 (21.885)	Loss 0.3562 (0.3562)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 9201MB
[2024-07-28 10:16:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.926 Acc@5 97.462
[2024-07-28 10:16:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-28 10:16:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.93%
[2024-07-28 10:16:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-28 10:16:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-28 10:16:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][0/2502]	eta 12:11:51 lr 0.000093	 wd 0.0000	time 17.5506 (17.5506)	loss 1.0459 (1.0459)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:16:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:16:44 lr 0.000093	 wd 0.0000	time 0.2011 (0.4183)	loss 0.8052 (0.8985)	grad_norm 1.7983 (1.8674)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:17:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:11:50 lr 0.000093	 wd 0.0000	time 0.1815 (0.3085)	loss 0.8242 (0.9045)	grad_norm 2.1437 (1.8918)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:17:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:09:58 lr 0.000093	 wd 0.0000	time 0.2006 (0.2716)	loss 0.8716 (0.9033)	grad_norm 1.8617 (1.8906)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:17:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:08:51 lr 0.000093	 wd 0.0000	time 0.2264 (0.2526)	loss 0.7900 (0.9017)	grad_norm 1.7651 (1.8666)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:18:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:08:14 lr 0.000093	 wd 0.0000	time 0.3419 (0.2468)	loss 0.9219 (0.9007)	grad_norm 1.7758 (1.8651)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:18:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:37 lr 0.000093	 wd 0.0000	time 0.2097 (0.2719)	loss 1.1279 (0.9033)	grad_norm 1.6815 (1.8695)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:19:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:51 lr 0.000093	 wd 0.0000	time 0.1924 (0.2616)	loss 0.9219 (0.9022)	grad_norm 1.6518 (1.8643)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:19:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:12 lr 0.000093	 wd 0.0000	time 0.1776 (0.2539)	loss 0.9336 (0.9027)	grad_norm 1.7484 (1.8616)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:20:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:59 lr 0.000092	 wd 0.0000	time 0.2987 (0.2618)	loss 0.8755 (0.9023)	grad_norm 1.9167 (1.8708)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:20:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:30 lr 0.000092	 wd 0.0000	time 0.2035 (0.2598)	loss 0.8237 (0.9030)	grad_norm 2.1009 (1.8736)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:20:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:56 lr 0.000092	 wd 0.0000	time 0.1855 (0.2544)	loss 0.8164 (0.9037)	grad_norm 2.1807 (1.8756)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:21:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:25 lr 0.000092	 wd 0.0000	time 0.1936 (0.2497)	loss 1.0410 (0.9038)	grad_norm 1.6581 (1.8774)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:21:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:56 lr 0.000092	 wd 0.0000	time 0.1917 (0.2465)	loss 0.8989 (0.9038)	grad_norm 1.6980 (1.8726)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:21:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:30 lr 0.000092	 wd 0.0000	time 0.2021 (0.2454)	loss 0.9209 (0.9028)	grad_norm 1.8063 (1.8675)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:22:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:04:03 lr 0.000092	 wd 0.0000	time 0.1927 (0.2426)	loss 0.9248 (0.9026)	grad_norm 3.8494 (1.8639)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:22:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:36 lr 0.000092	 wd 0.0000	time 0.2060 (0.2399)	loss 0.8315 (0.9021)	grad_norm 1.7727 (1.8664)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:22:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:10 lr 0.000092	 wd 0.0000	time 0.2055 (0.2377)	loss 0.9868 (0.9021)	grad_norm 1.6596 (1.8692)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:23:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:46 lr 0.000091	 wd 0.0000	time 0.2034 (0.2376)	loss 0.8896 (0.9021)	grad_norm 1.4417 (1.8701)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:23:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:22 lr 0.000091	 wd 0.0000	time 0.1837 (0.2368)	loss 1.0557 (0.9025)	grad_norm 2.0196 (1.8741)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:23:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:01:58 lr 0.000091	 wd 0.0000	time 0.2059 (0.2351)	loss 1.0518 (0.9023)	grad_norm 1.6196 (1.8777)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:24:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:33 lr 0.000091	 wd 0.0000	time 0.1977 (0.2334)	loss 0.9150 (0.9016)	grad_norm 1.6733 (1.8781)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:24:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:10 lr 0.000091	 wd 0.0000	time 0.2061 (0.2324)	loss 0.9199 (0.9014)	grad_norm 1.6193 (1.8722)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:25:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:46 lr 0.000091	 wd 0.0000	time 0.1898 (0.2322)	loss 0.7676 (0.9008)	grad_norm 1.6767 (1.8763)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:25:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:23 lr 0.000091	 wd 0.0000	time 0.1919 (0.2310)	loss 0.9409 (0.9008)	grad_norm 1.8875 (1.8750)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:25:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000091	 wd 0.0000	time 0.1809 (0.2295)	loss 0.9019 (0.9010)	grad_norm 1.7881 (1.8765)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:25:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 5 training takes 0:09:38
[2024-07-28 10:26:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 29.558 (29.558)	Loss 0.3611 (0.3611)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 10:26:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.806 Acc@5 97.506
[2024-07-28 10:26:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-28 10:26:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.93%
[2024-07-28 10:26:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][0/2502]	eta 11:54:54 lr 0.000091	 wd 0.0000	time 17.1441 (17.1441)	loss 0.9707 (0.9707)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:27:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:14:44 lr 0.000090	 wd 0.0000	time 0.1926 (0.3683)	loss 0.8574 (0.9013)	grad_norm 1.7810 (1.8196)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:27:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:10:51 lr 0.000090	 wd 0.0000	time 0.1897 (0.2828)	loss 0.7773 (0.8988)	grad_norm 2.1453 (1.8444)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:27:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:10:07 lr 0.000090	 wd 0.0000	time 0.3881 (0.2760)	loss 0.9365 (0.9004)	grad_norm 1.7765 (1.8442)	loss_scale 32768.0000 (18561.2757)	mem 9201MB
[2024-07-28 10:28:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:10:34 lr 0.000090	 wd 0.0000	time 0.1823 (0.3021)	loss 0.8887 (0.9006)	grad_norm 1.3492 (1.8348)	loss_scale 32768.0000 (22104.0998)	mem 9201MB
[2024-07-28 10:28:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:09:24 lr 0.000090	 wd 0.0000	time 0.1892 (0.2818)	loss 0.9424 (0.8992)	grad_norm 1.7023 (inf)	loss_scale 16384.0000 (20962.3633)	mem 9201MB
[2024-07-28 10:29:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:08:30 lr 0.000090	 wd 0.0000	time 0.1958 (0.2681)	loss 0.9897 (0.8994)	grad_norm 1.8866 (inf)	loss_scale 16384.0000 (20200.5724)	mem 9201MB
[2024-07-28 10:29:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:08:14 lr 0.000090	 wd 0.0000	time 0.1917 (0.2742)	loss 0.8989 (0.9006)	grad_norm 1.5658 (inf)	loss_scale 16384.0000 (19656.1255)	mem 9201MB
[2024-07-28 10:30:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:31 lr 0.000090	 wd 0.0000	time 0.1913 (0.2653)	loss 0.8438 (0.9021)	grad_norm 1.6429 (inf)	loss_scale 16384.0000 (19247.6205)	mem 9201MB
[2024-07-28 10:30:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:06:53 lr 0.000089	 wd 0.0000	time 0.2074 (0.2579)	loss 0.8936 (0.9020)	grad_norm 1.6785 (inf)	loss_scale 16384.0000 (18929.7936)	mem 9201MB
[2024-07-28 10:30:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:18 lr 0.000089	 wd 0.0000	time 0.1900 (0.2517)	loss 0.8672 (0.9033)	grad_norm 1.4134 (inf)	loss_scale 16384.0000 (18675.4685)	mem 9201MB
[2024-07-28 10:31:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:54 lr 0.000089	 wd 0.0000	time 0.3792 (0.2532)	loss 0.8062 (0.9021)	grad_norm 1.5943 (inf)	loss_scale 16384.0000 (18467.3424)	mem 9201MB
[2024-07-28 10:31:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:35 lr 0.000089	 wd 0.0000	time 0.2010 (0.2575)	loss 0.7510 (0.9023)	grad_norm 1.7425 (inf)	loss_scale 16384.0000 (18293.8751)	mem 9201MB
[2024-07-28 10:32:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:05:04 lr 0.000089	 wd 0.0000	time 0.1802 (0.2531)	loss 0.9160 (0.9032)	grad_norm 1.7241 (inf)	loss_scale 16384.0000 (18147.0746)	mem 9201MB
[2024-07-28 10:32:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:34 lr 0.000089	 wd 0.0000	time 0.1872 (0.2492)	loss 1.0928 (0.9018)	grad_norm 2.2191 (inf)	loss_scale 16384.0000 (18021.2305)	mem 9201MB
[2024-07-28 10:32:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:07 lr 0.000089	 wd 0.0000	time 0.2092 (0.2467)	loss 0.7363 (0.9018)	grad_norm 1.5885 (inf)	loss_scale 16384.0000 (17912.1546)	mem 9201MB
[2024-07-28 10:33:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:41 lr 0.000089	 wd 0.0000	time 0.1821 (0.2453)	loss 0.9219 (0.9016)	grad_norm 1.6416 (inf)	loss_scale 16384.0000 (17816.7046)	mem 9201MB
[2024-07-28 10:33:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:14 lr 0.000088	 wd 0.0000	time 0.2157 (0.2429)	loss 0.9761 (0.9004)	grad_norm 1.8905 (inf)	loss_scale 16384.0000 (17732.4774)	mem 9201MB
[2024-07-28 10:33:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:48 lr 0.000088	 wd 0.0000	time 0.1953 (0.2406)	loss 0.7622 (0.8995)	grad_norm 1.7546 (inf)	loss_scale 16384.0000 (17657.6036)	mem 9201MB
[2024-07-28 10:34:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:23 lr 0.000088	 wd 0.0000	time 0.1838 (0.2387)	loss 1.0264 (0.8994)	grad_norm 2.1953 (inf)	loss_scale 16384.0000 (17590.6070)	mem 9201MB
[2024-07-28 10:34:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:01:59 lr 0.000088	 wd 0.0000	time 0.2099 (0.2379)	loss 1.0752 (0.9005)	grad_norm 1.8840 (inf)	loss_scale 16384.0000 (17530.3068)	mem 9201MB
[2024-07-28 10:34:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:35 lr 0.000088	 wd 0.0000	time 0.2565 (0.2375)	loss 0.8999 (0.9007)	grad_norm 2.7352 (inf)	loss_scale 16384.0000 (17475.7468)	mem 9201MB
[2024-07-28 10:35:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:11 lr 0.000088	 wd 0.0000	time 0.1852 (0.2358)	loss 0.9336 (0.9011)	grad_norm 2.3043 (inf)	loss_scale 16384.0000 (17426.1445)	mem 9201MB
[2024-07-28 10:35:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:47 lr 0.000088	 wd 0.0000	time 0.1946 (0.2343)	loss 0.9331 (0.9010)	grad_norm 1.8985 (inf)	loss_scale 16384.0000 (17380.8535)	mem 9201MB
[2024-07-28 10:35:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:23 lr 0.000087	 wd 0.0000	time 0.2175 (0.2332)	loss 0.8867 (0.9005)	grad_norm 1.7145 (inf)	loss_scale 16384.0000 (17339.3353)	mem 9201MB
[2024-07-28 10:36:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000087	 wd 0.0000	time 0.1817 (0.2317)	loss 0.8027 (0.9002)	grad_norm 1.6959 (inf)	loss_scale 16384.0000 (17301.1371)	mem 9201MB
[2024-07-28 10:36:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 6 training takes 0:09:49
[2024-07-28 10:36:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 22.254 (22.254)	Loss 0.3594 (0.3594)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 10:36:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.814 Acc@5 97.494
[2024-07-28 10:36:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-28 10:36:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.93%
[2024-07-28 10:37:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][0/2502]	eta 11:37:38 lr 0.000087	 wd 0.0000	time 16.7302 (16.7302)	loss 1.0361 (1.0361)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:37:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:19:51 lr 0.000087	 wd 0.0000	time 0.2230 (0.4959)	loss 1.0117 (0.9091)	grad_norm 1.6414 (1.9096)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:38:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:13:30 lr 0.000087	 wd 0.0000	time 0.1866 (0.3521)	loss 0.9409 (0.8967)	grad_norm 1.7987 (1.8923)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:38:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:11:01 lr 0.000087	 wd 0.0000	time 0.1826 (0.3006)	loss 0.9014 (0.8959)	grad_norm 2.1295 (1.8321)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:38:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:09:37 lr 0.000087	 wd 0.0000	time 0.1893 (0.2748)	loss 0.9761 (0.8968)	grad_norm 1.8446 (1.8717)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:39:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:09:04 lr 0.000087	 wd 0.0000	time 0.3274 (0.2721)	loss 0.8672 (0.8958)	grad_norm 2.0963 (1.8723)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:39:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:09:07 lr 0.000086	 wd 0.0000	time 0.2165 (0.2877)	loss 0.8604 (0.8967)	grad_norm 1.3871 (1.8578)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:40:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:08:15 lr 0.000086	 wd 0.0000	time 0.1983 (0.2750)	loss 0.8252 (0.8957)	grad_norm 1.7088 (1.8579)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:40:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:07:31 lr 0.000086	 wd 0.0000	time 0.1848 (0.2655)	loss 0.8999 (0.8963)	grad_norm 1.8217 (1.8512)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:40:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:07:00 lr 0.000086	 wd 0.0000	time 0.3402 (0.2625)	loss 0.7568 (0.8970)	grad_norm 1.7674 (1.8460)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:41:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:28 lr 0.000086	 wd 0.0000	time 0.1880 (0.2585)	loss 0.8662 (0.8978)	grad_norm 1.7829 (1.8403)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:41:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:54 lr 0.000086	 wd 0.0000	time 0.2033 (0.2530)	loss 0.8184 (0.8968)	grad_norm 1.7937 (1.8399)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:41:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:23 lr 0.000086	 wd 0.0000	time 0.1931 (0.2486)	loss 0.7915 (0.8974)	grad_norm 1.9089 (1.8448)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:42:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:04:54 lr 0.000085	 wd 0.0000	time 0.2184 (0.2452)	loss 0.9502 (0.8971)	grad_norm 1.6658 (1.8377)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:42:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:35 lr 0.000085	 wd 0.0000	time 0.1960 (0.2497)	loss 0.9062 (0.8981)	grad_norm 1.8031 (1.8363)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:43:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:06 lr 0.000085	 wd 0.0000	time 0.1921 (0.2464)	loss 0.8105 (0.8976)	grad_norm 1.7433 (1.8357)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:43:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:39 lr 0.000085	 wd 0.0000	time 0.1994 (0.2433)	loss 0.9736 (0.8980)	grad_norm 1.7355 (1.8354)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:43:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:13 lr 0.000085	 wd 0.0000	time 0.1896 (0.2408)	loss 0.8389 (0.8979)	grad_norm 2.1252 (1.8367)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:44:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:47 lr 0.000085	 wd 0.0000	time 0.1877 (0.2390)	loss 0.8203 (0.8971)	grad_norm 1.6563 (1.8401)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:44:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:23 lr 0.000085	 wd 0.0000	time 0.1896 (0.2389)	loss 1.0312 (0.8980)	grad_norm 1.8776 (1.8383)	loss_scale 32768.0000 (16401.2372)	mem 9201MB
[2024-07-28 10:44:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:01:59 lr 0.000084	 wd 0.0000	time 0.2138 (0.2373)	loss 0.7915 (0.8976)	grad_norm 1.6937 (1.8366)	loss_scale 32768.0000 (17219.1664)	mem 9201MB
[2024-07-28 10:45:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:34 lr 0.000084	 wd 0.0000	time 0.1879 (0.2356)	loss 0.9326 (0.8981)	grad_norm 2.0431 (inf)	loss_scale 16384.0000 (17382.1685)	mem 9201MB
[2024-07-28 10:45:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:10 lr 0.000084	 wd 0.0000	time 0.1992 (0.2343)	loss 0.8311 (0.8978)	grad_norm 2.0350 (inf)	loss_scale 16384.0000 (17336.8178)	mem 9201MB
[2024-07-28 10:45:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:47 lr 0.000084	 wd 0.0000	time 0.2044 (0.2339)	loss 0.9580 (0.8976)	grad_norm 1.9959 (inf)	loss_scale 16384.0000 (17295.4090)	mem 9201MB
[2024-07-28 10:46:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:23 lr 0.000084	 wd 0.0000	time 0.1827 (0.2329)	loss 0.8267 (0.8981)	grad_norm 1.6257 (inf)	loss_scale 16384.0000 (17257.4494)	mem 9201MB
[2024-07-28 10:46:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000084	 wd 0.0000	time 0.1835 (0.2313)	loss 0.8335 (0.8985)	grad_norm 2.2221 (inf)	loss_scale 16384.0000 (17222.5254)	mem 9201MB
[2024-07-28 10:46:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 7 training takes 0:09:42
[2024-07-28 10:47:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 22.871 (22.871)	Loss 0.3579 (0.3579)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 10:47:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.850 Acc@5 97.492
[2024-07-28 10:47:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-28 10:47:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.93%
[2024-07-28 10:47:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][0/2502]	eta 18:01:25 lr 0.000084	 wd 0.0000	time 25.9333 (25.9333)	loss 0.9873 (0.9873)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:48:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:18:14 lr 0.000083	 wd 0.0000	time 0.1793 (0.4556)	loss 0.8833 (0.9088)	grad_norm 2.0245 (1.8931)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:48:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:12:31 lr 0.000083	 wd 0.0000	time 0.1908 (0.3263)	loss 0.8740 (0.9026)	grad_norm 2.0151 (1.8841)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:48:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:10:36 lr 0.000083	 wd 0.0000	time 0.3088 (0.2892)	loss 0.9399 (0.8968)	grad_norm 2.0830 (1.8550)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:49:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:10:37 lr 0.000083	 wd 0.0000	time 0.1867 (0.3033)	loss 0.9424 (0.8970)	grad_norm 1.5501 (1.8380)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:49:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:09:26 lr 0.000083	 wd 0.0000	time 0.2113 (0.2828)	loss 0.9395 (0.8980)	grad_norm 1.6173 (1.8282)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:49:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:30 lr 0.000083	 wd 0.0000	time 0.1828 (0.2686)	loss 0.7861 (0.8982)	grad_norm 2.0982 (1.8315)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:50:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:46 lr 0.000083	 wd 0.0000	time 0.2109 (0.2590)	loss 1.0039 (0.8963)	grad_norm 1.8674 (1.8421)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:50:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:38 lr 0.000082	 wd 0.0000	time 0.2321 (0.2696)	loss 1.0010 (0.8975)	grad_norm 1.7170 (1.8530)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:51:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:59 lr 0.000082	 wd 0.0000	time 0.1810 (0.2620)	loss 0.9932 (0.8971)	grad_norm 1.3942 (1.8530)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:51:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:24 lr 0.000082	 wd 0.0000	time 0.1999 (0.2558)	loss 0.9561 (0.8981)	grad_norm 1.4532 (1.8653)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:51:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:51 lr 0.000082	 wd 0.0000	time 0.1948 (0.2507)	loss 0.8896 (0.8982)	grad_norm 1.7355 (1.8649)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:52:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:25 lr 0.000082	 wd 0.0000	time 0.1909 (0.2503)	loss 0.8896 (0.8986)	grad_norm 1.9925 (1.8600)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:52:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:56 lr 0.000082	 wd 0.0000	time 0.2071 (0.2465)	loss 0.8340 (0.8994)	grad_norm 1.9926 (1.8650)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:52:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:28 lr 0.000081	 wd 0.0000	time 0.1969 (0.2434)	loss 0.8711 (0.9001)	grad_norm 1.7921 (1.8640)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:53:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:04:01 lr 0.000081	 wd 0.0000	time 0.1895 (0.2406)	loss 0.7876 (0.8999)	grad_norm 2.1646 (1.8648)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:53:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:35 lr 0.000081	 wd 0.0000	time 0.1790 (0.2385)	loss 1.0059 (0.8999)	grad_norm 1.8711 (1.8619)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:54:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:10 lr 0.000081	 wd 0.0000	time 0.1992 (0.2381)	loss 0.8140 (0.9004)	grad_norm 1.4595 (1.8656)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:54:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:45 lr 0.000081	 wd 0.0000	time 0.1936 (0.2364)	loss 0.8281 (0.9011)	grad_norm 3.7543 (1.8684)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:54:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:21 lr 0.000081	 wd 0.0000	time 0.1851 (0.2346)	loss 0.7715 (0.9004)	grad_norm 1.7475 (1.8631)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:55:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:56 lr 0.000080	 wd 0.0000	time 0.2094 (0.2330)	loss 0.9580 (0.9003)	grad_norm 2.1796 (1.8671)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:55:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:33 lr 0.000080	 wd 0.0000	time 0.1913 (0.2319)	loss 1.0527 (0.9006)	grad_norm 1.5277 (1.8636)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:55:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:10 lr 0.000080	 wd 0.0000	time 0.2301 (0.2323)	loss 0.9375 (0.9007)	grad_norm 1.8796 (1.8622)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:56:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:46 lr 0.000080	 wd 0.0000	time 0.1847 (0.2309)	loss 0.9326 (0.9003)	grad_norm 1.9335 (1.8602)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:56:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:23 lr 0.000080	 wd 0.0000	time 0.1817 (0.2297)	loss 0.9639 (0.9003)	grad_norm 2.8144 (1.8591)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:56:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000080	 wd 0.0000	time 0.1811 (0.2282)	loss 1.0391 (0.9004)	grad_norm 1.6686 (1.8586)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:56:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 8 training takes 0:09:35
[2024-07-28 10:57:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 43.517 (43.517)	Loss 0.3662 (0.3662)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 9201MB
[2024-07-28 10:57:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.884 Acc@5 97.476
[2024-07-28 10:57:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-28 10:57:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.93%
[2024-07-28 10:58:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][0/2502]	eta 11:22:13 lr 0.000080	 wd 0.0000	time 16.3602 (16.3602)	loss 0.8174 (0.8174)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:58:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:14:41 lr 0.000079	 wd 0.0000	time 0.2466 (0.3670)	loss 0.8896 (0.8919)	grad_norm 1.8854 (1.8173)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:58:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:13:20 lr 0.000079	 wd 0.0000	time 0.2149 (0.3476)	loss 0.7988 (0.8926)	grad_norm 2.5526 (1.8206)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:59:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:55 lr 0.000079	 wd 0.0000	time 0.1822 (0.2975)	loss 0.9253 (0.8983)	grad_norm 1.6676 (1.8211)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:59:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:33 lr 0.000079	 wd 0.0000	time 0.1922 (0.2727)	loss 0.7886 (0.8958)	grad_norm 1.7362 (1.8050)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 10:59:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:08:36 lr 0.000079	 wd 0.0000	time 0.2157 (0.2581)	loss 0.7896 (0.8950)	grad_norm 1.5583 (1.8001)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 11:00:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:43 lr 0.000079	 wd 0.0000	time 0.2624 (0.2754)	loss 0.8364 (0.8936)	grad_norm 1.7996 (1.8033)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 11:00:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:58 lr 0.000078	 wd 0.0000	time 0.2150 (0.2654)	loss 0.9819 (0.8943)	grad_norm 2.0044 (1.8043)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 11:01:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:17 lr 0.000078	 wd 0.0000	time 0.1871 (0.2571)	loss 1.0137 (0.8948)	grad_norm 1.5293 (1.8023)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 11:01:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:41 lr 0.000078	 wd 0.0000	time 0.2110 (0.2507)	loss 1.0322 (0.8958)	grad_norm 1.3136 (1.8050)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 11:01:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:11 lr 0.000078	 wd 0.0000	time 0.4480 (0.2476)	loss 0.9019 (0.8962)	grad_norm 2.0167 (1.8141)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 11:02:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:41 lr 0.000078	 wd 0.0000	time 0.1985 (0.2433)	loss 0.9365 (0.8955)	grad_norm 1.8863 (1.8247)	loss_scale 32768.0000 (17544.7193)	mem 9201MB
[2024-07-28 11:02:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:12 lr 0.000078	 wd 0.0000	time 0.1910 (0.2398)	loss 0.9258 (0.8969)	grad_norm 1.7208 (1.8189)	loss_scale 32768.0000 (18812.2698)	mem 9201MB
[2024-07-28 11:02:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:44 lr 0.000077	 wd 0.0000	time 0.1934 (0.2367)	loss 0.8999 (0.8970)	grad_norm 1.6349 (inf)	loss_scale 16384.0000 (18650.8101)	mem 9201MB
[2024-07-28 11:03:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:18 lr 0.000077	 wd 0.0000	time 0.1797 (0.2344)	loss 0.9282 (0.8971)	grad_norm 1.8212 (inf)	loss_scale 16384.0000 (18489.0107)	mem 9201MB
[2024-07-28 11:03:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:03:54 lr 0.000077	 wd 0.0000	time 0.1833 (0.2342)	loss 0.8994 (0.8981)	grad_norm 1.6736 (inf)	loss_scale 16384.0000 (18348.7702)	mem 9201MB
[2024-07-28 11:04:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:29 lr 0.000077	 wd 0.0000	time 0.1841 (0.2325)	loss 0.8760 (0.8967)	grad_norm 2.0240 (inf)	loss_scale 16384.0000 (18226.0487)	mem 9201MB
[2024-07-28 11:04:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:04 lr 0.000077	 wd 0.0000	time 0.2002 (0.2306)	loss 0.8579 (0.8966)	grad_norm 1.5226 (inf)	loss_scale 16384.0000 (18117.7566)	mem 9201MB
[2024-07-28 11:04:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:40 lr 0.000077	 wd 0.0000	time 0.1860 (0.2289)	loss 0.9019 (0.8968)	grad_norm 1.6920 (inf)	loss_scale 16384.0000 (18021.4903)	mem 9201MB
[2024-07-28 11:05:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:17 lr 0.000076	 wd 0.0000	time 0.2345 (0.2278)	loss 0.9243 (0.8971)	grad_norm inf (inf)	loss_scale 8192.0000 (17926.7333)	mem 9201MB
[2024-07-28 11:05:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:01:54 lr 0.000076	 wd 0.0000	time 0.1861 (0.2284)	loss 0.8652 (0.8978)	grad_norm 1.7330 (inf)	loss_scale 8192.0000 (17440.2399)	mem 9201MB
[2024-07-28 11:05:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:31 lr 0.000076	 wd 0.0000	time 0.1906 (0.2273)	loss 0.8682 (0.8978)	grad_norm 1.6397 (inf)	loss_scale 8192.0000 (17000.0571)	mem 9201MB
[2024-07-28 11:06:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:08 lr 0.000076	 wd 0.0000	time 0.1909 (0.2261)	loss 0.7266 (0.8975)	grad_norm 2.0848 (inf)	loss_scale 8192.0000 (16599.8728)	mem 9201MB
[2024-07-28 11:06:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:45 lr 0.000076	 wd 0.0000	time 0.1933 (0.2251)	loss 0.8384 (0.8974)	grad_norm 1.7508 (inf)	loss_scale 8192.0000 (16234.4720)	mem 9201MB
[2024-07-28 11:06:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:22 lr 0.000075	 wd 0.0000	time 0.1953 (0.2251)	loss 0.9517 (0.8976)	grad_norm 1.6994 (inf)	loss_scale 8192.0000 (15899.5085)	mem 9201MB
[2024-07-28 11:07:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000075	 wd 0.0000	time 0.1804 (0.2241)	loss 0.8726 (0.8980)	grad_norm 1.4914 (inf)	loss_scale 8192.0000 (15591.3315)	mem 9201MB
[2024-07-28 11:07:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 9 training takes 0:09:25
[2024-07-28 11:07:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 19.719 (19.719)	Loss 0.3621 (0.3621)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 9201MB
[2024-07-28 11:07:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.912 Acc@5 97.498
[2024-07-28 11:07:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-28 11:07:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.93%
[2024-07-28 11:08:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][0/2502]	eta 15:21:44 lr 0.000075	 wd 0.0000	time 22.1040 (22.1040)	loss 1.0059 (1.0059)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:08:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:18:45 lr 0.000075	 wd 0.0000	time 0.2043 (0.4685)	loss 0.9849 (0.9138)	grad_norm 1.7550 (1.8557)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:08:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:12:50 lr 0.000075	 wd 0.0000	time 0.1909 (0.3346)	loss 0.9126 (0.9052)	grad_norm 1.9641 (1.8555)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:09:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:36 lr 0.000075	 wd 0.0000	time 0.1876 (0.2892)	loss 0.8955 (0.9026)	grad_norm 1.6454 (1.8598)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:09:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:19 lr 0.000075	 wd 0.0000	time 0.1830 (0.2664)	loss 0.8755 (0.9017)	grad_norm 1.9181 (1.8570)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:09:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:08:42 lr 0.000074	 wd 0.0000	time 0.8359 (0.2609)	loss 0.8042 (0.9031)	grad_norm 1.7123 (1.8636)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:10:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:27 lr 0.000074	 wd 0.0000	time 0.1791 (0.2671)	loss 0.8525 (0.9025)	grad_norm 2.0714 (1.8632)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:10:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:44 lr 0.000074	 wd 0.0000	time 0.1930 (0.2576)	loss 0.7935 (0.8998)	grad_norm 2.0122 (1.8610)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:11:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:07:05 lr 0.000074	 wd 0.0000	time 0.1922 (0.2502)	loss 0.8794 (0.9009)	grad_norm 1.5719 (1.8581)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:11:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:33 lr 0.000074	 wd 0.0000	time 0.2909 (0.2457)	loss 0.8281 (0.8999)	grad_norm 1.5107 (1.8554)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:11:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:20 lr 0.000073	 wd 0.0000	time 0.1955 (0.2533)	loss 0.9731 (0.8991)	grad_norm 1.6654 (1.8568)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:12:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:48 lr 0.000073	 wd 0.0000	time 0.2071 (0.2482)	loss 0.9805 (0.8990)	grad_norm 1.6636 (1.8577)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:12:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:17 lr 0.000073	 wd 0.0000	time 0.2047 (0.2440)	loss 1.0068 (0.8985)	grad_norm 1.6071 (1.8510)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:12:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:49 lr 0.000073	 wd 0.0000	time 0.2218 (0.2409)	loss 0.8823 (0.8986)	grad_norm 1.6905 (1.8540)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:13:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:28 lr 0.000073	 wd 0.0000	time 0.1841 (0.2436)	loss 0.8564 (0.8988)	grad_norm 1.9457 (1.8577)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:13:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:04:01 lr 0.000073	 wd 0.0000	time 0.1780 (0.2406)	loss 0.9233 (0.8988)	grad_norm 1.8084 (1.8503)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:14:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:34 lr 0.000072	 wd 0.0000	time 0.2078 (0.2382)	loss 0.7339 (0.8983)	grad_norm 1.9955 (1.8497)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:14:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:09 lr 0.000072	 wd 0.0000	time 0.1859 (0.2359)	loss 0.8555 (0.8980)	grad_norm 2.3220 (1.8470)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:14:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:44 lr 0.000072	 wd 0.0000	time 0.1847 (0.2344)	loss 0.9937 (0.8979)	grad_norm 2.0533 (1.8508)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:15:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:21 lr 0.000072	 wd 0.0000	time 0.1826 (0.2344)	loss 0.9551 (0.8992)	grad_norm 1.8424 (1.8551)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:15:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:56 lr 0.000072	 wd 0.0000	time 0.1885 (0.2329)	loss 1.0713 (0.8996)	grad_norm 2.0453 (1.8638)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:15:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:33 lr 0.000071	 wd 0.0000	time 0.2126 (0.2314)	loss 0.8721 (0.8996)	grad_norm 1.7161 (1.8632)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:16:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:09 lr 0.000071	 wd 0.0000	time 0.2046 (0.2302)	loss 0.8994 (0.8998)	grad_norm 1.7829 (1.8603)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:16:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:46 lr 0.000071	 wd 0.0000	time 0.1929 (0.2302)	loss 0.9604 (0.8995)	grad_norm 1.8955 (1.8607)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:16:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:23 lr 0.000071	 wd 0.0000	time 0.2308 (0.2294)	loss 0.9829 (0.8996)	grad_norm 2.4626 (1.8593)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:17:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000071	 wd 0.0000	time 0.1799 (0.2279)	loss 0.7764 (0.8991)	grad_norm 1.3772 (1.8607)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:17:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 10 training takes 0:09:34
[2024-07-28 11:17:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 18.968 (18.968)	Loss 0.3679 (0.3679)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 11:17:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.942 Acc@5 97.472
[2024-07-28 11:17:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-28 11:17:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.94%
[2024-07-28 11:17:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-28 11:17:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-28 11:18:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][0/2502]	eta 22:15:38 lr 0.000071	 wd 0.0000	time 32.0299 (32.0299)	loss 0.8784 (0.8784)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:18:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:20:48 lr 0.000070	 wd 0.0000	time 0.1957 (0.5199)	loss 0.8481 (0.8992)	grad_norm 2.0823 (1.8593)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:19:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:13:45 lr 0.000070	 wd 0.0000	time 0.1915 (0.3587)	loss 0.8906 (0.8995)	grad_norm 1.6199 (1.8482)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:19:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:11:15 lr 0.000070	 wd 0.0000	time 0.2425 (0.3068)	loss 0.9111 (0.8953)	grad_norm 2.2253 (1.8232)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:20:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:11:16 lr 0.000070	 wd 0.0000	time 0.2295 (0.3219)	loss 0.8745 (0.8929)	grad_norm 1.5096 (1.8227)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:20:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:09:55 lr 0.000070	 wd 0.0000	time 0.1972 (0.2975)	loss 0.8989 (0.8906)	grad_norm 2.2657 (1.8150)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:20:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:54 lr 0.000069	 wd 0.0000	time 0.2004 (0.2812)	loss 0.9717 (0.8917)	grad_norm 1.8093 (1.8234)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:21:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:08:05 lr 0.000069	 wd 0.0000	time 0.2285 (0.2697)	loss 0.8672 (0.8930)	grad_norm 2.9603 (1.8283)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:21:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:07:30 lr 0.000069	 wd 0.0000	time 1.4373 (0.2644)	loss 1.0430 (0.8935)	grad_norm 1.5845 (1.8222)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:21:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:06:51 lr 0.000069	 wd 0.0000	time 0.1933 (0.2571)	loss 0.9111 (0.8964)	grad_norm 1.9986 (1.8230)	loss_scale 16384.0000 (8246.5527)	mem 9201MB
[2024-07-28 11:22:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:17 lr 0.000069	 wd 0.0000	time 0.1962 (0.2512)	loss 0.8711 (0.8965)	grad_norm 1.7687 (1.8238)	loss_scale 16384.0000 (9059.4845)	mem 9201MB
[2024-07-28 11:22:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:45 lr 0.000069	 wd 0.0000	time 0.1884 (0.2465)	loss 0.9229 (0.8960)	grad_norm 1.6452 (1.8221)	loss_scale 16384.0000 (9724.7448)	mem 9201MB
[2024-07-28 11:22:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:16 lr 0.000068	 wd 0.0000	time 0.1942 (0.2432)	loss 0.9893 (0.8961)	grad_norm 2.1910 (inf)	loss_scale 8192.0000 (9897.2456)	mem 9201MB
[2024-07-28 11:23:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:04:56 lr 0.000068	 wd 0.0000	time 0.1872 (0.2464)	loss 0.8755 (0.8968)	grad_norm 1.6956 (inf)	loss_scale 8192.0000 (9766.1737)	mem 9201MB
[2024-07-28 11:23:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:27 lr 0.000068	 wd 0.0000	time 0.1999 (0.2431)	loss 0.8950 (0.8969)	grad_norm 1.9429 (inf)	loss_scale 8192.0000 (9653.8130)	mem 9201MB
[2024-07-28 11:23:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:04:00 lr 0.000068	 wd 0.0000	time 0.1960 (0.2401)	loss 0.8262 (0.8962)	grad_norm 1.7140 (inf)	loss_scale 8192.0000 (9556.4237)	mem 9201MB
[2024-07-28 11:24:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:34 lr 0.000068	 wd 0.0000	time 0.2031 (0.2377)	loss 0.7588 (0.8963)	grad_norm 1.7629 (inf)	loss_scale 8192.0000 (9471.2005)	mem 9201MB
[2024-07-28 11:24:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:09 lr 0.000067	 wd 0.0000	time 0.1940 (0.2361)	loss 0.9473 (0.8955)	grad_norm 1.8488 (inf)	loss_scale 8192.0000 (9395.9976)	mem 9201MB
[2024-07-28 11:24:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:45 lr 0.000067	 wd 0.0000	time 0.2085 (0.2359)	loss 0.8940 (0.8962)	grad_norm 1.6148 (inf)	loss_scale 8192.0000 (9329.1460)	mem 9201MB
[2024-07-28 11:25:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:20 lr 0.000067	 wd 0.0000	time 0.1941 (0.2342)	loss 0.8193 (0.8966)	grad_norm 1.7198 (inf)	loss_scale 8192.0000 (9269.3277)	mem 9201MB
[2024-07-28 11:25:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:01:56 lr 0.000067	 wd 0.0000	time 0.1941 (0.2327)	loss 0.6841 (0.8965)	grad_norm 2.2145 (inf)	loss_scale 8192.0000 (9215.4883)	mem 9201MB
[2024-07-28 11:25:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:33 lr 0.000067	 wd 0.0000	time 0.1885 (0.2314)	loss 1.0107 (0.8962)	grad_norm 1.7532 (inf)	loss_scale 8192.0000 (9166.7739)	mem 9201MB
[2024-07-28 11:26:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:09 lr 0.000066	 wd 0.0000	time 0.2115 (0.2309)	loss 0.9795 (0.8964)	grad_norm 1.4952 (inf)	loss_scale 8192.0000 (9122.4861)	mem 9201MB
[2024-07-28 11:26:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:46 lr 0.000066	 wd 0.0000	time 0.1911 (0.2299)	loss 0.9233 (0.8964)	grad_norm 1.7194 (inf)	loss_scale 8192.0000 (9082.0478)	mem 9201MB
[2024-07-28 11:27:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:23 lr 0.000066	 wd 0.0000	time 0.1821 (0.2287)	loss 0.8540 (0.8962)	grad_norm 2.0736 (inf)	loss_scale 8192.0000 (9044.9779)	mem 9201MB
[2024-07-28 11:27:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000066	 wd 0.0000	time 0.1886 (0.2272)	loss 0.9531 (0.8960)	grad_norm 1.8775 (inf)	loss_scale 8192.0000 (9010.8725)	mem 9201MB
[2024-07-28 11:27:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 11 training takes 0:09:34
[2024-07-28 11:28:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 39.138 (39.138)	Loss 0.3589 (0.3589)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 11:28:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.824 Acc@5 97.476
[2024-07-28 11:28:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-28 11:28:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.94%
[2024-07-28 11:28:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][0/2502]	eta 11:42:03 lr 0.000066	 wd 0.0000	time 16.8360 (16.8360)	loss 0.8867 (0.8867)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:28:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:14:27 lr 0.000066	 wd 0.0000	time 0.2178 (0.3612)	loss 0.8306 (0.8923)	grad_norm 1.6561 (1.8705)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:29:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:13:11 lr 0.000065	 wd 0.0000	time 1.3732 (0.3438)	loss 0.8496 (0.8910)	grad_norm 1.5060 (1.8702)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:29:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:57 lr 0.000065	 wd 0.0000	time 0.1926 (0.2986)	loss 0.8164 (0.8995)	grad_norm 2.4608 (1.8867)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:30:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:34 lr 0.000065	 wd 0.0000	time 0.2012 (0.2735)	loss 0.8574 (0.8996)	grad_norm 1.6646 (1.9097)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:30:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:08:36 lr 0.000065	 wd 0.0000	time 0.1825 (0.2581)	loss 0.8950 (0.9012)	grad_norm 1.7088 (1.8987)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:30:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:08:01 lr 0.000065	 wd 0.0000	time 0.3458 (0.2531)	loss 0.9238 (0.8988)	grad_norm 1.7339 (1.8826)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:31:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:48 lr 0.000064	 wd 0.0000	time 0.1855 (0.2599)	loss 0.8687 (0.8995)	grad_norm 2.0542 (1.8830)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:31:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:07:09 lr 0.000064	 wd 0.0000	time 0.1831 (0.2524)	loss 1.0908 (0.8991)	grad_norm 1.5461 (1.8678)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:32:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:34 lr 0.000064	 wd 0.0000	time 0.1779 (0.2464)	loss 1.0342 (0.8987)	grad_norm 1.5328 (1.8582)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:32:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:04 lr 0.000064	 wd 0.0000	time 0.1924 (0.2424)	loss 0.8628 (0.8991)	grad_norm 2.4486 (1.8558)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:32:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:51 lr 0.000064	 wd 0.0000	time 0.2004 (0.2504)	loss 0.8433 (0.9002)	grad_norm 1.6799 (1.8566)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:33:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:20 lr 0.000063	 wd 0.0000	time 0.1828 (0.2460)	loss 0.9331 (0.9001)	grad_norm 1.8386 (1.8543)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:33:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:51 lr 0.000063	 wd 0.0000	time 0.1946 (0.2423)	loss 0.8945 (0.9001)	grad_norm 2.1624 (1.8630)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:33:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:23 lr 0.000063	 wd 0.0000	time 0.1895 (0.2394)	loss 1.0879 (0.9005)	grad_norm 2.1369 (1.8654)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:34:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:03:59 lr 0.000063	 wd 0.0000	time 1.7548 (0.2389)	loss 0.9395 (0.9007)	grad_norm 1.6751 (1.8668)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:34:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:33 lr 0.000063	 wd 0.0000	time 0.1823 (0.2367)	loss 0.9238 (0.8997)	grad_norm 1.9503 (1.8639)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:35:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:08 lr 0.000062	 wd 0.0000	time 0.1947 (0.2347)	loss 0.9873 (0.8996)	grad_norm 1.6537 (1.8636)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:35:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:43 lr 0.000062	 wd 0.0000	time 0.2049 (0.2328)	loss 0.7832 (0.8995)	grad_norm 2.1583 (1.8609)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:35:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:19 lr 0.000062	 wd 0.0000	time 0.2203 (0.2314)	loss 0.8452 (0.8997)	grad_norm 1.4655 (1.8622)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:36:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:01:56 lr 0.000062	 wd 0.0000	time 0.2184 (0.2318)	loss 0.8911 (0.9001)	grad_norm 1.7606 (1.8600)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:36:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:32 lr 0.000062	 wd 0.0000	time 0.2023 (0.2308)	loss 0.9893 (0.9006)	grad_norm 1.4906 (1.8600)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:36:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:09 lr 0.000061	 wd 0.0000	time 0.1942 (0.2295)	loss 1.0195 (0.9005)	grad_norm 1.9535 (1.8601)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:37:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:46 lr 0.000061	 wd 0.0000	time 0.2303 (0.2282)	loss 0.8193 (0.9002)	grad_norm 1.7210 (1.8608)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:37:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:23 lr 0.000061	 wd 0.0000	time 0.2137 (0.2273)	loss 0.8491 (0.8999)	grad_norm 1.7232 (1.8627)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:37:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000061	 wd 0.0000	time 0.1809 (0.2267)	loss 0.8281 (0.8999)	grad_norm 1.8599 (1.8640)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:37:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 12 training takes 0:09:38
[2024-07-28 11:38:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 20.130 (20.130)	Loss 0.3647 (0.3647)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 11:38:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.960 Acc@5 97.466
[2024-07-28 11:38:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-28 11:38:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.96%
[2024-07-28 11:38:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-28 11:38:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-28 11:39:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][0/2502]	eta 18:55:35 lr 0.000061	 wd 0.0000	time 27.2326 (27.2326)	loss 0.7681 (0.7681)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:39:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:19:49 lr 0.000061	 wd 0.0000	time 0.1816 (0.4951)	loss 0.8198 (0.8965)	grad_norm 1.7933 (1.8180)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 11:39:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:13:17 lr 0.000060	 wd 0.0000	time 0.1982 (0.3464)	loss 0.7769 (0.8935)	grad_norm 1.8277 (1.8464)	loss_scale 16384.0000 (10637.3731)	mem 9201MB
[2024-07-28 11:40:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:10:53 lr 0.000060	 wd 0.0000	time 0.1877 (0.2967)	loss 0.8813 (0.8894)	grad_norm 1.5138 (1.8532)	loss_scale 16384.0000 (12546.5515)	mem 9201MB
[2024-07-28 11:40:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:09:33 lr 0.000060	 wd 0.0000	time 0.2100 (0.2729)	loss 0.9438 (0.8936)	grad_norm 2.4272 (1.8488)	loss_scale 16384.0000 (13503.5212)	mem 9201MB
[2024-07-28 11:41:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:09:47 lr 0.000060	 wd 0.0000	time 0.1832 (0.2934)	loss 0.9033 (0.8921)	grad_norm 2.0467 (1.8400)	loss_scale 16384.0000 (14078.4671)	mem 9201MB
[2024-07-28 11:41:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:48 lr 0.000060	 wd 0.0000	time 0.1872 (0.2778)	loss 0.8926 (0.8907)	grad_norm 2.0440 (1.8374)	loss_scale 16384.0000 (14462.0832)	mem 9201MB
[2024-07-28 11:41:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:08:00 lr 0.000059	 wd 0.0000	time 0.1821 (0.2666)	loss 0.8325 (0.8910)	grad_norm 1.7376 (1.8421)	loss_scale 16384.0000 (14736.2511)	mem 9201MB
[2024-07-28 11:42:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:20 lr 0.000059	 wd 0.0000	time 0.2271 (0.2591)	loss 0.9243 (0.8910)	grad_norm 1.5777 (1.8441)	loss_scale 16384.0000 (14941.9625)	mem 9201MB
[2024-07-28 11:42:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:06:48 lr 0.000059	 wd 0.0000	time 0.1980 (0.2551)	loss 0.8672 (0.8927)	grad_norm 2.0804 (1.8454)	loss_scale 16384.0000 (15102.0111)	mem 9201MB
[2024-07-28 11:42:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:14 lr 0.000059	 wd 0.0000	time 0.1975 (0.2494)	loss 0.9253 (0.8948)	grad_norm 1.6328 (1.8356)	loss_scale 16384.0000 (15230.0819)	mem 9201MB
[2024-07-28 11:43:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:43 lr 0.000059	 wd 0.0000	time 0.2147 (0.2447)	loss 0.9048 (0.8948)	grad_norm 1.4754 (1.8369)	loss_scale 16384.0000 (15334.8883)	mem 9201MB
[2024-07-28 11:43:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:13 lr 0.000058	 wd 0.0000	time 0.2082 (0.2411)	loss 1.0195 (0.8944)	grad_norm 1.4469 (1.8352)	loss_scale 16384.0000 (15422.2415)	mem 9201MB
[2024-07-28 11:43:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:04:48 lr 0.000058	 wd 0.0000	time 0.2865 (0.2398)	loss 0.9629 (0.8946)	grad_norm 1.7899 (1.8424)	loss_scale 16384.0000 (15496.1660)	mem 9201MB
[2024-07-28 11:44:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:28 lr 0.000058	 wd 0.0000	time 0.1885 (0.2437)	loss 0.9209 (0.8937)	grad_norm 2.4515 (1.8378)	loss_scale 16384.0000 (15559.5375)	mem 9201MB
[2024-07-28 11:44:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:04:01 lr 0.000058	 wd 0.0000	time 0.1982 (0.2407)	loss 0.8457 (0.8949)	grad_norm 1.6838 (1.8399)	loss_scale 16384.0000 (15614.4650)	mem 9201MB
[2024-07-28 11:44:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:34 lr 0.000058	 wd 0.0000	time 0.1978 (0.2380)	loss 0.7163 (0.8954)	grad_norm 1.5742 (1.8375)	loss_scale 16384.0000 (15662.5309)	mem 9201MB
[2024-07-28 11:45:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:09 lr 0.000057	 wd 0.0000	time 0.1777 (0.2360)	loss 0.8579 (0.8961)	grad_norm 2.0468 (1.8347)	loss_scale 16384.0000 (15704.9453)	mem 9201MB
[2024-07-28 11:45:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:45 lr 0.000057	 wd 0.0000	time 0.1961 (0.2357)	loss 0.9077 (0.8966)	grad_norm 1.7182 (1.8353)	loss_scale 16384.0000 (15742.6496)	mem 9201MB
[2024-07-28 11:46:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:21 lr 0.000057	 wd 0.0000	time 0.1873 (0.2344)	loss 0.7778 (0.8959)	grad_norm 1.7178 (1.8349)	loss_scale 16384.0000 (15776.3872)	mem 9201MB
[2024-07-28 11:46:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:56 lr 0.000057	 wd 0.0000	time 0.1802 (0.2328)	loss 0.9009 (0.8955)	grad_norm 2.0773 (1.8388)	loss_scale 16384.0000 (15806.7526)	mem 9201MB
[2024-07-28 11:46:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:32 lr 0.000057	 wd 0.0000	time 0.1785 (0.2313)	loss 0.9077 (0.8959)	grad_norm 2.0493 (1.8452)	loss_scale 16384.0000 (15834.2275)	mem 9201MB
[2024-07-28 11:47:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:09 lr 0.000056	 wd 0.0000	time 0.2177 (0.2302)	loss 0.8218 (0.8956)	grad_norm 1.8060 (1.8486)	loss_scale 16384.0000 (15859.2058)	mem 9201MB
[2024-07-28 11:47:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:46 lr 0.000056	 wd 0.0000	time 0.1998 (0.2304)	loss 0.9360 (0.8957)	grad_norm 1.5525 (1.8528)	loss_scale 16384.0000 (15882.0130)	mem 9201MB
[2024-07-28 11:47:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:23 lr 0.000056	 wd 0.0000	time 0.2072 (0.2293)	loss 0.8677 (0.8957)	grad_norm 2.0067 (1.8562)	loss_scale 16384.0000 (15902.9204)	mem 9201MB
[2024-07-28 11:48:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000056	 wd 0.0000	time 0.1777 (0.2279)	loss 0.8340 (0.8956)	grad_norm 1.9189 (1.8570)	loss_scale 16384.0000 (15922.1559)	mem 9201MB
[2024-07-28 11:48:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 13 training takes 0:09:38
[2024-07-28 11:48:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 40.754 (40.754)	Loss 0.3647 (0.3647)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 11:49:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.966 Acc@5 97.516
[2024-07-28 11:49:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-28 11:49:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.97%
[2024-07-28 11:49:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-28 11:49:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-28 11:49:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][0/2502]	eta 10:20:16 lr 0.000056	 wd 0.0000	time 14.8748 (14.8748)	loss 0.8726 (0.8726)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 11:49:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:14:00 lr 0.000055	 wd 0.0000	time 0.1876 (0.3498)	loss 0.8882 (0.8979)	grad_norm 2.0484 (1.9195)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 11:50:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:10:58 lr 0.000055	 wd 0.0000	time 0.2808 (0.2862)	loss 0.8823 (0.8905)	grad_norm 1.7194 (1.8624)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 11:50:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:10:59 lr 0.000055	 wd 0.0000	time 0.1826 (0.2997)	loss 0.9590 (0.8929)	grad_norm 2.1126 (1.8486)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 11:51:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:09:37 lr 0.000055	 wd 0.0000	time 0.1938 (0.2745)	loss 1.0869 (0.8930)	grad_norm 1.5068 (1.8181)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 11:51:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:08:38 lr 0.000055	 wd 0.0000	time 0.1855 (0.2592)	loss 0.8916 (0.8923)	grad_norm 1.5353 (1.8186)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 11:51:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:07:56 lr 0.000054	 wd 0.0000	time 0.2346 (0.2505)	loss 0.8286 (0.8941)	grad_norm 1.4649 (1.8241)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 11:52:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:46 lr 0.000054	 wd 0.0000	time 0.1836 (0.2587)	loss 0.7959 (0.8961)	grad_norm 1.3472 (1.8251)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 11:52:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:07 lr 0.000054	 wd 0.0000	time 0.1983 (0.2513)	loss 0.9224 (0.8940)	grad_norm 1.7387 (1.8241)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 11:52:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:33 lr 0.000054	 wd 0.0000	time 0.1986 (0.2455)	loss 0.9644 (0.8936)	grad_norm 1.5352 (inf)	loss_scale 8192.0000 (15783.9201)	mem 9201MB
[2024-07-28 11:53:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:06:01 lr 0.000054	 wd 0.0000	time 0.2266 (0.2408)	loss 1.0068 (0.8932)	grad_norm 1.5950 (inf)	loss_scale 8192.0000 (15025.4865)	mem 9201MB
[2024-07-28 11:53:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:46 lr 0.000053	 wd 0.0000	time 0.2274 (0.2471)	loss 0.7861 (0.8937)	grad_norm 1.8491 (inf)	loss_scale 8192.0000 (14404.8247)	mem 9201MB
[2024-07-28 11:54:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:16 lr 0.000053	 wd 0.0000	time 0.1917 (0.2431)	loss 0.9722 (0.8944)	grad_norm 1.7782 (inf)	loss_scale 8192.0000 (13887.5204)	mem 9201MB
[2024-07-28 11:54:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:04:48 lr 0.000053	 wd 0.0000	time 0.1880 (0.2396)	loss 0.9478 (0.8942)	grad_norm 1.9649 (inf)	loss_scale 8192.0000 (13449.7402)	mem 9201MB
[2024-07-28 11:54:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:20 lr 0.000053	 wd 0.0000	time 0.2026 (0.2368)	loss 0.8545 (0.8935)	grad_norm 2.6449 (inf)	loss_scale 8192.0000 (13074.4554)	mem 9201MB
[2024-07-28 11:55:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:03:55 lr 0.000053	 wd 0.0000	time 0.1787 (0.2354)	loss 0.9712 (0.8934)	grad_norm 1.8686 (inf)	loss_scale 8192.0000 (12749.1752)	mem 9201MB
[2024-07-28 11:55:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:31 lr 0.000052	 wd 0.0000	time 0.1843 (0.2349)	loss 0.9443 (0.8939)	grad_norm 1.4316 (inf)	loss_scale 8192.0000 (12464.5297)	mem 9201MB
[2024-07-28 11:55:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:06 lr 0.000052	 wd 0.0000	time 0.1897 (0.2331)	loss 1.0059 (0.8940)	grad_norm 1.5594 (inf)	loss_scale 8192.0000 (12213.3521)	mem 9201MB
[2024-07-28 11:56:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:42 lr 0.000052	 wd 0.0000	time 0.1782 (0.2312)	loss 0.9849 (0.8940)	grad_norm 1.7935 (inf)	loss_scale 8192.0000 (11990.0677)	mem 9201MB
[2024-07-28 11:56:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:18 lr 0.000052	 wd 0.0000	time 0.2057 (0.2298)	loss 0.9150 (0.8940)	grad_norm 1.4984 (inf)	loss_scale 8192.0000 (11790.2746)	mem 9201MB
[2024-07-28 11:56:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:01:55 lr 0.000052	 wd 0.0000	time 0.1896 (0.2302)	loss 0.9502 (0.8944)	grad_norm 2.0330 (inf)	loss_scale 8192.0000 (11610.4508)	mem 9201MB
[2024-07-28 11:57:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:32 lr 0.000051	 wd 0.0000	time 0.1914 (0.2293)	loss 0.9043 (0.8950)	grad_norm 1.6957 (inf)	loss_scale 8192.0000 (11447.7449)	mem 9201MB
[2024-07-28 11:57:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:08 lr 0.000051	 wd 0.0000	time 0.1822 (0.2281)	loss 0.8232 (0.8957)	grad_norm 1.7795 (inf)	loss_scale 8192.0000 (11299.8237)	mem 9201MB
[2024-07-28 11:57:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:45 lr 0.000051	 wd 0.0000	time 0.1906 (0.2269)	loss 0.9434 (0.8960)	grad_norm 2.0758 (inf)	loss_scale 8192.0000 (11164.7597)	mem 9201MB
[2024-07-28 11:58:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:23 lr 0.000051	 wd 0.0000	time 0.1884 (0.2261)	loss 0.9155 (0.8962)	grad_norm 1.4717 (inf)	loss_scale 8192.0000 (11040.9463)	mem 9201MB
[2024-07-28 11:58:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000051	 wd 0.0000	time 0.1799 (0.2248)	loss 0.8604 (0.8961)	grad_norm 1.6719 (inf)	loss_scale 8192.0000 (10927.0340)	mem 9201MB
[2024-07-28 11:58:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 14 training takes 0:09:36
[2024-07-28 11:59:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 21.489 (21.489)	Loss 0.3621 (0.3621)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 11:59:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.950 Acc@5 97.510
[2024-07-28 11:59:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-28 11:59:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.97%
[2024-07-28 11:59:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][0/2502]	eta 15:27:10 lr 0.000051	 wd 0.0000	time 22.2343 (22.2343)	loss 0.7852 (0.7852)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:00:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:18:57 lr 0.000050	 wd 0.0000	time 0.2199 (0.4734)	loss 0.8955 (0.8938)	grad_norm 1.7257 (1.8154)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:00:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:12:54 lr 0.000050	 wd 0.0000	time 0.1917 (0.3363)	loss 1.1328 (0.8969)	grad_norm 1.5755 (1.8639)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:00:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:10:37 lr 0.000050	 wd 0.0000	time 0.1961 (0.2897)	loss 0.8237 (0.8972)	grad_norm 1.7028 (1.8579)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:01:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:09:20 lr 0.000050	 wd 0.0000	time 0.2021 (0.2668)	loss 0.7275 (0.8971)	grad_norm 1.6749 (1.8435)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:01:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:09:39 lr 0.000049	 wd 0.0000	time 0.4478 (0.2892)	loss 0.8496 (0.8977)	grad_norm 2.0094 (1.8401)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:02:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:08:56 lr 0.000049	 wd 0.0000	time 0.1818 (0.2819)	loss 0.8247 (0.8974)	grad_norm 1.6406 (1.8441)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:02:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:08:06 lr 0.000049	 wd 0.0000	time 0.1941 (0.2701)	loss 0.9023 (0.8966)	grad_norm 1.3990 (1.8480)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:03:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:07:25 lr 0.000049	 wd 0.0000	time 0.2198 (0.2617)	loss 0.8843 (0.8960)	grad_norm 1.6690 (1.8516)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:03:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:07:23 lr 0.000049	 wd 0.0000	time 0.1998 (0.2767)	loss 0.8589 (0.8959)	grad_norm 1.5062 (1.8484)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:04:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:06:44 lr 0.000048	 wd 0.0000	time 0.2392 (0.2691)	loss 0.8442 (0.8961)	grad_norm 1.7698 (1.8482)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:04:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:06:08 lr 0.000048	 wd 0.0000	time 0.2092 (0.2627)	loss 0.9609 (0.8946)	grad_norm 1.9941 (1.8460)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:04:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:35 lr 0.000048	 wd 0.0000	time 0.2095 (0.2577)	loss 0.7495 (0.8946)	grad_norm 1.5455 (1.8525)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:05:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:05:05 lr 0.000048	 wd 0.0000	time 0.1951 (0.2542)	loss 0.9292 (0.8951)	grad_norm 1.9585 (1.8583)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:05:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:36 lr 0.000048	 wd 0.0000	time 0.2021 (0.2512)	loss 0.8711 (0.8949)	grad_norm 1.6402 (1.8581)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:05:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:04:08 lr 0.000047	 wd 0.0000	time 0.1904 (0.2480)	loss 0.8799 (0.8945)	grad_norm 1.7926 (1.8537)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:06:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:41 lr 0.000047	 wd 0.0000	time 0.1832 (0.2450)	loss 0.9209 (0.8943)	grad_norm 1.8620 (1.8530)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:06:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:14 lr 0.000047	 wd 0.0000	time 0.1973 (0.2429)	loss 0.9126 (0.8940)	grad_norm 2.1810 (1.8568)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:06:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:49 lr 0.000047	 wd 0.0000	time 0.2241 (0.2421)	loss 0.9727 (0.8949)	grad_norm 2.0609 (1.8587)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:07:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:24 lr 0.000047	 wd 0.0000	time 0.1896 (0.2402)	loss 0.9917 (0.8949)	grad_norm 1.8539 (1.8566)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:07:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:01:59 lr 0.000046	 wd 0.0000	time 0.1893 (0.2382)	loss 1.0098 (0.8949)	grad_norm 2.3389 (1.8574)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:07:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:35 lr 0.000046	 wd 0.0000	time 0.1940 (0.2365)	loss 0.9590 (0.8947)	grad_norm 1.5860 (1.8549)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:08:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:11 lr 0.000046	 wd 0.0000	time 0.2072 (0.2353)	loss 0.8604 (0.8950)	grad_norm 1.9334 (1.8563)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:08:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:47 lr 0.000046	 wd 0.0000	time 0.2245 (0.2355)	loss 1.0215 (0.8947)	grad_norm 1.8838 (1.8518)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:08:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:23 lr 0.000046	 wd 0.0000	time 0.1953 (0.2341)	loss 0.8691 (0.8945)	grad_norm 1.7785 (1.8534)	loss_scale 16384.0000 (8424.0100)	mem 9201MB
[2024-07-28 12:09:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000045	 wd 0.0000	time 0.1830 (0.2324)	loss 1.0684 (0.8948)	grad_norm 1.7763 (inf)	loss_scale 8192.0000 (8657.1196)	mem 9201MB
[2024-07-28 12:09:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 15 training takes 0:09:48
[2024-07-28 12:09:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_15.pth saving......
[2024-07-28 12:09:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_15.pth saved !!!
[2024-07-28 12:10:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 38.660 (38.660)	Loss 0.3621 (0.3621)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 9201MB
[2024-07-28 12:10:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.994 Acc@5 97.494
[2024-07-28 12:10:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-28 12:10:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.99%
[2024-07-28 12:10:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-28 12:10:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-28 12:10:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][0/2502]	eta 10:09:12 lr 0.000045	 wd 0.0000	time 14.6093 (14.6093)	loss 0.8115 (0.8115)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:10:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:13:51 lr 0.000045	 wd 0.0000	time 0.2098 (0.3462)	loss 1.0732 (0.9064)	grad_norm 1.5876 (1.8186)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:11:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:11:18 lr 0.000045	 wd 0.0000	time 0.3795 (0.2947)	loss 0.9365 (0.9036)	grad_norm 1.9238 (1.8216)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:11:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:10:48 lr 0.000045	 wd 0.0000	time 0.1813 (0.2944)	loss 0.8940 (0.9027)	grad_norm 1.7801 (1.8359)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:12:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:09:27 lr 0.000045	 wd 0.0000	time 0.1900 (0.2701)	loss 0.9526 (0.9001)	grad_norm 1.6237 (1.8559)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:12:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:08:31 lr 0.000044	 wd 0.0000	time 0.1888 (0.2555)	loss 0.8623 (0.8979)	grad_norm 2.0534 (1.8942)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:12:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:07:51 lr 0.000044	 wd 0.0000	time 0.2160 (0.2477)	loss 0.9492 (0.8994)	grad_norm 1.7520 (1.8989)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:13:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:50 lr 0.000044	 wd 0.0000	time 0.1986 (0.2613)	loss 0.9287 (0.8985)	grad_norm 1.8844 (1.9033)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:13:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:07:11 lr 0.000044	 wd 0.0000	time 0.2067 (0.2534)	loss 1.0420 (0.8977)	grad_norm 1.7549 (1.8946)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:14:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:36 lr 0.000043	 wd 0.0000	time 0.1896 (0.2474)	loss 0.8584 (0.8993)	grad_norm 4.2138 (1.9016)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:14:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:06:05 lr 0.000043	 wd 0.0000	time 0.1985 (0.2432)	loss 0.9053 (0.9009)	grad_norm 1.7670 (1.8995)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:14:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:40 lr 0.000043	 wd 0.0000	time 0.2048 (0.2426)	loss 0.8096 (0.8996)	grad_norm 1.9013 (1.9007)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:15:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:11 lr 0.000043	 wd 0.0000	time 0.1923 (0.2395)	loss 0.9922 (0.9004)	grad_norm 1.6026 (1.9068)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:15:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:04:44 lr 0.000043	 wd 0.0000	time 0.1893 (0.2365)	loss 0.8789 (0.8987)	grad_norm 1.8328 (1.9050)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:15:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:17 lr 0.000042	 wd 0.0000	time 0.2155 (0.2339)	loss 0.8550 (0.8977)	grad_norm 1.8717 (1.9014)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:16:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:03:53 lr 0.000042	 wd 0.0000	time 0.2358 (0.2327)	loss 0.9160 (0.8973)	grad_norm 1.5958 (1.9021)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:16:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:30 lr 0.000042	 wd 0.0000	time 0.2259 (0.2329)	loss 0.8794 (0.8974)	grad_norm 1.8302 (1.9005)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:16:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:05 lr 0.000042	 wd 0.0000	time 0.1916 (0.2311)	loss 0.7705 (0.8978)	grad_norm 1.8424 (1.8962)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:17:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:41 lr 0.000042	 wd 0.0000	time 0.1816 (0.2294)	loss 0.9565 (0.8981)	grad_norm 1.7297 (1.8903)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:17:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:17 lr 0.000041	 wd 0.0000	time 0.1989 (0.2282)	loss 0.9741 (0.8982)	grad_norm 1.9290 (1.8879)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:17:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:01:54 lr 0.000041	 wd 0.0000	time 0.1979 (0.2286)	loss 0.8359 (0.8976)	grad_norm 1.4444 (1.8858)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:18:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:31 lr 0.000041	 wd 0.0000	time 0.2312 (0.2278)	loss 0.8013 (0.8973)	grad_norm 1.4543 (1.8818)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:18:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:08 lr 0.000041	 wd 0.0000	time 0.1795 (0.2266)	loss 0.8149 (0.8974)	grad_norm 1.4730 (1.8846)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:18:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:45 lr 0.000041	 wd 0.0000	time 0.2335 (0.2254)	loss 0.9526 (0.8973)	grad_norm 2.3580 (1.8851)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:19:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:22 lr 0.000040	 wd 0.0000	time 0.1941 (0.2246)	loss 0.7720 (0.8969)	grad_norm 1.6976 (1.8835)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:19:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1804 (0.2235)	loss 0.8726 (0.8965)	grad_norm 1.9298 (1.8832)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:19:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 16 training takes 0:09:32
[2024-07-28 12:20:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 19.137 (19.137)	Loss 0.3579 (0.3579)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 9201MB
[2024-07-28 12:20:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.934 Acc@5 97.518
[2024-07-28 12:20:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-28 12:20:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.99%
[2024-07-28 12:20:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][0/2502]	eta 14:58:35 lr 0.000040	 wd 0.0000	time 21.5490 (21.5490)	loss 0.8281 (0.8281)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:21:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:18:08 lr 0.000040	 wd 0.0000	time 0.2121 (0.4531)	loss 0.9639 (0.8928)	grad_norm 1.5888 (1.9308)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:21:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:12:31 lr 0.000040	 wd 0.0000	time 0.1931 (0.3266)	loss 1.0664 (0.9007)	grad_norm 1.4419 (1.8972)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:21:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:25 lr 0.000040	 wd 0.0000	time 0.1837 (0.2839)	loss 0.9126 (0.9002)	grad_norm 1.5936 (1.8864)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:22:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:09:11 lr 0.000039	 wd 0.0000	time 0.1924 (0.2625)	loss 0.8667 (0.8934)	grad_norm 1.5273 (1.8800)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:22:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:08:35 lr 0.000039	 wd 0.0000	time 0.3147 (0.2576)	loss 0.8188 (0.8953)	grad_norm 1.6943 (1.8802)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:23:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:22 lr 0.000039	 wd 0.0000	time 0.1955 (0.2641)	loss 0.9380 (0.8969)	grad_norm 2.3418 (1.8898)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:23:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:39 lr 0.000039	 wd 0.0000	time 0.1903 (0.2547)	loss 0.7783 (0.8953)	grad_norm 1.4936 (1.8898)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:23:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:07:01 lr 0.000039	 wd 0.0000	time 0.2003 (0.2476)	loss 0.8027 (0.8951)	grad_norm 1.9951 (1.8861)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:24:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:29 lr 0.000038	 wd 0.0000	time 0.2145 (0.2434)	loss 0.8472 (0.8953)	grad_norm 1.8894 (1.8806)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:24:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:03 lr 0.000038	 wd 0.0000	time 0.2111 (0.2421)	loss 0.9536 (0.8947)	grad_norm 1.8049 (1.8838)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:24:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:34 lr 0.000038	 wd 0.0000	time 0.1857 (0.2385)	loss 0.9575 (0.8962)	grad_norm 1.6352 (1.8848)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:25:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:06 lr 0.000038	 wd 0.0000	time 0.1993 (0.2354)	loss 0.9346 (0.8968)	grad_norm 1.9336 (1.8846)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:25:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:04:39 lr 0.000038	 wd 0.0000	time 0.2001 (0.2328)	loss 1.0186 (0.8953)	grad_norm 1.8846 (1.8876)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:25:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:15 lr 0.000037	 wd 0.0000	time 0.1901 (0.2314)	loss 0.8413 (0.8959)	grad_norm 1.5703 (1.8865)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:26:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:03:51 lr 0.000037	 wd 0.0000	time 0.1874 (0.2311)	loss 0.8530 (0.8961)	grad_norm 1.9903 (1.8821)	loss_scale 16384.0000 (8355.7308)	mem 9201MB
[2024-07-28 12:26:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:26 lr 0.000037	 wd 0.0000	time 0.1834 (0.2293)	loss 0.8052 (0.8958)	grad_norm 1.9439 (1.8848)	loss_scale 16384.0000 (8857.1843)	mem 9201MB
[2024-07-28 12:26:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:02 lr 0.000037	 wd 0.0000	time 0.1942 (0.2276)	loss 1.1504 (0.8960)	grad_norm 1.9734 (1.8922)	loss_scale 16384.0000 (9299.6778)	mem 9201MB
[2024-07-28 12:27:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:38 lr 0.000037	 wd 0.0000	time 0.1987 (0.2262)	loss 0.8477 (0.8963)	grad_norm 1.5265 (1.8896)	loss_scale 16384.0000 (9693.0328)	mem 9201MB
[2024-07-28 12:27:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:16 lr 0.000036	 wd 0.0000	time 0.1802 (0.2267)	loss 0.8096 (0.8965)	grad_norm 1.8024 (1.8888)	loss_scale 16384.0000 (10045.0037)	mem 9201MB
[2024-07-28 12:28:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:01:53 lr 0.000036	 wd 0.0000	time 0.2013 (0.2260)	loss 0.8794 (0.8960)	grad_norm 2.3167 (1.8864)	loss_scale 16384.0000 (10361.7951)	mem 9201MB
[2024-07-28 12:28:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:30 lr 0.000036	 wd 0.0000	time 0.1880 (0.2249)	loss 0.8965 (0.8961)	grad_norm 2.1697 (1.8889)	loss_scale 16384.0000 (10648.4303)	mem 9201MB
[2024-07-28 12:28:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:07 lr 0.000036	 wd 0.0000	time 0.1942 (0.2237)	loss 0.9219 (0.8962)	grad_norm 2.9122 (1.8905)	loss_scale 16384.0000 (10909.0195)	mem 9201MB
[2024-07-28 12:29:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:45 lr 0.000036	 wd 0.0000	time 0.1912 (0.2233)	loss 0.8853 (0.8958)	grad_norm 2.0577 (1.8884)	loss_scale 16384.0000 (11146.9587)	mem 9201MB
[2024-07-28 12:29:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:22 lr 0.000035	 wd 0.0000	time 0.2058 (0.2235)	loss 0.8037 (0.8967)	grad_norm 2.4311 (1.8848)	loss_scale 16384.0000 (11365.0779)	mem 9201MB
[2024-07-28 12:29:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1833 (0.2224)	loss 1.0508 (0.8971)	grad_norm 2.0492 (1.8855)	loss_scale 16384.0000 (11565.7545)	mem 9201MB
[2024-07-28 12:29:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 17 training takes 0:09:23
[2024-07-28 12:30:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 18.834 (18.834)	Loss 0.3662 (0.3662)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 12:30:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.890 Acc@5 97.502
[2024-07-28 12:30:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-28 12:30:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.99%
[2024-07-28 12:31:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][0/2502]	eta 1 day, 1:56:51 lr 0.000035	 wd 0.0000	time 37.3348 (37.3348)	loss 0.9229 (0.9229)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:31:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:22:51 lr 0.000035	 wd 0.0000	time 0.1828 (0.5710)	loss 0.8799 (0.8879)	grad_norm 2.1388 (1.9924)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:31:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:14:49 lr 0.000035	 wd 0.0000	time 0.1809 (0.3866)	loss 1.0059 (0.8883)	grad_norm 1.7389 (1.9240)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:32:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:12:04 lr 0.000035	 wd 0.0000	time 0.2872 (0.3289)	loss 0.9561 (0.8927)	grad_norm 1.7550 (1.9096)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:32:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:11:37 lr 0.000034	 wd 0.0000	time 0.1887 (0.3319)	loss 0.9165 (0.8962)	grad_norm 1.9511 (1.9144)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:33:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:10:11 lr 0.000034	 wd 0.0000	time 0.2534 (0.3056)	loss 0.8169 (0.8964)	grad_norm 2.0364 (1.9003)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:33:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:09:06 lr 0.000034	 wd 0.0000	time 0.1867 (0.2875)	loss 0.8081 (0.8946)	grad_norm 1.7328 (inf)	loss_scale 8192.0000 (16165.9101)	mem 9201MB
[2024-07-28 12:33:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:08:16 lr 0.000034	 wd 0.0000	time 0.2062 (0.2755)	loss 1.0684 (0.8943)	grad_norm 1.7373 (inf)	loss_scale 8192.0000 (15028.4051)	mem 9201MB
[2024-07-28 12:34:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:08:01 lr 0.000034	 wd 0.0000	time 0.1841 (0.2831)	loss 0.9458 (0.8921)	grad_norm 2.2969 (inf)	loss_scale 8192.0000 (14174.9213)	mem 9201MB
[2024-07-28 12:34:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:07:18 lr 0.000033	 wd 0.0000	time 0.2024 (0.2737)	loss 0.9189 (0.8919)	grad_norm 2.0783 (inf)	loss_scale 8192.0000 (13510.8901)	mem 9201MB
[2024-07-28 12:34:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:39 lr 0.000033	 wd 0.0000	time 0.1811 (0.2662)	loss 0.8057 (0.8917)	grad_norm 1.6621 (inf)	loss_scale 8192.0000 (12979.5325)	mem 9201MB
[2024-07-28 12:35:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:06:04 lr 0.000033	 wd 0.0000	time 0.2049 (0.2602)	loss 0.8984 (0.8931)	grad_norm 1.5831 (inf)	loss_scale 8192.0000 (12544.6975)	mem 9201MB
[2024-07-28 12:35:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:50 lr 0.000033	 wd 0.0000	time 0.1953 (0.2692)	loss 1.1709 (0.8925)	grad_norm 1.8840 (inf)	loss_scale 8192.0000 (12182.2748)	mem 9201MB
[2024-07-28 12:36:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:05:17 lr 0.000033	 wd 0.0000	time 0.1942 (0.2639)	loss 0.8013 (0.8935)	grad_norm 2.0096 (inf)	loss_scale 8192.0000 (11875.5665)	mem 9201MB
[2024-07-28 12:36:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:45 lr 0.000032	 wd 0.0000	time 0.1921 (0.2594)	loss 0.8652 (0.8929)	grad_norm 1.9459 (inf)	loss_scale 8192.0000 (11612.6424)	mem 9201MB
[2024-07-28 12:36:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:04:15 lr 0.000032	 wd 0.0000	time 0.1909 (0.2554)	loss 0.8452 (0.8933)	grad_norm 1.8360 (inf)	loss_scale 8192.0000 (11384.7515)	mem 9201MB
[2024-07-28 12:37:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:49 lr 0.000032	 wd 0.0000	time 0.1924 (0.2546)	loss 0.8809 (0.8931)	grad_norm 2.4909 (inf)	loss_scale 8192.0000 (11185.3292)	mem 9201MB
[2024-07-28 12:37:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:21 lr 0.000032	 wd 0.0000	time 0.2037 (0.2518)	loss 1.0332 (0.8930)	grad_norm 1.7534 (inf)	loss_scale 8192.0000 (11009.3545)	mem 9201MB
[2024-07-28 12:38:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:54 lr 0.000032	 wd 0.0000	time 0.2028 (0.2490)	loss 0.9639 (0.8932)	grad_norm 1.6277 (inf)	loss_scale 8192.0000 (10852.9217)	mem 9201MB
[2024-07-28 12:38:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:28 lr 0.000032	 wd 0.0000	time 0.1779 (0.2464)	loss 1.0801 (0.8934)	grad_norm 1.7874 (inf)	loss_scale 8192.0000 (10712.9469)	mem 9201MB
[2024-07-28 12:38:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:02:02 lr 0.000031	 wd 0.0000	time 0.1960 (0.2447)	loss 1.0361 (0.8943)	grad_norm 1.7545 (inf)	loss_scale 8192.0000 (10586.9625)	mem 9201MB
[2024-07-28 12:39:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:38 lr 0.000031	 wd 0.0000	time 0.1835 (0.2445)	loss 0.7690 (0.8941)	grad_norm 1.6745 (inf)	loss_scale 8192.0000 (10472.9710)	mem 9201MB
[2024-07-28 12:39:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:13 lr 0.000031	 wd 0.0000	time 0.1889 (0.2429)	loss 0.8120 (0.8947)	grad_norm 1.5209 (inf)	loss_scale 8192.0000 (10369.3376)	mem 9201MB
[2024-07-28 12:39:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:48 lr 0.000031	 wd 0.0000	time 0.2095 (0.2411)	loss 0.7935 (0.8949)	grad_norm 2.3267 (inf)	loss_scale 8192.0000 (10274.7119)	mem 9201MB
[2024-07-28 12:40:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:24 lr 0.000031	 wd 0.0000	time 0.2130 (0.2396)	loss 0.9263 (0.8947)	grad_norm 2.0095 (inf)	loss_scale 8192.0000 (10187.9683)	mem 9201MB
[2024-07-28 12:40:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000030	 wd 0.0000	time 0.1807 (0.2379)	loss 0.8682 (0.8950)	grad_norm 1.6943 (inf)	loss_scale 8192.0000 (10108.1615)	mem 9201MB
[2024-07-28 12:40:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 18 training takes 0:10:08
[2024-07-28 12:41:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 28.251 (28.251)	Loss 0.3660 (0.3660)	Acc@1 91.016 (91.016)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 12:41:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.906 Acc@5 97.512
[2024-07-28 12:41:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-28 12:41:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.99%
[2024-07-28 12:41:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][0/2502]	eta 12:49:59 lr 0.000030	 wd 0.0000	time 18.4651 (18.4651)	loss 0.8032 (0.8032)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:42:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:17:00 lr 0.000030	 wd 0.0000	time 0.2102 (0.4248)	loss 1.0605 (0.9040)	grad_norm 1.6464 (1.8659)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:42:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:12:00 lr 0.000030	 wd 0.0000	time 0.1904 (0.3128)	loss 0.7842 (0.9024)	grad_norm 1.9856 (1.8695)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:42:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:10:05 lr 0.000030	 wd 0.0000	time 0.1952 (0.2748)	loss 0.8535 (0.9002)	grad_norm 1.6511 (1.8732)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:43:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:08:57 lr 0.000030	 wd 0.0000	time 0.1922 (0.2555)	loss 0.9673 (0.8984)	grad_norm 1.6427 (1.8634)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:43:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:08:23 lr 0.000029	 wd 0.0000	time 0.3817 (0.2515)	loss 0.9160 (0.8971)	grad_norm 1.5997 (1.8786)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:44:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:38 lr 0.000029	 wd 0.0000	time 0.1947 (0.2726)	loss 0.8618 (0.8968)	grad_norm 1.8630 (1.8752)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:44:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:07:52 lr 0.000029	 wd 0.0000	time 0.1830 (0.2622)	loss 0.9248 (0.8969)	grad_norm 2.5149 (1.8703)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:44:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:07:12 lr 0.000029	 wd 0.0000	time 0.1868 (0.2543)	loss 0.8066 (0.8961)	grad_norm 1.7143 (1.8689)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:45:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:06:45 lr 0.000029	 wd 0.0000	time 0.2744 (0.2529)	loss 0.8110 (0.8947)	grad_norm 2.1710 (1.8655)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:45:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:23 lr 0.000028	 wd 0.0000	time 0.1928 (0.2553)	loss 0.8286 (0.8947)	grad_norm 1.7859 (1.8769)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:46:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:50 lr 0.000028	 wd 0.0000	time 0.1994 (0.2500)	loss 0.9570 (0.8952)	grad_norm 1.7700 (1.8841)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:46:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:19 lr 0.000028	 wd 0.0000	time 0.1899 (0.2456)	loss 0.8999 (0.8956)	grad_norm 1.8683 (1.8864)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:46:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:04:52 lr 0.000028	 wd 0.0000	time 0.1839 (0.2431)	loss 0.7383 (0.8959)	grad_norm 1.9561 (1.8836)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:47:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:27 lr 0.000028	 wd 0.0000	time 0.1818 (0.2423)	loss 0.8438 (0.8963)	grad_norm 1.7400 (1.8831)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:47:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:04:00 lr 0.000028	 wd 0.0000	time 0.1886 (0.2399)	loss 0.9478 (0.8966)	grad_norm 2.2804 (1.8826)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:47:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:34 lr 0.000027	 wd 0.0000	time 0.1890 (0.2375)	loss 0.8438 (0.8966)	grad_norm 1.4938 (1.8881)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:48:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:08 lr 0.000027	 wd 0.0000	time 0.2181 (0.2354)	loss 0.8086 (0.8963)	grad_norm 1.5869 (1.8849)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:48:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:44 lr 0.000027	 wd 0.0000	time 0.1973 (0.2343)	loss 0.7544 (0.8967)	grad_norm 1.6375 (1.8884)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:48:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:21 lr 0.000027	 wd 0.0000	time 0.2106 (0.2345)	loss 0.8848 (0.8963)	grad_norm 2.4233 (1.8925)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:49:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:56 lr 0.000027	 wd 0.0000	time 0.1873 (0.2330)	loss 0.9697 (0.8956)	grad_norm 1.9517 (1.8922)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 12:49:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:33 lr 0.000026	 wd 0.0000	time 0.2094 (0.2315)	loss 1.0615 (0.8952)	grad_norm 1.5951 (1.8916)	loss_scale 16384.0000 (8262.1837)	mem 9201MB
[2024-07-28 12:49:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:09 lr 0.000026	 wd 0.0000	time 0.2246 (0.2303)	loss 0.8784 (0.8948)	grad_norm 2.5758 (1.8923)	loss_scale 16384.0000 (8631.1895)	mem 9201MB
[2024-07-28 12:50:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:46 lr 0.000026	 wd 0.0000	time 0.2075 (0.2305)	loss 0.9185 (0.8952)	grad_norm 1.6997 (1.8928)	loss_scale 16384.0000 (8968.1217)	mem 9201MB
[2024-07-28 12:50:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:23 lr 0.000026	 wd 0.0000	time 0.1774 (0.2295)	loss 1.0781 (0.8949)	grad_norm 2.0608 (1.8909)	loss_scale 16384.0000 (9276.9879)	mem 9201MB
[2024-07-28 12:50:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1810 (0.2280)	loss 0.8213 (0.8946)	grad_norm 1.7298 (1.8918)	loss_scale 16384.0000 (9561.1547)	mem 9201MB
[2024-07-28 12:51:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 19 training takes 0:09:38
[2024-07-28 12:51:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 34.496 (34.496)	Loss 0.3657 (0.3657)	Acc@1 91.211 (91.211)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 12:52:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.980 Acc@5 97.534
[2024-07-28 12:52:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-28 12:52:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.99%
[2024-07-28 12:52:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][0/2502]	eta 11:14:58 lr 0.000026	 wd 0.0000	time 16.1865 (16.1865)	loss 1.0029 (1.0029)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:52:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:14:34 lr 0.000026	 wd 0.0000	time 0.1771 (0.3642)	loss 0.9917 (0.9078)	grad_norm 1.9010 (1.8662)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:53:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:10:53 lr 0.000025	 wd 0.0000	time 0.2227 (0.2840)	loss 1.0186 (0.9010)	grad_norm 1.6538 (1.8779)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:53:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:11:00 lr 0.000025	 wd 0.0000	time 0.2200 (0.2999)	loss 0.7939 (0.8990)	grad_norm 1.8784 (1.8731)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:53:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:09:37 lr 0.000025	 wd 0.0000	time 0.1906 (0.2747)	loss 0.8179 (0.8942)	grad_norm 1.7200 (1.8757)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:54:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:08:39 lr 0.000025	 wd 0.0000	time 0.1869 (0.2593)	loss 0.8887 (0.8957)	grad_norm 1.7676 (1.8666)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:54:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:07:54 lr 0.000025	 wd 0.0000	time 0.2009 (0.2494)	loss 0.8442 (0.8953)	grad_norm 2.3114 (1.8722)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:55:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:08:04 lr 0.000025	 wd 0.0000	time 0.2079 (0.2686)	loss 0.8081 (0.8946)	grad_norm 1.4004 (1.8866)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:55:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:07:23 lr 0.000024	 wd 0.0000	time 0.1956 (0.2603)	loss 0.8877 (0.8953)	grad_norm 1.6629 (1.8836)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:55:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:46 lr 0.000024	 wd 0.0000	time 0.1923 (0.2535)	loss 1.0244 (0.8952)	grad_norm 1.8502 (1.8850)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:56:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:12 lr 0.000024	 wd 0.0000	time 0.2024 (0.2483)	loss 0.8379 (0.8967)	grad_norm 1.7736 (1.8843)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:56:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:45 lr 0.000024	 wd 0.0000	time 0.2091 (0.2465)	loss 0.8071 (0.8962)	grad_norm 2.6869 (1.8869)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:56:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:16 lr 0.000024	 wd 0.0000	time 0.1791 (0.2429)	loss 0.7666 (0.8955)	grad_norm 1.9421 (1.8896)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:57:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:04:48 lr 0.000023	 wd 0.0000	time 0.1804 (0.2398)	loss 0.8340 (0.8943)	grad_norm 1.7071 (1.8820)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:57:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:21 lr 0.000023	 wd 0.0000	time 0.2016 (0.2369)	loss 0.9038 (0.8946)	grad_norm 1.7326 (1.8799)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:58:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:03:55 lr 0.000023	 wd 0.0000	time 0.1924 (0.2347)	loss 0.9370 (0.8940)	grad_norm 1.8127 (1.8797)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:58:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:31 lr 0.000023	 wd 0.0000	time 0.2959 (0.2349)	loss 0.9263 (0.8932)	grad_norm 1.5451 (1.8839)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:58:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:07 lr 0.000023	 wd 0.0000	time 0.2122 (0.2334)	loss 1.1250 (0.8933)	grad_norm 1.5410 (1.8846)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:59:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:42 lr 0.000023	 wd 0.0000	time 0.2007 (0.2316)	loss 0.9194 (0.8931)	grad_norm 2.0819 (1.8820)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:59:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:18 lr 0.000022	 wd 0.0000	time 0.1966 (0.2300)	loss 0.8994 (0.8934)	grad_norm 1.7397 (1.8826)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 12:59:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:01:54 lr 0.000022	 wd 0.0000	time 0.1966 (0.2289)	loss 0.9419 (0.8933)	grad_norm 2.6941 (1.8865)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:00:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:32 lr 0.000022	 wd 0.0000	time 0.2504 (0.2293)	loss 0.9507 (0.8937)	grad_norm 2.1843 (1.8927)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:00:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:08 lr 0.000022	 wd 0.0000	time 0.2119 (0.2282)	loss 0.9346 (0.8935)	grad_norm 1.7242 (1.8901)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:00:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:45 lr 0.000022	 wd 0.0000	time 0.1852 (0.2270)	loss 0.8721 (0.8940)	grad_norm 1.5317 (1.8913)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:01:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:23 lr 0.000022	 wd 0.0000	time 0.2076 (0.2260)	loss 0.8467 (0.8943)	grad_norm 1.9266 (1.8906)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:01:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1853 (0.2248)	loss 0.8481 (0.8942)	grad_norm 1.7246 (1.8927)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:01:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 20 training takes 0:09:35
[2024-07-28 13:02:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 26.893 (26.893)	Loss 0.3665 (0.3665)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 13:02:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.966 Acc@5 97.534
[2024-07-28 13:02:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-28 13:02:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.99%
[2024-07-28 13:02:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][0/2502]	eta 12:21:34 lr 0.000021	 wd 0.0000	time 17.7834 (17.7834)	loss 0.9146 (0.9146)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:03:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:19:22 lr 0.000021	 wd 0.0000	time 0.1969 (0.4841)	loss 0.8706 (0.8956)	grad_norm 1.6228 (1.9010)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:03:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:13:07 lr 0.000021	 wd 0.0000	time 0.1779 (0.3420)	loss 0.8589 (0.9002)	grad_norm 1.9209 (1.8719)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:03:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:10:48 lr 0.000021	 wd 0.0000	time 0.2007 (0.2943)	loss 0.8369 (0.8943)	grad_norm 1.7097 (1.8511)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:04:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:09:28 lr 0.000021	 wd 0.0000	time 0.1991 (0.2706)	loss 0.8066 (0.8922)	grad_norm 1.8259 (1.8674)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:04:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:09:37 lr 0.000021	 wd 0.0000	time 0.3760 (0.2885)	loss 0.9922 (0.8935)	grad_norm 1.5536 (1.8660)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:05:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:54 lr 0.000020	 wd 0.0000	time 0.1926 (0.2812)	loss 0.9307 (0.8938)	grad_norm 1.6142 (1.8855)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:05:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:08:05 lr 0.000020	 wd 0.0000	time 0.1979 (0.2694)	loss 0.8999 (0.8941)	grad_norm 1.8648 (1.8843)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:05:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:24 lr 0.000020	 wd 0.0000	time 0.1868 (0.2609)	loss 0.9194 (0.8939)	grad_norm 1.8373 (1.8778)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:06:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:07:14 lr 0.000020	 wd 0.0000	time 0.2258 (0.2715)	loss 0.8516 (0.8932)	grad_norm 1.7108 (1.8822)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:06:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:37 lr 0.000020	 wd 0.0000	time 0.1892 (0.2648)	loss 0.8105 (0.8924)	grad_norm 1.9123 (inf)	loss_scale 8192.0000 (15925.7063)	mem 9201MB
[2024-07-28 13:07:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:06:02 lr 0.000020	 wd 0.0000	time 0.1926 (0.2587)	loss 0.8516 (0.8930)	grad_norm 1.9476 (inf)	loss_scale 8192.0000 (15223.2807)	mem 9201MB
[2024-07-28 13:07:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:30 lr 0.000019	 wd 0.0000	time 0.2073 (0.2536)	loss 0.9395 (0.8931)	grad_norm 2.2659 (inf)	loss_scale 8192.0000 (14637.8285)	mem 9201MB
[2024-07-28 13:08:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:05:07 lr 0.000019	 wd 0.0000	time 0.2117 (0.2558)	loss 0.9829 (0.8929)	grad_norm 1.5257 (inf)	loss_scale 8192.0000 (14142.3766)	mem 9201MB
[2024-07-28 13:08:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:37 lr 0.000019	 wd 0.0000	time 0.2072 (0.2518)	loss 0.8320 (0.8929)	grad_norm 1.6638 (inf)	loss_scale 8192.0000 (13717.6531)	mem 9201MB
[2024-07-28 13:08:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:04:08 lr 0.000019	 wd 0.0000	time 0.1891 (0.2483)	loss 0.8579 (0.8926)	grad_norm 1.7942 (inf)	loss_scale 8192.0000 (13349.5217)	mem 9201MB
[2024-07-28 13:09:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:41 lr 0.000019	 wd 0.0000	time 0.1942 (0.2453)	loss 0.8672 (0.8918)	grad_norm 1.7309 (inf)	loss_scale 8192.0000 (13027.3779)	mem 9201MB
[2024-07-28 13:09:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:15 lr 0.000019	 wd 0.0000	time 0.2176 (0.2432)	loss 0.8760 (0.8914)	grad_norm 1.7474 (inf)	loss_scale 8192.0000 (12743.1111)	mem 9201MB
[2024-07-28 13:09:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:50 lr 0.000018	 wd 0.0000	time 0.2367 (0.2430)	loss 0.8901 (0.8910)	grad_norm 2.3303 (inf)	loss_scale 8192.0000 (12490.4120)	mem 9201MB
[2024-07-28 13:10:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:25 lr 0.000018	 wd 0.0000	time 0.1817 (0.2409)	loss 0.7524 (0.8904)	grad_norm 2.0491 (inf)	loss_scale 8192.0000 (12264.2988)	mem 9201MB
[2024-07-28 13:10:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:59 lr 0.000018	 wd 0.0000	time 0.1896 (0.2390)	loss 0.8511 (0.8904)	grad_norm 1.8797 (inf)	loss_scale 8192.0000 (12060.7856)	mem 9201MB
[2024-07-28 13:10:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:35 lr 0.000018	 wd 0.0000	time 0.1890 (0.2374)	loss 0.8418 (0.8905)	grad_norm 2.4664 (inf)	loss_scale 8192.0000 (11876.6454)	mem 9201MB
[2024-07-28 13:11:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:11 lr 0.000018	 wd 0.0000	time 0.2003 (0.2368)	loss 0.7202 (0.8905)	grad_norm 1.7206 (inf)	loss_scale 8192.0000 (11709.2376)	mem 9201MB
[2024-07-28 13:11:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:47 lr 0.000018	 wd 0.0000	time 0.2028 (0.2357)	loss 0.9663 (0.8913)	grad_norm 2.0445 (inf)	loss_scale 8192.0000 (11556.3807)	mem 9201MB
[2024-07-28 13:11:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:23 lr 0.000018	 wd 0.0000	time 0.1905 (0.2343)	loss 0.8779 (0.8915)	grad_norm 1.7612 (inf)	loss_scale 8192.0000 (11416.2566)	mem 9201MB
[2024-07-28 13:12:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000017	 wd 0.0000	time 0.1811 (0.2327)	loss 0.9312 (0.8918)	grad_norm 1.7750 (inf)	loss_scale 8192.0000 (11287.3379)	mem 9201MB
[2024-07-28 13:12:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 21 training takes 0:09:49
[2024-07-28 13:13:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 42.445 (42.445)	Loss 0.3650 (0.3650)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 13:13:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.924 Acc@5 97.522
[2024-07-28 13:13:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-28 13:13:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.99%
[2024-07-28 13:13:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][0/2502]	eta 11:23:04 lr 0.000017	 wd 0.0000	time 16.3809 (16.3809)	loss 0.9790 (0.9790)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:13:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:14:31 lr 0.000017	 wd 0.0000	time 0.1922 (0.3626)	loss 1.0059 (0.9032)	grad_norm 1.8173 (1.9574)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:14:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:12:43 lr 0.000017	 wd 0.0000	time 0.1987 (0.3316)	loss 0.7949 (0.9002)	grad_norm 1.9396 (1.9359)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:14:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:10:36 lr 0.000017	 wd 0.0000	time 0.1874 (0.2892)	loss 0.9717 (0.8958)	grad_norm 2.1079 (1.9435)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:15:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:09:19 lr 0.000017	 wd 0.0000	time 0.1885 (0.2663)	loss 0.9189 (0.8981)	grad_norm 1.6622 (1.9374)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:15:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:08:25 lr 0.000017	 wd 0.0000	time 0.1848 (0.2525)	loss 0.9883 (0.8986)	grad_norm 2.1829 (1.9461)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:15:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:07:46 lr 0.000016	 wd 0.0000	time 0.3148 (0.2454)	loss 1.0566 (0.9002)	grad_norm 2.0820 (1.9344)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:16:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:46 lr 0.000016	 wd 0.0000	time 0.2353 (0.2586)	loss 0.8896 (0.9002)	grad_norm 1.8732 (1.9350)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:16:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:07:07 lr 0.000016	 wd 0.0000	time 0.1904 (0.2513)	loss 0.8545 (0.9008)	grad_norm 1.8363 (1.9333)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:17:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:33 lr 0.000016	 wd 0.0000	time 0.1849 (0.2455)	loss 0.8857 (0.8995)	grad_norm 1.9387 (1.9259)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:17:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:02 lr 0.000016	 wd 0.0000	time 0.1911 (0.2415)	loss 0.7808 (0.9000)	grad_norm 1.7656 (1.9290)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:17:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:47 lr 0.000016	 wd 0.0000	time 0.1904 (0.2481)	loss 0.8730 (0.9001)	grad_norm 1.7989 (1.9385)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:18:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:17 lr 0.000016	 wd 0.0000	time 0.1825 (0.2439)	loss 0.8745 (0.9000)	grad_norm 2.0215 (1.9334)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:18:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:04:48 lr 0.000015	 wd 0.0000	time 0.1880 (0.2403)	loss 0.9116 (0.8995)	grad_norm 2.1417 (1.9290)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:18:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:21 lr 0.000015	 wd 0.0000	time 0.1953 (0.2374)	loss 0.8218 (0.8997)	grad_norm 1.6798 (1.9372)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:19:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:03:57 lr 0.000015	 wd 0.0000	time 0.2027 (0.2373)	loss 0.6514 (0.8997)	grad_norm 1.7611 (1.9313)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:19:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:32 lr 0.000015	 wd 0.0000	time 0.1956 (0.2354)	loss 1.0283 (0.8995)	grad_norm 1.7768 (1.9268)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:19:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:07 lr 0.000015	 wd 0.0000	time 0.1975 (0.2334)	loss 0.7588 (0.8987)	grad_norm 2.2846 (1.9256)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:20:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:42 lr 0.000015	 wd 0.0000	time 0.2070 (0.2315)	loss 1.0498 (0.8977)	grad_norm 2.2490 (1.9240)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:20:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:18 lr 0.000015	 wd 0.0000	time 0.1913 (0.2301)	loss 1.0068 (0.8983)	grad_norm 1.4864 (1.9255)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:21:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:55 lr 0.000014	 wd 0.0000	time 0.2036 (0.2305)	loss 0.9526 (0.8982)	grad_norm 2.0026 (1.9237)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:21:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:32 lr 0.000014	 wd 0.0000	time 0.1970 (0.2294)	loss 0.8530 (0.8982)	grad_norm 2.1035 (1.9275)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:21:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:08 lr 0.000014	 wd 0.0000	time 0.1916 (0.2282)	loss 0.7183 (0.8975)	grad_norm 1.9422 (1.9283)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:22:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:45 lr 0.000014	 wd 0.0000	time 0.2026 (0.2270)	loss 0.9150 (0.8971)	grad_norm 1.8425 (1.9292)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:22:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:23 lr 0.000014	 wd 0.0000	time 0.1932 (0.2263)	loss 0.8418 (0.8977)	grad_norm 1.8675 (1.9275)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:22:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1810 (0.2258)	loss 0.8853 (0.8976)	grad_norm 2.0102 (1.9248)	loss_scale 16384.0000 (8381.9784)	mem 9201MB
[2024-07-28 13:22:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 22 training takes 0:09:37
[2024-07-28 13:23:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 20.937 (20.937)	Loss 0.3618 (0.3618)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 13:23:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.966 Acc@5 97.532
[2024-07-28 13:23:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-28 13:23:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.99%
[2024-07-28 13:24:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][0/2502]	eta 20:58:00 lr 0.000014	 wd 0.0000	time 30.1680 (30.1680)	loss 0.9263 (0.9263)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:24:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:21:12 lr 0.000014	 wd 0.0000	time 0.1810 (0.5300)	loss 0.9277 (0.8906)	grad_norm 2.0905 (2.0132)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:24:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:13:57 lr 0.000013	 wd 0.0000	time 0.1927 (0.3640)	loss 0.8145 (0.8874)	grad_norm 1.9439 (1.9429)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:25:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:11:19 lr 0.000013	 wd 0.0000	time 0.1933 (0.3084)	loss 0.8516 (0.8882)	grad_norm 1.8026 (1.9216)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:25:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:10:00 lr 0.000013	 wd 0.0000	time 0.3078 (0.2858)	loss 1.0049 (0.8927)	grad_norm 1.9060 (inf)	loss_scale 8192.0000 (14422.8229)	mem 9201MB
[2024-07-28 13:26:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:10:12 lr 0.000013	 wd 0.0000	time 0.2018 (0.3061)	loss 1.0039 (0.8961)	grad_norm 2.4240 (inf)	loss_scale 8192.0000 (13179.1457)	mem 9201MB
[2024-07-28 13:26:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:09:08 lr 0.000013	 wd 0.0000	time 0.2048 (0.2885)	loss 0.9600 (0.8957)	grad_norm 2.1152 (inf)	loss_scale 8192.0000 (12349.3378)	mem 9201MB
[2024-07-28 13:26:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:08:16 lr 0.000013	 wd 0.0000	time 0.2300 (0.2754)	loss 0.9673 (0.8970)	grad_norm 1.7339 (inf)	loss_scale 8192.0000 (11756.2796)	mem 9201MB
[2024-07-28 13:27:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:07:35 lr 0.000013	 wd 0.0000	time 0.2092 (0.2676)	loss 0.8799 (0.8957)	grad_norm 1.9055 (inf)	loss_scale 8192.0000 (11311.3009)	mem 9201MB
[2024-07-28 13:27:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:07:06 lr 0.000012	 wd 0.0000	time 0.1778 (0.2665)	loss 1.1143 (0.8955)	grad_norm 2.0175 (inf)	loss_scale 8192.0000 (10965.0966)	mem 9201MB
[2024-07-28 13:27:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:29 lr 0.000012	 wd 0.0000	time 0.1853 (0.2595)	loss 0.8091 (0.8964)	grad_norm 2.5292 (inf)	loss_scale 8192.0000 (10688.0639)	mem 9201MB
[2024-07-28 13:28:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:56 lr 0.000012	 wd 0.0000	time 0.1922 (0.2540)	loss 0.8994 (0.8946)	grad_norm 2.4405 (inf)	loss_scale 8192.0000 (10461.3551)	mem 9201MB
[2024-07-28 13:28:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:25 lr 0.000012	 wd 0.0000	time 0.1968 (0.2498)	loss 0.8120 (0.8947)	grad_norm 2.1769 (inf)	loss_scale 8192.0000 (10272.3997)	mem 9201MB
[2024-07-28 13:29:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:05:01 lr 0.000012	 wd 0.0000	time 0.1880 (0.2512)	loss 0.9648 (0.8935)	grad_norm 1.4619 (inf)	loss_scale 8192.0000 (10112.4919)	mem 9201MB
[2024-07-28 13:29:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:32 lr 0.000012	 wd 0.0000	time 0.2006 (0.2476)	loss 0.9683 (0.8930)	grad_norm 2.2201 (inf)	loss_scale 8192.0000 (9975.4118)	mem 9201MB
[2024-07-28 13:29:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:04:05 lr 0.000012	 wd 0.0000	time 0.2020 (0.2446)	loss 0.9590 (0.8924)	grad_norm 2.3440 (inf)	loss_scale 8192.0000 (9856.5969)	mem 9201MB
[2024-07-28 13:30:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:38 lr 0.000012	 wd 0.0000	time 0.1984 (0.2418)	loss 0.8418 (0.8925)	grad_norm 1.8781 (inf)	loss_scale 8192.0000 (9752.6246)	mem 9201MB
[2024-07-28 13:30:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:12 lr 0.000011	 wd 0.0000	time 0.2261 (0.2397)	loss 0.7314 (0.8927)	grad_norm 1.8016 (inf)	loss_scale 8192.0000 (9660.8771)	mem 9201MB
[2024-07-28 13:30:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:48 lr 0.000011	 wd 0.0000	time 0.1774 (0.2396)	loss 0.9360 (0.8929)	grad_norm 1.9580 (inf)	loss_scale 8192.0000 (9579.3182)	mem 9201MB
[2024-07-28 13:31:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:23 lr 0.000011	 wd 0.0000	time 0.1855 (0.2377)	loss 0.7676 (0.8925)	grad_norm 1.3916 (inf)	loss_scale 8192.0000 (9506.3398)	mem 9201MB
[2024-07-28 13:31:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:01:58 lr 0.000011	 wd 0.0000	time 0.1869 (0.2360)	loss 0.9106 (0.8918)	grad_norm 2.5217 (inf)	loss_scale 8192.0000 (9440.6557)	mem 9201MB
[2024-07-28 13:31:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:34 lr 0.000011	 wd 0.0000	time 0.1948 (0.2344)	loss 0.8926 (0.8923)	grad_norm 2.7157 (inf)	loss_scale 8192.0000 (9381.2242)	mem 9201MB
[2024-07-28 13:32:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:10 lr 0.000011	 wd 0.0000	time 0.5061 (0.2345)	loss 0.9448 (0.8923)	grad_norm 1.4818 (inf)	loss_scale 8192.0000 (9327.1931)	mem 9201MB
[2024-07-28 13:32:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:47 lr 0.000011	 wd 0.0000	time 0.1988 (0.2335)	loss 0.9038 (0.8927)	grad_norm 2.3190 (inf)	loss_scale 8192.0000 (9277.8583)	mem 9201MB
[2024-07-28 13:32:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:23 lr 0.000011	 wd 0.0000	time 0.1861 (0.2322)	loss 0.8833 (0.8927)	grad_norm 2.0073 (inf)	loss_scale 8192.0000 (9232.6331)	mem 9201MB
[2024-07-28 13:33:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1808 (0.2307)	loss 0.9043 (0.8924)	grad_norm 1.9315 (inf)	loss_scale 8192.0000 (9191.0244)	mem 9201MB
[2024-07-28 13:33:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 23 training takes 0:09:44
[2024-07-28 13:34:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 43.118 (43.118)	Loss 0.3635 (0.3635)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 9201MB
[2024-07-28 13:34:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.962 Acc@5 97.514
[2024-07-28 13:34:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-28 13:34:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.99%
[2024-07-28 13:34:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][0/2502]	eta 11:40:23 lr 0.000010	 wd 0.0000	time 16.7961 (16.7961)	loss 0.8218 (0.8218)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:34:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:14:34 lr 0.000010	 wd 0.0000	time 0.2338 (0.3640)	loss 0.9736 (0.8869)	grad_norm 1.8987 (1.9344)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:35:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:13:02 lr 0.000010	 wd 0.0000	time 0.1862 (0.3400)	loss 0.9409 (0.8913)	grad_norm 1.9400 (1.9457)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:35:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:10:50 lr 0.000010	 wd 0.0000	time 0.1986 (0.2955)	loss 0.8760 (0.8901)	grad_norm 2.1360 (1.9592)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:36:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:09:30 lr 0.000010	 wd 0.0000	time 0.1802 (0.2714)	loss 0.9385 (0.8905)	grad_norm 1.8499 (1.9331)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:36:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:08:33 lr 0.000010	 wd 0.0000	time 0.1919 (0.2564)	loss 0.8730 (0.8918)	grad_norm 2.7520 (1.9319)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:36:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:08:06 lr 0.000010	 wd 0.0000	time 0.3829 (0.2557)	loss 0.8252 (0.8911)	grad_norm 1.9690 (1.9165)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:37:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:07:56 lr 0.000010	 wd 0.0000	time 0.1885 (0.2643)	loss 0.8330 (0.8914)	grad_norm 2.2664 (1.9209)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:37:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:07:16 lr 0.000010	 wd 0.0000	time 0.1821 (0.2562)	loss 0.8198 (0.8924)	grad_norm 2.2739 (1.9250)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:38:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:06:40 lr 0.000009	 wd 0.0000	time 0.1869 (0.2497)	loss 0.9531 (0.8932)	grad_norm 3.3835 (1.9287)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:38:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:12 lr 0.000009	 wd 0.0000	time 0.2937 (0.2483)	loss 0.9053 (0.8942)	grad_norm 1.7208 (1.9283)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:39:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:05:55 lr 0.000009	 wd 0.0000	time 0.1884 (0.2535)	loss 0.8286 (0.8925)	grad_norm 2.1108 (1.9266)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:39:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:24 lr 0.000009	 wd 0.0000	time 0.1875 (0.2491)	loss 0.7871 (0.8921)	grad_norm 2.1855 (1.9313)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:39:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:04:54 lr 0.000009	 wd 0.0000	time 0.1861 (0.2450)	loss 0.9189 (0.8930)	grad_norm 1.7595 (1.9329)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:40:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:27 lr 0.000009	 wd 0.0000	time 0.2905 (0.2423)	loss 0.9360 (0.8935)	grad_norm 1.9678 (1.9257)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:40:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:08 lr 0.000009	 wd 0.0000	time 0.1942 (0.2481)	loss 0.7627 (0.8935)	grad_norm 1.7924 (1.9167)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:40:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:40 lr 0.000009	 wd 0.0000	time 0.1804 (0.2449)	loss 0.8301 (0.8934)	grad_norm 1.9595 (1.9165)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:41:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:14 lr 0.000008	 wd 0.0000	time 0.1778 (0.2423)	loss 0.9546 (0.8939)	grad_norm 1.7349 (1.9171)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:41:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:48 lr 0.000008	 wd 0.0000	time 0.2209 (0.2402)	loss 0.7993 (0.8935)	grad_norm 2.2622 (1.9150)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:41:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:24 lr 0.000008	 wd 0.0000	time 0.1836 (0.2398)	loss 0.6758 (0.8939)	grad_norm 1.5447 (1.9145)	loss_scale 16384.0000 (8614.3125)	mem 9201MB
[2024-07-28 13:42:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:01:59 lr 0.000008	 wd 0.0000	time 0.1860 (0.2384)	loss 0.9248 (0.8935)	grad_norm 2.2835 (1.9150)	loss_scale 16384.0000 (9002.6027)	mem 9201MB
[2024-07-28 13:42:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:35 lr 0.000008	 wd 0.0000	time 0.1862 (0.2367)	loss 0.8774 (0.8932)	grad_norm 2.1567 (1.9185)	loss_scale 16384.0000 (9353.9305)	mem 9201MB
[2024-07-28 13:42:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:11 lr 0.000008	 wd 0.0000	time 0.2038 (0.2352)	loss 0.9365 (0.8928)	grad_norm 2.1462 (1.9205)	loss_scale 16384.0000 (9673.3339)	mem 9201MB
[2024-07-28 13:43:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:47 lr 0.000008	 wd 0.0000	time 0.1983 (0.2340)	loss 0.9790 (0.8929)	grad_norm 1.9994 (1.9192)	loss_scale 16384.0000 (9964.9752)	mem 9201MB
[2024-07-28 13:43:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:23 lr 0.000008	 wd 0.0000	time 0.1910 (0.2340)	loss 1.0703 (0.8929)	grad_norm 1.6409 (1.9145)	loss_scale 16384.0000 (10232.3232)	mem 9201MB
[2024-07-28 13:44:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1811 (0.2324)	loss 1.0234 (0.8930)	grad_norm 1.8516 (1.9132)	loss_scale 16384.0000 (10478.2919)	mem 9201MB
[2024-07-28 13:44:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 24 training takes 0:09:49
[2024-07-28 13:44:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 18.822 (18.822)	Loss 0.3616 (0.3616)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 13:44:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.996 Acc@5 97.528
[2024-07-28 13:44:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-28 13:44:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 85.00%
[2024-07-28 13:44:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-28 13:44:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-28 13:45:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][0/2502]	eta 1 day, 1:16:41 lr 0.000008	 wd 0.0000	time 36.3715 (36.3715)	loss 0.8662 (0.8662)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:45:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:22:44 lr 0.000008	 wd 0.0000	time 0.1911 (0.5680)	loss 0.9067 (0.8923)	grad_norm 1.8640 (1.8900)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 13:46:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:14:42 lr 0.000007	 wd 0.0000	time 0.1963 (0.3832)	loss 0.7944 (0.8917)	grad_norm 1.7594 (inf)	loss_scale 8192.0000 (15813.4129)	mem 9201MB
[2024-07-28 13:46:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:12:40 lr 0.000007	 wd 0.0000	time 0.3963 (0.3453)	loss 0.9453 (0.8930)	grad_norm 1.8817 (inf)	loss_scale 8192.0000 (13281.3821)	mem 9201MB
[2024-07-28 13:47:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:12:25 lr 0.000007	 wd 0.0000	time 0.1837 (0.3545)	loss 0.9321 (0.8916)	grad_norm 2.0046 (inf)	loss_scale 8192.0000 (12012.2095)	mem 9201MB
[2024-07-28 13:47:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:10:47 lr 0.000007	 wd 0.0000	time 0.1965 (0.3234)	loss 0.8354 (0.8919)	grad_norm 2.1100 (inf)	loss_scale 8192.0000 (11249.6926)	mem 9201MB
[2024-07-28 13:47:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:09:35 lr 0.000007	 wd 0.0000	time 0.1999 (0.3025)	loss 0.9502 (0.8921)	grad_norm 1.6679 (inf)	loss_scale 8192.0000 (10740.9251)	mem 9201MB
[2024-07-28 13:48:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:09:25 lr 0.000007	 wd 0.0000	time 0.3071 (0.3138)	loss 0.9062 (0.8910)	grad_norm 1.8392 (inf)	loss_scale 8192.0000 (10377.3124)	mem 9201MB
[2024-07-28 13:48:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:08:38 lr 0.000007	 wd 0.0000	time 0.1859 (0.3046)	loss 0.9355 (0.8913)	grad_norm 2.2398 (inf)	loss_scale 8192.0000 (10104.4894)	mem 9201MB
[2024-07-28 13:49:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:07:49 lr 0.000007	 wd 0.0000	time 0.1836 (0.2928)	loss 0.8501 (0.8909)	grad_norm 1.5943 (inf)	loss_scale 8192.0000 (9892.2264)	mem 9201MB
[2024-07-28 13:49:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:07:06 lr 0.000007	 wd 0.0000	time 0.2199 (0.2837)	loss 1.0391 (0.8907)	grad_norm 1.9858 (inf)	loss_scale 8192.0000 (9722.3736)	mem 9201MB
[2024-07-28 13:49:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:06:29 lr 0.000007	 wd 0.0000	time 0.1845 (0.2781)	loss 0.8813 (0.8904)	grad_norm 1.5951 (inf)	loss_scale 8192.0000 (9583.3751)	mem 9201MB
[2024-07-28 13:50:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:53 lr 0.000006	 wd 0.0000	time 0.1846 (0.2713)	loss 1.1104 (0.8912)	grad_norm 1.5383 (inf)	loss_scale 8192.0000 (9467.5237)	mem 9201MB
[2024-07-28 13:50:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:05:19 lr 0.000006	 wd 0.0000	time 0.2154 (0.2661)	loss 0.8564 (0.8915)	grad_norm 1.9078 (inf)	loss_scale 8192.0000 (9369.4819)	mem 9201MB
[2024-07-28 13:50:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:48 lr 0.000006	 wd 0.0000	time 0.1838 (0.2614)	loss 0.8433 (0.8910)	grad_norm 1.4612 (inf)	loss_scale 8192.0000 (9285.4361)	mem 9201MB
[2024-07-28 13:51:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:04:18 lr 0.000006	 wd 0.0000	time 0.2114 (0.2577)	loss 0.9321 (0.8915)	grad_norm 1.8608 (inf)	loss_scale 8192.0000 (9212.5889)	mem 9201MB
[2024-07-28 13:51:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:51 lr 0.000006	 wd 0.0000	time 0.1893 (0.2562)	loss 0.8623 (0.8910)	grad_norm 1.8022 (inf)	loss_scale 8192.0000 (9148.8420)	mem 9201MB
[2024-07-28 13:52:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:23 lr 0.000006	 wd 0.0000	time 0.1962 (0.2533)	loss 0.8584 (0.8904)	grad_norm 2.2431 (inf)	loss_scale 8192.0000 (9092.5902)	mem 9201MB
[2024-07-28 13:52:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:55 lr 0.000006	 wd 0.0000	time 0.1883 (0.2505)	loss 1.0605 (0.8911)	grad_norm 1.5964 (inf)	loss_scale 8192.0000 (9042.5852)	mem 9201MB
[2024-07-28 13:52:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:29 lr 0.000006	 wd 0.0000	time 0.1945 (0.2479)	loss 1.2480 (0.8913)	grad_norm 1.7538 (inf)	loss_scale 8192.0000 (8997.8411)	mem 9201MB
[2024-07-28 13:53:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:02:03 lr 0.000006	 wd 0.0000	time 0.2009 (0.2459)	loss 0.9932 (0.8910)	grad_norm 1.7353 (inf)	loss_scale 8192.0000 (8957.5692)	mem 9201MB
[2024-07-28 13:53:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:38 lr 0.000006	 wd 0.0000	time 0.1866 (0.2455)	loss 0.9570 (0.8910)	grad_norm 1.7571 (inf)	loss_scale 8192.0000 (8921.1309)	mem 9201MB
[2024-07-28 13:53:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:13 lr 0.000006	 wd 0.0000	time 0.1997 (0.2435)	loss 0.8677 (0.8900)	grad_norm 1.8903 (inf)	loss_scale 8192.0000 (8888.0036)	mem 9201MB
[2024-07-28 13:54:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:48 lr 0.000005	 wd 0.0000	time 0.2129 (0.2416)	loss 0.8350 (0.8900)	grad_norm 1.8313 (inf)	loss_scale 8192.0000 (8857.7558)	mem 9201MB
[2024-07-28 13:54:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:24 lr 0.000005	 wd 0.0000	time 0.1952 (0.2401)	loss 0.8335 (0.8899)	grad_norm 1.6052 (inf)	loss_scale 8192.0000 (8830.0275)	mem 9201MB
[2024-07-28 13:54:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000005	 wd 0.0000	time 0.1839 (0.2383)	loss 0.8638 (0.8897)	grad_norm 1.7568 (inf)	loss_scale 8192.0000 (8804.5166)	mem 9201MB
[2024-07-28 13:55:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 25 training takes 0:10:10
[2024-07-28 13:55:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 28.806 (28.806)	Loss 0.3625 (0.3625)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 13:55:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.992 Acc@5 97.520
[2024-07-28 13:55:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-28 13:55:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 85.00%
[2024-07-28 13:56:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][0/2502]	eta 13:55:16 lr 0.000005	 wd 0.0000	time 20.0304 (20.0304)	loss 0.8774 (0.8774)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:56:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:17:50 lr 0.000005	 wd 0.0000	time 0.1801 (0.4456)	loss 0.9839 (0.8918)	grad_norm 1.9481 (1.9810)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:56:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:12:23 lr 0.000005	 wd 0.0000	time 0.2068 (0.3229)	loss 0.8633 (0.8938)	grad_norm 2.1896 (1.9716)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:57:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:10:20 lr 0.000005	 wd 0.0000	time 0.2141 (0.2816)	loss 0.8525 (0.8934)	grad_norm 2.1236 (1.9573)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:57:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:09:07 lr 0.000005	 wd 0.0000	time 0.1999 (0.2603)	loss 0.9766 (0.8913)	grad_norm 1.7847 (1.9590)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:58:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:09:09 lr 0.000005	 wd 0.0000	time 0.2080 (0.2744)	loss 0.9849 (0.8922)	grad_norm 1.5525 (1.9536)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:58:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:08:20 lr 0.000005	 wd 0.0000	time 0.1966 (0.2631)	loss 0.8735 (0.8918)	grad_norm 2.0717 (1.9464)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:58:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:37 lr 0.000005	 wd 0.0000	time 0.1830 (0.2540)	loss 1.0703 (0.8906)	grad_norm 1.7143 (1.9449)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:59:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:07:00 lr 0.000005	 wd 0.0000	time 0.1904 (0.2468)	loss 0.8696 (0.8904)	grad_norm 2.0474 (1.9372)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:59:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:06:32 lr 0.000005	 wd 0.0000	time 0.4028 (0.2448)	loss 0.8726 (0.8896)	grad_norm 1.8316 (1.9403)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 13:59:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:14 lr 0.000004	 wd 0.0000	time 0.1947 (0.2493)	loss 1.0068 (0.8896)	grad_norm 1.8905 (1.9405)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:00:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:43 lr 0.000004	 wd 0.0000	time 0.2128 (0.2448)	loss 0.9233 (0.8895)	grad_norm 1.9214 (1.9404)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:00:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:13 lr 0.000004	 wd 0.0000	time 0.1785 (0.2409)	loss 0.8042 (0.8903)	grad_norm 1.7524 (1.9374)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:00:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:04:46 lr 0.000004	 wd 0.0000	time 0.2030 (0.2382)	loss 0.7671 (0.8905)	grad_norm 1.7854 (1.9366)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:01:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:28 lr 0.000004	 wd 0.0000	time 0.1901 (0.2440)	loss 1.0020 (0.8910)	grad_norm 1.7615 (1.9360)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:01:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:04:01 lr 0.000004	 wd 0.0000	time 0.1961 (0.2410)	loss 0.8242 (0.8912)	grad_norm 2.4344 (1.9324)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:02:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:34 lr 0.000004	 wd 0.0000	time 0.2089 (0.2383)	loss 0.7773 (0.8904)	grad_norm 1.7072 (1.9329)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:02:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:09 lr 0.000004	 wd 0.0000	time 0.2065 (0.2362)	loss 0.7891 (0.8899)	grad_norm 1.7180 (1.9275)	loss_scale 16384.0000 (8269.0558)	mem 9201MB
[2024-07-28 14:02:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:45 lr 0.000004	 wd 0.0000	time 0.1988 (0.2353)	loss 0.9106 (0.8901)	grad_norm 1.6066 (1.9252)	loss_scale 16384.0000 (8719.6358)	mem 9201MB
[2024-07-28 14:03:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:21 lr 0.000004	 wd 0.0000	time 0.1907 (0.2343)	loss 0.8071 (0.8900)	grad_norm 2.0677 (1.9231)	loss_scale 16384.0000 (9122.8112)	mem 9201MB
[2024-07-28 14:03:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:01:56 lr 0.000004	 wd 0.0000	time 0.1970 (0.2329)	loss 0.9556 (0.8902)	grad_norm 1.8633 (1.9195)	loss_scale 16384.0000 (9485.6892)	mem 9201MB
[2024-07-28 14:03:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:32 lr 0.000004	 wd 0.0000	time 0.1861 (0.2313)	loss 0.9263 (0.8905)	grad_norm 1.7163 (1.9216)	loss_scale 16384.0000 (9814.0238)	mem 9201MB
[2024-07-28 14:04:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:09 lr 0.000004	 wd 0.0000	time 0.1872 (0.2302)	loss 0.8711 (0.8907)	grad_norm 2.0389 (1.9209)	loss_scale 16384.0000 (10112.5234)	mem 9201MB
[2024-07-28 14:04:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:46 lr 0.000004	 wd 0.0000	time 0.2246 (0.2296)	loss 0.7847 (0.8907)	grad_norm 2.4258 (1.9220)	loss_scale 16384.0000 (10385.0778)	mem 9201MB
[2024-07-28 14:04:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:23 lr 0.000003	 wd 0.0000	time 0.1900 (0.2287)	loss 0.9429 (0.8911)	grad_norm 1.9990 (1.9196)	loss_scale 16384.0000 (10634.9288)	mem 9201MB
[2024-07-28 14:05:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1815 (0.2272)	loss 0.7974 (0.8916)	grad_norm 1.8668 (1.9222)	loss_scale 16384.0000 (10864.7997)	mem 9201MB
[2024-07-28 14:05:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 26 training takes 0:09:36
[2024-07-28 14:05:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 31.435 (31.435)	Loss 0.3635 (0.3635)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 14:06:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.978 Acc@5 97.534
[2024-07-28 14:06:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-28 14:06:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 85.00%
[2024-07-28 14:06:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][0/2502]	eta 11:15:15 lr 0.000003	 wd 0.0000	time 16.1932 (16.1932)	loss 0.8320 (0.8320)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 14:06:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:14:35 lr 0.000003	 wd 0.0000	time 0.1894 (0.3644)	loss 0.8901 (0.8925)	grad_norm 2.5694 (inf)	loss_scale 8192.0000 (15572.9109)	mem 9201MB
[2024-07-28 14:07:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:10:50 lr 0.000003	 wd 0.0000	time 0.2142 (0.2825)	loss 0.8804 (0.8905)	grad_norm 1.9089 (inf)	loss_scale 8192.0000 (11900.8159)	mem 9201MB
[2024-07-28 14:07:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:11:09 lr 0.000003	 wd 0.0000	time 0.2507 (0.3042)	loss 0.9097 (0.8871)	grad_norm 2.0062 (inf)	loss_scale 8192.0000 (10668.6512)	mem 9201MB
[2024-07-28 14:08:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:09:48 lr 0.000003	 wd 0.0000	time 0.1961 (0.2797)	loss 0.8604 (0.8873)	grad_norm 1.5608 (inf)	loss_scale 8192.0000 (10051.0324)	mem 9201MB
[2024-07-28 14:08:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:08:47 lr 0.000003	 wd 0.0000	time 0.1789 (0.2633)	loss 0.8130 (0.8860)	grad_norm 1.9178 (inf)	loss_scale 8192.0000 (9679.9681)	mem 9201MB
[2024-07-28 14:08:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:00 lr 0.000003	 wd 0.0000	time 0.1851 (0.2525)	loss 0.8511 (0.8895)	grad_norm 1.5246 (inf)	loss_scale 8192.0000 (9432.3860)	mem 9201MB
[2024-07-28 14:09:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:54 lr 0.000003	 wd 0.0000	time 0.2996 (0.2636)	loss 0.9209 (0.8911)	grad_norm 1.9090 (inf)	loss_scale 8192.0000 (9255.4408)	mem 9201MB
[2024-07-28 14:09:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:18 lr 0.000003	 wd 0.0000	time 0.1778 (0.2574)	loss 0.9307 (0.8900)	grad_norm 1.7114 (inf)	loss_scale 8192.0000 (9122.6767)	mem 9201MB
[2024-07-28 14:10:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:42 lr 0.000003	 wd 0.0000	time 0.1825 (0.2510)	loss 0.8301 (0.8916)	grad_norm 1.8872 (inf)	loss_scale 8192.0000 (9019.3829)	mem 9201MB
[2024-07-28 14:10:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:09 lr 0.000003	 wd 0.0000	time 0.1960 (0.2458)	loss 0.9824 (0.8909)	grad_norm 1.7754 (inf)	loss_scale 8192.0000 (8936.7273)	mem 9201MB
[2024-07-28 14:10:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:54 lr 0.000003	 wd 0.0000	time 1.2309 (0.2526)	loss 0.8018 (0.8906)	grad_norm 3.3413 (inf)	loss_scale 8192.0000 (8869.0863)	mem 9201MB
[2024-07-28 14:11:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:24 lr 0.000003	 wd 0.0000	time 0.2080 (0.2492)	loss 0.8662 (0.8894)	grad_norm 2.3836 (inf)	loss_scale 8192.0000 (8812.7094)	mem 9201MB
[2024-07-28 14:11:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:55 lr 0.000003	 wd 0.0000	time 0.1933 (0.2454)	loss 0.9155 (0.8892)	grad_norm 2.2047 (inf)	loss_scale 8192.0000 (8764.9992)	mem 9201MB
[2024-07-28 14:11:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:26 lr 0.000003	 wd 0.0000	time 0.1930 (0.2419)	loss 0.7827 (0.8893)	grad_norm 1.7838 (inf)	loss_scale 8192.0000 (8724.0999)	mem 9201MB
[2024-07-28 14:12:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:04:00 lr 0.000003	 wd 0.0000	time 0.1951 (0.2397)	loss 0.9468 (0.8897)	grad_norm 1.7039 (inf)	loss_scale 8192.0000 (8688.6502)	mem 9201MB
[2024-07-28 14:12:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:35 lr 0.000003	 wd 0.0000	time 0.1823 (0.2394)	loss 0.8530 (0.8904)	grad_norm 1.7526 (inf)	loss_scale 8192.0000 (8657.6290)	mem 9201MB
[2024-07-28 14:13:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:10 lr 0.000002	 wd 0.0000	time 0.1868 (0.2373)	loss 0.9912 (0.8900)	grad_norm 1.7631 (inf)	loss_scale 8192.0000 (8630.2551)	mem 9201MB
[2024-07-28 14:13:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:45 lr 0.000002	 wd 0.0000	time 0.2053 (0.2353)	loss 0.8467 (0.8902)	grad_norm 1.9307 (inf)	loss_scale 8192.0000 (8605.9212)	mem 9201MB
[2024-07-28 14:13:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:20 lr 0.000002	 wd 0.0000	time 0.2029 (0.2336)	loss 0.9282 (0.8901)	grad_norm 1.8629 (inf)	loss_scale 8192.0000 (8584.1473)	mem 9201MB
[2024-07-28 14:14:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:57 lr 0.000002	 wd 0.0000	time 0.1933 (0.2336)	loss 0.7334 (0.8897)	grad_norm 1.6894 (inf)	loss_scale 8192.0000 (8564.5497)	mem 9201MB
[2024-07-28 14:14:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:33 lr 0.000002	 wd 0.0000	time 0.1903 (0.2327)	loss 1.1113 (0.8912)	grad_norm 2.5648 (inf)	loss_scale 8192.0000 (8546.8177)	mem 9201MB
[2024-07-28 14:14:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:09 lr 0.000002	 wd 0.0000	time 0.1839 (0.2313)	loss 0.8066 (0.8912)	grad_norm 1.9788 (inf)	loss_scale 8192.0000 (8530.6970)	mem 9201MB
[2024-07-28 14:15:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:46 lr 0.000002	 wd 0.0000	time 0.1896 (0.2300)	loss 0.9463 (0.8916)	grad_norm 1.9823 (inf)	loss_scale 8192.0000 (8515.9774)	mem 9201MB
[2024-07-28 14:15:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:23 lr 0.000002	 wd 0.0000	time 0.2491 (0.2291)	loss 0.9351 (0.8917)	grad_norm 1.8365 (inf)	loss_scale 8192.0000 (8502.4840)	mem 9201MB
[2024-07-28 14:15:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1797 (0.2278)	loss 0.8423 (0.8919)	grad_norm 1.9398 (inf)	loss_scale 8192.0000 (8490.0696)	mem 9201MB
[2024-07-28 14:16:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 27 training takes 0:09:44
[2024-07-28 14:16:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 21.748 (21.748)	Loss 0.3635 (0.3635)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 14:16:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.978 Acc@5 97.532
[2024-07-28 14:16:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-28 14:16:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 85.00%
[2024-07-28 14:17:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][0/2502]	eta 11:29:28 lr 0.000002	 wd 0.0000	time 16.5342 (16.5342)	loss 0.8560 (0.8560)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:17:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:17:27 lr 0.000002	 wd 0.0000	time 0.1908 (0.4359)	loss 0.9648 (0.9039)	grad_norm 2.2856 (1.8828)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:17:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:12:14 lr 0.000002	 wd 0.0000	time 0.1860 (0.3192)	loss 0.9722 (0.8978)	grad_norm 2.9261 (1.9166)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:18:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:10:14 lr 0.000002	 wd 0.0000	time 0.1993 (0.2791)	loss 0.9565 (0.8974)	grad_norm 1.6370 (1.9070)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:18:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:09:03 lr 0.000002	 wd 0.0000	time 0.1956 (0.2584)	loss 0.7627 (0.8941)	grad_norm 1.5659 (1.9057)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:18:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:08:35 lr 0.000002	 wd 0.0000	time 0.3595 (0.2574)	loss 0.9556 (0.8951)	grad_norm 1.7865 (1.8933)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:19:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:28 lr 0.000002	 wd 0.0000	time 0.1880 (0.2672)	loss 0.9336 (0.8943)	grad_norm 1.9450 (1.8896)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:19:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:43 lr 0.000002	 wd 0.0000	time 0.1826 (0.2575)	loss 0.8638 (0.8936)	grad_norm 2.1414 (1.8929)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:20:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:05 lr 0.000002	 wd 0.0000	time 0.2131 (0.2503)	loss 0.8823 (0.8930)	grad_norm 1.9547 (1.8958)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:20:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:34 lr 0.000002	 wd 0.0000	time 0.1968 (0.2463)	loss 0.9229 (0.8912)	grad_norm 2.2935 (1.8960)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:20:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:05 lr 0.000002	 wd 0.0000	time 0.2037 (0.2431)	loss 0.9238 (0.8910)	grad_norm 1.8590 (1.8951)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:21:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:35 lr 0.000002	 wd 0.0000	time 0.1826 (0.2392)	loss 0.8462 (0.8905)	grad_norm 1.7119 (1.8933)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:21:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:07 lr 0.000002	 wd 0.0000	time 0.2178 (0.2361)	loss 0.9468 (0.8897)	grad_norm 1.9341 (1.8902)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:21:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:04:40 lr 0.000002	 wd 0.0000	time 0.1931 (0.2335)	loss 0.8105 (0.8896)	grad_norm 1.9627 (1.8923)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:22:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:18 lr 0.000002	 wd 0.0000	time 0.4693 (0.2343)	loss 0.8428 (0.8895)	grad_norm 1.7831 (1.8907)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:22:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:03:52 lr 0.000002	 wd 0.0000	time 0.1864 (0.2322)	loss 0.8428 (0.8893)	grad_norm 1.5609 (1.8957)	loss_scale 8192.0000 (8192.0000)	mem 9201MB
[2024-07-28 14:22:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:27 lr 0.000002	 wd 0.0000	time 0.1915 (0.2303)	loss 0.8008 (0.8894)	grad_norm 1.5231 (1.8977)	loss_scale 16384.0000 (8253.4016)	mem 9201MB
[2024-07-28 14:23:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:03 lr 0.000001	 wd 0.0000	time 0.1890 (0.2286)	loss 0.7710 (0.8897)	grad_norm 1.5808 (1.8946)	loss_scale 16384.0000 (8731.3909)	mem 9201MB
[2024-07-28 14:23:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:39 lr 0.000001	 wd 0.0000	time 0.2014 (0.2272)	loss 0.7808 (0.8898)	grad_norm 2.0419 (1.8970)	loss_scale 16384.0000 (9156.2998)	mem 9201MB
[2024-07-28 14:23:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:17 lr 0.000001	 wd 0.0000	time 0.1865 (0.2277)	loss 0.9170 (0.8899)	grad_norm 1.8400 (1.8981)	loss_scale 16384.0000 (9536.5050)	mem 9201MB
[2024-07-28 14:24:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:01:53 lr 0.000001	 wd 0.0000	time 0.1914 (0.2268)	loss 0.8530 (0.8896)	grad_norm 1.8180 (1.8951)	loss_scale 16384.0000 (9878.7086)	mem 9201MB
[2024-07-28 14:24:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:30 lr 0.000001	 wd 0.0000	time 0.2165 (0.2256)	loss 0.9819 (0.8899)	grad_norm 1.9312 (1.8960)	loss_scale 16384.0000 (10188.3370)	mem 9201MB
[2024-07-28 14:24:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:07 lr 0.000001	 wd 0.0000	time 0.2217 (0.2246)	loss 0.9521 (0.8898)	grad_norm 2.2430 (1.8969)	loss_scale 16384.0000 (10469.8301)	mem 9201MB
[2024-07-28 14:25:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:45 lr 0.000001	 wd 0.0000	time 0.1787 (0.2238)	loss 0.8291 (0.8903)	grad_norm 1.8842 (1.8985)	loss_scale 16384.0000 (10726.8561)	mem 9201MB
[2024-07-28 14:25:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:22 lr 0.000001	 wd 0.0000	time 0.2750 (0.2241)	loss 0.9727 (0.8904)	grad_norm 2.2393 (1.8967)	loss_scale 16384.0000 (10962.4723)	mem 9201MB
[2024-07-28 14:26:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1837 (0.2228)	loss 0.8848 (0.8908)	grad_norm 1.7880 (1.8961)	loss_scale 16384.0000 (11179.2467)	mem 9201MB
[2024-07-28 14:26:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 28 training takes 0:09:25
[2024-07-28 14:26:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 18.712 (18.712)	Loss 0.3630 (0.3630)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 14:26:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 85.006 Acc@5 97.530
[2024-07-28 14:26:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-28 14:26:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 85.01%
[2024-07-28 14:26:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-28 14:26:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-28 14:27:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][0/2502]	eta 22:31:57 lr 0.000001	 wd 0.0000	time 32.4210 (32.4210)	loss 0.8452 (0.8452)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 14:27:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:21:18 lr 0.000001	 wd 0.0000	time 0.1961 (0.5323)	loss 1.0596 (0.8909)	grad_norm 1.6484 (1.7809)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 14:28:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:14:00 lr 0.000001	 wd 0.0000	time 0.2006 (0.3651)	loss 0.8643 (0.9001)	grad_norm 1.6743 (1.8255)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 14:28:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:11:26 lr 0.000001	 wd 0.0000	time 0.2258 (0.3116)	loss 0.8462 (0.8975)	grad_norm 1.8560 (1.8704)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 14:28:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:10:52 lr 0.000001	 wd 0.0000	time 0.1814 (0.3105)	loss 0.8013 (0.8993)	grad_norm 1.9274 (1.8961)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 14:29:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:09:36 lr 0.000001	 wd 0.0000	time 0.2082 (0.2882)	loss 0.8374 (0.8986)	grad_norm 2.0627 (1.8901)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 14:29:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:39 lr 0.000001	 wd 0.0000	time 0.1859 (0.2732)	loss 0.8247 (0.8951)	grad_norm 1.6849 (1.8921)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 14:29:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:53 lr 0.000001	 wd 0.0000	time 0.2061 (0.2628)	loss 0.8950 (0.8928)	grad_norm 2.0926 (1.8875)	loss_scale 16384.0000 (16384.0000)	mem 9201MB
[2024-07-28 14:30:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:07:56 lr 0.000001	 wd 0.0000	time 0.2145 (0.2801)	loss 0.7324 (0.8948)	grad_norm 1.9064 (inf)	loss_scale 8192.0000 (16159.0012)	mem 9201MB
[2024-07-28 14:30:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:07:15 lr 0.000001	 wd 0.0000	time 0.2107 (0.2717)	loss 0.8706 (0.8947)	grad_norm 3.1408 (inf)	loss_scale 8192.0000 (15274.7614)	mem 9201MB
[2024-07-28 14:31:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:37 lr 0.000001	 wd 0.0000	time 0.1966 (0.2644)	loss 0.8115 (0.8941)	grad_norm 1.5402 (inf)	loss_scale 8192.0000 (14567.1928)	mem 9201MB
[2024-07-28 14:31:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:06:03 lr 0.000001	 wd 0.0000	time 0.2305 (0.2592)	loss 0.9106 (0.8942)	grad_norm 1.9766 (inf)	loss_scale 8192.0000 (13988.1562)	mem 9201MB
[2024-07-28 14:31:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:33 lr 0.000001	 wd 0.0000	time 0.1883 (0.2563)	loss 0.7959 (0.8927)	grad_norm 1.7241 (inf)	loss_scale 8192.0000 (13505.5454)	mem 9201MB
[2024-07-28 14:32:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:05:03 lr 0.000001	 wd 0.0000	time 0.1837 (0.2523)	loss 0.7959 (0.8937)	grad_norm 1.8942 (inf)	loss_scale 8192.0000 (13097.1253)	mem 9201MB
[2024-07-28 14:32:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:34 lr 0.000001	 wd 0.0000	time 0.1863 (0.2487)	loss 1.0195 (0.8938)	grad_norm 1.8819 (inf)	loss_scale 8192.0000 (12747.0093)	mem 9201MB
[2024-07-28 14:32:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:04:05 lr 0.000001	 wd 0.0000	time 0.1975 (0.2454)	loss 0.7778 (0.8935)	grad_norm 1.9462 (inf)	loss_scale 8192.0000 (12443.5443)	mem 9201MB
[2024-07-28 14:33:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:39 lr 0.000001	 wd 0.0000	time 0.1898 (0.2431)	loss 0.8613 (0.8934)	grad_norm 1.9076 (inf)	loss_scale 8192.0000 (12177.9888)	mem 9201MB
[2024-07-28 14:33:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:14 lr 0.000001	 wd 0.0000	time 0.1999 (0.2421)	loss 1.0537 (0.8941)	grad_norm 1.7749 (inf)	loss_scale 8192.0000 (11943.6567)	mem 9201MB
[2024-07-28 14:33:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:48 lr 0.000001	 wd 0.0000	time 0.1813 (0.2400)	loss 0.7715 (0.8943)	grad_norm 1.6570 (inf)	loss_scale 8192.0000 (11735.3470)	mem 9201MB
[2024-07-28 14:34:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:23 lr 0.000001	 wd 0.0000	time 0.1994 (0.2380)	loss 0.8276 (0.8951)	grad_norm 2.0004 (inf)	loss_scale 8192.0000 (11548.9532)	mem 9201MB
[2024-07-28 14:34:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:01:58 lr 0.000001	 wd 0.0000	time 0.2125 (0.2363)	loss 0.9609 (0.8952)	grad_norm 2.1091 (inf)	loss_scale 8192.0000 (11381.1894)	mem 9201MB
[2024-07-28 14:35:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:34 lr 0.000001	 wd 0.0000	time 0.1778 (0.2348)	loss 0.8613 (0.8951)	grad_norm 2.0329 (inf)	loss_scale 8192.0000 (11229.3955)	mem 9201MB
[2024-07-28 14:35:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:11 lr 0.000001	 wd 0.0000	time 0.1969 (0.2352)	loss 0.9873 (0.8946)	grad_norm 1.4405 (inf)	loss_scale 8192.0000 (11091.3948)	mem 9201MB
[2024-07-28 14:35:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:47 lr 0.000001	 wd 0.0000	time 0.1953 (0.2338)	loss 0.8408 (0.8945)	grad_norm 2.0388 (inf)	loss_scale 8192.0000 (10965.3890)	mem 9201MB
[2024-07-28 14:36:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:23 lr 0.000001	 wd 0.0000	time 0.1884 (0.2324)	loss 0.8789 (0.8946)	grad_norm 1.6974 (inf)	loss_scale 8192.0000 (10849.8792)	mem 9201MB
[2024-07-28 14:36:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1838 (0.2308)	loss 1.0791 (0.8944)	grad_norm 1.6244 (inf)	loss_scale 8192.0000 (10743.6066)	mem 9201MB
[2024-07-28 14:36:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 29 training takes 0:09:47
[2024-07-28 14:36:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_29.pth saving......
[2024-07-28 14:36:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_29.pth saved !!!
[2024-07-28 14:37:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 40.897 (40.897)	Loss 0.3628 (0.3628)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 9201MB
[2024-07-28 14:37:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 85.002 Acc@5 97.528
[2024-07-28 14:37:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-28 14:37:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 85.01%
[2024-07-28 14:37:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 189): INFO Training time 5:15:07
