[2024-07-27 17:15:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 366): INFO Full config saved to pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_conv_b_step_stage3/config.json
[2024-07-27 17:15:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: convnext_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 27
    - 3
    DIMS:
    - 128
    - 256
    - 512
    - 1024
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: stage3
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_conv_b_step_stage3
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_conv_b_step_stage3
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 0.0001
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 0.8
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.0e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 1.0e-08

[2024-07-27 17:15:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/diffusion_finetune/convnext/convnext/diffusion_ft_convnext_base_224_22kto1k_step_stage_process3.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/diffusion-ft", "tag": "diffusion_ft_conv_b_step_stage3", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-27 17:15:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 108): INFO Creating model:convnext_diffusion_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3
[2024-07-27 17:15:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 110): INFO ConvNeXt_Diffusion_Finetune(
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (3): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (4): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (5): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (6): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (7): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (8): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (9): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (10): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (11): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (12): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (13): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (14): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (15): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (16): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (17): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (18): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (19): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (20): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (21): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (22): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (23): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (24): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (25): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (26): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-27 17:15:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 113): INFO number of params: 26377576
[2024-07-27 17:15:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 150): INFO no checkpoint found in pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_conv_b_step_stage3, ignoring auto resume
[2024-07-27 17:15:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth for fine-tuning......
[2024-07-27 17:16:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 127): WARNING <All keys matched successfully>
[2024-07-27 17:16:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_conv_b_step_stage2/ckpt_epoch_best.pth'
[2024-07-27 17:17:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 67.824 (67.824)	Loss 0.3584 (0.3584)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 3131MB
[2024-07-27 17:17:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.628 Acc@5 97.618
[2024-07-27 17:17:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 162): INFO Accuracy of the network on the 50000 test images: 85.6%
[2024-07-27 17:17:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 168): INFO Start training
[2024-07-27 17:17:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][0/2502]	eta 13:52:52 lr 0.000100	 wd 0.0000	time 19.9731 (19.9731)	loss 0.7427 (0.7427)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 7891MB
[2024-07-27 17:18:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:17:13 lr 0.000100	 wd 0.0000	time 0.3915 (0.4302)	loss 0.7891 (0.7589)	grad_norm 1.8348 (nan)	loss_scale 32768.0000 (33092.4356)	mem 7891MB
[2024-07-27 17:18:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:15:26 lr 0.000100	 wd 0.0000	time 0.1779 (0.4024)	loss 0.7515 (0.7702)	grad_norm 1.4272 (nan)	loss_scale 32768.0000 (32931.0249)	mem 7891MB
[2024-07-27 17:19:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:08 lr 0.000100	 wd 0.0000	time 0.1779 (0.3310)	loss 0.7588 (0.7745)	grad_norm 1.6175 (nan)	loss_scale 32768.0000 (32876.8638)	mem 7891MB
[2024-07-27 17:19:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:19 lr 0.000100	 wd 0.0000	time 0.1804 (0.2947)	loss 1.0371 (0.7771)	grad_norm inf (nan)	loss_scale 16384.0000 (32768.0000)	mem 7891MB
[2024-07-27 17:19:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:09:22 lr 0.000100	 wd 0.0000	time 0.4030 (0.2810)	loss 0.6924 (0.7770)	grad_norm 2.5910 (nan)	loss_scale 16384.0000 (29497.7405)	mem 7891MB
[2024-07-27 17:20:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:34 lr 0.000100	 wd 0.0000	time 0.1831 (0.3021)	loss 0.6934 (0.7770)	grad_norm 1.3519 (nan)	loss_scale 16384.0000 (27315.7537)	mem 7891MB
[2024-07-27 17:20:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:35 lr 0.000100	 wd 0.0000	time 0.1738 (0.2859)	loss 0.8203 (0.7775)	grad_norm 2.1740 (nan)	loss_scale 16384.0000 (25756.3024)	mem 7891MB
[2024-07-27 17:21:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:45 lr 0.000100	 wd 0.0000	time 0.1782 (0.2734)	loss 0.7803 (0.7770)	grad_norm 2.6221 (nan)	loss_scale 16384.0000 (24586.2272)	mem 7891MB
[2024-07-27 17:21:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:34 lr 0.000100	 wd 0.0000	time 0.3078 (0.2840)	loss 0.7656 (0.7764)	grad_norm 1.9537 (nan)	loss_scale 16384.0000 (23675.8801)	mem 7891MB
[2024-07-27 17:22:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:07:02 lr 0.000100	 wd 0.0000	time 0.2042 (0.2812)	loss 0.8647 (0.7767)	grad_norm 2.9898 (nan)	loss_scale 16384.0000 (22947.4206)	mem 7891MB
[2024-07-27 17:22:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:22 lr 0.000100	 wd 0.0000	time 0.1862 (0.2727)	loss 0.7202 (0.7769)	grad_norm 2.5608 (nan)	loss_scale 16384.0000 (22351.2879)	mem 7891MB
[2024-07-27 17:22:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:45 lr 0.000100	 wd 0.0000	time 0.1915 (0.2656)	loss 0.7217 (0.7773)	grad_norm 1.3291 (nan)	loss_scale 16384.0000 (21854.4280)	mem 7891MB
[2024-07-27 17:23:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:16 lr 0.000100	 wd 0.0000	time 0.5798 (0.2632)	loss 0.6675 (0.7781)	grad_norm 1.7600 (nan)	loss_scale 16384.0000 (21433.9493)	mem 7891MB
[2024-07-27 17:23:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:48 lr 0.000100	 wd 0.0000	time 0.1851 (0.2615)	loss 0.7847 (0.7778)	grad_norm 2.2299 (nan)	loss_scale 16384.0000 (21073.4961)	mem 7891MB
[2024-07-27 17:23:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:17 lr 0.000100	 wd 0.0000	time 0.1772 (0.2566)	loss 0.8281 (0.7779)	grad_norm 1.5696 (nan)	loss_scale 16384.0000 (20761.0713)	mem 7891MB
[2024-07-27 17:24:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:47 lr 0.000100	 wd 0.0000	time 0.1781 (0.2524)	loss 0.8394 (0.7773)	grad_norm 1.2609 (nan)	loss_scale 16384.0000 (20487.6752)	mem 7891MB
[2024-07-27 17:24:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:19 lr 0.000100	 wd 0.0000	time 0.2415 (0.2493)	loss 0.6631 (0.7770)	grad_norm 1.4565 (nan)	loss_scale 16384.0000 (20246.4245)	mem 7891MB
[2024-07-27 17:25:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:02:57 lr 0.000100	 wd 0.0000	time 0.1791 (0.2532)	loss 0.7524 (0.7769)	grad_norm 1.9589 (nan)	loss_scale 16384.0000 (20031.9645)	mem 7891MB
[2024-07-27 17:25:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:30 lr 0.000100	 wd 0.0000	time 0.1804 (0.2498)	loss 0.7734 (0.7766)	grad_norm 1.1579 (nan)	loss_scale 16384.0000 (19840.0673)	mem 7891MB
[2024-07-27 17:25:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:03 lr 0.000100	 wd 0.0000	time 0.1972 (0.2467)	loss 0.8311 (0.7770)	grad_norm 1.3271 (nan)	loss_scale 16384.0000 (19667.3503)	mem 7891MB
[2024-07-27 17:26:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:38 lr 0.000100	 wd 0.0000	time 0.2070 (0.2442)	loss 0.7124 (0.7773)	grad_norm 1.8190 (nan)	loss_scale 16384.0000 (19511.0747)	mem 7891MB
[2024-07-27 17:26:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:13 lr 0.000100	 wd 0.0000	time 0.2444 (0.2448)	loss 0.8228 (0.7771)	grad_norm 1.9091 (nan)	loss_scale 16384.0000 (19368.9995)	mem 7891MB
[2024-07-27 17:26:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:49 lr 0.000100	 wd 0.0000	time 0.1819 (0.2429)	loss 0.8931 (0.7767)	grad_norm 1.5795 (nan)	loss_scale 16384.0000 (19239.2734)	mem 7891MB
[2024-07-27 17:27:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:24 lr 0.000100	 wd 0.0000	time 0.1882 (0.2408)	loss 0.7275 (0.7768)	grad_norm 1.6096 (nan)	loss_scale 16384.0000 (19120.3532)	mem 7891MB
[2024-07-27 17:27:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000100	 wd 0.0000	time 0.1661 (0.2384)	loss 0.8232 (0.7765)	grad_norm 1.3645 (nan)	loss_scale 16384.0000 (19010.9428)	mem 7891MB
[2024-07-27 17:27:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 0 training takes 0:10:00
[2024-07-27 17:27:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_conv_b_step_stage3/ckpt_epoch_0.pth saving......
[2024-07-27 17:27:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_conv_b_step_stage3/ckpt_epoch_0.pth saved !!!
[2024-07-27 17:28:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 43.254 (43.254)	Loss 0.3716 (0.3716)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 17:28:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.478 Acc@5 97.578
[2024-07-27 17:28:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-27 17:28:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.48%
[2024-07-27 17:28:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_conv_b_step_stage3/ckpt_epoch_best.pth saving......
[2024-07-27 17:28:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_conv_b_step_stage3/ckpt_epoch_best.pth saved !!!
[2024-07-27 17:28:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][0/2502]	eta 10:35:56 lr 0.000100	 wd 0.0000	time 15.2503 (15.2503)	loss 0.8091 (0.8091)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:29:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:13:30 lr 0.000100	 wd 0.0000	time 0.1697 (0.3376)	loss 0.6772 (0.7710)	grad_norm 1.5777 (1.7280)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:29:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:10:22 lr 0.000100	 wd 0.0000	time 0.3198 (0.2703)	loss 0.8696 (0.7767)	grad_norm 1.3137 (1.6701)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:30:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:52 lr 0.000100	 wd 0.0000	time 0.2095 (0.3238)	loss 0.8730 (0.7740)	grad_norm 1.2421 (1.6728)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:30:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:10:10 lr 0.000100	 wd 0.0000	time 0.1782 (0.2904)	loss 0.6826 (0.7767)	grad_norm 1.7117 (1.6794)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:30:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:08:59 lr 0.000100	 wd 0.0000	time 0.1814 (0.2696)	loss 0.8286 (0.7751)	grad_norm 1.8962 (1.6816)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:31:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:08:13 lr 0.000100	 wd 0.0000	time 0.3513 (0.2592)	loss 0.8384 (0.7754)	grad_norm 1.6136 (1.6753)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:31:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:27 lr 0.000100	 wd 0.0000	time 0.1927 (0.2816)	loss 0.6763 (0.7745)	grad_norm 1.6743 (1.6747)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:32:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:39 lr 0.000100	 wd 0.0000	time 0.1738 (0.2699)	loss 0.6646 (0.7744)	grad_norm 1.3282 (1.6816)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:32:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:06:57 lr 0.000099	 wd 0.0000	time 0.1765 (0.2608)	loss 0.8179 (0.7743)	grad_norm 1.7594 (1.6803)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:32:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:23 lr 0.000099	 wd 0.0000	time 0.2818 (0.2556)	loss 0.7598 (0.7733)	grad_norm 1.1857 (1.6862)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:33:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:06:05 lr 0.000099	 wd 0.0000	time 0.1885 (0.2608)	loss 0.8887 (0.7734)	grad_norm 1.8012 (1.6866)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:33:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:31 lr 0.000099	 wd 0.0000	time 0.1881 (0.2548)	loss 0.8101 (0.7733)	grad_norm 1.6729 (1.6860)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:33:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:04:59 lr 0.000099	 wd 0.0000	time 0.1754 (0.2494)	loss 0.8369 (0.7739)	grad_norm 1.4672 (1.6845)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:34:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:30 lr 0.000099	 wd 0.0000	time 0.1781 (0.2455)	loss 0.7646 (0.7745)	grad_norm 1.6548 (1.6905)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:34:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:14 lr 0.000099	 wd 0.0000	time 0.1977 (0.2541)	loss 0.8071 (0.7747)	grad_norm 1.3960 (1.6881)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:35:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:45 lr 0.000099	 wd 0.0000	time 0.1909 (0.2500)	loss 0.8765 (0.7752)	grad_norm 1.0405 (1.6927)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:35:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:17 lr 0.000099	 wd 0.0000	time 0.2097 (0.2463)	loss 0.6831 (0.7751)	grad_norm 1.4394 (1.6893)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:35:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:50 lr 0.000099	 wd 0.0000	time 0.1872 (0.2434)	loss 0.8667 (0.7755)	grad_norm 1.3633 (1.6906)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:36:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:26 lr 0.000099	 wd 0.0000	time 0.1754 (0.2431)	loss 0.7598 (0.7758)	grad_norm 1.6753 (1.6990)	loss_scale 32768.0000 (16418.4745)	mem 7891MB
[2024-07-27 17:36:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:01 lr 0.000099	 wd 0.0000	time 0.1766 (0.2414)	loss 0.6807 (0.7752)	grad_norm 1.4430 (inf)	loss_scale 16384.0000 (16727.8921)	mem 7891MB
[2024-07-27 17:36:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:36 lr 0.000099	 wd 0.0000	time 0.2058 (0.2391)	loss 0.7681 (0.7753)	grad_norm 1.2561 (inf)	loss_scale 16384.0000 (16711.5240)	mem 7891MB
[2024-07-27 17:37:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:11 lr 0.000099	 wd 0.0000	time 0.1951 (0.2369)	loss 0.6206 (0.7750)	grad_norm 1.4395 (inf)	loss_scale 16384.0000 (16696.6433)	mem 7891MB
[2024-07-27 17:37:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:47 lr 0.000099	 wd 0.0000	time 0.2271 (0.2354)	loss 0.8970 (0.7752)	grad_norm 1.7628 (inf)	loss_scale 16384.0000 (16683.0561)	mem 7891MB
[2024-07-27 17:37:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:23 lr 0.000099	 wd 0.0000	time 0.2077 (0.2351)	loss 0.8120 (0.7751)	grad_norm 1.5938 (inf)	loss_scale 16384.0000 (16670.6006)	mem 7891MB
[2024-07-27 17:38:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000099	 wd 0.0000	time 0.1664 (0.2331)	loss 0.9009 (0.7752)	grad_norm 1.5414 (inf)	loss_scale 16384.0000 (16659.1411)	mem 7891MB
[2024-07-27 17:38:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 1 training takes 0:09:47
[2024-07-27 17:38:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 26.379 (26.379)	Loss 0.3645 (0.3645)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 17:38:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.390 Acc@5 97.524
[2024-07-27 17:38:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 17:38:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.48%
[2024-07-27 17:39:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][0/2502]	eta 1 day, 0:40:06 lr 0.000099	 wd 0.0000	time 35.4942 (35.4942)	loss 0.7188 (0.7188)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:39:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:21:44 lr 0.000099	 wd 0.0000	time 0.1991 (0.5430)	loss 0.7422 (0.7727)	grad_norm 2.8080 (1.9432)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:40:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:14:02 lr 0.000099	 wd 0.0000	time 0.1876 (0.3659)	loss 0.7397 (0.7643)	grad_norm 1.7595 (1.8251)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:40:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:11:13 lr 0.000099	 wd 0.0000	time 0.1774 (0.3060)	loss 0.8237 (0.7653)	grad_norm 1.6296 (1.7566)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:40:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:10:02 lr 0.000099	 wd 0.0000	time 0.3241 (0.2868)	loss 0.6851 (0.7661)	grad_norm 1.4950 (1.7123)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:41:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:10:04 lr 0.000099	 wd 0.0000	time 0.2147 (0.3018)	loss 0.9414 (0.7649)	grad_norm 1.9509 (1.7077)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:41:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:58 lr 0.000099	 wd 0.0000	time 0.1937 (0.2832)	loss 0.7954 (0.7652)	grad_norm 1.8191 (1.6887)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:42:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:08:05 lr 0.000099	 wd 0.0000	time 0.1818 (0.2693)	loss 0.9414 (0.7652)	grad_norm 1.7382 (1.7170)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:42:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:25 lr 0.000099	 wd 0.0000	time 0.3303 (0.2615)	loss 0.6357 (0.7643)	grad_norm 1.2821 (1.7324)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:42:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:07:15 lr 0.000098	 wd 0.0000	time 0.2059 (0.2719)	loss 0.7202 (0.7650)	grad_norm 1.5537 (1.7188)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:43:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:35 lr 0.000098	 wd 0.0000	time 0.1836 (0.2635)	loss 0.7656 (0.7651)	grad_norm 1.5890 (1.7206)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:43:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:59 lr 0.000098	 wd 0.0000	time 0.1702 (0.2565)	loss 0.7236 (0.7650)	grad_norm 1.4498 (1.7211)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:43:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:27 lr 0.000098	 wd 0.0000	time 0.2239 (0.2513)	loss 0.8921 (0.7646)	grad_norm 1.9413 (1.7188)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:44:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:05:15 lr 0.000098	 wd 0.0000	time 0.2083 (0.2629)	loss 0.7832 (0.7652)	grad_norm 1.6980 (1.7141)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:44:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:43 lr 0.000098	 wd 0.0000	time 0.1943 (0.2576)	loss 0.7954 (0.7652)	grad_norm 1.5582 (1.7241)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:45:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:13 lr 0.000098	 wd 0.0000	time 0.1708 (0.2528)	loss 0.7026 (0.7653)	grad_norm 1.4479 (1.7169)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:45:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:44 lr 0.000098	 wd 0.0000	time 0.2066 (0.2492)	loss 0.7578 (0.7655)	grad_norm 1.2015 (1.7116)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:45:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:18 lr 0.000098	 wd 0.0000	time 0.1905 (0.2479)	loss 0.8452 (0.7658)	grad_norm 1.3253 (1.6966)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:46:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:52 lr 0.000098	 wd 0.0000	time 0.1844 (0.2454)	loss 0.6948 (0.7655)	grad_norm 1.5356 (1.6928)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:46:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:26 lr 0.000098	 wd 0.0000	time 0.1798 (0.2426)	loss 0.7065 (0.7658)	grad_norm 1.5934 (1.6987)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:46:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:02:00 lr 0.000098	 wd 0.0000	time 0.1748 (0.2402)	loss 0.7837 (0.7654)	grad_norm 1.7932 (1.6961)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:47:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:36 lr 0.000098	 wd 0.0000	time 0.2386 (0.2390)	loss 0.8389 (0.7658)	grad_norm 1.3618 (1.6958)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:47:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:12 lr 0.000098	 wd 0.0000	time 0.2165 (0.2389)	loss 0.7363 (0.7657)	grad_norm 2.5632 (1.6904)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:48:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:47 lr 0.000098	 wd 0.0000	time 0.1714 (0.2371)	loss 0.8608 (0.7656)	grad_norm 1.1615 (1.6865)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:48:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:23 lr 0.000098	 wd 0.0000	time 0.1761 (0.2352)	loss 0.9775 (0.7658)	grad_norm 1.4253 (1.6832)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:48:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000098	 wd 0.0000	time 0.1727 (0.2330)	loss 0.7485 (0.7663)	grad_norm 1.8484 (1.6788)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:48:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 2 training takes 0:09:47
[2024-07-27 17:49:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 44.057 (44.057)	Loss 0.3655 (0.3655)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 17:49:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.402 Acc@5 97.518
[2024-07-27 17:49:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 17:49:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.48%
[2024-07-27 17:49:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][0/2502]	eta 12:11:16 lr 0.000098	 wd 0.0000	time 17.5367 (17.5367)	loss 0.6816 (0.6816)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:50:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:14:22 lr 0.000098	 wd 0.0000	time 0.1780 (0.3589)	loss 0.7344 (0.7616)	grad_norm 1.4208 (1.5477)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:50:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:13:10 lr 0.000097	 wd 0.0000	time 0.2412 (0.3435)	loss 0.7363 (0.7630)	grad_norm 1.2439 (1.6308)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:51:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:11:00 lr 0.000097	 wd 0.0000	time 0.1772 (0.3001)	loss 0.9023 (0.7642)	grad_norm 1.4553 (1.6351)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:51:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:09:32 lr 0.000097	 wd 0.0000	time 0.1857 (0.2721)	loss 0.7754 (0.7636)	grad_norm 1.1640 (1.6723)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:51:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:08:30 lr 0.000097	 wd 0.0000	time 0.2115 (0.2548)	loss 0.7520 (0.7630)	grad_norm 1.6497 (1.6708)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:52:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:07:54 lr 0.000097	 wd 0.0000	time 0.3181 (0.2495)	loss 0.6694 (0.7619)	grad_norm 1.7706 (1.6780)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:52:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:08:00 lr 0.000097	 wd 0.0000	time 0.1934 (0.2664)	loss 0.8701 (0.7622)	grad_norm 1.4423 (1.7027)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:53:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:16 lr 0.000097	 wd 0.0000	time 0.1798 (0.2567)	loss 0.8159 (0.7631)	grad_norm 1.3932 (1.7027)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:53:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:06:39 lr 0.000097	 wd 0.0000	time 0.1998 (0.2492)	loss 0.8481 (0.7630)	grad_norm 1.5543 (1.6867)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 17:53:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:08 lr 0.000097	 wd 0.0000	time 0.3461 (0.2453)	loss 0.8071 (0.7637)	grad_norm 1.5906 (1.6929)	loss_scale 32768.0000 (17464.2637)	mem 7891MB
[2024-07-27 17:54:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:05:48 lr 0.000097	 wd 0.0000	time 0.1921 (0.2485)	loss 0.7168 (0.7651)	grad_norm 2.1189 (1.6953)	loss_scale 32768.0000 (18854.2489)	mem 7891MB
[2024-07-27 17:54:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:16 lr 0.000097	 wd 0.0000	time 0.1954 (0.2434)	loss 0.8677 (0.7658)	grad_norm 2.1478 (1.7009)	loss_scale 32768.0000 (20012.7627)	mem 7891MB
[2024-07-27 17:54:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:04:47 lr 0.000097	 wd 0.0000	time 0.1833 (0.2389)	loss 0.8994 (0.7662)	grad_norm 1.4728 (1.6936)	loss_scale 32768.0000 (20993.1806)	mem 7891MB
[2024-07-27 17:55:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:19 lr 0.000097	 wd 0.0000	time 0.2064 (0.2356)	loss 0.7070 (0.7666)	grad_norm 2.6213 (1.6895)	loss_scale 32768.0000 (21833.6388)	mem 7891MB
[2024-07-27 17:55:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:01 lr 0.000097	 wd 0.0000	time 0.2397 (0.2408)	loss 0.6733 (0.7671)	grad_norm 1.9520 (1.6871)	loss_scale 32768.0000 (22562.1106)	mem 7891MB
[2024-07-27 17:55:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:34 lr 0.000096	 wd 0.0000	time 0.1727 (0.2376)	loss 0.6982 (0.7667)	grad_norm 2.2637 (1.6910)	loss_scale 32768.0000 (23199.5803)	mem 7891MB
[2024-07-27 17:56:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:08 lr 0.000096	 wd 0.0000	time 0.1781 (0.2346)	loss 0.7754 (0.7668)	grad_norm 1.4380 (1.6906)	loss_scale 32768.0000 (23762.0976)	mem 7891MB
[2024-07-27 17:56:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:42 lr 0.000096	 wd 0.0000	time 0.1735 (0.2321)	loss 0.8564 (0.7664)	grad_norm 1.6778 (1.6916)	loss_scale 32768.0000 (24262.1477)	mem 7891MB
[2024-07-27 17:56:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:18 lr 0.000096	 wd 0.0000	time 0.1944 (0.2308)	loss 0.7798 (0.7666)	grad_norm 1.6491 (1.6928)	loss_scale 32768.0000 (24709.5886)	mem 7891MB
[2024-07-27 17:57:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:01:56 lr 0.000096	 wd 0.0000	time 0.3179 (0.2315)	loss 0.7480 (0.7665)	grad_norm 1.7124 (1.6927)	loss_scale 32768.0000 (25112.3078)	mem 7891MB
[2024-07-27 17:57:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:32 lr 0.000096	 wd 0.0000	time 0.1808 (0.2300)	loss 0.7300 (0.7665)	grad_norm 1.5779 (1.6947)	loss_scale 32768.0000 (25476.6911)	mem 7891MB
[2024-07-27 17:58:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:08 lr 0.000096	 wd 0.0000	time 0.1748 (0.2283)	loss 0.7998 (0.7663)	grad_norm 1.1776 (inf)	loss_scale 16384.0000 (25078.4625)	mem 7891MB
[2024-07-27 17:58:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:45 lr 0.000096	 wd 0.0000	time 0.2094 (0.2268)	loss 0.8140 (0.7662)	grad_norm 1.5517 (inf)	loss_scale 16384.0000 (24700.6067)	mem 7891MB
[2024-07-27 17:58:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:23 lr 0.000096	 wd 0.0000	time 0.2190 (0.2262)	loss 0.7568 (0.7660)	grad_norm 1.9701 (inf)	loss_scale 16384.0000 (24354.2257)	mem 7891MB
[2024-07-27 17:59:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000096	 wd 0.0000	time 0.1670 (0.2251)	loss 0.8477 (0.7661)	grad_norm 1.6146 (inf)	loss_scale 16384.0000 (24035.5442)	mem 7891MB
[2024-07-27 17:59:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 3 training takes 0:09:29
[2024-07-27 17:59:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 24.421 (24.421)	Loss 0.3777 (0.3777)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 17:59:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.358 Acc@5 97.570
[2024-07-27 17:59:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 17:59:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.48%
[2024-07-27 18:00:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][0/2502]	eta 12:23:49 lr 0.000096	 wd 0.0000	time 17.8375 (17.8375)	loss 0.7998 (0.7998)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:00:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:19:21 lr 0.000096	 wd 0.0000	time 0.2070 (0.4836)	loss 0.6562 (0.7609)	grad_norm 2.2261 (1.6725)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:00:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:12:54 lr 0.000096	 wd 0.0000	time 0.1724 (0.3363)	loss 0.8687 (0.7667)	grad_norm 1.2974 (1.6293)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:01:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:10:31 lr 0.000095	 wd 0.0000	time 0.1977 (0.2870)	loss 0.7686 (0.7656)	grad_norm 1.8463 (1.6671)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:01:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:09:10 lr 0.000095	 wd 0.0000	time 0.2013 (0.2618)	loss 0.8071 (0.7620)	grad_norm 1.1294 (1.6387)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:01:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:08:48 lr 0.000095	 wd 0.0000	time 0.5734 (0.2639)	loss 0.8184 (0.7612)	grad_norm 2.0046 (1.6172)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:02:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:08:36 lr 0.000095	 wd 0.0000	time 0.1774 (0.2717)	loss 0.7515 (0.7629)	grad_norm 1.5919 (1.6202)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:02:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:07:48 lr 0.000095	 wd 0.0000	time 0.1688 (0.2600)	loss 0.8994 (0.7614)	grad_norm 1.6576 (1.6235)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:03:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:06 lr 0.000095	 wd 0.0000	time 0.1816 (0.2509)	loss 0.6538 (0.7606)	grad_norm 1.2410 (1.6204)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:03:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:06:39 lr 0.000095	 wd 0.0000	time 0.3538 (0.2492)	loss 0.7734 (0.7607)	grad_norm 1.8592 (1.6491)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:03:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:22 lr 0.000095	 wd 0.0000	time 0.1790 (0.2549)	loss 0.7500 (0.7609)	grad_norm 1.4086 (1.6791)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:04:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:05:48 lr 0.000095	 wd 0.0000	time 0.1709 (0.2488)	loss 0.7637 (0.7613)	grad_norm 1.4152 (1.6824)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:04:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:16 lr 0.000095	 wd 0.0000	time 0.1840 (0.2434)	loss 0.6899 (0.7612)	grad_norm 1.8428 (1.6876)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:04:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:04:47 lr 0.000095	 wd 0.0000	time 0.2738 (0.2395)	loss 0.6680 (0.7605)	grad_norm 1.2437 (1.6893)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:05:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:30 lr 0.000094	 wd 0.0000	time 0.2003 (0.2455)	loss 0.7407 (0.7598)	grad_norm 2.6427 (1.6896)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:05:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:02 lr 0.000094	 wd 0.0000	time 0.1683 (0.2417)	loss 0.7002 (0.7600)	grad_norm 1.4550 (1.6883)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:06:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:34 lr 0.000094	 wd 0.0000	time 0.1826 (0.2382)	loss 0.7783 (0.7603)	grad_norm 1.1723 (1.6851)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:06:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:08 lr 0.000094	 wd 0.0000	time 0.2031 (0.2354)	loss 0.7852 (0.7609)	grad_norm 1.3053 (1.6838)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:06:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:48 lr 0.000094	 wd 0.0000	time 0.2004 (0.2396)	loss 0.8198 (0.7616)	grad_norm 1.6155 (1.6929)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:07:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:22 lr 0.000094	 wd 0.0000	time 0.1885 (0.2370)	loss 0.7065 (0.7612)	grad_norm 1.6386 (1.6896)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:07:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:01:57 lr 0.000094	 wd 0.0000	time 0.1973 (0.2347)	loss 0.6724 (0.7608)	grad_norm 1.8214 (1.6837)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:07:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:33 lr 0.000094	 wd 0.0000	time 0.1829 (0.2326)	loss 0.7422 (0.7610)	grad_norm 2.9937 (1.6866)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:08:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:09 lr 0.000094	 wd 0.0000	time 0.2184 (0.2315)	loss 0.7798 (0.7608)	grad_norm 1.6247 (1.6919)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:08:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:46 lr 0.000094	 wd 0.0000	time 0.2181 (0.2313)	loss 0.7134 (0.7613)	grad_norm 2.1498 (1.6930)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:08:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:23 lr 0.000093	 wd 0.0000	time 0.1822 (0.2298)	loss 0.6777 (0.7613)	grad_norm 1.4366 (1.6886)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:09:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000093	 wd 0.0000	time 0.1705 (0.2279)	loss 0.6816 (0.7614)	grad_norm 1.4022 (1.6882)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:09:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 4 training takes 0:09:34
[2024-07-27 18:09:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 26.732 (26.732)	Loss 0.3701 (0.3701)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 18:10:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.478 Acc@5 97.552
[2024-07-27 18:10:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-27 18:10:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.48%
[2024-07-27 18:10:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_conv_b_step_stage3/ckpt_epoch_best.pth saving......
[2024-07-27 18:10:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_conv_b_step_stage3/ckpt_epoch_best.pth saved !!!
[2024-07-27 18:10:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][0/2502]	eta 11:51:39 lr 0.000093	 wd 0.0000	time 17.0661 (17.0661)	loss 0.8892 (0.8892)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:10:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:14:19 lr 0.000093	 wd 0.0000	time 0.1696 (0.3580)	loss 0.7012 (0.7556)	grad_norm 1.4929 (1.6011)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:11:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:10:28 lr 0.000093	 wd 0.0000	time 0.1791 (0.2729)	loss 0.7173 (0.7599)	grad_norm 1.2940 (1.6245)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:11:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:53 lr 0.000093	 wd 0.0000	time 0.3741 (0.2968)	loss 0.7480 (0.7577)	grad_norm 1.0897 (1.6822)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:12:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:59 lr 0.000093	 wd 0.0000	time 0.1850 (0.2854)	loss 0.6680 (0.7568)	grad_norm 1.6316 (1.7298)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:12:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:08:52 lr 0.000093	 wd 0.0000	time 0.1825 (0.2659)	loss 0.7905 (0.7567)	grad_norm 2.5003 (1.7602)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:12:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:00 lr 0.000093	 wd 0.0000	time 0.1846 (0.2525)	loss 0.9614 (0.7583)	grad_norm 1.3879 (1.7432)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:13:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:27 lr 0.000093	 wd 0.0000	time 0.3518 (0.2486)	loss 0.8169 (0.7587)	grad_norm 2.2970 (1.7440)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:13:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:17 lr 0.000093	 wd 0.0000	time 0.1721 (0.2570)	loss 0.8574 (0.7594)	grad_norm 1.5555 (1.7295)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:13:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:39 lr 0.000092	 wd 0.0000	time 0.1917 (0.2493)	loss 0.7344 (0.7593)	grad_norm 1.6131 (inf)	loss_scale 8192.0000 (15529.3407)	mem 7891MB
[2024-07-27 18:14:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:05 lr 0.000092	 wd 0.0000	time 0.2001 (0.2431)	loss 0.7095 (0.7593)	grad_norm 1.7297 (inf)	loss_scale 8192.0000 (14796.3397)	mem 7891MB
[2024-07-27 18:14:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:35 lr 0.000092	 wd 0.0000	time 0.2231 (0.2392)	loss 0.6943 (0.7596)	grad_norm 2.7651 (inf)	loss_scale 8192.0000 (14196.4905)	mem 7891MB
[2024-07-27 18:15:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:15 lr 0.000092	 wd 0.0000	time 0.1928 (0.2423)	loss 0.8574 (0.7597)	grad_norm 1.2241 (inf)	loss_scale 8192.0000 (13696.5329)	mem 7891MB
[2024-07-27 18:15:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:46 lr 0.000092	 wd 0.0000	time 0.1751 (0.2381)	loss 0.7441 (0.7593)	grad_norm 1.1786 (inf)	loss_scale 8192.0000 (13273.4327)	mem 7891MB
[2024-07-27 18:15:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:18 lr 0.000092	 wd 0.0000	time 0.2157 (0.2346)	loss 0.8110 (0.7590)	grad_norm 1.6166 (inf)	loss_scale 8192.0000 (12910.7323)	mem 7891MB
[2024-07-27 18:16:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:03:52 lr 0.000092	 wd 0.0000	time 0.1917 (0.2317)	loss 0.8281 (0.7591)	grad_norm 2.0205 (inf)	loss_scale 8192.0000 (12596.3598)	mem 7891MB
[2024-07-27 18:16:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:28 lr 0.000092	 wd 0.0000	time 0.2081 (0.2314)	loss 0.7075 (0.7587)	grad_norm 1.4587 (inf)	loss_scale 8192.0000 (12321.2592)	mem 7891MB
[2024-07-27 18:16:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:04 lr 0.000092	 wd 0.0000	time 0.1846 (0.2304)	loss 0.7534 (0.7586)	grad_norm 1.5355 (inf)	loss_scale 4096.0000 (11842.5209)	mem 7891MB
[2024-07-27 18:17:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:40 lr 0.000091	 wd 0.0000	time 0.1753 (0.2285)	loss 0.6812 (0.7585)	grad_norm 1.4865 (inf)	loss_scale 4096.0000 (11412.3976)	mem 7891MB
[2024-07-27 18:17:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:16 lr 0.000091	 wd 0.0000	time 0.1803 (0.2266)	loss 0.8735 (0.7590)	grad_norm 1.6071 (inf)	loss_scale 4096.0000 (11027.5266)	mem 7891MB
[2024-07-27 18:17:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:01:53 lr 0.000091	 wd 0.0000	time 0.2188 (0.2251)	loss 0.8945 (0.7588)	grad_norm 1.2934 (inf)	loss_scale 4096.0000 (10681.1234)	mem 7891MB
[2024-07-27 18:18:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:30 lr 0.000091	 wd 0.0000	time 0.1776 (0.2258)	loss 0.7598 (0.7581)	grad_norm 1.6443 (inf)	loss_scale 4096.0000 (10367.6954)	mem 7891MB
[2024-07-27 18:18:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:07 lr 0.000091	 wd 0.0000	time 0.1932 (0.2248)	loss 0.7554 (0.7580)	grad_norm 1.3809 (inf)	loss_scale 4096.0000 (10082.7478)	mem 7891MB
[2024-07-27 18:18:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:45 lr 0.000091	 wd 0.0000	time 0.1962 (0.2234)	loss 0.6221 (0.7576)	grad_norm 1.3605 (inf)	loss_scale 4096.0000 (9822.5676)	mem 7891MB
[2024-07-27 18:19:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:22 lr 0.000091	 wd 0.0000	time 0.2088 (0.2219)	loss 0.7515 (0.7576)	grad_norm 1.5248 (inf)	loss_scale 4096.0000 (9584.0600)	mem 7891MB
[2024-07-27 18:19:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000091	 wd 0.0000	time 0.1673 (0.2203)	loss 0.7378 (0.7578)	grad_norm 1.9584 (inf)	loss_scale 4096.0000 (9364.6253)	mem 7891MB
[2024-07-27 18:19:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 5 training takes 0:09:15
[2024-07-27 18:20:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 42.770 (42.770)	Loss 0.3721 (0.3721)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 18:20:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.522 Acc@5 97.518
[2024-07-27 18:20:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-27 18:20:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 18:20:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_conv_b_step_stage3/ckpt_epoch_best.pth saving......
[2024-07-27 18:20:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_conv_b_step_stage3/ckpt_epoch_best.pth saved !!!
[2024-07-27 18:20:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][0/2502]	eta 10:32:14 lr 0.000091	 wd 0.0000	time 15.1618 (15.1618)	loss 0.8413 (0.8413)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:21:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:14:54 lr 0.000090	 wd 0.0000	time 0.4369 (0.3726)	loss 0.7148 (0.7549)	grad_norm 1.9095 (1.6315)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:21:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:13:25 lr 0.000090	 wd 0.0000	time 0.1802 (0.3498)	loss 0.6919 (0.7536)	grad_norm 1.5970 (1.6404)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:21:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:10:51 lr 0.000090	 wd 0.0000	time 0.1722 (0.2958)	loss 0.7949 (0.7558)	grad_norm 1.5489 (1.6140)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:22:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:09:24 lr 0.000090	 wd 0.0000	time 0.1763 (0.2685)	loss 0.7725 (0.7550)	grad_norm 1.1996 (1.6141)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:22:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:08:25 lr 0.000090	 wd 0.0000	time 0.1824 (0.2527)	loss 0.8247 (0.7529)	grad_norm 1.8072 (1.6288)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:23:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:08:49 lr 0.000090	 wd 0.0000	time 0.1809 (0.2783)	loss 0.8130 (0.7528)	grad_norm 1.8030 (1.6425)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:23:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:07:58 lr 0.000090	 wd 0.0000	time 0.1805 (0.2654)	loss 0.8369 (0.7545)	grad_norm 1.5027 (1.6208)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:23:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:15 lr 0.000090	 wd 0.0000	time 0.1877 (0.2558)	loss 0.6953 (0.7554)	grad_norm 1.8497 (1.6141)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:24:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:06:38 lr 0.000089	 wd 0.0000	time 0.2512 (0.2491)	loss 0.7666 (0.7552)	grad_norm 1.0370 (1.6231)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:24:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:31 lr 0.000089	 wd 0.0000	time 0.1741 (0.2609)	loss 0.7622 (0.7563)	grad_norm 1.5232 (1.6280)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:25:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:56 lr 0.000089	 wd 0.0000	time 0.1981 (0.2545)	loss 0.6826 (0.7557)	grad_norm 1.8147 (1.6389)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:25:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:24 lr 0.000089	 wd 0.0000	time 0.1796 (0.2489)	loss 0.6187 (0.7560)	grad_norm 1.4401 (1.6394)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:25:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:04:53 lr 0.000089	 wd 0.0000	time 0.2158 (0.2444)	loss 0.7065 (0.7569)	grad_norm 1.8150 (1.6526)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:26:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:33 lr 0.000089	 wd 0.0000	time 0.1878 (0.2485)	loss 0.9155 (0.7556)	grad_norm 1.5934 (1.6509)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:26:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:05 lr 0.000089	 wd 0.0000	time 0.1705 (0.2446)	loss 0.6387 (0.7555)	grad_norm 1.2715 (1.6505)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:26:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:37 lr 0.000089	 wd 0.0000	time 0.1988 (0.2412)	loss 0.8174 (0.7553)	grad_norm 1.3819 (1.6524)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:27:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:11 lr 0.000088	 wd 0.0000	time 0.2244 (0.2382)	loss 0.8638 (0.7545)	grad_norm 3.0455 (1.6647)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:27:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:45 lr 0.000088	 wd 0.0000	time 0.2285 (0.2362)	loss 0.6836 (0.7537)	grad_norm 1.1698 (1.6648)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:27:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:22 lr 0.000088	 wd 0.0000	time 0.1676 (0.2364)	loss 0.8320 (0.7537)	grad_norm 1.4624 (1.6590)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:28:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:01:57 lr 0.000088	 wd 0.0000	time 0.2138 (0.2344)	loss 0.9253 (0.7545)	grad_norm 1.6269 (1.6654)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:28:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:33 lr 0.000088	 wd 0.0000	time 0.1805 (0.2324)	loss 0.7954 (0.7548)	grad_norm 1.6061 (1.6715)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:28:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:09 lr 0.000088	 wd 0.0000	time 0.1622 (0.2305)	loss 0.7812 (0.7552)	grad_norm 1.4784 (1.6730)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:29:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:46 lr 0.000088	 wd 0.0000	time 0.2091 (0.2297)	loss 0.7842 (0.7550)	grad_norm 1.6104 (1.6697)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:29:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:23 lr 0.000087	 wd 0.0000	time 0.1773 (0.2297)	loss 0.7705 (0.7548)	grad_norm 1.3951 (1.6717)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:29:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000087	 wd 0.0000	time 0.1664 (0.2278)	loss 0.6787 (0.7544)	grad_norm 1.4481 (1.6712)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:30:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 6 training takes 0:09:34
[2024-07-27 18:30:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 19.156 (19.156)	Loss 0.3660 (0.3660)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 18:30:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.450 Acc@5 97.526
[2024-07-27 18:30:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 18:30:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 18:31:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][0/2502]	eta 1 day, 1:06:54 lr 0.000087	 wd 0.0000	time 36.1368 (36.1368)	loss 0.8154 (0.8154)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:31:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:22:46 lr 0.000087	 wd 0.0000	time 0.1620 (0.5689)	loss 0.8887 (0.7611)	grad_norm 1.9112 (1.7012)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:31:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:14:31 lr 0.000087	 wd 0.0000	time 0.1723 (0.3787)	loss 0.7974 (0.7495)	grad_norm 2.6485 (1.6911)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:32:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:11:31 lr 0.000087	 wd 0.0000	time 0.1764 (0.3141)	loss 0.7480 (0.7490)	grad_norm 1.9502 (1.6963)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:32:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:11:13 lr 0.000087	 wd 0.0000	time 0.3311 (0.3203)	loss 0.8184 (0.7484)	grad_norm 1.4831 (1.6921)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:33:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:10:12 lr 0.000087	 wd 0.0000	time 0.1901 (0.3060)	loss 0.6753 (0.7491)	grad_norm 1.5252 (1.6781)	loss_scale 4096.0000 (4096.0000)	mem 7891MB
[2024-07-27 18:33:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:09:05 lr 0.000086	 wd 0.0000	time 0.1884 (0.2866)	loss 0.7505 (0.7498)	grad_norm 1.2565 (1.6579)	loss_scale 8192.0000 (4109.6306)	mem 7891MB
[2024-07-27 18:33:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:08:10 lr 0.000086	 wd 0.0000	time 0.1876 (0.2723)	loss 0.6528 (0.7486)	grad_norm 1.4485 (1.6519)	loss_scale 8192.0000 (4691.9943)	mem 7891MB
[2024-07-27 18:34:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:07:57 lr 0.000086	 wd 0.0000	time 0.2175 (0.2808)	loss 0.7427 (0.7491)	grad_norm 2.1182 (1.6480)	loss_scale 8192.0000 (5128.9488)	mem 7891MB
[2024-07-27 18:34:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:07:15 lr 0.000086	 wd 0.0000	time 0.1756 (0.2718)	loss 0.6436 (0.7498)	grad_norm 1.5536 (1.6450)	loss_scale 8192.0000 (5468.9101)	mem 7891MB
[2024-07-27 18:34:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:35 lr 0.000086	 wd 0.0000	time 0.1761 (0.2634)	loss 0.7358 (0.7504)	grad_norm 1.4462 (1.6455)	loss_scale 8192.0000 (5740.9471)	mem 7891MB
[2024-07-27 18:35:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:59 lr 0.000086	 wd 0.0000	time 0.1798 (0.2563)	loss 0.7236 (0.7498)	grad_norm 1.5695 (1.6490)	loss_scale 8192.0000 (5963.5677)	mem 7891MB
[2024-07-27 18:35:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:29 lr 0.000086	 wd 0.0000	time 0.3632 (0.2534)	loss 0.6880 (0.7507)	grad_norm 1.7150 (1.6473)	loss_scale 8192.0000 (6149.1157)	mem 7891MB
[2024-07-27 18:36:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:05:15 lr 0.000085	 wd 0.0000	time 0.1817 (0.2628)	loss 0.7803 (0.7506)	grad_norm 1.6241 (1.6436)	loss_scale 8192.0000 (6306.1399)	mem 7891MB
[2024-07-27 18:36:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:43 lr 0.000085	 wd 0.0000	time 0.1762 (0.2575)	loss 0.7368 (0.7512)	grad_norm 1.5407 (1.6447)	loss_scale 8192.0000 (6440.7480)	mem 7891MB
[2024-07-27 18:36:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:13 lr 0.000085	 wd 0.0000	time 0.1897 (0.2529)	loss 0.6528 (0.7506)	grad_norm 1.7902 (1.6471)	loss_scale 8192.0000 (6557.4204)	mem 7891MB
[2024-07-27 18:37:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:45 lr 0.000085	 wd 0.0000	time 0.1854 (0.2495)	loss 0.7822 (0.7511)	grad_norm 1.3912 (1.6423)	loss_scale 8192.0000 (6659.5178)	mem 7891MB
[2024-07-27 18:37:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:19 lr 0.000085	 wd 0.0000	time 0.1799 (0.2487)	loss 0.7222 (0.7510)	grad_norm 2.2238 (1.6393)	loss_scale 8192.0000 (6749.6108)	mem 7891MB
[2024-07-27 18:37:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:52 lr 0.000085	 wd 0.0000	time 0.1933 (0.2456)	loss 0.7002 (0.7501)	grad_norm 2.5678 (1.6347)	loss_scale 8192.0000 (6829.6991)	mem 7891MB
[2024-07-27 18:38:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:26 lr 0.000085	 wd 0.0000	time 0.1796 (0.2428)	loss 0.8452 (0.7508)	grad_norm 1.4288 (1.6308)	loss_scale 8192.0000 (6901.3614)	mem 7891MB
[2024-07-27 18:38:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:02:00 lr 0.000084	 wd 0.0000	time 0.1992 (0.2403)	loss 0.6592 (0.7506)	grad_norm 1.4473 (1.6373)	loss_scale 8192.0000 (6965.8611)	mem 7891MB
[2024-07-27 18:39:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:37 lr 0.000084	 wd 0.0000	time 0.2688 (0.2434)	loss 0.7383 (0.7510)	grad_norm 1.8660 (1.6386)	loss_scale 8192.0000 (7024.2208)	mem 7891MB
[2024-07-27 18:39:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:12 lr 0.000084	 wd 0.0000	time 0.1925 (0.2413)	loss 0.7085 (0.7509)	grad_norm 2.1687 (1.6476)	loss_scale 8192.0000 (7077.2776)	mem 7891MB
[2024-07-27 18:39:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:48 lr 0.000084	 wd 0.0000	time 0.1765 (0.2390)	loss 0.7578 (0.7507)	grad_norm 1.6557 (1.6514)	loss_scale 8192.0000 (7125.7227)	mem 7891MB
[2024-07-27 18:40:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:24 lr 0.000084	 wd 0.0000	time 0.1835 (0.2370)	loss 0.7109 (0.7512)	grad_norm 1.2782 (1.6508)	loss_scale 8192.0000 (7170.1324)	mem 7891MB
[2024-07-27 18:40:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000084	 wd 0.0000	time 0.1689 (0.2347)	loss 0.6855 (0.7515)	grad_norm 1.4518 (1.6553)	loss_scale 8192.0000 (7210.9908)	mem 7891MB
[2024-07-27 18:40:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 7 training takes 0:09:52
[2024-07-27 18:41:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 44.843 (44.843)	Loss 0.3594 (0.3594)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 18:41:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.354 Acc@5 97.576
[2024-07-27 18:41:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 18:41:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 18:41:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][0/2502]	eta 11:36:48 lr 0.000084	 wd 0.0000	time 16.7099 (16.7099)	loss 0.8398 (0.8398)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:41:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:14:33 lr 0.000083	 wd 0.0000	time 0.2654 (0.3638)	loss 0.7188 (0.7585)	grad_norm 1.9768 (1.6189)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:42:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:13:26 lr 0.000083	 wd 0.0000	time 0.1737 (0.3504)	loss 0.6904 (0.7516)	grad_norm 1.4036 (1.5767)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:42:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:10:51 lr 0.000083	 wd 0.0000	time 0.1760 (0.2959)	loss 0.7910 (0.7470)	grad_norm 1.3140 (1.6086)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:43:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:09:25 lr 0.000083	 wd 0.0000	time 0.1907 (0.2689)	loss 0.7769 (0.7471)	grad_norm 1.4620 (1.6241)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:43:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:08:25 lr 0.000083	 wd 0.0000	time 0.1914 (0.2527)	loss 0.7510 (0.7483)	grad_norm 1.7110 (1.6476)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:44:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:49 lr 0.000083	 wd 0.0000	time 0.1921 (0.2786)	loss 0.6885 (0.7483)	grad_norm 2.5939 (1.6624)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:44:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:59 lr 0.000083	 wd 0.0000	time 0.1943 (0.2663)	loss 0.8989 (0.7473)	grad_norm 1.7705 (1.6614)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:44:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:16 lr 0.000082	 wd 0.0000	time 0.1875 (0.2566)	loss 0.7983 (0.7476)	grad_norm 1.8582 (1.6645)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:45:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:39 lr 0.000082	 wd 0.0000	time 0.2422 (0.2495)	loss 0.8291 (0.7471)	grad_norm 1.7234 (1.6702)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:45:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:22 lr 0.000082	 wd 0.0000	time 0.2067 (0.2549)	loss 0.7715 (0.7482)	grad_norm 1.4589 (1.6636)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:45:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:48 lr 0.000082	 wd 0.0000	time 0.1902 (0.2488)	loss 0.7256 (0.7484)	grad_norm 1.2997 (1.6661)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:46:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:17 lr 0.000082	 wd 0.0000	time 0.1757 (0.2437)	loss 0.8013 (0.7488)	grad_norm 1.7100 (1.6580)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:46:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:47 lr 0.000082	 wd 0.0000	time 0.1846 (0.2393)	loss 0.7144 (0.7494)	grad_norm 1.6010 (1.6615)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:46:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:20 lr 0.000081	 wd 0.0000	time 0.2357 (0.2368)	loss 0.7490 (0.7503)	grad_norm 1.5289 (1.6611)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:47:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:03:59 lr 0.000081	 wd 0.0000	time 0.1824 (0.2392)	loss 0.6450 (0.7503)	grad_norm 1.4023 (1.6563)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:47:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:32 lr 0.000081	 wd 0.0000	time 0.1734 (0.2359)	loss 0.7891 (0.7503)	grad_norm 1.2031 (1.6559)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:47:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:07 lr 0.000081	 wd 0.0000	time 0.1808 (0.2332)	loss 0.6812 (0.7506)	grad_norm 1.3778 (1.6533)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:48:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:42 lr 0.000081	 wd 0.0000	time 0.1744 (0.2309)	loss 0.6860 (0.7510)	grad_norm 1.6661 (1.6567)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:48:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:18 lr 0.000081	 wd 0.0000	time 0.1816 (0.2295)	loss 0.6719 (0.7504)	grad_norm 1.2955 (1.6565)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:49:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:55 lr 0.000080	 wd 0.0000	time 0.1826 (0.2299)	loss 0.7437 (0.7503)	grad_norm 1.3450 (1.6624)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 18:49:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:31 lr 0.000080	 wd 0.0000	time 0.2181 (0.2282)	loss 0.8403 (0.7505)	grad_norm 1.8748 (1.6685)	loss_scale 16384.0000 (8207.5964)	mem 7891MB
[2024-07-27 18:49:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:08 lr 0.000080	 wd 0.0000	time 0.1854 (0.2266)	loss 0.7603 (0.7505)	grad_norm 1.3029 (1.6678)	loss_scale 16384.0000 (8579.0822)	mem 7891MB
[2024-07-27 18:50:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:45 lr 0.000080	 wd 0.0000	time 0.1997 (0.2251)	loss 0.7690 (0.7503)	grad_norm 1.5451 (1.6685)	loss_scale 16384.0000 (8918.2790)	mem 7891MB
[2024-07-27 18:50:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:22 lr 0.000080	 wd 0.0000	time 0.2250 (0.2246)	loss 0.7803 (0.7502)	grad_norm 1.4889 (1.6666)	loss_scale 16384.0000 (9229.2212)	mem 7891MB
[2024-07-27 18:50:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000080	 wd 0.0000	time 0.1674 (0.2232)	loss 0.8247 (0.7502)	grad_norm 2.4004 (1.6642)	loss_scale 16384.0000 (9515.2979)	mem 7891MB
[2024-07-27 18:50:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 8 training takes 0:09:23
[2024-07-27 18:51:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 20.549 (20.549)	Loss 0.3745 (0.3745)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 18:51:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.472 Acc@5 97.540
[2024-07-27 18:51:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-27 18:51:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 18:51:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][0/2502]	eta 14:47:26 lr 0.000080	 wd 0.0000	time 21.2815 (21.2815)	loss 0.6426 (0.6426)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:52:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:19:11 lr 0.000079	 wd 0.0000	time 0.2080 (0.4794)	loss 0.7295 (0.7419)	grad_norm 1.9321 (1.6868)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:52:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:12:48 lr 0.000079	 wd 0.0000	time 0.1716 (0.3340)	loss 0.6519 (0.7393)	grad_norm 1.6855 (1.6754)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:52:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:28 lr 0.000079	 wd 0.0000	time 0.1863 (0.2853)	loss 0.7930 (0.7449)	grad_norm 1.3849 (1.6698)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:53:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:07 lr 0.000079	 wd 0.0000	time 0.1878 (0.2603)	loss 0.6777 (0.7440)	grad_norm 1.3415 (1.6309)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:53:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:08:37 lr 0.000079	 wd 0.0000	time 0.4035 (0.2584)	loss 0.6533 (0.7432)	grad_norm 1.5723 (1.6136)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:54:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:31 lr 0.000079	 wd 0.0000	time 0.1837 (0.2689)	loss 0.6982 (0.7421)	grad_norm 1.4911 (1.5997)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:54:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:44 lr 0.000078	 wd 0.0000	time 0.1945 (0.2575)	loss 0.7725 (0.7431)	grad_norm 1.3903 (1.5923)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:54:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:02 lr 0.000078	 wd 0.0000	time 0.1793 (0.2485)	loss 0.8540 (0.7438)	grad_norm 1.4439 (1.6133)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:55:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:34 lr 0.000078	 wd 0.0000	time 0.3222 (0.2465)	loss 0.8423 (0.7447)	grad_norm 1.3699 (1.6055)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:55:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:22 lr 0.000078	 wd 0.0000	time 0.2025 (0.2546)	loss 0.7295 (0.7448)	grad_norm 2.0343 (1.6105)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:55:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:48 lr 0.000078	 wd 0.0000	time 0.1868 (0.2485)	loss 0.8359 (0.7444)	grad_norm 1.4403 (1.6188)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:56:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:17 lr 0.000078	 wd 0.0000	time 0.1857 (0.2435)	loss 0.7881 (0.7458)	grad_norm 1.8040 (1.6064)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:56:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:47 lr 0.000077	 wd 0.0000	time 0.1848 (0.2396)	loss 0.7393 (0.7461)	grad_norm 1.2152 (1.6033)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:56:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:23 lr 0.000077	 wd 0.0000	time 0.1651 (0.2389)	loss 0.8164 (0.7466)	grad_norm 1.4972 (1.5997)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:57:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:03:56 lr 0.000077	 wd 0.0000	time 0.1981 (0.2359)	loss 0.7046 (0.7473)	grad_norm 2.0637 (1.6066)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:57:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:30 lr 0.000077	 wd 0.0000	time 0.1829 (0.2331)	loss 0.7329 (0.7462)	grad_norm 1.4357 (1.6072)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:57:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:04 lr 0.000077	 wd 0.0000	time 0.1819 (0.2305)	loss 0.7153 (0.7463)	grad_norm 2.5179 (1.6042)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:58:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:40 lr 0.000077	 wd 0.0000	time 0.1935 (0.2288)	loss 0.7559 (0.7465)	grad_norm 1.2088 (1.6055)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:58:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:17 lr 0.000076	 wd 0.0000	time 0.1839 (0.2289)	loss 0.7368 (0.7470)	grad_norm 1.6160 (1.6052)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:58:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:01:54 lr 0.000076	 wd 0.0000	time 0.1751 (0.2274)	loss 0.7236 (0.7475)	grad_norm 2.2321 (1.6070)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:59:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:30 lr 0.000076	 wd 0.0000	time 0.1904 (0.2258)	loss 0.7451 (0.7477)	grad_norm 1.5546 (1.6098)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:59:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:07 lr 0.000076	 wd 0.0000	time 0.1907 (0.2242)	loss 0.5933 (0.7476)	grad_norm 1.3788 (1.6146)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 18:59:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:45 lr 0.000076	 wd 0.0000	time 0.2870 (0.2234)	loss 0.7349 (0.7474)	grad_norm 1.4484 (1.6135)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:00:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:22 lr 0.000075	 wd 0.0000	time 0.1787 (0.2238)	loss 0.8262 (0.7479)	grad_norm 1.0900 (1.6094)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:00:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000075	 wd 0.0000	time 0.1700 (0.2221)	loss 0.7954 (0.7482)	grad_norm 1.7093 (1.6074)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:00:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 9 training takes 0:09:21
[2024-07-27 19:00:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 20.006 (20.006)	Loss 0.3713 (0.3713)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 19:01:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.358 Acc@5 97.540
[2024-07-27 19:01:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 19:01:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 19:01:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][0/2502]	eta 23:09:27 lr 0.000075	 wd 0.0000	time 33.3202 (33.3202)	loss 0.8062 (0.8062)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:02:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:20:41 lr 0.000075	 wd 0.0000	time 0.1882 (0.5167)	loss 0.7974 (0.7572)	grad_norm 1.4605 (1.5433)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:02:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:13:31 lr 0.000075	 wd 0.0000	time 0.1982 (0.3524)	loss 0.7129 (0.7525)	grad_norm 1.2090 (1.5951)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:02:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:53 lr 0.000075	 wd 0.0000	time 0.1733 (0.2969)	loss 0.7266 (0.7513)	grad_norm 1.8182 (1.6163)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:03:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:48 lr 0.000075	 wd 0.0000	time 0.4312 (0.2799)	loss 0.7100 (0.7513)	grad_norm 1.8971 (1.5998)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:03:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:09:32 lr 0.000074	 wd 0.0000	time 0.1732 (0.2862)	loss 0.6943 (0.7521)	grad_norm 1.5994 (1.5894)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:03:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:33 lr 0.000074	 wd 0.0000	time 0.2056 (0.2701)	loss 0.7075 (0.7517)	grad_norm 1.7789 (1.6130)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:04:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:44 lr 0.000074	 wd 0.0000	time 0.1774 (0.2579)	loss 0.6821 (0.7492)	grad_norm 1.9823 (1.6118)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:04:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:07:05 lr 0.000074	 wd 0.0000	time 0.2359 (0.2499)	loss 0.6885 (0.7502)	grad_norm 1.9208 (1.6059)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:05:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:57 lr 0.000074	 wd 0.0000	time 0.1828 (0.2606)	loss 0.6592 (0.7495)	grad_norm 1.1246 (1.5957)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:05:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:20 lr 0.000073	 wd 0.0000	time 0.1771 (0.2535)	loss 0.8403 (0.7493)	grad_norm 1.7086 (nan)	loss_scale 8192.0000 (16351.2647)	mem 7891MB
[2024-07-27 19:05:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:46 lr 0.000073	 wd 0.0000	time 0.1826 (0.2475)	loss 0.8086 (0.7486)	grad_norm 1.0509 (nan)	loss_scale 8192.0000 (15610.1871)	mem 7891MB
[2024-07-27 19:06:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:15 lr 0.000073	 wd 0.0000	time 0.2031 (0.2426)	loss 0.8340 (0.7482)	grad_norm 1.8656 (nan)	loss_scale 8192.0000 (14992.5196)	mem 7891MB
[2024-07-27 19:06:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:48 lr 0.000073	 wd 0.0000	time 0.2097 (0.2400)	loss 0.7241 (0.7479)	grad_norm 1.9336 (nan)	loss_scale 8192.0000 (14469.8048)	mem 7891MB
[2024-07-27 19:06:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:22 lr 0.000073	 wd 0.0000	time 0.1717 (0.2386)	loss 0.7437 (0.7478)	grad_norm 1.8152 (nan)	loss_scale 8192.0000 (14021.7102)	mem 7891MB
[2024-07-27 19:07:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:03:55 lr 0.000073	 wd 0.0000	time 0.1621 (0.2355)	loss 0.7373 (0.7479)	grad_norm 1.7999 (nan)	loss_scale 8192.0000 (13633.3218)	mem 7891MB
[2024-07-27 19:07:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:29 lr 0.000072	 wd 0.0000	time 0.1833 (0.2326)	loss 0.6187 (0.7478)	grad_norm 1.7682 (nan)	loss_scale 8192.0000 (13293.4516)	mem 7891MB
[2024-07-27 19:07:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:04 lr 0.000072	 wd 0.0000	time 0.2085 (0.2302)	loss 0.7109 (0.7476)	grad_norm 1.5263 (nan)	loss_scale 8192.0000 (12993.5426)	mem 7891MB
[2024-07-27 19:08:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:41 lr 0.000072	 wd 0.0000	time 0.1845 (0.2308)	loss 0.8418 (0.7476)	grad_norm 1.6367 (nan)	loss_scale 8192.0000 (12726.9384)	mem 7891MB
[2024-07-27 19:08:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:17 lr 0.000072	 wd 0.0000	time 0.1822 (0.2292)	loss 0.8301 (0.7489)	grad_norm 1.2181 (nan)	loss_scale 8192.0000 (12488.3830)	mem 7891MB
[2024-07-27 19:08:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:54 lr 0.000072	 wd 0.0000	time 0.1732 (0.2273)	loss 0.9380 (0.7492)	grad_norm 1.8850 (nan)	loss_scale 8192.0000 (12273.6712)	mem 7891MB
[2024-07-27 19:09:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:30 lr 0.000071	 wd 0.0000	time 0.1848 (0.2256)	loss 0.6860 (0.7493)	grad_norm 1.4552 (nan)	loss_scale 8192.0000 (12079.3984)	mem 7891MB
[2024-07-27 19:09:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:07 lr 0.000071	 wd 0.0000	time 0.2102 (0.2243)	loss 0.7773 (0.7496)	grad_norm 1.4917 (nan)	loss_scale 8192.0000 (11902.7787)	mem 7891MB
[2024-07-27 19:09:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:45 lr 0.000071	 wd 0.0000	time 0.1731 (0.2245)	loss 0.7949 (0.7496)	grad_norm 1.5104 (nan)	loss_scale 8192.0000 (11741.5106)	mem 7891MB
[2024-07-27 19:10:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:22 lr 0.000071	 wd 0.0000	time 0.1902 (0.2235)	loss 0.7949 (0.7496)	grad_norm 1.6221 (nan)	loss_scale 8192.0000 (11593.6760)	mem 7891MB
[2024-07-27 19:10:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000071	 wd 0.0000	time 0.1734 (0.2218)	loss 0.6685 (0.7493)	grad_norm 1.4198 (nan)	loss_scale 8192.0000 (11457.6633)	mem 7891MB
[2024-07-27 19:10:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 10 training takes 0:09:21
[2024-07-27 19:10:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 19.163 (19.163)	Loss 0.3821 (0.3821)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 19:11:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.400 Acc@5 97.500
[2024-07-27 19:11:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 19:11:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 19:11:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][0/2502]	eta 23:01:36 lr 0.000071	 wd 0.0000	time 33.1320 (33.1320)	loss 0.7183 (0.7183)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:12:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:20:47 lr 0.000070	 wd 0.0000	time 0.1997 (0.5195)	loss 0.6943 (0.7464)	grad_norm 1.4691 (1.6360)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:12:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:13:31 lr 0.000070	 wd 0.0000	time 0.1767 (0.3525)	loss 0.7427 (0.7463)	grad_norm 1.4286 (1.6430)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:12:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:11:11 lr 0.000070	 wd 0.0000	time 0.3114 (0.3050)	loss 0.7090 (0.7449)	grad_norm 1.7252 (1.6383)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:13:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:10:49 lr 0.000070	 wd 0.0000	time 0.1713 (0.3088)	loss 0.6758 (0.7427)	grad_norm 1.8198 (1.6125)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:13:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:09:29 lr 0.000070	 wd 0.0000	time 0.1723 (0.2845)	loss 0.7520 (0.7417)	grad_norm 1.7361 (1.6216)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:13:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:30 lr 0.000069	 wd 0.0000	time 0.1704 (0.2684)	loss 0.8262 (0.7421)	grad_norm 1.5707 (1.6241)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:14:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:07:43 lr 0.000069	 wd 0.0000	time 0.2020 (0.2570)	loss 0.7358 (0.7420)	grad_norm 1.5450 (1.6119)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:14:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:07:29 lr 0.000069	 wd 0.0000	time 0.3035 (0.2642)	loss 0.8154 (0.7427)	grad_norm 1.3610 (1.6281)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:15:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:06:54 lr 0.000069	 wd 0.0000	time 0.1786 (0.2587)	loss 0.7476 (0.7449)	grad_norm 1.5503 (1.6166)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:15:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:17 lr 0.000069	 wd 0.0000	time 0.2165 (0.2516)	loss 0.7407 (0.7456)	grad_norm 1.6483 (1.6254)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:15:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:44 lr 0.000069	 wd 0.0000	time 0.1768 (0.2459)	loss 0.7720 (0.7450)	grad_norm 1.6325 (1.6142)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:16:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:18 lr 0.000068	 wd 0.0000	time 0.3327 (0.2446)	loss 0.7749 (0.7451)	grad_norm 1.6391 (1.6146)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:16:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:04:59 lr 0.000068	 wd 0.0000	time 0.1710 (0.2492)	loss 0.6514 (0.7457)	grad_norm 1.5201 (1.6178)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:16:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:29 lr 0.000068	 wd 0.0000	time 0.1996 (0.2448)	loss 0.7212 (0.7457)	grad_norm 1.4389 (1.6094)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:17:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:04:01 lr 0.000068	 wd 0.0000	time 0.1890 (0.2408)	loss 0.7466 (0.7452)	grad_norm 1.0946 (1.6065)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:17:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:34 lr 0.000068	 wd 0.0000	time 0.2291 (0.2383)	loss 0.6802 (0.7453)	grad_norm 1.2690 (1.6132)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:17:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:10 lr 0.000067	 wd 0.0000	time 0.1812 (0.2379)	loss 0.7432 (0.7452)	grad_norm 1.3152 (1.6023)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:18:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:45 lr 0.000067	 wd 0.0000	time 0.1897 (0.2358)	loss 0.7188 (0.7457)	grad_norm 1.2488 (1.6002)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:18:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:20 lr 0.000067	 wd 0.0000	time 0.1987 (0.2335)	loss 0.7256 (0.7464)	grad_norm 2.9117 (1.5994)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:18:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:01:56 lr 0.000067	 wd 0.0000	time 0.1733 (0.2314)	loss 0.6016 (0.7465)	grad_norm 2.0363 (1.5975)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:19:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:32 lr 0.000067	 wd 0.0000	time 0.1708 (0.2299)	loss 0.8472 (0.7461)	grad_norm 1.5934 (1.5993)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:19:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:09 lr 0.000066	 wd 0.0000	time 0.1833 (0.2301)	loss 0.8242 (0.7464)	grad_norm 1.2421 (1.6008)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:19:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:46 lr 0.000066	 wd 0.0000	time 0.1821 (0.2287)	loss 0.7578 (0.7466)	grad_norm 1.5140 (1.6001)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:20:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:23 lr 0.000066	 wd 0.0000	time 0.2035 (0.2272)	loss 0.7681 (0.7465)	grad_norm 2.1422 (1.5999)	loss_scale 8192.0000 (8192.0000)	mem 7891MB
[2024-07-27 19:20:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000066	 wd 0.0000	time 0.1703 (0.2253)	loss 0.7271 (0.7464)	grad_norm 1.7196 (1.5973)	loss_scale 16384.0000 (8211.6529)	mem 7891MB
[2024-07-27 19:20:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 11 training takes 0:09:32
[2024-07-27 19:21:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 36.544 (36.544)	Loss 0.3733 (0.3733)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 19:21:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.368 Acc@5 97.520
[2024-07-27 19:21:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 19:21:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 19:21:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][0/2502]	eta 11:27:35 lr 0.000066	 wd 0.0000	time 16.4891 (16.4891)	loss 0.6724 (0.6724)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:22:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:14:00 lr 0.000066	 wd 0.0000	time 0.1918 (0.3500)	loss 0.7285 (0.7449)	grad_norm 1.3795 (1.5293)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:22:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:13:06 lr 0.000065	 wd 0.0000	time 0.2083 (0.3417)	loss 0.7246 (0.7415)	grad_norm 1.5012 (1.5683)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:23:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:46 lr 0.000065	 wd 0.0000	time 0.1797 (0.2938)	loss 0.6948 (0.7483)	grad_norm 3.0903 (1.5581)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:23:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:20 lr 0.000065	 wd 0.0000	time 0.1744 (0.2667)	loss 0.7178 (0.7476)	grad_norm 1.5663 (1.5935)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:23:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:08:21 lr 0.000065	 wd 0.0000	time 0.1764 (0.2503)	loss 0.8169 (0.7488)	grad_norm 1.3971 (1.5927)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:24:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:07:56 lr 0.000065	 wd 0.0000	time 0.3739 (0.2505)	loss 0.8032 (0.7468)	grad_norm 1.2452 (1.5818)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:24:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:08:03 lr 0.000064	 wd 0.0000	time 0.1841 (0.2682)	loss 0.7676 (0.7484)	grad_norm 1.6395 (1.5982)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:25:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:07:19 lr 0.000064	 wd 0.0000	time 0.1948 (0.2583)	loss 0.9580 (0.7479)	grad_norm 1.5314 (1.6018)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:25:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:41 lr 0.000064	 wd 0.0000	time 0.1889 (0.2504)	loss 0.8501 (0.7480)	grad_norm 1.2976 (1.5900)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:25:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:27 lr 0.000064	 wd 0.0000	time 0.2164 (0.2581)	loss 0.6860 (0.7480)	grad_norm 1.1729 (1.5847)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:26:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:56 lr 0.000064	 wd 0.0000	time 0.1877 (0.2541)	loss 0.6860 (0.7490)	grad_norm 1.1571 (1.5742)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:26:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:23 lr 0.000063	 wd 0.0000	time 0.1808 (0.2485)	loss 0.8062 (0.7492)	grad_norm 1.7330 (1.5790)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:26:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:52 lr 0.000063	 wd 0.0000	time 0.1865 (0.2436)	loss 0.7354 (0.7496)	grad_norm 1.4141 (1.5818)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:27:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:25 lr 0.000063	 wd 0.0000	time 0.3018 (0.2406)	loss 0.8833 (0.7505)	grad_norm 1.5187 (1.5848)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:27:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:04:06 lr 0.000063	 wd 0.0000	time 0.1885 (0.2463)	loss 0.7480 (0.7507)	grad_norm 1.3352 (1.5847)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:28:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:38 lr 0.000063	 wd 0.0000	time 0.1883 (0.2426)	loss 0.7534 (0.7497)	grad_norm 1.7718 (1.5895)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:28:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:12 lr 0.000062	 wd 0.0000	time 0.2077 (0.2394)	loss 0.8311 (0.7496)	grad_norm 1.8669 (1.5905)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:28:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:46 lr 0.000062	 wd 0.0000	time 0.1978 (0.2368)	loss 0.6255 (0.7496)	grad_norm 1.1852 (1.5886)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:29:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:22 lr 0.000062	 wd 0.0000	time 0.1826 (0.2370)	loss 0.7373 (0.7498)	grad_norm 1.8493 (1.5852)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:29:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:01:58 lr 0.000062	 wd 0.0000	time 0.1838 (0.2352)	loss 0.6729 (0.7498)	grad_norm 1.6408 (1.5873)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:29:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:33 lr 0.000062	 wd 0.0000	time 0.1730 (0.2331)	loss 0.8008 (0.7499)	grad_norm 1.5139 (1.5850)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:30:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:09 lr 0.000061	 wd 0.0000	time 0.1774 (0.2313)	loss 0.8682 (0.7500)	grad_norm 1.4559 (1.5883)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:30:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:46 lr 0.000061	 wd 0.0000	time 0.1879 (0.2298)	loss 0.7158 (0.7499)	grad_norm 1.7016 (1.5962)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:30:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:23 lr 0.000061	 wd 0.0000	time 0.2070 (0.2294)	loss 0.7056 (0.7496)	grad_norm 1.6441 (1.5958)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:31:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000061	 wd 0.0000	time 0.1655 (0.2277)	loss 0.6851 (0.7497)	grad_norm 1.6113 (1.5951)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:31:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 12 training takes 0:09:39
[2024-07-27 19:31:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 20.313 (20.313)	Loss 0.3752 (0.3752)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 19:31:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.366 Acc@5 97.538
[2024-07-27 19:31:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 19:31:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 19:32:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][0/2502]	eta 1 day, 0:33:26 lr 0.000061	 wd 0.0000	time 35.3345 (35.3345)	loss 0.6172 (0.6172)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:32:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:21:27 lr 0.000061	 wd 0.0000	time 0.1696 (0.5362)	loss 0.6792 (0.7473)	grad_norm 1.7076 (1.5151)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:33:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:13:51 lr 0.000060	 wd 0.0000	time 0.1779 (0.3611)	loss 0.6182 (0.7427)	grad_norm 1.4063 (1.4885)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:33:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:11:07 lr 0.000060	 wd 0.0000	time 0.1651 (0.3030)	loss 0.7017 (0.7405)	grad_norm 1.5704 (1.5025)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:33:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:10:45 lr 0.000060	 wd 0.0000	time 0.7830 (0.3072)	loss 0.7788 (0.7441)	grad_norm 1.6355 (1.5224)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:34:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:09:58 lr 0.000060	 wd 0.0000	time 0.1678 (0.2988)	loss 0.7769 (0.7433)	grad_norm 1.5026 (1.5450)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:34:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:53 lr 0.000060	 wd 0.0000	time 0.1732 (0.2803)	loss 0.7495 (0.7420)	grad_norm 1.5915 (1.5594)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:35:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:08:00 lr 0.000059	 wd 0.0000	time 0.1749 (0.2669)	loss 0.7261 (0.7425)	grad_norm 1.2185 (1.5607)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:35:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:27 lr 0.000059	 wd 0.0000	time 0.3913 (0.2628)	loss 0.7681 (0.7426)	grad_norm 1.5384 (1.5641)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:35:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:07:08 lr 0.000059	 wd 0.0000	time 0.1852 (0.2676)	loss 0.7339 (0.7440)	grad_norm 1.6734 (1.5700)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:36:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:30 lr 0.000059	 wd 0.0000	time 0.1814 (0.2597)	loss 0.7549 (0.7460)	grad_norm 1.2081 (1.5719)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:36:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:54 lr 0.000059	 wd 0.0000	time 0.1773 (0.2529)	loss 0.7329 (0.7461)	grad_norm 1.2582 (1.5697)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:36:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:22 lr 0.000058	 wd 0.0000	time 0.2044 (0.2481)	loss 0.8252 (0.7459)	grad_norm 1.4718 (1.5659)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:37:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:05:02 lr 0.000058	 wd 0.0000	time 0.1798 (0.2520)	loss 0.8018 (0.7460)	grad_norm 1.4871 (1.5682)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:37:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:32 lr 0.000058	 wd 0.0000	time 0.1735 (0.2474)	loss 0.8022 (0.7454)	grad_norm 1.7914 (1.5733)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:37:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:04:03 lr 0.000058	 wd 0.0000	time 0.1888 (0.2433)	loss 0.6934 (0.7463)	grad_norm 1.4733 (1.5721)	loss_scale 32768.0000 (16493.1539)	mem 7891MB
[2024-07-27 19:38:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:36 lr 0.000058	 wd 0.0000	time 0.1995 (0.2399)	loss 0.6152 (0.7466)	grad_norm 1.3979 (1.5718)	loss_scale 32768.0000 (17509.6964)	mem 7891MB
[2024-07-27 19:38:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:11 lr 0.000057	 wd 0.0000	time 0.1969 (0.2382)	loss 0.7188 (0.7472)	grad_norm 2.0595 (1.5759)	loss_scale 32768.0000 (18406.7160)	mem 7891MB
[2024-07-27 19:39:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:46 lr 0.000057	 wd 0.0000	time 0.1801 (0.2375)	loss 0.7358 (0.7477)	grad_norm 1.4294 (1.5772)	loss_scale 32768.0000 (19204.1222)	mem 7891MB
[2024-07-27 19:39:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:21 lr 0.000057	 wd 0.0000	time 0.2115 (0.2351)	loss 0.6802 (0.7476)	grad_norm 1.5378 (inf)	loss_scale 16384.0000 (19331.5686)	mem 7891MB
[2024-07-27 19:39:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:56 lr 0.000057	 wd 0.0000	time 0.2236 (0.2329)	loss 0.7720 (0.7474)	grad_norm 1.3688 (inf)	loss_scale 16384.0000 (19184.2639)	mem 7891MB
[2024-07-27 19:39:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:32 lr 0.000057	 wd 0.0000	time 0.2066 (0.2310)	loss 0.7070 (0.7475)	grad_norm 1.3403 (inf)	loss_scale 16384.0000 (19050.9814)	mem 7891MB
[2024-07-27 19:40:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:09 lr 0.000056	 wd 0.0000	time 0.1938 (0.2312)	loss 0.6792 (0.7472)	grad_norm 1.4495 (inf)	loss_scale 16384.0000 (18929.8101)	mem 7891MB
[2024-07-27 19:40:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:46 lr 0.000056	 wd 0.0000	time 0.1865 (0.2299)	loss 0.8062 (0.7473)	grad_norm 1.2229 (inf)	loss_scale 16384.0000 (18819.1708)	mem 7891MB
[2024-07-27 19:41:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:23 lr 0.000056	 wd 0.0000	time 0.1944 (0.2283)	loss 0.6733 (0.7474)	grad_norm 1.2851 (inf)	loss_scale 16384.0000 (18717.7476)	mem 7891MB
[2024-07-27 19:41:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000056	 wd 0.0000	time 0.1683 (0.2264)	loss 0.7090 (0.7474)	grad_norm 1.3647 (inf)	loss_scale 16384.0000 (18624.4350)	mem 7891MB
[2024-07-27 19:41:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 13 training takes 0:09:33
[2024-07-27 19:42:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 36.821 (36.821)	Loss 0.3774 (0.3774)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 19:42:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.426 Acc@5 97.492
[2024-07-27 19:42:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 19:42:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 19:42:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][0/2502]	eta 11:12:58 lr 0.000056	 wd 0.0000	time 16.1383 (16.1383)	loss 0.7051 (0.7051)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:42:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:13:51 lr 0.000055	 wd 0.0000	time 0.1856 (0.3462)	loss 0.7188 (0.7458)	grad_norm 1.4873 (1.6117)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:43:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:11:04 lr 0.000055	 wd 0.0000	time 0.3198 (0.2885)	loss 0.7178 (0.7431)	grad_norm 1.2426 (1.5588)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:44:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:11:52 lr 0.000055	 wd 0.0000	time 0.1761 (0.3237)	loss 0.8066 (0.7462)	grad_norm 1.3559 (1.5687)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:44:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:10:09 lr 0.000055	 wd 0.0000	time 0.1734 (0.2902)	loss 0.8872 (0.7457)	grad_norm 0.9637 (1.5834)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:44:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:08:59 lr 0.000055	 wd 0.0000	time 0.1733 (0.2694)	loss 0.7749 (0.7444)	grad_norm 1.8322 (1.5609)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:44:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:08:16 lr 0.000054	 wd 0.0000	time 0.3048 (0.2610)	loss 0.7271 (0.7466)	grad_norm 1.2274 (1.5575)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:45:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:08:08 lr 0.000054	 wd 0.0000	time 0.1913 (0.2714)	loss 0.6807 (0.7481)	grad_norm 1.2293 (1.5554)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:45:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:24 lr 0.000054	 wd 0.0000	time 0.1932 (0.2610)	loss 0.7222 (0.7467)	grad_norm 1.5119 (1.5472)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:46:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:44 lr 0.000054	 wd 0.0000	time 0.1626 (0.2527)	loss 0.7788 (0.7463)	grad_norm 1.4609 (1.5522)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:46:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:06:11 lr 0.000054	 wd 0.0000	time 0.2501 (0.2472)	loss 0.8711 (0.7463)	grad_norm 1.6284 (1.5632)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:47:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:55 lr 0.000053	 wd 0.0000	time 0.1892 (0.2538)	loss 0.6880 (0.7470)	grad_norm 1.2974 (1.5594)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:47:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:23 lr 0.000053	 wd 0.0000	time 0.1833 (0.2483)	loss 0.7534 (0.7470)	grad_norm 1.5593 (1.5615)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:47:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:04:52 lr 0.000053	 wd 0.0000	time 0.1801 (0.2435)	loss 0.7700 (0.7470)	grad_norm 1.3066 (1.5579)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:47:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:23 lr 0.000053	 wd 0.0000	time 0.1795 (0.2394)	loss 0.7651 (0.7462)	grad_norm 1.3303 (1.5619)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:48:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:04:05 lr 0.000053	 wd 0.0000	time 0.1930 (0.2446)	loss 0.8013 (0.7462)	grad_norm 2.0549 (1.5649)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:48:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:37 lr 0.000052	 wd 0.0000	time 0.1777 (0.2413)	loss 0.8071 (0.7466)	grad_norm 1.4319 (1.5641)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:49:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:10 lr 0.000052	 wd 0.0000	time 0.1733 (0.2380)	loss 0.8301 (0.7468)	grad_norm 1.6318 (1.5667)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:49:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:45 lr 0.000052	 wd 0.0000	time 0.1848 (0.2353)	loss 0.8745 (0.7469)	grad_norm 1.3823 (1.5657)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:49:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:20 lr 0.000052	 wd 0.0000	time 0.2474 (0.2338)	loss 0.7231 (0.7473)	grad_norm 1.4541 (1.5610)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:50:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:01:57 lr 0.000052	 wd 0.0000	time 0.1837 (0.2339)	loss 0.7495 (0.7473)	grad_norm 1.3654 (1.5582)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:50:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:33 lr 0.000051	 wd 0.0000	time 0.1790 (0.2321)	loss 0.7090 (0.7476)	grad_norm 1.2216 (1.5599)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:50:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:09 lr 0.000051	 wd 0.0000	time 0.1773 (0.2302)	loss 0.6763 (0.7481)	grad_norm 1.4225 (1.5558)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:51:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:46 lr 0.000051	 wd 0.0000	time 0.1843 (0.2285)	loss 0.8247 (0.7484)	grad_norm 2.2306 (1.5579)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:51:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:23 lr 0.000051	 wd 0.0000	time 0.2076 (0.2277)	loss 0.7007 (0.7485)	grad_norm 1.4513 (1.5561)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:51:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000051	 wd 0.0000	time 0.1661 (0.2267)	loss 0.7041 (0.7487)	grad_norm 1.3672 (1.5572)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:52:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 14 training takes 0:09:38
[2024-07-27 19:52:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 19.788 (19.788)	Loss 0.3721 (0.3721)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 19:52:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.402 Acc@5 97.492
[2024-07-27 19:52:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 19:52:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 19:53:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][0/2502]	eta 18:00:51 lr 0.000051	 wd 0.0000	time 25.9199 (25.9199)	loss 0.6504 (0.6504)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:53:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:20:05 lr 0.000050	 wd 0.0000	time 0.2003 (0.5021)	loss 0.7842 (0.7406)	grad_norm 1.2120 (1.5834)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:53:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:13:13 lr 0.000050	 wd 0.0000	time 0.1794 (0.3449)	loss 0.9131 (0.7487)	grad_norm 1.5073 (1.5648)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:54:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:10:52 lr 0.000050	 wd 0.0000	time 0.1903 (0.2961)	loss 0.6665 (0.7495)	grad_norm 1.4616 (1.6201)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:54:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:09:25 lr 0.000050	 wd 0.0000	time 0.1733 (0.2692)	loss 0.6113 (0.7489)	grad_norm 1.5021 (1.6168)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:55:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:09:52 lr 0.000049	 wd 0.0000	time 0.2251 (0.2959)	loss 0.7036 (0.7488)	grad_norm 1.3263 (1.6230)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:55:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:08:50 lr 0.000049	 wd 0.0000	time 0.1842 (0.2790)	loss 0.6641 (0.7502)	grad_norm 1.7251 (1.6074)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:55:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:59 lr 0.000049	 wd 0.0000	time 0.1746 (0.2660)	loss 0.7817 (0.7499)	grad_norm 1.3059 (1.6016)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:56:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:07:16 lr 0.000049	 wd 0.0000	time 0.2075 (0.2566)	loss 0.7207 (0.7491)	grad_norm 1.5273 (1.5932)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 19:56:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:07:07 lr 0.000049	 wd 0.0000	time 0.2149 (0.2670)	loss 0.7290 (0.7488)	grad_norm 1.3452 (1.5906)	loss_scale 32768.0000 (17693.2653)	mem 7891MB
[2024-07-27 19:56:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:06:29 lr 0.000048	 wd 0.0000	time 0.1830 (0.2594)	loss 0.7129 (0.7489)	grad_norm 1.4237 (1.5886)	loss_scale 32768.0000 (19199.2328)	mem 7891MB
[2024-07-27 19:57:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:54 lr 0.000048	 wd 0.0000	time 0.1733 (0.2528)	loss 0.7705 (0.7480)	grad_norm 1.6403 (1.5818)	loss_scale 32768.0000 (20431.6367)	mem 7891MB
[2024-07-27 19:57:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:21 lr 0.000048	 wd 0.0000	time 0.1826 (0.2471)	loss 0.6777 (0.7478)	grad_norm 1.3732 (1.5781)	loss_scale 32768.0000 (21458.8110)	mem 7891MB
[2024-07-27 19:58:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:05:07 lr 0.000048	 wd 0.0000	time 0.6071 (0.2556)	loss 0.7959 (0.7482)	grad_norm 1.5055 (1.5773)	loss_scale 32768.0000 (22328.0799)	mem 7891MB
[2024-07-27 19:58:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:38 lr 0.000048	 wd 0.0000	time 0.1769 (0.2526)	loss 0.7573 (0.7481)	grad_norm 1.7617 (1.5788)	loss_scale 32768.0000 (23073.2562)	mem 7891MB
[2024-07-27 19:58:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:04:08 lr 0.000047	 wd 0.0000	time 0.1869 (0.2483)	loss 0.7539 (0.7479)	grad_norm 2.2176 (1.5746)	loss_scale 32768.0000 (23719.1419)	mem 7891MB
[2024-07-27 19:59:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:40 lr 0.000047	 wd 0.0000	time 0.1909 (0.2445)	loss 0.7778 (0.7476)	grad_norm 1.8536 (1.5734)	loss_scale 32768.0000 (24284.3423)	mem 7891MB
[2024-07-27 19:59:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:14 lr 0.000047	 wd 0.0000	time 0.2052 (0.2421)	loss 0.7666 (0.7474)	grad_norm 1.2739 (1.5719)	loss_scale 32768.0000 (24783.0876)	mem 7891MB
[2024-07-27 19:59:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:49 lr 0.000047	 wd 0.0000	time 0.1879 (0.2414)	loss 0.7837 (0.7485)	grad_norm 1.5881 (1.5724)	loss_scale 32768.0000 (25226.4475)	mem 7891MB
[2024-07-27 20:00:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:24 lr 0.000047	 wd 0.0000	time 0.1934 (0.2392)	loss 0.7773 (0.7485)	grad_norm 1.6051 (1.5716)	loss_scale 32768.0000 (25623.1625)	mem 7891MB
[2024-07-27 20:00:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:01:58 lr 0.000046	 wd 0.0000	time 0.1767 (0.2368)	loss 0.8110 (0.7484)	grad_norm 1.6529 (1.5709)	loss_scale 32768.0000 (25980.2259)	mem 7891MB
[2024-07-27 20:00:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:34 lr 0.000046	 wd 0.0000	time 0.2405 (0.2347)	loss 0.7622 (0.7484)	grad_norm 1.5816 (1.5701)	loss_scale 32768.0000 (26303.2994)	mem 7891MB
[2024-07-27 20:01:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:10 lr 0.000046	 wd 0.0000	time 0.1845 (0.2333)	loss 0.7524 (0.7489)	grad_norm 1.4109 (1.5693)	loss_scale 32768.0000 (26597.0159)	mem 7891MB
[2024-07-27 20:01:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:46 lr 0.000046	 wd 0.0000	time 0.2461 (0.2327)	loss 0.8921 (0.7487)	grad_norm 1.6949 (1.5660)	loss_scale 32768.0000 (26865.2030)	mem 7891MB
[2024-07-27 20:01:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:23 lr 0.000046	 wd 0.0000	time 0.1816 (0.2310)	loss 0.7427 (0.7488)	grad_norm 1.4359 (1.5666)	loss_scale 32768.0000 (27111.0504)	mem 7891MB
[2024-07-27 20:02:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000045	 wd 0.0000	time 0.1704 (0.2290)	loss 0.9272 (0.7491)	grad_norm 1.3020 (1.5643)	loss_scale 32768.0000 (27337.2379)	mem 7891MB
[2024-07-27 20:02:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 15 training takes 0:09:39
[2024-07-27 20:02:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_conv_b_step_stage3/ckpt_epoch_15.pth saving......
[2024-07-27 20:02:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_conv_b_step_stage3/ckpt_epoch_15.pth saved !!!
[2024-07-27 20:03:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 42.351 (42.351)	Loss 0.3779 (0.3779)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 20:03:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.406 Acc@5 97.516
[2024-07-27 20:03:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 20:03:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 20:03:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][0/2502]	eta 11:59:17 lr 0.000045	 wd 0.0000	time 17.2493 (17.2493)	loss 0.7432 (0.7432)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 20:03:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:14:19 lr 0.000045	 wd 0.0000	time 0.1828 (0.3579)	loss 0.8984 (0.7576)	grad_norm 1.4941 (1.6761)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 20:04:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:11:08 lr 0.000045	 wd 0.0000	time 0.3898 (0.2904)	loss 0.7744 (0.7589)	grad_norm 1.2373 (1.6428)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 20:04:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:11:01 lr 0.000045	 wd 0.0000	time 0.1868 (0.3003)	loss 0.7939 (0.7563)	grad_norm 1.3784 (1.6126)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 20:05:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:09:31 lr 0.000045	 wd 0.0000	time 0.1960 (0.2721)	loss 0.7759 (0.7541)	grad_norm 1.2446 (1.5914)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 20:05:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:08:30 lr 0.000044	 wd 0.0000	time 0.2028 (0.2551)	loss 0.6968 (0.7518)	grad_norm 1.7968 (1.5924)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 20:05:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:07:45 lr 0.000044	 wd 0.0000	time 0.1990 (0.2447)	loss 0.7393 (0.7531)	grad_norm 1.1538 (1.5922)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 20:06:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:46 lr 0.000044	 wd 0.0000	time 0.2047 (0.2592)	loss 0.7607 (0.7530)	grad_norm 1.4175 (1.5716)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 20:06:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:07:06 lr 0.000044	 wd 0.0000	time 0.1757 (0.2507)	loss 0.8735 (0.7525)	grad_norm 1.6531 (1.5826)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 20:06:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:30 lr 0.000043	 wd 0.0000	time 0.1923 (0.2436)	loss 0.7202 (0.7540)	grad_norm 1.3687 (1.5893)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 20:07:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:05:57 lr 0.000043	 wd 0.0000	time 0.1803 (0.2381)	loss 0.6992 (0.7548)	grad_norm 1.9864 (1.5906)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 20:07:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:30 lr 0.000043	 wd 0.0000	time 0.2599 (0.2356)	loss 0.6621 (0.7539)	grad_norm 1.3738 (1.5871)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 20:08:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:05 lr 0.000043	 wd 0.0000	time 0.1872 (0.2344)	loss 0.8003 (0.7546)	grad_norm 0.9625 (1.5818)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 20:08:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:04:37 lr 0.000043	 wd 0.0000	time 0.1961 (0.2310)	loss 0.7451 (0.7529)	grad_norm 1.6734 (1.5800)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 20:08:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:11 lr 0.000042	 wd 0.0000	time 0.1883 (0.2279)	loss 0.7666 (0.7522)	grad_norm 1.3285 (1.5788)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 20:08:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:03:45 lr 0.000042	 wd 0.0000	time 0.1795 (0.2255)	loss 0.7954 (0.7522)	grad_norm 1.7611 (1.5729)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 20:09:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:24 lr 0.000042	 wd 0.0000	time 0.1793 (0.2265)	loss 0.7681 (0.7521)	grad_norm 1.5972 (1.5717)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 20:09:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:00 lr 0.000042	 wd 0.0000	time 0.1736 (0.2248)	loss 0.6421 (0.7528)	grad_norm 1.2516 (inf)	loss_scale 16384.0000 (32652.4162)	mem 7891MB
[2024-07-27 20:10:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:36 lr 0.000042	 wd 0.0000	time 0.1831 (0.2230)	loss 0.7817 (0.7530)	grad_norm 1.6029 (inf)	loss_scale 16384.0000 (31749.1172)	mem 7891MB
[2024-07-27 20:10:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:13 lr 0.000041	 wd 0.0000	time 0.1944 (0.2212)	loss 0.8052 (0.7534)	grad_norm 1.7405 (inf)	loss_scale 16384.0000 (30940.8522)	mem 7891MB
[2024-07-27 20:10:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:01:50 lr 0.000041	 wd 0.0000	time 0.2125 (0.2201)	loss 0.6758 (0.7529)	grad_norm 1.3656 (inf)	loss_scale 16384.0000 (30213.3733)	mem 7891MB
[2024-07-27 20:11:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:28 lr 0.000041	 wd 0.0000	time 0.1745 (0.2211)	loss 0.6719 (0.7530)	grad_norm 0.9931 (inf)	loss_scale 16384.0000 (29555.1452)	mem 7891MB
[2024-07-27 20:11:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:06 lr 0.000041	 wd 0.0000	time 0.1792 (0.2202)	loss 0.7241 (0.7531)	grad_norm 1.5178 (inf)	loss_scale 16384.0000 (28956.7288)	mem 7891MB
[2024-07-27 20:11:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:44 lr 0.000041	 wd 0.0000	time 0.1857 (0.2189)	loss 0.7651 (0.7533)	grad_norm 1.3323 (inf)	loss_scale 16384.0000 (28410.3259)	mem 7891MB
[2024-07-27 20:12:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:22 lr 0.000040	 wd 0.0000	time 0.1779 (0.2177)	loss 0.7080 (0.7529)	grad_norm 1.3379 (inf)	loss_scale 16384.0000 (27909.4377)	mem 7891MB
[2024-07-27 20:12:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1723 (0.2163)	loss 0.7354 (0.7528)	grad_norm 1.4190 (inf)	loss_scale 16384.0000 (27448.6046)	mem 7891MB
[2024-07-27 20:12:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 16 training takes 0:09:10
[2024-07-27 20:13:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 39.039 (39.039)	Loss 0.3726 (0.3726)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 20:13:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.352 Acc@5 97.506
[2024-07-27 20:13:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 20:13:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 20:13:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][0/2502]	eta 10:58:15 lr 0.000040	 wd 0.0000	time 15.7857 (15.7857)	loss 0.6934 (0.6934)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:14:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:19:22 lr 0.000040	 wd 0.0000	time 0.1890 (0.4841)	loss 0.8394 (0.7521)	grad_norm 1.2599 (1.4783)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:14:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:13:03 lr 0.000040	 wd 0.0000	time 0.1946 (0.3406)	loss 0.8589 (0.7589)	grad_norm 1.9159 (1.5113)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:14:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:36 lr 0.000040	 wd 0.0000	time 0.1728 (0.2891)	loss 0.8008 (0.7579)	grad_norm 1.8071 (1.5194)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:15:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:09:13 lr 0.000039	 wd 0.0000	time 0.1914 (0.2632)	loss 0.7158 (0.7528)	grad_norm 1.3880 (1.5304)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:15:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:08:27 lr 0.000039	 wd 0.0000	time 0.2332 (0.2535)	loss 0.7217 (0.7542)	grad_norm 1.3314 (1.5316)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:16:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:28 lr 0.000039	 wd 0.0000	time 0.1688 (0.2674)	loss 0.7495 (0.7550)	grad_norm 1.2582 (1.5383)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:16:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:41 lr 0.000039	 wd 0.0000	time 0.1715 (0.2561)	loss 0.6846 (0.7544)	grad_norm 1.4653 (1.5450)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:16:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:07:01 lr 0.000039	 wd 0.0000	time 0.1760 (0.2474)	loss 0.6733 (0.7552)	grad_norm 1.1510 (1.5555)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:17:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:26 lr 0.000038	 wd 0.0000	time 0.1892 (0.2413)	loss 0.7271 (0.7557)	grad_norm 1.5866 (1.5610)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:17:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:15 lr 0.000038	 wd 0.0000	time 0.1971 (0.2502)	loss 0.8262 (0.7553)	grad_norm 1.8638 (1.5665)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:17:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:42 lr 0.000038	 wd 0.0000	time 0.1857 (0.2446)	loss 0.8462 (0.7562)	grad_norm 1.8468 (1.5584)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:18:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:12 lr 0.000038	 wd 0.0000	time 0.1794 (0.2397)	loss 0.8042 (0.7567)	grad_norm 1.7472 (1.5557)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:18:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:04:43 lr 0.000038	 wd 0.0000	time 0.1821 (0.2355)	loss 0.8862 (0.7560)	grad_norm 1.3714 (1.5543)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:18:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:20 lr 0.000037	 wd 0.0000	time 0.4875 (0.2363)	loss 0.7109 (0.7566)	grad_norm 1.1611 (1.5596)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:19:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:03:58 lr 0.000037	 wd 0.0000	time 0.1778 (0.2385)	loss 0.7500 (0.7569)	grad_norm 1.1961 (1.5583)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:19:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:32 lr 0.000037	 wd 0.0000	time 0.1756 (0.2353)	loss 0.6787 (0.7566)	grad_norm 1.7748 (1.5596)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:20:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:06 lr 0.000037	 wd 0.0000	time 0.1920 (0.2325)	loss 0.8936 (0.7563)	grad_norm 1.4393 (1.5601)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:20:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:41 lr 0.000037	 wd 0.0000	time 0.1885 (0.2305)	loss 0.6855 (0.7565)	grad_norm 1.0722 (1.5593)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:20:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:18 lr 0.000036	 wd 0.0000	time 0.2286 (0.2305)	loss 0.7061 (0.7565)	grad_norm 1.6763 (1.5594)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:21:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:01:54 lr 0.000036	 wd 0.0000	time 0.1856 (0.2290)	loss 0.7417 (0.7560)	grad_norm 2.3669 (1.5608)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:21:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:31 lr 0.000036	 wd 0.0000	time 0.1952 (0.2273)	loss 0.6934 (0.7559)	grad_norm 2.5711 (1.5587)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:21:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:08 lr 0.000036	 wd 0.0000	time 0.1745 (0.2256)	loss 0.7534 (0.7560)	grad_norm 1.2990 (1.5602)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:22:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:45 lr 0.000036	 wd 0.0000	time 0.1854 (0.2246)	loss 0.7261 (0.7558)	grad_norm 1.9032 (1.5593)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:22:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:22 lr 0.000035	 wd 0.0000	time 0.2343 (0.2243)	loss 0.6958 (0.7567)	grad_norm 2.0130 (1.5575)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:22:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1695 (0.2227)	loss 0.8877 (0.7571)	grad_norm 1.7609 (1.5610)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:22:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 17 training takes 0:09:25
[2024-07-27 20:23:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 20.544 (20.544)	Loss 0.3774 (0.3774)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 20:23:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.440 Acc@5 97.518
[2024-07-27 20:23:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 20:23:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 20:24:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][0/2502]	eta 1 day, 1:44:25 lr 0.000035	 wd 0.0000	time 37.0367 (37.0367)	loss 0.8032 (0.8032)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:24:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:22:28 lr 0.000035	 wd 0.0000	time 0.1759 (0.5613)	loss 0.7256 (0.7512)	grad_norm 1.2542 (1.6177)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:24:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:14:24 lr 0.000035	 wd 0.0000	time 0.1746 (0.3756)	loss 0.8306 (0.7487)	grad_norm 1.3015 (1.5681)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:25:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:11:31 lr 0.000035	 wd 0.0000	time 0.2080 (0.3139)	loss 0.7964 (0.7538)	grad_norm 1.4964 (1.5392)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:25:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:11:26 lr 0.000034	 wd 0.0000	time 0.1885 (0.3267)	loss 0.7495 (0.7559)	grad_norm 1.2527 (1.5516)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:26:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:10:02 lr 0.000034	 wd 0.0000	time 0.2078 (0.3008)	loss 0.6919 (0.7567)	grad_norm 1.7595 (1.5589)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:26:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:08:56 lr 0.000034	 wd 0.0000	time 0.1717 (0.2819)	loss 0.6963 (0.7563)	grad_norm 2.6344 (1.5524)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:26:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:08:03 lr 0.000034	 wd 0.0000	time 0.1742 (0.2683)	loss 0.8682 (0.7553)	grad_norm 1.3786 (1.5564)	loss_scale 32768.0000 (16757.9572)	mem 7891MB
[2024-07-27 20:27:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:46 lr 0.000034	 wd 0.0000	time 0.2319 (0.2741)	loss 0.7505 (0.7534)	grad_norm 1.9372 (1.5517)	loss_scale 32768.0000 (18756.7141)	mem 7891MB
[2024-07-27 20:27:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:07:05 lr 0.000033	 wd 0.0000	time 0.1762 (0.2657)	loss 0.8096 (0.7537)	grad_norm 2.4409 (inf)	loss_scale 16384.0000 (18602.4772)	mem 7891MB
[2024-07-27 20:27:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:27 lr 0.000033	 wd 0.0000	time 0.1860 (0.2578)	loss 0.6992 (0.7535)	grad_norm 1.5100 (inf)	loss_scale 16384.0000 (18380.8511)	mem 7891MB
[2024-07-27 20:28:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:52 lr 0.000033	 wd 0.0000	time 0.1815 (0.2512)	loss 0.7241 (0.7545)	grad_norm 1.5585 (inf)	loss_scale 16384.0000 (18199.4841)	mem 7891MB
[2024-07-27 20:28:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:23 lr 0.000033	 wd 0.0000	time 0.3936 (0.2487)	loss 0.9907 (0.7543)	grad_norm 1.6643 (inf)	loss_scale 16384.0000 (18048.3197)	mem 7891MB
[2024-07-27 20:29:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:05:06 lr 0.000033	 wd 0.0000	time 0.1765 (0.2548)	loss 0.6445 (0.7549)	grad_norm 1.4250 (inf)	loss_scale 16384.0000 (17920.3935)	mem 7891MB
[2024-07-27 20:29:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:35 lr 0.000032	 wd 0.0000	time 0.1766 (0.2500)	loss 0.7046 (0.7537)	grad_norm 1.7359 (inf)	loss_scale 16384.0000 (17810.7295)	mem 7891MB
[2024-07-27 20:29:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:04:06 lr 0.000032	 wd 0.0000	time 0.1803 (0.2457)	loss 0.7031 (0.7542)	grad_norm 1.6803 (inf)	loss_scale 16384.0000 (17715.6775)	mem 7891MB
[2024-07-27 20:30:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:38 lr 0.000032	 wd 0.0000	time 0.1869 (0.2427)	loss 0.7583 (0.7542)	grad_norm 1.5685 (inf)	loss_scale 16384.0000 (17632.4997)	mem 7891MB
[2024-07-27 20:30:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:13 lr 0.000032	 wd 0.0000	time 0.1806 (0.2415)	loss 0.8667 (0.7542)	grad_norm 1.4505 (inf)	loss_scale 16384.0000 (17559.1017)	mem 7891MB
[2024-07-27 20:30:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:47 lr 0.000032	 wd 0.0000	time 0.1818 (0.2391)	loss 0.7729 (0.7545)	grad_norm 1.4761 (inf)	loss_scale 16384.0000 (17493.8545)	mem 7891MB
[2024-07-27 20:31:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:22 lr 0.000032	 wd 0.0000	time 0.1902 (0.2366)	loss 0.9019 (0.7544)	grad_norm 1.3340 (inf)	loss_scale 16384.0000 (17435.4719)	mem 7891MB
[2024-07-27 20:31:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:01:57 lr 0.000031	 wd 0.0000	time 0.1628 (0.2344)	loss 0.8652 (0.7551)	grad_norm 1.4665 (inf)	loss_scale 16384.0000 (17382.9245)	mem 7891MB
[2024-07-27 20:31:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:33 lr 0.000031	 wd 0.0000	time 0.2081 (0.2327)	loss 0.6953 (0.7550)	grad_norm 1.4381 (inf)	loss_scale 16384.0000 (17335.3793)	mem 7891MB
[2024-07-27 20:32:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:10 lr 0.000031	 wd 0.0000	time 0.2601 (0.2329)	loss 0.6533 (0.7555)	grad_norm 1.1579 (inf)	loss_scale 16384.0000 (17292.1545)	mem 7891MB
[2024-07-27 20:32:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:46 lr 0.000031	 wd 0.0000	time 0.1837 (0.2314)	loss 0.6982 (0.7559)	grad_norm 1.6948 (inf)	loss_scale 16384.0000 (17252.6867)	mem 7891MB
[2024-07-27 20:32:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:23 lr 0.000031	 wd 0.0000	time 0.1700 (0.2297)	loss 0.7788 (0.7558)	grad_norm 1.7142 (inf)	loss_scale 16384.0000 (17216.5065)	mem 7891MB
[2024-07-27 20:33:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000030	 wd 0.0000	time 0.1702 (0.2277)	loss 0.7539 (0.7563)	grad_norm 1.4276 (inf)	loss_scale 16384.0000 (17183.2195)	mem 7891MB
[2024-07-27 20:33:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 18 training takes 0:09:38
[2024-07-27 20:33:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 38.369 (38.369)	Loss 0.3765 (0.3765)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 20:34:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.352 Acc@5 97.504
[2024-07-27 20:34:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 20:34:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 20:34:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][0/2502]	eta 10:46:23 lr 0.000030	 wd 0.0000	time 15.5009 (15.5009)	loss 0.7192 (0.7192)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:34:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:13:58 lr 0.000030	 wd 0.0000	time 0.1857 (0.3493)	loss 0.9106 (0.7681)	grad_norm 1.6435 (1.5888)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:35:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:14:05 lr 0.000030	 wd 0.0000	time 0.1758 (0.3674)	loss 0.6338 (0.7683)	grad_norm 2.3046 (1.5669)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:35:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:11:26 lr 0.000030	 wd 0.0000	time 0.1755 (0.3118)	loss 0.7222 (0.7656)	grad_norm 1.2696 (1.5421)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:35:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:09:50 lr 0.000030	 wd 0.0000	time 0.1747 (0.2808)	loss 0.8184 (0.7635)	grad_norm 1.2327 (1.5357)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:36:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:08:44 lr 0.000029	 wd 0.0000	time 0.1850 (0.2621)	loss 0.8149 (0.7615)	grad_norm 1.3537 (1.5239)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:36:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:45 lr 0.000029	 wd 0.0000	time 0.7914 (0.2762)	loss 0.7339 (0.7620)	grad_norm 1.5834 (1.5162)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:37:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:08:04 lr 0.000029	 wd 0.0000	time 0.1855 (0.2690)	loss 0.7725 (0.7619)	grad_norm 1.5554 (1.5151)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:37:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:07:20 lr 0.000029	 wd 0.0000	time 0.1718 (0.2588)	loss 0.6777 (0.7612)	grad_norm 1.3872 (1.5147)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:37:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:06:41 lr 0.000029	 wd 0.0000	time 0.1712 (0.2509)	loss 0.6782 (0.7597)	grad_norm 1.7734 (1.5144)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:38:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:18 lr 0.000028	 wd 0.0000	time 0.5467 (0.2519)	loss 0.6602 (0.7594)	grad_norm 2.7034 (1.5219)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:38:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:06:00 lr 0.000028	 wd 0.0000	time 0.1713 (0.2569)	loss 0.8569 (0.7598)	grad_norm 1.8163 (1.5262)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:39:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:27 lr 0.000028	 wd 0.0000	time 0.1768 (0.2512)	loss 0.7471 (0.7594)	grad_norm 1.2408 (1.5318)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:39:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:04:55 lr 0.000028	 wd 0.0000	time 0.1773 (0.2461)	loss 0.6494 (0.7602)	grad_norm 1.8288 (1.5360)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:39:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:28 lr 0.000028	 wd 0.0000	time 0.2834 (0.2440)	loss 0.6924 (0.7607)	grad_norm 1.5568 (1.5354)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:40:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:04:08 lr 0.000028	 wd 0.0000	time 0.1758 (0.2477)	loss 0.7896 (0.7615)	grad_norm 1.5141 (1.5342)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:40:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:40 lr 0.000027	 wd 0.0000	time 0.1821 (0.2440)	loss 0.7090 (0.7615)	grad_norm 1.6677 (1.5357)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:40:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:12 lr 0.000027	 wd 0.0000	time 0.1797 (0.2406)	loss 0.6431 (0.7611)	grad_norm 1.7583 (1.5377)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:41:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:47 lr 0.000027	 wd 0.0000	time 0.1962 (0.2380)	loss 0.6709 (0.7615)	grad_norm 1.3087 (1.5349)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:41:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:23 lr 0.000027	 wd 0.0000	time 0.1908 (0.2378)	loss 0.7842 (0.7613)	grad_norm 1.4318 (1.5380)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:41:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:58 lr 0.000027	 wd 0.0000	time 0.1797 (0.2359)	loss 0.8276 (0.7606)	grad_norm 1.8718 (1.5420)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:42:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:34 lr 0.000026	 wd 0.0000	time 0.1899 (0.2340)	loss 0.9053 (0.7603)	grad_norm 1.6306 (1.5398)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:42:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:10 lr 0.000026	 wd 0.0000	time 0.2080 (0.2320)	loss 0.7856 (0.7604)	grad_norm 1.9406 (1.5416)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:42:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:46 lr 0.000026	 wd 0.0000	time 0.2473 (0.2308)	loss 0.8340 (0.7607)	grad_norm 1.2718 (1.5382)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:43:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:23 lr 0.000026	 wd 0.0000	time 0.1819 (0.2311)	loss 0.9248 (0.7607)	grad_norm 1.8437 (1.5404)	loss_scale 32768.0000 (17039.0870)	mem 7891MB
[2024-07-27 20:43:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1724 (0.2292)	loss 0.6865 (0.7605)	grad_norm 1.3713 (1.5427)	loss_scale 32768.0000 (17667.9920)	mem 7891MB
[2024-07-27 20:43:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 19 training takes 0:09:42
[2024-07-27 20:44:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 21.307 (21.307)	Loss 0.3743 (0.3743)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 20:44:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.456 Acc@5 97.510
[2024-07-27 20:44:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-27 20:44:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 20:45:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][0/2502]	eta 1 day, 2:29:43 lr 0.000026	 wd 0.0000	time 38.1230 (38.1230)	loss 0.8896 (0.8896)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 20:45:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:23:28 lr 0.000026	 wd 0.0000	time 0.1751 (0.5864)	loss 0.7749 (0.7685)	grad_norm 1.8413 (inf)	loss_scale 16384.0000 (30172.5149)	mem 7891MB
[2024-07-27 20:45:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:14:50 lr 0.000025	 wd 0.0000	time 0.1779 (0.3867)	loss 0.8345 (0.7647)	grad_norm 1.6108 (inf)	loss_scale 16384.0000 (23312.5572)	mem 7891MB
[2024-07-27 20:46:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:11:58 lr 0.000025	 wd 0.0000	time 0.3034 (0.3263)	loss 0.7085 (0.7644)	grad_norm 1.7918 (inf)	loss_scale 16384.0000 (21010.7110)	mem 7891MB
[2024-07-27 20:46:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:12:27 lr 0.000025	 wd 0.0000	time 0.1733 (0.3555)	loss 0.6860 (0.7613)	grad_norm 1.2944 (inf)	loss_scale 16384.0000 (19856.9177)	mem 7891MB
[2024-07-27 20:47:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:10:44 lr 0.000025	 wd 0.0000	time 0.1888 (0.3221)	loss 0.7915 (0.7617)	grad_norm 1.2033 (inf)	loss_scale 16384.0000 (19163.7206)	mem 7891MB
[2024-07-27 20:47:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:09:30 lr 0.000025	 wd 0.0000	time 0.1765 (0.2997)	loss 0.7207 (0.7615)	grad_norm 1.4714 (inf)	loss_scale 16384.0000 (18701.2047)	mem 7891MB
[2024-07-27 20:47:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:08:39 lr 0.000025	 wd 0.0000	time 0.3781 (0.2885)	loss 0.6748 (0.7616)	grad_norm 1.4345 (inf)	loss_scale 16384.0000 (18370.6476)	mem 7891MB
[2024-07-27 20:48:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:08:19 lr 0.000024	 wd 0.0000	time 0.1784 (0.2934)	loss 0.7607 (0.7623)	grad_norm 1.5628 (inf)	loss_scale 16384.0000 (18122.6267)	mem 7891MB
[2024-07-27 20:48:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:07:31 lr 0.000024	 wd 0.0000	time 0.1829 (0.2819)	loss 0.9180 (0.7621)	grad_norm 1.8274 (inf)	loss_scale 16384.0000 (17929.6604)	mem 7891MB
[2024-07-27 20:49:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:48 lr 0.000024	 wd 0.0000	time 0.2011 (0.2722)	loss 0.7183 (0.7636)	grad_norm 1.6749 (inf)	loss_scale 16384.0000 (17775.2488)	mem 7891MB
[2024-07-27 20:49:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:06:11 lr 0.000024	 wd 0.0000	time 0.2042 (0.2653)	loss 0.7031 (0.7636)	grad_norm 1.6184 (inf)	loss_scale 16384.0000 (17648.8865)	mem 7891MB
[2024-07-27 20:49:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:50 lr 0.000024	 wd 0.0000	time 0.1742 (0.2692)	loss 0.6772 (0.7631)	grad_norm 1.6432 (inf)	loss_scale 16384.0000 (17543.5670)	mem 7891MB
[2024-07-27 20:50:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:05:15 lr 0.000023	 wd 0.0000	time 0.1765 (0.2629)	loss 0.7222 (0.7624)	grad_norm 1.3381 (inf)	loss_scale 16384.0000 (17454.4381)	mem 7891MB
[2024-07-27 20:50:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:43 lr 0.000023	 wd 0.0000	time 0.1715 (0.2574)	loss 0.7583 (0.7627)	grad_norm 1.6684 (inf)	loss_scale 16384.0000 (17378.0328)	mem 7891MB
[2024-07-27 20:50:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:04:13 lr 0.000023	 wd 0.0000	time 0.2230 (0.2528)	loss 0.8115 (0.7623)	grad_norm 1.4666 (inf)	loss_scale 16384.0000 (17311.8081)	mem 7891MB
[2024-07-27 20:51:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:45 lr 0.000023	 wd 0.0000	time 0.2555 (0.2504)	loss 0.8032 (0.7614)	grad_norm 1.0787 (inf)	loss_scale 16384.0000 (17253.8563)	mem 7891MB
[2024-07-27 20:51:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:19 lr 0.000023	 wd 0.0000	time 0.1766 (0.2490)	loss 0.9414 (0.7615)	grad_norm 1.2099 (inf)	loss_scale 16384.0000 (17202.7184)	mem 7891MB
[2024-07-27 20:51:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:52 lr 0.000023	 wd 0.0000	time 0.1682 (0.2459)	loss 0.7754 (0.7615)	grad_norm 1.7522 (inf)	loss_scale 16384.0000 (17157.2593)	mem 7891MB
[2024-07-27 20:52:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:26 lr 0.000022	 wd 0.0000	time 0.1892 (0.2430)	loss 0.7646 (0.7616)	grad_norm 1.3684 (inf)	loss_scale 16384.0000 (17116.5829)	mem 7891MB
[2024-07-27 20:52:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:02:00 lr 0.000022	 wd 0.0000	time 0.2046 (0.2405)	loss 0.8042 (0.7616)	grad_norm 1.7903 (inf)	loss_scale 16384.0000 (17079.9720)	mem 7891MB
[2024-07-27 20:52:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:36 lr 0.000022	 wd 0.0000	time 0.1786 (0.2396)	loss 0.8120 (0.7618)	grad_norm 1.3987 (inf)	loss_scale 16384.0000 (17046.8463)	mem 7891MB
[2024-07-27 20:53:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:12 lr 0.000022	 wd 0.0000	time 0.1977 (0.2385)	loss 0.7939 (0.7618)	grad_norm 1.5476 (inf)	loss_scale 16384.0000 (17016.7306)	mem 7891MB
[2024-07-27 20:53:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:47 lr 0.000022	 wd 0.0000	time 0.2051 (0.2366)	loss 0.7383 (0.7620)	grad_norm 1.2267 (inf)	loss_scale 16384.0000 (16989.2325)	mem 7891MB
[2024-07-27 20:53:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:23 lr 0.000022	 wd 0.0000	time 0.1872 (0.2347)	loss 0.7549 (0.7625)	grad_norm 1.3471 (inf)	loss_scale 16384.0000 (16964.0250)	mem 7891MB
[2024-07-27 20:54:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1674 (0.2325)	loss 0.7700 (0.7624)	grad_norm 1.0234 (inf)	loss_scale 16384.0000 (16940.8333)	mem 7891MB
[2024-07-27 20:54:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 20 training takes 0:09:49
[2024-07-27 20:54:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 38.968 (38.968)	Loss 0.3760 (0.3760)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 20:55:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.386 Acc@5 97.514
[2024-07-27 20:55:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 20:55:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 20:55:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][0/2502]	eta 11:29:14 lr 0.000021	 wd 0.0000	time 16.5286 (16.5286)	loss 0.8276 (0.8276)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:55:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:15:25 lr 0.000021	 wd 0.0000	time 0.2951 (0.3855)	loss 0.7363 (0.7661)	grad_norm 1.6376 (1.5101)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:56:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:12:52 lr 0.000021	 wd 0.0000	time 0.1728 (0.3354)	loss 0.7646 (0.7682)	grad_norm 1.2866 (1.5573)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:56:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:10:29 lr 0.000021	 wd 0.0000	time 0.1853 (0.2860)	loss 0.7227 (0.7618)	grad_norm 1.1325 (1.5765)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:57:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:09:08 lr 0.000021	 wd 0.0000	time 0.1730 (0.2611)	loss 0.6782 (0.7610)	grad_norm 1.4723 (1.5662)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:57:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:08:13 lr 0.000021	 wd 0.0000	time 0.2142 (0.2464)	loss 0.8745 (0.7629)	grad_norm 1.5710 (1.5598)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:57:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:24 lr 0.000020	 wd 0.0000	time 0.2326 (0.2651)	loss 0.8169 (0.7634)	grad_norm 1.2446 (1.5481)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:58:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:07:38 lr 0.000020	 wd 0.0000	time 0.1631 (0.2543)	loss 0.7446 (0.7637)	grad_norm 1.5808 (1.5499)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:58:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:06:58 lr 0.000020	 wd 0.0000	time 0.1712 (0.2459)	loss 0.7881 (0.7631)	grad_norm 1.4767 (1.5348)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:58:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:23 lr 0.000020	 wd 0.0000	time 0.1987 (0.2394)	loss 0.7563 (0.7628)	grad_norm 1.2976 (1.5338)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:59:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:11 lr 0.000020	 wd 0.0000	time 0.6284 (0.2471)	loss 0.7373 (0.7622)	grad_norm 1.4602 (1.5322)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 20:59:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:05:44 lr 0.000020	 wd 0.0000	time 0.1718 (0.2454)	loss 0.7437 (0.7630)	grad_norm 1.2243 (1.5277)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:00:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:13 lr 0.000019	 wd 0.0000	time 0.1797 (0.2406)	loss 0.8193 (0.7632)	grad_norm 2.5204 (1.5293)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:00:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:44 lr 0.000019	 wd 0.0000	time 0.2044 (0.2363)	loss 0.8618 (0.7628)	grad_norm 1.2355 (1.5334)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:00:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:17 lr 0.000019	 wd 0.0000	time 0.3467 (0.2341)	loss 0.7075 (0.7628)	grad_norm 1.7519 (1.5351)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:01:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:03:59 lr 0.000019	 wd 0.0000	time 0.1993 (0.2389)	loss 0.7769 (0.7628)	grad_norm 1.5436 (1.5366)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:01:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:32 lr 0.000019	 wd 0.0000	time 0.1947 (0.2356)	loss 0.7769 (0.7623)	grad_norm 1.4447 (1.5373)	loss_scale 32768.0000 (16568.2049)	mem 7891MB
[2024-07-27 21:01:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:06 lr 0.000019	 wd 0.0000	time 0.1778 (0.2328)	loss 0.7515 (0.7622)	grad_norm 1.5454 (inf)	loss_scale 16384.0000 (17135.2945)	mem 7891MB
[2024-07-27 21:02:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:41 lr 0.000018	 wd 0.0000	time 0.1867 (0.2306)	loss 0.7827 (0.7620)	grad_norm 1.4168 (inf)	loss_scale 16384.0000 (17093.5791)	mem 7891MB
[2024-07-27 21:02:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:19 lr 0.000018	 wd 0.0000	time 0.1849 (0.2314)	loss 0.6875 (0.7618)	grad_norm 1.8610 (inf)	loss_scale 16384.0000 (17056.2525)	mem 7891MB
[2024-07-27 21:02:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:55 lr 0.000018	 wd 0.0000	time 0.1901 (0.2300)	loss 0.7583 (0.7622)	grad_norm 1.2618 (inf)	loss_scale 16384.0000 (17022.6567)	mem 7891MB
[2024-07-27 21:03:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:31 lr 0.000018	 wd 0.0000	time 0.1742 (0.2282)	loss 0.7783 (0.7624)	grad_norm 1.7532 (inf)	loss_scale 16384.0000 (16992.2589)	mem 7891MB
[2024-07-27 21:03:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:08 lr 0.000018	 wd 0.0000	time 0.2046 (0.2265)	loss 0.6455 (0.7625)	grad_norm 1.3933 (inf)	loss_scale 16384.0000 (16964.6234)	mem 7891MB
[2024-07-27 21:03:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:45 lr 0.000018	 wd 0.0000	time 0.2091 (0.2253)	loss 0.8486 (0.7632)	grad_norm 1.5184 (inf)	loss_scale 16384.0000 (16939.3898)	mem 7891MB
[2024-07-27 21:04:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:23 lr 0.000018	 wd 0.0000	time 0.1798 (0.2255)	loss 0.7583 (0.7634)	grad_norm 1.5763 (inf)	loss_scale 16384.0000 (16916.2582)	mem 7891MB
[2024-07-27 21:04:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000017	 wd 0.0000	time 0.1650 (0.2239)	loss 0.8076 (0.7638)	grad_norm 1.1332 (inf)	loss_scale 16384.0000 (16894.9764)	mem 7891MB
[2024-07-27 21:04:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 21 training takes 0:09:26
[2024-07-27 21:05:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 20.136 (20.136)	Loss 0.3740 (0.3740)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 21:05:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.428 Acc@5 97.498
[2024-07-27 21:05:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 21:05:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 21:05:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][0/2502]	eta 1 day, 1:13:58 lr 0.000017	 wd 0.0000	time 36.3065 (36.3065)	loss 0.8066 (0.8066)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:06:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:21:54 lr 0.000017	 wd 0.0000	time 0.2036 (0.5472)	loss 0.8774 (0.7767)	grad_norm 1.2573 (1.6201)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:06:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:14:06 lr 0.000017	 wd 0.0000	time 0.1930 (0.3676)	loss 0.6655 (0.7733)	grad_norm 1.4303 (1.5721)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:06:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:11:14 lr 0.000017	 wd 0.0000	time 0.1856 (0.3064)	loss 0.8579 (0.7701)	grad_norm 2.1264 (1.5786)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:07:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:10:12 lr 0.000017	 wd 0.0000	time 0.3673 (0.2916)	loss 0.8354 (0.7721)	grad_norm 1.3722 (1.5669)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:07:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:10:08 lr 0.000017	 wd 0.0000	time 0.1773 (0.3040)	loss 0.8735 (0.7743)	grad_norm 1.6776 (1.5705)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:08:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:09:02 lr 0.000016	 wd 0.0000	time 0.1966 (0.2851)	loss 0.8843 (0.7743)	grad_norm 1.5228 (1.5597)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:08:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:08:08 lr 0.000016	 wd 0.0000	time 0.1737 (0.2711)	loss 0.7539 (0.7748)	grad_norm 1.1639 (1.5526)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:08:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:07:38 lr 0.000016	 wd 0.0000	time 0.4379 (0.2693)	loss 0.7061 (0.7755)	grad_norm 1.8305 (1.5538)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:09:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:07:31 lr 0.000016	 wd 0.0000	time 0.1741 (0.2816)	loss 0.7749 (0.7744)	grad_norm 1.2897 (1.5547)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:09:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:48 lr 0.000016	 wd 0.0000	time 0.1906 (0.2722)	loss 0.6782 (0.7752)	grad_norm 1.6553 (1.5531)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:10:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:06:10 lr 0.000016	 wd 0.0000	time 0.2020 (0.2645)	loss 0.7197 (0.7751)	grad_norm 1.2664 (1.5550)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:10:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:38 lr 0.000016	 wd 0.0000	time 0.1841 (0.2602)	loss 0.7905 (0.7754)	grad_norm 1.4129 (1.5520)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:10:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:05:08 lr 0.000015	 wd 0.0000	time 0.1873 (0.2568)	loss 0.7334 (0.7753)	grad_norm 1.4427 (1.5483)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:11:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:37 lr 0.000015	 wd 0.0000	time 0.2145 (0.2520)	loss 0.7705 (0.7751)	grad_norm 1.6795 (1.5456)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:11:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:04:08 lr 0.000015	 wd 0.0000	time 0.1802 (0.2478)	loss 0.6216 (0.7753)	grad_norm 1.4690 (1.5411)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:11:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:40 lr 0.000015	 wd 0.0000	time 0.2133 (0.2443)	loss 0.8540 (0.7754)	grad_norm 1.2373 (1.5378)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:12:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:15 lr 0.000015	 wd 0.0000	time 0.1734 (0.2441)	loss 0.6587 (0.7746)	grad_norm 1.5401 (1.5354)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:12:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:49 lr 0.000015	 wd 0.0000	time 0.2138 (0.2416)	loss 0.9341 (0.7739)	grad_norm 1.5284 (1.5342)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:12:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:23 lr 0.000015	 wd 0.0000	time 0.1998 (0.2390)	loss 0.8311 (0.7744)	grad_norm 1.1927 (1.5373)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:13:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:58 lr 0.000014	 wd 0.0000	time 0.1864 (0.2367)	loss 0.7637 (0.7744)	grad_norm 1.1861 (1.5349)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:13:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:34 lr 0.000014	 wd 0.0000	time 0.1712 (0.2348)	loss 0.7329 (0.7744)	grad_norm 1.6494 (1.5376)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:13:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:10 lr 0.000014	 wd 0.0000	time 0.1811 (0.2347)	loss 0.6538 (0.7738)	grad_norm 1.3813 (1.5382)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:14:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:47 lr 0.000014	 wd 0.0000	time 0.1908 (0.2333)	loss 0.7583 (0.7735)	grad_norm 1.6942 (1.5402)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:14:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:23 lr 0.000014	 wd 0.0000	time 0.1736 (0.2315)	loss 0.7510 (0.7740)	grad_norm 1.3184 (1.5385)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:14:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1756 (0.2294)	loss 0.7407 (0.7740)	grad_norm 1.3801 (1.5371)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:15:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 22 training takes 0:09:43
[2024-07-27 21:15:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 42.315 (42.315)	Loss 0.3730 (0.3730)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 21:16:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.380 Acc@5 97.492
[2024-07-27 21:16:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 21:16:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 21:16:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][0/2502]	eta 11:06:25 lr 0.000014	 wd 0.0000	time 15.9814 (15.9814)	loss 0.7593 (0.7593)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:16:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:14:19 lr 0.000014	 wd 0.0000	time 0.2280 (0.3578)	loss 0.8408 (0.7702)	grad_norm 1.6533 (1.6214)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:17:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:13:13 lr 0.000013	 wd 0.0000	time 0.2130 (0.3446)	loss 0.7261 (0.7697)	grad_norm 1.8302 (1.5520)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:17:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:10:47 lr 0.000013	 wd 0.0000	time 0.1948 (0.2942)	loss 0.7344 (0.7710)	grad_norm 1.9502 (1.5698)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:17:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:09:21 lr 0.000013	 wd 0.0000	time 0.1775 (0.2671)	loss 0.8960 (0.7731)	grad_norm 1.5029 (1.5567)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:18:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:08:21 lr 0.000013	 wd 0.0000	time 0.1696 (0.2507)	loss 0.8750 (0.7754)	grad_norm 1.6201 (1.5634)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:18:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:07:55 lr 0.000013	 wd 0.0000	time 0.3703 (0.2499)	loss 0.8950 (0.7759)	grad_norm 2.1316 (1.5669)	loss_scale 16384.0000 (16384.0000)	mem 7891MB
[2024-07-27 21:19:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:47 lr 0.000013	 wd 0.0000	time 0.1986 (0.2594)	loss 0.8091 (0.7769)	grad_norm 1.3009 (1.5651)	loss_scale 32768.0000 (17412.3823)	mem 7891MB
[2024-07-27 21:19:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:07:06 lr 0.000013	 wd 0.0000	time 0.1843 (0.2506)	loss 0.7148 (0.7753)	grad_norm 1.4620 (1.5627)	loss_scale 32768.0000 (19329.4382)	mem 7891MB
[2024-07-27 21:19:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:06:30 lr 0.000012	 wd 0.0000	time 0.1758 (0.2435)	loss 0.9844 (0.7746)	grad_norm 1.3306 (1.5640)	loss_scale 32768.0000 (20820.9545)	mem 7891MB
[2024-07-27 21:20:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:00 lr 0.000012	 wd 0.0000	time 0.3106 (0.2402)	loss 0.6885 (0.7756)	grad_norm 1.6111 (1.5623)	loss_scale 32768.0000 (22014.4655)	mem 7891MB
[2024-07-27 21:20:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:45 lr 0.000012	 wd 0.0000	time 0.1807 (0.2466)	loss 0.7383 (0.7744)	grad_norm 1.8653 (1.5604)	loss_scale 32768.0000 (22991.1717)	mem 7891MB
[2024-07-27 21:20:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:14 lr 0.000012	 wd 0.0000	time 0.1914 (0.2417)	loss 0.7607 (0.7747)	grad_norm 1.9234 (1.5588)	loss_scale 32768.0000 (23805.2290)	mem 7891MB
[2024-07-27 21:21:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:04:45 lr 0.000012	 wd 0.0000	time 0.1644 (0.2374)	loss 0.8022 (0.7737)	grad_norm 1.7173 (1.5574)	loss_scale 32768.0000 (24494.1430)	mem 7891MB
[2024-07-27 21:21:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:17 lr 0.000012	 wd 0.0000	time 0.2045 (0.2341)	loss 0.8052 (0.7735)	grad_norm 1.7532 (1.5598)	loss_scale 32768.0000 (25084.7109)	mem 7891MB
[2024-07-27 21:22:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:04:02 lr 0.000012	 wd 0.0000	time 0.2098 (0.2419)	loss 0.8545 (0.7730)	grad_norm 1.8442 (1.5615)	loss_scale 32768.0000 (25596.5889)	mem 7891MB
[2024-07-27 21:22:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:35 lr 0.000012	 wd 0.0000	time 0.1744 (0.2386)	loss 0.7622 (0.7732)	grad_norm 1.7432 (1.5582)	loss_scale 32768.0000 (26044.5222)	mem 7891MB
[2024-07-27 21:22:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:08 lr 0.000011	 wd 0.0000	time 0.1920 (0.2357)	loss 0.6831 (0.7735)	grad_norm 1.4110 (1.5590)	loss_scale 32768.0000 (26439.7884)	mem 7891MB
[2024-07-27 21:23:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:43 lr 0.000011	 wd 0.0000	time 0.1787 (0.2330)	loss 0.8271 (0.7738)	grad_norm 1.3900 (1.5592)	loss_scale 32768.0000 (26791.1605)	mem 7891MB
[2024-07-27 21:23:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:19 lr 0.000011	 wd 0.0000	time 0.1962 (0.2324)	loss 0.7358 (0.7738)	grad_norm 1.2573 (1.5593)	loss_scale 32768.0000 (27105.5655)	mem 7891MB
[2024-07-27 21:23:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:01:56 lr 0.000011	 wd 0.0000	time 0.1901 (0.2329)	loss 0.8667 (0.7733)	grad_norm 1.9178 (1.5588)	loss_scale 32768.0000 (27388.5457)	mem 7891MB
[2024-07-27 21:24:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:32 lr 0.000011	 wd 0.0000	time 0.1841 (0.2310)	loss 0.7876 (0.7737)	grad_norm 2.0626 (1.5608)	loss_scale 32768.0000 (27644.5883)	mem 7891MB
[2024-07-27 21:24:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:09 lr 0.000011	 wd 0.0000	time 0.1939 (0.2291)	loss 0.7979 (0.7737)	grad_norm 1.3892 (1.5633)	loss_scale 32768.0000 (27877.3648)	mem 7891MB
[2024-07-27 21:24:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:46 lr 0.000011	 wd 0.0000	time 0.2367 (0.2278)	loss 0.8408 (0.7739)	grad_norm 1.6798 (1.5618)	loss_scale 32768.0000 (28089.9087)	mem 7891MB
[2024-07-27 21:25:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:23 lr 0.000011	 wd 0.0000	time 0.1724 (0.2277)	loss 0.7983 (0.7739)	grad_norm 1.5330 (1.5617)	loss_scale 32768.0000 (28284.7480)	mem 7891MB
[2024-07-27 21:25:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1680 (0.2259)	loss 0.8101 (0.7737)	grad_norm 1.4133 (1.5607)	loss_scale 32768.0000 (28464.0064)	mem 7891MB
[2024-07-27 21:25:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 23 training takes 0:09:35
[2024-07-27 21:26:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 20.163 (20.163)	Loss 0.3755 (0.3755)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 21:26:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.424 Acc@5 97.518
[2024-07-27 21:26:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 21:26:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 21:26:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][0/2502]	eta 1 day, 0:28:46 lr 0.000010	 wd 0.0000	time 35.2225 (35.2225)	loss 0.7114 (0.7114)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:27:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:21:33 lr 0.000010	 wd 0.0000	time 0.2015 (0.5384)	loss 0.8125 (0.7672)	grad_norm 1.8182 (1.6107)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:27:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:13:56 lr 0.000010	 wd 0.0000	time 0.1900 (0.3634)	loss 0.8071 (0.7743)	grad_norm 1.5004 (1.6025)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:27:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:11:10 lr 0.000010	 wd 0.0000	time 0.1956 (0.3044)	loss 0.7358 (0.7730)	grad_norm 1.7574 (1.6019)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:28:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:10:16 lr 0.000010	 wd 0.0000	time 0.3079 (0.2933)	loss 0.8115 (0.7729)	grad_norm 1.4259 (1.5899)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:28:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:09:57 lr 0.000010	 wd 0.0000	time 0.1745 (0.2984)	loss 0.7676 (0.7742)	grad_norm 2.2752 (1.5915)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:29:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:08:52 lr 0.000010	 wd 0.0000	time 0.1970 (0.2800)	loss 0.7261 (0.7739)	grad_norm 1.2803 (1.5707)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:29:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:08:00 lr 0.000010	 wd 0.0000	time 0.1790 (0.2667)	loss 0.7188 (0.7742)	grad_norm 1.7038 (1.5633)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:29:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:07:24 lr 0.000010	 wd 0.0000	time 0.3412 (0.2613)	loss 0.6987 (0.7752)	grad_norm 1.2652 (1.5648)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:30:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:07:08 lr 0.000009	 wd 0.0000	time 0.1856 (0.2673)	loss 0.7993 (0.7754)	grad_norm 1.5203 (1.5637)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:30:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:29 lr 0.000009	 wd 0.0000	time 0.1794 (0.2595)	loss 0.8257 (0.7769)	grad_norm 1.6771 (1.5627)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:30:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:05:54 lr 0.000009	 wd 0.0000	time 0.1832 (0.2529)	loss 0.6982 (0.7754)	grad_norm 1.6586 (1.5551)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:31:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:23 lr 0.000009	 wd 0.0000	time 0.2172 (0.2484)	loss 0.6968 (0.7752)	grad_norm 1.6485 (1.5565)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:31:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:05:07 lr 0.000009	 wd 0.0000	time 0.2003 (0.2556)	loss 0.8657 (0.7763)	grad_norm 1.5399 (1.5641)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:32:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:36 lr 0.000009	 wd 0.0000	time 0.1709 (0.2507)	loss 0.8472 (0.7767)	grad_norm 1.8255 (1.5609)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:32:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:06 lr 0.000009	 wd 0.0000	time 0.1796 (0.2464)	loss 0.6670 (0.7771)	grad_norm 1.5194 (1.5539)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:32:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:39 lr 0.000009	 wd 0.0000	time 0.1804 (0.2429)	loss 0.7729 (0.7772)	grad_norm 1.4094 (1.5531)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:33:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:19 lr 0.000008	 wd 0.0000	time 0.1732 (0.2482)	loss 0.8052 (0.7777)	grad_norm 1.4973 (1.5552)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:33:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:51 lr 0.000008	 wd 0.0000	time 0.1800 (0.2449)	loss 0.7363 (0.7773)	grad_norm 2.4271 (1.5558)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:33:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:25 lr 0.000008	 wd 0.0000	time 0.1839 (0.2419)	loss 0.5923 (0.7777)	grad_norm 1.4982 (1.5601)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:34:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:02:00 lr 0.000008	 wd 0.0000	time 0.2021 (0.2394)	loss 0.8188 (0.7773)	grad_norm 1.6437 (1.5601)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:34:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:35 lr 0.000008	 wd 0.0000	time 0.2083 (0.2380)	loss 0.7739 (0.7770)	grad_norm 1.4291 (1.5581)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:35:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:11 lr 0.000008	 wd 0.0000	time 0.2333 (0.2379)	loss 0.8472 (0.7768)	grad_norm 1.6951 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7891MB
[2024-07-27 21:35:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:47 lr 0.000008	 wd 0.0000	time 0.1932 (0.2359)	loss 0.8535 (0.7771)	grad_norm 1.8469 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7891MB
[2024-07-27 21:35:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:23 lr 0.000008	 wd 0.0000	time 0.1740 (0.2341)	loss 0.8774 (0.7773)	grad_norm 1.3810 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7891MB
[2024-07-27 21:35:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1736 (0.2319)	loss 0.8813 (0.7776)	grad_norm 1.5901 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7891MB
[2024-07-27 21:36:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 24 training takes 0:09:48
[2024-07-27 21:36:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 35.150 (35.150)	Loss 0.3743 (0.3743)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 21:37:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.432 Acc@5 97.492
[2024-07-27 21:37:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 21:37:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 21:37:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][0/2502]	eta 10:38:38 lr 0.000008	 wd 0.0000	time 15.3151 (15.3151)	loss 0.7393 (0.7393)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:37:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:14:03 lr 0.000008	 wd 0.0000	time 0.2077 (0.3510)	loss 0.7920 (0.7764)	grad_norm 1.7517 (1.6184)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:38:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:13:36 lr 0.000007	 wd 0.0000	time 0.1990 (0.3545)	loss 0.7163 (0.7769)	grad_norm 1.4789 (1.6020)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:38:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:10:59 lr 0.000007	 wd 0.0000	time 0.1757 (0.2995)	loss 0.7988 (0.7793)	grad_norm 1.6618 (1.5755)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:38:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:09:29 lr 0.000007	 wd 0.0000	time 0.1933 (0.2711)	loss 0.8198 (0.7778)	grad_norm 1.3777 (1.5686)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:39:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:08:28 lr 0.000007	 wd 0.0000	time 0.1966 (0.2542)	loss 0.7432 (0.7783)	grad_norm 1.5386 (1.5587)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:39:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:26 lr 0.000007	 wd 0.0000	time 0.3302 (0.2662)	loss 0.7705 (0.7789)	grad_norm 1.2742 (1.5607)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:40:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:07:52 lr 0.000007	 wd 0.0000	time 0.1743 (0.2622)	loss 0.8149 (0.7778)	grad_norm 1.3596 (1.5556)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:40:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:07:10 lr 0.000007	 wd 0.0000	time 0.1756 (0.2529)	loss 0.8379 (0.7775)	grad_norm 1.8680 (1.5637)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:40:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:06:33 lr 0.000007	 wd 0.0000	time 0.1773 (0.2455)	loss 0.7485 (0.7771)	grad_norm 1.4524 (1.5618)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:41:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:07 lr 0.000007	 wd 0.0000	time 0.3728 (0.2446)	loss 0.8657 (0.7771)	grad_norm 1.0936 (1.5634)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:41:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:48 lr 0.000007	 wd 0.0000	time 0.1647 (0.2489)	loss 0.7285 (0.7769)	grad_norm 1.5202 (1.5662)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:41:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:17 lr 0.000006	 wd 0.0000	time 0.1777 (0.2438)	loss 0.9868 (0.7783)	grad_norm 1.3489 (1.5600)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:42:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:04:47 lr 0.000006	 wd 0.0000	time 0.1794 (0.2394)	loss 0.7866 (0.7786)	grad_norm 1.3755 (1.5611)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:42:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:20 lr 0.000006	 wd 0.0000	time 0.2170 (0.2362)	loss 0.7778 (0.7784)	grad_norm 1.6768 (1.5589)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:43:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:04:02 lr 0.000006	 wd 0.0000	time 0.1996 (0.2422)	loss 0.8032 (0.7786)	grad_norm 1.5535 (1.5587)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:43:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:35 lr 0.000006	 wd 0.0000	time 0.1893 (0.2389)	loss 0.7944 (0.7782)	grad_norm 1.4096 (1.5594)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:43:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:09 lr 0.000006	 wd 0.0000	time 0.1732 (0.2358)	loss 0.7681 (0.7779)	grad_norm 1.8227 (1.5622)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:44:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:43 lr 0.000006	 wd 0.0000	time 0.2002 (0.2334)	loss 0.9785 (0.7788)	grad_norm 1.5721 (1.5597)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:44:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:19 lr 0.000006	 wd 0.0000	time 0.1652 (0.2321)	loss 1.0576 (0.7792)	grad_norm 1.3926 (1.5625)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:44:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:01:56 lr 0.000006	 wd 0.0000	time 0.1846 (0.2322)	loss 0.8022 (0.7790)	grad_norm 1.5048 (1.5615)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:45:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:32 lr 0.000006	 wd 0.0000	time 0.1876 (0.2303)	loss 0.8223 (0.7791)	grad_norm 1.2738 (1.5620)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:45:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:09 lr 0.000006	 wd 0.0000	time 0.1918 (0.2286)	loss 0.6729 (0.7784)	grad_norm 2.0741 (1.5594)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:45:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:45 lr 0.000005	 wd 0.0000	time 0.2111 (0.2272)	loss 0.7700 (0.7783)	grad_norm 1.4498 (1.5612)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:46:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:23 lr 0.000005	 wd 0.0000	time 0.1926 (0.2274)	loss 0.7798 (0.7782)	grad_norm 1.4605 (1.5613)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:46:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000005	 wd 0.0000	time 0.1715 (0.2258)	loss 0.7100 (0.7780)	grad_norm 1.8459 (1.5615)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:46:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 25 training takes 0:09:35
[2024-07-27 21:46:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 21.221 (21.221)	Loss 0.3738 (0.3738)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 21:47:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.442 Acc@5 97.532
[2024-07-27 21:47:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 21:47:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 21:47:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][0/2502]	eta 23:32:28 lr 0.000005	 wd 0.0000	time 33.8723 (33.8723)	loss 0.7671 (0.7671)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:48:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:21:13 lr 0.000005	 wd 0.0000	time 0.1929 (0.5303)	loss 0.9028 (0.7836)	grad_norm 1.2080 (1.5672)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:48:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:13:44 lr 0.000005	 wd 0.0000	time 0.1793 (0.3584)	loss 0.7959 (0.7829)	grad_norm 1.9002 (1.5593)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:48:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:11:02 lr 0.000005	 wd 0.0000	time 0.1965 (0.3007)	loss 0.7266 (0.7833)	grad_norm 1.5832 (1.5429)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:49:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:09:54 lr 0.000005	 wd 0.0000	time 0.2971 (0.2829)	loss 0.8140 (0.7817)	grad_norm 1.3763 (1.5436)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:49:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:09:39 lr 0.000005	 wd 0.0000	time 0.1951 (0.2896)	loss 0.8804 (0.7830)	grad_norm 1.5009 (1.5476)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:50:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:08:38 lr 0.000005	 wd 0.0000	time 0.2048 (0.2728)	loss 0.7554 (0.7828)	grad_norm 1.6195 (1.5443)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:50:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:49 lr 0.000005	 wd 0.0000	time 0.1863 (0.2604)	loss 0.9253 (0.7820)	grad_norm 1.2451 (1.5415)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:50:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:07:10 lr 0.000005	 wd 0.0000	time 0.2734 (0.2530)	loss 0.7563 (0.7817)	grad_norm 1.3975 (1.5431)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:51:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:07:01 lr 0.000005	 wd 0.0000	time 0.1821 (0.2630)	loss 0.8198 (0.7812)	grad_norm 1.4394 (1.5430)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:51:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:23 lr 0.000004	 wd 0.0000	time 0.1811 (0.2556)	loss 0.8994 (0.7813)	grad_norm 1.1485 (1.5443)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:51:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:49 lr 0.000004	 wd 0.0000	time 0.1983 (0.2494)	loss 0.8193 (0.7810)	grad_norm 1.4673 (1.5399)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:52:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:18 lr 0.000004	 wd 0.0000	time 0.1867 (0.2444)	loss 0.7241 (0.7817)	grad_norm 1.4749 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7891MB
[2024-07-27 21:52:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:04:52 lr 0.000004	 wd 0.0000	time 0.1751 (0.2437)	loss 0.7246 (0.7816)	grad_norm 1.7059 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7891MB
[2024-07-27 21:52:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:24 lr 0.000004	 wd 0.0000	time 0.1866 (0.2400)	loss 0.8516 (0.7819)	grad_norm 2.0081 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7891MB
[2024-07-27 21:53:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:03:57 lr 0.000004	 wd 0.0000	time 0.1786 (0.2369)	loss 0.7144 (0.7823)	grad_norm 1.5396 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7891MB
[2024-07-27 21:53:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:30 lr 0.000004	 wd 0.0000	time 0.1966 (0.2339)	loss 0.7271 (0.7814)	grad_norm 1.4610 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7891MB
[2024-07-27 21:53:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:05 lr 0.000004	 wd 0.0000	time 0.2459 (0.2317)	loss 0.7012 (0.7808)	grad_norm 1.7581 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7891MB
[2024-07-27 21:54:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:43 lr 0.000004	 wd 0.0000	time 0.1949 (0.2324)	loss 0.7637 (0.7808)	grad_norm 1.3691 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7891MB
[2024-07-27 21:54:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:18 lr 0.000004	 wd 0.0000	time 0.1998 (0.2307)	loss 0.6924 (0.7811)	grad_norm 1.5688 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7891MB
[2024-07-27 21:54:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:01:54 lr 0.000004	 wd 0.0000	time 0.1894 (0.2288)	loss 0.7998 (0.7812)	grad_norm 1.2058 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7891MB
[2024-07-27 21:55:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:31 lr 0.000004	 wd 0.0000	time 0.1902 (0.2270)	loss 0.8101 (0.7813)	grad_norm 1.4311 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7891MB
[2024-07-27 21:55:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:08 lr 0.000004	 wd 0.0000	time 0.2237 (0.2262)	loss 0.8042 (0.7813)	grad_norm 1.5064 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7891MB
[2024-07-27 21:55:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:45 lr 0.000004	 wd 0.0000	time 0.1859 (0.2264)	loss 0.7275 (0.7818)	grad_norm 1.5352 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7891MB
[2024-07-27 21:56:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:22 lr 0.000003	 wd 0.0000	time 0.1718 (0.2250)	loss 0.8071 (0.7820)	grad_norm 1.9377 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7891MB
[2024-07-27 21:56:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1711 (0.2232)	loss 0.7100 (0.7828)	grad_norm 1.8411 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7891MB
[2024-07-27 21:56:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 26 training takes 0:09:27
[2024-07-27 21:57:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 45.098 (45.098)	Loss 0.3745 (0.3745)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 21:57:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.436 Acc@5 97.526
[2024-07-27 21:57:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 21:57:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 21:58:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][0/2502]	eta 11:06:51 lr 0.000003	 wd 0.0000	time 15.9920 (15.9920)	loss 0.7041 (0.7041)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:58:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:14:01 lr 0.000003	 wd 0.0000	time 0.1938 (0.3504)	loss 0.8062 (0.7882)	grad_norm 1.9523 (1.5845)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:58:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:10:56 lr 0.000003	 wd 0.0000	time 0.3259 (0.2851)	loss 0.7974 (0.7883)	grad_norm 1.4742 (1.6096)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:59:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:11:25 lr 0.000003	 wd 0.0000	time 0.1969 (0.3115)	loss 0.8032 (0.7853)	grad_norm 1.4025 (1.6260)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:59:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:09:51 lr 0.000003	 wd 0.0000	time 0.2036 (0.2813)	loss 0.8105 (0.7860)	grad_norm 1.3232 (1.6243)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 21:59:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:08:44 lr 0.000003	 wd 0.0000	time 0.1846 (0.2621)	loss 0.7192 (0.7840)	grad_norm 1.4284 (1.6034)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:00:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:07:59 lr 0.000003	 wd 0.0000	time 0.2109 (0.2519)	loss 0.7329 (0.7870)	grad_norm 1.5947 (1.5963)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:00:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:08:09 lr 0.000003	 wd 0.0000	time 0.1648 (0.2716)	loss 0.8052 (0.7890)	grad_norm 1.7336 (1.5862)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:01:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:24 lr 0.000003	 wd 0.0000	time 0.1936 (0.2611)	loss 0.8418 (0.7876)	grad_norm 1.3756 (1.5857)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:01:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:45 lr 0.000003	 wd 0.0000	time 0.1735 (0.2529)	loss 0.7573 (0.7897)	grad_norm 1.5574 (1.5816)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:01:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:11 lr 0.000003	 wd 0.0000	time 0.2828 (0.2475)	loss 0.9160 (0.7890)	grad_norm 1.7266 (1.5842)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:02:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:06:00 lr 0.000003	 wd 0.0000	time 0.1846 (0.2568)	loss 0.7061 (0.7894)	grad_norm 2.2251 (1.5847)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:02:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:26 lr 0.000003	 wd 0.0000	time 0.1836 (0.2511)	loss 0.7368 (0.7890)	grad_norm 1.4884 (1.5860)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:03:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:55 lr 0.000003	 wd 0.0000	time 0.1782 (0.2461)	loss 0.8262 (0.7889)	grad_norm 1.4435 (1.5847)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:03:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:26 lr 0.000003	 wd 0.0000	time 0.1873 (0.2418)	loss 0.7183 (0.7890)	grad_norm 1.5038 (1.5792)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:03:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:04:01 lr 0.000003	 wd 0.0000	time 0.1718 (0.2412)	loss 0.7949 (0.7894)	grad_norm 1.8375 (1.5763)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:04:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:34 lr 0.000003	 wd 0.0000	time 0.1785 (0.2383)	loss 0.7305 (0.7898)	grad_norm 1.5839 (1.5737)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:04:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:08 lr 0.000002	 wd 0.0000	time 0.2122 (0.2355)	loss 0.8735 (0.7895)	grad_norm 1.1387 (1.5710)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:04:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:43 lr 0.000002	 wd 0.0000	time 0.1741 (0.2330)	loss 0.7412 (0.7896)	grad_norm 1.4288 (1.5685)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:05:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:19 lr 0.000002	 wd 0.0000	time 0.1877 (0.2310)	loss 0.8560 (0.7894)	grad_norm 1.6165 (1.5685)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:05:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:56 lr 0.000002	 wd 0.0000	time 0.1743 (0.2323)	loss 0.6934 (0.7892)	grad_norm 1.5630 (1.5686)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:05:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:32 lr 0.000002	 wd 0.0000	time 0.1739 (0.2307)	loss 0.9536 (0.7903)	grad_norm 1.4464 (1.5686)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:06:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:09 lr 0.000002	 wd 0.0000	time 0.1840 (0.2290)	loss 0.7124 (0.7903)	grad_norm 1.2749 (1.5690)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:06:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:45 lr 0.000002	 wd 0.0000	time 0.1791 (0.2273)	loss 0.8247 (0.7906)	grad_norm 1.4598 (1.5700)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:06:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:23 lr 0.000002	 wd 0.0000	time 0.2399 (0.2263)	loss 0.8447 (0.7906)	grad_norm 1.3172 (1.5706)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:07:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1704 (0.2247)	loss 0.7363 (0.7908)	grad_norm 1.7302 (1.5731)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:07:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 27 training takes 0:09:36
[2024-07-27 22:07:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 18.787 (18.787)	Loss 0.3733 (0.3733)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 22:08:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.448 Acc@5 97.522
[2024-07-27 22:08:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 22:08:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 22:08:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][0/2502]	eta 1 day, 1:02:49 lr 0.000002	 wd 0.0000	time 36.0391 (36.0391)	loss 0.7808 (0.7808)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:09:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:24:27 lr 0.000002	 wd 0.0000	time 0.1861 (0.6110)	loss 0.8091 (0.8012)	grad_norm 1.2787 (1.5108)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:09:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:15:19 lr 0.000002	 wd 0.0000	time 0.1802 (0.3996)	loss 0.8623 (0.7959)	grad_norm 1.4695 (nan)	loss_scale 32768.0000 (33094.0498)	mem 7891MB
[2024-07-27 22:09:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:12:02 lr 0.000002	 wd 0.0000	time 0.1890 (0.3283)	loss 0.8320 (0.7960)	grad_norm 1.2615 (nan)	loss_scale 32768.0000 (32985.7276)	mem 7891MB
[2024-07-27 22:10:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:10:29 lr 0.000002	 wd 0.0000	time 0.3206 (0.2996)	loss 0.6826 (0.7939)	grad_norm 1.2825 (nan)	loss_scale 32768.0000 (32931.4314)	mem 7891MB
[2024-07-27 22:10:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:10:15 lr 0.000002	 wd 0.0000	time 0.1940 (0.3075)	loss 0.9106 (0.7941)	grad_norm 1.2617 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7891MB
[2024-07-27 22:10:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:09:07 lr 0.000002	 wd 0.0000	time 0.1984 (0.2877)	loss 0.7930 (0.7929)	grad_norm 1.8130 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7891MB
[2024-07-27 22:11:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:08:12 lr 0.000002	 wd 0.0000	time 0.1759 (0.2733)	loss 0.7666 (0.7914)	grad_norm 1.7923 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7891MB
[2024-07-27 22:11:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:28 lr 0.000002	 wd 0.0000	time 0.2137 (0.2632)	loss 0.7856 (0.7905)	grad_norm 1.6782 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7891MB
[2024-07-27 22:12:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:07:12 lr 0.000002	 wd 0.0000	time 0.1981 (0.2703)	loss 0.8418 (0.7892)	grad_norm 2.1340 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7891MB
[2024-07-27 22:12:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:33 lr 0.000002	 wd 0.0000	time 0.1640 (0.2620)	loss 0.8691 (0.7887)	grad_norm 1.5869 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7891MB
[2024-07-27 22:12:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:57 lr 0.000002	 wd 0.0000	time 0.2000 (0.2552)	loss 0.7573 (0.7884)	grad_norm 1.7295 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7891MB
[2024-07-27 22:13:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:24 lr 0.000002	 wd 0.0000	time 0.2197 (0.2494)	loss 0.8779 (0.7875)	grad_norm 1.6837 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7891MB
[2024-07-27 22:13:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:05:09 lr 0.000002	 wd 0.0000	time 0.1981 (0.2578)	loss 0.7305 (0.7873)	grad_norm 1.8634 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7891MB
[2024-07-27 22:13:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:39 lr 0.000002	 wd 0.0000	time 0.2066 (0.2534)	loss 0.7397 (0.7873)	grad_norm 1.4941 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7891MB
[2024-07-27 22:14:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:04:09 lr 0.000002	 wd 0.0000	time 0.1836 (0.2490)	loss 0.7568 (0.7873)	grad_norm 1.2971 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7891MB
[2024-07-27 22:14:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:41 lr 0.000002	 wd 0.0000	time 0.1972 (0.2450)	loss 0.6865 (0.7877)	grad_norm 1.3098 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7891MB
[2024-07-27 22:14:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:14 lr 0.000001	 wd 0.0000	time 0.1853 (0.2428)	loss 0.6963 (0.7880)	grad_norm 1.5008 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7891MB
[2024-07-27 22:15:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:49 lr 0.000001	 wd 0.0000	time 0.2276 (0.2418)	loss 0.6904 (0.7882)	grad_norm 1.7622 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7891MB
[2024-07-27 22:15:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:24 lr 0.000001	 wd 0.0000	time 0.1940 (0.2394)	loss 0.8330 (0.7885)	grad_norm 1.4259 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7891MB
[2024-07-27 22:15:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:01:58 lr 0.000001	 wd 0.0000	time 0.1794 (0.2371)	loss 0.7676 (0.7884)	grad_norm 1.4966 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7891MB
[2024-07-27 22:16:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:34 lr 0.000001	 wd 0.0000	time 0.1867 (0.2348)	loss 0.8682 (0.7889)	grad_norm 1.4864 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7891MB
[2024-07-27 22:16:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:10 lr 0.000001	 wd 0.0000	time 0.1849 (0.2335)	loss 0.8506 (0.7888)	grad_norm 1.6288 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7891MB
[2024-07-27 22:16:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:47 lr 0.000001	 wd 0.0000	time 0.1808 (0.2335)	loss 0.7671 (0.7892)	grad_norm 1.6111 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7891MB
[2024-07-27 22:17:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:23 lr 0.000001	 wd 0.0000	time 0.1741 (0.2318)	loss 0.8311 (0.7895)	grad_norm 2.0968 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7891MB
[2024-07-27 22:17:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1671 (0.2298)	loss 0.7437 (0.7899)	grad_norm 1.4368 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7891MB
[2024-07-27 22:17:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 28 training takes 0:09:44
[2024-07-27 22:18:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 38.602 (38.602)	Loss 0.3735 (0.3735)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 22:18:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.430 Acc@5 97.512
[2024-07-27 22:18:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 22:18:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 22:18:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][0/2502]	eta 10:26:02 lr 0.000001	 wd 0.0000	time 15.0130 (15.0130)	loss 0.7729 (0.7729)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:19:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:13:48 lr 0.000001	 wd 0.0000	time 0.1759 (0.3449)	loss 0.8872 (0.7911)	grad_norm 1.3229 (1.5544)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:19:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:10:30 lr 0.000001	 wd 0.0000	time 0.2747 (0.2741)	loss 0.7368 (0.7969)	grad_norm 1.2937 (1.5148)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:20:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:10:56 lr 0.000001	 wd 0.0000	time 0.1905 (0.2982)	loss 0.7393 (0.7934)	grad_norm 1.7055 (1.5381)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:20:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:09:29 lr 0.000001	 wd 0.0000	time 0.1800 (0.2707)	loss 0.7139 (0.7941)	grad_norm 1.4725 (1.5338)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:20:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:08:28 lr 0.000001	 wd 0.0000	time 0.1841 (0.2539)	loss 0.7466 (0.7934)	grad_norm 1.3646 (1.5362)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:21:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:07:42 lr 0.000001	 wd 0.0000	time 0.1958 (0.2432)	loss 0.7554 (0.7910)	grad_norm 1.4528 (1.5328)	loss_scale 32768.0000 (32768.0000)	mem 7891MB
[2024-07-27 22:21:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:57 lr 0.000001	 wd 0.0000	time 0.1876 (0.2648)	loss 0.8677 (0.7894)	grad_norm 1.4316 (inf)	loss_scale 16384.0000 (31833.1070)	mem 7891MB
[2024-07-27 22:22:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:07:14 lr 0.000001	 wd 0.0000	time 0.1804 (0.2552)	loss 0.6860 (0.7911)	grad_norm 1.7006 (inf)	loss_scale 16384.0000 (29904.3795)	mem 7891MB
[2024-07-27 22:22:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:06:36 lr 0.000001	 wd 0.0000	time 0.1873 (0.2476)	loss 0.8242 (0.7906)	grad_norm 1.3125 (inf)	loss_scale 16384.0000 (28403.7825)	mem 7891MB
[2024-07-27 22:22:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:03 lr 0.000001	 wd 0.0000	time 0.2237 (0.2418)	loss 0.7012 (0.7900)	grad_norm 1.3967 (inf)	loss_scale 16384.0000 (27203.0050)	mem 7891MB
[2024-07-27 22:23:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:47 lr 0.000001	 wd 0.0000	time 0.2079 (0.2480)	loss 0.7954 (0.7906)	grad_norm 1.5736 (inf)	loss_scale 16384.0000 (26220.3524)	mem 7891MB
[2024-07-27 22:23:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:16 lr 0.000001	 wd 0.0000	time 0.1855 (0.2430)	loss 0.8027 (0.7897)	grad_norm 1.4834 (inf)	loss_scale 16384.0000 (25401.3389)	mem 7891MB
[2024-07-27 22:23:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:04:46 lr 0.000001	 wd 0.0000	time 0.1791 (0.2387)	loss 0.6895 (0.7907)	grad_norm 1.3888 (inf)	loss_scale 16384.0000 (24708.2306)	mem 7891MB
[2024-07-27 22:24:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:18 lr 0.000001	 wd 0.0000	time 0.1864 (0.2349)	loss 0.8677 (0.7912)	grad_norm 1.5446 (inf)	loss_scale 16384.0000 (24114.0671)	mem 7891MB
[2024-07-27 22:24:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:03:53 lr 0.000001	 wd 0.0000	time 0.2273 (0.2334)	loss 0.7222 (0.7911)	grad_norm 1.5596 (inf)	loss_scale 16384.0000 (23599.0726)	mem 7891MB
[2024-07-27 22:24:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:30 lr 0.000001	 wd 0.0000	time 0.2477 (0.2330)	loss 0.8047 (0.7908)	grad_norm 1.3475 (inf)	loss_scale 16384.0000 (23148.4122)	mem 7891MB
[2024-07-27 22:25:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:04 lr 0.000001	 wd 0.0000	time 0.1732 (0.2307)	loss 0.9663 (0.7914)	grad_norm 1.5845 (inf)	loss_scale 16384.0000 (22750.7396)	mem 7891MB
[2024-07-27 22:25:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:40 lr 0.000001	 wd 0.0000	time 0.1759 (0.2284)	loss 0.6572 (0.7917)	grad_norm 1.8406 (inf)	loss_scale 16384.0000 (22397.2282)	mem 7891MB
[2024-07-27 22:25:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:16 lr 0.000001	 wd 0.0000	time 0.2013 (0.2265)	loss 0.7500 (0.7922)	grad_norm 1.3500 (inf)	loss_scale 16384.0000 (22080.9090)	mem 7891MB
[2024-07-27 22:26:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:01:53 lr 0.000001	 wd 0.0000	time 0.2109 (0.2256)	loss 0.8413 (0.7923)	grad_norm 1.5456 (inf)	loss_scale 16384.0000 (21796.2059)	mem 7891MB
[2024-07-27 22:26:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:30 lr 0.000001	 wd 0.0000	time 0.2093 (0.2258)	loss 0.8076 (0.7922)	grad_norm 1.7502 (inf)	loss_scale 16384.0000 (21538.6045)	mem 7891MB
[2024-07-27 22:26:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:07 lr 0.000001	 wd 0.0000	time 0.1900 (0.2244)	loss 0.9263 (0.7919)	grad_norm 1.1403 (inf)	loss_scale 16384.0000 (21304.4107)	mem 7891MB
[2024-07-27 22:27:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:45 lr 0.000001	 wd 0.0000	time 0.2419 (0.2230)	loss 0.8008 (0.7916)	grad_norm 1.8310 (inf)	loss_scale 16384.0000 (21090.5728)	mem 7891MB
[2024-07-27 22:27:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:22 lr 0.000001	 wd 0.0000	time 0.1923 (0.2217)	loss 0.7700 (0.7918)	grad_norm 1.4471 (inf)	loss_scale 16384.0000 (20894.5473)	mem 7891MB
[2024-07-27 22:27:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1683 (0.2202)	loss 0.9658 (0.7917)	grad_norm 1.2538 (inf)	loss_scale 16384.0000 (20714.1975)	mem 7891MB
[2024-07-27 22:28:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 29 training takes 0:09:24
[2024-07-27 22:28:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_conv_b_step_stage3/ckpt_epoch_29.pth saving......
[2024-07-27 22:28:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_conv_b_step_stage3/ckpt_epoch_29.pth saved !!!
[2024-07-27 22:28:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 25.516 (25.516)	Loss 0.3728 (0.3728)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 7891MB
[2024-07-27 22:28:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.446 Acc@5 97.512
[2024-07-27 22:28:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-27 22:28:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.52%
[2024-07-27 22:28:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 189): INFO Training time 5:11:23
