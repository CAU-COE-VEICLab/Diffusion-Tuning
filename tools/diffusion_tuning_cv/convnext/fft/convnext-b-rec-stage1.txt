[2024-07-26 09:41:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 366): INFO Full config saved to pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/config.json
[2024-07-26 09:41:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: convnext_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 27
    - 3
    DIMS:
    - 128
    - 256
    - 512
    - 1024
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: stage1
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_conv_b_step_stage1
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 0.0001
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 0.8
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.0e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 1.0e-08

[2024-07-26 09:41:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/diffusion_finetune/convnext/convnext/diffusion_ft_convnext_base_224_22kto1k_step_stage_process1.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/diffusion-ft", "tag": "diffusion_ft_conv_b_step_stage1", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-26 09:41:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 108): INFO Creating model:convnext_diffusion_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1
[2024-07-26 09:41:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 110): INFO ConvNeXt_Diffusion_Finetune(
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (3): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (4): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (5): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (6): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (7): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (8): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (9): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (10): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (11): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (12): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (13): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (14): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (15): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (16): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (17): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (18): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (19): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (20): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (21): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (22): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (23): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (24): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (25): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (26): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-26 09:41:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 113): INFO number of params: 3176296
[2024-07-26 09:41:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 150): INFO no checkpoint found in pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1, ignoring auto resume
[2024-07-26 09:41:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth for fine-tuning......
[2024-07-26 09:41:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 127): WARNING <All keys matched successfully>
[2024-07-26 09:41:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth'
[2024-07-26 09:42:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 62.392 (62.392)	Loss 0.3643 (0.3643)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 3046MB
[2024-07-26 09:43:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.866 Acc@5 97.508
[2024-07-26 09:43:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 162): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-26 09:43:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 168): INFO Start training
[2024-07-26 09:43:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][0/2502]	eta 19:54:09 lr 0.000100	 wd 0.0000	time 28.6371 (28.6371)	loss 0.8501 (0.8501)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 8211MB
[2024-07-26 09:43:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:19:03 lr 0.000100	 wd 0.0000	time 0.1849 (0.4759)	loss 0.9331 (0.8867)	grad_norm 1.8739 (nan)	loss_scale 32768.0000 (33092.4356)	mem 8211MB
[2024-07-26 09:44:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:12:29 lr 0.000100	 wd 0.0000	time 0.1993 (0.3258)	loss 0.9277 (0.8975)	grad_norm 1.5474 (nan)	loss_scale 32768.0000 (32931.0249)	mem 8211MB
[2024-07-26 09:44:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:52 lr 0.000100	 wd 0.0000	time 0.1727 (0.3506)	loss 0.8760 (0.9022)	grad_norm 1.3784 (nan)	loss_scale 32768.0000 (32876.8638)	mem 8211MB
[2024-07-26 09:45:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:11:08 lr 0.000100	 wd 0.0000	time 0.1848 (0.3178)	loss 1.1973 (0.9048)	grad_norm inf (nan)	loss_scale 16384.0000 (32768.0000)	mem 8211MB
[2024-07-26 09:45:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:09:40 lr 0.000100	 wd 0.0000	time 0.1564 (0.2902)	loss 0.7744 (0.9050)	grad_norm 3.4967 (nan)	loss_scale 16384.0000 (29497.7405)	mem 8211MB
[2024-07-26 09:45:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:08:35 lr 0.000100	 wd 0.0000	time 0.1665 (0.2711)	loss 0.8594 (0.9046)	grad_norm 1.2618 (nan)	loss_scale 16384.0000 (27315.7537)	mem 8211MB
[2024-07-26 09:46:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:32 lr 0.000100	 wd 0.0000	time 1.0440 (0.2845)	loss 0.9653 (0.9051)	grad_norm 3.2872 (nan)	loss_scale 16384.0000 (25756.3024)	mem 8211MB
[2024-07-26 09:46:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:08:07 lr 0.000100	 wd 0.0000	time 0.1652 (0.2863)	loss 0.9272 (0.9044)	grad_norm 2.3947 (nan)	loss_scale 16384.0000 (24586.2272)	mem 8211MB
[2024-07-26 09:47:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:19 lr 0.000100	 wd 0.0000	time 0.1833 (0.2741)	loss 0.9385 (0.9035)	grad_norm 2.0819 (nan)	loss_scale 16384.0000 (23675.8801)	mem 8211MB
[2024-07-26 09:47:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:06:37 lr 0.000100	 wd 0.0000	time 0.1672 (0.2648)	loss 0.9810 (0.9036)	grad_norm 3.0575 (nan)	loss_scale 16384.0000 (22947.4206)	mem 8211MB
[2024-07-26 09:48:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:15 lr 0.000100	 wd 0.0000	time 0.2248 (0.2681)	loss 0.8154 (0.9034)	grad_norm 2.1550 (nan)	loss_scale 16384.0000 (22351.2879)	mem 8211MB
[2024-07-26 09:48:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:39 lr 0.000100	 wd 0.0000	time 0.1698 (0.2611)	loss 0.8730 (0.9037)	grad_norm 1.8876 (nan)	loss_scale 16384.0000 (21854.4280)	mem 8211MB
[2024-07-26 09:48:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:05 lr 0.000100	 wd 0.0000	time 0.1652 (0.2545)	loss 0.7568 (0.9046)	grad_norm 1.5374 (nan)	loss_scale 16384.0000 (21433.9493)	mem 8211MB
[2024-07-26 09:48:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:34 lr 0.000100	 wd 0.0000	time 0.1689 (0.2491)	loss 0.9336 (0.9044)	grad_norm 2.5898 (nan)	loss_scale 16384.0000 (21073.4961)	mem 8211MB
[2024-07-26 09:49:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:05 lr 0.000100	 wd 0.0000	time 0.1705 (0.2448)	loss 0.9712 (0.9046)	grad_norm 2.1181 (nan)	loss_scale 16384.0000 (20761.0713)	mem 8211MB
[2024-07-26 09:49:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:44 lr 0.000100	 wd 0.0000	time 0.1566 (0.2485)	loss 1.0156 (0.9040)	grad_norm 1.9549 (nan)	loss_scale 16384.0000 (20487.6752)	mem 8211MB
[2024-07-26 09:50:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:15 lr 0.000100	 wd 0.0000	time 0.1819 (0.2443)	loss 0.7827 (0.9039)	grad_norm 1.8842 (nan)	loss_scale 16384.0000 (20246.4245)	mem 8211MB
[2024-07-26 09:50:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:02:48 lr 0.000100	 wd 0.0000	time 0.1865 (0.2407)	loss 0.8765 (0.9035)	grad_norm 1.7657 (nan)	loss_scale 16384.0000 (20031.9645)	mem 8211MB
[2024-07-26 09:50:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:23 lr 0.000100	 wd 0.0000	time 0.1653 (0.2377)	loss 0.8799 (0.9033)	grad_norm 1.5259 (nan)	loss_scale 16384.0000 (19840.0673)	mem 8211MB
[2024-07-26 09:51:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:01:59 lr 0.000100	 wd 0.0000	time 0.4436 (0.2377)	loss 0.9419 (0.9039)	grad_norm 2.0086 (nan)	loss_scale 16384.0000 (19667.3503)	mem 8211MB
[2024-07-26 09:51:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:36 lr 0.000100	 wd 0.0000	time 0.1658 (0.2405)	loss 0.8555 (0.9043)	grad_norm 2.1566 (nan)	loss_scale 16384.0000 (19511.0747)	mem 8211MB
[2024-07-26 09:51:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:11 lr 0.000100	 wd 0.0000	time 0.1734 (0.2376)	loss 0.9482 (0.9041)	grad_norm 1.4688 (nan)	loss_scale 16384.0000 (19368.9995)	mem 8211MB
[2024-07-26 09:52:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:47 lr 0.000100	 wd 0.0000	time 0.1722 (0.2352)	loss 1.0020 (0.9038)	grad_norm 1.4406 (nan)	loss_scale 16384.0000 (19239.2734)	mem 8211MB
[2024-07-26 09:52:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:23 lr 0.000100	 wd 0.0000	time 0.1961 (0.2333)	loss 0.8418 (0.9038)	grad_norm 2.1699 (nan)	loss_scale 16384.0000 (19120.3532)	mem 8211MB
[2024-07-26 09:52:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000100	 wd 0.0000	time 0.1597 (0.2314)	loss 1.0195 (0.9035)	grad_norm 1.8643 (nan)	loss_scale 16384.0000 (19010.9428)	mem 8211MB
[2024-07-26 09:52:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 0 training takes 0:09:48
[2024-07-26 09:52:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_0.pth saving......
[2024-07-26 09:52:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_0.pth saved !!!
[2024-07-26 09:53:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 51.571 (51.571)	Loss 0.3682 (0.3682)	Acc@1 91.211 (91.211)	Acc@5 98.828 (98.828)	Mem 8211MB
[2024-07-26 09:53:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.780 Acc@5 97.482
[2024-07-26 09:53:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-26 09:53:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.78%
[2024-07-26 09:53:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saving......
[2024-07-26 09:53:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-26 09:54:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][0/2502]	eta 1 day, 4:33:21 lr 0.000100	 wd 0.0000	time 41.0877 (41.0877)	loss 0.8892 (0.8892)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 09:54:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:23:33 lr 0.000100	 wd 0.0000	time 0.1646 (0.5885)	loss 0.8022 (0.8986)	grad_norm 1.3997 (1.9375)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 09:55:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:14:41 lr 0.000100	 wd 0.0000	time 0.1840 (0.3829)	loss 1.0176 (0.9040)	grad_norm 1.9154 (1.8689)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 09:55:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:32 lr 0.000100	 wd 0.0000	time 0.1884 (0.3145)	loss 0.9902 (0.9006)	grad_norm 2.4459 (1.9021)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 09:56:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:12:08 lr 0.000100	 wd 0.0000	time 0.1890 (0.3468)	loss 0.7739 (0.9026)	grad_norm 2.1092 (1.8650)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 09:56:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:10:28 lr 0.000100	 wd 0.0000	time 0.1666 (0.3138)	loss 0.9243 (0.9001)	grad_norm 1.4541 (1.8536)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 09:56:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:09:13 lr 0.000100	 wd 0.0000	time 0.1593 (0.2908)	loss 1.0000 (0.9017)	grad_norm 1.3851 (1.8822)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 09:57:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:14 lr 0.000100	 wd 0.0000	time 0.1657 (0.2745)	loss 0.8228 (0.9012)	grad_norm 1.8009 (1.8687)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 09:57:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:08:04 lr 0.000100	 wd 0.0000	time 0.3359 (0.2848)	loss 0.8193 (0.9023)	grad_norm 1.4424 (1.8720)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 09:58:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:20 lr 0.000099	 wd 0.0000	time 0.1557 (0.2748)	loss 0.9404 (0.9021)	grad_norm 2.6034 (1.8751)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 09:58:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:38 lr 0.000099	 wd 0.0000	time 0.1670 (0.2651)	loss 0.9106 (0.9014)	grad_norm 1.6773 (1.8758)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 09:58:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:06:00 lr 0.000099	 wd 0.0000	time 0.1892 (0.2568)	loss 1.0576 (0.9016)	grad_norm 1.6815 (1.8776)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 09:59:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:31 lr 0.000099	 wd 0.0000	time 0.3616 (0.2547)	loss 0.9312 (0.9015)	grad_norm 2.0525 (1.8818)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 09:59:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:13 lr 0.000099	 wd 0.0000	time 0.1664 (0.2604)	loss 0.9980 (0.9022)	grad_norm 1.4454 (1.8812)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 09:59:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:40 lr 0.000099	 wd 0.0000	time 0.1594 (0.2544)	loss 0.8833 (0.9024)	grad_norm 1.6589 (1.8775)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:00:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:09 lr 0.000099	 wd 0.0000	time 0.1726 (0.2492)	loss 0.9521 (0.9026)	grad_norm 1.3886 (1.8709)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:00:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:44 lr 0.000099	 wd 0.0000	time 0.4299 (0.2487)	loss 0.9805 (0.9032)	grad_norm 1.7099 (1.8665)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:01:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:26 lr 0.000099	 wd 0.0000	time 0.1951 (0.2571)	loss 0.7764 (0.9031)	grad_norm 1.6333 (1.8686)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:01:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:57 lr 0.000099	 wd 0.0000	time 0.1819 (0.2526)	loss 1.0801 (0.9034)	grad_norm 1.5077 (1.8668)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:01:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:29 lr 0.000099	 wd 0.0000	time 0.1597 (0.2484)	loss 0.8960 (0.9040)	grad_norm 1.6436 (1.8693)	loss_scale 32768.0000 (16418.4745)	mem 8211MB
[2024-07-26 10:02:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:03 lr 0.000099	 wd 0.0000	time 0.1621 (0.2456)	loss 0.7979 (0.9037)	grad_norm 1.5198 (1.8686)	loss_scale 32768.0000 (17235.5422)	mem 8211MB
[2024-07-26 10:02:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:38 lr 0.000099	 wd 0.0000	time 0.1625 (0.2446)	loss 0.8501 (0.9039)	grad_norm 1.7645 (1.8686)	loss_scale 32768.0000 (17974.8310)	mem 8211MB
[2024-07-26 10:02:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:13 lr 0.000099	 wd 0.0000	time 0.1912 (0.2424)	loss 0.7256 (0.9038)	grad_norm 2.0358 (1.8671)	loss_scale 32768.0000 (18646.9423)	mem 8211MB
[2024-07-26 10:03:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:48 lr 0.000099	 wd 0.0000	time 0.1661 (0.2398)	loss 1.1172 (0.9044)	grad_norm 2.0095 (1.8700)	loss_scale 32768.0000 (19260.6345)	mem 8211MB
[2024-07-26 10:03:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:24 lr 0.000099	 wd 0.0000	time 0.1725 (0.2372)	loss 0.9355 (0.9041)	grad_norm 1.3998 (inf)	loss_scale 16384.0000 (19563.9017)	mem 8211MB
[2024-07-26 10:03:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000099	 wd 0.0000	time 0.1592 (0.2347)	loss 1.0801 (0.9044)	grad_norm 2.1046 (inf)	loss_scale 16384.0000 (19436.7565)	mem 8211MB
[2024-07-26 10:03:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 1 training takes 0:09:51
[2024-07-26 10:04:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 42.819 (42.819)	Loss 0.3691 (0.3691)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 8211MB
[2024-07-26 10:04:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.872 Acc@5 97.482
[2024-07-26 10:04:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-26 10:04:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.87%
[2024-07-26 10:04:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saving......
[2024-07-26 10:04:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-26 10:05:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][0/2502]	eta 11:36:18 lr 0.000099	 wd 0.0000	time 16.6982 (16.6982)	loss 0.8198 (0.8198)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:05:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:15:02 lr 0.000099	 wd 0.0000	time 0.3337 (0.3759)	loss 0.9355 (0.9066)	grad_norm 2.0506 (2.0013)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:05:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:13:09 lr 0.000099	 wd 0.0000	time 0.1856 (0.3430)	loss 0.9121 (0.8981)	grad_norm 1.5569 (1.9431)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:06:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:10:31 lr 0.000099	 wd 0.0000	time 0.1701 (0.2869)	loss 0.9614 (0.8984)	grad_norm 1.7643 (1.9078)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:06:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:09:04 lr 0.000099	 wd 0.0000	time 0.1638 (0.2590)	loss 0.8105 (0.8975)	grad_norm 1.7179 (1.9148)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:06:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:08:04 lr 0.000099	 wd 0.0000	time 0.1612 (0.2418)	loss 1.0830 (0.8964)	grad_norm 1.9747 (1.9253)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:07:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:39 lr 0.000099	 wd 0.0000	time 0.1929 (0.2730)	loss 0.9565 (0.8973)	grad_norm 2.3881 (1.9053)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:07:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:07:50 lr 0.000099	 wd 0.0000	time 0.1576 (0.2613)	loss 0.9854 (0.8975)	grad_norm 1.6270 (1.9073)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:08:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:06 lr 0.000099	 wd 0.0000	time 0.1770 (0.2508)	loss 0.7881 (0.8964)	grad_norm 1.8518 (1.8875)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:08:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:28 lr 0.000098	 wd 0.0000	time 0.1836 (0.2426)	loss 0.8950 (0.8972)	grad_norm 1.8054 (1.8794)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:08:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:18 lr 0.000098	 wd 0.0000	time 0.1950 (0.2522)	loss 0.8301 (0.8975)	grad_norm 1.6806 (1.8897)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:09:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:46 lr 0.000098	 wd 0.0000	time 0.1547 (0.2471)	loss 0.8984 (0.8974)	grad_norm 1.4251 (1.8914)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:09:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:14 lr 0.000098	 wd 0.0000	time 0.1612 (0.2413)	loss 1.0732 (0.8967)	grad_norm 2.2242 (1.8980)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:09:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:04:43 lr 0.000098	 wd 0.0000	time 0.1622 (0.2361)	loss 0.9644 (0.8976)	grad_norm 1.4469 (1.8904)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:10:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:17 lr 0.000098	 wd 0.0000	time 0.2225 (0.2333)	loss 0.9106 (0.8979)	grad_norm 1.5112 (1.8846)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:10:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:03:53 lr 0.000098	 wd 0.0000	time 0.1818 (0.2329)	loss 0.8594 (0.8977)	grad_norm 1.4924 (1.8759)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:10:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:27 lr 0.000098	 wd 0.0000	time 0.1975 (0.2299)	loss 0.9014 (0.8978)	grad_norm 1.4095 (1.8722)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:11:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:02 lr 0.000098	 wd 0.0000	time 0.1734 (0.2270)	loss 0.9463 (0.8983)	grad_norm 1.4972 (1.8614)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:11:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:37 lr 0.000098	 wd 0.0000	time 0.1775 (0.2243)	loss 0.8252 (0.8979)	grad_norm 1.8470 (1.8576)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:11:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:14 lr 0.000098	 wd 0.0000	time 0.2466 (0.2228)	loss 0.8271 (0.8984)	grad_norm 1.6778 (1.8638)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:12:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:01:52 lr 0.000098	 wd 0.0000	time 0.2230 (0.2233)	loss 0.8779 (0.8981)	grad_norm 1.6890 (1.8579)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:12:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:29 lr 0.000098	 wd 0.0000	time 0.1801 (0.2219)	loss 0.9956 (0.8987)	grad_norm 1.7906 (1.8565)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:12:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:06 lr 0.000098	 wd 0.0000	time 0.1764 (0.2200)	loss 0.8647 (0.8984)	grad_norm 1.6925 (1.8574)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:13:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:44 lr 0.000098	 wd 0.0000	time 0.1606 (0.2182)	loss 0.9873 (0.8983)	grad_norm 2.0815 (1.8536)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:13:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:22 lr 0.000098	 wd 0.0000	time 0.1927 (0.2172)	loss 1.1172 (0.8983)	grad_norm 2.1551 (1.8504)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:13:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000098	 wd 0.0000	time 0.1597 (0.2158)	loss 0.8643 (0.8986)	grad_norm 1.6359 (1.8563)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:13:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 2 training takes 0:09:09
[2024-07-26 10:14:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 23.221 (23.221)	Loss 0.3613 (0.3613)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 10:14:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.864 Acc@5 97.494
[2024-07-26 10:14:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-26 10:14:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.87%
[2024-07-26 10:14:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][0/2502]	eta 11:24:40 lr 0.000098	 wd 0.0000	time 16.4192 (16.4192)	loss 0.7764 (0.7764)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:15:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:17:15 lr 0.000098	 wd 0.0000	time 0.5192 (0.4309)	loss 0.8638 (0.8972)	grad_norm 2.1449 (1.7818)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:15:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:14:08 lr 0.000097	 wd 0.0000	time 0.1824 (0.3685)	loss 0.9087 (0.8971)	grad_norm 1.6287 (1.8751)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:16:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:11:09 lr 0.000097	 wd 0.0000	time 0.1756 (0.3041)	loss 1.0059 (0.8989)	grad_norm 1.9332 (1.8316)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:16:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:09:31 lr 0.000097	 wd 0.0000	time 0.1605 (0.2719)	loss 0.9390 (0.8981)	grad_norm 1.7388 (1.8272)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:16:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:08:36 lr 0.000097	 wd 0.0000	time 0.2813 (0.2578)	loss 0.9038 (0.8976)	grad_norm 1.8862 (1.8028)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:17:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:08:34 lr 0.000097	 wd 0.0000	time 0.1978 (0.2704)	loss 0.8174 (0.8971)	grad_norm 2.0828 (1.8253)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:17:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:07:43 lr 0.000097	 wd 0.0000	time 0.1718 (0.2571)	loss 1.0889 (0.8976)	grad_norm 2.6340 (1.8242)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:17:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:00 lr 0.000097	 wd 0.0000	time 0.1662 (0.2471)	loss 0.9448 (0.8986)	grad_norm 1.7390 (1.8159)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:18:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:06:23 lr 0.000097	 wd 0.0000	time 0.1857 (0.2394)	loss 1.0098 (0.8991)	grad_norm 1.9628 (1.8240)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:18:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:15 lr 0.000097	 wd 0.0000	time 0.2881 (0.2502)	loss 0.9619 (0.9007)	grad_norm 1.8802 (1.8220)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:19:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:05:43 lr 0.000097	 wd 0.0000	time 0.1802 (0.2450)	loss 0.8623 (0.9018)	grad_norm 2.2760 (1.8260)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:19:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:11 lr 0.000097	 wd 0.0000	time 0.1666 (0.2392)	loss 0.9790 (0.9022)	grad_norm 2.0787 (1.8231)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:19:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:04:41 lr 0.000097	 wd 0.0000	time 0.1623 (0.2343)	loss 1.0186 (0.9027)	grad_norm 2.3323 (1.8218)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:19:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:16 lr 0.000097	 wd 0.0000	time 0.3540 (0.2327)	loss 0.8311 (0.9033)	grad_norm 2.1434 (1.8196)	loss_scale 32768.0000 (16875.1692)	mem 8211MB
[2024-07-26 10:20:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:03:58 lr 0.000097	 wd 0.0000	time 0.1598 (0.2385)	loss 0.8276 (0.9039)	grad_norm 1.7300 (inf)	loss_scale 16384.0000 (17366.3851)	mem 8211MB
[2024-07-26 10:20:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:31 lr 0.000096	 wd 0.0000	time 0.1668 (0.2346)	loss 0.8540 (0.9032)	grad_norm 1.7036 (inf)	loss_scale 16384.0000 (17305.0244)	mem 8211MB
[2024-07-26 10:21:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:05 lr 0.000096	 wd 0.0000	time 0.1742 (0.2311)	loss 0.8789 (0.9030)	grad_norm 1.4345 (inf)	loss_scale 16384.0000 (17250.8783)	mem 8211MB
[2024-07-26 10:21:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:40 lr 0.000096	 wd 0.0000	time 0.1661 (0.2286)	loss 1.0303 (0.9028)	grad_norm 1.6936 (inf)	loss_scale 16384.0000 (17202.7451)	mem 8211MB
[2024-07-26 10:21:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:17 lr 0.000096	 wd 0.0000	time 0.1720 (0.2287)	loss 0.8950 (0.9026)	grad_norm 1.7614 (inf)	loss_scale 16384.0000 (17159.6760)	mem 8211MB
[2024-07-26 10:22:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:01:53 lr 0.000096	 wd 0.0000	time 0.2059 (0.2270)	loss 0.9067 (0.9028)	grad_norm 2.0666 (inf)	loss_scale 16384.0000 (17120.9115)	mem 8211MB
[2024-07-26 10:22:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:30 lr 0.000096	 wd 0.0000	time 0.1848 (0.2249)	loss 0.8345 (0.9027)	grad_norm 1.3903 (inf)	loss_scale 16384.0000 (17085.8372)	mem 8211MB
[2024-07-26 10:22:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:07 lr 0.000096	 wd 0.0000	time 0.1764 (0.2228)	loss 0.8994 (0.9023)	grad_norm 1.6835 (inf)	loss_scale 16384.0000 (17053.9500)	mem 8211MB
[2024-07-26 10:23:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:44 lr 0.000096	 wd 0.0000	time 0.2494 (0.2212)	loss 0.9546 (0.9025)	grad_norm 1.2413 (inf)	loss_scale 16384.0000 (17024.8344)	mem 8211MB
[2024-07-26 10:23:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:22 lr 0.000096	 wd 0.0000	time 0.1729 (0.2221)	loss 0.9526 (0.9021)	grad_norm 1.3662 (inf)	loss_scale 16384.0000 (16998.1441)	mem 8211MB
[2024-07-26 10:23:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000096	 wd 0.0000	time 0.1581 (0.2200)	loss 1.0176 (0.9022)	grad_norm 1.6681 (inf)	loss_scale 16384.0000 (16973.5882)	mem 8211MB
[2024-07-26 10:23:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 3 training takes 0:09:15
[2024-07-26 10:24:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 25.995 (25.995)	Loss 0.3613 (0.3613)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 10:24:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.876 Acc@5 97.510
[2024-07-26 10:24:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-26 10:24:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.88%
[2024-07-26 10:24:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saving......
[2024-07-26 10:24:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-26 10:24:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][0/2502]	eta 23:44:06 lr 0.000096	 wd 0.0000	time 34.1512 (34.1512)	loss 0.9302 (0.9302)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:25:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:21:10 lr 0.000096	 wd 0.0000	time 0.1854 (0.5290)	loss 0.8301 (0.8923)	grad_norm 1.5928 (1.8219)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:25:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:13:31 lr 0.000096	 wd 0.0000	time 0.2071 (0.3526)	loss 0.9854 (0.9004)	grad_norm 1.5308 (1.7845)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:25:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:10:46 lr 0.000095	 wd 0.0000	time 0.1741 (0.2936)	loss 0.8428 (0.9009)	grad_norm 3.4072 (1.8223)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:26:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:09:20 lr 0.000095	 wd 0.0000	time 0.3017 (0.2667)	loss 0.9321 (0.8966)	grad_norm 1.8995 (1.8169)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:26:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:09:56 lr 0.000095	 wd 0.0000	time 0.1985 (0.2982)	loss 0.9736 (0.8969)	grad_norm 1.8338 (1.8258)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:27:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:08:49 lr 0.000095	 wd 0.0000	time 0.1802 (0.2783)	loss 0.8447 (0.8993)	grad_norm 1.8063 (1.8375)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:27:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:07:55 lr 0.000095	 wd 0.0000	time 0.1722 (0.2640)	loss 1.1006 (0.8978)	grad_norm 2.4992 (1.8412)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:27:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:11 lr 0.000095	 wd 0.0000	time 0.1863 (0.2536)	loss 0.8081 (0.8971)	grad_norm 1.8858 (1.8604)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:28:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:07:03 lr 0.000095	 wd 0.0000	time 0.1796 (0.2642)	loss 0.9565 (0.8979)	grad_norm 1.4636 (1.8601)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:28:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:24 lr 0.000095	 wd 0.0000	time 0.1754 (0.2558)	loss 0.8555 (0.8981)	grad_norm 1.8754 (1.8651)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:28:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:05:48 lr 0.000095	 wd 0.0000	time 0.1635 (0.2485)	loss 1.0195 (0.8987)	grad_norm 1.6422 (1.8510)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:29:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:15 lr 0.000095	 wd 0.0000	time 0.1681 (0.2422)	loss 0.8452 (0.8989)	grad_norm 1.9750 (1.8498)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:29:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:04:46 lr 0.000095	 wd 0.0000	time 0.2319 (0.2381)	loss 0.7720 (0.8980)	grad_norm 1.3373 (1.8587)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:29:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:20 lr 0.000094	 wd 0.0000	time 0.1640 (0.2364)	loss 0.9058 (0.8972)	grad_norm 1.6490 (1.8609)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:30:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:03:53 lr 0.000094	 wd 0.0000	time 0.1596 (0.2329)	loss 0.7920 (0.8976)	grad_norm 1.3764 (1.8559)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:30:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:27 lr 0.000094	 wd 0.0000	time 0.1608 (0.2296)	loss 0.9399 (0.8980)	grad_norm 1.4813 (1.8570)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:30:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:01 lr 0.000094	 wd 0.0000	time 0.1689 (0.2266)	loss 0.9229 (0.8984)	grad_norm 1.5735 (1.8485)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:31:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:37 lr 0.000094	 wd 0.0000	time 0.2004 (0.2248)	loss 0.9941 (0.8993)	grad_norm 2.0402 (1.8513)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:31:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:15 lr 0.000094	 wd 0.0000	time 0.1669 (0.2250)	loss 0.8408 (0.8990)	grad_norm 1.7937 (1.8524)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:31:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:01:52 lr 0.000094	 wd 0.0000	time 0.2080 (0.2234)	loss 0.7861 (0.8985)	grad_norm 1.7959 (1.8427)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:32:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:28 lr 0.000094	 wd 0.0000	time 0.1830 (0.2214)	loss 0.8184 (0.8985)	grad_norm 1.9222 (1.8411)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:32:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:06 lr 0.000094	 wd 0.0000	time 0.1657 (0.2195)	loss 0.8979 (0.8983)	grad_norm 1.3983 (1.8401)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:32:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:44 lr 0.000094	 wd 0.0000	time 0.1954 (0.2184)	loss 0.8926 (0.8985)	grad_norm 1.5078 (1.8419)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:33:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:22 lr 0.000093	 wd 0.0000	time 0.1653 (0.2185)	loss 0.8267 (0.8986)	grad_norm 2.5112 (1.8496)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:33:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000093	 wd 0.0000	time 0.1577 (0.2167)	loss 0.7900 (0.8987)	grad_norm 2.1599 (1.8476)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:33:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 4 training takes 0:09:06
[2024-07-26 10:33:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 23.136 (23.136)	Loss 0.3582 (0.3582)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 8211MB
[2024-07-26 10:34:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.902 Acc@5 97.508
[2024-07-26 10:34:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-26 10:34:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.90%
[2024-07-26 10:34:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saving......
[2024-07-26 10:34:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-26 10:34:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][0/2502]	eta 23:10:53 lr 0.000093	 wd 0.0000	time 33.3547 (33.3547)	loss 1.0469 (1.0469)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:34:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:20:45 lr 0.000093	 wd 0.0000	time 0.1772 (0.5186)	loss 0.8091 (0.8954)	grad_norm 1.6862 (1.7345)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:35:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:13:20 lr 0.000093	 wd 0.0000	time 0.1860 (0.3477)	loss 0.8213 (0.9015)	grad_norm 1.7465 (1.8358)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:35:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:39 lr 0.000093	 wd 0.0000	time 0.1697 (0.2905)	loss 0.8579 (0.9003)	grad_norm 1.4974 (1.8427)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:35:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:14 lr 0.000093	 wd 0.0000	time 0.2162 (0.2638)	loss 0.7856 (0.8990)	grad_norm 1.8875 (1.8531)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:36:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:09:32 lr 0.000093	 wd 0.0000	time 0.1752 (0.2860)	loss 0.9219 (0.8981)	grad_norm 1.7521 (1.8628)	loss_scale 32768.0000 (18215.3453)	mem 8211MB
[2024-07-26 10:36:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:30 lr 0.000093	 wd 0.0000	time 0.1562 (0.2682)	loss 1.1279 (0.9007)	grad_norm 1.9634 (1.8602)	loss_scale 32768.0000 (20636.7521)	mem 8211MB
[2024-07-26 10:37:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:39 lr 0.000093	 wd 0.0000	time 0.1615 (0.2551)	loss 0.9097 (0.8997)	grad_norm 1.5826 (1.8865)	loss_scale 32768.0000 (22367.3153)	mem 8211MB
[2024-07-26 10:37:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:06:57 lr 0.000093	 wd 0.0000	time 0.1631 (0.2452)	loss 0.9355 (0.9001)	grad_norm 1.8630 (1.8692)	loss_scale 32768.0000 (23665.7778)	mem 8211MB
[2024-07-26 10:37:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:27 lr 0.000092	 wd 0.0000	time 0.2542 (0.2420)	loss 0.8813 (0.8997)	grad_norm 2.0032 (1.8552)	loss_scale 32768.0000 (24676.0133)	mem 8211MB
[2024-07-26 10:38:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:05 lr 0.000092	 wd 0.0000	time 0.1882 (0.2436)	loss 0.8066 (0.9002)	grad_norm 2.7670 (1.8579)	loss_scale 32768.0000 (25484.4036)	mem 8211MB
[2024-07-26 10:38:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:33 lr 0.000092	 wd 0.0000	time 0.1635 (0.2375)	loss 0.8174 (0.9010)	grad_norm 1.9462 (1.8545)	loss_scale 32768.0000 (26145.9473)	mem 8211MB
[2024-07-26 10:38:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:02 lr 0.000092	 wd 0.0000	time 0.1741 (0.2321)	loss 1.0312 (0.9011)	grad_norm 1.9782 (1.8634)	loss_scale 32768.0000 (26697.3256)	mem 8211MB
[2024-07-26 10:39:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:34 lr 0.000092	 wd 0.0000	time 0.2079 (0.2281)	loss 0.8916 (0.9010)	grad_norm 1.3685 (1.8562)	loss_scale 32768.0000 (27163.9416)	mem 8211MB
[2024-07-26 10:39:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:20 lr 0.000092	 wd 0.0000	time 0.2144 (0.2368)	loss 0.9297 (0.9000)	grad_norm 1.7559 (1.8515)	loss_scale 32768.0000 (27563.9458)	mem 8211MB
[2024-07-26 10:39:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:03:53 lr 0.000092	 wd 0.0000	time 0.1598 (0.2331)	loss 0.9297 (0.8998)	grad_norm 2.2024 (1.8442)	loss_scale 32768.0000 (27910.6516)	mem 8211MB
[2024-07-26 10:40:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:27 lr 0.000092	 wd 0.0000	time 0.1594 (0.2295)	loss 0.8359 (0.8993)	grad_norm 2.3231 (inf)	loss_scale 16384.0000 (27661.4316)	mem 8211MB
[2024-07-26 10:40:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:01 lr 0.000092	 wd 0.0000	time 0.1715 (0.2264)	loss 0.9780 (0.8993)	grad_norm 1.9289 (inf)	loss_scale 16384.0000 (26998.4433)	mem 8211MB
[2024-07-26 10:40:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:37 lr 0.000091	 wd 0.0000	time 0.1582 (0.2244)	loss 0.8979 (0.8992)	grad_norm 1.5982 (inf)	loss_scale 16384.0000 (26409.0794)	mem 8211MB
[2024-07-26 10:41:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:15 lr 0.000091	 wd 0.0000	time 0.2402 (0.2244)	loss 1.0625 (0.8997)	grad_norm 1.5467 (inf)	loss_scale 16384.0000 (25881.7212)	mem 8211MB
[2024-07-26 10:41:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:01:51 lr 0.000091	 wd 0.0000	time 0.2136 (0.2226)	loss 1.0635 (0.8994)	grad_norm 1.4369 (inf)	loss_scale 16384.0000 (25407.0725)	mem 8211MB
[2024-07-26 10:41:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:28 lr 0.000091	 wd 0.0000	time 0.1775 (0.2206)	loss 0.9160 (0.8987)	grad_norm 1.9048 (inf)	loss_scale 16384.0000 (24977.6069)	mem 8211MB
[2024-07-26 10:42:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:06 lr 0.000091	 wd 0.0000	time 0.1689 (0.2187)	loss 0.9189 (0.8985)	grad_norm 1.7807 (inf)	loss_scale 16384.0000 (24587.1658)	mem 8211MB
[2024-07-26 10:42:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:44 lr 0.000091	 wd 0.0000	time 0.2676 (0.2179)	loss 0.7769 (0.8980)	grad_norm 2.2591 (inf)	loss_scale 16384.0000 (24230.6615)	mem 8211MB
[2024-07-26 10:42:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:22 lr 0.000091	 wd 0.0000	time 0.1794 (0.2177)	loss 0.9321 (0.8980)	grad_norm 1.5798 (inf)	loss_scale 16384.0000 (23903.8534)	mem 8211MB
[2024-07-26 10:43:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000091	 wd 0.0000	time 0.1577 (0.2161)	loss 0.8926 (0.8981)	grad_norm 1.5403 (inf)	loss_scale 16384.0000 (23603.1795)	mem 8211MB
[2024-07-26 10:43:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 5 training takes 0:09:04
[2024-07-26 10:43:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 19.087 (19.087)	Loss 0.3582 (0.3582)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 10:43:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.922 Acc@5 97.518
[2024-07-26 10:43:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-26 10:43:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.92%
[2024-07-26 10:43:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saving......
[2024-07-26 10:43:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-26 10:44:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][0/2502]	eta 19:30:48 lr 0.000091	 wd 0.0000	time 28.0769 (28.0769)	loss 0.9741 (0.9741)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:44:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:19:43 lr 0.000090	 wd 0.0000	time 0.1902 (0.4928)	loss 0.8438 (0.8983)	grad_norm 1.8891 (1.7456)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:44:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:12:51 lr 0.000090	 wd 0.0000	time 0.1624 (0.3350)	loss 0.7764 (0.8958)	grad_norm 1.6065 (1.7433)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:45:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:10:20 lr 0.000090	 wd 0.0000	time 0.1781 (0.2820)	loss 0.9326 (0.8977)	grad_norm 1.6513 (1.7398)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:45:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:08:56 lr 0.000090	 wd 0.0000	time 0.1961 (0.2555)	loss 0.8799 (0.8978)	grad_norm 1.2673 (1.7228)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:46:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:09:08 lr 0.000090	 wd 0.0000	time 0.2233 (0.2740)	loss 0.9487 (0.8964)	grad_norm 1.2211 (1.7372)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:46:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:08:26 lr 0.000090	 wd 0.0000	time 0.1611 (0.2664)	loss 0.9858 (0.8966)	grad_norm 1.9394 (1.7692)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:46:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:07:37 lr 0.000090	 wd 0.0000	time 0.1580 (0.2538)	loss 0.8989 (0.8977)	grad_norm 1.5126 (1.7611)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:46:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:06:55 lr 0.000090	 wd 0.0000	time 0.1617 (0.2440)	loss 0.8540 (0.8994)	grad_norm 1.3903 (1.7616)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:47:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:06:23 lr 0.000089	 wd 0.0000	time 0.2227 (0.2394)	loss 0.8916 (0.8993)	grad_norm 1.4434 (1.7772)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:47:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:04 lr 0.000089	 wd 0.0000	time 0.1665 (0.2426)	loss 0.8574 (0.9005)	grad_norm 1.7140 (1.7786)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:48:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:31 lr 0.000089	 wd 0.0000	time 0.1582 (0.2366)	loss 0.7910 (0.8993)	grad_norm 1.5163 (1.7791)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:48:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:01 lr 0.000089	 wd 0.0000	time 0.1609 (0.2314)	loss 0.7393 (0.8993)	grad_norm 1.4705 (1.7899)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:48:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:04:33 lr 0.000089	 wd 0.0000	time 0.1636 (0.2273)	loss 0.9043 (0.9003)	grad_norm 1.5376 (1.7885)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:49:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:18 lr 0.000089	 wd 0.0000	time 0.2102 (0.2344)	loss 1.0898 (0.8988)	grad_norm 2.3619 (1.7866)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:49:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:03:51 lr 0.000089	 wd 0.0000	time 0.1610 (0.2312)	loss 0.7329 (0.8988)	grad_norm 1.8980 (1.7847)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:49:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:25 lr 0.000089	 wd 0.0000	time 0.1783 (0.2279)	loss 0.9307 (0.8985)	grad_norm 1.5397 (1.7856)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:50:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:00 lr 0.000088	 wd 0.0000	time 0.1862 (0.2249)	loss 0.9751 (0.8974)	grad_norm 1.4300 (1.7917)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:50:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:36 lr 0.000088	 wd 0.0000	time 0.2003 (0.2227)	loss 0.7563 (0.8964)	grad_norm 1.6269 (1.7967)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:50:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:14 lr 0.000088	 wd 0.0000	time 0.1750 (0.2230)	loss 1.0234 (0.8962)	grad_norm 2.3369 (1.7944)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:51:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:01:51 lr 0.000088	 wd 0.0000	time 0.1748 (0.2218)	loss 1.0791 (0.8974)	grad_norm 1.6801 (1.7930)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:51:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:28 lr 0.000088	 wd 0.0000	time 0.1761 (0.2200)	loss 0.8979 (0.8976)	grad_norm 2.3066 (1.7927)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:51:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:05 lr 0.000088	 wd 0.0000	time 0.1663 (0.2181)	loss 0.9443 (0.8979)	grad_norm 2.3769 (1.7934)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:52:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:43 lr 0.000088	 wd 0.0000	time 0.1825 (0.2167)	loss 0.9395 (0.8978)	grad_norm 1.3703 (1.7919)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:52:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:22 lr 0.000087	 wd 0.0000	time 0.1771 (0.2168)	loss 0.8809 (0.8974)	grad_norm 1.6487 (1.7934)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:52:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000087	 wd 0.0000	time 0.1596 (0.2151)	loss 0.8037 (0.8971)	grad_norm 1.3863 (1.7918)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:52:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 6 training takes 0:09:03
[2024-07-26 10:53:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 22.668 (22.668)	Loss 0.3586 (0.3586)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 10:53:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.958 Acc@5 97.514
[2024-07-26 10:53:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-26 10:53:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.96%
[2024-07-26 10:53:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saving......
[2024-07-26 10:53:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-26 10:53:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][0/2502]	eta 13:34:23 lr 0.000087	 wd 0.0000	time 19.5296 (19.5296)	loss 1.0342 (1.0342)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:54:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:16:36 lr 0.000087	 wd 0.0000	time 0.1663 (0.4150)	loss 1.0137 (0.9058)	grad_norm 1.8340 (1.7495)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:54:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:11:27 lr 0.000087	 wd 0.0000	time 0.1589 (0.2988)	loss 0.9380 (0.8936)	grad_norm 1.6419 (1.8246)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:54:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:09:28 lr 0.000087	 wd 0.0000	time 0.1695 (0.2580)	loss 0.8989 (0.8926)	grad_norm 2.2695 (1.7858)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:54:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:08:19 lr 0.000087	 wd 0.0000	time 0.1615 (0.2377)	loss 0.9683 (0.8936)	grad_norm 2.0004 (1.7892)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:55:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:07:36 lr 0.000087	 wd 0.0000	time 0.2072 (0.2278)	loss 0.8623 (0.8928)	grad_norm 1.9586 (1.7849)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 10:55:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:06 lr 0.000086	 wd 0.0000	time 0.1753 (0.2557)	loss 0.8491 (0.8936)	grad_norm 1.1627 (1.7693)	loss_scale 32768.0000 (17965.1514)	mem 8211MB
[2024-07-26 10:56:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:07:20 lr 0.000086	 wd 0.0000	time 0.1720 (0.2445)	loss 0.8257 (0.8926)	grad_norm 1.4293 (1.7701)	loss_scale 32768.0000 (20076.8274)	mem 8211MB
[2024-07-26 10:56:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:06:41 lr 0.000086	 wd 0.0000	time 0.1688 (0.2360)	loss 0.8994 (0.8934)	grad_norm 2.4522 (1.7766)	loss_scale 32768.0000 (21661.2434)	mem 8211MB
[2024-07-26 10:56:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:06:08 lr 0.000086	 wd 0.0000	time 0.2272 (0.2298)	loss 0.7505 (0.8940)	grad_norm 1.6328 (inf)	loss_scale 16384.0000 (22021.1143)	mem 8211MB
[2024-07-26 10:57:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:05:44 lr 0.000086	 wd 0.0000	time 1.8238 (0.2294)	loss 0.8657 (0.8947)	grad_norm 2.3220 (inf)	loss_scale 16384.0000 (21457.9660)	mem 8211MB
[2024-07-26 10:57:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:14 lr 0.000086	 wd 0.0000	time 0.1760 (0.2245)	loss 0.8198 (0.8938)	grad_norm 1.5271 (inf)	loss_scale 16384.0000 (20997.1153)	mem 8211MB
[2024-07-26 10:57:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:04:47 lr 0.000086	 wd 0.0000	time 0.1631 (0.2209)	loss 0.8018 (0.8944)	grad_norm 2.1476 (inf)	loss_scale 16384.0000 (20613.0092)	mem 8211MB
[2024-07-26 10:58:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:04:21 lr 0.000085	 wd 0.0000	time 0.1830 (0.2177)	loss 0.9512 (0.8941)	grad_norm 1.8275 (inf)	loss_scale 16384.0000 (20287.9508)	mem 8211MB
[2024-07-26 10:58:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:03:56 lr 0.000085	 wd 0.0000	time 0.1754 (0.2148)	loss 0.9072 (0.8952)	grad_norm 2.2508 (inf)	loss_scale 16384.0000 (20009.2962)	mem 8211MB
[2024-07-26 10:58:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:03:35 lr 0.000085	 wd 0.0000	time 0.1769 (0.2146)	loss 0.8130 (0.8947)	grad_norm 1.6770 (inf)	loss_scale 16384.0000 (19767.7708)	mem 8211MB
[2024-07-26 10:59:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:13 lr 0.000085	 wd 0.0000	time 0.1676 (0.2148)	loss 0.9653 (0.8952)	grad_norm 1.8355 (inf)	loss_scale 16384.0000 (19556.4172)	mem 8211MB
[2024-07-26 10:59:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:02:50 lr 0.000085	 wd 0.0000	time 0.1913 (0.2127)	loss 0.8389 (0.8950)	grad_norm 1.5899 (inf)	loss_scale 16384.0000 (19369.9142)	mem 8211MB
[2024-07-26 10:59:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:28 lr 0.000085	 wd 0.0000	time 0.1758 (0.2110)	loss 0.8267 (0.8942)	grad_norm 1.9295 (inf)	loss_scale 16384.0000 (19204.1222)	mem 8211MB
[2024-07-26 11:00:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:06 lr 0.000085	 wd 0.0000	time 0.1770 (0.2094)	loss 1.0244 (0.8951)	grad_norm 1.7155 (inf)	loss_scale 16384.0000 (19055.7728)	mem 8211MB
[2024-07-26 11:00:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:01:45 lr 0.000084	 wd 0.0000	time 0.1907 (0.2094)	loss 0.8003 (0.8947)	grad_norm 1.3007 (inf)	loss_scale 16384.0000 (18922.2509)	mem 8211MB
[2024-07-26 11:00:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:24 lr 0.000084	 wd 0.0000	time 0.1600 (0.2101)	loss 0.9170 (0.8951)	grad_norm 2.1395 (inf)	loss_scale 16384.0000 (18801.4393)	mem 8211MB
[2024-07-26 11:01:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:03 lr 0.000084	 wd 0.0000	time 0.1702 (0.2088)	loss 0.8237 (0.8948)	grad_norm 2.0080 (inf)	loss_scale 16384.0000 (18691.6056)	mem 8211MB
[2024-07-26 11:01:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:41 lr 0.000084	 wd 0.0000	time 0.1888 (0.2075)	loss 0.9512 (0.8946)	grad_norm 2.2010 (inf)	loss_scale 16384.0000 (18591.3186)	mem 8211MB
[2024-07-26 11:01:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:21 lr 0.000084	 wd 0.0000	time 0.1973 (0.2064)	loss 0.8262 (0.8951)	grad_norm 1.9790 (inf)	loss_scale 16384.0000 (18499.3853)	mem 8211MB
[2024-07-26 11:01:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000084	 wd 0.0000	time 0.1585 (0.2052)	loss 0.8281 (0.8955)	grad_norm 1.4492 (inf)	loss_scale 16384.0000 (18414.8037)	mem 8211MB
[2024-07-26 11:02:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 7 training takes 0:08:39
[2024-07-26 11:02:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 26.111 (26.111)	Loss 0.3538 (0.3538)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 8211MB
[2024-07-26 11:02:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.960 Acc@5 97.494
[2024-07-26 11:02:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-26 11:02:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.96%
[2024-07-26 11:02:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saving......
[2024-07-26 11:02:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-26 11:02:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][0/2502]	eta 10:41:17 lr 0.000084	 wd 0.0000	time 15.3787 (15.3787)	loss 0.9775 (0.9775)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:03:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:13:15 lr 0.000083	 wd 0.0000	time 0.1774 (0.3312)	loss 0.8638 (0.9048)	grad_norm 1.5819 (1.8109)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:03:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:12:45 lr 0.000083	 wd 0.0000	time 0.1969 (0.3327)	loss 0.8638 (0.8987)	grad_norm 1.5411 (1.7966)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:04:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:10:22 lr 0.000083	 wd 0.0000	time 0.1595 (0.2827)	loss 0.9380 (0.8931)	grad_norm 1.7478 (1.8253)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:04:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:08:58 lr 0.000083	 wd 0.0000	time 0.1781 (0.2561)	loss 0.9414 (0.8936)	grad_norm 1.6359 (1.7931)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:04:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:07:59 lr 0.000083	 wd 0.0000	time 0.1546 (0.2397)	loss 0.9414 (0.8946)	grad_norm 1.5593 (1.7797)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:05:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:07:21 lr 0.000083	 wd 0.0000	time 0.2117 (0.2323)	loss 0.7788 (0.8947)	grad_norm 2.1963 (1.7741)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:05:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:23 lr 0.000083	 wd 0.0000	time 0.1640 (0.2463)	loss 1.0059 (0.8930)	grad_norm 1.8552 (1.7727)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:05:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:06:44 lr 0.000082	 wd 0.0000	time 0.1862 (0.2377)	loss 0.9971 (0.8942)	grad_norm 2.0596 (1.7683)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:06:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:09 lr 0.000082	 wd 0.0000	time 0.1649 (0.2309)	loss 1.0088 (0.8936)	grad_norm 1.5329 (1.7812)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:06:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:05:38 lr 0.000082	 wd 0.0000	time 0.2099 (0.2257)	loss 0.9541 (0.8945)	grad_norm 1.6893 (1.7983)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:06:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:29 lr 0.000082	 wd 0.0000	time 0.1791 (0.2349)	loss 0.8848 (0.8949)	grad_norm 1.5829 (1.7989)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:07:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:00 lr 0.000082	 wd 0.0000	time 0.1667 (0.2307)	loss 0.8892 (0.8953)	grad_norm 1.8358 (1.7914)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:07:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:32 lr 0.000082	 wd 0.0000	time 0.1792 (0.2265)	loss 0.8193 (0.8961)	grad_norm 1.9023 (1.7957)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:07:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:05 lr 0.000081	 wd 0.0000	time 0.1657 (0.2226)	loss 0.8760 (0.8968)	grad_norm 1.9233 (1.8036)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:08:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:03:40 lr 0.000081	 wd 0.0000	time 0.2292 (0.2204)	loss 0.7910 (0.8967)	grad_norm 1.8136 (1.7948)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:08:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:18 lr 0.000081	 wd 0.0000	time 0.1610 (0.2205)	loss 1.0137 (0.8967)	grad_norm 2.0595 (1.7942)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:08:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:02:55 lr 0.000081	 wd 0.0000	time 0.1639 (0.2184)	loss 0.8145 (0.8972)	grad_norm 1.6356 (1.7996)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:09:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:31 lr 0.000081	 wd 0.0000	time 0.1622 (0.2164)	loss 0.8306 (0.8979)	grad_norm 2.6092 (1.7955)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:09:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:09 lr 0.000081	 wd 0.0000	time 0.1759 (0.2144)	loss 0.7700 (0.8971)	grad_norm 1.7380 (1.7886)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:09:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:46 lr 0.000080	 wd 0.0000	time 0.2261 (0.2130)	loss 0.9473 (0.8971)	grad_norm 1.4683 (1.7921)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:10:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:26 lr 0.000080	 wd 0.0000	time 0.1736 (0.2147)	loss 1.0459 (0.8974)	grad_norm 1.6210 (1.7910)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:10:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:04 lr 0.000080	 wd 0.0000	time 0.1632 (0.2136)	loss 0.9297 (0.8974)	grad_norm 1.4766 (1.7904)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:10:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:42 lr 0.000080	 wd 0.0000	time 0.1887 (0.2122)	loss 0.9478 (0.8971)	grad_norm 1.7841 (1.7880)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:11:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:21 lr 0.000080	 wd 0.0000	time 0.1597 (0.2108)	loss 0.9609 (0.8971)	grad_norm 2.4908 (1.7830)	loss_scale 32768.0000 (16725.1912)	mem 8211MB
[2024-07-26 11:11:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000080	 wd 0.0000	time 0.1582 (0.2092)	loss 1.0312 (0.8973)	grad_norm 2.3777 (1.7831)	loss_scale 32768.0000 (17366.6469)	mem 8211MB
[2024-07-26 11:11:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 8 training takes 0:08:47
[2024-07-26 11:12:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 39.199 (39.199)	Loss 0.3647 (0.3647)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 8211MB
[2024-07-26 11:12:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.916 Acc@5 97.500
[2024-07-26 11:12:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-26 11:12:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.96%
[2024-07-26 11:12:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][0/2502]	eta 12:06:23 lr 0.000080	 wd 0.0000	time 17.4196 (17.4196)	loss 0.8003 (0.8003)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:12:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:14:06 lr 0.000079	 wd 0.0000	time 0.2923 (0.3523)	loss 0.8799 (0.8881)	grad_norm 2.0362 (1.7282)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:13:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:13:03 lr 0.000079	 wd 0.0000	time 0.1790 (0.3402)	loss 0.8008 (0.8888)	grad_norm 1.6061 (1.7418)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:13:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:36 lr 0.000079	 wd 0.0000	time 0.1803 (0.2890)	loss 0.9302 (0.8947)	grad_norm 1.5490 (1.7272)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:14:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:08 lr 0.000079	 wd 0.0000	time 0.1823 (0.2609)	loss 0.7954 (0.8923)	grad_norm 1.6115 (1.7264)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:14:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:08:07 lr 0.000079	 wd 0.0000	time 0.1636 (0.2436)	loss 0.7847 (0.8916)	grad_norm 1.4130 (1.7662)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:14:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:07:27 lr 0.000079	 wd 0.0000	time 0.2073 (0.2354)	loss 0.8286 (0.8903)	grad_norm 2.0271 (1.7604)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:15:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:26 lr 0.000078	 wd 0.0000	time 0.1765 (0.2476)	loss 0.9741 (0.8910)	grad_norm 1.9294 (1.7573)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:15:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:06:46 lr 0.000078	 wd 0.0000	time 0.1744 (0.2390)	loss 1.0039 (0.8916)	grad_norm 1.2293 (1.7567)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:15:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:11 lr 0.000078	 wd 0.0000	time 0.1729 (0.2320)	loss 1.0303 (0.8927)	grad_norm 1.5544 (1.7460)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:16:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:05:40 lr 0.000078	 wd 0.0000	time 0.1753 (0.2264)	loss 0.8916 (0.8930)	grad_norm 2.4992 (1.7498)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:16:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:30 lr 0.000078	 wd 0.0000	time 0.2482 (0.2360)	loss 0.9341 (0.8924)	grad_norm 1.8117 (1.7492)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:16:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:02 lr 0.000078	 wd 0.0000	time 0.1664 (0.2320)	loss 0.9321 (0.8937)	grad_norm 1.8799 (1.7418)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:17:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:33 lr 0.000077	 wd 0.0000	time 0.1707 (0.2278)	loss 0.8940 (0.8939)	grad_norm 1.5937 (1.7593)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:17:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:06 lr 0.000077	 wd 0.0000	time 0.1747 (0.2240)	loss 0.9199 (0.8941)	grad_norm 1.5065 (1.7547)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:17:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:03:42 lr 0.000077	 wd 0.0000	time 0.2400 (0.2217)	loss 0.8960 (0.8950)	grad_norm 1.6748 (1.7597)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:18:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:19 lr 0.000077	 wd 0.0000	time 0.1582 (0.2214)	loss 0.8745 (0.8937)	grad_norm 2.1883 (1.7607)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:18:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:02:55 lr 0.000077	 wd 0.0000	time 0.1596 (0.2194)	loss 0.8506 (0.8935)	grad_norm 1.3797 (1.7562)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:18:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:32 lr 0.000077	 wd 0.0000	time 0.1706 (0.2173)	loss 0.8994 (0.8936)	grad_norm 1.4863 (1.7513)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:19:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:09 lr 0.000076	 wd 0.0000	time 0.1788 (0.2153)	loss 0.9233 (0.8940)	grad_norm 2.2327 (1.7511)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:19:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:01:47 lr 0.000076	 wd 0.0000	time 0.1967 (0.2140)	loss 0.8618 (0.8946)	grad_norm 1.6951 (1.7503)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:19:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:26 lr 0.000076	 wd 0.0000	time 0.1550 (0.2143)	loss 0.8618 (0.8946)	grad_norm 1.8327 (1.7513)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:20:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:04 lr 0.000076	 wd 0.0000	time 0.1603 (0.2135)	loss 0.7231 (0.8943)	grad_norm 1.5904 (1.7503)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:20:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:42 lr 0.000076	 wd 0.0000	time 0.1786 (0.2122)	loss 0.8438 (0.8942)	grad_norm 2.0152 (1.7513)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:20:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:21 lr 0.000075	 wd 0.0000	time 0.1621 (0.2108)	loss 0.9468 (0.8944)	grad_norm 1.6732 (1.7511)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:21:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000075	 wd 0.0000	time 0.1602 (0.2092)	loss 0.8628 (0.8948)	grad_norm 1.7126 (1.7487)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:21:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 9 training takes 0:08:47
[2024-07-26 11:21:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 41.716 (41.716)	Loss 0.3608 (0.3608)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 8211MB
[2024-07-26 11:22:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.986 Acc@5 97.506
[2024-07-26 11:22:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-26 11:22:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.99%
[2024-07-26 11:22:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saving......
[2024-07-26 11:22:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-26 11:22:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][0/2502]	eta 10:44:08 lr 0.000075	 wd 0.0000	time 15.4470 (15.4470)	loss 1.0088 (1.0088)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 11:22:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:13:20 lr 0.000075	 wd 0.0000	time 0.1934 (0.3332)	loss 0.9844 (0.9114)	grad_norm 1.7718 (inf)	loss_scale 16384.0000 (25630.4158)	mem 8211MB
[2024-07-26 11:23:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:13:47 lr 0.000075	 wd 0.0000	time 0.2223 (0.3596)	loss 0.9004 (0.9027)	grad_norm 1.5947 (inf)	loss_scale 16384.0000 (21030.2090)	mem 8211MB
[2024-07-26 11:23:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:11:02 lr 0.000075	 wd 0.0000	time 0.1619 (0.3007)	loss 0.8940 (0.9002)	grad_norm 1.9016 (inf)	loss_scale 16384.0000 (19486.6179)	mem 8211MB
[2024-07-26 11:23:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:25 lr 0.000075	 wd 0.0000	time 0.1657 (0.2692)	loss 0.8682 (0.8989)	grad_norm 2.1322 (inf)	loss_scale 16384.0000 (18712.8978)	mem 8211MB
[2024-07-26 11:24:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:08:20 lr 0.000074	 wd 0.0000	time 0.1610 (0.2500)	loss 0.8027 (0.9000)	grad_norm 1.6337 (inf)	loss_scale 16384.0000 (18248.0479)	mem 8211MB
[2024-07-26 11:24:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:23 lr 0.000074	 wd 0.0000	time 0.7421 (0.2647)	loss 0.8574 (0.8995)	grad_norm 1.5413 (inf)	loss_scale 16384.0000 (17937.8902)	mem 8211MB
[2024-07-26 11:25:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:47 lr 0.000074	 wd 0.0000	time 0.1600 (0.2594)	loss 0.7930 (0.8969)	grad_norm 1.4008 (inf)	loss_scale 16384.0000 (17716.2225)	mem 8211MB
[2024-07-26 11:25:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:07:03 lr 0.000074	 wd 0.0000	time 0.2025 (0.2490)	loss 0.8711 (0.8979)	grad_norm 1.6078 (inf)	loss_scale 16384.0000 (17549.9026)	mem 8211MB
[2024-07-26 11:25:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:26 lr 0.000074	 wd 0.0000	time 0.1770 (0.2410)	loss 0.8267 (0.8969)	grad_norm 1.7298 (inf)	loss_scale 16384.0000 (17420.5017)	mem 8211MB
[2024-07-26 11:25:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:05:54 lr 0.000073	 wd 0.0000	time 0.2413 (0.2363)	loss 0.9839 (0.8960)	grad_norm 1.5593 (inf)	loss_scale 16384.0000 (17316.9550)	mem 8211MB
[2024-07-26 11:26:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:42 lr 0.000073	 wd 0.0000	time 0.1673 (0.2444)	loss 0.9702 (0.8958)	grad_norm 1.6501 (inf)	loss_scale 16384.0000 (17232.2180)	mem 8211MB
[2024-07-26 11:26:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:10 lr 0.000073	 wd 0.0000	time 0.1548 (0.2388)	loss 1.0098 (0.8953)	grad_norm 1.5500 (inf)	loss_scale 16384.0000 (17161.5920)	mem 8211MB
[2024-07-26 11:27:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:41 lr 0.000073	 wd 0.0000	time 0.1664 (0.2340)	loss 0.8760 (0.8954)	grad_norm 1.5942 (inf)	loss_scale 16384.0000 (17101.8232)	mem 8211MB
[2024-07-26 11:27:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:13 lr 0.000073	 wd 0.0000	time 0.1654 (0.2297)	loss 0.8574 (0.8955)	grad_norm 1.7014 (inf)	loss_scale 16384.0000 (17050.5867)	mem 8211MB
[2024-07-26 11:27:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:03:53 lr 0.000073	 wd 0.0000	time 0.2099 (0.2327)	loss 0.9170 (0.8955)	grad_norm 1.8331 (inf)	loss_scale 16384.0000 (17006.1772)	mem 8211MB
[2024-07-26 11:28:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:28 lr 0.000072	 wd 0.0000	time 0.1748 (0.2312)	loss 0.7319 (0.8951)	grad_norm 1.7741 (inf)	loss_scale 16384.0000 (16967.3154)	mem 8211MB
[2024-07-26 11:28:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:02 lr 0.000072	 wd 0.0000	time 0.1711 (0.2279)	loss 0.8452 (0.8948)	grad_norm 1.3746 (inf)	loss_scale 16384.0000 (16933.0229)	mem 8211MB
[2024-07-26 11:28:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:38 lr 0.000072	 wd 0.0000	time 0.1589 (0.2251)	loss 0.9976 (0.8947)	grad_norm 2.0625 (inf)	loss_scale 16384.0000 (16902.5386)	mem 8211MB
[2024-07-26 11:29:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:14 lr 0.000072	 wd 0.0000	time 0.2080 (0.2230)	loss 0.9497 (0.8960)	grad_norm 1.7534 (inf)	loss_scale 16384.0000 (16875.2614)	mem 8211MB
[2024-07-26 11:29:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:51 lr 0.000072	 wd 0.0000	time 0.1874 (0.2228)	loss 1.0635 (0.8964)	grad_norm 1.7753 (inf)	loss_scale 16384.0000 (16850.7106)	mem 8211MB
[2024-07-26 11:29:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:29 lr 0.000071	 wd 0.0000	time 0.1844 (0.2215)	loss 0.8789 (0.8964)	grad_norm 1.5605 (inf)	loss_scale 16384.0000 (16828.4969)	mem 8211MB
[2024-07-26 11:30:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:06 lr 0.000071	 wd 0.0000	time 0.1650 (0.2197)	loss 0.9043 (0.8966)	grad_norm 1.6650 (inf)	loss_scale 16384.0000 (16808.3017)	mem 8211MB
[2024-07-26 11:30:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:44 lr 0.000071	 wd 0.0000	time 0.1737 (0.2180)	loss 0.9609 (0.8963)	grad_norm 1.8884 (inf)	loss_scale 16384.0000 (16789.8618)	mem 8211MB
[2024-07-26 11:30:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:22 lr 0.000071	 wd 0.0000	time 0.1801 (0.2167)	loss 0.9717 (0.8964)	grad_norm 1.8761 (inf)	loss_scale 16384.0000 (16772.9579)	mem 8211MB
[2024-07-26 11:31:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000071	 wd 0.0000	time 0.1578 (0.2155)	loss 0.7783 (0.8960)	grad_norm 1.3231 (inf)	loss_scale 16384.0000 (16757.4058)	mem 8211MB
[2024-07-26 11:31:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 10 training takes 0:09:08
[2024-07-26 11:31:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 29.464 (29.464)	Loss 0.3682 (0.3682)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 11:31:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.990 Acc@5 97.494
[2024-07-26 11:31:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-26 11:31:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.99%
[2024-07-26 11:31:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saving......
[2024-07-26 11:31:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-26 11:32:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][0/2502]	eta 10:33:31 lr 0.000071	 wd 0.0000	time 15.1926 (15.1926)	loss 0.8906 (0.8906)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:32:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:14:54 lr 0.000070	 wd 0.0000	time 0.3360 (0.3724)	loss 0.8501 (0.8960)	grad_norm 1.5437 (1.7270)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:32:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:12:18 lr 0.000070	 wd 0.0000	time 0.1951 (0.3208)	loss 0.8848 (0.8960)	grad_norm 1.7475 (1.7158)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:33:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:09:59 lr 0.000070	 wd 0.0000	time 0.1610 (0.2724)	loss 0.9126 (0.8923)	grad_norm 2.3202 (1.7176)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:33:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:08:40 lr 0.000070	 wd 0.0000	time 0.1778 (0.2477)	loss 0.8726 (0.8897)	grad_norm 1.7378 (1.7223)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:33:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:07:47 lr 0.000070	 wd 0.0000	time 0.1879 (0.2335)	loss 0.8950 (0.8878)	grad_norm 1.5387 (1.7233)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:34:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:07 lr 0.000069	 wd 0.0000	time 0.1738 (0.2561)	loss 0.9736 (0.8887)	grad_norm 1.3050 (1.7174)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:34:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:07:23 lr 0.000069	 wd 0.0000	time 0.1600 (0.2459)	loss 0.8682 (0.8901)	grad_norm 1.8069 (1.7025)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:35:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:06:43 lr 0.000069	 wd 0.0000	time 0.1721 (0.2373)	loss 1.0322 (0.8905)	grad_norm 1.5217 (1.7007)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:35:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:06:09 lr 0.000069	 wd 0.0000	time 0.1648 (0.2307)	loss 0.9102 (0.8934)	grad_norm 1.5908 (1.6853)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:35:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:05:41 lr 0.000069	 wd 0.0000	time 0.1728 (0.2275)	loss 0.8779 (0.8935)	grad_norm 1.5860 (1.6923)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:36:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:14 lr 0.000069	 wd 0.0000	time 0.1879 (0.2246)	loss 0.9146 (0.8931)	grad_norm 1.7913 (1.6946)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:36:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:04:48 lr 0.000068	 wd 0.0000	time 0.1682 (0.2216)	loss 0.9868 (0.8931)	grad_norm 2.1765 (1.6945)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:36:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:04:22 lr 0.000068	 wd 0.0000	time 0.1724 (0.2184)	loss 0.8721 (0.8938)	grad_norm 1.8323 (1.7041)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:36:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:03:57 lr 0.000068	 wd 0.0000	time 0.1803 (0.2154)	loss 0.8911 (0.8939)	grad_norm 1.6338 (1.7011)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:37:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:03:34 lr 0.000068	 wd 0.0000	time 0.2343 (0.2143)	loss 0.8169 (0.8933)	grad_norm 1.4232 (1.7004)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:37:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:17 lr 0.000068	 wd 0.0000	time 0.1632 (0.2184)	loss 0.7549 (0.8933)	grad_norm 1.6019 (1.7003)	loss_scale 32768.0000 (16854.7458)	mem 8211MB
[2024-07-26 11:38:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:02:53 lr 0.000067	 wd 0.0000	time 0.1701 (0.2160)	loss 0.9458 (0.8926)	grad_norm 1.5908 (1.7045)	loss_scale 32768.0000 (17790.2693)	mem 8211MB
[2024-07-26 11:38:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:30 lr 0.000067	 wd 0.0000	time 0.2057 (0.2138)	loss 0.8804 (0.8933)	grad_norm 1.8441 (1.7092)	loss_scale 32768.0000 (18621.9034)	mem 8211MB
[2024-07-26 11:38:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:07 lr 0.000067	 wd 0.0000	time 0.1793 (0.2120)	loss 0.8174 (0.8936)	grad_norm 1.6754 (1.7017)	loss_scale 32768.0000 (19366.0431)	mem 8211MB
[2024-07-26 11:38:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:01:46 lr 0.000067	 wd 0.0000	time 0.1946 (0.2120)	loss 0.6885 (0.8936)	grad_norm 2.0320 (1.7033)	loss_scale 32768.0000 (20035.8061)	mem 8211MB
[2024-07-26 11:39:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:25 lr 0.000067	 wd 0.0000	time 0.2109 (0.2127)	loss 1.0049 (0.8932)	grad_norm 1.5404 (1.7040)	loss_scale 32768.0000 (20641.8125)	mem 8211MB
[2024-07-26 11:39:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:03 lr 0.000066	 wd 0.0000	time 0.1748 (0.2113)	loss 0.9707 (0.8934)	grad_norm 1.2604 (1.6997)	loss_scale 32768.0000 (21192.7524)	mem 8211MB
[2024-07-26 11:39:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:42 lr 0.000066	 wd 0.0000	time 0.1556 (0.2100)	loss 0.9292 (0.8934)	grad_norm 1.2927 (inf)	loss_scale 16384.0000 (21240.1008)	mem 8211MB
[2024-07-26 11:40:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:21 lr 0.000066	 wd 0.0000	time 0.1931 (0.2087)	loss 0.8501 (0.8932)	grad_norm 1.8671 (inf)	loss_scale 16384.0000 (21037.8476)	mem 8211MB
[2024-07-26 11:40:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000066	 wd 0.0000	time 0.1588 (0.2074)	loss 0.9604 (0.8930)	grad_norm 1.9026 (inf)	loss_scale 16384.0000 (20851.7681)	mem 8211MB
[2024-07-26 11:40:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 11 training takes 0:08:44
[2024-07-26 11:41:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 35.770 (35.770)	Loss 0.3633 (0.3633)	Acc@1 91.016 (91.016)	Acc@5 98.828 (98.828)	Mem 8211MB
[2024-07-26 11:41:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.900 Acc@5 97.474
[2024-07-26 11:41:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-26 11:41:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.99%
[2024-07-26 11:41:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][0/2502]	eta 11:16:24 lr 0.000066	 wd 0.0000	time 16.2210 (16.2210)	loss 0.8716 (0.8716)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:42:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:14:36 lr 0.000066	 wd 0.0000	time 0.3195 (0.3651)	loss 0.8179 (0.8890)	grad_norm 1.4067 (1.6076)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:42:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:12:51 lr 0.000065	 wd 0.0000	time 0.1899 (0.3351)	loss 0.8511 (0.8885)	grad_norm 1.2644 (1.6729)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:42:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:21 lr 0.000065	 wd 0.0000	time 0.1604 (0.2823)	loss 0.8164 (0.8968)	grad_norm 3.3540 (1.7176)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:43:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:08:57 lr 0.000065	 wd 0.0000	time 0.1614 (0.2557)	loss 0.8574 (0.8967)	grad_norm 1.3334 (1.7098)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:43:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:07:59 lr 0.000065	 wd 0.0000	time 0.1814 (0.2393)	loss 0.8936 (0.8983)	grad_norm 1.4730 (1.7105)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:43:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:07:41 lr 0.000065	 wd 0.0000	time 0.2832 (0.2425)	loss 0.9229 (0.8959)	grad_norm 1.4023 (1.6919)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:44:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:26 lr 0.000064	 wd 0.0000	time 0.1673 (0.2480)	loss 0.8745 (0.8965)	grad_norm 1.6251 (1.7126)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:44:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:06:47 lr 0.000064	 wd 0.0000	time 0.1700 (0.2394)	loss 1.0869 (0.8962)	grad_norm 1.7237 (1.6977)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:44:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:12 lr 0.000064	 wd 0.0000	time 0.1597 (0.2323)	loss 1.0361 (0.8959)	grad_norm 1.3279 (1.6866)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:45:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:05:41 lr 0.000064	 wd 0.0000	time 0.1934 (0.2276)	loss 0.8638 (0.8962)	grad_norm 1.4241 (1.6741)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:45:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:16 lr 0.000064	 wd 0.0000	time 0.1740 (0.2258)	loss 0.8394 (0.8973)	grad_norm 1.4329 (1.6777)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:45:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:04:49 lr 0.000063	 wd 0.0000	time 0.1947 (0.2223)	loss 0.9375 (0.8972)	grad_norm 2.2386 (1.6908)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:46:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:23 lr 0.000063	 wd 0.0000	time 0.1720 (0.2192)	loss 0.9038 (0.8973)	grad_norm 1.7542 (1.7101)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:46:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:03:58 lr 0.000063	 wd 0.0000	time 0.1650 (0.2161)	loss 1.0859 (0.8977)	grad_norm 1.6286 (1.7199)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:46:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:03:34 lr 0.000063	 wd 0.0000	time 0.2132 (0.2139)	loss 0.9326 (0.8978)	grad_norm 1.3700 (1.7182)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:47:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:18 lr 0.000063	 wd 0.0000	time 1.1765 (0.2206)	loss 0.9268 (0.8969)	grad_norm 1.6176 (1.7098)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:47:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:02:54 lr 0.000062	 wd 0.0000	time 0.1639 (0.2181)	loss 0.9868 (0.8967)	grad_norm 1.4744 (1.7069)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:47:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:31 lr 0.000062	 wd 0.0000	time 0.1779 (0.2158)	loss 0.7832 (0.8967)	grad_norm 1.7616 (1.7058)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:48:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:08 lr 0.000062	 wd 0.0000	time 0.1676 (0.2138)	loss 0.8442 (0.8969)	grad_norm 1.4090 (1.7093)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:48:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:01:46 lr 0.000062	 wd 0.0000	time 0.2018 (0.2130)	loss 0.8833 (0.8972)	grad_norm 2.1907 (1.7093)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:48:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:26 lr 0.000062	 wd 0.0000	time 0.1690 (0.2142)	loss 0.9951 (0.8977)	grad_norm 1.5471 (1.7084)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:49:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:04 lr 0.000061	 wd 0.0000	time 0.1657 (0.2129)	loss 1.0127 (0.8977)	grad_norm 1.4650 (1.7109)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:49:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:42 lr 0.000061	 wd 0.0000	time 0.1745 (0.2115)	loss 0.8237 (0.8974)	grad_norm 1.9298 (1.7213)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:49:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:21 lr 0.000061	 wd 0.0000	time 0.1695 (0.2101)	loss 0.8491 (0.8970)	grad_norm 1.4612 (1.7232)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:50:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000061	 wd 0.0000	time 0.1600 (0.2087)	loss 0.8257 (0.8970)	grad_norm 1.4361 (1.7274)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:50:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 12 training takes 0:08:50
[2024-07-26 11:50:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 35.474 (35.474)	Loss 0.3640 (0.3640)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 11:51:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.958 Acc@5 97.494
[2024-07-26 11:51:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-26 11:51:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.99%
[2024-07-26 11:51:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][0/2502]	eta 11:32:04 lr 0.000061	 wd 0.0000	time 16.5967 (16.5967)	loss 0.7603 (0.7603)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:51:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:15:29 lr 0.000061	 wd 0.0000	time 0.2744 (0.3870)	loss 0.8135 (0.8933)	grad_norm 1.5192 (1.5965)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:52:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:12:52 lr 0.000060	 wd 0.0000	time 0.1773 (0.3354)	loss 0.7842 (0.8906)	grad_norm 1.5901 (1.6166)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:52:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:10:22 lr 0.000060	 wd 0.0000	time 0.1896 (0.2826)	loss 0.8730 (0.8864)	grad_norm 1.9309 (1.6520)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:52:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:08:57 lr 0.000060	 wd 0.0000	time 0.1605 (0.2556)	loss 0.9438 (0.8906)	grad_norm 1.8857 (1.6666)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:53:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:08:00 lr 0.000060	 wd 0.0000	time 0.1697 (0.2399)	loss 0.9023 (0.8891)	grad_norm 1.9724 (1.6612)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:53:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:08 lr 0.000060	 wd 0.0000	time 0.2433 (0.2570)	loss 0.8955 (0.8878)	grad_norm 1.5537 (1.6714)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:54:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:07:24 lr 0.000059	 wd 0.0000	time 0.1668 (0.2466)	loss 0.8252 (0.8881)	grad_norm 1.6741 (1.6682)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:54:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:06:44 lr 0.000059	 wd 0.0000	time 0.1626 (0.2378)	loss 0.9194 (0.8881)	grad_norm 1.5035 (1.6772)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:54:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:06:09 lr 0.000059	 wd 0.0000	time 0.1854 (0.2308)	loss 0.8638 (0.8898)	grad_norm 2.7601 (1.6800)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:54:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:05:41 lr 0.000059	 wd 0.0000	time 0.3352 (0.2276)	loss 0.9180 (0.8919)	grad_norm 1.5346 (1.6870)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:55:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:32 lr 0.000059	 wd 0.0000	time 0.1823 (0.2370)	loss 0.9019 (0.8919)	grad_norm 1.7423 (1.6936)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:55:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:01 lr 0.000058	 wd 0.0000	time 0.1654 (0.2319)	loss 1.0078 (0.8914)	grad_norm 1.1177 (1.6924)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 11:56:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:04:33 lr 0.000058	 wd 0.0000	time 0.1659 (0.2277)	loss 0.9634 (0.8917)	grad_norm 2.0046 (1.6926)	loss_scale 32768.0000 (17240.3505)	mem 8211MB
[2024-07-26 11:56:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:06 lr 0.000058	 wd 0.0000	time 0.1771 (0.2240)	loss 0.9150 (0.8908)	grad_norm 1.5409 (1.6872)	loss_scale 32768.0000 (18348.6767)	mem 8211MB
[2024-07-26 11:56:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:03:49 lr 0.000058	 wd 0.0000	time 0.7878 (0.2286)	loss 0.8398 (0.8921)	grad_norm 1.1353 (1.6885)	loss_scale 32768.0000 (19309.3245)	mem 8211MB
[2024-07-26 11:57:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:23 lr 0.000058	 wd 0.0000	time 0.1597 (0.2258)	loss 0.7241 (0.8926)	grad_norm 1.5522 (1.6878)	loss_scale 32768.0000 (20149.9663)	mem 8211MB
[2024-07-26 11:57:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:02:58 lr 0.000057	 wd 0.0000	time 0.1558 (0.2227)	loss 0.8701 (0.8933)	grad_norm 2.0590 (1.6885)	loss_scale 32768.0000 (20891.7672)	mem 8211MB
[2024-07-26 11:57:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:34 lr 0.000057	 wd 0.0000	time 0.1719 (0.2204)	loss 0.9004 (0.8938)	grad_norm 1.8393 (1.6961)	loss_scale 32768.0000 (21551.1916)	mem 8211MB
[2024-07-26 11:58:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:11 lr 0.000057	 wd 0.0000	time 0.1808 (0.2186)	loss 0.7778 (0.8933)	grad_norm 1.5397 (1.6979)	loss_scale 32768.0000 (22141.2393)	mem 8211MB
[2024-07-26 11:58:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:50 lr 0.000057	 wd 0.0000	time 0.1841 (0.2196)	loss 0.8916 (0.8929)	grad_norm 1.3145 (1.6994)	loss_scale 32768.0000 (22672.3118)	mem 8211MB
[2024-07-26 11:58:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:27 lr 0.000057	 wd 0.0000	time 0.1821 (0.2184)	loss 0.8979 (0.8932)	grad_norm 1.9868 (1.7036)	loss_scale 32768.0000 (23152.8301)	mem 8211MB
[2024-07-26 11:59:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:05 lr 0.000056	 wd 0.0000	time 0.1761 (0.2168)	loss 0.8193 (0.8929)	grad_norm 1.7199 (1.7109)	loss_scale 32768.0000 (23589.6847)	mem 8211MB
[2024-07-26 11:59:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:43 lr 0.000056	 wd 0.0000	time 0.1682 (0.2152)	loss 0.9326 (0.8930)	grad_norm 1.6100 (1.7098)	loss_scale 32768.0000 (23988.5684)	mem 8211MB
[2024-07-26 11:59:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:21 lr 0.000056	 wd 0.0000	time 0.1950 (0.2141)	loss 0.8623 (0.8931)	grad_norm 1.4560 (1.7087)	loss_scale 32768.0000 (24354.2257)	mem 8211MB
[2024-07-26 12:00:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000056	 wd 0.0000	time 0.1587 (0.2126)	loss 0.8354 (0.8929)	grad_norm 1.9137 (1.7122)	loss_scale 32768.0000 (24690.6421)	mem 8211MB
[2024-07-26 12:00:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 13 training takes 0:09:06
[2024-07-26 12:00:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 24.629 (24.629)	Loss 0.3655 (0.3655)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 12:00:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.978 Acc@5 97.524
[2024-07-26 12:00:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-26 12:00:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.99%
[2024-07-26 12:01:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][0/2502]	eta 11:57:21 lr 0.000056	 wd 0.0000	time 17.2028 (17.2028)	loss 0.8652 (0.8652)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:01:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:18:30 lr 0.000055	 wd 0.0000	time 0.1921 (0.4621)	loss 0.8794 (0.8943)	grad_norm 2.1990 (1.8982)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:02:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:12:19 lr 0.000055	 wd 0.0000	time 0.1709 (0.3213)	loss 0.8813 (0.8872)	grad_norm 1.6642 (1.7914)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:02:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:10:00 lr 0.000055	 wd 0.0000	time 0.1813 (0.2727)	loss 0.9585 (0.8897)	grad_norm 1.6846 (1.7549)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:02:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:08:41 lr 0.000055	 wd 0.0000	time 0.1602 (0.2483)	loss 1.0859 (0.8899)	grad_norm 1.2770 (1.7217)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:02:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:07:50 lr 0.000055	 wd 0.0000	time 0.1959 (0.2351)	loss 0.8940 (0.8892)	grad_norm 1.3870 (1.7010)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:03:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:07:51 lr 0.000054	 wd 0.0000	time 0.2581 (0.2482)	loss 0.8286 (0.8911)	grad_norm 1.2662 (1.6916)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:03:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:09 lr 0.000054	 wd 0.0000	time 0.1819 (0.2385)	loss 0.7954 (0.8933)	grad_norm 1.1663 (1.6833)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:04:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:06:32 lr 0.000054	 wd 0.0000	time 0.1765 (0.2307)	loss 0.9253 (0.8911)	grad_norm 1.5625 (1.6760)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:04:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:05:59 lr 0.000054	 wd 0.0000	time 0.1708 (0.2246)	loss 0.9604 (0.8907)	grad_norm 1.6692 (1.6725)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:04:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:05:37 lr 0.000054	 wd 0.0000	time 0.3597 (0.2250)	loss 1.0029 (0.8903)	grad_norm 1.6207 (inf)	loss_scale 16384.0000 (31589.5305)	mem 8211MB
[2024-07-26 12:05:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:25 lr 0.000053	 wd 0.0000	time 0.1854 (0.2319)	loss 0.7891 (0.8908)	grad_norm 1.5783 (inf)	loss_scale 16384.0000 (30208.4650)	mem 8211MB
[2024-07-26 12:05:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:04:55 lr 0.000053	 wd 0.0000	time 0.1612 (0.2273)	loss 0.9756 (0.8915)	grad_norm 1.5514 (inf)	loss_scale 16384.0000 (29057.3855)	mem 8211MB
[2024-07-26 12:05:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:04:28 lr 0.000053	 wd 0.0000	time 0.1763 (0.2233)	loss 0.9482 (0.8914)	grad_norm 1.7751 (inf)	loss_scale 16384.0000 (28083.2590)	mem 8211MB
[2024-07-26 12:06:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:02 lr 0.000053	 wd 0.0000	time 0.1551 (0.2202)	loss 0.8574 (0.8907)	grad_norm 2.7031 (inf)	loss_scale 16384.0000 (27248.1941)	mem 8211MB
[2024-07-26 12:06:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:03:41 lr 0.000053	 wd 0.0000	time 0.1585 (0.2207)	loss 0.9707 (0.8905)	grad_norm 2.4823 (inf)	loss_scale 16384.0000 (26524.3971)	mem 8211MB
[2024-07-26 12:06:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:17 lr 0.000052	 wd 0.0000	time 0.1714 (0.2184)	loss 0.9360 (0.8910)	grad_norm 1.3678 (inf)	loss_scale 16384.0000 (25891.0181)	mem 8211MB
[2024-07-26 12:07:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:02:53 lr 0.000052	 wd 0.0000	time 0.1709 (0.2160)	loss 1.0029 (0.8912)	grad_norm 1.3224 (inf)	loss_scale 16384.0000 (25332.1105)	mem 8211MB
[2024-07-26 12:07:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:30 lr 0.000052	 wd 0.0000	time 0.1830 (0.2140)	loss 0.9873 (0.8912)	grad_norm 1.4351 (inf)	loss_scale 16384.0000 (24835.2693)	mem 8211MB
[2024-07-26 12:07:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:07 lr 0.000052	 wd 0.0000	time 0.1612 (0.2123)	loss 0.9009 (0.8913)	grad_norm 1.3661 (inf)	loss_scale 16384.0000 (24390.6996)	mem 8211MB
[2024-07-26 12:08:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:01:46 lr 0.000052	 wd 0.0000	time 0.1923 (0.2116)	loss 0.9395 (0.8916)	grad_norm 1.5331 (inf)	loss_scale 16384.0000 (23990.5647)	mem 8211MB
[2024-07-26 12:08:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:25 lr 0.000051	 wd 0.0000	time 0.1702 (0.2121)	loss 0.9028 (0.8922)	grad_norm 1.5916 (inf)	loss_scale 16384.0000 (23628.5198)	mem 8211MB
[2024-07-26 12:08:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:03 lr 0.000051	 wd 0.0000	time 0.1639 (0.2107)	loss 0.8154 (0.8929)	grad_norm 1.3472 (inf)	loss_scale 16384.0000 (23299.3730)	mem 8211MB
[2024-07-26 12:09:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:42 lr 0.000051	 wd 0.0000	time 0.1715 (0.2094)	loss 0.9443 (0.8931)	grad_norm 2.6192 (inf)	loss_scale 16384.0000 (22998.8353)	mem 8211MB
[2024-07-26 12:09:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:21 lr 0.000051	 wd 0.0000	time 0.1984 (0.2082)	loss 0.9058 (0.8933)	grad_norm 1.3710 (inf)	loss_scale 16384.0000 (22723.3319)	mem 8211MB
[2024-07-26 12:09:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000051	 wd 0.0000	time 0.1581 (0.2071)	loss 0.8545 (0.8933)	grad_norm 1.6958 (inf)	loss_scale 16384.0000 (22469.8601)	mem 8211MB
[2024-07-26 12:09:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 14 training takes 0:08:49
[2024-07-26 12:10:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 31.147 (31.147)	Loss 0.3633 (0.3633)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 8211MB
[2024-07-26 12:10:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.952 Acc@5 97.494
[2024-07-26 12:10:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-26 12:10:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.99%
[2024-07-26 12:10:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][0/2502]	eta 11:09:18 lr 0.000051	 wd 0.0000	time 16.0506 (16.0506)	loss 0.7847 (0.7847)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:11:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:18:42 lr 0.000050	 wd 0.0000	time 0.1917 (0.4671)	loss 0.8931 (0.8914)	grad_norm 1.4514 (1.6639)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:11:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:12:29 lr 0.000050	 wd 0.0000	time 0.1802 (0.3256)	loss 1.1279 (0.8945)	grad_norm 1.2244 (1.7169)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:12:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:10:07 lr 0.000050	 wd 0.0000	time 0.1798 (0.2760)	loss 0.8188 (0.8949)	grad_norm 1.5544 (1.7252)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:12:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:08:47 lr 0.000050	 wd 0.0000	time 0.1622 (0.2510)	loss 0.7144 (0.8947)	grad_norm 1.9516 (1.7006)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:12:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:07:57 lr 0.000049	 wd 0.0000	time 0.3159 (0.2385)	loss 0.8491 (0.8952)	grad_norm 1.5182 (1.7177)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:13:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:08:29 lr 0.000049	 wd 0.0000	time 0.1865 (0.2681)	loss 0.8306 (0.8948)	grad_norm 1.3981 (1.7027)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:13:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:39 lr 0.000049	 wd 0.0000	time 0.1733 (0.2551)	loss 0.9038 (0.8941)	grad_norm 1.4435 (1.6947)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:13:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:06:57 lr 0.000049	 wd 0.0000	time 0.1768 (0.2452)	loss 0.8823 (0.8934)	grad_norm 1.6622 (1.6941)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:14:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:22 lr 0.000049	 wd 0.0000	time 0.1965 (0.2385)	loss 0.8623 (0.8935)	grad_norm 1.2849 (1.7008)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:14:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:06:15 lr 0.000048	 wd 0.0000	time 0.2014 (0.2503)	loss 0.8379 (0.8937)	grad_norm 1.5186 (1.7027)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:15:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:41 lr 0.000048	 wd 0.0000	time 0.1733 (0.2437)	loss 0.9629 (0.8923)	grad_norm 1.8464 (1.7005)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:15:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:10 lr 0.000048	 wd 0.0000	time 0.1890 (0.2382)	loss 0.7490 (0.8924)	grad_norm 1.4351 (1.7025)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:15:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:04:40 lr 0.000048	 wd 0.0000	time 0.2125 (0.2333)	loss 0.9204 (0.8929)	grad_norm 1.8287 (1.7091)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:16:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:15 lr 0.000048	 wd 0.0000	time 0.2766 (0.2316)	loss 0.8623 (0.8926)	grad_norm 1.4835 (1.7071)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:16:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:03:53 lr 0.000047	 wd 0.0000	time 0.1918 (0.2334)	loss 0.8779 (0.8922)	grad_norm 2.0007 (1.6990)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:16:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:27 lr 0.000047	 wd 0.0000	time 0.1623 (0.2298)	loss 0.9199 (0.8919)	grad_norm 1.6312 (1.6949)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:17:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:01 lr 0.000047	 wd 0.0000	time 0.1817 (0.2267)	loss 0.9058 (0.8916)	grad_norm 1.4631 (1.6890)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:17:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:37 lr 0.000047	 wd 0.0000	time 0.1811 (0.2242)	loss 0.9683 (0.8926)	grad_norm 1.3169 (1.6924)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:17:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:14 lr 0.000047	 wd 0.0000	time 0.1734 (0.2231)	loss 0.9922 (0.8926)	grad_norm 1.7144 (1.6917)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:18:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:01:52 lr 0.000046	 wd 0.0000	time 0.1834 (0.2231)	loss 1.0029 (0.8926)	grad_norm 1.9390 (1.6921)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:18:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:28 lr 0.000046	 wd 0.0000	time 0.1899 (0.2211)	loss 0.9521 (0.8924)	grad_norm 1.6072 (1.6899)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:18:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:06 lr 0.000046	 wd 0.0000	time 0.1686 (0.2193)	loss 0.8550 (0.8927)	grad_norm 1.3011 (1.6865)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:18:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:44 lr 0.000046	 wd 0.0000	time 0.1745 (0.2178)	loss 1.0195 (0.8924)	grad_norm 1.8778 (1.6818)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:19:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:22 lr 0.000046	 wd 0.0000	time 0.2063 (0.2180)	loss 0.8623 (0.8922)	grad_norm 1.5741 (1.6822)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:19:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000045	 wd 0.0000	time 0.1568 (0.2162)	loss 1.0664 (0.8925)	grad_norm 1.8502 (1.6815)	loss_scale 32768.0000 (16868.7725)	mem 8211MB
[2024-07-26 12:19:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 15 training takes 0:09:12
[2024-07-26 12:19:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_15.pth saving......
[2024-07-26 12:19:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_15.pth saved !!!
[2024-07-26 12:20:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 18.466 (18.466)	Loss 0.3613 (0.3613)	Acc@1 91.211 (91.211)	Acc@5 98.828 (98.828)	Mem 8211MB
[2024-07-26 12:20:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 85.002 Acc@5 97.508
[2024-07-26 12:20:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-26 12:20:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 85.00%
[2024-07-26 12:20:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saving......
[2024-07-26 12:20:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-26 12:21:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][0/2502]	eta 23:25:01 lr 0.000045	 wd 0.0000	time 33.6938 (33.6938)	loss 0.8076 (0.8076)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:21:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:21:04 lr 0.000045	 wd 0.0000	time 0.1955 (0.5265)	loss 1.0801 (0.9045)	grad_norm 1.4244 (1.7478)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:21:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:13:29 lr 0.000045	 wd 0.0000	time 0.1673 (0.3517)	loss 0.9346 (0.9019)	grad_norm 1.8870 (1.7363)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:21:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:10:45 lr 0.000045	 wd 0.0000	time 0.1546 (0.2932)	loss 0.8892 (0.9007)	grad_norm 1.4880 (1.7177)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:22:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:09:27 lr 0.000045	 wd 0.0000	time 0.2965 (0.2698)	loss 0.9609 (0.8981)	grad_norm 1.6048 (1.7030)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:22:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:09:59 lr 0.000044	 wd 0.0000	time 0.1755 (0.2992)	loss 0.8530 (0.8957)	grad_norm 1.7572 (1.7054)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:23:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:50 lr 0.000044	 wd 0.0000	time 0.1730 (0.2790)	loss 0.9478 (0.8970)	grad_norm 1.5762 (1.6973)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:23:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:56 lr 0.000044	 wd 0.0000	time 0.1689 (0.2642)	loss 0.9204 (0.8960)	grad_norm 1.4675 (1.6957)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:23:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:07:12 lr 0.000044	 wd 0.0000	time 0.2355 (0.2541)	loss 1.0420 (0.8952)	grad_norm 1.3987 (1.6878)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:24:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:07:08 lr 0.000043	 wd 0.0000	time 0.1979 (0.2675)	loss 0.8564 (0.8968)	grad_norm 1.5952 (1.6975)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:24:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:06:28 lr 0.000043	 wd 0.0000	time 0.1743 (0.2584)	loss 0.9004 (0.8983)	grad_norm 1.5773 (1.7053)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 12:25:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:51 lr 0.000043	 wd 0.0000	time 0.1598 (0.2508)	loss 0.8135 (0.8970)	grad_norm 1.4512 (inf)	loss_scale 16384.0000 (32232.2834)	mem 8211MB
[2024-07-26 12:25:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:18 lr 0.000043	 wd 0.0000	time 0.1899 (0.2446)	loss 0.9927 (0.8979)	grad_norm 1.1677 (inf)	loss_scale 16384.0000 (30912.6928)	mem 8211MB
[2024-07-26 12:25:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:04:49 lr 0.000043	 wd 0.0000	time 0.1731 (0.2410)	loss 0.8691 (0.8962)	grad_norm 1.6289 (inf)	loss_scale 16384.0000 (29795.9600)	mem 8211MB
[2024-07-26 12:26:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:23 lr 0.000042	 wd 0.0000	time 0.1859 (0.2390)	loss 0.8530 (0.8953)	grad_norm 1.4398 (inf)	loss_scale 16384.0000 (28838.6467)	mem 8211MB
[2024-07-26 12:26:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:03:55 lr 0.000042	 wd 0.0000	time 0.1849 (0.2351)	loss 0.9155 (0.8949)	grad_norm 1.6354 (inf)	loss_scale 16384.0000 (28008.8901)	mem 8211MB
[2024-07-26 12:26:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:28 lr 0.000042	 wd 0.0000	time 0.1550 (0.2316)	loss 0.8770 (0.8949)	grad_norm 1.5045 (inf)	loss_scale 16384.0000 (27282.7883)	mem 8211MB
[2024-07-26 12:26:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:03 lr 0.000042	 wd 0.0000	time 0.2172 (0.2286)	loss 0.7812 (0.8954)	grad_norm 1.6519 (inf)	loss_scale 16384.0000 (26642.0600)	mem 8211MB
[2024-07-26 12:27:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:39 lr 0.000042	 wd 0.0000	time 0.1786 (0.2275)	loss 0.9531 (0.8958)	grad_norm 1.5079 (inf)	loss_scale 16384.0000 (26072.4842)	mem 8211MB
[2024-07-26 12:27:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:16 lr 0.000041	 wd 0.0000	time 0.1756 (0.2272)	loss 0.9736 (0.8959)	grad_norm 1.6036 (inf)	loss_scale 16384.0000 (25562.8322)	mem 8211MB
[2024-07-26 12:27:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:01:52 lr 0.000041	 wd 0.0000	time 0.1647 (0.2250)	loss 0.8340 (0.8953)	grad_norm 1.2611 (inf)	loss_scale 16384.0000 (25104.1199)	mem 8211MB
[2024-07-26 12:28:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:29 lr 0.000041	 wd 0.0000	time 0.1632 (0.2229)	loss 0.7930 (0.8950)	grad_norm 1.2597 (inf)	loss_scale 16384.0000 (24689.0738)	mem 8211MB
[2024-07-26 12:28:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:06 lr 0.000041	 wd 0.0000	time 0.1549 (0.2210)	loss 0.8081 (0.8951)	grad_norm 1.2701 (inf)	loss_scale 16384.0000 (24311.7419)	mem 8211MB
[2024-07-26 12:28:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:44 lr 0.000041	 wd 0.0000	time 0.2055 (0.2199)	loss 0.9590 (0.8950)	grad_norm 2.1432 (inf)	loss_scale 16384.0000 (23967.2073)	mem 8211MB
[2024-07-26 12:29:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:22 lr 0.000040	 wd 0.0000	time 0.1600 (0.2196)	loss 0.7798 (0.8946)	grad_norm 1.5496 (inf)	loss_scale 16384.0000 (23651.3719)	mem 8211MB
[2024-07-26 12:29:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1610 (0.2177)	loss 0.8667 (0.8942)	grad_norm 1.4847 (inf)	loss_scale 16384.0000 (23360.7933)	mem 8211MB
[2024-07-26 12:29:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 16 training takes 0:09:13
[2024-07-26 12:30:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 19.661 (19.661)	Loss 0.3611 (0.3611)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 12:30:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.936 Acc@5 97.520
[2024-07-26 12:30:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-26 12:30:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 85.00%
[2024-07-26 12:30:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][0/2502]	eta 1 day, 0:43:13 lr 0.000040	 wd 0.0000	time 35.5691 (35.5691)	loss 0.8306 (0.8306)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:31:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:21:31 lr 0.000040	 wd 0.0000	time 0.1867 (0.5377)	loss 0.9658 (0.8908)	grad_norm 1.6934 (1.6658)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:31:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:13:41 lr 0.000040	 wd 0.0000	time 0.1702 (0.3570)	loss 1.0625 (0.8985)	grad_norm 1.2175 (1.7492)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:31:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:53 lr 0.000040	 wd 0.0000	time 0.1786 (0.2967)	loss 0.9102 (0.8978)	grad_norm 2.1032 (1.7241)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:32:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:10:57 lr 0.000039	 wd 0.0000	time 0.3077 (0.3130)	loss 0.8604 (0.8913)	grad_norm 1.7005 (1.7183)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:32:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:09:46 lr 0.000039	 wd 0.0000	time 0.1782 (0.2928)	loss 0.8179 (0.8931)	grad_norm 1.4084 (1.6891)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:33:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:39 lr 0.000039	 wd 0.0000	time 0.1598 (0.2732)	loss 0.9351 (0.8946)	grad_norm 1.7383 (1.6916)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:33:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:47 lr 0.000039	 wd 0.0000	time 0.1752 (0.2594)	loss 0.7700 (0.8931)	grad_norm 1.5376 (1.6832)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:33:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:07:11 lr 0.000039	 wd 0.0000	time 0.2790 (0.2535)	loss 0.8047 (0.8930)	grad_norm 1.3255 (1.6744)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:34:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:52 lr 0.000038	 wd 0.0000	time 0.1705 (0.2574)	loss 0.8501 (0.8931)	grad_norm 1.5584 (1.6686)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:34:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:14 lr 0.000038	 wd 0.0000	time 0.1597 (0.2493)	loss 0.9531 (0.8925)	grad_norm 1.7571 (1.6644)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:34:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:40 lr 0.000038	 wd 0.0000	time 0.1747 (0.2425)	loss 0.9502 (0.8940)	grad_norm 1.5053 (1.6632)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:35:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:08 lr 0.000038	 wd 0.0000	time 0.1889 (0.2372)	loss 0.9248 (0.8946)	grad_norm 1.7410 (1.6652)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:35:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:04:53 lr 0.000038	 wd 0.0000	time 0.2000 (0.2442)	loss 1.0156 (0.8931)	grad_norm 1.5404 (1.6627)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:35:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:24 lr 0.000037	 wd 0.0000	time 0.1591 (0.2396)	loss 0.8418 (0.8938)	grad_norm 1.5041 (1.6674)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:36:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:03:55 lr 0.000037	 wd 0.0000	time 0.1850 (0.2354)	loss 0.8608 (0.8939)	grad_norm 1.3518 (1.6611)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:36:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:29 lr 0.000037	 wd 0.0000	time 0.1950 (0.2318)	loss 0.8062 (0.8936)	grad_norm 2.0333 (1.6625)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:36:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:03 lr 0.000037	 wd 0.0000	time 0.1748 (0.2290)	loss 1.1514 (0.8938)	grad_norm 1.3860 (1.6652)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:37:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:40 lr 0.000037	 wd 0.0000	time 0.2745 (0.2293)	loss 0.8452 (0.8941)	grad_norm 1.3670 (1.6653)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:37:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:16 lr 0.000036	 wd 0.0000	time 0.1804 (0.2273)	loss 0.8062 (0.8943)	grad_norm 1.6825 (1.6638)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:37:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:01:52 lr 0.000036	 wd 0.0000	time 0.1860 (0.2250)	loss 0.8799 (0.8938)	grad_norm 2.1605 (1.6596)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:38:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:29 lr 0.000036	 wd 0.0000	time 0.1783 (0.2228)	loss 0.8940 (0.8939)	grad_norm 2.5920 (1.6598)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:38:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:06 lr 0.000036	 wd 0.0000	time 0.2181 (0.2214)	loss 0.9194 (0.8940)	grad_norm 1.8351 (1.6593)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:38:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:44 lr 0.000036	 wd 0.0000	time 0.1607 (0.2216)	loss 0.8882 (0.8937)	grad_norm 1.7247 (1.6610)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:39:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:22 lr 0.000035	 wd 0.0000	time 0.1686 (0.2201)	loss 0.8027 (0.8945)	grad_norm 1.7306 (1.6576)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:39:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1586 (0.2181)	loss 1.0420 (0.8950)	grad_norm 2.0851 (1.6573)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:39:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 17 training takes 0:09:15
[2024-07-26 12:39:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 21.758 (21.758)	Loss 0.3650 (0.3650)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 12:40:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.906 Acc@5 97.504
[2024-07-26 12:40:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-26 12:40:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 85.00%
[2024-07-26 12:40:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][0/2502]	eta 20:46:04 lr 0.000035	 wd 0.0000	time 29.8820 (29.8820)	loss 0.9204 (0.9204)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:41:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:18:59 lr 0.000035	 wd 0.0000	time 0.1680 (0.4744)	loss 0.8779 (0.8856)	grad_norm 2.0824 (1.7110)	loss_scale 32768.0000 (22872.7129)	mem 8211MB
[2024-07-26 12:41:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:12:28 lr 0.000035	 wd 0.0000	time 0.1575 (0.3253)	loss 1.0127 (0.8858)	grad_norm 1.3659 (1.6691)	loss_scale 32768.0000 (27795.7413)	mem 8211MB
[2024-07-26 12:41:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:12:07 lr 0.000035	 wd 0.0000	time 3.3034 (0.3304)	loss 0.9585 (0.8904)	grad_norm 1.4833 (1.6458)	loss_scale 32768.0000 (29447.6545)	mem 8211MB
[2024-07-26 12:42:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:10:46 lr 0.000034	 wd 0.0000	time 0.1694 (0.3077)	loss 0.9141 (0.8938)	grad_norm 1.6169 (1.6590)	loss_scale 32768.0000 (30275.6708)	mem 8211MB
[2024-07-26 12:42:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:09:23 lr 0.000034	 wd 0.0000	time 0.1601 (0.2817)	loss 0.8223 (0.8942)	grad_norm 1.6153 (1.6401)	loss_scale 32768.0000 (30773.1417)	mem 8211MB
[2024-07-26 12:42:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:08:22 lr 0.000034	 wd 0.0000	time 0.1594 (0.2640)	loss 0.8076 (0.8927)	grad_norm 1.5297 (1.6344)	loss_scale 32768.0000 (31105.0649)	mem 8211MB
[2024-07-26 12:43:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:07:42 lr 0.000034	 wd 0.0000	time 0.3877 (0.2566)	loss 1.0801 (0.8924)	grad_norm 1.7382 (1.6373)	loss_scale 32768.0000 (31342.2882)	mem 8211MB
[2024-07-26 12:43:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:40 lr 0.000034	 wd 0.0000	time 0.1682 (0.2705)	loss 0.9351 (0.8902)	grad_norm 2.0448 (inf)	loss_scale 16384.0000 (29515.7453)	mem 8211MB
[2024-07-26 12:44:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:06:56 lr 0.000033	 wd 0.0000	time 0.1795 (0.2601)	loss 0.9204 (0.8900)	grad_norm 1.7820 (inf)	loss_scale 16384.0000 (28058.2819)	mem 8211MB
[2024-07-26 12:44:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:18 lr 0.000033	 wd 0.0000	time 0.1726 (0.2518)	loss 0.8037 (0.8898)	grad_norm 1.6375 (inf)	loss_scale 16384.0000 (26892.0200)	mem 8211MB
[2024-07-26 12:44:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:44 lr 0.000033	 wd 0.0000	time 0.1887 (0.2457)	loss 0.8911 (0.8912)	grad_norm 1.1512 (inf)	loss_scale 16384.0000 (25937.6131)	mem 8211MB
[2024-07-26 12:45:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:38 lr 0.000033	 wd 0.0000	time 0.1830 (0.2601)	loss 1.1699 (0.8906)	grad_norm 1.7246 (inf)	loss_scale 16384.0000 (25142.1415)	mem 8211MB
[2024-07-26 12:45:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:05:05 lr 0.000033	 wd 0.0000	time 0.1918 (0.2538)	loss 0.8022 (0.8915)	grad_norm 1.4990 (inf)	loss_scale 16384.0000 (24468.9562)	mem 8211MB
[2024-07-26 12:46:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:33 lr 0.000032	 wd 0.0000	time 0.1939 (0.2483)	loss 0.8701 (0.8909)	grad_norm 1.7574 (inf)	loss_scale 16384.0000 (23891.8715)	mem 8211MB
[2024-07-26 12:46:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:04:04 lr 0.000032	 wd 0.0000	time 0.1944 (0.2438)	loss 0.8389 (0.8913)	grad_norm 1.5826 (inf)	loss_scale 16384.0000 (23391.6802)	mem 8211MB
[2024-07-26 12:46:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:38 lr 0.000032	 wd 0.0000	time 0.1999 (0.2419)	loss 0.8682 (0.8911)	grad_norm 1.8802 (inf)	loss_scale 16384.0000 (22953.9738)	mem 8211MB
[2024-07-26 12:47:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:11 lr 0.000032	 wd 0.0000	time 0.1667 (0.2388)	loss 1.0332 (0.8910)	grad_norm 1.7611 (inf)	loss_scale 16384.0000 (22567.7319)	mem 8211MB
[2024-07-26 12:47:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:45 lr 0.000032	 wd 0.0000	time 0.1604 (0.2357)	loss 0.9570 (0.8913)	grad_norm 1.5738 (inf)	loss_scale 16384.0000 (22224.3820)	mem 8211MB
[2024-07-26 12:47:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:20 lr 0.000032	 wd 0.0000	time 0.1839 (0.2328)	loss 1.0723 (0.8914)	grad_norm 1.4177 (inf)	loss_scale 16384.0000 (21917.1552)	mem 8211MB
[2024-07-26 12:48:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:01:55 lr 0.000031	 wd 0.0000	time 0.1748 (0.2305)	loss 1.0293 (0.8922)	grad_norm 1.2488 (inf)	loss_scale 16384.0000 (21640.6357)	mem 8211MB
[2024-07-26 12:48:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:32 lr 0.000031	 wd 0.0000	time 0.1747 (0.2312)	loss 0.7632 (0.8921)	grad_norm 1.5492 (inf)	loss_scale 16384.0000 (21390.4388)	mem 8211MB
[2024-07-26 12:48:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:09 lr 0.000031	 wd 0.0000	time 0.1736 (0.2297)	loss 0.8018 (0.8926)	grad_norm 1.3496 (inf)	loss_scale 16384.0000 (21162.9768)	mem 8211MB
[2024-07-26 12:49:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:45 lr 0.000031	 wd 0.0000	time 0.1622 (0.2276)	loss 0.7925 (0.8929)	grad_norm 1.7665 (inf)	loss_scale 16384.0000 (20955.2855)	mem 8211MB
[2024-07-26 12:49:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:23 lr 0.000031	 wd 0.0000	time 0.1553 (0.2256)	loss 0.9214 (0.8927)	grad_norm 1.5832 (inf)	loss_scale 16384.0000 (20764.8946)	mem 8211MB
[2024-07-26 12:49:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000030	 wd 0.0000	time 0.1579 (0.2234)	loss 0.8662 (0.8930)	grad_norm 1.4255 (inf)	loss_scale 16384.0000 (20589.7289)	mem 8211MB
[2024-07-26 12:49:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 18 training takes 0:09:26
[2024-07-26 12:50:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 36.247 (36.247)	Loss 0.3660 (0.3660)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 12:50:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.940 Acc@5 97.530
[2024-07-26 12:50:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-26 12:50:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 85.00%
[2024-07-26 12:50:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][0/2502]	eta 11:10:46 lr 0.000030	 wd 0.0000	time 16.0857 (16.0857)	loss 0.8032 (0.8032)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:51:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:13:57 lr 0.000030	 wd 0.0000	time 0.2047 (0.3487)	loss 1.0527 (0.9019)	grad_norm 1.4735 (1.6234)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:51:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:12:38 lr 0.000030	 wd 0.0000	time 0.1596 (0.3297)	loss 0.7827 (0.9003)	grad_norm 1.9303 (1.5950)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:52:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:10:13 lr 0.000030	 wd 0.0000	time 0.1784 (0.2787)	loss 0.8442 (0.8980)	grad_norm 1.2613 (1.6158)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:52:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:08:51 lr 0.000030	 wd 0.0000	time 0.1715 (0.2531)	loss 0.9629 (0.8965)	grad_norm 1.2937 (1.6135)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:52:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:07:55 lr 0.000029	 wd 0.0000	time 0.1708 (0.2374)	loss 0.9180 (0.8951)	grad_norm 1.4159 (1.6060)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:53:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:07:32 lr 0.000029	 wd 0.0000	time 0.2980 (0.2377)	loss 0.8633 (0.8950)	grad_norm 1.9039 (1.5944)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:53:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:07:23 lr 0.000029	 wd 0.0000	time 0.1549 (0.2459)	loss 0.9248 (0.8952)	grad_norm 1.4757 (1.5930)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:53:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:06:43 lr 0.000029	 wd 0.0000	time 0.1781 (0.2373)	loss 0.8047 (0.8944)	grad_norm 1.4404 (1.5902)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:54:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:06:09 lr 0.000029	 wd 0.0000	time 0.1593 (0.2307)	loss 0.8062 (0.8930)	grad_norm 1.9755 (1.5840)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:54:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:05:38 lr 0.000028	 wd 0.0000	time 0.1788 (0.2256)	loss 0.8237 (0.8930)	grad_norm 1.6537 (1.5929)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:55:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:34 lr 0.000028	 wd 0.0000	time 0.1960 (0.2384)	loss 0.9531 (0.8934)	grad_norm 2.0082 (1.5958)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:55:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:04 lr 0.000028	 wd 0.0000	time 0.1786 (0.2336)	loss 0.9023 (0.8939)	grad_norm 1.6009 (1.6019)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:55:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:04:35 lr 0.000028	 wd 0.0000	time 0.1599 (0.2292)	loss 0.7378 (0.8942)	grad_norm 1.7083 (1.5998)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:55:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:08 lr 0.000028	 wd 0.0000	time 0.1602 (0.2253)	loss 0.8511 (0.8945)	grad_norm 1.4441 (1.5989)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:56:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:03:43 lr 0.000028	 wd 0.0000	time 0.1827 (0.2231)	loss 0.9443 (0.8949)	grad_norm 1.8318 (1.5972)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:56:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:20 lr 0.000027	 wd 0.0000	time 0.2275 (0.2224)	loss 0.8491 (0.8949)	grad_norm 1.7374 (1.5969)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:56:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:02:56 lr 0.000027	 wd 0.0000	time 0.1696 (0.2201)	loss 0.8062 (0.8946)	grad_norm 1.5552 (1.5960)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:57:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:33 lr 0.000027	 wd 0.0000	time 0.1633 (0.2179)	loss 0.7578 (0.8950)	grad_norm 1.7189 (1.5939)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:57:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:10 lr 0.000027	 wd 0.0000	time 0.1755 (0.2161)	loss 0.8838 (0.8946)	grad_norm 1.6040 (1.5985)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:57:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:48 lr 0.000027	 wd 0.0000	time 0.2039 (0.2152)	loss 0.9678 (0.8940)	grad_norm 1.6805 (1.5981)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:58:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:26 lr 0.000026	 wd 0.0000	time 0.1611 (0.2159)	loss 1.0625 (0.8935)	grad_norm 1.8531 (1.5977)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:58:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:04 lr 0.000026	 wd 0.0000	time 0.1795 (0.2145)	loss 0.8721 (0.8931)	grad_norm 2.7715 (1.5993)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 12:58:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:43 lr 0.000026	 wd 0.0000	time 0.1587 (0.2130)	loss 0.9121 (0.8935)	grad_norm 1.3153 (1.5966)	loss_scale 32768.0000 (17096.0382)	mem 8211MB
[2024-07-26 12:59:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:21 lr 0.000026	 wd 0.0000	time 0.1882 (0.2117)	loss 1.0771 (0.8932)	grad_norm 2.0989 (1.5966)	loss_scale 32768.0000 (17748.7647)	mem 8211MB
[2024-07-26 12:59:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1578 (0.2102)	loss 0.8257 (0.8928)	grad_norm 1.6661 (1.5972)	loss_scale 32768.0000 (18349.2939)	mem 8211MB
[2024-07-26 12:59:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 19 training takes 0:08:53
[2024-07-26 13:00:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 37.920 (37.920)	Loss 0.3657 (0.3657)	Acc@1 91.211 (91.211)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 13:00:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.948 Acc@5 97.514
[2024-07-26 13:00:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-26 13:00:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 85.00%
[2024-07-26 13:00:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][0/2502]	eta 11:22:24 lr 0.000026	 wd 0.0000	time 16.3649 (16.3649)	loss 1.0020 (1.0020)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:01:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:19:49 lr 0.000026	 wd 0.0000	time 0.1874 (0.4951)	loss 0.9834 (0.9056)	grad_norm 1.4715 (1.6262)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:01:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:13:07 lr 0.000025	 wd 0.0000	time 0.1826 (0.3420)	loss 1.0186 (0.8995)	grad_norm 1.7200 (1.6374)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:01:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:10:31 lr 0.000025	 wd 0.0000	time 0.1785 (0.2868)	loss 0.7876 (0.8976)	grad_norm 1.4652 (1.6289)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:02:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:09:03 lr 0.000025	 wd 0.0000	time 0.1656 (0.2585)	loss 0.8159 (0.8927)	grad_norm 1.4895 (1.6163)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:02:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:08:08 lr 0.000025	 wd 0.0000	time 0.2132 (0.2438)	loss 0.8765 (0.8941)	grad_norm 1.4859 (1.5986)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:03:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:08:31 lr 0.000025	 wd 0.0000	time 0.1838 (0.2689)	loss 0.8447 (0.8936)	grad_norm 1.7108 (1.5981)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:03:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:40 lr 0.000025	 wd 0.0000	time 0.1612 (0.2557)	loss 0.8052 (0.8929)	grad_norm 1.1634 (1.6131)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:03:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:06:58 lr 0.000024	 wd 0.0000	time 0.1894 (0.2457)	loss 0.8906 (0.8936)	grad_norm 1.5513 (1.6083)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:04:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:21 lr 0.000024	 wd 0.0000	time 0.1969 (0.2381)	loss 1.0264 (0.8934)	grad_norm 1.7178 (1.6081)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:04:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:11 lr 0.000024	 wd 0.0000	time 0.2679 (0.2472)	loss 0.8340 (0.8949)	grad_norm 1.6143 (1.6017)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:04:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:41 lr 0.000024	 wd 0.0000	time 0.1668 (0.2437)	loss 0.8130 (0.8945)	grad_norm 2.1323 (1.5943)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:05:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:10 lr 0.000024	 wd 0.0000	time 0.1740 (0.2382)	loss 0.7642 (0.8938)	grad_norm 1.9555 (1.5978)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:05:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:04:40 lr 0.000023	 wd 0.0000	time 0.1617 (0.2333)	loss 0.8296 (0.8926)	grad_norm 1.3750 (1.5886)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:05:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:13 lr 0.000023	 wd 0.0000	time 0.1978 (0.2301)	loss 0.9062 (0.8929)	grad_norm 1.5616 (1.5868)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:06:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:03:49 lr 0.000023	 wd 0.0000	time 0.2162 (0.2291)	loss 0.9331 (0.8924)	grad_norm 1.4588 (1.5835)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:06:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:24 lr 0.000023	 wd 0.0000	time 0.1705 (0.2263)	loss 0.9253 (0.8916)	grad_norm 1.4869 (1.5849)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:06:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:02:59 lr 0.000023	 wd 0.0000	time 0.1797 (0.2236)	loss 1.1172 (0.8916)	grad_norm 1.1816 (1.5853)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:07:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:35 lr 0.000023	 wd 0.0000	time 0.1965 (0.2212)	loss 0.9136 (0.8914)	grad_norm 1.9182 (1.5860)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:07:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:12 lr 0.000022	 wd 0.0000	time 0.2300 (0.2198)	loss 0.9019 (0.8917)	grad_norm 1.2967 (1.5869)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:07:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:01:50 lr 0.000022	 wd 0.0000	time 0.1639 (0.2204)	loss 0.9414 (0.8916)	grad_norm 2.5927 (1.5869)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:08:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:27 lr 0.000022	 wd 0.0000	time 0.1805 (0.2189)	loss 0.9448 (0.8920)	grad_norm 1.9506 (1.5867)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:08:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:05 lr 0.000022	 wd 0.0000	time 0.1745 (0.2173)	loss 0.9365 (0.8918)	grad_norm 1.3247 (1.5836)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:08:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:43 lr 0.000022	 wd 0.0000	time 0.1667 (0.2156)	loss 0.8657 (0.8924)	grad_norm 1.3216 (1.5835)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:09:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:21 lr 0.000022	 wd 0.0000	time 0.1852 (0.2150)	loss 0.8501 (0.8926)	grad_norm 1.5591 (1.5830)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:09:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1593 (0.2135)	loss 0.8486 (0.8926)	grad_norm 1.1358 (1.5843)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:09:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 20 training takes 0:09:07
[2024-07-26 13:10:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 21.234 (21.234)	Loss 0.3657 (0.3657)	Acc@1 91.211 (91.211)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 13:10:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.938 Acc@5 97.518
[2024-07-26 13:10:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-26 13:10:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 85.00%
[2024-07-26 13:10:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][0/2502]	eta 13:59:13 lr 0.000021	 wd 0.0000	time 20.1255 (20.1255)	loss 0.9189 (0.9189)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:11:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:19:20 lr 0.000021	 wd 0.0000	time 0.1621 (0.4832)	loss 0.8647 (0.8941)	grad_norm 1.3846 (1.6140)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:11:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:12:41 lr 0.000021	 wd 0.0000	time 0.1695 (0.3306)	loss 0.8613 (0.8985)	grad_norm 1.8212 (1.6051)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:11:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:10:15 lr 0.000021	 wd 0.0000	time 0.1595 (0.2793)	loss 0.8340 (0.8926)	grad_norm 1.5440 (1.5928)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:11:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:08:51 lr 0.000021	 wd 0.0000	time 0.1703 (0.2528)	loss 0.7964 (0.8907)	grad_norm 1.5852 (1.5778)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:12:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:08:13 lr 0.000021	 wd 0.0000	time 0.4038 (0.2467)	loss 0.9849 (0.8920)	grad_norm 1.3333 (1.5649)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:12:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:31 lr 0.000020	 wd 0.0000	time 0.1765 (0.2689)	loss 0.9307 (0.8923)	grad_norm 1.4013 (1.5641)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:13:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:07:41 lr 0.000020	 wd 0.0000	time 0.1756 (0.2559)	loss 0.8945 (0.8926)	grad_norm 1.7384 (1.5725)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:13:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:06:58 lr 0.000020	 wd 0.0000	time 0.1774 (0.2460)	loss 0.9150 (0.8924)	grad_norm 1.6000 (1.5622)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:13:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:25 lr 0.000020	 wd 0.0000	time 0.2733 (0.2406)	loss 0.8535 (0.8918)	grad_norm 1.5062 (1.5703)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:14:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:19 lr 0.000020	 wd 0.0000	time 0.1667 (0.2529)	loss 0.8057 (0.8909)	grad_norm 1.9641 (1.5705)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:14:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:05:44 lr 0.000020	 wd 0.0000	time 0.1836 (0.2459)	loss 0.8535 (0.8916)	grad_norm 1.4073 (1.5636)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:15:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:12 lr 0.000019	 wd 0.0000	time 0.1992 (0.2399)	loss 0.9341 (0.8916)	grad_norm nan (nan)	loss_scale 32768.0000 (32822.5679)	mem 8211MB
[2024-07-26 13:15:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:42 lr 0.000019	 wd 0.0000	time 0.2143 (0.2353)	loss 0.9775 (0.8914)	grad_norm 1.2926 (nan)	loss_scale 32768.0000 (32818.3736)	mem 8211MB
[2024-07-26 13:15:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:23 lr 0.000019	 wd 0.0000	time 0.1911 (0.2394)	loss 0.8252 (0.8915)	grad_norm 1.3915 (nan)	loss_scale 32768.0000 (32814.7780)	mem 8211MB
[2024-07-26 13:16:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:03:55 lr 0.000019	 wd 0.0000	time 0.1790 (0.2353)	loss 0.8564 (0.8912)	grad_norm 1.4139 (nan)	loss_scale 32768.0000 (32811.6616)	mem 8211MB
[2024-07-26 13:16:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:28 lr 0.000019	 wd 0.0000	time 0.1781 (0.2317)	loss 0.8687 (0.8904)	grad_norm 1.2885 (nan)	loss_scale 32768.0000 (32808.9344)	mem 8211MB
[2024-07-26 13:16:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:03 lr 0.000019	 wd 0.0000	time 0.1608 (0.2284)	loss 0.8755 (0.8900)	grad_norm 1.5725 (nan)	loss_scale 32768.0000 (32806.5279)	mem 8211MB
[2024-07-26 13:17:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:38 lr 0.000018	 wd 0.0000	time 0.1880 (0.2261)	loss 0.8823 (0.8896)	grad_norm 1.8064 (nan)	loss_scale 32768.0000 (32804.3887)	mem 8211MB
[2024-07-26 13:17:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:16 lr 0.000018	 wd 0.0000	time 0.1898 (0.2262)	loss 0.7510 (0.8890)	grad_norm 1.9058 (nan)	loss_scale 32768.0000 (32802.4745)	mem 8211MB
[2024-07-26 13:17:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:52 lr 0.000018	 wd 0.0000	time 0.1666 (0.2244)	loss 0.8433 (0.8890)	grad_norm 1.5399 (nan)	loss_scale 32768.0000 (32800.7516)	mem 8211MB
[2024-07-26 13:18:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:29 lr 0.000018	 wd 0.0000	time 0.1677 (0.2224)	loss 0.8384 (0.8891)	grad_norm 1.9530 (nan)	loss_scale 32768.0000 (32799.1928)	mem 8211MB
[2024-07-26 13:18:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:06 lr 0.000018	 wd 0.0000	time 0.1960 (0.2205)	loss 0.7188 (0.8892)	grad_norm 1.2601 (nan)	loss_scale 32768.0000 (32797.7756)	mem 8211MB
[2024-07-26 13:18:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:44 lr 0.000018	 wd 0.0000	time 0.1834 (0.2191)	loss 0.9663 (0.8899)	grad_norm 1.4557 (nan)	loss_scale 32768.0000 (32796.4815)	mem 8211MB
[2024-07-26 13:19:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:22 lr 0.000018	 wd 0.0000	time 0.1727 (0.2187)	loss 0.8735 (0.8901)	grad_norm 1.3475 (nan)	loss_scale 32768.0000 (32795.2953)	mem 8211MB
[2024-07-26 13:19:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000017	 wd 0.0000	time 0.1578 (0.2170)	loss 0.9233 (0.8905)	grad_norm 1.3134 (nan)	loss_scale 32768.0000 (32794.2039)	mem 8211MB
[2024-07-26 13:19:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 21 training takes 0:09:12
[2024-07-26 13:19:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 20.915 (20.915)	Loss 0.3655 (0.3655)	Acc@1 91.211 (91.211)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 13:20:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.972 Acc@5 97.508
[2024-07-26 13:20:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-26 13:20:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 85.00%
[2024-07-26 13:20:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][0/2502]	eta 22:51:46 lr 0.000017	 wd 0.0000	time 32.8962 (32.8962)	loss 0.9790 (0.9790)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:21:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:20:43 lr 0.000017	 wd 0.0000	time 0.1810 (0.5176)	loss 1.0029 (0.9013)	grad_norm 1.4756 (1.5538)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:21:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:13:17 lr 0.000017	 wd 0.0000	time 0.1704 (0.3464)	loss 0.7905 (0.8988)	grad_norm 1.5575 (1.5509)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:21:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:10:37 lr 0.000017	 wd 0.0000	time 0.1645 (0.2895)	loss 0.9712 (0.8946)	grad_norm 1.8885 (1.5754)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:21:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:09:17 lr 0.000017	 wd 0.0000	time 0.2669 (0.2654)	loss 0.9160 (0.8968)	grad_norm 1.4763 (1.5726)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:22:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:09:14 lr 0.000017	 wd 0.0000	time 0.2010 (0.2771)	loss 0.9912 (0.8973)	grad_norm 1.8265 (1.5709)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:22:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:15 lr 0.000016	 wd 0.0000	time 0.1774 (0.2606)	loss 1.0557 (0.8989)	grad_norm 1.3511 (1.5576)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:23:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:28 lr 0.000016	 wd 0.0000	time 0.1623 (0.2486)	loss 0.8877 (0.8990)	grad_norm 1.3971 (1.5569)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:23:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:06:47 lr 0.000016	 wd 0.0000	time 0.1736 (0.2394)	loss 0.8496 (0.8995)	grad_norm 1.8482 (1.5575)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:23:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:20 lr 0.000016	 wd 0.0000	time 0.3344 (0.2375)	loss 0.8833 (0.8982)	grad_norm 1.4935 (1.5561)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:24:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:03 lr 0.000016	 wd 0.0000	time 0.1643 (0.2421)	loss 0.7852 (0.8988)	grad_norm 1.5266 (1.5543)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:24:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:31 lr 0.000016	 wd 0.0000	time 0.1741 (0.2362)	loss 0.8730 (0.8988)	grad_norm 1.5146 (1.5590)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:24:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:00 lr 0.000016	 wd 0.0000	time 0.1753 (0.2311)	loss 0.8750 (0.8988)	grad_norm 1.8827 (1.5574)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:25:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:04:32 lr 0.000015	 wd 0.0000	time 0.1943 (0.2269)	loss 0.9126 (0.8983)	grad_norm 2.2146 (1.5555)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:25:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:17 lr 0.000015	 wd 0.0000	time 0.1712 (0.2339)	loss 0.8174 (0.8984)	grad_norm 1.4503 (1.5589)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:25:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:03:50 lr 0.000015	 wd 0.0000	time 0.1551 (0.2302)	loss 0.6538 (0.8985)	grad_norm 1.3016 (1.5559)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:26:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:24 lr 0.000015	 wd 0.0000	time 0.1632 (0.2268)	loss 1.0254 (0.8983)	grad_norm 1.4005 (1.5544)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:26:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:02:59 lr 0.000015	 wd 0.0000	time 0.1682 (0.2238)	loss 0.7578 (0.8974)	grad_norm 1.6099 (1.5555)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:26:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:35 lr 0.000015	 wd 0.0000	time 0.1695 (0.2218)	loss 1.0488 (0.8965)	grad_norm 1.6313 (1.5523)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:27:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:13 lr 0.000015	 wd 0.0000	time 0.1890 (0.2220)	loss 1.0146 (0.8971)	grad_norm 1.3010 (1.5523)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:27:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:50 lr 0.000014	 wd 0.0000	time 0.1624 (0.2206)	loss 0.9502 (0.8969)	grad_norm 1.2924 (1.5498)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:27:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:27 lr 0.000014	 wd 0.0000	time 0.1780 (0.2187)	loss 0.8496 (0.8970)	grad_norm 1.6984 (1.5527)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:28:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:05 lr 0.000014	 wd 0.0000	time 0.1617 (0.2169)	loss 0.7178 (0.8963)	grad_norm 1.6368 (1.5530)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:28:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:43 lr 0.000014	 wd 0.0000	time 0.1911 (0.2158)	loss 0.9175 (0.8959)	grad_norm 1.6705 (1.5539)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:28:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:22 lr 0.000014	 wd 0.0000	time 0.1551 (0.2159)	loss 0.8359 (0.8965)	grad_norm 1.4381 (1.5546)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:29:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1591 (0.2143)	loss 0.8882 (0.8963)	grad_norm 1.6589 (1.5529)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:29:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 22 training takes 0:09:05
[2024-07-26 13:29:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 19.425 (19.425)	Loss 0.3630 (0.3630)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 13:29:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.980 Acc@5 97.508
[2024-07-26 13:29:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-26 13:29:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 85.00%
[2024-07-26 13:30:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][0/2502]	eta 1 day, 0:07:49 lr 0.000014	 wd 0.0000	time 34.7200 (34.7200)	loss 0.9209 (0.9209)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:30:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:21:34 lr 0.000014	 wd 0.0000	time 0.1608 (0.5387)	loss 0.9233 (0.8893)	grad_norm 1.8182 (1.5678)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:31:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:13:42 lr 0.000013	 wd 0.0000	time 0.1703 (0.3574)	loss 0.8101 (0.8863)	grad_norm 1.3299 (nan)	loss_scale 32768.0000 (33094.0498)	mem 8211MB
[2024-07-26 13:31:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:10:52 lr 0.000013	 wd 0.0000	time 0.1749 (0.2961)	loss 0.8545 (0.8872)	grad_norm 1.6614 (nan)	loss_scale 32768.0000 (32985.7276)	mem 8211MB
[2024-07-26 13:31:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:09:40 lr 0.000013	 wd 0.0000	time 0.2752 (0.2761)	loss 1.0039 (0.8917)	grad_norm 1.2899 (nan)	loss_scale 32768.0000 (32931.4314)	mem 8211MB
[2024-07-26 13:32:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:09:45 lr 0.000013	 wd 0.0000	time 0.1707 (0.2925)	loss 1.0059 (0.8952)	grad_norm 1.9958 (nan)	loss_scale 32768.0000 (32898.8104)	mem 8211MB
[2024-07-26 13:32:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:08:39 lr 0.000013	 wd 0.0000	time 0.1955 (0.2733)	loss 0.9570 (0.8948)	grad_norm 1.9862 (nan)	loss_scale 32768.0000 (32877.0449)	mem 8211MB
[2024-07-26 13:32:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:47 lr 0.000013	 wd 0.0000	time 0.1642 (0.2594)	loss 0.9609 (0.8961)	grad_norm 1.2832 (nan)	loss_scale 32768.0000 (32861.4893)	mem 8211MB
[2024-07-26 13:33:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:07:05 lr 0.000013	 wd 0.0000	time 0.2042 (0.2497)	loss 0.8828 (0.8948)	grad_norm 1.3690 (nan)	loss_scale 32768.0000 (32849.8177)	mem 8211MB
[2024-07-26 13:33:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:06:44 lr 0.000012	 wd 0.0000	time 0.1699 (0.2523)	loss 1.1172 (0.8946)	grad_norm 1.7239 (nan)	loss_scale 32768.0000 (32840.7370)	mem 8211MB
[2024-07-26 13:33:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:07 lr 0.000012	 wd 0.0000	time 0.1609 (0.2449)	loss 0.8076 (0.8955)	grad_norm 1.7197 (nan)	loss_scale 32768.0000 (32833.4705)	mem 8211MB
[2024-07-26 13:34:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:34 lr 0.000012	 wd 0.0000	time 0.1707 (0.2385)	loss 0.8979 (0.8936)	grad_norm 2.0550 (nan)	loss_scale 32768.0000 (32827.5241)	mem 8211MB
[2024-07-26 13:34:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:04 lr 0.000012	 wd 0.0000	time 0.2031 (0.2335)	loss 0.8130 (0.8938)	grad_norm 1.6111 (nan)	loss_scale 32768.0000 (32822.5679)	mem 8211MB
[2024-07-26 13:34:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:04:38 lr 0.000012	 wd 0.0000	time 0.3269 (0.2319)	loss 0.9600 (0.8926)	grad_norm 1.1202 (nan)	loss_scale 32768.0000 (32818.3736)	mem 8211MB
[2024-07-26 13:35:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:29 lr 0.000012	 wd 0.0000	time 0.1625 (0.2445)	loss 0.9692 (0.8921)	grad_norm 1.8170 (nan)	loss_scale 32768.0000 (32814.7780)	mem 8211MB
[2024-07-26 13:35:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:04:00 lr 0.000012	 wd 0.0000	time 0.1570 (0.2400)	loss 0.9526 (0.8915)	grad_norm 1.8990 (nan)	loss_scale 32768.0000 (32811.6616)	mem 8211MB
[2024-07-26 13:36:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:32 lr 0.000012	 wd 0.0000	time 0.1935 (0.2360)	loss 0.8472 (0.8916)	grad_norm 1.6096 (nan)	loss_scale 32768.0000 (32808.9344)	mem 8211MB
[2024-07-26 13:36:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:06 lr 0.000011	 wd 0.0000	time 0.1793 (0.2330)	loss 0.7290 (0.8918)	grad_norm 1.4164 (nan)	loss_scale 32768.0000 (32806.5279)	mem 8211MB
[2024-07-26 13:36:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:43 lr 0.000011	 wd 0.0000	time 0.1724 (0.2326)	loss 0.9404 (0.8919)	grad_norm 1.7944 (nan)	loss_scale 32768.0000 (32804.3887)	mem 8211MB
[2024-07-26 13:37:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:18 lr 0.000011	 wd 0.0000	time 0.1738 (0.2303)	loss 0.7642 (0.8916)	grad_norm 1.2445 (nan)	loss_scale 32768.0000 (32802.4745)	mem 8211MB
[2024-07-26 13:37:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:01:54 lr 0.000011	 wd 0.0000	time 0.1715 (0.2280)	loss 0.9160 (0.8909)	grad_norm 2.6257 (nan)	loss_scale 32768.0000 (32800.7516)	mem 8211MB
[2024-07-26 13:37:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:30 lr 0.000011	 wd 0.0000	time 0.1546 (0.2257)	loss 0.8911 (0.8914)	grad_norm 1.6601 (nan)	loss_scale 32768.0000 (32799.1928)	mem 8211MB
[2024-07-26 13:38:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:07 lr 0.000011	 wd 0.0000	time 0.2439 (0.2240)	loss 0.9419 (0.8914)	grad_norm 1.4038 (nan)	loss_scale 32768.0000 (32797.7756)	mem 8211MB
[2024-07-26 13:38:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:45 lr 0.000011	 wd 0.0000	time 0.1809 (0.2236)	loss 0.9072 (0.8918)	grad_norm 1.7177 (nan)	loss_scale 32768.0000 (32796.4815)	mem 8211MB
[2024-07-26 13:38:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:22 lr 0.000011	 wd 0.0000	time 0.1875 (0.2221)	loss 0.8882 (0.8918)	grad_norm 1.5797 (nan)	loss_scale 32768.0000 (32795.2953)	mem 8211MB
[2024-07-26 13:39:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1586 (0.2200)	loss 0.9028 (0.8915)	grad_norm 1.6317 (nan)	loss_scale 32768.0000 (32794.2039)	mem 8211MB
[2024-07-26 13:39:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 23 training takes 0:09:17
[2024-07-26 13:39:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 18.619 (18.619)	Loss 0.3638 (0.3638)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 13:39:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.978 Acc@5 97.498
[2024-07-26 13:39:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-26 13:39:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 85.00%
[2024-07-26 13:40:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][0/2502]	eta 1 day, 0:24:48 lr 0.000010	 wd 0.0000	time 35.1272 (35.1272)	loss 0.8198 (0.8198)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:40:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:21:15 lr 0.000010	 wd 0.0000	time 0.1742 (0.5309)	loss 0.9692 (0.8863)	grad_norm 1.4547 (1.4728)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:40:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:13:33 lr 0.000010	 wd 0.0000	time 0.1701 (0.3534)	loss 0.9404 (0.8907)	grad_norm 1.5760 (1.4969)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:41:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:10:56 lr 0.000010	 wd 0.0000	time 0.2928 (0.2982)	loss 0.8760 (0.8894)	grad_norm 1.3177 (1.5172)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:41:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:11:04 lr 0.000010	 wd 0.0000	time 0.1813 (0.3162)	loss 0.9395 (0.8897)	grad_norm 1.3170 (1.5234)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:42:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:09:37 lr 0.000010	 wd 0.0000	time 0.1898 (0.2883)	loss 0.8740 (0.8912)	grad_norm 2.0137 (1.5361)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:42:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:08:32 lr 0.000010	 wd 0.0000	time 0.1632 (0.2696)	loss 0.8296 (0.8904)	grad_norm 1.4060 (1.5196)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:42:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:07:41 lr 0.000010	 wd 0.0000	time 0.1741 (0.2562)	loss 0.8291 (0.8907)	grad_norm 1.6973 (1.5174)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:43:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:07:27 lr 0.000010	 wd 0.0000	time 0.2374 (0.2631)	loss 0.8159 (0.8917)	grad_norm 1.7561 (1.5280)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:43:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:06:50 lr 0.000009	 wd 0.0000	time 0.1761 (0.2563)	loss 0.9521 (0.8925)	grad_norm 1.3751 (1.5340)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:43:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:13 lr 0.000009	 wd 0.0000	time 0.1595 (0.2485)	loss 0.9082 (0.8935)	grad_norm 1.7027 (1.5407)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:44:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:05:38 lr 0.000009	 wd 0.0000	time 0.1665 (0.2417)	loss 0.8281 (0.8918)	grad_norm 1.9032 (1.5393)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:44:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:08 lr 0.000009	 wd 0.0000	time 0.2301 (0.2371)	loss 0.7861 (0.8914)	grad_norm 1.5216 (1.5387)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:45:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:04:54 lr 0.000009	 wd 0.0000	time 0.1761 (0.2451)	loss 0.9209 (0.8923)	grad_norm 1.4814 (1.5368)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:45:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:24 lr 0.000009	 wd 0.0000	time 0.1732 (0.2402)	loss 0.9336 (0.8927)	grad_norm 1.7559 (1.5298)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:45:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:03:56 lr 0.000009	 wd 0.0000	time 0.1590 (0.2359)	loss 0.7583 (0.8927)	grad_norm 1.4986 (1.5221)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:45:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:29 lr 0.000009	 wd 0.0000	time 0.1718 (0.2322)	loss 0.8247 (0.8926)	grad_norm 1.5067 (1.5228)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:46:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:04 lr 0.000008	 wd 0.0000	time 0.1594 (0.2304)	loss 0.9521 (0.8932)	grad_norm 1.3055 (nan)	loss_scale 32768.0000 (32806.5279)	mem 8211MB
[2024-07-26 13:46:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:41 lr 0.000008	 wd 0.0000	time 0.1805 (0.2297)	loss 0.8008 (0.8928)	grad_norm 1.8948 (nan)	loss_scale 32768.0000 (32804.3887)	mem 8211MB
[2024-07-26 13:46:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:16 lr 0.000008	 wd 0.0000	time 0.1764 (0.2272)	loss 0.6758 (0.8931)	grad_norm 1.3191 (nan)	loss_scale 32768.0000 (32802.4745)	mem 8211MB
[2024-07-26 13:47:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:01:52 lr 0.000008	 wd 0.0000	time 0.1729 (0.2250)	loss 0.9194 (0.8928)	grad_norm 1.8864 (nan)	loss_scale 32768.0000 (32800.7516)	mem 8211MB
[2024-07-26 13:47:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:29 lr 0.000008	 wd 0.0000	time 0.1738 (0.2230)	loss 0.8794 (0.8925)	grad_norm 1.8035 (nan)	loss_scale 32768.0000 (32799.1928)	mem 8211MB
[2024-07-26 13:47:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:07 lr 0.000008	 wd 0.0000	time 0.1841 (0.2220)	loss 0.9399 (0.8921)	grad_norm 1.8766 (nan)	loss_scale 32768.0000 (32797.7756)	mem 8211MB
[2024-07-26 13:48:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:44 lr 0.000008	 wd 0.0000	time 0.1733 (0.2217)	loss 0.9805 (0.8922)	grad_norm 1.6286 (nan)	loss_scale 32768.0000 (32796.4815)	mem 8211MB
[2024-07-26 13:48:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:22 lr 0.000008	 wd 0.0000	time 0.1546 (0.2201)	loss 1.0693 (0.8923)	grad_norm 1.3468 (nan)	loss_scale 32768.0000 (32795.2953)	mem 8211MB
[2024-07-26 13:48:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1589 (0.2182)	loss 1.0205 (0.8924)	grad_norm 1.6314 (nan)	loss_scale 32768.0000 (32794.2039)	mem 8211MB
[2024-07-26 13:49:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 24 training takes 0:09:13
[2024-07-26 13:49:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 41.537 (41.537)	Loss 0.3630 (0.3630)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 13:50:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 85.002 Acc@5 97.502
[2024-07-26 13:50:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-26 13:50:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 85.00%
[2024-07-26 13:50:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saving......
[2024-07-26 13:50:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-26 13:50:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][0/2502]	eta 11:49:01 lr 0.000008	 wd 0.0000	time 17.0030 (17.0030)	loss 0.8711 (0.8711)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:50:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:13:39 lr 0.000008	 wd 0.0000	time 0.1684 (0.3414)	loss 0.9048 (0.8915)	grad_norm 1.5672 (1.5302)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 13:51:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:10:57 lr 0.000007	 wd 0.0000	time 0.4080 (0.2858)	loss 0.7925 (0.8911)	grad_norm 1.4589 (inf)	loss_scale 16384.0000 (31626.8259)	mem 8211MB
[2024-07-26 13:51:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:11:37 lr 0.000007	 wd 0.0000	time 0.1937 (0.3169)	loss 0.9443 (0.8925)	grad_norm 1.4534 (inf)	loss_scale 16384.0000 (26562.7641)	mem 8211MB
[2024-07-26 13:51:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:09:53 lr 0.000007	 wd 0.0000	time 0.1622 (0.2823)	loss 0.9326 (0.8911)	grad_norm 1.4683 (inf)	loss_scale 16384.0000 (24024.4190)	mem 8211MB
[2024-07-26 13:52:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:08:41 lr 0.000007	 wd 0.0000	time 0.1747 (0.2606)	loss 0.8384 (0.8914)	grad_norm 1.6022 (inf)	loss_scale 16384.0000 (22499.3852)	mem 8211MB
[2024-07-26 13:52:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:07:54 lr 0.000007	 wd 0.0000	time 0.2609 (0.2496)	loss 0.9468 (0.8915)	grad_norm 1.3916 (inf)	loss_scale 16384.0000 (21481.8502)	mem 8211MB
[2024-07-26 13:53:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:07:46 lr 0.000007	 wd 0.0000	time 0.1735 (0.2587)	loss 0.9097 (0.8905)	grad_norm 1.1995 (inf)	loss_scale 16384.0000 (20754.6248)	mem 8211MB
[2024-07-26 13:53:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:07:02 lr 0.000007	 wd 0.0000	time 0.1732 (0.2484)	loss 0.9316 (0.8907)	grad_norm 1.5539 (inf)	loss_scale 16384.0000 (20208.9788)	mem 8211MB
[2024-07-26 13:53:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:06:24 lr 0.000007	 wd 0.0000	time 0.1593 (0.2402)	loss 0.8481 (0.8904)	grad_norm 1.3401 (inf)	loss_scale 16384.0000 (19784.4528)	mem 8211MB
[2024-07-26 13:53:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:05:50 lr 0.000007	 wd 0.0000	time 0.1546 (0.2334)	loss 1.0430 (0.8902)	grad_norm 1.4478 (inf)	loss_scale 16384.0000 (19444.7473)	mem 8211MB
[2024-07-26 13:54:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:27 lr 0.000007	 wd 0.0000	time 0.3730 (0.2338)	loss 0.8838 (0.8898)	grad_norm 1.3343 (inf)	loss_scale 16384.0000 (19166.7502)	mem 8211MB
[2024-07-26 13:54:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:09 lr 0.000006	 wd 0.0000	time 0.1877 (0.2375)	loss 1.1104 (0.8907)	grad_norm 1.1535 (inf)	loss_scale 16384.0000 (18935.0475)	mem 8211MB
[2024-07-26 13:55:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:04:39 lr 0.000006	 wd 0.0000	time 0.1719 (0.2328)	loss 0.8555 (0.8909)	grad_norm 1.1192 (inf)	loss_scale 16384.0000 (18738.9639)	mem 8211MB
[2024-07-26 13:55:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:11 lr 0.000006	 wd 0.0000	time 0.1595 (0.2287)	loss 0.8442 (0.8905)	grad_norm 1.3926 (inf)	loss_scale 16384.0000 (18570.8722)	mem 8211MB
[2024-07-26 13:55:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:03:45 lr 0.000006	 wd 0.0000	time 0.1958 (0.2255)	loss 0.9326 (0.8910)	grad_norm 1.3700 (inf)	loss_scale 16384.0000 (18425.1779)	mem 8211MB
[2024-07-26 13:56:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:21 lr 0.000006	 wd 0.0000	time 0.4115 (0.2237)	loss 0.8672 (0.8905)	grad_norm 1.3153 (inf)	loss_scale 16384.0000 (18297.6839)	mem 8211MB
[2024-07-26 13:56:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:02:58 lr 0.000006	 wd 0.0000	time 0.1849 (0.2231)	loss 0.8613 (0.8900)	grad_norm 1.6200 (inf)	loss_scale 16384.0000 (18185.1805)	mem 8211MB
[2024-07-26 13:56:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:35 lr 0.000006	 wd 0.0000	time 0.1595 (0.2208)	loss 1.0596 (0.8906)	grad_norm 1.2340 (inf)	loss_scale 16384.0000 (18085.1705)	mem 8211MB
[2024-07-26 13:57:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:11 lr 0.000006	 wd 0.0000	time 0.1628 (0.2188)	loss 1.2422 (0.8909)	grad_norm 1.2355 (inf)	loss_scale 16384.0000 (17995.6823)	mem 8211MB
[2024-07-26 13:57:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:01:48 lr 0.000006	 wd 0.0000	time 0.1999 (0.2169)	loss 0.9927 (0.8905)	grad_norm 1.3613 (inf)	loss_scale 16384.0000 (17915.1384)	mem 8211MB
[2024-07-26 13:57:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:26 lr 0.000006	 wd 0.0000	time 0.1831 (0.2158)	loss 0.9595 (0.8905)	grad_norm 1.4934 (inf)	loss_scale 16384.0000 (17842.2618)	mem 8211MB
[2024-07-26 13:58:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:05 lr 0.000006	 wd 0.0000	time 0.2512 (0.2165)	loss 0.8706 (0.8895)	grad_norm 1.5227 (inf)	loss_scale 16384.0000 (17776.0073)	mem 8211MB
[2024-07-26 13:58:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:43 lr 0.000005	 wd 0.0000	time 0.1718 (0.2150)	loss 0.8394 (0.8895)	grad_norm 1.3454 (inf)	loss_scale 16384.0000 (17715.5115)	mem 8211MB
[2024-07-26 13:58:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:21 lr 0.000005	 wd 0.0000	time 0.1617 (0.2135)	loss 0.8306 (0.8894)	grad_norm 1.3835 (inf)	loss_scale 16384.0000 (17660.0550)	mem 8211MB
[2024-07-26 13:58:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000005	 wd 0.0000	time 0.1579 (0.2118)	loss 0.8584 (0.8892)	grad_norm 1.3475 (inf)	loss_scale 16384.0000 (17609.0332)	mem 8211MB
[2024-07-26 13:59:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 25 training takes 0:08:58
[2024-07-26 13:59:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 34.576 (34.576)	Loss 0.3633 (0.3633)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 13:59:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.996 Acc@5 97.504
[2024-07-26 13:59:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-26 13:59:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 85.00%
[2024-07-26 14:00:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][0/2502]	eta 11:10:12 lr 0.000005	 wd 0.0000	time 16.0720 (16.0720)	loss 0.8716 (0.8716)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:00:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:13:27 lr 0.000005	 wd 0.0000	time 0.1707 (0.3360)	loss 0.9854 (0.8908)	grad_norm 1.4931 (1.5060)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:01:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:13:57 lr 0.000005	 wd 0.0000	time 0.1852 (0.3638)	loss 0.8667 (0.8932)	grad_norm 1.5666 (1.5077)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:01:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:11:06 lr 0.000005	 wd 0.0000	time 0.1677 (0.3026)	loss 0.8447 (0.8928)	grad_norm 1.6520 (1.4970)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:01:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:09:29 lr 0.000005	 wd 0.0000	time 0.1714 (0.2708)	loss 0.9756 (0.8909)	grad_norm 1.6226 (1.5116)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:02:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:08:23 lr 0.000005	 wd 0.0000	time 0.1571 (0.2515)	loss 0.9756 (0.8918)	grad_norm 1.2199 (1.5098)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:02:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:07:59 lr 0.000005	 wd 0.0000	time 0.3875 (0.2519)	loss 0.8701 (0.8914)	grad_norm 1.7279 (1.5041)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:02:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:44 lr 0.000005	 wd 0.0000	time 0.2021 (0.2575)	loss 1.0674 (0.8902)	grad_norm 1.3143 (1.4987)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:03:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:07:01 lr 0.000005	 wd 0.0000	time 0.1673 (0.2474)	loss 0.8696 (0.8901)	grad_norm 1.9703 (1.4959)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:03:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:06:23 lr 0.000005	 wd 0.0000	time 0.1692 (0.2393)	loss 0.8735 (0.8893)	grad_norm 1.6885 (1.5031)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:03:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:05:51 lr 0.000004	 wd 0.0000	time 0.2474 (0.2343)	loss 1.0068 (0.8893)	grad_norm 1.4283 (1.5026)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:04:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:39 lr 0.000004	 wd 0.0000	time 0.1699 (0.2419)	loss 0.9214 (0.8892)	grad_norm 1.3637 (1.4991)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:04:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:07 lr 0.000004	 wd 0.0000	time 0.1705 (0.2364)	loss 0.8022 (0.8900)	grad_norm 1.6737 (1.4964)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:04:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:04:38 lr 0.000004	 wd 0.0000	time 0.1685 (0.2316)	loss 0.7642 (0.8902)	grad_norm 1.4892 (1.4959)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:05:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:10 lr 0.000004	 wd 0.0000	time 0.1739 (0.2275)	loss 0.9956 (0.8907)	grad_norm 1.4263 (1.4933)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:05:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:03:46 lr 0.000004	 wd 0.0000	time 0.1990 (0.2260)	loss 0.8203 (0.8908)	grad_norm 1.7558 (1.4888)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:05:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:23 lr 0.000004	 wd 0.0000	time 0.2306 (0.2254)	loss 0.7754 (0.8901)	grad_norm 1.5666 (1.4914)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:06:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:02:58 lr 0.000004	 wd 0.0000	time 0.1624 (0.2228)	loss 0.7939 (0.8896)	grad_norm 1.3961 (1.4893)	loss_scale 32768.0000 (16538.1117)	mem 8211MB
[2024-07-26 14:06:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:34 lr 0.000004	 wd 0.0000	time 0.1600 (0.2203)	loss 0.9067 (0.8897)	grad_norm 1.2699 (1.4883)	loss_scale 32768.0000 (17439.2715)	mem 8211MB
[2024-07-26 14:06:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:11 lr 0.000004	 wd 0.0000	time 0.1868 (0.2182)	loss 0.8057 (0.8896)	grad_norm 1.6050 (1.4875)	loss_scale 32768.0000 (18245.6223)	mem 8211MB
[2024-07-26 14:07:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:01:49 lr 0.000004	 wd 0.0000	time 0.1748 (0.2173)	loss 0.9551 (0.8898)	grad_norm 1.2948 (1.4830)	loss_scale 32768.0000 (18971.3783)	mem 8211MB
[2024-07-26 14:07:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:27 lr 0.000004	 wd 0.0000	time 0.1717 (0.2175)	loss 0.9224 (0.8901)	grad_norm 1.2315 (1.4838)	loss_scale 32768.0000 (19628.0476)	mem 8211MB
[2024-07-26 14:07:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:05 lr 0.000004	 wd 0.0000	time 0.1602 (0.2161)	loss 0.8721 (0.8903)	grad_norm 1.8032 (1.4814)	loss_scale 32768.0000 (20225.0468)	mem 8211MB
[2024-07-26 14:08:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:43 lr 0.000004	 wd 0.0000	time 0.1698 (0.2145)	loss 0.7847 (0.8903)	grad_norm 1.9278 (inf)	loss_scale 16384.0000 (20513.8218)	mem 8211MB
[2024-07-26 14:08:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:21 lr 0.000003	 wd 0.0000	time 0.1729 (0.2130)	loss 0.9409 (0.8907)	grad_norm 1.6620 (inf)	loss_scale 16384.0000 (20341.8176)	mem 8211MB
[2024-07-26 14:08:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1579 (0.2114)	loss 0.7974 (0.8912)	grad_norm 1.3461 (inf)	loss_scale 16384.0000 (20183.5682)	mem 8211MB
[2024-07-26 14:08:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 26 training takes 0:08:55
[2024-07-26 14:09:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 36.697 (36.697)	Loss 0.3640 (0.3640)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 14:09:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 85.012 Acc@5 97.518
[2024-07-26 14:09:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-26 14:09:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 85.01%
[2024-07-26 14:09:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saving......
[2024-07-26 14:09:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-26 14:10:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][0/2502]	eta 9:48:02 lr 0.000003	 wd 0.0000	time 14.1018 (14.1018)	loss 0.8306 (0.8306)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:10:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:16:04 lr 0.000003	 wd 0.0000	time 0.3155 (0.4016)	loss 0.8911 (0.8924)	grad_norm 1.5824 (1.4932)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:10:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:12:54 lr 0.000003	 wd 0.0000	time 0.1547 (0.3364)	loss 0.8765 (0.8900)	grad_norm 1.4538 (1.4968)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:11:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:10:22 lr 0.000003	 wd 0.0000	time 0.1548 (0.2829)	loss 0.9121 (0.8868)	grad_norm 1.4143 (1.4962)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:11:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:08:57 lr 0.000003	 wd 0.0000	time 0.1611 (0.2558)	loss 0.8569 (0.8871)	grad_norm 1.3728 (1.4896)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:11:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:08:01 lr 0.000003	 wd 0.0000	time 0.1980 (0.2404)	loss 0.8115 (0.8858)	grad_norm 1.3180 (1.4837)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:12:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:16 lr 0.000003	 wd 0.0000	time 0.1684 (0.2610)	loss 0.8525 (0.8894)	grad_norm 1.3674 (1.4836)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:12:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:29 lr 0.000003	 wd 0.0000	time 0.1791 (0.2494)	loss 0.9194 (0.8909)	grad_norm 1.5515 (1.4801)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:13:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:06:49 lr 0.000003	 wd 0.0000	time 0.1644 (0.2404)	loss 0.9287 (0.8898)	grad_norm 1.3028 (1.4799)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:13:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:13 lr 0.000003	 wd 0.0000	time 0.1673 (0.2332)	loss 0.8320 (0.8914)	grad_norm 1.5514 (1.4803)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:13:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:05:50 lr 0.000003	 wd 0.0000	time 0.4485 (0.2336)	loss 0.9751 (0.8906)	grad_norm 1.4648 (1.4823)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:14:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:36 lr 0.000003	 wd 0.0000	time 0.1799 (0.2398)	loss 0.7998 (0.8904)	grad_norm 1.8579 (1.4842)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:14:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:05 lr 0.000003	 wd 0.0000	time 0.1623 (0.2344)	loss 0.8604 (0.8892)	grad_norm 1.6005 (1.4846)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:14:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:36 lr 0.000003	 wd 0.0000	time 0.1589 (0.2299)	loss 0.9165 (0.8890)	grad_norm 1.8628 (1.4829)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:15:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:09 lr 0.000003	 wd 0.0000	time 0.1791 (0.2265)	loss 0.7808 (0.8890)	grad_norm 1.2940 (1.4808)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:15:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:03:55 lr 0.000003	 wd 0.0000	time 0.1662 (0.2347)	loss 0.9463 (0.8895)	grad_norm 1.4193 (1.4800)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:15:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:28 lr 0.000003	 wd 0.0000	time 0.1974 (0.2310)	loss 0.8511 (0.8901)	grad_norm 1.5168 (1.4765)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:16:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:02 lr 0.000002	 wd 0.0000	time 0.1595 (0.2277)	loss 0.9893 (0.8898)	grad_norm 1.6127 (1.4778)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:16:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:37 lr 0.000002	 wd 0.0000	time 0.1980 (0.2250)	loss 0.8428 (0.8900)	grad_norm 1.6147 (1.4764)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:16:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:14 lr 0.000002	 wd 0.0000	time 0.1835 (0.2237)	loss 0.9248 (0.8898)	grad_norm 1.5027 (1.4752)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:17:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:52 lr 0.000002	 wd 0.0000	time 0.2440 (0.2239)	loss 0.7383 (0.8894)	grad_norm 1.3734 (1.4747)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:17:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:29 lr 0.000002	 wd 0.0000	time 0.1619 (0.2218)	loss 1.1094 (0.8909)	grad_norm 1.5804 (1.4760)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:17:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:06 lr 0.000002	 wd 0.0000	time 0.1750 (0.2200)	loss 0.8062 (0.8909)	grad_norm 1.6510 (1.4754)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:18:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:44 lr 0.000002	 wd 0.0000	time 0.1726 (0.2183)	loss 0.9438 (0.8913)	grad_norm 1.7740 (1.4766)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:18:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:22 lr 0.000002	 wd 0.0000	time 0.1964 (0.2174)	loss 0.9370 (0.8914)	grad_norm 1.2304 (1.4763)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:18:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1597 (0.2164)	loss 0.8418 (0.8916)	grad_norm 1.5290 (1.4769)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:19:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 27 training takes 0:09:12
[2024-07-26 14:19:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 20.214 (20.214)	Loss 0.3645 (0.3645)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 14:19:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 85.020 Acc@5 97.504
[2024-07-26 14:19:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-26 14:19:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-26 14:19:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saving......
[2024-07-26 14:19:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-26 14:20:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][0/2502]	eta 22:27:20 lr 0.000002	 wd 0.0000	time 32.3102 (32.3102)	loss 0.8540 (0.8540)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:20:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:22:10 lr 0.000002	 wd 0.0000	time 0.1556 (0.5540)	loss 0.9653 (0.9042)	grad_norm 1.2615 (1.4517)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:20:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:13:59 lr 0.000002	 wd 0.0000	time 0.1713 (0.3648)	loss 0.9727 (0.8980)	grad_norm 1.7711 (1.4698)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:21:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:11:05 lr 0.000002	 wd 0.0000	time 0.1625 (0.3023)	loss 0.9541 (0.8976)	grad_norm 1.3231 (1.4579)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:21:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:09:34 lr 0.000002	 wd 0.0000	time 0.2344 (0.2734)	loss 0.7603 (0.8942)	grad_norm 1.3632 (1.4608)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:22:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:09:39 lr 0.000002	 wd 0.0000	time 0.1772 (0.2896)	loss 0.9531 (0.8952)	grad_norm 1.3056 (1.4569)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:22:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:36 lr 0.000002	 wd 0.0000	time 0.1664 (0.2713)	loss 0.9341 (0.8944)	grad_norm 1.7238 (1.4557)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:22:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:44 lr 0.000002	 wd 0.0000	time 0.1628 (0.2578)	loss 0.8647 (0.8936)	grad_norm 1.7932 (1.4591)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:22:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:01 lr 0.000002	 wd 0.0000	time 0.1698 (0.2474)	loss 0.8862 (0.8931)	grad_norm 1.5199 (1.4587)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:23:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:31 lr 0.000002	 wd 0.0000	time 0.3456 (0.2445)	loss 0.9224 (0.8912)	grad_norm 1.5107 (1.4589)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:23:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:15 lr 0.000002	 wd 0.0000	time 0.1912 (0.2501)	loss 0.9209 (0.8910)	grad_norm 1.6458 (1.4600)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:24:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:41 lr 0.000002	 wd 0.0000	time 0.1609 (0.2434)	loss 0.8457 (0.8905)	grad_norm 1.3801 (1.4605)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:24:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:09 lr 0.000002	 wd 0.0000	time 0.1599 (0.2377)	loss 0.9468 (0.8896)	grad_norm 1.2081 (1.4569)	loss_scale 16384.0000 (16384.0000)	mem 8211MB
[2024-07-26 14:24:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:04:40 lr 0.000002	 wd 0.0000	time 0.1888 (0.2332)	loss 0.8062 (0.8896)	grad_norm 1.6555 (1.4598)	loss_scale 32768.0000 (16887.7356)	mem 8211MB
[2024-07-26 14:25:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:25 lr 0.000002	 wd 0.0000	time 0.2011 (0.2412)	loss 0.8403 (0.8895)	grad_norm 1.4287 (1.4590)	loss_scale 32768.0000 (18021.2305)	mem 8211MB
[2024-07-26 14:25:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:03:57 lr 0.000002	 wd 0.0000	time 0.1870 (0.2370)	loss 0.8433 (0.8892)	grad_norm 1.1748 (1.4633)	loss_scale 32768.0000 (19003.6935)	mem 8211MB
[2024-07-26 14:25:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:30 lr 0.000002	 wd 0.0000	time 0.1731 (0.2332)	loss 0.8037 (0.8894)	grad_norm 1.1980 (1.4655)	loss_scale 32768.0000 (19863.4254)	mem 8211MB
[2024-07-26 14:26:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:04 lr 0.000001	 wd 0.0000	time 0.1731 (0.2299)	loss 0.7734 (0.8897)	grad_norm 1.1647 (1.4645)	loss_scale 32768.0000 (20622.0717)	mem 8211MB
[2024-07-26 14:26:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:40 lr 0.000001	 wd 0.0000	time 0.2044 (0.2281)	loss 0.7827 (0.8897)	grad_norm 1.6640 (1.4678)	loss_scale 32768.0000 (21296.4708)	mem 8211MB
[2024-07-26 14:26:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:17 lr 0.000001	 wd 0.0000	time 0.1728 (0.2277)	loss 0.9111 (0.8899)	grad_norm 1.3744 (1.4678)	loss_scale 32768.0000 (21899.9179)	mem 8211MB
[2024-07-26 14:27:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:01:53 lr 0.000001	 wd 0.0000	time 0.1589 (0.2256)	loss 0.8506 (0.8895)	grad_norm 1.4945 (1.4668)	loss_scale 32768.0000 (22443.0505)	mem 8211MB
[2024-07-26 14:27:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:29 lr 0.000001	 wd 0.0000	time 0.1746 (0.2235)	loss 0.9819 (0.8899)	grad_norm 1.2424 (1.4675)	loss_scale 32768.0000 (22934.4807)	mem 8211MB
[2024-07-26 14:27:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:06 lr 0.000001	 wd 0.0000	time 0.1631 (0.2215)	loss 0.9404 (0.8897)	grad_norm 1.9230 (1.4682)	loss_scale 32768.0000 (23381.2558)	mem 8211MB
[2024-07-26 14:28:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:44 lr 0.000001	 wd 0.0000	time 0.1953 (0.2206)	loss 0.8257 (0.8902)	grad_norm 1.1499 (1.4682)	loss_scale 32768.0000 (23789.1977)	mem 8211MB
[2024-07-26 14:28:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:22 lr 0.000001	 wd 0.0000	time 0.2262 (0.2202)	loss 0.9736 (0.8903)	grad_norm 1.8770 (1.4671)	loss_scale 32768.0000 (24163.1587)	mem 8211MB
[2024-07-26 14:28:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1589 (0.2183)	loss 0.8843 (0.8907)	grad_norm 1.2406 (1.4665)	loss_scale 32768.0000 (24507.2147)	mem 8211MB
[2024-07-26 14:28:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 28 training takes 0:09:15
[2024-07-26 14:29:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 19.046 (19.046)	Loss 0.3638 (0.3638)	Acc@1 91.211 (91.211)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 14:29:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 85.014 Acc@5 97.526
[2024-07-26 14:29:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-26 14:29:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-26 14:30:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][0/2502]	eta 1 day, 1:59:30 lr 0.000001	 wd 0.0000	time 37.3984 (37.3984)	loss 0.8433 (0.8433)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:30:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:21:54 lr 0.000001	 wd 0.0000	time 0.1788 (0.5472)	loss 1.0596 (0.8904)	grad_norm 1.1913 (1.4157)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:30:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:13:53 lr 0.000001	 wd 0.0000	time 0.1660 (0.3622)	loss 0.8618 (0.8998)	grad_norm 1.1760 (1.4087)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:31:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:10:59 lr 0.000001	 wd 0.0000	time 0.1754 (0.2994)	loss 0.8433 (0.8973)	grad_norm 1.3784 (1.4386)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:31:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:11:21 lr 0.000001	 wd 0.0000	time 1.1269 (0.3240)	loss 0.7998 (0.8991)	grad_norm 1.5016 (1.4372)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:32:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:10:14 lr 0.000001	 wd 0.0000	time 0.1750 (0.3068)	loss 0.8374 (0.8983)	grad_norm 1.5192 (1.4388)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:32:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:09:02 lr 0.000001	 wd 0.0000	time 0.1906 (0.2854)	loss 0.8228 (0.8948)	grad_norm 1.2783 (1.4339)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:32:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:08:07 lr 0.000001	 wd 0.0000	time 0.1792 (0.2704)	loss 0.8955 (0.8925)	grad_norm 1.6591 (1.4390)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:33:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:08:06 lr 0.000001	 wd 0.0000	time 0.3472 (0.2857)	loss 0.7314 (0.8945)	grad_norm 1.6752 (1.4430)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:33:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:07:19 lr 0.000001	 wd 0.0000	time 0.1855 (0.2745)	loss 0.8696 (0.8943)	grad_norm 1.7594 (1.4500)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:33:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:37 lr 0.000001	 wd 0.0000	time 0.1549 (0.2646)	loss 0.8145 (0.8938)	grad_norm 1.1104 (1.4506)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:34:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:59 lr 0.000001	 wd 0.0000	time 0.1658 (0.2563)	loss 0.9126 (0.8938)	grad_norm 1.5955 (1.4487)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:34:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:29 lr 0.000001	 wd 0.0000	time 0.2500 (0.2533)	loss 0.7998 (0.8924)	grad_norm 1.2429 (1.4487)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:35:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:05:06 lr 0.000001	 wd 0.0000	time 0.1590 (0.2549)	loss 0.7949 (0.8935)	grad_norm 1.4787 (1.4511)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:35:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:34 lr 0.000001	 wd 0.0000	time 0.1804 (0.2493)	loss 1.0205 (0.8936)	grad_norm 1.2947 (1.4520)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:35:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:04:04 lr 0.000001	 wd 0.0000	time 0.1616 (0.2443)	loss 0.7754 (0.8932)	grad_norm 1.7713 (1.4489)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:35:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:37 lr 0.000001	 wd 0.0000	time 0.1731 (0.2406)	loss 0.8633 (0.8931)	grad_norm 1.3101 (1.4510)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:36:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:12 lr 0.000001	 wd 0.0000	time 0.1739 (0.2405)	loss 1.0566 (0.8938)	grad_norm 1.4902 (1.4514)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:36:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:46 lr 0.000001	 wd 0.0000	time 0.1617 (0.2376)	loss 0.7690 (0.8940)	grad_norm 1.5508 (1.4520)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:37:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:21 lr 0.000001	 wd 0.0000	time 0.1640 (0.2347)	loss 0.8291 (0.8948)	grad_norm 1.5438 (1.4538)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:37:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:01:56 lr 0.000001	 wd 0.0000	time 0.1621 (0.2320)	loss 0.9668 (0.8949)	grad_norm 1.6268 (1.4553)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:37:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:32 lr 0.000001	 wd 0.0000	time 0.2093 (0.2298)	loss 0.8604 (0.8948)	grad_norm 1.7987 (1.4558)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:38:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:09 lr 0.000001	 wd 0.0000	time 0.1745 (0.2300)	loss 0.9854 (0.8943)	grad_norm 1.2041 (1.4563)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:38:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:46 lr 0.000001	 wd 0.0000	time 0.1950 (0.2284)	loss 0.8403 (0.8942)	grad_norm 1.6069 (1.4573)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:38:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:23 lr 0.000001	 wd 0.0000	time 0.1901 (0.2264)	loss 0.8809 (0.8943)	grad_norm 1.2901 (1.4565)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:38:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1581 (0.2242)	loss 1.0762 (0.8941)	grad_norm 1.2068 (1.4566)	loss_scale 32768.0000 (32768.0000)	mem 8211MB
[2024-07-26 14:39:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 29 training takes 0:09:28
[2024-07-26 14:39:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_29.pth saving......
[2024-07-26 14:39:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_conv_b_step_stage1/ckpt_epoch_29.pth saved !!!
[2024-07-26 14:39:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 38.248 (38.248)	Loss 0.3635 (0.3635)	Acc@1 91.211 (91.211)	Acc@5 98.633 (98.633)	Mem 8211MB
[2024-07-26 14:40:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.998 Acc@5 97.518
[2024-07-26 14:40:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-26 14:40:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 85.02%
[2024-07-26 14:40:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 189): INFO Training time 4:56:54
