[2024-07-28 19:42:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 366): INFO Full config saved to pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/config.json
[2024-07-28 19:42:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: convnext_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 27
    - 3
    DIMS:
    - 128
    - 256
    - 512
    - 1024
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: sequence_stage2
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_conv_b_sequence_stage2
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 0.0001
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 0.8
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.0e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 1.0e-08

[2024-07-28 19:42:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/diffusion_finetune/convnext/convnext/diffusion_ft_convnext_base_224_22kto1k_sequence_stage_process2.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/diffusion-ft", "tag": "diffusion_ft_conv_b_sequence_stage2", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-28 19:43:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 108): INFO Creating model:convnext_diffusion_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2
[2024-07-28 19:43:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 110): INFO ConvNeXt_Diffusion_Finetune(
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (3): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (4): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (5): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (6): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (7): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (8): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (9): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (10): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (11): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (12): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (13): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (14): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (15): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (16): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (17): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (18): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (19): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (20): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (21): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (22): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (23): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (24): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (25): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (26): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-28 19:43:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 113): INFO number of params: 63247464
[2024-07-28 19:43:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 150): INFO no checkpoint found in pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2, ignoring auto resume
[2024-07-28 19:43:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth for fine-tuning......
[2024-07-28 19:43:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 127): WARNING <All keys matched successfully>
[2024-07-28 19:43:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_conv_b_sequence_stage1/ckpt_epoch_best.pth'
[2024-07-28 19:44:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 62.177 (62.177)	Loss 0.3628 (0.3628)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 3387MB
[2024-07-28 19:44:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.010 Acc@5 97.532
[2024-07-28 19:44:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 162): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-28 19:44:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 168): INFO Start training
[2024-07-28 19:44:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][0/2502]	eta 15:39:27 lr 0.000100	 wd 0.0000	time 22.5290 (22.5290)	loss 0.8389 (0.8389)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 11441MB
[2024-07-28 19:45:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:21:43 lr 0.000100	 wd 0.0000	time 0.3017 (0.5427)	loss 0.8999 (0.8765)	grad_norm 2.7339 (nan)	loss_scale 16384.0000 (22386.0594)	mem 11441MB
[2024-07-28 19:45:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:16:13 lr 0.000100	 wd 0.0000	time 0.2816 (0.4229)	loss 0.8999 (0.8882)	grad_norm 2.7670 (nan)	loss_scale 16384.0000 (19399.9602)	mem 11441MB
[2024-07-28 19:46:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:14:01 lr 0.000100	 wd 0.0000	time 0.2791 (0.3823)	loss 0.8608 (0.8938)	grad_norm 2.1039 (nan)	loss_scale 16384.0000 (18397.9801)	mem 11441MB
[2024-07-28 19:46:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:12:43 lr 0.000100	 wd 0.0000	time 0.2913 (0.3633)	loss 1.1787 (0.8967)	grad_norm 1.9025 (nan)	loss_scale 16384.0000 (17895.7406)	mem 11441MB
[2024-07-28 19:47:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:11:42 lr 0.000100	 wd 0.0000	time 0.2760 (0.3508)	loss 0.7739 (0.8978)	grad_norm 2.5274 (nan)	loss_scale 16384.0000 (17593.9960)	mem 11441MB
[2024-07-28 19:47:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:10:51 lr 0.000100	 wd 0.0000	time 0.2733 (0.3428)	loss 0.8330 (0.8981)	grad_norm 2.0722 (nan)	loss_scale 16384.0000 (17392.6656)	mem 11441MB
[2024-07-28 19:48:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:10:07 lr 0.000100	 wd 0.0000	time 0.2954 (0.3373)	loss 0.9448 (0.8990)	grad_norm 3.2171 (nan)	loss_scale 16384.0000 (17248.7760)	mem 11441MB
[2024-07-28 19:48:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:09:28 lr 0.000100	 wd 0.0000	time 0.2802 (0.3340)	loss 0.9189 (0.8982)	grad_norm 1.9169 (nan)	loss_scale 16384.0000 (17140.8140)	mem 11441MB
[2024-07-28 19:49:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:08:49 lr 0.000100	 wd 0.0000	time 0.2852 (0.3306)	loss 0.9414 (0.8972)	grad_norm 2.5036 (nan)	loss_scale 16384.0000 (17056.8169)	mem 11441MB
[2024-07-28 19:49:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:08:12 lr 0.000100	 wd 0.0000	time 0.2714 (0.3280)	loss 0.9844 (0.8976)	grad_norm 2.0396 (nan)	loss_scale 16384.0000 (16989.6024)	mem 11441MB
[2024-07-28 19:50:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:07:37 lr 0.000100	 wd 0.0000	time 0.2799 (0.3265)	loss 0.8286 (0.8978)	grad_norm 2.4872 (nan)	loss_scale 16384.0000 (16934.5976)	mem 11441MB
[2024-07-28 19:50:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:07:02 lr 0.000100	 wd 0.0000	time 0.2924 (0.3245)	loss 0.8672 (0.8979)	grad_norm 1.8399 (nan)	loss_scale 16384.0000 (16888.7527)	mem 11441MB
[2024-07-28 19:51:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:06:28 lr 0.000100	 wd 0.0000	time 0.2851 (0.3229)	loss 0.7354 (0.8990)	grad_norm 1.8344 (nan)	loss_scale 16384.0000 (16849.9554)	mem 11441MB
[2024-07-28 19:52:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:06:24 lr 0.000100	 wd 0.0000	time 0.6462 (0.3491)	loss 0.9287 (0.8989)	grad_norm 2.6741 (nan)	loss_scale 16384.0000 (16816.6966)	mem 11441MB
[2024-07-28 19:53:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:06:02 lr 0.000100	 wd 0.0000	time 0.2897 (0.3614)	loss 0.9668 (0.8992)	grad_norm 2.1503 (nan)	loss_scale 16384.0000 (16787.8694)	mem 11441MB
[2024-07-28 19:53:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:05:22 lr 0.000100	 wd 0.0000	time 0.2937 (0.3578)	loss 0.9912 (0.8988)	grad_norm 1.8795 (nan)	loss_scale 16384.0000 (16762.6433)	mem 11441MB
[2024-07-28 19:54:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:04:44 lr 0.000100	 wd 0.0000	time 0.2942 (0.3548)	loss 0.8066 (0.8988)	grad_norm 2.1611 (nan)	loss_scale 16384.0000 (16740.3833)	mem 11441MB
[2024-07-28 19:54:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:04:07 lr 0.000100	 wd 0.0000	time 0.2809 (0.3528)	loss 0.9019 (0.8984)	grad_norm 2.1995 (nan)	loss_scale 16384.0000 (16720.5952)	mem 11441MB
[2024-07-28 19:55:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:03:30 lr 0.000100	 wd 0.0000	time 0.2640 (0.3504)	loss 0.8652 (0.8980)	grad_norm 1.5962 (nan)	loss_scale 16384.0000 (16702.8890)	mem 11441MB
[2024-07-28 19:55:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:54 lr 0.000100	 wd 0.0000	time 0.2938 (0.3482)	loss 0.9619 (0.8987)	grad_norm 1.8889 (nan)	loss_scale 16384.0000 (16686.9525)	mem 11441MB
[2024-07-28 19:56:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:02:19 lr 0.000100	 wd 0.0000	time 0.2699 (0.3464)	loss 0.8516 (0.8991)	grad_norm 1.7368 (nan)	loss_scale 16384.0000 (16672.5331)	mem 11441MB
[2024-07-28 19:57:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:44 lr 0.000100	 wd 0.0000	time 0.3097 (0.3447)	loss 0.9121 (0.8988)	grad_norm 1.9204 (nan)	loss_scale 16384.0000 (16659.4239)	mem 11441MB
[2024-07-28 19:57:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:01:09 lr 0.000100	 wd 0.0000	time 0.2650 (0.3429)	loss 1.0293 (0.8986)	grad_norm 1.7433 (nan)	loss_scale 16384.0000 (16647.4542)	mem 11441MB
[2024-07-28 19:58:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:34 lr 0.000100	 wd 0.0000	time 0.2862 (0.3414)	loss 0.8296 (0.8985)	grad_norm 2.4744 (nan)	loss_scale 16384.0000 (16636.4815)	mem 11441MB
[2024-07-28 19:58:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000100	 wd 0.0000	time 0.2707 (0.3485)	loss 1.0244 (0.8983)	grad_norm 1.9611 (nan)	loss_scale 16384.0000 (16626.3862)	mem 11441MB
[2024-07-28 19:58:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 0 training takes 0:14:37
[2024-07-28 19:58:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_0.pth saving......
[2024-07-28 19:59:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_0.pth saved !!!
[2024-07-28 20:00:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 68.442 (68.442)	Loss 0.3655 (0.3655)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 11441MB
[2024-07-28 20:00:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.866 Acc@5 97.502
[2024-07-28 20:00:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-28 20:00:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.87%
[2024-07-28 20:00:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-28 20:00:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-28 20:00:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][0/2502]	eta 9:22:34 lr 0.000100	 wd 0.0000	time 13.4911 (13.4911)	loss 0.8647 (0.8647)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:01:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:18:27 lr 0.000100	 wd 0.0000	time 0.3079 (0.4612)	loss 0.7778 (0.8863)	grad_norm 1.8053 (1.9976)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:01:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:14:44 lr 0.000100	 wd 0.0000	time 0.2784 (0.3844)	loss 1.0381 (0.8939)	grad_norm 1.8394 (1.9881)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:02:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:13:06 lr 0.000100	 wd 0.0000	time 0.2809 (0.3571)	loss 1.0098 (0.8909)	grad_norm 1.8906 (1.9819)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:02:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:12:01 lr 0.000100	 wd 0.0000	time 0.3117 (0.3433)	loss 0.7876 (0.8921)	grad_norm 2.0404 (1.9854)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:03:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:11:11 lr 0.000100	 wd 0.0000	time 0.2809 (0.3355)	loss 0.9009 (0.8897)	grad_norm 1.8209 (1.9855)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:03:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:10:27 lr 0.000100	 wd 0.0000	time 0.2959 (0.3298)	loss 0.9634 (0.8909)	grad_norm 1.9354 (1.9856)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:04:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:09:47 lr 0.000100	 wd 0.0000	time 0.2924 (0.3260)	loss 0.7764 (0.8906)	grad_norm 2.1425 (2.0027)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:04:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:09:10 lr 0.000100	 wd 0.0000	time 0.2754 (0.3234)	loss 0.8027 (0.8918)	grad_norm 1.8301 (2.0001)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:05:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:08:34 lr 0.000099	 wd 0.0000	time 0.2946 (0.3212)	loss 0.9375 (0.8916)	grad_norm 1.7925 (1.9879)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:05:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:07:59 lr 0.000099	 wd 0.0000	time 0.3036 (0.3195)	loss 0.9131 (0.8911)	grad_norm 1.9091 (1.9830)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:06:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:07:26 lr 0.000099	 wd 0.0000	time 0.4654 (0.3186)	loss 1.0293 (0.8913)	grad_norm 2.5352 (1.9829)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:06:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:06:53 lr 0.000099	 wd 0.0000	time 0.2936 (0.3176)	loss 0.9004 (0.8911)	grad_norm 1.8631 (1.9811)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:07:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:06:20 lr 0.000099	 wd 0.0000	time 0.2586 (0.3165)	loss 0.9517 (0.8920)	grad_norm 1.8443 (1.9795)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:07:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:05:47 lr 0.000099	 wd 0.0000	time 0.2890 (0.3156)	loss 0.8999 (0.8926)	grad_norm 2.0150 (1.9775)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:09:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:06:00 lr 0.000099	 wd 0.0000	time 0.3009 (0.3600)	loss 0.9434 (0.8927)	grad_norm 2.0761 (1.9793)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:10:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:05:25 lr 0.000099	 wd 0.0000	time 0.2632 (0.3611)	loss 0.9868 (0.8934)	grad_norm 1.7532 (1.9819)	loss_scale 32768.0000 (17079.8851)	mem 11441MB
[2024-07-28 20:10:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:04:46 lr 0.000099	 wd 0.0000	time 0.2769 (0.3578)	loss 0.7690 (0.8932)	grad_norm 2.2417 (1.9808)	loss_scale 32768.0000 (18002.1728)	mem 11441MB
[2024-07-28 20:11:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:04:09 lr 0.000099	 wd 0.0000	time 0.2989 (0.3550)	loss 1.0537 (0.8937)	grad_norm 1.8867 (inf)	loss_scale 16384.0000 (18585.5147)	mem 11441MB
[2024-07-28 20:11:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:03:32 lr 0.000099	 wd 0.0000	time 0.2616 (0.3528)	loss 0.8872 (0.8944)	grad_norm 1.9932 (inf)	loss_scale 16384.0000 (18469.7065)	mem 11441MB
[2024-07-28 20:12:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:55 lr 0.000099	 wd 0.0000	time 0.2948 (0.3505)	loss 0.7856 (0.8939)	grad_norm 1.7348 (inf)	loss_scale 16384.0000 (18365.4733)	mem 11441MB
[2024-07-28 20:12:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:02:20 lr 0.000099	 wd 0.0000	time 0.2721 (0.3483)	loss 0.8423 (0.8941)	grad_norm 2.0019 (inf)	loss_scale 16384.0000 (18271.1623)	mem 11441MB
[2024-07-28 20:13:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:44 lr 0.000099	 wd 0.0000	time 0.2778 (0.3467)	loss 0.7124 (0.8941)	grad_norm 1.9894 (inf)	loss_scale 16384.0000 (18185.4212)	mem 11441MB
[2024-07-28 20:13:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:01:09 lr 0.000099	 wd 0.0000	time 0.2890 (0.3449)	loss 1.0977 (0.8945)	grad_norm 1.8071 (inf)	loss_scale 16384.0000 (18107.1326)	mem 11441MB
[2024-07-28 20:14:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:35 lr 0.000099	 wd 0.0000	time 0.2880 (0.3433)	loss 0.9438 (0.8944)	grad_norm 2.0196 (inf)	loss_scale 16384.0000 (18035.3653)	mem 11441MB
[2024-07-28 20:14:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000099	 wd 0.0000	time 0.2763 (0.3416)	loss 1.0820 (0.8946)	grad_norm 1.5280 (inf)	loss_scale 16384.0000 (17969.3371)	mem 11441MB
[2024-07-28 20:14:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 1 training takes 0:14:29
[2024-07-28 20:16:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 75.955 (75.955)	Loss 0.3718 (0.3718)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 11441MB
[2024-07-28 20:16:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.894 Acc@5 97.512
[2024-07-28 20:16:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-28 20:16:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.89%
[2024-07-28 20:16:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-28 20:16:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-28 20:16:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][0/2502]	eta 10:03:26 lr 0.000099	 wd 0.0000	time 14.4709 (14.4709)	loss 0.8115 (0.8115)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:17:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:17:40 lr 0.000099	 wd 0.0000	time 0.2584 (0.4415)	loss 0.8994 (0.8881)	grad_norm 1.6801 (1.9870)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:17:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:14:22 lr 0.000099	 wd 0.0000	time 0.3160 (0.3748)	loss 0.8828 (0.8822)	grad_norm 1.6151 (1.9645)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:18:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:12:51 lr 0.000099	 wd 0.0000	time 0.2726 (0.3503)	loss 0.9565 (0.8823)	grad_norm 1.6130 (1.9708)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:18:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:11:50 lr 0.000099	 wd 0.0000	time 0.2787 (0.3381)	loss 0.7915 (0.8824)	grad_norm 2.1807 (1.9767)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:19:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:11:02 lr 0.000099	 wd 0.0000	time 0.2664 (0.3311)	loss 1.0781 (0.8805)	grad_norm 2.1007 (1.9835)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:19:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:10:20 lr 0.000099	 wd 0.0000	time 0.2966 (0.3265)	loss 0.9302 (0.8814)	grad_norm 2.0527 (1.9866)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:20:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:09:42 lr 0.000099	 wd 0.0000	time 0.2686 (0.3231)	loss 1.0107 (0.8819)	grad_norm 2.1069 (1.9820)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:20:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:09:05 lr 0.000099	 wd 0.0000	time 0.2982 (0.3204)	loss 0.8018 (0.8812)	grad_norm 1.9060 (1.9824)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:21:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:08:30 lr 0.000098	 wd 0.0000	time 0.2890 (0.3188)	loss 0.8628 (0.8821)	grad_norm 1.8148 (1.9740)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:21:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:07:56 lr 0.000098	 wd 0.0000	time 0.2763 (0.3172)	loss 0.8091 (0.8825)	grad_norm 1.7449 (1.9701)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:22:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:07:22 lr 0.000098	 wd 0.0000	time 0.2642 (0.3158)	loss 0.9014 (0.8824)	grad_norm 2.0969 (1.9664)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:23:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:07:30 lr 0.000098	 wd 0.0000	time 0.5746 (0.3460)	loss 1.0557 (0.8817)	grad_norm 1.6749 (1.9632)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:24:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:07:25 lr 0.000098	 wd 0.0000	time 0.2895 (0.3709)	loss 0.9395 (0.8829)	grad_norm 2.2923 (1.9718)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:25:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:06:43 lr 0.000098	 wd 0.0000	time 0.2879 (0.3660)	loss 0.8906 (0.8831)	grad_norm 1.7760 (1.9782)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:25:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:06:02 lr 0.000098	 wd 0.0000	time 0.2953 (0.3620)	loss 0.8525 (0.8830)	grad_norm 1.8050 (1.9748)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:26:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:05:23 lr 0.000098	 wd 0.0000	time 0.2908 (0.3585)	loss 0.9038 (0.8832)	grad_norm 2.3186 (1.9739)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:26:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:04:45 lr 0.000098	 wd 0.0000	time 0.2789 (0.3554)	loss 0.9185 (0.8837)	grad_norm 2.0267 (1.9708)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:27:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:04:07 lr 0.000098	 wd 0.0000	time 0.3020 (0.3525)	loss 0.7925 (0.8834)	grad_norm 1.9974 (1.9679)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:27:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:03:31 lr 0.000098	 wd 0.0000	time 0.2845 (0.3506)	loss 0.7944 (0.8840)	grad_norm 1.8625 (1.9711)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:28:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:02:54 lr 0.000098	 wd 0.0000	time 0.2955 (0.3485)	loss 0.8721 (0.8838)	grad_norm 1.5338 (1.9715)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:28:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:02:19 lr 0.000098	 wd 0.0000	time 0.2595 (0.3465)	loss 0.9956 (0.8843)	grad_norm 1.7958 (1.9688)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:29:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:45 lr 0.000098	 wd 0.0000	time 0.2939 (0.3494)	loss 0.8423 (0.8841)	grad_norm 1.8018 (1.9642)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:29:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:01:10 lr 0.000098	 wd 0.0000	time 0.3169 (0.3486)	loss 1.0146 (0.8840)	grad_norm 1.6160 (1.9607)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:30:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:35 lr 0.000098	 wd 0.0000	time 0.3572 (0.3482)	loss 1.1221 (0.8842)	grad_norm 2.2233 (1.9610)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:31:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000098	 wd 0.0000	time 0.2841 (0.3517)	loss 0.8359 (0.8845)	grad_norm 1.6060 (1.9582)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:31:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 2 training takes 0:14:51
[2024-07-28 20:32:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 72.236 (72.236)	Loss 0.3494 (0.3494)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 11441MB
[2024-07-28 20:32:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.986 Acc@5 97.504
[2024-07-28 20:32:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-28 20:32:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.99%
[2024-07-28 20:32:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-28 20:32:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-28 20:33:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][0/2502]	eta 11:23:47 lr 0.000098	 wd 0.0000	time 16.3981 (16.3981)	loss 0.7710 (0.7710)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:33:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:18:26 lr 0.000098	 wd 0.0000	time 0.2848 (0.4608)	loss 0.8359 (0.8757)	grad_norm 2.0859 (1.9444)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:34:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:14:44 lr 0.000097	 wd 0.0000	time 0.2679 (0.3842)	loss 0.8545 (0.8773)	grad_norm 1.7393 (1.9562)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:34:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:13:04 lr 0.000097	 wd 0.0000	time 0.2813 (0.3563)	loss 0.9966 (0.8792)	grad_norm 1.9923 (1.9470)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:35:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:11:59 lr 0.000097	 wd 0.0000	time 0.2779 (0.3423)	loss 0.9058 (0.8792)	grad_norm 1.7735 (1.9445)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:35:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:11:09 lr 0.000097	 wd 0.0000	time 0.2807 (0.3345)	loss 0.8613 (0.8783)	grad_norm 1.7753 (1.9259)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:36:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:10:25 lr 0.000097	 wd 0.0000	time 0.2815 (0.3290)	loss 0.8135 (0.8778)	grad_norm 2.8634 (1.9308)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:36:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:09:45 lr 0.000097	 wd 0.0000	time 0.2788 (0.3250)	loss 1.0459 (0.8783)	grad_norm 2.3787 (1.9391)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:37:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:09:08 lr 0.000097	 wd 0.0000	time 0.2638 (0.3225)	loss 0.9629 (0.8793)	grad_norm 2.1305 (1.9348)	loss_scale 32768.0000 (16997.6330)	mem 11441MB
[2024-07-28 20:37:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:08:33 lr 0.000097	 wd 0.0000	time 0.2809 (0.3208)	loss 0.9863 (0.8797)	grad_norm 1.8351 (inf)	loss_scale 16384.0000 (18093.3185)	mem 11441MB
[2024-07-28 20:38:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:07:59 lr 0.000097	 wd 0.0000	time 0.2549 (0.3190)	loss 0.9624 (0.8811)	grad_norm 1.8316 (inf)	loss_scale 16384.0000 (17922.5574)	mem 11441MB
[2024-07-28 20:38:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:07:24 lr 0.000097	 wd 0.0000	time 0.2545 (0.3174)	loss 0.8794 (0.8823)	grad_norm 2.1665 (inf)	loss_scale 16384.0000 (17782.8156)	mem 11441MB
[2024-07-28 20:39:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:07:36 lr 0.000097	 wd 0.0000	time 0.5054 (0.3507)	loss 0.9746 (0.8827)	grad_norm 1.8553 (inf)	loss_scale 16384.0000 (17666.3447)	mem 11441MB
[2024-07-28 20:40:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:07:26 lr 0.000097	 wd 0.0000	time 0.2783 (0.3711)	loss 0.9971 (0.8830)	grad_norm 2.3151 (inf)	loss_scale 16384.0000 (17567.7786)	mem 11441MB
[2024-07-28 20:41:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:06:43 lr 0.000097	 wd 0.0000	time 0.2799 (0.3663)	loss 0.8047 (0.8834)	grad_norm 1.8553 (inf)	loss_scale 16384.0000 (17483.2834)	mem 11441MB
[2024-07-28 20:41:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:06:02 lr 0.000097	 wd 0.0000	time 0.2977 (0.3623)	loss 0.7622 (0.8839)	grad_norm 1.9976 (inf)	loss_scale 16384.0000 (17410.0466)	mem 11441MB
[2024-07-28 20:42:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:05:23 lr 0.000096	 wd 0.0000	time 0.2759 (0.3588)	loss 0.8364 (0.8834)	grad_norm 1.6966 (inf)	loss_scale 16384.0000 (17345.9588)	mem 11441MB
[2024-07-28 20:42:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:04:45 lr 0.000096	 wd 0.0000	time 0.2807 (0.3556)	loss 0.8599 (0.8835)	grad_norm 2.0502 (inf)	loss_scale 16384.0000 (17289.4062)	mem 11441MB
[2024-07-28 20:43:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:04:07 lr 0.000096	 wd 0.0000	time 0.2602 (0.3528)	loss 0.9609 (0.8832)	grad_norm 1.7372 (inf)	loss_scale 16384.0000 (17239.1338)	mem 11441MB
[2024-07-28 20:43:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:03:31 lr 0.000096	 wd 0.0000	time 0.3120 (0.3509)	loss 0.8677 (0.8831)	grad_norm 2.0403 (inf)	loss_scale 16384.0000 (17194.1504)	mem 11441MB
[2024-07-28 20:44:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:55 lr 0.000096	 wd 0.0000	time 0.2831 (0.3486)	loss 0.8975 (0.8833)	grad_norm 2.1493 (inf)	loss_scale 16384.0000 (17153.6632)	mem 11441MB
[2024-07-28 20:44:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:02:19 lr 0.000096	 wd 0.0000	time 0.3028 (0.3466)	loss 0.8125 (0.8833)	grad_norm 1.7598 (inf)	loss_scale 16384.0000 (17117.0300)	mem 11441MB
[2024-07-28 20:45:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:44 lr 0.000096	 wd 0.0000	time 0.2944 (0.3461)	loss 0.9185 (0.8831)	grad_norm 1.8691 (inf)	loss_scale 16384.0000 (17083.7256)	mem 11441MB
[2024-07-28 20:46:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:01:11 lr 0.000096	 wd 0.0000	time 0.5080 (0.3523)	loss 0.9375 (0.8833)	grad_norm 1.9267 (inf)	loss_scale 16384.0000 (17053.3159)	mem 11441MB
[2024-07-28 20:46:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:35 lr 0.000096	 wd 0.0000	time 0.2922 (0.3514)	loss 0.9023 (0.8830)	grad_norm 1.7590 (inf)	loss_scale 16384.0000 (17025.4394)	mem 11441MB
[2024-07-28 20:48:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000096	 wd 0.0000	time 0.2792 (0.3687)	loss 0.9751 (0.8831)	grad_norm 2.0618 (inf)	loss_scale 16384.0000 (16999.7921)	mem 11441MB
[2024-07-28 20:48:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 3 training takes 0:15:28
[2024-07-28 20:49:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 51.966 (51.966)	Loss 0.3669 (0.3669)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 11441MB
[2024-07-28 20:49:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.064 Acc@5 97.506
[2024-07-28 20:49:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-28 20:49:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.06%
[2024-07-28 20:49:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-28 20:49:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-28 20:49:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][0/2502]	eta 10:17:14 lr 0.000096	 wd 0.0000	time 14.8021 (14.8021)	loss 0.8979 (0.8979)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:50:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:17:59 lr 0.000096	 wd 0.0000	time 0.2821 (0.4496)	loss 0.8257 (0.8705)	grad_norm 1.7929 (1.8674)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:50:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:14:30 lr 0.000096	 wd 0.0000	time 0.3061 (0.3782)	loss 0.9946 (0.8775)	grad_norm 1.9159 (1.8471)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:51:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:12:56 lr 0.000095	 wd 0.0000	time 0.2909 (0.3527)	loss 0.8428 (0.8784)	grad_norm 2.1310 (1.8640)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:51:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:11:54 lr 0.000095	 wd 0.0000	time 0.2843 (0.3398)	loss 0.9067 (0.8743)	grad_norm 1.7188 (1.8740)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:52:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:11:06 lr 0.000095	 wd 0.0000	time 0.2714 (0.3327)	loss 0.9814 (0.8743)	grad_norm 2.3314 (1.8843)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:52:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:10:23 lr 0.000095	 wd 0.0000	time 0.2919 (0.3276)	loss 0.8350 (0.8764)	grad_norm 1.9647 (1.8892)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:53:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:09:43 lr 0.000095	 wd 0.0000	time 0.2795 (0.3237)	loss 1.0244 (0.8750)	grad_norm 2.1517 (1.9020)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 20:53:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:09:07 lr 0.000095	 wd 0.0000	time 0.2840 (0.3216)	loss 0.8086 (0.8742)	grad_norm 1.6494 (inf)	loss_scale 8192.0000 (15422.6417)	mem 11441MB
[2024-07-28 20:54:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:08:32 lr 0.000095	 wd 0.0000	time 0.2767 (0.3199)	loss 0.9287 (0.8750)	grad_norm 1.9978 (inf)	loss_scale 8192.0000 (14620.1287)	mem 11441MB
[2024-07-28 20:54:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:07:57 lr 0.000095	 wd 0.0000	time 0.2590 (0.3179)	loss 0.8550 (0.8750)	grad_norm 1.8596 (inf)	loss_scale 8192.0000 (13977.9580)	mem 11441MB
[2024-07-28 20:55:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:07:24 lr 0.000095	 wd 0.0000	time 0.2928 (0.3168)	loss 0.9468 (0.8756)	grad_norm 1.8720 (inf)	loss_scale 8192.0000 (13452.4396)	mem 11441MB
[2024-07-28 20:55:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:06:51 lr 0.000095	 wd 0.0000	time 0.2801 (0.3160)	loss 0.7852 (0.8759)	grad_norm 1.8081 (inf)	loss_scale 8192.0000 (13014.4346)	mem 11441MB
[2024-07-28 20:56:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:06:18 lr 0.000095	 wd 0.0000	time 0.2816 (0.3149)	loss 0.7319 (0.8752)	grad_norm 2.1256 (inf)	loss_scale 8192.0000 (12643.7633)	mem 11441MB
[2024-07-28 20:56:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:05:46 lr 0.000094	 wd 0.0000	time 0.3052 (0.3141)	loss 0.8550 (0.8746)	grad_norm 2.4968 (inf)	loss_scale 8192.0000 (12326.0071)	mem 11441MB
[2024-07-28 20:57:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:05:43 lr 0.000094	 wd 0.0000	time 0.5253 (0.3431)	loss 0.8013 (0.8750)	grad_norm 1.6563 (inf)	loss_scale 8192.0000 (12050.5903)	mem 11441MB
[2024-07-28 20:58:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:05:15 lr 0.000094	 wd 0.0000	time 0.2974 (0.3501)	loss 0.9277 (0.8754)	grad_norm 1.7657 (inf)	loss_scale 8192.0000 (11809.5790)	mem 11441MB
[2024-07-28 20:59:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:04:38 lr 0.000094	 wd 0.0000	time 0.2819 (0.3475)	loss 0.8911 (0.8758)	grad_norm 1.9167 (inf)	loss_scale 8192.0000 (11596.9053)	mem 11441MB
[2024-07-28 20:59:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:04:02 lr 0.000094	 wd 0.0000	time 0.2891 (0.3450)	loss 0.9404 (0.8767)	grad_norm 2.4330 (inf)	loss_scale 8192.0000 (11407.8490)	mem 11441MB
[2024-07-28 21:00:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:03:26 lr 0.000094	 wd 0.0000	time 0.2803 (0.3434)	loss 0.8374 (0.8763)	grad_norm 1.9302 (inf)	loss_scale 8192.0000 (11238.6828)	mem 11441MB
[2024-07-28 21:00:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:02:51 lr 0.000094	 wd 0.0000	time 0.2757 (0.3417)	loss 0.7666 (0.8759)	grad_norm 1.5807 (inf)	loss_scale 8192.0000 (11086.4248)	mem 11441MB
[2024-07-28 21:01:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:02:16 lr 0.000094	 wd 0.0000	time 0.2540 (0.3400)	loss 0.7979 (0.8759)	grad_norm 1.9914 (inf)	loss_scale 8192.0000 (10948.6606)	mem 11441MB
[2024-07-28 21:01:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:42 lr 0.000094	 wd 0.0000	time 0.2707 (0.3385)	loss 0.8906 (0.8757)	grad_norm 1.8070 (inf)	loss_scale 8192.0000 (10823.4148)	mem 11441MB
[2024-07-28 21:02:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:01:08 lr 0.000094	 wd 0.0000	time 0.2901 (0.3372)	loss 0.8267 (0.8760)	grad_norm 2.1752 (inf)	loss_scale 8192.0000 (10709.0552)	mem 11441MB
[2024-07-28 21:02:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:34 lr 0.000093	 wd 0.0000	time 0.2647 (0.3358)	loss 0.7900 (0.8762)	grad_norm 1.7000 (inf)	loss_scale 8192.0000 (10604.2216)	mem 11441MB
[2024-07-28 21:03:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000093	 wd 0.0000	time 0.2773 (0.3344)	loss 0.7529 (0.8762)	grad_norm 2.1339 (inf)	loss_scale 8192.0000 (10507.7713)	mem 11441MB
[2024-07-28 21:03:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 4 training takes 0:14:01
[2024-07-28 21:04:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 61.626 (61.626)	Loss 0.3591 (0.3591)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 11441MB
[2024-07-28 21:04:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.062 Acc@5 97.506
[2024-07-28 21:04:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-28 21:04:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.06%
[2024-07-28 21:05:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][0/2502]	eta 1 day, 4:12:21 lr 0.000093	 wd 0.0000	time 40.5840 (40.5840)	loss 1.0215 (1.0215)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:05:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:28:06 lr 0.000093	 wd 0.0000	time 0.2809 (0.7020)	loss 0.7925 (0.8684)	grad_norm 1.7418 (1.9303)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:06:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:19:17 lr 0.000093	 wd 0.0000	time 0.2902 (0.5030)	loss 0.7881 (0.8748)	grad_norm 2.2170 (1.9345)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:06:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:16:03 lr 0.000093	 wd 0.0000	time 0.2814 (0.4377)	loss 0.8218 (0.8722)	grad_norm 1.9409 (1.9427)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:07:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:14:07 lr 0.000093	 wd 0.0000	time 0.2796 (0.4034)	loss 0.7515 (0.8708)	grad_norm 1.8148 (1.9409)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:07:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:12:46 lr 0.000093	 wd 0.0000	time 0.2728 (0.3829)	loss 0.8799 (0.8705)	grad_norm 2.4405 (1.9419)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:08:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:11:43 lr 0.000093	 wd 0.0000	time 0.2525 (0.3697)	loss 1.1279 (0.8734)	grad_norm 1.7724 (1.9420)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:08:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:10:49 lr 0.000093	 wd 0.0000	time 0.3202 (0.3602)	loss 0.8872 (0.8731)	grad_norm 1.7737 (1.9362)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:09:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:10:00 lr 0.000093	 wd 0.0000	time 0.2623 (0.3529)	loss 0.9375 (0.8740)	grad_norm 1.6730 (1.9328)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:09:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:09:16 lr 0.000092	 wd 0.0000	time 0.2715 (0.3475)	loss 0.8252 (0.8738)	grad_norm 1.8627 (1.9365)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:10:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:08:35 lr 0.000092	 wd 0.0000	time 0.2885 (0.3433)	loss 0.8179 (0.8739)	grad_norm 2.0333 (1.9306)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:10:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:07:56 lr 0.000092	 wd 0.0000	time 0.2798 (0.3397)	loss 0.7764 (0.8746)	grad_norm 2.0704 (1.9331)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:11:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:07:18 lr 0.000092	 wd 0.0000	time 0.2872 (0.3367)	loss 1.0186 (0.8749)	grad_norm 1.6733 (1.9336)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:12:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:07:20 lr 0.000092	 wd 0.0000	time 0.5976 (0.3661)	loss 0.8701 (0.8750)	grad_norm 1.6542 (1.9311)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:13:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:06:59 lr 0.000092	 wd 0.0000	time 0.2852 (0.3810)	loss 0.8882 (0.8742)	grad_norm 2.0897 (1.9313)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:14:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:06:16 lr 0.000092	 wd 0.0000	time 0.2881 (0.3759)	loss 0.8955 (0.8741)	grad_norm 2.1007 (1.9282)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:14:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:05:35 lr 0.000092	 wd 0.0000	time 0.2904 (0.3714)	loss 0.8252 (0.8736)	grad_norm 1.6767 (1.9266)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:15:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:04:54 lr 0.000092	 wd 0.0000	time 0.2831 (0.3677)	loss 0.9702 (0.8738)	grad_norm 1.6916 (1.9294)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:15:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:04:15 lr 0.000091	 wd 0.0000	time 0.3020 (0.3641)	loss 0.8389 (0.8737)	grad_norm 1.5492 (1.9279)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:16:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:03:37 lr 0.000091	 wd 0.0000	time 0.2947 (0.3611)	loss 1.0049 (0.8741)	grad_norm 1.7202 (1.9335)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:16:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:03:00 lr 0.000091	 wd 0.0000	time 0.2875 (0.3592)	loss 1.0352 (0.8739)	grad_norm 1.6296 (1.9387)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:17:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:02:23 lr 0.000091	 wd 0.0000	time 0.2735 (0.3568)	loss 0.8994 (0.8731)	grad_norm 2.1299 (1.9416)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:17:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:47 lr 0.000091	 wd 0.0000	time 0.2715 (0.3545)	loss 0.8755 (0.8731)	grad_norm 1.7913 (1.9402)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 21:18:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:01:13 lr 0.000091	 wd 0.0000	time 0.3176 (0.3638)	loss 0.7158 (0.8726)	grad_norm 2.3014 (1.9413)	loss_scale 16384.0000 (8533.7784)	mem 11441MB
[2024-07-28 21:19:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:37 lr 0.000091	 wd 0.0000	time 0.2940 (0.3656)	loss 0.9160 (0.8724)	grad_norm 2.2727 (1.9391)	loss_scale 16384.0000 (8860.7347)	mem 11441MB
[2024-07-28 21:19:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000091	 wd 0.0000	time 0.2851 (0.3635)	loss 0.8535 (0.8726)	grad_norm 2.3094 (1.9389)	loss_scale 16384.0000 (9161.5450)	mem 11441MB
[2024-07-28 21:19:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 5 training takes 0:15:18
[2024-07-28 21:21:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 64.781 (64.781)	Loss 0.3589 (0.3589)	Acc@1 92.773 (92.773)	Acc@5 98.633 (98.633)	Mem 11441MB
[2024-07-28 21:21:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.114 Acc@5 97.578
[2024-07-28 21:21:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-28 21:21:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.11%
[2024-07-28 21:21:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-28 21:21:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-28 21:21:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][0/2502]	eta 13:13:08 lr 0.000091	 wd 0.0000	time 19.0201 (19.0201)	loss 0.9351 (0.9351)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:22:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:19:23 lr 0.000090	 wd 0.0000	time 0.2635 (0.4845)	loss 0.8130 (0.8706)	grad_norm 1.7807 (1.9195)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:22:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:15:09 lr 0.000090	 wd 0.0000	time 0.2999 (0.3952)	loss 0.7568 (0.8671)	grad_norm 2.3691 (1.9075)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:23:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:13:24 lr 0.000090	 wd 0.0000	time 0.2839 (0.3652)	loss 0.9097 (0.8675)	grad_norm 1.6600 (1.8915)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:23:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:12:14 lr 0.000090	 wd 0.0000	time 0.2966 (0.3494)	loss 0.8823 (0.8674)	grad_norm 1.5617 (1.8948)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:24:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:11:20 lr 0.000090	 wd 0.0000	time 0.2989 (0.3400)	loss 0.9165 (0.8657)	grad_norm 1.6631 (1.8987)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:24:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:10:35 lr 0.000090	 wd 0.0000	time 0.2783 (0.3341)	loss 0.9409 (0.8659)	grad_norm 1.8818 (1.8996)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:25:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:09:53 lr 0.000090	 wd 0.0000	time 0.2776 (0.3295)	loss 0.9185 (0.8677)	grad_norm 2.7645 (1.8991)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:25:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:09:14 lr 0.000090	 wd 0.0000	time 0.2881 (0.3259)	loss 0.8003 (0.8688)	grad_norm 1.7271 (1.9092)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:26:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:08:38 lr 0.000089	 wd 0.0000	time 0.2800 (0.3239)	loss 0.8804 (0.8687)	grad_norm 1.8821 (1.9198)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:26:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:08:03 lr 0.000089	 wd 0.0000	time 0.2681 (0.3220)	loss 0.8486 (0.8697)	grad_norm 1.5764 (1.9257)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:27:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:07:28 lr 0.000089	 wd 0.0000	time 0.2794 (0.3200)	loss 0.7661 (0.8690)	grad_norm 1.9034 (1.9276)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:27:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:06:54 lr 0.000089	 wd 0.0000	time 0.2700 (0.3187)	loss 0.7163 (0.8693)	grad_norm 2.0179 (1.9310)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:28:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:06:36 lr 0.000089	 wd 0.0000	time 0.3087 (0.3302)	loss 0.8706 (0.8703)	grad_norm 2.6330 (1.9324)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:29:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:06:10 lr 0.000089	 wd 0.0000	time 0.2976 (0.3362)	loss 1.0762 (0.8686)	grad_norm 2.0852 (1.9302)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:30:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:06:14 lr 0.000089	 wd 0.0000	time 0.2970 (0.3739)	loss 0.7090 (0.8686)	grad_norm 1.4527 (1.9293)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:31:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:05:38 lr 0.000089	 wd 0.0000	time 0.2819 (0.3748)	loss 0.9072 (0.8684)	grad_norm 1.7416 (1.9232)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:31:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:04:57 lr 0.000088	 wd 0.0000	time 0.2866 (0.3706)	loss 0.9536 (0.8674)	grad_norm 1.5674 (1.9212)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:32:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:04:17 lr 0.000088	 wd 0.0000	time 0.2942 (0.3670)	loss 0.7451 (0.8669)	grad_norm 1.8371 (1.9239)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:33:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:03:39 lr 0.000088	 wd 0.0000	time 0.2728 (0.3644)	loss 0.9585 (0.8669)	grad_norm 3.2418 (1.9245)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:33:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:03:01 lr 0.000088	 wd 0.0000	time 0.2732 (0.3616)	loss 1.0742 (0.8680)	grad_norm 2.1153 (1.9243)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:34:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:02:24 lr 0.000088	 wd 0.0000	time 0.3048 (0.3590)	loss 0.8911 (0.8684)	grad_norm 2.5385 (1.9295)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:34:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:47 lr 0.000088	 wd 0.0000	time 0.3469 (0.3571)	loss 0.9209 (0.8688)	grad_norm 2.1310 (1.9266)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:35:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:01:11 lr 0.000088	 wd 0.0000	time 0.2899 (0.3549)	loss 0.8667 (0.8687)	grad_norm 2.2858 (1.9251)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:35:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:35 lr 0.000087	 wd 0.0000	time 0.2928 (0.3529)	loss 0.8770 (0.8683)	grad_norm 1.9713 (1.9235)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:36:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000087	 wd 0.0000	time 0.2817 (0.3509)	loss 0.7563 (0.8679)	grad_norm 1.5987 (1.9215)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:36:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 6 training takes 0:14:59
[2024-07-28 21:37:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 70.000 (70.000)	Loss 0.3640 (0.3640)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 11441MB
[2024-07-28 21:38:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.094 Acc@5 97.544
[2024-07-28 21:38:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-28 21:38:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.11%
[2024-07-28 21:38:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][0/2502]	eta 11:43:58 lr 0.000087	 wd 0.0000	time 16.8817 (16.8817)	loss 1.0010 (1.0010)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:38:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:18:36 lr 0.000087	 wd 0.0000	time 0.2858 (0.4650)	loss 1.0225 (0.8716)	grad_norm 1.8174 (1.9311)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:39:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:14:53 lr 0.000087	 wd 0.0000	time 0.2886 (0.3880)	loss 0.8970 (0.8587)	grad_norm 1.9784 (1.9126)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:39:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:13:10 lr 0.000087	 wd 0.0000	time 0.2873 (0.3591)	loss 0.8560 (0.8595)	grad_norm 2.1033 (1.8849)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:40:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:12:04 lr 0.000087	 wd 0.0000	time 0.2822 (0.3447)	loss 0.9253 (0.8600)	grad_norm 1.6103 (1.8884)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:40:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:11:13 lr 0.000087	 wd 0.0000	time 0.2897 (0.3362)	loss 0.8135 (0.8605)	grad_norm 1.7999 (1.8921)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:41:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:10:28 lr 0.000086	 wd 0.0000	time 0.2834 (0.3307)	loss 0.8057 (0.8610)	grad_norm 1.4878 (1.8831)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:41:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:09:48 lr 0.000086	 wd 0.0000	time 0.2737 (0.3265)	loss 0.7734 (0.8604)	grad_norm 1.6529 (1.8846)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:42:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:09:10 lr 0.000086	 wd 0.0000	time 0.2881 (0.3235)	loss 0.8286 (0.8608)	grad_norm 1.9410 (1.8810)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:42:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:08:35 lr 0.000086	 wd 0.0000	time 0.2884 (0.3217)	loss 0.7212 (0.8612)	grad_norm 1.7891 (1.8803)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:43:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:08:00 lr 0.000086	 wd 0.0000	time 0.2830 (0.3197)	loss 0.8379 (0.8620)	grad_norm 2.0339 (1.8757)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:43:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:07:25 lr 0.000086	 wd 0.0000	time 0.2823 (0.3181)	loss 0.8267 (0.8609)	grad_norm 1.6887 (1.8788)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:44:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:06:53 lr 0.000086	 wd 0.0000	time 0.3093 (0.3173)	loss 0.7305 (0.8616)	grad_norm 1.7103 (1.8833)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:44:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:06:20 lr 0.000085	 wd 0.0000	time 0.2872 (0.3163)	loss 0.9204 (0.8614)	grad_norm 1.8249 (1.8786)	loss_scale 32768.0000 (17643.3390)	mem 11441MB
[2024-07-28 21:45:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:05:47 lr 0.000085	 wd 0.0000	time 0.2922 (0.3152)	loss 0.8833 (0.8625)	grad_norm 1.8637 (1.8764)	loss_scale 32768.0000 (18722.9008)	mem 11441MB
[2024-07-28 21:45:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:05:15 lr 0.000085	 wd 0.0000	time 0.3952 (0.3148)	loss 0.8013 (0.8618)	grad_norm 1.7281 (inf)	loss_scale 16384.0000 (19396.6476)	mem 11441MB
[2024-07-28 21:47:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:05:08 lr 0.000085	 wd 0.0000	time 0.2916 (0.3416)	loss 0.8960 (0.8623)	grad_norm 1.8559 (inf)	loss_scale 16384.0000 (19208.4747)	mem 11441MB
[2024-07-28 21:47:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:04:36 lr 0.000085	 wd 0.0000	time 0.2938 (0.3444)	loss 0.8081 (0.8622)	grad_norm 1.8457 (inf)	loss_scale 16384.0000 (19042.4268)	mem 11441MB
[2024-07-28 21:48:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:04:00 lr 0.000085	 wd 0.0000	time 0.2706 (0.3422)	loss 0.8037 (0.8614)	grad_norm 1.9029 (inf)	loss_scale 16384.0000 (18894.8184)	mem 11441MB
[2024-07-28 21:48:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:03:24 lr 0.000085	 wd 0.0000	time 0.2751 (0.3403)	loss 0.9873 (0.8622)	grad_norm 1.8071 (inf)	loss_scale 16384.0000 (18762.7396)	mem 11441MB
[2024-07-28 21:49:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:02:50 lr 0.000084	 wd 0.0000	time 0.2570 (0.3391)	loss 0.7686 (0.8621)	grad_norm 2.1245 (inf)	loss_scale 16384.0000 (18643.8621)	mem 11441MB
[2024-07-28 21:49:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:02:15 lr 0.000084	 wd 0.0000	time 0.2882 (0.3375)	loss 0.9277 (0.8624)	grad_norm 1.9100 (inf)	loss_scale 16384.0000 (18536.3008)	mem 11441MB
[2024-07-28 21:50:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:41 lr 0.000084	 wd 0.0000	time 0.2569 (0.3361)	loss 0.8369 (0.8622)	grad_norm 2.1081 (inf)	loss_scale 16384.0000 (18438.5134)	mem 11441MB
[2024-07-28 21:50:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:01:08 lr 0.000084	 wd 0.0000	time 0.2743 (0.3381)	loss 0.8662 (0.8621)	grad_norm 1.6603 (inf)	loss_scale 16384.0000 (18349.2256)	mem 11441MB
[2024-07-28 21:51:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:34 lr 0.000084	 wd 0.0000	time 0.5750 (0.3412)	loss 0.7793 (0.8627)	grad_norm 1.6405 (inf)	loss_scale 16384.0000 (18267.3753)	mem 11441MB
[2024-07-28 21:52:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000084	 wd 0.0000	time 0.2871 (0.3401)	loss 0.8086 (0.8632)	grad_norm 1.8025 (inf)	loss_scale 16384.0000 (18192.0704)	mem 11441MB
[2024-07-28 21:52:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 7 training takes 0:14:16
[2024-07-28 21:53:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 75.435 (75.435)	Loss 0.3542 (0.3542)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 11441MB
[2024-07-28 21:53:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.028 Acc@5 97.584
[2024-07-28 21:53:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-28 21:53:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.11%
[2024-07-28 21:54:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][0/2502]	eta 1 day, 3:14:12 lr 0.000084	 wd 0.0000	time 39.1896 (39.1896)	loss 0.9629 (0.9629)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:54:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:27:44 lr 0.000083	 wd 0.0000	time 0.2893 (0.6930)	loss 0.8208 (0.8670)	grad_norm 1.8413 (1.8999)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:55:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:19:07 lr 0.000083	 wd 0.0000	time 0.2699 (0.4985)	loss 0.7886 (0.8603)	grad_norm 1.7959 (1.9223)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:55:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:15:55 lr 0.000083	 wd 0.0000	time 0.2801 (0.4338)	loss 0.8921 (0.8566)	grad_norm 1.6519 (1.9049)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:56:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:14:01 lr 0.000083	 wd 0.0000	time 0.2807 (0.4005)	loss 0.9155 (0.8563)	grad_norm 1.6672 (1.9032)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:56:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:12:41 lr 0.000083	 wd 0.0000	time 0.2914 (0.3804)	loss 0.9136 (0.8581)	grad_norm 1.8075 (1.9079)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:57:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:11:38 lr 0.000083	 wd 0.0000	time 0.2783 (0.3674)	loss 0.7368 (0.8583)	grad_norm 1.9530 (1.9040)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:57:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:10:45 lr 0.000083	 wd 0.0000	time 0.2578 (0.3584)	loss 1.0049 (0.8570)	grad_norm 1.6007 (1.9139)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:58:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:09:57 lr 0.000082	 wd 0.0000	time 0.2859 (0.3513)	loss 0.9453 (0.8578)	grad_norm 1.7136 (1.9220)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:58:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:09:14 lr 0.000082	 wd 0.0000	time 0.2859 (0.3464)	loss 0.9404 (0.8573)	grad_norm 1.7766 (1.9175)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:59:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:08:33 lr 0.000082	 wd 0.0000	time 0.2752 (0.3420)	loss 0.9048 (0.8585)	grad_norm 1.7280 (1.9127)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 21:59:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:07:54 lr 0.000082	 wd 0.0000	time 0.2812 (0.3383)	loss 0.8350 (0.8588)	grad_norm 2.3318 (1.9094)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:00:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:07:16 lr 0.000082	 wd 0.0000	time 0.2697 (0.3354)	loss 0.8896 (0.8593)	grad_norm 2.1184 (1.9057)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:01:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:07:33 lr 0.000082	 wd 0.0000	time 0.3009 (0.3776)	loss 0.8130 (0.8598)	grad_norm 1.7757 (1.9078)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:02:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:06:56 lr 0.000081	 wd 0.0000	time 0.2928 (0.3781)	loss 0.8296 (0.8608)	grad_norm 1.8384 (1.9067)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:03:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:06:13 lr 0.000081	 wd 0.0000	time 0.2760 (0.3732)	loss 0.7451 (0.8607)	grad_norm 1.8445 (1.9035)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:03:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:05:32 lr 0.000081	 wd 0.0000	time 0.2930 (0.3689)	loss 0.9209 (0.8606)	grad_norm 2.2065 (1.9049)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:04:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:04:53 lr 0.000081	 wd 0.0000	time 0.2813 (0.3653)	loss 0.7690 (0.8612)	grad_norm 1.7703 (1.9067)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:04:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:04:14 lr 0.000081	 wd 0.0000	time 0.2753 (0.3619)	loss 0.7915 (0.8619)	grad_norm 2.4499 (1.9105)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:05:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:03:36 lr 0.000081	 wd 0.0000	time 0.2769 (0.3591)	loss 0.7812 (0.8613)	grad_norm 1.9720 (1.9089)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:05:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:02:59 lr 0.000080	 wd 0.0000	time 0.2599 (0.3570)	loss 0.9097 (0.8612)	grad_norm 1.9107 (inf)	loss_scale 8192.0000 (16130.1749)	mem 11441MB
[2024-07-28 22:06:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:02:22 lr 0.000080	 wd 0.0000	time 0.2992 (0.3548)	loss 0.9805 (0.8615)	grad_norm 1.9471 (inf)	loss_scale 8192.0000 (15752.3465)	mem 11441MB
[2024-07-28 22:06:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:46 lr 0.000080	 wd 0.0000	time 0.2844 (0.3526)	loss 0.9180 (0.8616)	grad_norm 2.0242 (inf)	loss_scale 8192.0000 (15408.8505)	mem 11441MB
[2024-07-28 22:07:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:01:13 lr 0.000080	 wd 0.0000	time 0.2867 (0.3624)	loss 0.9038 (0.8614)	grad_norm 2.1737 (inf)	loss_scale 8192.0000 (15095.2108)	mem 11441MB
[2024-07-28 22:08:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:37 lr 0.000080	 wd 0.0000	time 0.2892 (0.3652)	loss 0.9067 (0.8613)	grad_norm 2.5388 (inf)	loss_scale 8192.0000 (14807.6968)	mem 11441MB
[2024-07-28 22:09:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000080	 wd 0.0000	time 0.2799 (0.3728)	loss 0.9419 (0.8614)	grad_norm 2.1927 (inf)	loss_scale 8192.0000 (14543.1747)	mem 11441MB
[2024-07-28 22:09:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 8 training takes 0:15:40
[2024-07-28 22:10:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 65.443 (65.443)	Loss 0.3650 (0.3650)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 11441MB
[2024-07-28 22:10:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.212 Acc@5 97.568
[2024-07-28 22:10:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-28 22:10:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.21%
[2024-07-28 22:10:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-28 22:10:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-28 22:11:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][0/2502]	eta 10:30:30 lr 0.000080	 wd 0.0000	time 15.1202 (15.1202)	loss 0.7290 (0.7290)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:11:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:17:56 lr 0.000079	 wd 0.0000	time 0.2735 (0.4480)	loss 0.8535 (0.8482)	grad_norm 1.5659 (1.8500)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:12:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:14:28 lr 0.000079	 wd 0.0000	time 0.2919 (0.3773)	loss 0.7637 (0.8473)	grad_norm 2.4322 (1.8595)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:12:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:12:54 lr 0.000079	 wd 0.0000	time 0.2871 (0.3519)	loss 0.9307 (0.8543)	grad_norm 1.5634 (1.8494)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:13:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:11:53 lr 0.000079	 wd 0.0000	time 0.2560 (0.3392)	loss 0.7534 (0.8531)	grad_norm 1.5171 (1.8342)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:13:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:11:05 lr 0.000079	 wd 0.0000	time 0.2946 (0.3323)	loss 0.7607 (0.8517)	grad_norm 1.6623 (1.8328)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:14:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:10:22 lr 0.000079	 wd 0.0000	time 0.2917 (0.3272)	loss 0.8022 (0.8503)	grad_norm 1.9050 (1.8488)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:14:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:09:42 lr 0.000078	 wd 0.0000	time 0.2781 (0.3234)	loss 0.9414 (0.8510)	grad_norm 2.1339 (1.8490)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:15:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:09:05 lr 0.000078	 wd 0.0000	time 0.3034 (0.3206)	loss 0.9805 (0.8511)	grad_norm 1.6211 (1.8537)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:15:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:08:30 lr 0.000078	 wd 0.0000	time 0.2493 (0.3189)	loss 0.9727 (0.8524)	grad_norm 1.4474 (1.8509)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:16:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:07:56 lr 0.000078	 wd 0.0000	time 0.2827 (0.3173)	loss 0.8423 (0.8532)	grad_norm 1.7505 (1.8529)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:16:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:07:22 lr 0.000078	 wd 0.0000	time 0.2646 (0.3159)	loss 0.9277 (0.8527)	grad_norm 2.0172 (1.8544)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:17:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:06:50 lr 0.000078	 wd 0.0000	time 0.2931 (0.3153)	loss 0.8701 (0.8540)	grad_norm 1.7802 (1.8552)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:17:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:06:17 lr 0.000077	 wd 0.0000	time 0.2815 (0.3142)	loss 0.8433 (0.8542)	grad_norm 1.7443 (1.8611)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:18:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:05:45 lr 0.000077	 wd 0.0000	time 0.2831 (0.3133)	loss 0.9067 (0.8545)	grad_norm 1.7082 (1.8621)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:19:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:05:33 lr 0.000077	 wd 0.0000	time 6.9806 (0.3333)	loss 0.8276 (0.8556)	grad_norm 1.6052 (1.8664)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:20:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:05:13 lr 0.000077	 wd 0.0000	time 0.7848 (0.3478)	loss 0.8179 (0.8542)	grad_norm 1.9504 (1.8661)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:20:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:04:39 lr 0.000077	 wd 0.0000	time 0.2575 (0.3486)	loss 0.8110 (0.8542)	grad_norm 1.7679 (1.8682)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:21:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:04:02 lr 0.000077	 wd 0.0000	time 0.2585 (0.3461)	loss 0.8594 (0.8544)	grad_norm 1.7374 (1.8702)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:21:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:03:27 lr 0.000076	 wd 0.0000	time 0.2961 (0.3441)	loss 0.8750 (0.8548)	grad_norm 1.7238 (1.8715)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:22:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:02:52 lr 0.000076	 wd 0.0000	time 0.2804 (0.3427)	loss 0.7939 (0.8556)	grad_norm 2.1773 (1.8740)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:22:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:02:17 lr 0.000076	 wd 0.0000	time 0.2748 (0.3409)	loss 0.8188 (0.8557)	grad_norm 1.7179 (1.8767)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:23:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:42 lr 0.000076	 wd 0.0000	time 0.2687 (0.3393)	loss 0.6699 (0.8554)	grad_norm 1.9625 (1.8797)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:23:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:01:08 lr 0.000076	 wd 0.0000	time 0.2804 (0.3382)	loss 0.8198 (0.8552)	grad_norm 1.9323 (1.8812)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:24:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:34 lr 0.000075	 wd 0.0000	time 0.2798 (0.3368)	loss 0.9170 (0.8556)	grad_norm 1.9670 (1.8837)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:24:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000075	 wd 0.0000	time 0.2835 (0.3354)	loss 0.8540 (0.8559)	grad_norm 1.7470 (1.8834)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:24:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 9 training takes 0:14:03
[2024-07-28 22:25:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 61.771 (61.771)	Loss 0.3584 (0.3584)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 11441MB
[2024-07-28 22:26:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.122 Acc@5 97.516
[2024-07-28 22:26:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-28 22:26:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.21%
[2024-07-28 22:26:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][0/2502]	eta 18:59:38 lr 0.000075	 wd 0.0000	time 27.3296 (27.3296)	loss 0.9194 (0.9194)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:27:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:24:43 lr 0.000075	 wd 0.0000	time 0.2792 (0.6176)	loss 0.9341 (0.8665)	grad_norm 1.6891 (1.9152)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:27:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:17:38 lr 0.000075	 wd 0.0000	time 0.2802 (0.4598)	loss 0.8521 (0.8584)	grad_norm 2.1285 (1.9372)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:28:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:14:57 lr 0.000075	 wd 0.0000	time 0.2551 (0.4077)	loss 0.8545 (0.8557)	grad_norm 1.6645 (1.9282)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:28:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:13:21 lr 0.000075	 wd 0.0000	time 0.3045 (0.3815)	loss 0.8535 (0.8555)	grad_norm 1.8633 (1.9239)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:29:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:12:11 lr 0.000074	 wd 0.0000	time 0.2906 (0.3654)	loss 0.7998 (0.8574)	grad_norm 1.9568 (1.9259)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:29:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:11:15 lr 0.000074	 wd 0.0000	time 0.2870 (0.3549)	loss 0.8057 (0.8566)	grad_norm 1.8777 (1.9305)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:30:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:10:27 lr 0.000074	 wd 0.0000	time 0.2850 (0.3481)	loss 0.7617 (0.8537)	grad_norm 1.7862 (1.9347)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:30:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:09:42 lr 0.000074	 wd 0.0000	time 0.2848 (0.3422)	loss 0.8291 (0.8549)	grad_norm 2.1066 (1.9359)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:31:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:09:00 lr 0.000074	 wd 0.0000	time 0.2999 (0.3376)	loss 0.7720 (0.8542)	grad_norm 1.6439 (1.9308)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 22:31:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:08:22 lr 0.000073	 wd 0.0000	time 0.2977 (0.3347)	loss 0.9644 (0.8537)	grad_norm 1.6339 (1.9255)	loss_scale 16384.0000 (8732.1319)	mem 11441MB
[2024-07-28 22:32:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:07:44 lr 0.000073	 wd 0.0000	time 0.2664 (0.3316)	loss 0.9253 (0.8533)	grad_norm 1.7403 (1.9209)	loss_scale 16384.0000 (9427.1244)	mem 11441MB
[2024-07-28 22:32:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:07:08 lr 0.000073	 wd 0.0000	time 0.3000 (0.3290)	loss 0.9678 (0.8530)	grad_norm 1.5639 (1.9195)	loss_scale 16384.0000 (10006.3813)	mem 11441MB
[2024-07-28 22:33:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:06:33 lr 0.000073	 wd 0.0000	time 0.8651 (0.3278)	loss 0.8149 (0.8530)	grad_norm 1.9345 (1.9185)	loss_scale 16384.0000 (10496.5903)	mem 11441MB
[2024-07-28 22:34:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:06:25 lr 0.000073	 wd 0.0000	time 0.3229 (0.3502)	loss 0.8271 (0.8532)	grad_norm 2.3132 (1.9183)	loss_scale 16384.0000 (10916.8194)	mem 11441MB
[2024-07-28 22:34:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:05:54 lr 0.000073	 wd 0.0000	time 0.2799 (0.3542)	loss 0.8765 (0.8532)	grad_norm 1.8632 (1.9158)	loss_scale 16384.0000 (11281.0553)	mem 11441MB
[2024-07-28 22:35:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:05:16 lr 0.000072	 wd 0.0000	time 0.2791 (0.3510)	loss 0.6855 (0.8527)	grad_norm 2.0451 (1.9139)	loss_scale 16384.0000 (11599.7901)	mem 11441MB
[2024-07-28 22:35:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:04:39 lr 0.000072	 wd 0.0000	time 0.2789 (0.3483)	loss 0.7959 (0.8526)	grad_norm 2.1592 (1.9129)	loss_scale 16384.0000 (11881.0488)	mem 11441MB
[2024-07-28 22:36:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:04:03 lr 0.000072	 wd 0.0000	time 0.3002 (0.3462)	loss 0.9385 (0.8527)	grad_norm 1.7746 (1.9172)	loss_scale 16384.0000 (12131.0738)	mem 11441MB
[2024-07-28 22:37:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:03:27 lr 0.000072	 wd 0.0000	time 0.2763 (0.3441)	loss 0.9443 (0.8541)	grad_norm 1.8751 (1.9180)	loss_scale 16384.0000 (12354.7943)	mem 11441MB
[2024-07-28 22:37:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:02:51 lr 0.000072	 wd 0.0000	time 0.2960 (0.3422)	loss 1.0283 (0.8547)	grad_norm 3.0320 (1.9249)	loss_scale 16384.0000 (12556.1539)	mem 11441MB
[2024-07-28 22:38:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:02:16 lr 0.000071	 wd 0.0000	time 0.2764 (0.3405)	loss 0.8379 (0.8548)	grad_norm 2.0100 (1.9251)	loss_scale 16384.0000 (12738.3455)	mem 11441MB
[2024-07-28 22:38:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:42 lr 0.000071	 wd 0.0000	time 0.3008 (0.3393)	loss 0.8809 (0.8550)	grad_norm 1.8993 (1.9230)	loss_scale 16384.0000 (12903.9818)	mem 11441MB
[2024-07-28 22:39:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:01:08 lr 0.000071	 wd 0.0000	time 0.3080 (0.3378)	loss 0.9131 (0.8548)	grad_norm 1.5788 (1.9208)	loss_scale 16384.0000 (13055.2212)	mem 11441MB
[2024-07-28 22:39:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:34 lr 0.000071	 wd 0.0000	time 0.2698 (0.3364)	loss 0.9238 (0.8549)	grad_norm 1.9893 (1.9181)	loss_scale 16384.0000 (13193.8626)	mem 11441MB
[2024-07-28 22:40:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000071	 wd 0.0000	time 0.2792 (0.3441)	loss 0.7378 (0.8544)	grad_norm 1.4792 (1.9194)	loss_scale 16384.0000 (13321.4170)	mem 11441MB
[2024-07-28 22:40:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 10 training takes 0:14:30
[2024-07-28 22:41:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 56.777 (56.777)	Loss 0.3672 (0.3672)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 11441MB
[2024-07-28 22:41:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.300 Acc@5 97.536
[2024-07-28 22:41:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-28 22:41:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.30%
[2024-07-28 22:41:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-28 22:41:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-28 22:42:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][0/2502]	eta 9:50:48 lr 0.000071	 wd 0.0000	time 14.1679 (14.1679)	loss 0.8066 (0.8066)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:42:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:17:31 lr 0.000070	 wd 0.0000	time 0.2723 (0.4380)	loss 0.7905 (0.8495)	grad_norm 1.8923 (1.8903)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:43:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:14:18 lr 0.000070	 wd 0.0000	time 0.2925 (0.3728)	loss 0.8765 (0.8506)	grad_norm 1.7354 (1.8952)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:43:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:12:47 lr 0.000070	 wd 0.0000	time 0.2814 (0.3486)	loss 0.8267 (0.8476)	grad_norm 1.9244 (1.8862)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:44:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:11:47 lr 0.000070	 wd 0.0000	time 0.2715 (0.3367)	loss 0.7983 (0.8440)	grad_norm 2.0487 (1.8929)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:44:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:10:59 lr 0.000070	 wd 0.0000	time 0.2876 (0.3295)	loss 0.8354 (0.8422)	grad_norm 2.0561 (1.9119)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:45:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:10:18 lr 0.000069	 wd 0.0000	time 0.2813 (0.3251)	loss 0.9048 (0.8430)	grad_norm 1.8705 (1.9050)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:45:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:09:39 lr 0.000069	 wd 0.0000	time 0.2975 (0.3218)	loss 0.8296 (0.8437)	grad_norm 2.4409 (1.8984)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:46:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:09:03 lr 0.000069	 wd 0.0000	time 0.2699 (0.3194)	loss 0.9268 (0.8447)	grad_norm 1.5800 (1.9008)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:46:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:08:30 lr 0.000069	 wd 0.0000	time 0.3052 (0.3184)	loss 0.8818 (0.8477)	grad_norm 1.9526 (1.8981)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:47:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:07:55 lr 0.000069	 wd 0.0000	time 0.2911 (0.3169)	loss 0.8394 (0.8482)	grad_norm 1.7607 (1.8960)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:47:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:07:22 lr 0.000069	 wd 0.0000	time 0.2863 (0.3155)	loss 0.8594 (0.8477)	grad_norm 1.8074 (1.8965)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:48:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:07:14 lr 0.000068	 wd 0.0000	time 0.2967 (0.3337)	loss 0.9365 (0.8475)	grad_norm 2.0405 (1.8964)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:49:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:06:45 lr 0.000068	 wd 0.0000	time 0.3103 (0.3377)	loss 0.8076 (0.8482)	grad_norm 1.6529 (1.8969)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:50:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:06:50 lr 0.000068	 wd 0.0000	time 0.5737 (0.3728)	loss 0.8330 (0.8484)	grad_norm 1.8041 (1.8947)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:51:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:06:23 lr 0.000068	 wd 0.0000	time 0.2768 (0.3830)	loss 0.8218 (0.8478)	grad_norm 1.7516 (1.8910)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:51:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:05:41 lr 0.000068	 wd 0.0000	time 0.2570 (0.3781)	loss 0.7319 (0.8480)	grad_norm 1.8753 (1.8954)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:52:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:04:59 lr 0.000067	 wd 0.0000	time 0.2742 (0.3736)	loss 0.8438 (0.8475)	grad_norm 1.6688 (1.8963)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:52:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:04:19 lr 0.000067	 wd 0.0000	time 0.2963 (0.3701)	loss 0.8350 (0.8484)	grad_norm 1.6990 (1.8959)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:53:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:03:40 lr 0.000067	 wd 0.0000	time 0.3038 (0.3668)	loss 0.7822 (0.8490)	grad_norm 1.8002 (1.8921)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:53:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:03:02 lr 0.000067	 wd 0.0000	time 0.2673 (0.3636)	loss 0.6592 (0.8489)	grad_norm 1.9868 (1.8930)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:54:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:02:25 lr 0.000067	 wd 0.0000	time 0.3284 (0.3611)	loss 0.9395 (0.8486)	grad_norm 2.3839 (1.8929)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:54:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:48 lr 0.000066	 wd 0.0000	time 0.2622 (0.3586)	loss 0.9336 (0.8489)	grad_norm 1.7377 (1.8954)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:55:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:01:11 lr 0.000066	 wd 0.0000	time 0.2919 (0.3563)	loss 0.8389 (0.8489)	grad_norm 2.1084 (1.8987)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:55:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:36 lr 0.000066	 wd 0.0000	time 0.3158 (0.3542)	loss 0.8306 (0.8486)	grad_norm 2.0639 (1.8998)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 22:56:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000066	 wd 0.0000	time 0.2789 (0.3599)	loss 0.8354 (0.8485)	grad_norm 2.2878 (1.8987)	loss_scale 32768.0000 (16829.4666)	mem 11441MB
[2024-07-28 22:56:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 11 training takes 0:15:07
[2024-07-28 22:57:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 56.669 (56.669)	Loss 0.3599 (0.3599)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 11441MB
[2024-07-28 22:58:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.184 Acc@5 97.582
[2024-07-28 22:58:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-28 22:58:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.30%
[2024-07-28 22:58:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][0/2502]	eta 11:05:47 lr 0.000066	 wd 0.0000	time 15.9662 (15.9662)	loss 0.8076 (0.8076)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 11441MB
[2024-07-28 22:58:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:18:21 lr 0.000066	 wd 0.0000	time 0.2957 (0.4584)	loss 0.8164 (0.8463)	grad_norm 2.0578 (1.9605)	loss_scale 32768.0000 (32768.0000)	mem 11441MB
[2024-07-28 22:59:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:14:41 lr 0.000065	 wd 0.0000	time 0.2739 (0.3829)	loss 0.8096 (0.8434)	grad_norm 1.5978 (1.9542)	loss_scale 32768.0000 (32768.0000)	mem 11441MB
[2024-07-28 22:59:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:13:03 lr 0.000065	 wd 0.0000	time 0.2967 (0.3557)	loss 0.7793 (0.8509)	grad_norm 1.9728 (inf)	loss_scale 16384.0000 (27324.8106)	mem 11441MB
[2024-07-28 23:00:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:11:59 lr 0.000065	 wd 0.0000	time 0.2710 (0.3421)	loss 0.8042 (0.8498)	grad_norm 1.7342 (inf)	loss_scale 16384.0000 (24596.4289)	mem 11441MB
[2024-07-28 23:00:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:11:10 lr 0.000065	 wd 0.0000	time 0.2906 (0.3347)	loss 0.8760 (0.8506)	grad_norm 1.6945 (inf)	loss_scale 16384.0000 (22957.2216)	mem 11441MB
[2024-07-28 23:01:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:10:26 lr 0.000065	 wd 0.0000	time 0.2918 (0.3295)	loss 0.8677 (0.8477)	grad_norm 1.9422 (inf)	loss_scale 16384.0000 (21863.5075)	mem 11441MB
[2024-07-28 23:01:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:09:46 lr 0.000064	 wd 0.0000	time 0.2667 (0.3254)	loss 0.8667 (0.8486)	grad_norm 2.4305 (inf)	loss_scale 16384.0000 (21081.8374)	mem 11441MB
[2024-07-28 23:02:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:09:09 lr 0.000064	 wd 0.0000	time 0.2740 (0.3227)	loss 1.0586 (0.8482)	grad_norm 1.9373 (inf)	loss_scale 16384.0000 (20495.3408)	mem 11441MB
[2024-07-28 23:02:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:08:33 lr 0.000064	 wd 0.0000	time 0.2857 (0.3206)	loss 0.9810 (0.8478)	grad_norm 1.7934 (inf)	loss_scale 8192.0000 (20002.6637)	mem 11441MB
[2024-07-28 23:03:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:07:59 lr 0.000064	 wd 0.0000	time 0.2622 (0.3189)	loss 0.8184 (0.8480)	grad_norm 2.1345 (inf)	loss_scale 8192.0000 (18822.7772)	mem 11441MB
[2024-07-28 23:03:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:07:25 lr 0.000064	 wd 0.0000	time 0.2718 (0.3178)	loss 0.7949 (0.8494)	grad_norm 1.7801 (inf)	loss_scale 8192.0000 (17857.2207)	mem 11441MB
[2024-07-28 23:04:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:07:11 lr 0.000063	 wd 0.0000	time 0.2697 (0.3312)	loss 0.8970 (0.8494)	grad_norm 2.2479 (inf)	loss_scale 8192.0000 (17052.4563)	mem 11441MB
[2024-07-28 23:05:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:06:46 lr 0.000063	 wd 0.0000	time 0.2830 (0.3381)	loss 0.8364 (0.8498)	grad_norm 2.1804 (inf)	loss_scale 8192.0000 (16371.4066)	mem 11441MB
[2024-07-28 23:06:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:06:27 lr 0.000063	 wd 0.0000	time 0.3168 (0.3519)	loss 1.0068 (0.8504)	grad_norm 2.0773 (inf)	loss_scale 8192.0000 (15787.5803)	mem 11441MB
[2024-07-28 23:06:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:05:51 lr 0.000063	 wd 0.0000	time 0.2695 (0.3506)	loss 0.8784 (0.8505)	grad_norm 1.7402 (inf)	loss_scale 8192.0000 (15281.5456)	mem 11441MB
[2024-07-28 23:07:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:05:19 lr 0.000063	 wd 0.0000	time 8.0479 (0.3544)	loss 0.8481 (0.8496)	grad_norm 2.0952 (inf)	loss_scale 8192.0000 (14838.7258)	mem 11441MB
[2024-07-28 23:08:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:04:47 lr 0.000062	 wd 0.0000	time 0.3471 (0.3585)	loss 0.9224 (0.8494)	grad_norm 2.0032 (inf)	loss_scale 8192.0000 (14447.9718)	mem 11441MB
[2024-07-28 23:08:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:04:10 lr 0.000062	 wd 0.0000	time 0.3076 (0.3573)	loss 0.6953 (0.8494)	grad_norm 2.2703 (inf)	loss_scale 8192.0000 (14100.6108)	mem 11441MB
[2024-07-28 23:09:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:03:39 lr 0.000062	 wd 0.0000	time 0.2878 (0.3640)	loss 0.8052 (0.8496)	grad_norm 1.5082 (inf)	loss_scale 8192.0000 (13789.7948)	mem 11441MB
[2024-07-28 23:10:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:03:02 lr 0.000062	 wd 0.0000	time 0.3102 (0.3630)	loss 0.8032 (0.8497)	grad_norm 1.7289 (inf)	loss_scale 8192.0000 (13510.0450)	mem 11441MB
[2024-07-28 23:11:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:02:29 lr 0.000062	 wd 0.0000	time 0.3252 (0.3717)	loss 0.9219 (0.8502)	grad_norm 2.0470 (inf)	loss_scale 8192.0000 (13256.9253)	mem 11441MB
[2024-07-28 23:11:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:51 lr 0.000061	 wd 0.0000	time 0.3214 (0.3702)	loss 0.9771 (0.8502)	grad_norm 1.6882 (inf)	loss_scale 8192.0000 (13026.8060)	mem 11441MB
[2024-07-28 23:12:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:01:14 lr 0.000061	 wd 0.0000	time 0.3686 (0.3682)	loss 0.7666 (0.8500)	grad_norm 1.8988 (inf)	loss_scale 8192.0000 (12816.6884)	mem 11441MB
[2024-07-28 23:13:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:38 lr 0.000061	 wd 0.0000	time 0.2610 (0.3784)	loss 0.7861 (0.8497)	grad_norm 1.6014 (inf)	loss_scale 8192.0000 (12624.0733)	mem 11441MB
[2024-07-28 23:13:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000061	 wd 0.0000	time 0.2798 (0.3760)	loss 0.8091 (0.8497)	grad_norm 1.7712 (inf)	loss_scale 8192.0000 (12446.8613)	mem 11441MB
[2024-07-28 23:13:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 12 training takes 0:15:46
[2024-07-28 23:14:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 66.889 (66.889)	Loss 0.3774 (0.3774)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 11441MB
[2024-07-28 23:15:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.332 Acc@5 97.580
[2024-07-28 23:15:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-28 23:15:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.33%
[2024-07-28 23:15:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-28 23:15:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-28 23:15:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][0/2502]	eta 1 day, 4:27:08 lr 0.000061	 wd 0.0000	time 40.9387 (40.9387)	loss 0.7085 (0.7085)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:16:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:28:10 lr 0.000061	 wd 0.0000	time 0.2892 (0.7036)	loss 0.7666 (0.8420)	grad_norm 2.1584 (1.8751)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:16:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:19:19 lr 0.000060	 wd 0.0000	time 0.2684 (0.5038)	loss 0.7231 (0.8386)	grad_norm 1.7847 (1.8692)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:17:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:16:03 lr 0.000060	 wd 0.0000	time 0.2830 (0.4377)	loss 0.8228 (0.8361)	grad_norm 1.9139 (1.8892)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:17:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:14:07 lr 0.000060	 wd 0.0000	time 0.2814 (0.4033)	loss 0.8926 (0.8407)	grad_norm 2.3688 (1.8949)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:18:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:12:46 lr 0.000060	 wd 0.0000	time 0.2835 (0.3827)	loss 0.8389 (0.8396)	grad_norm 2.4292 (1.9053)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:19:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:11:43 lr 0.000060	 wd 0.0000	time 0.2633 (0.3699)	loss 0.8223 (0.8380)	grad_norm 1.9936 (1.9023)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:19:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:10:49 lr 0.000059	 wd 0.0000	time 0.2959 (0.3603)	loss 0.8008 (0.8382)	grad_norm 2.0439 (1.8975)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:20:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:10:00 lr 0.000059	 wd 0.0000	time 0.2846 (0.3530)	loss 0.8569 (0.8383)	grad_norm 1.5987 (1.8978)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:20:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:09:16 lr 0.000059	 wd 0.0000	time 0.2929 (0.3477)	loss 0.8140 (0.8398)	grad_norm 2.6107 (1.8970)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:21:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:08:35 lr 0.000059	 wd 0.0000	time 0.2652 (0.3433)	loss 0.8779 (0.8422)	grad_norm 1.9438 (1.8947)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:21:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:07:56 lr 0.000059	 wd 0.0000	time 0.2826 (0.3395)	loss 0.8369 (0.8420)	grad_norm 1.9459 (1.9003)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:22:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:07:18 lr 0.000058	 wd 0.0000	time 0.2946 (0.3367)	loss 0.9292 (0.8415)	grad_norm 1.5905 (1.9013)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:22:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:06:41 lr 0.000058	 wd 0.0000	time 0.2883 (0.3343)	loss 0.9092 (0.8418)	grad_norm 1.7685 (1.9007)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:23:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:06:05 lr 0.000058	 wd 0.0000	time 0.2659 (0.3320)	loss 0.8730 (0.8408)	grad_norm 2.5263 (1.8982)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:23:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:05:30 lr 0.000058	 wd 0.0000	time 0.2882 (0.3302)	loss 0.7769 (0.8419)	grad_norm 1.8310 (1.8954)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:24:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:05:08 lr 0.000058	 wd 0.0000	time 0.2620 (0.3424)	loss 0.6689 (0.8424)	grad_norm 1.6672 (1.8956)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:25:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:04:34 lr 0.000057	 wd 0.0000	time 0.2956 (0.3422)	loss 0.8296 (0.8434)	grad_norm 2.6272 (1.8947)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:25:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:04:07 lr 0.000057	 wd 0.0000	time 0.2806 (0.3528)	loss 0.8457 (0.8441)	grad_norm 1.6561 (1.8948)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:26:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:03:32 lr 0.000057	 wd 0.0000	time 0.3101 (0.3522)	loss 0.7446 (0.8436)	grad_norm 1.8059 (1.8936)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:27:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:03:00 lr 0.000057	 wd 0.0000	time 0.6756 (0.3589)	loss 0.8628 (0.8432)	grad_norm 1.5861 (1.8951)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:27:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:02:23 lr 0.000057	 wd 0.0000	time 0.2899 (0.3581)	loss 0.8252 (0.8436)	grad_norm 1.8423 (1.8966)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:28:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:47 lr 0.000056	 wd 0.0000	time 0.3014 (0.3568)	loss 0.7754 (0.8433)	grad_norm 1.8788 (1.8970)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:29:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:01:13 lr 0.000056	 wd 0.0000	time 0.2990 (0.3662)	loss 0.8926 (0.8434)	grad_norm 1.7256 (1.8979)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-28 23:29:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:37 lr 0.000056	 wd 0.0000	time 0.3140 (0.3647)	loss 0.8096 (0.8436)	grad_norm 1.8713 (1.8970)	loss_scale 16384.0000 (8212.4715)	mem 11441MB
[2024-07-28 23:30:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000056	 wd 0.0000	time 0.2796 (0.3625)	loss 0.7661 (0.8435)	grad_norm 1.6626 (1.8984)	loss_scale 16384.0000 (8539.2019)	mem 11441MB
[2024-07-28 23:30:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 13 training takes 0:15:21
[2024-07-28 23:31:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 70.572 (70.572)	Loss 0.3716 (0.3716)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 11441MB
[2024-07-28 23:32:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.416 Acc@5 97.550
[2024-07-28 23:32:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-28 23:32:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.42%
[2024-07-28 23:32:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-28 23:32:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-28 23:32:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][0/2502]	eta 10:27:48 lr 0.000056	 wd 0.0000	time 15.0555 (15.0555)	loss 0.7842 (0.7842)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:33:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:18:01 lr 0.000055	 wd 0.0000	time 0.2971 (0.4504)	loss 0.8037 (0.8382)	grad_norm 1.7375 (1.8506)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:33:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:14:36 lr 0.000055	 wd 0.0000	time 0.2812 (0.3806)	loss 0.8081 (0.8345)	grad_norm 1.8265 (1.8938)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:34:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:13:00 lr 0.000055	 wd 0.0000	time 0.2672 (0.3543)	loss 0.9053 (0.8378)	grad_norm 1.7845 (1.9028)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:34:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:11:57 lr 0.000055	 wd 0.0000	time 0.2897 (0.3414)	loss 1.0137 (0.8387)	grad_norm 1.7793 (1.8942)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:35:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:11:08 lr 0.000055	 wd 0.0000	time 0.2864 (0.3340)	loss 0.8223 (0.8377)	grad_norm 1.7126 (1.8883)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:35:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:10:26 lr 0.000054	 wd 0.0000	time 0.2580 (0.3291)	loss 0.7969 (0.8394)	grad_norm 1.9091 (1.8932)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:36:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:09:46 lr 0.000054	 wd 0.0000	time 0.2787 (0.3253)	loss 0.7529 (0.8417)	grad_norm 1.5922 (1.9025)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:36:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:09:08 lr 0.000054	 wd 0.0000	time 0.2536 (0.3225)	loss 0.8340 (0.8399)	grad_norm 1.7665 (1.9025)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:37:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:08:33 lr 0.000054	 wd 0.0000	time 0.2898 (0.3207)	loss 0.9082 (0.8392)	grad_norm 1.5582 (1.9053)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:37:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:07:58 lr 0.000054	 wd 0.0000	time 0.2632 (0.3189)	loss 0.9526 (0.8386)	grad_norm 2.0650 (1.8996)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:38:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:07:24 lr 0.000053	 wd 0.0000	time 0.2858 (0.3174)	loss 0.7485 (0.8391)	grad_norm 1.8327 (1.8981)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:38:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:07:14 lr 0.000053	 wd 0.0000	time 0.3159 (0.3338)	loss 0.8862 (0.8396)	grad_norm 1.9252 (1.8970)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:39:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:06:45 lr 0.000053	 wd 0.0000	time 0.2942 (0.3371)	loss 0.9072 (0.8395)	grad_norm 1.6721 (1.8947)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:40:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:06:29 lr 0.000053	 wd 0.0000	time 0.3390 (0.3534)	loss 0.8711 (0.8387)	grad_norm 2.4728 (1.8922)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:41:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:05:52 lr 0.000053	 wd 0.0000	time 0.2954 (0.3521)	loss 0.9023 (0.8389)	grad_norm 2.1803 (1.8999)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:41:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:05:16 lr 0.000052	 wd 0.0000	time 0.4426 (0.3510)	loss 0.8872 (0.8396)	grad_norm 1.7926 (1.9036)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:42:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:04:49 lr 0.000052	 wd 0.0000	time 0.3768 (0.3608)	loss 0.9561 (0.8398)	grad_norm 1.8157 (1.9082)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:43:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:04:12 lr 0.000052	 wd 0.0000	time 0.3085 (0.3596)	loss 0.9370 (0.8399)	grad_norm 2.2100 (1.9098)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:43:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:03:41 lr 0.000052	 wd 0.0000	time 0.2654 (0.3678)	loss 0.8228 (0.8398)	grad_norm 1.6766 (1.9074)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:44:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:03:03 lr 0.000052	 wd 0.0000	time 0.2756 (0.3665)	loss 0.8721 (0.8399)	grad_norm 2.1824 (1.9107)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:45:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:02:31 lr 0.000051	 wd 0.0000	time 0.2987 (0.3764)	loss 0.8330 (0.8404)	grad_norm 1.8056 (1.9122)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:46:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:53 lr 0.000051	 wd 0.0000	time 0.2848 (0.3744)	loss 0.7480 (0.8411)	grad_norm 2.6337 (1.9147)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:46:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:01:16 lr 0.000051	 wd 0.0000	time 0.3225 (0.3810)	loss 0.9058 (0.8414)	grad_norm 2.6284 (1.9153)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:47:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:38 lr 0.000051	 wd 0.0000	time 0.3341 (0.3819)	loss 0.7998 (0.8416)	grad_norm 1.6232 (1.9149)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:48:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000051	 wd 0.0000	time 0.2778 (0.3791)	loss 0.8140 (0.8417)	grad_norm 1.5584 (1.9149)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:48:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 14 training takes 0:16:02
[2024-07-28 23:49:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 69.357 (69.357)	Loss 0.3643 (0.3643)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 11441MB
[2024-07-28 23:49:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.390 Acc@5 97.592
[2024-07-28 23:49:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-28 23:49:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.42%
[2024-07-28 23:50:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][0/2502]	eta 21:15:33 lr 0.000051	 wd 0.0000	time 30.5890 (30.5890)	loss 0.7324 (0.7324)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:50:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:24:31 lr 0.000050	 wd 0.0000	time 0.2754 (0.6125)	loss 0.8564 (0.8335)	grad_norm 2.0347 (1.9103)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:51:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:18:04 lr 0.000050	 wd 0.0000	time 0.2730 (0.4712)	loss 1.0723 (0.8410)	grad_norm 2.1947 (1.9257)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:51:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:15:16 lr 0.000050	 wd 0.0000	time 0.2682 (0.4164)	loss 0.7451 (0.8412)	grad_norm 1.7498 (1.9176)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:52:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:13:34 lr 0.000050	 wd 0.0000	time 0.2813 (0.3876)	loss 0.6792 (0.8406)	grad_norm 1.7035 (1.9130)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:52:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:12:21 lr 0.000049	 wd 0.0000	time 0.2652 (0.3704)	loss 0.7651 (0.8405)	grad_norm 1.7011 (1.9071)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:53:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:11:23 lr 0.000049	 wd 0.0000	time 0.2798 (0.3593)	loss 0.7476 (0.8403)	grad_norm 1.7414 (1.8978)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:53:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:10:32 lr 0.000049	 wd 0.0000	time 0.2612 (0.3511)	loss 0.8149 (0.8395)	grad_norm 1.5431 (1.8917)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:54:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:09:47 lr 0.000049	 wd 0.0000	time 0.2925 (0.3449)	loss 0.7954 (0.8390)	grad_norm 1.6994 (1.8935)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:54:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:09:05 lr 0.000049	 wd 0.0000	time 0.2944 (0.3407)	loss 0.8140 (0.8388)	grad_norm 1.8819 (1.8934)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:55:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:08:26 lr 0.000048	 wd 0.0000	time 0.2778 (0.3369)	loss 0.8076 (0.8390)	grad_norm 1.8370 (1.8980)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:55:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:07:47 lr 0.000048	 wd 0.0000	time 0.2517 (0.3336)	loss 0.8926 (0.8378)	grad_norm 2.6631 (1.9015)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:56:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:07:11 lr 0.000048	 wd 0.0000	time 0.2546 (0.3312)	loss 0.7266 (0.8373)	grad_norm 1.7401 (1.9020)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:56:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:06:36 lr 0.000048	 wd 0.0000	time 0.3026 (0.3295)	loss 0.9072 (0.8377)	grad_norm 2.0345 (1.9047)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-28 23:57:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:06:01 lr 0.000048	 wd 0.0000	time 0.2805 (0.3276)	loss 0.8574 (0.8374)	grad_norm 1.7658 (1.9064)	loss_scale 32768.0000 (16500.9450)	mem 11441MB
[2024-07-28 23:57:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:05:26 lr 0.000047	 wd 0.0000	time 0.2861 (0.3261)	loss 0.8242 (0.8372)	grad_norm 1.9824 (inf)	loss_scale 16384.0000 (16886.1079)	mem 11441MB
[2024-07-28 23:58:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:05:09 lr 0.000047	 wd 0.0000	time 0.3493 (0.3428)	loss 0.8892 (0.8369)	grad_norm 1.9503 (inf)	loss_scale 16384.0000 (16854.7458)	mem 11441MB
[2024-07-28 23:59:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:04:34 lr 0.000047	 wd 0.0000	time 0.2883 (0.3426)	loss 0.9028 (0.8365)	grad_norm 1.7686 (inf)	loss_scale 16384.0000 (16827.0711)	mem 11441MB
[2024-07-29 00:00:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:04:08 lr 0.000047	 wd 0.0000	time 0.3239 (0.3543)	loss 0.8667 (0.8376)	grad_norm 1.6896 (inf)	loss_scale 16384.0000 (16802.4697)	mem 11441MB
[2024-07-29 00:00:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:03:32 lr 0.000047	 wd 0.0000	time 0.3291 (0.3532)	loss 0.8623 (0.8375)	grad_norm 1.9430 (inf)	loss_scale 16384.0000 (16780.4566)	mem 11441MB
[2024-07-29 00:01:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:03:02 lr 0.000046	 wd 0.0000	time 0.2776 (0.3643)	loss 0.9302 (0.8375)	grad_norm 2.1035 (inf)	loss_scale 16384.0000 (16760.6437)	mem 11441MB
[2024-07-29 00:02:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:02:26 lr 0.000046	 wd 0.0000	time 0.3620 (0.3640)	loss 0.8530 (0.8375)	grad_norm 1.7968 (inf)	loss_scale 16384.0000 (16742.7168)	mem 11441MB
[2024-07-29 00:03:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:52 lr 0.000046	 wd 0.0000	time 0.2595 (0.3733)	loss 0.8384 (0.8377)	grad_norm 2.1826 (inf)	loss_scale 16384.0000 (16726.4189)	mem 11441MB
[2024-07-29 00:03:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:01:15 lr 0.000046	 wd 0.0000	time 0.3167 (0.3715)	loss 0.9595 (0.8373)	grad_norm 2.0792 (inf)	loss_scale 16384.0000 (16711.5376)	mem 11441MB
[2024-07-29 00:04:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:38 lr 0.000046	 wd 0.0000	time 0.5114 (0.3790)	loss 0.8164 (0.8373)	grad_norm 1.7109 (inf)	loss_scale 8192.0000 (16465.8859)	mem 11441MB
[2024-07-29 00:05:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000045	 wd 0.0000	time 0.2757 (0.3789)	loss 1.0371 (0.8377)	grad_norm 1.5450 (inf)	loss_scale 8192.0000 (16135.0628)	mem 11441MB
[2024-07-29 00:05:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 15 training takes 0:15:55
[2024-07-29 00:05:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_15.pth saving......
[2024-07-29 00:05:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_15.pth saved !!!
[2024-07-29 00:06:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 51.650 (51.650)	Loss 0.3687 (0.3687)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 11441MB
[2024-07-29 00:06:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.292 Acc@5 97.620
[2024-07-29 00:06:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-29 00:06:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.42%
[2024-07-29 00:07:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][0/2502]	eta 11:19:54 lr 0.000045	 wd 0.0000	time 16.3048 (16.3048)	loss 0.8076 (0.8076)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:07:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:18:38 lr 0.000045	 wd 0.0000	time 0.3099 (0.4655)	loss 0.9971 (0.8423)	grad_norm 2.2051 (1.9233)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:08:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:14:53 lr 0.000045	 wd 0.0000	time 0.2821 (0.3883)	loss 0.8516 (0.8436)	grad_norm 1.6036 (1.9248)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:08:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:13:11 lr 0.000045	 wd 0.0000	time 0.2825 (0.3594)	loss 0.8374 (0.8416)	grad_norm 1.6896 (1.9295)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:09:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:12:04 lr 0.000045	 wd 0.0000	time 0.2781 (0.3448)	loss 0.8950 (0.8394)	grad_norm 1.5837 (1.9237)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:09:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:11:14 lr 0.000044	 wd 0.0000	time 0.2773 (0.3368)	loss 0.7817 (0.8368)	grad_norm 2.0255 (1.9270)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:10:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:10:29 lr 0.000044	 wd 0.0000	time 0.2630 (0.3309)	loss 0.8203 (0.8382)	grad_norm 2.3441 (1.9380)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:10:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:09:48 lr 0.000044	 wd 0.0000	time 0.3029 (0.3268)	loss 0.8647 (0.8376)	grad_norm 1.6549 (1.9382)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:11:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:09:12 lr 0.000044	 wd 0.0000	time 0.2906 (0.3247)	loss 0.9658 (0.8371)	grad_norm 2.3234 (1.9382)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:11:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:08:36 lr 0.000043	 wd 0.0000	time 0.2987 (0.3227)	loss 0.8032 (0.8392)	grad_norm 2.5714 (1.9384)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:12:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:08:01 lr 0.000043	 wd 0.0000	time 0.2903 (0.3207)	loss 0.7866 (0.8405)	grad_norm 2.1135 (1.9377)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:12:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:07:27 lr 0.000043	 wd 0.0000	time 0.2758 (0.3193)	loss 0.7554 (0.8396)	grad_norm 1.8203 (1.9459)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:13:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:06:54 lr 0.000043	 wd 0.0000	time 0.3407 (0.3186)	loss 0.9136 (0.8401)	grad_norm 1.7231 (1.9460)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:13:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:06:21 lr 0.000043	 wd 0.0000	time 0.2799 (0.3175)	loss 0.8008 (0.8384)	grad_norm 1.9259 (1.9462)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:14:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:05:48 lr 0.000042	 wd 0.0000	time 0.2803 (0.3164)	loss 0.8174 (0.8377)	grad_norm 1.8170 (1.9439)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:15:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:05:33 lr 0.000042	 wd 0.0000	time 0.3224 (0.3329)	loss 0.8774 (0.8373)	grad_norm 2.0683 (1.9419)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:15:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:05:02 lr 0.000042	 wd 0.0000	time 0.2748 (0.3352)	loss 0.8394 (0.8373)	grad_norm 1.8441 (1.9393)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:16:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:04:39 lr 0.000042	 wd 0.0000	time 0.3381 (0.3490)	loss 0.7012 (0.8381)	grad_norm 1.8560 (1.9402)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:17:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:04:04 lr 0.000042	 wd 0.0000	time 0.2908 (0.3480)	loss 0.8682 (0.8382)	grad_norm 1.6949 (1.9390)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:18:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:03:33 lr 0.000041	 wd 0.0000	time 0.2869 (0.3549)	loss 0.9609 (0.8386)	grad_norm 2.2538 (1.9416)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:18:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:02:57 lr 0.000041	 wd 0.0000	time 0.3322 (0.3541)	loss 0.7617 (0.8381)	grad_norm 1.7623 (1.9406)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:19:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:02:21 lr 0.000041	 wd 0.0000	time 0.3553 (0.3527)	loss 0.7529 (0.8380)	grad_norm 1.7130 (1.9368)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:20:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:49 lr 0.000041	 wd 0.0000	time 0.2759 (0.3636)	loss 0.7705 (0.8381)	grad_norm 1.7946 (1.9378)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:20:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:01:13 lr 0.000041	 wd 0.0000	time 0.2946 (0.3622)	loss 0.8379 (0.8380)	grad_norm 1.7533 (1.9379)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:21:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:37 lr 0.000040	 wd 0.0000	time 0.3182 (0.3719)	loss 0.7412 (0.8375)	grad_norm 2.0409 (1.9371)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:22:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.2684 (0.3696)	loss 0.8442 (0.8372)	grad_norm 1.9106 (1.9370)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:22:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 16 training takes 0:15:33
[2024-07-29 00:23:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 76.261 (76.261)	Loss 0.3604 (0.3604)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 11441MB
[2024-07-29 00:23:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.376 Acc@5 97.616
[2024-07-29 00:23:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-29 00:23:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.42%
[2024-07-29 00:24:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][0/2502]	eta 1 day, 1:05:55 lr 0.000040	 wd 0.0000	time 36.1133 (36.1133)	loss 0.7671 (0.7671)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:25:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:26:21 lr 0.000040	 wd 0.0000	time 0.2708 (0.6585)	loss 0.8950 (0.8303)	grad_norm 1.7083 (1.9826)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:25:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:18:29 lr 0.000040	 wd 0.0000	time 0.2841 (0.4821)	loss 0.9668 (0.8386)	grad_norm 2.0445 (1.9472)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:26:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:15:32 lr 0.000040	 wd 0.0000	time 0.2874 (0.4234)	loss 0.8667 (0.8388)	grad_norm 1.6879 (1.9422)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:26:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:13:45 lr 0.000039	 wd 0.0000	time 0.2799 (0.3929)	loss 0.7905 (0.8322)	grad_norm 2.2149 (1.9458)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:27:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:12:30 lr 0.000039	 wd 0.0000	time 0.2855 (0.3747)	loss 0.7646 (0.8338)	grad_norm 1.7363 (1.9448)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:27:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:11:29 lr 0.000039	 wd 0.0000	time 0.2812 (0.3627)	loss 0.8838 (0.8348)	grad_norm 2.4012 (1.9449)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:28:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:10:37 lr 0.000039	 wd 0.0000	time 0.2784 (0.3538)	loss 0.7446 (0.8334)	grad_norm 1.7792 (1.9411)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:28:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:09:50 lr 0.000039	 wd 0.0000	time 0.2744 (0.3472)	loss 0.7397 (0.8336)	grad_norm 1.7633 (1.9438)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:29:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:09:09 lr 0.000038	 wd 0.0000	time 0.2910 (0.3427)	loss 0.7886 (0.8342)	grad_norm 1.5943 (1.9431)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:29:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:08:28 lr 0.000038	 wd 0.0000	time 0.2693 (0.3387)	loss 0.9033 (0.8340)	grad_norm 2.0521 (1.9425)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:30:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:07:50 lr 0.000038	 wd 0.0000	time 0.2811 (0.3354)	loss 0.9014 (0.8353)	grad_norm 1.7005 (1.9431)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:30:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:07:13 lr 0.000038	 wd 0.0000	time 0.2654 (0.3328)	loss 0.9165 (0.8360)	grad_norm 1.8223 (1.9448)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:31:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:06:38 lr 0.000038	 wd 0.0000	time 0.2723 (0.3311)	loss 0.9902 (0.8348)	grad_norm 2.2679 (1.9517)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:31:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:06:02 lr 0.000037	 wd 0.0000	time 0.2841 (0.3291)	loss 0.7778 (0.8354)	grad_norm 2.0739 (1.9612)	loss_scale 16384.0000 (8613.0021)	mem 11441MB
[2024-07-29 00:32:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:05:28 lr 0.000037	 wd 0.0000	time 0.2876 (0.3274)	loss 0.8057 (0.8356)	grad_norm 2.1487 (1.9582)	loss_scale 16384.0000 (9130.7235)	mem 11441MB
[2024-07-29 00:33:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:05:14 lr 0.000037	 wd 0.0000	time 1.8221 (0.3487)	loss 0.7461 (0.8353)	grad_norm 2.0989 (1.9633)	loss_scale 16384.0000 (9583.7701)	mem 11441MB
[2024-07-29 00:34:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:04:54 lr 0.000037	 wd 0.0000	time 0.8851 (0.3671)	loss 1.0332 (0.8353)	grad_norm 1.9250 (1.9659)	loss_scale 16384.0000 (9983.5485)	mem 11441MB
[2024-07-29 00:35:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:04:31 lr 0.000037	 wd 0.0000	time 0.3079 (0.3870)	loss 0.7744 (0.8355)	grad_norm 1.8123 (1.9619)	loss_scale 16384.0000 (10338.9317)	mem 11441MB
[2024-07-29 00:36:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:03:50 lr 0.000036	 wd 0.0000	time 0.2973 (0.3829)	loss 0.7705 (0.8356)	grad_norm 1.8895 (1.9567)	loss_scale 16384.0000 (10656.9258)	mem 11441MB
[2024-07-29 00:36:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:03:10 lr 0.000036	 wd 0.0000	time 0.3033 (0.3790)	loss 0.8042 (0.8351)	grad_norm 2.3470 (inf)	loss_scale 8192.0000 (10902.1969)	mem 11441MB
[2024-07-29 00:37:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:02:30 lr 0.000036	 wd 0.0000	time 0.2967 (0.3756)	loss 0.7983 (0.8352)	grad_norm 1.8640 (inf)	loss_scale 8192.0000 (10773.2013)	mem 11441MB
[2024-07-29 00:37:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:52 lr 0.000036	 wd 0.0000	time 0.2861 (0.3729)	loss 0.8398 (0.8352)	grad_norm 1.8653 (inf)	loss_scale 8192.0000 (10655.9273)	mem 11441MB
[2024-07-29 00:38:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:01:14 lr 0.000036	 wd 0.0000	time 0.3043 (0.3699)	loss 0.8237 (0.8348)	grad_norm 1.9545 (inf)	loss_scale 8192.0000 (10548.8466)	mem 11441MB
[2024-07-29 00:38:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:37 lr 0.000035	 wd 0.0000	time 0.3132 (0.3672)	loss 0.7300 (0.8356)	grad_norm 2.0133 (inf)	loss_scale 8192.0000 (10450.6855)	mem 11441MB
[2024-07-29 00:39:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.2831 (0.3648)	loss 0.9961 (0.8361)	grad_norm 1.9423 (inf)	loss_scale 8192.0000 (10360.3743)	mem 11441MB
[2024-07-29 00:39:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 17 training takes 0:15:24
[2024-07-29 00:39:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 23.585 (23.585)	Loss 0.3613 (0.3613)	Acc@1 92.383 (92.383)	Acc@5 98.438 (98.438)	Mem 11441MB
[2024-07-29 00:40:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.408 Acc@5 97.572
[2024-07-29 00:40:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-29 00:40:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.42%
[2024-07-29 00:40:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][0/2502]	eta 21:40:23 lr 0.000035	 wd 0.0000	time 31.1846 (31.1846)	loss 0.8984 (0.8984)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:41:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:24:20 lr 0.000035	 wd 0.0000	time 0.2833 (0.6080)	loss 0.8262 (0.8281)	grad_norm 2.0093 (2.0305)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:41:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:17:26 lr 0.000035	 wd 0.0000	time 0.2762 (0.4547)	loss 0.9189 (0.8263)	grad_norm 1.9453 (2.0188)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:42:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:14:51 lr 0.000035	 wd 0.0000	time 0.2696 (0.4049)	loss 0.9248 (0.8306)	grad_norm 2.0964 (1.9989)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:42:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:13:16 lr 0.000034	 wd 0.0000	time 0.2799 (0.3787)	loss 0.8335 (0.8340)	grad_norm 2.1456 (1.9920)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:43:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:12:06 lr 0.000034	 wd 0.0000	time 0.2822 (0.3629)	loss 0.7593 (0.8345)	grad_norm 1.9481 (1.9881)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:43:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:11:11 lr 0.000034	 wd 0.0000	time 0.2559 (0.3532)	loss 0.7588 (0.8336)	grad_norm 1.6668 (1.9737)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:44:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:10:24 lr 0.000034	 wd 0.0000	time 0.2776 (0.3467)	loss 0.9741 (0.8327)	grad_norm 2.0018 (1.9721)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:44:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:09:40 lr 0.000034	 wd 0.0000	time 0.2860 (0.3410)	loss 0.8804 (0.8302)	grad_norm 1.8417 (1.9613)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:45:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:08:59 lr 0.000033	 wd 0.0000	time 0.2819 (0.3367)	loss 0.8667 (0.8300)	grad_norm 2.4223 (1.9611)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:45:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:08:21 lr 0.000033	 wd 0.0000	time 0.2608 (0.3338)	loss 0.7695 (0.8299)	grad_norm 2.1379 (1.9629)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:46:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:07:43 lr 0.000033	 wd 0.0000	time 0.2655 (0.3309)	loss 0.7939 (0.8309)	grad_norm 1.9795 (1.9643)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:46:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:07:07 lr 0.000033	 wd 0.0000	time 0.2802 (0.3286)	loss 1.1357 (0.8304)	grad_norm 1.8920 (1.9630)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:47:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:07:12 lr 0.000033	 wd 0.0000	time 0.5702 (0.3601)	loss 0.7202 (0.8311)	grad_norm 1.6170 (1.9557)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:48:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:06:57 lr 0.000032	 wd 0.0000	time 0.2498 (0.3785)	loss 0.7769 (0.8300)	grad_norm 2.0376 (1.9569)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:49:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:06:14 lr 0.000032	 wd 0.0000	time 0.2943 (0.3735)	loss 0.7798 (0.8301)	grad_norm 3.3720 (1.9598)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:49:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:05:32 lr 0.000032	 wd 0.0000	time 0.2985 (0.3691)	loss 0.8501 (0.8300)	grad_norm 2.1614 (1.9578)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:50:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:04:53 lr 0.000032	 wd 0.0000	time 0.2766 (0.3654)	loss 0.9668 (0.8300)	grad_norm 1.8736 (1.9653)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:50:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:04:14 lr 0.000032	 wd 0.0000	time 0.2638 (0.3621)	loss 0.9155 (0.8303)	grad_norm 1.6967 (1.9636)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:51:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:03:36 lr 0.000032	 wd 0.0000	time 0.2754 (0.3592)	loss 1.0010 (0.8303)	grad_norm 1.8267 (1.9628)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:51:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:02:59 lr 0.000031	 wd 0.0000	time 0.3146 (0.3570)	loss 0.9492 (0.8311)	grad_norm 1.8660 (1.9658)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:52:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:02:22 lr 0.000031	 wd 0.0000	time 0.3105 (0.3547)	loss 0.7432 (0.8310)	grad_norm 1.8599 (1.9685)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:52:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:46 lr 0.000031	 wd 0.0000	time 0.3045 (0.3524)	loss 0.7310 (0.8315)	grad_norm 1.6113 (1.9685)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:53:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:01:10 lr 0.000031	 wd 0.0000	time 0.4766 (0.3507)	loss 0.7769 (0.8317)	grad_norm 2.0268 (1.9747)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:54:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:36 lr 0.000031	 wd 0.0000	time 0.2852 (0.3612)	loss 0.8667 (0.8315)	grad_norm 2.1240 (1.9750)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:55:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000030	 wd 0.0000	time 0.2531 (0.3593)	loss 0.8232 (0.8318)	grad_norm 1.9865 (1.9748)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:55:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 18 training takes 0:15:21
[2024-07-29 00:56:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 79.842 (79.842)	Loss 0.3601 (0.3601)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 11441MB
[2024-07-29 00:57:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.422 Acc@5 97.570
[2024-07-29 00:57:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-29 00:57:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.42%
[2024-07-29 00:57:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-29 00:57:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-29 00:57:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][0/2502]	eta 11:39:15 lr 0.000030	 wd 0.0000	time 16.7688 (16.7688)	loss 0.7817 (0.7817)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:58:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:18:33 lr 0.000030	 wd 0.0000	time 0.2712 (0.4634)	loss 0.9897 (0.8392)	grad_norm 1.9941 (1.9727)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:58:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:14:46 lr 0.000030	 wd 0.0000	time 0.2610 (0.3853)	loss 0.7393 (0.8395)	grad_norm 1.9071 (1.9751)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:59:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:13:06 lr 0.000030	 wd 0.0000	time 0.2841 (0.3572)	loss 0.7856 (0.8376)	grad_norm 1.6003 (1.9551)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 00:59:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:12:01 lr 0.000030	 wd 0.0000	time 0.2906 (0.3432)	loss 0.8765 (0.8348)	grad_norm 1.7665 (1.9533)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:00:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:11:11 lr 0.000029	 wd 0.0000	time 0.2957 (0.3355)	loss 0.8516 (0.8327)	grad_norm 1.6973 (1.9564)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:00:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:10:27 lr 0.000029	 wd 0.0000	time 0.2759 (0.3297)	loss 0.7866 (0.8328)	grad_norm 1.8975 (1.9545)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:01:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:09:47 lr 0.000029	 wd 0.0000	time 0.2680 (0.3258)	loss 0.8745 (0.8330)	grad_norm 2.1604 (1.9547)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:01:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:09:09 lr 0.000029	 wd 0.0000	time 0.2899 (0.3230)	loss 0.7319 (0.8321)	grad_norm 2.2496 (1.9536)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:02:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:08:34 lr 0.000029	 wd 0.0000	time 0.2713 (0.3213)	loss 0.7432 (0.8310)	grad_norm 2.2971 (1.9545)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:02:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:07:59 lr 0.000028	 wd 0.0000	time 0.2675 (0.3193)	loss 0.7227 (0.8308)	grad_norm 2.0348 (1.9547)	loss_scale 16384.0000 (8306.5734)	mem 11441MB
[2024-07-29 01:03:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:07:25 lr 0.000028	 wd 0.0000	time 0.2805 (0.3177)	loss 0.9248 (0.8311)	grad_norm 2.3054 (1.9541)	loss_scale 16384.0000 (9040.2180)	mem 11441MB
[2024-07-29 01:03:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:06:52 lr 0.000028	 wd 0.0000	time 0.2798 (0.3168)	loss 0.8135 (0.8309)	grad_norm 1.8752 (1.9591)	loss_scale 16384.0000 (9651.6903)	mem 11441MB
[2024-07-29 01:04:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:06:19 lr 0.000028	 wd 0.0000	time 0.3092 (0.3156)	loss 0.6816 (0.8314)	grad_norm 1.8344 (1.9564)	loss_scale 16384.0000 (10169.1622)	mem 11441MB
[2024-07-29 01:04:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:05:46 lr 0.000028	 wd 0.0000	time 0.3012 (0.3147)	loss 0.7686 (0.8317)	grad_norm 1.8445 (1.9552)	loss_scale 16384.0000 (10612.7623)	mem 11441MB
[2024-07-29 01:05:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:05:27 lr 0.000028	 wd 0.0000	time 0.2806 (0.3269)	loss 0.8716 (0.8321)	grad_norm 1.9673 (1.9553)	loss_scale 16384.0000 (10997.2552)	mem 11441MB
[2024-07-29 01:06:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:04:58 lr 0.000027	 wd 0.0000	time 0.2576 (0.3312)	loss 0.7559 (0.8321)	grad_norm 1.7278 (1.9589)	loss_scale 16384.0000 (11333.7164)	mem 11441MB
[2024-07-29 01:07:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:04:47 lr 0.000027	 wd 0.0000	time 0.6059 (0.3588)	loss 0.7314 (0.8318)	grad_norm 1.9719 (1.9551)	loss_scale 16384.0000 (11630.6173)	mem 11441MB
[2024-07-29 01:08:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:04:18 lr 0.000027	 wd 0.0000	time 0.2653 (0.3681)	loss 0.7119 (0.8322)	grad_norm 1.9527 (1.9577)	loss_scale 16384.0000 (11894.5475)	mem 11441MB
[2024-07-29 01:08:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:03:39 lr 0.000027	 wd 0.0000	time 0.2830 (0.3646)	loss 0.8418 (0.8317)	grad_norm 2.2990 (1.9575)	loss_scale 16384.0000 (12130.7102)	mem 11441MB
[2024-07-29 01:09:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:03:01 lr 0.000027	 wd 0.0000	time 0.2740 (0.3616)	loss 0.8774 (0.8310)	grad_norm 1.8570 (1.9612)	loss_scale 16384.0000 (12343.2684)	mem 11441MB
[2024-07-29 01:09:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:02:24 lr 0.000026	 wd 0.0000	time 0.2702 (0.3592)	loss 0.9668 (0.8307)	grad_norm 1.9079 (1.9626)	loss_scale 16384.0000 (12535.5926)	mem 11441MB
[2024-07-29 01:10:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:47 lr 0.000026	 wd 0.0000	time 0.2864 (0.3570)	loss 0.8281 (0.8305)	grad_norm 2.2743 (1.9636)	loss_scale 16384.0000 (12710.4407)	mem 11441MB
[2024-07-29 01:10:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:01:11 lr 0.000026	 wd 0.0000	time 0.2941 (0.3548)	loss 0.8979 (0.8308)	grad_norm 1.8223 (1.9615)	loss_scale 16384.0000 (12870.0913)	mem 11441MB
[2024-07-29 01:11:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:35 lr 0.000026	 wd 0.0000	time 0.2685 (0.3527)	loss 1.0332 (0.8306)	grad_norm 2.1820 (1.9639)	loss_scale 16384.0000 (13016.4431)	mem 11441MB
[2024-07-29 01:11:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.2883 (0.3510)	loss 0.7603 (0.8303)	grad_norm 1.6654 (1.9674)	loss_scale 16384.0000 (13151.0916)	mem 11441MB
[2024-07-29 01:12:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 19 training takes 0:14:48
[2024-07-29 01:12:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 20.170 (20.170)	Loss 0.3625 (0.3625)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 11441MB
[2024-07-29 01:12:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.462 Acc@5 97.612
[2024-07-29 01:12:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-29 01:12:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.46%
[2024-07-29 01:12:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-29 01:12:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-29 01:13:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][0/2502]	eta 19:09:53 lr 0.000026	 wd 0.0000	time 27.5754 (27.5754)	loss 0.9312 (0.9312)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 01:13:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:23:13 lr 0.000026	 wd 0.0000	time 0.2902 (0.5801)	loss 0.8599 (0.8361)	grad_norm 1.9103 (1.9716)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 01:14:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:16:55 lr 0.000025	 wd 0.0000	time 0.2896 (0.4409)	loss 0.9316 (0.8329)	grad_norm 1.7912 (1.9486)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 01:14:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:14:33 lr 0.000025	 wd 0.0000	time 0.2957 (0.3965)	loss 0.7490 (0.8311)	grad_norm 2.0206 (1.9626)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 01:15:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:13:03 lr 0.000025	 wd 0.0000	time 0.2784 (0.3725)	loss 0.7192 (0.8273)	grad_norm 1.9872 (1.9673)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 01:15:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:11:57 lr 0.000025	 wd 0.0000	time 0.2770 (0.3584)	loss 0.8687 (0.8281)	grad_norm 1.7883 (1.9736)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 01:16:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:11:04 lr 0.000025	 wd 0.0000	time 0.2854 (0.3492)	loss 0.7964 (0.8278)	grad_norm 2.1988 (1.9736)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 01:16:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:10:18 lr 0.000025	 wd 0.0000	time 0.2831 (0.3430)	loss 0.7290 (0.8275)	grad_norm 1.7568 (1.9794)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 01:17:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:09:34 lr 0.000024	 wd 0.0000	time 0.3106 (0.3378)	loss 0.8281 (0.8286)	grad_norm 1.8311 (1.9744)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 01:17:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:08:54 lr 0.000024	 wd 0.0000	time 0.2890 (0.3338)	loss 0.9561 (0.8282)	grad_norm 2.3187 (1.9733)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 01:18:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:08:17 lr 0.000024	 wd 0.0000	time 0.2800 (0.3313)	loss 0.7720 (0.8299)	grad_norm 1.8358 (1.9729)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 01:18:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:07:40 lr 0.000024	 wd 0.0000	time 0.2786 (0.3286)	loss 0.7319 (0.8295)	grad_norm 1.9191 (1.9697)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 01:19:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:07:04 lr 0.000024	 wd 0.0000	time 0.2887 (0.3263)	loss 0.7207 (0.8291)	grad_norm 2.2427 (1.9622)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 01:20:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:07:00 lr 0.000023	 wd 0.0000	time 0.5436 (0.3495)	loss 0.7773 (0.8280)	grad_norm 2.1997 (inf)	loss_scale 8192.0000 (16283.2529)	mem 11441MB
[2024-07-29 01:21:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:06:45 lr 0.000023	 wd 0.0000	time 0.2725 (0.3681)	loss 0.8550 (0.8282)	grad_norm 2.1769 (inf)	loss_scale 8192.0000 (15705.7188)	mem 11441MB
[2024-07-29 01:21:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:06:04 lr 0.000023	 wd 0.0000	time 0.2698 (0.3639)	loss 0.8853 (0.8277)	grad_norm 2.5408 (inf)	loss_scale 8192.0000 (15205.1379)	mem 11441MB
[2024-07-29 01:22:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:05:24 lr 0.000023	 wd 0.0000	time 0.2737 (0.3601)	loss 0.8560 (0.8267)	grad_norm 1.5497 (inf)	loss_scale 8192.0000 (14767.0906)	mem 11441MB
[2024-07-29 01:22:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:04:46 lr 0.000023	 wd 0.0000	time 0.3179 (0.3568)	loss 1.0430 (0.8267)	grad_norm 1.6086 (inf)	loss_scale 8192.0000 (14380.5479)	mem 11441MB
[2024-07-29 01:23:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:04:08 lr 0.000023	 wd 0.0000	time 0.2913 (0.3543)	loss 0.8281 (0.8266)	grad_norm 2.1400 (inf)	loss_scale 8192.0000 (14036.9306)	mem 11441MB
[2024-07-29 01:23:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:03:31 lr 0.000022	 wd 0.0000	time 0.2940 (0.3517)	loss 0.8340 (0.8266)	grad_norm 2.1934 (inf)	loss_scale 8192.0000 (13729.4645)	mem 11441MB
[2024-07-29 01:24:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:02:55 lr 0.000022	 wd 0.0000	time 0.2798 (0.3494)	loss 0.8794 (0.8265)	grad_norm 1.9773 (inf)	loss_scale 8192.0000 (13452.7296)	mem 11441MB
[2024-07-29 01:24:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:02:19 lr 0.000022	 wd 0.0000	time 0.2717 (0.3480)	loss 0.8530 (0.8267)	grad_norm 1.9006 (inf)	loss_scale 8192.0000 (13202.3379)	mem 11441MB
[2024-07-29 01:25:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:44 lr 0.000022	 wd 0.0000	time 0.2696 (0.3459)	loss 0.8486 (0.8264)	grad_norm 2.2846 (inf)	loss_scale 8192.0000 (12974.6988)	mem 11441MB
[2024-07-29 01:25:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:01:09 lr 0.000022	 wd 0.0000	time 0.2782 (0.3442)	loss 0.7993 (0.8268)	grad_norm 1.6946 (inf)	loss_scale 8192.0000 (12766.8457)	mem 11441MB
[2024-07-29 01:26:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:36 lr 0.000022	 wd 0.0000	time 0.3779 (0.3554)	loss 0.7930 (0.8272)	grad_norm 2.0267 (inf)	loss_scale 8192.0000 (12576.3065)	mem 11441MB
[2024-07-29 01:27:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.2978 (0.3539)	loss 0.7910 (0.8270)	grad_norm 1.7298 (inf)	loss_scale 8192.0000 (12401.0044)	mem 11441MB
[2024-07-29 01:27:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 20 training takes 0:14:57
[2024-07-29 01:28:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 34.852 (34.852)	Loss 0.3643 (0.3643)	Acc@1 92.578 (92.578)	Acc@5 98.438 (98.438)	Mem 11441MB
[2024-07-29 01:28:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.418 Acc@5 97.614
[2024-07-29 01:28:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-07-29 01:28:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.46%
[2024-07-29 01:28:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][0/2502]	eta 11:08:59 lr 0.000021	 wd 0.0000	time 16.0429 (16.0429)	loss 0.8569 (0.8569)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:29:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:18:27 lr 0.000021	 wd 0.0000	time 0.2542 (0.4611)	loss 0.8037 (0.8272)	grad_norm 2.3193 (2.0191)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:29:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:14:38 lr 0.000021	 wd 0.0000	time 0.2765 (0.3816)	loss 0.8281 (0.8315)	grad_norm 2.1922 (1.9729)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:30:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:13:01 lr 0.000021	 wd 0.0000	time 0.2800 (0.3547)	loss 0.7954 (0.8243)	grad_norm 1.9048 (1.9653)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:30:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:11:57 lr 0.000021	 wd 0.0000	time 0.2833 (0.3414)	loss 0.7334 (0.8231)	grad_norm 2.0636 (1.9747)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:31:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:11:08 lr 0.000021	 wd 0.0000	time 0.2904 (0.3338)	loss 0.9429 (0.8246)	grad_norm 2.0383 (1.9827)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:31:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:10:24 lr 0.000020	 wd 0.0000	time 0.2679 (0.3283)	loss 0.8647 (0.8248)	grad_norm 1.8081 (1.9851)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:32:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:09:44 lr 0.000020	 wd 0.0000	time 0.2992 (0.3243)	loss 0.8174 (0.8249)	grad_norm 2.3257 (1.9884)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:32:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:09:08 lr 0.000020	 wd 0.0000	time 0.2675 (0.3221)	loss 0.8306 (0.8245)	grad_norm 1.7662 (1.9836)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:33:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:08:32 lr 0.000020	 wd 0.0000	time 0.2797 (0.3198)	loss 0.8223 (0.8242)	grad_norm 1.7025 (1.9857)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:33:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:07:57 lr 0.000020	 wd 0.0000	time 0.2878 (0.3179)	loss 0.7559 (0.8234)	grad_norm 1.9431 (1.9841)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:34:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:07:24 lr 0.000020	 wd 0.0000	time 0.3503 (0.3171)	loss 0.7842 (0.8241)	grad_norm 2.2760 (1.9855)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:34:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:06:51 lr 0.000019	 wd 0.0000	time 0.2522 (0.3158)	loss 0.8862 (0.8239)	grad_norm 2.4513 (1.9834)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:35:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:06:18 lr 0.000019	 wd 0.0000	time 0.2893 (0.3148)	loss 0.9136 (0.8237)	grad_norm 1.5781 (1.9785)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:35:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:05:45 lr 0.000019	 wd 0.0000	time 0.2640 (0.3139)	loss 0.7588 (0.8239)	grad_norm 1.9662 (1.9857)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:36:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:05:29 lr 0.000019	 wd 0.0000	time 0.4072 (0.3288)	loss 0.8105 (0.8238)	grad_norm 1.7543 (1.9877)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:37:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:04:57 lr 0.000019	 wd 0.0000	time 0.2536 (0.3300)	loss 0.7993 (0.8231)	grad_norm 1.9139 (1.9861)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:38:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:04:52 lr 0.000019	 wd 0.0000	time 0.3011 (0.3645)	loss 0.8013 (0.8226)	grad_norm 1.9050 (1.9858)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:39:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:04:15 lr 0.000018	 wd 0.0000	time 0.3049 (0.3647)	loss 0.8037 (0.8220)	grad_norm 2.0054 (1.9856)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:40:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:03:37 lr 0.000018	 wd 0.0000	time 0.2868 (0.3615)	loss 0.7148 (0.8218)	grad_norm 1.8166 (1.9865)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:40:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:03:00 lr 0.000018	 wd 0.0000	time 0.2797 (0.3586)	loss 0.8018 (0.8220)	grad_norm 1.6168 (1.9869)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:41:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:02:23 lr 0.000018	 wd 0.0000	time 0.2920 (0.3566)	loss 0.8247 (0.8221)	grad_norm 2.4380 (1.9847)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:41:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:46 lr 0.000018	 wd 0.0000	time 0.2887 (0.3543)	loss 0.6763 (0.8221)	grad_norm 1.6871 (1.9837)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:42:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:01:11 lr 0.000018	 wd 0.0000	time 0.2695 (0.3521)	loss 0.9053 (0.8229)	grad_norm 2.1434 (1.9868)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:42:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:35 lr 0.000018	 wd 0.0000	time 0.3323 (0.3505)	loss 0.8320 (0.8231)	grad_norm 1.8773 (1.9874)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:43:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000017	 wd 0.0000	time 0.2818 (0.3486)	loss 0.8564 (0.8233)	grad_norm 1.6237 (1.9877)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:43:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 21 training takes 0:14:42
[2024-07-29 01:43:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 19.080 (19.080)	Loss 0.3608 (0.3608)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 11441MB
[2024-07-29 01:43:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.508 Acc@5 97.572
[2024-07-29 01:43:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-29 01:43:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.51%
[2024-07-29 01:43:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-29 01:43:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-29 01:44:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][0/2502]	eta 20:18:48 lr 0.000017	 wd 0.0000	time 29.2279 (29.2279)	loss 0.8560 (0.8560)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:44:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:23:26 lr 0.000017	 wd 0.0000	time 0.2743 (0.5856)	loss 0.9204 (0.8348)	grad_norm 1.6276 (2.0214)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:45:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:17:00 lr 0.000017	 wd 0.0000	time 0.2760 (0.4435)	loss 0.7075 (0.8321)	grad_norm 1.7513 (1.9608)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 01:45:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:14:35 lr 0.000017	 wd 0.0000	time 0.2781 (0.3978)	loss 0.9014 (0.8281)	grad_norm 2.3876 (2.0038)	loss_scale 16384.0000 (8736.3189)	mem 11441MB
[2024-07-29 01:46:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:13:04 lr 0.000017	 wd 0.0000	time 0.2640 (0.3734)	loss 0.8828 (0.8297)	grad_norm 1.8417 (2.0071)	loss_scale 16384.0000 (10643.4713)	mem 11441MB
[2024-07-29 01:46:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:11:58 lr 0.000017	 wd 0.0000	time 0.2831 (0.3589)	loss 0.9097 (0.8311)	grad_norm 1.9484 (2.0127)	loss_scale 16384.0000 (11789.2854)	mem 11441MB
[2024-07-29 01:47:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:11:05 lr 0.000016	 wd 0.0000	time 0.2684 (0.3502)	loss 0.9834 (0.8313)	grad_norm 2.0252 (2.0111)	loss_scale 16384.0000 (12553.7970)	mem 11441MB
[2024-07-29 01:47:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:10:18 lr 0.000016	 wd 0.0000	time 0.2952 (0.3433)	loss 0.8164 (0.8315)	grad_norm 1.7647 (2.0088)	loss_scale 16384.0000 (13100.1883)	mem 11441MB
[2024-07-29 01:48:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:09:35 lr 0.000016	 wd 0.0000	time 0.2993 (0.3380)	loss 0.7485 (0.8318)	grad_norm 1.9736 (2.0042)	loss_scale 16384.0000 (13510.1523)	mem 11441MB
[2024-07-29 01:48:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:08:55 lr 0.000016	 wd 0.0000	time 0.2741 (0.3340)	loss 0.8032 (0.8307)	grad_norm 1.6785 (2.0012)	loss_scale 16384.0000 (13829.1143)	mem 11441MB
[2024-07-29 01:49:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:08:17 lr 0.000016	 wd 0.0000	time 0.2923 (0.3314)	loss 0.7266 (0.8316)	grad_norm 2.3476 (2.0060)	loss_scale 16384.0000 (14084.3477)	mem 11441MB
[2024-07-29 01:49:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:07:41 lr 0.000016	 wd 0.0000	time 0.2673 (0.3288)	loss 0.7544 (0.8315)	grad_norm 1.9128 (2.0097)	loss_scale 16384.0000 (14293.2171)	mem 11441MB
[2024-07-29 01:50:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:07:05 lr 0.000016	 wd 0.0000	time 0.2903 (0.3267)	loss 0.8394 (0.8316)	grad_norm 1.9479 (2.0069)	loss_scale 16384.0000 (14467.3039)	mem 11441MB
[2024-07-29 01:51:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:06:51 lr 0.000015	 wd 0.0000	time 0.2745 (0.3420)	loss 0.8110 (0.8312)	grad_norm 2.0568 (2.0012)	loss_scale 16384.0000 (14614.6287)	mem 11441MB
[2024-07-29 01:52:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:06:22 lr 0.000015	 wd 0.0000	time 0.2889 (0.3470)	loss 0.8330 (0.8310)	grad_norm 1.9188 (2.0024)	loss_scale 16384.0000 (14740.9222)	mem 11441MB
[2024-07-29 01:52:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:05:50 lr 0.000015	 wd 0.0000	time 0.2517 (0.3500)	loss 0.6309 (0.8311)	grad_norm 2.1556 (2.0002)	loss_scale 16384.0000 (14850.3877)	mem 11441MB
[2024-07-29 01:53:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:05:13 lr 0.000015	 wd 0.0000	time 0.2884 (0.3471)	loss 0.9316 (0.8310)	grad_norm 1.6654 (1.9986)	loss_scale 16384.0000 (14946.1786)	mem 11441MB
[2024-07-29 01:53:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:04:36 lr 0.000015	 wd 0.0000	time 0.2750 (0.3445)	loss 0.6919 (0.8301)	grad_norm 1.9595 (1.9987)	loss_scale 16384.0000 (15030.7066)	mem 11441MB
[2024-07-29 01:54:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:04:00 lr 0.000015	 wd 0.0000	time 0.2971 (0.3427)	loss 1.0078 (0.8292)	grad_norm 1.9086 (2.0002)	loss_scale 16384.0000 (15105.8479)	mem 11441MB
[2024-07-29 01:54:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:03:25 lr 0.000015	 wd 0.0000	time 0.3078 (0.3407)	loss 0.8945 (0.8295)	grad_norm 1.9509 (2.0050)	loss_scale 16384.0000 (15173.0836)	mem 11441MB
[2024-07-29 01:55:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:02:50 lr 0.000014	 wd 0.0000	time 0.3018 (0.3389)	loss 0.8408 (0.8295)	grad_norm 2.0691 (2.0037)	loss_scale 16384.0000 (15233.5992)	mem 11441MB
[2024-07-29 01:55:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:02:15 lr 0.000014	 wd 0.0000	time 0.2733 (0.3377)	loss 0.7852 (0.8294)	grad_norm 2.0499 (2.0076)	loss_scale 16384.0000 (15288.3541)	mem 11441MB
[2024-07-29 01:56:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:41 lr 0.000014	 wd 0.0000	time 0.2798 (0.3362)	loss 0.6787 (0.8287)	grad_norm 1.6702 (2.0083)	loss_scale 16384.0000 (15338.1336)	mem 11441MB
[2024-07-29 01:56:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:01:07 lr 0.000014	 wd 0.0000	time 0.2639 (0.3348)	loss 0.8179 (0.8283)	grad_norm 2.2716 (2.0097)	loss_scale 16384.0000 (15383.5863)	mem 11441MB
[2024-07-29 01:57:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:35 lr 0.000014	 wd 0.0000	time 0.3237 (0.3455)	loss 0.7866 (0.8288)	grad_norm 2.0334 (2.0082)	loss_scale 16384.0000 (15425.2528)	mem 11441MB
[2024-07-29 01:58:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.2774 (0.3443)	loss 0.7808 (0.8286)	grad_norm 1.9671 (2.0037)	loss_scale 16384.0000 (15463.5874)	mem 11441MB
[2024-07-29 01:58:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 22 training takes 0:14:33
[2024-07-29 02:00:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 105.015 (105.015)	Loss 0.3586 (0.3586)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 11441MB
[2024-07-29 02:00:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.496 Acc@5 97.586
[2024-07-29 02:00:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-29 02:00:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.51%
[2024-07-29 02:01:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][0/2502]	eta 12:12:54 lr 0.000014	 wd 0.0000	time 17.5757 (17.5757)	loss 0.8525 (0.8525)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:01:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:19:14 lr 0.000014	 wd 0.0000	time 0.2978 (0.4808)	loss 0.8892 (0.8214)	grad_norm 2.1308 (1.9992)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:02:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:15:08 lr 0.000013	 wd 0.0000	time 0.2747 (0.3945)	loss 0.7563 (0.8188)	grad_norm 2.2636 (1.9758)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:02:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:13:19 lr 0.000013	 wd 0.0000	time 0.2800 (0.3632)	loss 0.7676 (0.8195)	grad_norm 2.0757 (1.9850)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:03:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:12:10 lr 0.000013	 wd 0.0000	time 0.2812 (0.3474)	loss 0.9521 (0.8232)	grad_norm 2.0810 (1.9850)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:03:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:11:18 lr 0.000013	 wd 0.0000	time 0.2615 (0.3388)	loss 0.9482 (0.8259)	grad_norm 2.5643 (2.0030)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:04:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:10:32 lr 0.000013	 wd 0.0000	time 0.2695 (0.3327)	loss 0.9453 (0.8264)	grad_norm 2.3392 (2.0035)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:04:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:09:51 lr 0.000013	 wd 0.0000	time 0.2583 (0.3281)	loss 0.8965 (0.8275)	grad_norm 1.7904 (2.0007)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:05:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:09:12 lr 0.000013	 wd 0.0000	time 0.2714 (0.3247)	loss 0.7837 (0.8258)	grad_norm 1.8584 (1.9946)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:05:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:08:36 lr 0.000012	 wd 0.0000	time 0.2680 (0.3226)	loss 1.0449 (0.8252)	grad_norm 2.1208 (1.9963)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:06:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:08:01 lr 0.000012	 wd 0.0000	time 0.2621 (0.3204)	loss 0.7031 (0.8263)	grad_norm 2.5068 (1.9971)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:06:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:07:27 lr 0.000012	 wd 0.0000	time 0.2827 (0.3189)	loss 0.8052 (0.8250)	grad_norm 2.0202 (1.9956)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:07:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:06:54 lr 0.000012	 wd 0.0000	time 0.2810 (0.3182)	loss 0.7754 (0.8252)	grad_norm 2.6419 (1.9979)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:07:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:06:21 lr 0.000012	 wd 0.0000	time 0.2818 (0.3171)	loss 0.8735 (0.8241)	grad_norm 1.6732 (1.9934)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:08:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:05:48 lr 0.000012	 wd 0.0000	time 0.3051 (0.3160)	loss 0.8657 (0.8237)	grad_norm 2.2222 (1.9955)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:08:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:05:20 lr 0.000012	 wd 0.0000	time 1.0104 (0.3200)	loss 0.9238 (0.8231)	grad_norm 3.6373 (1.9971)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:09:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:04:59 lr 0.000012	 wd 0.0000	time 0.2660 (0.3320)	loss 0.7910 (0.8232)	grad_norm 2.3973 (1.9931)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:10:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:04:37 lr 0.000011	 wd 0.0000	time 0.3586 (0.3461)	loss 0.6953 (0.8235)	grad_norm 2.0030 (1.9925)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:11:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:04:05 lr 0.000011	 wd 0.0000	time 0.2848 (0.3497)	loss 0.8647 (0.8238)	grad_norm 2.0333 (1.9966)	loss_scale 32768.0000 (16584.1377)	mem 11441MB
[2024-07-29 02:12:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:03:32 lr 0.000011	 wd 0.0000	time 0.2613 (0.3525)	loss 0.7607 (0.8236)	grad_norm 1.6577 (inf)	loss_scale 16384.0000 (16935.5918)	mem 11441MB
[2024-07-29 02:12:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:02:55 lr 0.000011	 wd 0.0000	time 0.2977 (0.3501)	loss 0.8984 (0.8229)	grad_norm 2.0491 (inf)	loss_scale 16384.0000 (16908.0260)	mem 11441MB
[2024-07-29 02:13:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:02:19 lr 0.000011	 wd 0.0000	time 0.2882 (0.3479)	loss 0.8428 (0.8233)	grad_norm 2.5108 (inf)	loss_scale 16384.0000 (16883.0842)	mem 11441MB
[2024-07-29 02:13:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:44 lr 0.000011	 wd 0.0000	time 0.2769 (0.3462)	loss 0.8633 (0.8232)	grad_norm 1.6247 (inf)	loss_scale 16384.0000 (16860.4089)	mem 11441MB
[2024-07-29 02:14:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:01:09 lr 0.000011	 wd 0.0000	time 0.2859 (0.3445)	loss 0.8857 (0.8233)	grad_norm 2.0900 (inf)	loss_scale 16384.0000 (16839.7045)	mem 11441MB
[2024-07-29 02:14:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:34 lr 0.000011	 wd 0.0000	time 0.2495 (0.3429)	loss 0.8315 (0.8233)	grad_norm 1.8810 (inf)	loss_scale 16384.0000 (16820.7247)	mem 11441MB
[2024-07-29 02:15:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.2819 (0.3413)	loss 0.8618 (0.8230)	grad_norm 1.8370 (inf)	loss_scale 16384.0000 (16803.2627)	mem 11441MB
[2024-07-29 02:15:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 23 training takes 0:14:25
[2024-07-29 02:15:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 30.269 (30.269)	Loss 0.3633 (0.3633)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 11441MB
[2024-07-29 02:16:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.530 Acc@5 97.602
[2024-07-29 02:16:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-29 02:16:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.53%
[2024-07-29 02:16:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-29 02:16:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-29 02:16:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][0/2502]	eta 12:28:36 lr 0.000010	 wd 0.0000	time 17.9524 (17.9524)	loss 0.7764 (0.7764)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:16:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:19:15 lr 0.000010	 wd 0.0000	time 0.2599 (0.4809)	loss 0.8774 (0.8122)	grad_norm 1.9300 (2.0293)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:17:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:15:00 lr 0.000010	 wd 0.0000	time 0.2768 (0.3912)	loss 0.8784 (0.8202)	grad_norm 1.5779 (2.0135)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:17:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:13:15 lr 0.000010	 wd 0.0000	time 0.3031 (0.3613)	loss 0.7949 (0.8186)	grad_norm 2.4597 (2.0154)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:18:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:12:09 lr 0.000010	 wd 0.0000	time 0.2921 (0.3473)	loss 0.8462 (0.8191)	grad_norm 1.8893 (1.9997)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:18:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:11:17 lr 0.000010	 wd 0.0000	time 0.2656 (0.3382)	loss 0.8057 (0.8198)	grad_norm 2.5942 (2.0033)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:19:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:10:31 lr 0.000010	 wd 0.0000	time 0.2856 (0.3321)	loss 0.7695 (0.8194)	grad_norm 2.1644 (1.9870)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:19:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:09:51 lr 0.000010	 wd 0.0000	time 0.2695 (0.3280)	loss 0.7646 (0.8197)	grad_norm 1.9037 (1.9899)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:20:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:09:13 lr 0.000010	 wd 0.0000	time 0.2791 (0.3253)	loss 0.7427 (0.8208)	grad_norm 1.7750 (1.9947)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:20:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:08:36 lr 0.000009	 wd 0.0000	time 0.2666 (0.3227)	loss 0.8672 (0.8215)	grad_norm 1.7817 (1.9958)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:21:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:08:01 lr 0.000009	 wd 0.0000	time 0.2793 (0.3207)	loss 0.8677 (0.8227)	grad_norm 1.9423 (1.9997)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:22:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:08:01 lr 0.000009	 wd 0.0000	time 0.3550 (0.3434)	loss 0.7524 (0.8212)	grad_norm 2.0385 (1.9991)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:23:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:07:33 lr 0.000009	 wd 0.0000	time 0.2602 (0.3486)	loss 0.7280 (0.8208)	grad_norm 2.2530 (1.9976)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:23:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:07:02 lr 0.000009	 wd 0.0000	time 0.2757 (0.3512)	loss 0.8745 (0.8218)	grad_norm 2.0519 (2.0011)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:24:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:06:23 lr 0.000009	 wd 0.0000	time 0.2785 (0.3478)	loss 0.8789 (0.8222)	grad_norm 1.9920 (1.9959)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 02:24:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:05:45 lr 0.000009	 wd 0.0000	time 0.2986 (0.3449)	loss 0.7324 (0.8225)	grad_norm 1.9083 (inf)	loss_scale 8192.0000 (16078.3691)	mem 11441MB
[2024-07-29 02:25:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:05:09 lr 0.000009	 wd 0.0000	time 0.2858 (0.3429)	loss 0.7910 (0.8223)	grad_norm 2.1499 (inf)	loss_scale 8192.0000 (15585.7789)	mem 11441MB
[2024-07-29 02:25:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:04:33 lr 0.000008	 wd 0.0000	time 0.2924 (0.3406)	loss 0.8506 (0.8229)	grad_norm 1.8322 (inf)	loss_scale 8192.0000 (15151.1064)	mem 11441MB
[2024-07-29 02:26:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:03:57 lr 0.000008	 wd 0.0000	time 0.2677 (0.3385)	loss 0.7529 (0.8224)	grad_norm 2.0643 (inf)	loss_scale 8192.0000 (14764.7041)	mem 11441MB
[2024-07-29 02:26:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:03:23 lr 0.000008	 wd 0.0000	time 0.2530 (0.3376)	loss 0.6211 (0.8228)	grad_norm 1.8866 (inf)	loss_scale 8192.0000 (14418.9542)	mem 11441MB
[2024-07-29 02:27:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:02:48 lr 0.000008	 wd 0.0000	time 0.2782 (0.3361)	loss 0.8687 (0.8224)	grad_norm 2.2577 (inf)	loss_scale 8192.0000 (14107.7621)	mem 11441MB
[2024-07-29 02:27:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:02:14 lr 0.000008	 wd 0.0000	time 0.2858 (0.3345)	loss 0.8164 (0.8218)	grad_norm 2.0357 (inf)	loss_scale 8192.0000 (13826.1932)	mem 11441MB
[2024-07-29 02:28:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:42 lr 0.000008	 wd 0.0000	time 0.2775 (0.3409)	loss 0.8628 (0.8215)	grad_norm 2.1565 (inf)	loss_scale 8192.0000 (13570.2099)	mem 11441MB
[2024-07-29 02:29:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:01:09 lr 0.000008	 wd 0.0000	time 0.2691 (0.3416)	loss 0.9282 (0.8217)	grad_norm 2.0210 (inf)	loss_scale 8192.0000 (13336.4763)	mem 11441MB
[2024-07-29 02:29:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:34 lr 0.000008	 wd 0.0000	time 0.6080 (0.3417)	loss 0.9399 (0.8218)	grad_norm 1.9537 (inf)	loss_scale 8192.0000 (13122.2124)	mem 11441MB
[2024-07-29 02:31:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.2853 (0.3604)	loss 0.9248 (0.8221)	grad_norm 2.1153 (inf)	loss_scale 8192.0000 (12925.0828)	mem 11441MB
[2024-07-29 02:31:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 24 training takes 0:15:10
[2024-07-29 02:31:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 39.913 (39.913)	Loss 0.3613 (0.3613)	Acc@1 91.797 (91.797)	Acc@5 98.438 (98.438)	Mem 11441MB
[2024-07-29 02:32:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.606 Acc@5 97.586
[2024-07-29 02:32:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.6%
[2024-07-29 02:32:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.61%
[2024-07-29 02:32:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-29 02:32:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-29 02:32:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][0/2502]	eta 11:03:58 lr 0.000008	 wd 0.0000	time 15.9226 (15.9226)	loss 0.7983 (0.7983)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:33:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:18:24 lr 0.000008	 wd 0.0000	time 0.2940 (0.4597)	loss 0.8501 (0.8167)	grad_norm 1.7864 (2.0010)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:33:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:14:39 lr 0.000007	 wd 0.0000	time 0.2806 (0.3819)	loss 0.7412 (0.8182)	grad_norm 1.7827 (1.9972)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:34:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:13:01 lr 0.000007	 wd 0.0000	time 0.2645 (0.3548)	loss 0.8511 (0.8198)	grad_norm 2.2792 (1.9849)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:34:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:11:58 lr 0.000007	 wd 0.0000	time 0.2853 (0.3417)	loss 0.8555 (0.8187)	grad_norm 1.9731 (2.0008)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:35:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:11:08 lr 0.000007	 wd 0.0000	time 0.2922 (0.3341)	loss 0.7764 (0.8192)	grad_norm 1.7861 (1.9946)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:35:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:10:24 lr 0.000007	 wd 0.0000	time 0.2769 (0.3284)	loss 0.8320 (0.8199)	grad_norm 1.8935 (1.9980)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:36:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:09:44 lr 0.000007	 wd 0.0000	time 0.2731 (0.3246)	loss 0.8384 (0.8193)	grad_norm 1.9778 (1.9981)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:36:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:09:08 lr 0.000007	 wd 0.0000	time 0.2707 (0.3220)	loss 0.8833 (0.8193)	grad_norm 1.8580 (1.9983)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:37:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:08:32 lr 0.000007	 wd 0.0000	time 0.2714 (0.3197)	loss 0.7988 (0.8190)	grad_norm 2.0206 (2.0019)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:37:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:07:57 lr 0.000007	 wd 0.0000	time 0.2593 (0.3179)	loss 0.9277 (0.8192)	grad_norm 1.9177 (2.0052)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:38:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:07:24 lr 0.000007	 wd 0.0000	time 0.3036 (0.3172)	loss 0.7661 (0.8189)	grad_norm 1.7930 (2.0066)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:38:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:06:51 lr 0.000006	 wd 0.0000	time 0.2593 (0.3160)	loss 1.0137 (0.8201)	grad_norm 1.8343 (1.9964)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:39:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:06:18 lr 0.000006	 wd 0.0000	time 0.2687 (0.3148)	loss 0.8066 (0.8204)	grad_norm 1.7131 (1.9952)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:39:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:05:46 lr 0.000006	 wd 0.0000	time 0.2810 (0.3140)	loss 0.8169 (0.8200)	grad_norm 1.7127 (1.9922)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:40:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:05:29 lr 0.000006	 wd 0.0000	time 0.3494 (0.3291)	loss 0.8564 (0.8202)	grad_norm 1.9569 (1.9933)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:41:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:05:00 lr 0.000006	 wd 0.0000	time 0.3401 (0.3327)	loss 0.8257 (0.8195)	grad_norm 1.8408 (1.9924)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:41:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:04:29 lr 0.000006	 wd 0.0000	time 0.2955 (0.3356)	loss 0.8003 (0.8190)	grad_norm 1.9601 (1.9931)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:42:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:03:54 lr 0.000006	 wd 0.0000	time 0.2754 (0.3338)	loss 0.9912 (0.8198)	grad_norm 2.7594 (1.9897)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:42:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:03:20 lr 0.000006	 wd 0.0000	time 0.2896 (0.3324)	loss 1.1045 (0.8201)	grad_norm 1.8414 (1.9944)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:43:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:02:46 lr 0.000006	 wd 0.0000	time 0.2942 (0.3315)	loss 0.8696 (0.8199)	grad_norm 1.9901 (1.9956)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:43:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:02:12 lr 0.000006	 wd 0.0000	time 0.2889 (0.3302)	loss 0.8579 (0.8199)	grad_norm 1.8191 (1.9955)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:44:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:39 lr 0.000006	 wd 0.0000	time 0.3067 (0.3291)	loss 0.7256 (0.8190)	grad_norm 1.8667 (1.9925)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:44:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:01:06 lr 0.000005	 wd 0.0000	time 0.2512 (0.3283)	loss 0.8066 (0.8188)	grad_norm 1.6683 (1.9948)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:45:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:33 lr 0.000005	 wd 0.0000	time 0.2853 (0.3273)	loss 0.7969 (0.8188)	grad_norm 1.6670 (1.9956)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:45:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000005	 wd 0.0000	time 0.2837 (0.3263)	loss 0.7568 (0.8185)	grad_norm 2.1516 (1.9958)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:46:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 25 training takes 0:13:44
[2024-07-29 02:47:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 84.715 (84.715)	Loss 0.3604 (0.3604)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 11441MB
[2024-07-29 02:47:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.536 Acc@5 97.616
[2024-07-29 02:47:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-29 02:47:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.61%
[2024-07-29 02:48:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][0/2502]	eta 20:36:28 lr 0.000005	 wd 0.0000	time 29.6517 (29.6517)	loss 0.8101 (0.8101)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:48:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:23:49 lr 0.000005	 wd 0.0000	time 0.2828 (0.5952)	loss 0.9448 (0.8217)	grad_norm 1.9144 (1.9409)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:49:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:17:16 lr 0.000005	 wd 0.0000	time 0.2984 (0.4501)	loss 0.8311 (0.8210)	grad_norm 2.8943 (1.9987)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:49:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:14:42 lr 0.000005	 wd 0.0000	time 0.2871 (0.4006)	loss 0.7725 (0.8210)	grad_norm 1.9640 (2.0006)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:50:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:13:09 lr 0.000005	 wd 0.0000	time 0.3084 (0.3756)	loss 0.8789 (0.8197)	grad_norm 1.9327 (1.9909)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 02:50:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:12:02 lr 0.000005	 wd 0.0000	time 0.2880 (0.3610)	loss 0.9131 (0.8210)	grad_norm 1.8336 (1.9873)	loss_scale 16384.0000 (9173.0778)	mem 11441MB
[2024-07-29 02:51:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:11:08 lr 0.000005	 wd 0.0000	time 0.2789 (0.3514)	loss 0.8135 (0.8211)	grad_norm 2.0537 (1.9914)	loss_scale 16384.0000 (10372.8985)	mem 11441MB
[2024-07-29 02:51:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:10:21 lr 0.000005	 wd 0.0000	time 0.2867 (0.3447)	loss 0.9971 (0.8202)	grad_norm 1.7602 (1.9934)	loss_scale 16384.0000 (11230.4023)	mem 11441MB
[2024-07-29 02:52:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:09:37 lr 0.000005	 wd 0.0000	time 0.2816 (0.3394)	loss 0.7954 (0.8197)	grad_norm 1.9243 (1.9941)	loss_scale 16384.0000 (11873.7978)	mem 11441MB
[2024-07-29 02:52:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:08:58 lr 0.000005	 wd 0.0000	time 0.2747 (0.3359)	loss 0.8281 (0.8191)	grad_norm 1.8335 (1.9959)	loss_scale 16384.0000 (12374.3751)	mem 11441MB
[2024-07-29 02:53:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:08:19 lr 0.000004	 wd 0.0000	time 0.2972 (0.3326)	loss 0.9561 (0.8193)	grad_norm 1.8928 (2.0017)	loss_scale 16384.0000 (12774.9371)	mem 11441MB
[2024-07-29 02:53:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:07:42 lr 0.000004	 wd 0.0000	time 0.2958 (0.3298)	loss 0.8716 (0.8189)	grad_norm 1.7706 (2.0012)	loss_scale 16384.0000 (13102.7357)	mem 11441MB
[2024-07-29 02:54:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:07:06 lr 0.000004	 wd 0.0000	time 0.2861 (0.3280)	loss 0.7466 (0.8196)	grad_norm 1.8296 (1.9959)	loss_scale 16384.0000 (13375.9467)	mem 11441MB
[2024-07-29 02:54:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:06:32 lr 0.000004	 wd 0.0000	time 0.2692 (0.3262)	loss 0.7456 (0.8197)	grad_norm 2.1455 (1.9979)	loss_scale 16384.0000 (13607.1576)	mem 11441MB
[2024-07-29 02:55:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:05:57 lr 0.000004	 wd 0.0000	time 0.2804 (0.3244)	loss 0.8936 (0.8199)	grad_norm 1.8791 (1.9981)	loss_scale 16384.0000 (13805.3619)	mem 11441MB
[2024-07-29 02:56:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:05:23 lr 0.000004	 wd 0.0000	time 0.2939 (0.3230)	loss 0.7471 (0.8200)	grad_norm 2.1755 (1.9935)	loss_scale 16384.0000 (13977.1566)	mem 11441MB
[2024-07-29 02:56:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:05:05 lr 0.000004	 wd 0.0000	time 0.3838 (0.3391)	loss 0.7300 (0.8189)	grad_norm 2.0560 (1.9938)	loss_scale 16384.0000 (14127.4903)	mem 11441MB
[2024-07-29 02:57:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:04:34 lr 0.000004	 wd 0.0000	time 0.5460 (0.3426)	loss 0.7490 (0.8182)	grad_norm 2.3952 (1.9917)	loss_scale 16384.0000 (14260.1481)	mem 11441MB
[2024-07-29 02:59:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:04:20 lr 0.000004	 wd 0.0000	time 0.2748 (0.3714)	loss 0.8311 (0.8182)	grad_norm 1.8659 (1.9918)	loss_scale 16384.0000 (14378.0744)	mem 11441MB
[2024-07-29 02:59:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:03:43 lr 0.000004	 wd 0.0000	time 0.2822 (0.3721)	loss 0.7236 (0.8183)	grad_norm 1.8212 (1.9924)	loss_scale 16384.0000 (14483.5939)	mem 11441MB
[2024-07-29 03:00:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:03:05 lr 0.000004	 wd 0.0000	time 0.2940 (0.3687)	loss 0.8418 (0.8183)	grad_norm 1.6352 (1.9915)	loss_scale 16384.0000 (14578.5667)	mem 11441MB
[2024-07-29 03:00:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:02:26 lr 0.000004	 wd 0.0000	time 0.2895 (0.3657)	loss 0.8457 (0.8184)	grad_norm 1.8460 (1.9926)	loss_scale 16384.0000 (14664.4988)	mem 11441MB
[2024-07-29 03:01:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:49 lr 0.000004	 wd 0.0000	time 0.2700 (0.3634)	loss 0.8267 (0.8184)	grad_norm 1.6566 (1.9920)	loss_scale 16384.0000 (14742.6224)	mem 11441MB
[2024-07-29 03:01:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:01:12 lr 0.000004	 wd 0.0000	time 0.2709 (0.3609)	loss 0.7681 (0.8186)	grad_norm 2.1630 (1.9900)	loss_scale 16384.0000 (14813.9557)	mem 11441MB
[2024-07-29 03:02:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:36 lr 0.000003	 wd 0.0000	time 0.2844 (0.3585)	loss 0.8535 (0.8189)	grad_norm 2.5559 (1.9872)	loss_scale 16384.0000 (14879.3469)	mem 11441MB
[2024-07-29 03:02:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.2823 (0.3562)	loss 0.7388 (0.8195)	grad_norm 2.7246 (1.9885)	loss_scale 16384.0000 (14939.5090)	mem 11441MB
[2024-07-29 03:03:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 26 training takes 0:15:05
[2024-07-29 03:03:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 25.905 (25.905)	Loss 0.3616 (0.3616)	Acc@1 91.797 (91.797)	Acc@5 98.438 (98.438)	Mem 11441MB
[2024-07-29 03:03:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.550 Acc@5 97.606
[2024-07-29 03:03:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.5%
[2024-07-29 03:03:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.61%
[2024-07-29 03:04:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][0/2502]	eta 21:39:44 lr 0.000003	 wd 0.0000	time 31.1689 (31.1689)	loss 0.7383 (0.7383)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:04:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:24:18 lr 0.000003	 wd 0.0000	time 0.2857 (0.6071)	loss 0.8281 (0.8210)	grad_norm 2.7269 (2.0336)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:05:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:17:27 lr 0.000003	 wd 0.0000	time 0.2982 (0.4549)	loss 0.8345 (0.8190)	grad_norm 1.8356 (2.0251)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:05:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:14:52 lr 0.000003	 wd 0.0000	time 0.2795 (0.4051)	loss 0.8179 (0.8159)	grad_norm 2.0364 (2.0364)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:06:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:13:16 lr 0.000003	 wd 0.0000	time 0.2877 (0.3792)	loss 0.8169 (0.8160)	grad_norm 1.7555 (2.0174)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:06:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:12:07 lr 0.000003	 wd 0.0000	time 0.2785 (0.3632)	loss 0.7437 (0.8141)	grad_norm 1.8288 (1.9990)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:07:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:11:11 lr 0.000003	 wd 0.0000	time 0.2916 (0.3530)	loss 0.7578 (0.8171)	grad_norm 1.7273 (1.9916)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:07:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:10:24 lr 0.000003	 wd 0.0000	time 0.2526 (0.3464)	loss 0.8384 (0.8187)	grad_norm 1.8733 (1.9937)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:08:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:09:40 lr 0.000003	 wd 0.0000	time 0.2855 (0.3408)	loss 0.9033 (0.8174)	grad_norm 1.8090 (1.9977)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:08:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:08:59 lr 0.000003	 wd 0.0000	time 0.2752 (0.3366)	loss 0.7881 (0.8194)	grad_norm 1.8902 (1.9993)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:09:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:08:20 lr 0.000003	 wd 0.0000	time 0.2917 (0.3335)	loss 0.9258 (0.8187)	grad_norm 2.0250 (2.0078)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:09:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:07:43 lr 0.000003	 wd 0.0000	time 0.2906 (0.3306)	loss 0.7412 (0.8188)	grad_norm 2.4782 (2.0032)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:10:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:07:07 lr 0.000003	 wd 0.0000	time 0.2995 (0.3282)	loss 0.7637 (0.8181)	grad_norm 2.0653 (1.9996)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:10:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:06:41 lr 0.000003	 wd 0.0000	time 0.8597 (0.3338)	loss 0.8394 (0.8181)	grad_norm 2.0321 (1.9960)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:12:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:06:37 lr 0.000003	 wd 0.0000	time 0.2791 (0.3611)	loss 0.7212 (0.8181)	grad_norm 2.2059 (1.9927)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:12:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:06:02 lr 0.000003	 wd 0.0000	time 0.2965 (0.3617)	loss 0.8296 (0.8187)	grad_norm 2.4079 (1.9869)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:13:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:05:22 lr 0.000003	 wd 0.0000	time 0.2953 (0.3581)	loss 0.7485 (0.8191)	grad_norm 1.9146 (1.9835)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:13:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:04:44 lr 0.000002	 wd 0.0000	time 0.2730 (0.3549)	loss 0.8994 (0.8187)	grad_norm 1.9609 (1.9803)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:14:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:04:07 lr 0.000002	 wd 0.0000	time 0.2808 (0.3526)	loss 0.7744 (0.8189)	grad_norm 2.0163 (1.9793)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:14:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:03:30 lr 0.000002	 wd 0.0000	time 0.2965 (0.3501)	loss 0.8618 (0.8188)	grad_norm 1.9203 (1.9779)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:15:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:02:54 lr 0.000002	 wd 0.0000	time 0.2839 (0.3477)	loss 0.7002 (0.8184)	grad_norm 1.9145 (inf)	loss_scale 16384.0000 (16449.5032)	mem 11441MB
[2024-07-29 03:15:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:02:19 lr 0.000002	 wd 0.0000	time 0.2991 (0.3464)	loss 0.9922 (0.8195)	grad_norm 2.0881 (inf)	loss_scale 16384.0000 (16446.3855)	mem 11441MB
[2024-07-29 03:16:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:44 lr 0.000002	 wd 0.0000	time 0.3001 (0.3446)	loss 0.7334 (0.8195)	grad_norm 1.8017 (inf)	loss_scale 16384.0000 (16443.5511)	mem 11441MB
[2024-07-29 03:16:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:01:09 lr 0.000002	 wd 0.0000	time 0.2920 (0.3428)	loss 0.8589 (0.8199)	grad_norm 2.1009 (inf)	loss_scale 16384.0000 (16440.9631)	mem 11441MB
[2024-07-29 03:17:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:35 lr 0.000002	 wd 0.0000	time 0.3010 (0.3502)	loss 0.8594 (0.8198)	grad_norm 1.8416 (inf)	loss_scale 16384.0000 (16438.5906)	mem 11441MB
[2024-07-29 03:18:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.2810 (0.3492)	loss 0.7710 (0.8201)	grad_norm 1.6507 (inf)	loss_scale 16384.0000 (16436.4078)	mem 11441MB
[2024-07-29 03:18:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 27 training takes 0:14:45
[2024-07-29 03:20:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 108.533 (108.533)	Loss 0.3608 (0.3608)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 11441MB
[2024-07-29 03:20:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.552 Acc@5 97.604
[2024-07-29 03:20:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.6%
[2024-07-29 03:20:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.61%
[2024-07-29 03:21:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][0/2502]	eta 11:19:51 lr 0.000002	 wd 0.0000	time 16.3036 (16.3036)	loss 0.8076 (0.8076)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:21:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:19:00 lr 0.000002	 wd 0.0000	time 0.2879 (0.4748)	loss 0.8711 (0.8301)	grad_norm 1.8523 (1.9249)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:22:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:15:00 lr 0.000002	 wd 0.0000	time 0.2898 (0.3911)	loss 0.8901 (0.8246)	grad_norm 2.5184 (1.9650)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:22:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:13:14 lr 0.000002	 wd 0.0000	time 0.2758 (0.3608)	loss 0.8428 (0.8247)	grad_norm 1.6819 (1.9477)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:23:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:12:06 lr 0.000002	 wd 0.0000	time 0.2790 (0.3457)	loss 0.7065 (0.8223)	grad_norm 2.1234 (1.9599)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:23:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:11:14 lr 0.000002	 wd 0.0000	time 0.3163 (0.3368)	loss 0.9170 (0.8225)	grad_norm 1.7633 (1.9634)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:24:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:10:29 lr 0.000002	 wd 0.0000	time 0.2954 (0.3309)	loss 0.8271 (0.8217)	grad_norm 1.6833 (1.9643)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:24:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:09:48 lr 0.000002	 wd 0.0000	time 0.2752 (0.3268)	loss 0.7905 (0.8203)	grad_norm 2.5861 (1.9788)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:25:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:09:10 lr 0.000002	 wd 0.0000	time 0.2774 (0.3235)	loss 0.8027 (0.8195)	grad_norm 1.9324 (1.9757)	loss_scale 16384.0000 (16384.0000)	mem 11441MB
[2024-07-29 03:25:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:08:35 lr 0.000002	 wd 0.0000	time 0.2746 (0.3219)	loss 0.8765 (0.8181)	grad_norm 2.3935 (inf)	loss_scale 8192.0000 (15747.5516)	mem 11441MB
[2024-07-29 03:26:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:08:00 lr 0.000002	 wd 0.0000	time 0.2930 (0.3200)	loss 0.8828 (0.8179)	grad_norm 1.8528 (inf)	loss_scale 8192.0000 (14992.7512)	mem 11441MB
[2024-07-29 03:26:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:07:26 lr 0.000002	 wd 0.0000	time 0.2852 (0.3183)	loss 0.7744 (0.8174)	grad_norm 1.9138 (inf)	loss_scale 8192.0000 (14375.0627)	mem 11441MB
[2024-07-29 03:27:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:06:53 lr 0.000002	 wd 0.0000	time 0.2818 (0.3176)	loss 0.9106 (0.8167)	grad_norm 2.4787 (inf)	loss_scale 8192.0000 (13860.2365)	mem 11441MB
[2024-07-29 03:27:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:06:20 lr 0.000002	 wd 0.0000	time 0.2544 (0.3163)	loss 0.7646 (0.8166)	grad_norm 2.3109 (inf)	loss_scale 8192.0000 (13424.5534)	mem 11441MB
[2024-07-29 03:28:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:05:47 lr 0.000002	 wd 0.0000	time 0.2845 (0.3153)	loss 0.7593 (0.8166)	grad_norm 1.9514 (inf)	loss_scale 8192.0000 (13051.0664)	mem 11441MB
[2024-07-29 03:28:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:05:16 lr 0.000002	 wd 0.0000	time 0.6116 (0.3161)	loss 0.7812 (0.8164)	grad_norm 1.6483 (inf)	loss_scale 8192.0000 (12727.3444)	mem 11441MB
[2024-07-29 03:29:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:05:01 lr 0.000002	 wd 0.0000	time 0.2990 (0.3342)	loss 0.7207 (0.8167)	grad_norm 1.6293 (inf)	loss_scale 8192.0000 (12444.0625)	mem 11441MB
[2024-07-29 03:31:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:04:48 lr 0.000001	 wd 0.0000	time 0.5328 (0.3593)	loss 0.7183 (0.8170)	grad_norm 1.7821 (inf)	loss_scale 8192.0000 (12194.0882)	mem 11441MB
[2024-07-29 03:32:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:04:23 lr 0.000001	 wd 0.0000	time 0.3010 (0.3756)	loss 0.7173 (0.8172)	grad_norm 2.1342 (inf)	loss_scale 8192.0000 (11971.8734)	mem 11441MB
[2024-07-29 03:32:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:03:43 lr 0.000001	 wd 0.0000	time 0.3250 (0.3718)	loss 0.8940 (0.8174)	grad_norm 1.8928 (inf)	loss_scale 8192.0000 (11773.0373)	mem 11441MB
[2024-07-29 03:33:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:03:04 lr 0.000001	 wd 0.0000	time 0.2954 (0.3684)	loss 0.7749 (0.8172)	grad_norm 1.7276 (inf)	loss_scale 8192.0000 (11594.0750)	mem 11441MB
[2024-07-29 03:33:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:02:27 lr 0.000001	 wd 0.0000	time 0.3290 (0.3658)	loss 0.8984 (0.8176)	grad_norm 2.0112 (inf)	loss_scale 8192.0000 (11432.1485)	mem 11441MB
[2024-07-29 03:34:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:49 lr 0.000001	 wd 0.0000	time 0.2664 (0.3632)	loss 0.8975 (0.8175)	grad_norm 1.9862 (inf)	loss_scale 8192.0000 (11284.9359)	mem 11441MB
[2024-07-29 03:34:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:01:12 lr 0.000001	 wd 0.0000	time 0.2904 (0.3607)	loss 0.7778 (0.8180)	grad_norm 2.0554 (inf)	loss_scale 8192.0000 (11150.5189)	mem 11441MB
[2024-07-29 03:35:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:36 lr 0.000001	 wd 0.0000	time 0.2787 (0.3588)	loss 0.8613 (0.8182)	grad_norm 2.2411 (inf)	loss_scale 8192.0000 (11027.2986)	mem 11441MB
[2024-07-29 03:35:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.2801 (0.3567)	loss 0.7852 (0.8187)	grad_norm 1.8500 (inf)	loss_scale 8192.0000 (10913.9320)	mem 11441MB
[2024-07-29 03:35:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 28 training takes 0:15:04
[2024-07-29 03:36:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 18.964 (18.964)	Loss 0.3604 (0.3604)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 11441MB
[2024-07-29 03:36:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.602 Acc@5 97.596
[2024-07-29 03:36:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.6%
[2024-07-29 03:36:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.61%
[2024-07-29 03:37:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][0/2502]	eta 23:18:06 lr 0.000001	 wd 0.0000	time 33.5277 (33.5277)	loss 0.8086 (0.8086)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:37:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:25:30 lr 0.000001	 wd 0.0000	time 0.2678 (0.6371)	loss 0.9253 (0.8181)	grad_norm 1.8112 (1.9442)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:38:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:18:01 lr 0.000001	 wd 0.0000	time 0.2676 (0.4698)	loss 0.7744 (0.8260)	grad_norm 2.1489 (1.9345)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:38:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:15:13 lr 0.000001	 wd 0.0000	time 0.2859 (0.4148)	loss 0.7598 (0.8231)	grad_norm 2.2127 (1.9618)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:39:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:13:32 lr 0.000001	 wd 0.0000	time 0.2785 (0.3866)	loss 0.7466 (0.8243)	grad_norm 2.1461 (1.9788)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:39:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:12:19 lr 0.000001	 wd 0.0000	time 0.2757 (0.3694)	loss 0.7710 (0.8240)	grad_norm 1.8353 (1.9844)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:40:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:11:21 lr 0.000001	 wd 0.0000	time 0.3076 (0.3585)	loss 0.7808 (0.8211)	grad_norm 2.0601 (1.9817)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:40:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:10:31 lr 0.000001	 wd 0.0000	time 0.2812 (0.3506)	loss 0.8989 (0.8193)	grad_norm 1.8926 (1.9679)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:41:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:09:46 lr 0.000001	 wd 0.0000	time 0.2842 (0.3444)	loss 0.7100 (0.8214)	grad_norm 1.9984 (1.9756)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:41:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:09:04 lr 0.000001	 wd 0.0000	time 0.2824 (0.3399)	loss 0.8462 (0.8212)	grad_norm 1.9877 (1.9770)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:42:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:08:25 lr 0.000001	 wd 0.0000	time 0.2734 (0.3365)	loss 0.7202 (0.8205)	grad_norm 1.8970 (1.9750)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:42:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:07:47 lr 0.000001	 wd 0.0000	time 0.2956 (0.3333)	loss 0.8101 (0.8212)	grad_norm 1.9051 (1.9730)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:43:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:07:10 lr 0.000001	 wd 0.0000	time 0.2670 (0.3307)	loss 0.8003 (0.8200)	grad_norm 1.8602 (1.9715)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:44:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:07:21 lr 0.000001	 wd 0.0000	time 0.5689 (0.3677)	loss 0.7261 (0.8211)	grad_norm 2.0448 (1.9703)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:45:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:06:55 lr 0.000001	 wd 0.0000	time 0.2771 (0.3769)	loss 0.9014 (0.8213)	grad_norm 1.9748 (1.9677)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:45:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:06:12 lr 0.000001	 wd 0.0000	time 0.2721 (0.3720)	loss 0.7441 (0.8210)	grad_norm 1.8634 (1.9644)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:46:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:05:31 lr 0.000001	 wd 0.0000	time 0.2756 (0.3678)	loss 0.8130 (0.8207)	grad_norm 1.9702 (1.9663)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:46:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:04:52 lr 0.000001	 wd 0.0000	time 0.2943 (0.3645)	loss 0.9961 (0.8212)	grad_norm 1.8100 (1.9702)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:47:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:04:13 lr 0.000001	 wd 0.0000	time 0.2508 (0.3611)	loss 0.6943 (0.8215)	grad_norm 1.8847 (1.9745)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:47:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:03:35 lr 0.000001	 wd 0.0000	time 0.2721 (0.3581)	loss 0.7593 (0.8221)	grad_norm 1.8241 (1.9729)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:48:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:02:58 lr 0.000001	 wd 0.0000	time 0.2542 (0.3562)	loss 0.8687 (0.8223)	grad_norm 2.0892 (1.9716)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:48:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:02:22 lr 0.000001	 wd 0.0000	time 0.3033 (0.3539)	loss 0.8203 (0.8223)	grad_norm 1.9040 (1.9697)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:49:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:46 lr 0.000001	 wd 0.0000	time 0.3080 (0.3517)	loss 0.9409 (0.8219)	grad_norm 1.6435 (1.9715)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:50:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:01:11 lr 0.000001	 wd 0.0000	time 0.7349 (0.3525)	loss 0.8032 (0.8215)	grad_norm 2.0420 (1.9720)	loss_scale 8192.0000 (8192.0000)	mem 11441MB
[2024-07-29 03:50:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:36 lr 0.000001	 wd 0.0000	time 0.2758 (0.3608)	loss 0.8076 (0.8217)	grad_norm 1.7576 (1.9683)	loss_scale 16384.0000 (8437.6576)	mem 11441MB
[2024-07-29 03:51:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.2808 (0.3586)	loss 0.9814 (0.8215)	grad_norm 1.6976 (1.9717)	loss_scale 16384.0000 (8755.3842)	mem 11441MB
[2024-07-29 03:51:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 29 training takes 0:15:16
[2024-07-29 03:51:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_29.pth saving......
[2024-07-29 03:51:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_conv_b_sequence_stage2/ckpt_epoch_29.pth saved !!!
[2024-07-29 03:53:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 72.642 (72.642)	Loss 0.3604 (0.3604)	Acc@1 91.992 (91.992)	Acc@5 98.438 (98.438)	Mem 11441MB
[2024-07-29 03:53:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.582 Acc@5 97.600
[2024-07-29 03:53:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.6%
[2024-07-29 03:53:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.61%
[2024-07-29 03:53:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 189): INFO Training time 8:09:13
