[2024-07-25 21:42:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 366): INFO Full config saved to pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/config.json
[2024-07-25 21:42:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/convnext-b/convnext_base_22k_224.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: convnext_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 27
    - 3
    DIMS:
    - 128
    - 256
    - 512
    - 1024
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_conv_b_step_stage0
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 0.0001
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 0.8
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.0e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 1.0e-08

[2024-07-25 21:42:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/diffusion_finetune/convnext/convnext/diffusion_ft_convnext_base_224_22kto1k_step_stage_process0.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/convnext-b/convnext_base_22k_224.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/diffusion-ft", "tag": "diffusion_ft_conv_b_step_stage0", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-25 21:42:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 108): INFO Creating model:convnext_diffusion_finetune/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0
[2024-07-25 21:42:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 110): INFO ConvNeXt_Diffusion_Finetune(
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (3): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (4): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (5): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (6): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (7): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (8): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (9): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (10): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (11): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (12): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (13): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (14): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (15): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (16): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (17): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (18): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (19): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (20): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (21): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (22): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (23): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (24): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (25): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
      (26): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
      (1): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
      (2): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-25 21:42:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 113): INFO number of params: 1580648
[2024-07-25 21:42:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 150): INFO no checkpoint found in pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0, ignoring auto resume
[2024-07-25 21:42:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/convnext-b/convnext_base_22k_224.pth for fine-tuning......
[2024-07-25 21:42:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 112): INFO loading ImageNet-22K weight to ImageNet-1K ......
[2024-07-25 21:42:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 127): WARNING <All keys matched successfully>
[2024-07-25 21:42:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/convnext-b/convnext_base_22k_224.pth'
[2024-07-25 21:43:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 77.074 (77.074)	Loss 0.3726 (0.3726)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 3038MB
[2024-07-25 21:44:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 65.032 Acc@5 77.620
[2024-07-25 21:44:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 162): INFO Accuracy of the network on the 50000 test images: 65.0%
[2024-07-25 21:44:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 168): INFO Start training
[2024-07-25 21:44:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][0/2502]	eta 13:42:36 lr 0.000100	 wd 0.0000	time 19.7269 (19.7269)	loss 1.6660 (1.6660)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 8691MB
[2024-07-25 21:44:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:15:46 lr 0.000100	 wd 0.0000	time 0.2592 (0.3939)	loss 1.5176 (1.5823)	grad_norm 7.0864 (nan)	loss_scale 16384.0000 (18168.3960)	mem 8691MB
[2024-07-25 21:45:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:15:35 lr 0.000100	 wd 0.0000	time 0.1786 (0.4062)	loss 1.3027 (1.5622)	grad_norm 3.7524 (nan)	loss_scale 16384.0000 (17280.6368)	mem 8691MB
[2024-07-25 21:45:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:11 lr 0.000100	 wd 0.0000	time 0.1802 (0.3320)	loss 1.7861 (1.5463)	grad_norm 4.5493 (nan)	loss_scale 8192.0000 (14751.0432)	mem 8691MB
[2024-07-25 21:46:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:18 lr 0.000100	 wd 0.0000	time 0.1687 (0.2945)	loss 1.6455 (1.5205)	grad_norm 2.6769 (nan)	loss_scale 8192.0000 (13115.3716)	mem 8691MB
[2024-07-25 21:46:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:09:05 lr 0.000100	 wd 0.0000	time 0.1985 (0.2725)	loss 1.2412 (1.4975)	grad_norm 3.4546 (nan)	loss_scale 8192.0000 (12132.6627)	mem 8691MB
[2024-07-25 21:47:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:08 lr 0.000100	 wd 0.0000	time 0.2073 (0.2882)	loss 1.3838 (1.4701)	grad_norm 2.7650 (nan)	loss_scale 8192.0000 (11476.9784)	mem 8691MB
[2024-07-25 21:47:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:13 lr 0.000100	 wd 0.0000	time 0.1724 (0.2738)	loss 1.3594 (1.4494)	grad_norm 3.6068 (nan)	loss_scale 8192.0000 (11008.3652)	mem 8691MB
[2024-07-25 21:47:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:26 lr 0.000100	 wd 0.0000	time 0.1896 (0.2626)	loss 1.1914 (1.4266)	grad_norm 2.7783 (nan)	loss_scale 8192.0000 (10656.7591)	mem 8691MB
[2024-07-25 21:47:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:06:46 lr 0.000100	 wd 0.0000	time 0.1725 (0.2540)	loss 1.3613 (1.4050)	grad_norm 3.8686 (nan)	loss_scale 8192.0000 (10383.2009)	mem 8691MB
[2024-07-25 21:48:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:06:34 lr 0.000100	 wd 0.0000	time 0.2257 (0.2628)	loss 1.1963 (1.3845)	grad_norm 3.5474 (nan)	loss_scale 8192.0000 (10164.2997)	mem 8691MB
[2024-07-25 21:48:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:01 lr 0.000100	 wd 0.0000	time 0.1795 (0.2576)	loss 1.1260 (1.3660)	grad_norm 3.9238 (nan)	loss_scale 8192.0000 (9985.1626)	mem 8691MB
[2024-07-25 21:49:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:27 lr 0.000100	 wd 0.0000	time 0.1813 (0.2517)	loss 1.1230 (1.3481)	grad_norm 2.1596 (nan)	loss_scale 8192.0000 (9835.8568)	mem 8691MB
[2024-07-25 21:49:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:04:56 lr 0.000100	 wd 0.0000	time 0.1733 (0.2465)	loss 0.9814 (1.3317)	grad_norm 2.6028 (nan)	loss_scale 8192.0000 (9709.5035)	mem 8691MB
[2024-07-25 21:49:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:30 lr 0.000100	 wd 0.0000	time 0.3637 (0.2450)	loss 1.1670 (1.3159)	grad_norm 3.2942 (nan)	loss_scale 8192.0000 (9601.1877)	mem 8691MB
[2024-07-25 21:50:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:08 lr 0.000100	 wd 0.0000	time 0.1774 (0.2484)	loss 1.2129 (1.3014)	grad_norm 2.2275 (nan)	loss_scale 8192.0000 (9507.3045)	mem 8691MB
[2024-07-25 21:50:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:40 lr 0.000100	 wd 0.0000	time 0.1730 (0.2445)	loss 1.1152 (1.2867)	grad_norm 2.2983 (nan)	loss_scale 8192.0000 (9425.1493)	mem 8691MB
[2024-07-25 21:50:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:13 lr 0.000100	 wd 0.0000	time 0.1751 (0.2409)	loss 0.8701 (1.2730)	grad_norm 3.5432 (nan)	loss_scale 4096.0000 (9155.1981)	mem 8691MB
[2024-07-25 21:51:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:02:47 lr 0.000100	 wd 0.0000	time 0.2304 (0.2381)	loss 0.9546 (1.2601)	grad_norm 2.9303 (nan)	loss_scale 4096.0000 (8874.2876)	mem 8691MB
[2024-07-25 21:51:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:23 lr 0.000100	 wd 0.0000	time 0.1727 (0.2386)	loss 1.0557 (1.2482)	grad_norm 2.0989 (nan)	loss_scale 4096.0000 (8622.9311)	mem 8691MB
[2024-07-25 21:52:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:01:58 lr 0.000100	 wd 0.0000	time 0.1701 (0.2361)	loss 1.0371 (1.2379)	grad_norm 2.7576 (nan)	loss_scale 4096.0000 (8396.6977)	mem 8691MB
[2024-07-25 21:52:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:34 lr 0.000100	 wd 0.0000	time 0.1731 (0.2339)	loss 0.9917 (1.2280)	grad_norm 3.0003 (nan)	loss_scale 4096.0000 (8192.0000)	mem 8691MB
[2024-07-25 21:52:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:09 lr 0.000100	 wd 0.0000	time 0.1831 (0.2317)	loss 1.0439 (1.2181)	grad_norm 2.1895 (nan)	loss_scale 4096.0000 (8005.9028)	mem 8691MB
[2024-07-25 21:52:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:46 lr 0.000100	 wd 0.0000	time 0.2207 (0.2305)	loss 1.0762 (1.2086)	grad_norm 2.0285 (nan)	loss_scale 4096.0000 (7835.9809)	mem 8691MB
[2024-07-25 21:53:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:23 lr 0.000100	 wd 0.0000	time 0.1762 (0.2302)	loss 0.9956 (1.2000)	grad_norm 2.8805 (nan)	loss_scale 4096.0000 (7680.2132)	mem 8691MB
[2024-07-25 21:53:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000100	 wd 0.0000	time 0.1689 (0.2283)	loss 1.1670 (1.1917)	grad_norm 2.0765 (nan)	loss_scale 4096.0000 (7536.9020)	mem 8691MB
[2024-07-25 21:53:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 0 training takes 0:09:35
[2024-07-25 21:53:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_0.pth saving......
[2024-07-25 21:53:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_0.pth saved !!!
[2024-07-25 21:54:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 42.792 (42.792)	Loss 0.3879 (0.3879)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-25 21:55:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 82.022 Acc@5 96.284
[2024-07-25 21:55:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 82.0%
[2024-07-25 21:55:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 82.02%
[2024-07-25 21:55:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saving......
[2024-07-25 21:55:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-25 21:55:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][0/2502]	eta 13:22:34 lr 0.000100	 wd 0.0000	time 19.2463 (19.2463)	loss 0.9673 (0.9673)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 21:55:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:15:09 lr 0.000100	 wd 0.0000	time 0.1906 (0.3787)	loss 0.8525 (0.9877)	grad_norm 2.4040 (2.5912)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 21:55:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:10:49 lr 0.000100	 wd 0.0000	time 0.1996 (0.2821)	loss 1.0811 (0.9945)	grad_norm 2.8291 (2.5654)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 21:56:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:36 lr 0.000100	 wd 0.0000	time 0.1773 (0.3162)	loss 1.0986 (0.9889)	grad_norm 2.1016 (2.5316)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 21:56:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:10:01 lr 0.000100	 wd 0.0000	time 0.1865 (0.2863)	loss 0.8052 (0.9897)	grad_norm 2.1144 (2.5357)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 21:57:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:08:51 lr 0.000100	 wd 0.0000	time 0.1733 (0.2656)	loss 0.9658 (0.9856)	grad_norm 2.7181 (2.5184)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 21:57:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:07:58 lr 0.000100	 wd 0.0000	time 0.1745 (0.2517)	loss 1.0918 (0.9866)	grad_norm 2.2424 (2.5208)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 21:57:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:07:30 lr 0.000100	 wd 0.0000	time 0.3655 (0.2498)	loss 0.8950 (0.9853)	grad_norm 2.3809 (2.5233)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 21:58:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:25 lr 0.000100	 wd 0.0000	time 0.1879 (0.2615)	loss 0.8633 (0.9852)	grad_norm 2.9160 (2.5246)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 21:58:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:06:45 lr 0.000099	 wd 0.0000	time 0.2119 (0.2530)	loss 1.0527 (0.9835)	grad_norm 2.5736 (2.5180)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 21:59:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:09 lr 0.000099	 wd 0.0000	time 0.1829 (0.2462)	loss 0.9727 (0.9819)	grad_norm 2.4289 (2.5224)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 21:59:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:05:40 lr 0.000099	 wd 0.0000	time 0.2414 (0.2428)	loss 1.1289 (0.9809)	grad_norm 2.0343 (2.5165)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 21:59:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:11 lr 0.000099	 wd 0.0000	time 0.1725 (0.2395)	loss 1.0625 (0.9802)	grad_norm 2.8338 (2.5044)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:00:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:04:43 lr 0.000099	 wd 0.0000	time 0.1829 (0.2360)	loss 1.0283 (0.9800)	grad_norm 2.0391 (2.4948)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:00:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:16 lr 0.000099	 wd 0.0000	time 0.1710 (0.2325)	loss 0.9893 (0.9792)	grad_norm 2.7458 (2.4746)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:00:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:03:49 lr 0.000099	 wd 0.0000	time 0.1836 (0.2294)	loss 1.0166 (0.9785)	grad_norm 2.2135 (2.4719)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:01:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:25 lr 0.000099	 wd 0.0000	time 0.1932 (0.2278)	loss 1.0273 (0.9783)	grad_norm 3.1013 (2.4721)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:01:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:02 lr 0.000099	 wd 0.0000	time 0.2462 (0.2276)	loss 0.8047 (0.9774)	grad_norm 2.4035 (2.4671)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:01:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:38 lr 0.000099	 wd 0.0000	time 0.1964 (0.2257)	loss 1.1152 (0.9772)	grad_norm 2.3009 (2.4643)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:02:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:14 lr 0.000099	 wd 0.0000	time 0.1950 (0.2236)	loss 0.9575 (0.9771)	grad_norm 4.2178 (2.4627)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:02:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:01:51 lr 0.000099	 wd 0.0000	time 0.1969 (0.2218)	loss 0.8213 (0.9762)	grad_norm 1.8318 (2.4627)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:02:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:28 lr 0.000099	 wd 0.0000	time 0.1811 (0.2208)	loss 0.8906 (0.9759)	grad_norm 2.0470 (2.4661)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:03:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:06 lr 0.000099	 wd 0.0000	time 0.1691 (0.2213)	loss 0.7861 (0.9751)	grad_norm 2.1912 (2.4605)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:03:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:44 lr 0.000099	 wd 0.0000	time 0.1694 (0.2199)	loss 1.1758 (0.9750)	grad_norm 2.5302 (2.4556)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:03:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:22 lr 0.000099	 wd 0.0000	time 0.1791 (0.2185)	loss 1.0010 (0.9742)	grad_norm 2.7092 (2.4535)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:04:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000099	 wd 0.0000	time 0.1697 (0.2169)	loss 1.1133 (0.9739)	grad_norm 1.7708 (2.4482)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:04:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 1 training takes 0:09:06
[2024-07-25 22:04:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 37.360 (37.360)	Loss 0.3855 (0.3855)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-25 22:04:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.546 Acc@5 96.948
[2024-07-25 22:04:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.5%
[2024-07-25 22:04:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.55%
[2024-07-25 22:04:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saving......
[2024-07-25 22:05:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-25 22:05:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][0/2502]	eta 11:14:09 lr 0.000099	 wd 0.0000	time 16.1669 (16.1669)	loss 0.8716 (0.8716)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:05:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:13:44 lr 0.000099	 wd 0.0000	time 0.1922 (0.3431)	loss 1.0000 (0.9601)	grad_norm 3.3221 (2.4513)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:05:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:11:09 lr 0.000099	 wd 0.0000	time 0.3708 (0.2910)	loss 0.9604 (0.9501)	grad_norm 3.4415 (2.4387)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:06:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:11:16 lr 0.000099	 wd 0.0000	time 0.1940 (0.3074)	loss 1.0400 (0.9500)	grad_norm 2.2526 (2.3967)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:06:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:09:42 lr 0.000099	 wd 0.0000	time 0.1951 (0.2772)	loss 0.8867 (0.9483)	grad_norm 2.6990 (2.3824)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:07:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:08:36 lr 0.000099	 wd 0.0000	time 0.1726 (0.2581)	loss 1.1533 (0.9470)	grad_norm 2.7076 (2.3947)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:07:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:07:54 lr 0.000099	 wd 0.0000	time 0.2673 (0.2494)	loss 1.0137 (0.9479)	grad_norm 2.4501 (2.3912)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:08:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:07:41 lr 0.000099	 wd 0.0000	time 0.1879 (0.2562)	loss 1.0205 (0.9479)	grad_norm 2.5147 (2.3905)	loss_scale 8192.0000 (4598.5050)	mem 8691MB
[2024-07-25 22:08:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:01 lr 0.000099	 wd 0.0000	time 0.1675 (0.2474)	loss 0.8169 (0.9462)	grad_norm 2.5472 (2.3837)	loss_scale 8192.0000 (5047.1311)	mem 8691MB
[2024-07-25 22:08:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:24 lr 0.000098	 wd 0.0000	time 0.1833 (0.2401)	loss 0.9692 (0.9468)	grad_norm 2.1083 (2.3675)	loss_scale 8192.0000 (5396.1731)	mem 8691MB
[2024-07-25 22:08:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:05:52 lr 0.000098	 wd 0.0000	time 0.1962 (0.2344)	loss 0.8623 (0.9469)	grad_norm 2.9703 (2.3710)	loss_scale 8192.0000 (5675.4765)	mem 8691MB
[2024-07-25 22:09:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:49 lr 0.000098	 wd 0.0000	time 0.2839 (0.2490)	loss 0.9346 (0.9464)	grad_norm 2.2322 (2.3628)	loss_scale 8192.0000 (5904.0436)	mem 8691MB
[2024-07-25 22:09:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:21 lr 0.000098	 wd 0.0000	time 0.1840 (0.2472)	loss 1.1377 (0.9457)	grad_norm 2.6370 (2.3668)	loss_scale 8192.0000 (6094.5479)	mem 8691MB
[2024-07-25 22:10:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:04:51 lr 0.000098	 wd 0.0000	time 0.1927 (0.2424)	loss 0.9980 (0.9464)	grad_norm 1.8586 (2.3608)	loss_scale 8192.0000 (6255.7663)	mem 8691MB
[2024-07-25 22:10:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:22 lr 0.000098	 wd 0.0000	time 0.1930 (0.2386)	loss 0.9570 (0.9465)	grad_norm 2.9399 (2.3482)	loss_scale 8192.0000 (6393.9700)	mem 8691MB
[2024-07-25 22:10:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:03:56 lr 0.000098	 wd 0.0000	time 0.3795 (0.2364)	loss 0.9126 (0.9460)	grad_norm 1.7482 (2.3352)	loss_scale 8192.0000 (6513.7588)	mem 8691MB
[2024-07-25 22:11:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:31 lr 0.000098	 wd 0.0000	time 0.1812 (0.2350)	loss 0.9297 (0.9458)	grad_norm 2.1608 (2.3261)	loss_scale 8192.0000 (6618.5834)	mem 8691MB
[2024-07-25 22:11:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:06 lr 0.000098	 wd 0.0000	time 0.2043 (0.2323)	loss 0.9868 (0.9460)	grad_norm 2.3272 (2.3169)	loss_scale 8192.0000 (6711.0829)	mem 8691MB
[2024-07-25 22:11:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:41 lr 0.000098	 wd 0.0000	time 0.2145 (0.2298)	loss 0.8408 (0.9456)	grad_norm 1.6676 (2.3095)	loss_scale 8192.0000 (6793.3104)	mem 8691MB
[2024-07-25 22:12:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:17 lr 0.000098	 wd 0.0000	time 0.1823 (0.2277)	loss 0.8872 (0.9460)	grad_norm 2.2554 (2.3152)	loss_scale 8192.0000 (6866.8869)	mem 8691MB
[2024-07-25 22:12:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:01:54 lr 0.000098	 wd 0.0000	time 0.1692 (0.2282)	loss 0.9048 (0.9454)	grad_norm 1.7289 (2.3113)	loss_scale 8192.0000 (6933.1094)	mem 8691MB
[2024-07-25 22:12:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:31 lr 0.000098	 wd 0.0000	time 0.1981 (0.2270)	loss 1.0332 (0.9458)	grad_norm 2.4844 (2.3056)	loss_scale 8192.0000 (6993.0281)	mem 8691MB
[2024-07-25 22:13:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:08 lr 0.000098	 wd 0.0000	time 0.1807 (0.2253)	loss 0.9097 (0.9454)	grad_norm 2.0577 (2.2992)	loss_scale 8192.0000 (7047.5020)	mem 8691MB
[2024-07-25 22:13:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:45 lr 0.000098	 wd 0.0000	time 0.1757 (0.2236)	loss 1.0137 (0.9450)	grad_norm 2.1101 (2.3024)	loss_scale 8192.0000 (7097.2412)	mem 8691MB
[2024-07-25 22:13:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:22 lr 0.000098	 wd 0.0000	time 0.2082 (0.2224)	loss 1.1699 (0.9447)	grad_norm 2.4646 (2.2994)	loss_scale 8192.0000 (7142.8372)	mem 8691MB
[2024-07-25 22:14:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000098	 wd 0.0000	time 0.1695 (0.2212)	loss 0.8979 (0.9448)	grad_norm 2.5070 (2.2968)	loss_scale 8192.0000 (7184.7869)	mem 8691MB
[2024-07-25 22:14:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 2 training takes 0:09:22
[2024-07-25 22:14:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 25.931 (25.931)	Loss 0.3828 (0.3828)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-25 22:15:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.002 Acc@5 97.166
[2024-07-25 22:15:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-25 22:15:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.00%
[2024-07-25 22:15:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saving......
[2024-07-25 22:15:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-25 22:15:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][0/2502]	eta 10:39:16 lr 0.000098	 wd 0.0000	time 15.3304 (15.3304)	loss 0.7935 (0.7935)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:15:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:16:12 lr 0.000098	 wd 0.0000	time 0.3857 (0.4047)	loss 0.8931 (0.9360)	grad_norm 2.3989 (2.3330)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:16:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:13:03 lr 0.000097	 wd 0.0000	time 0.1842 (0.3402)	loss 0.9683 (0.9360)	grad_norm 1.9375 (2.2610)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:16:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:10:34 lr 0.000097	 wd 0.0000	time 0.1760 (0.2880)	loss 1.0537 (0.9381)	grad_norm 2.2400 (2.2445)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:16:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:09:09 lr 0.000097	 wd 0.0000	time 0.1701 (0.2616)	loss 0.9751 (0.9376)	grad_norm 2.1445 (2.2476)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:17:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:08:16 lr 0.000097	 wd 0.0000	time 0.2557 (0.2481)	loss 0.9609 (0.9367)	grad_norm 2.2989 (2.2330)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:17:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:08:24 lr 0.000097	 wd 0.0000	time 0.2154 (0.2654)	loss 0.8813 (0.9365)	grad_norm 3.1622 (2.2142)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:18:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:07:38 lr 0.000097	 wd 0.0000	time 0.1880 (0.2544)	loss 1.1338 (0.9366)	grad_norm 2.5668 (2.2404)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:18:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:06:58 lr 0.000097	 wd 0.0000	time 0.2019 (0.2459)	loss 0.9707 (0.9374)	grad_norm 2.1718 (2.2265)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:18:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:06:23 lr 0.000097	 wd 0.0000	time 0.1730 (0.2394)	loss 1.0830 (0.9381)	grad_norm 2.1591 (2.2450)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:19:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:12 lr 0.000097	 wd 0.0000	time 0.1993 (0.2479)	loss 0.9951 (0.9396)	grad_norm 1.9359 (2.2392)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:19:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:05:40 lr 0.000097	 wd 0.0000	time 0.2097 (0.2425)	loss 0.8926 (0.9402)	grad_norm 2.0016 (2.2344)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:19:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:09 lr 0.000097	 wd 0.0000	time 0.1673 (0.2377)	loss 1.0107 (0.9407)	grad_norm 1.6698 (2.2222)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:20:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:04:40 lr 0.000097	 wd 0.0000	time 0.1824 (0.2333)	loss 1.0371 (0.9412)	grad_norm 2.9001 (2.2144)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:20:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:16 lr 0.000097	 wd 0.0000	time 0.2642 (0.2328)	loss 0.8633 (0.9417)	grad_norm 1.6803 (2.2101)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:20:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:03:56 lr 0.000097	 wd 0.0000	time 0.1758 (0.2357)	loss 0.8613 (0.9419)	grad_norm 2.0978 (2.2128)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:21:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:29 lr 0.000096	 wd 0.0000	time 0.1702 (0.2325)	loss 0.8750 (0.9410)	grad_norm 1.8849 (2.2110)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:21:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:04 lr 0.000096	 wd 0.0000	time 0.1904 (0.2297)	loss 0.8892 (0.9405)	grad_norm 1.8640 (2.2082)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:21:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:39 lr 0.000096	 wd 0.0000	time 0.1817 (0.2276)	loss 1.0732 (0.9401)	grad_norm 3.1486 (2.2130)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:22:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:17 lr 0.000096	 wd 0.0000	time 0.1694 (0.2281)	loss 0.9263 (0.9397)	grad_norm 2.5585 (2.2099)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:22:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:01:53 lr 0.000096	 wd 0.0000	time 0.1703 (0.2267)	loss 0.9473 (0.9398)	grad_norm 2.2567 (2.2080)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:22:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:30 lr 0.000096	 wd 0.0000	time 0.1992 (0.2249)	loss 0.8848 (0.9396)	grad_norm 2.1089 (2.2055)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:23:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:07 lr 0.000096	 wd 0.0000	time 0.1826 (0.2231)	loss 0.9126 (0.9389)	grad_norm 1.8987 (2.2002)	loss_scale 16384.0000 (8519.5311)	mem 8691MB
[2024-07-25 22:23:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:44 lr 0.000096	 wd 0.0000	time 0.1982 (0.2219)	loss 0.9814 (0.9389)	grad_norm 2.2227 (2.2035)	loss_scale 16384.0000 (8861.3159)	mem 8691MB
[2024-07-25 22:23:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:22 lr 0.000096	 wd 0.0000	time 0.1705 (0.2215)	loss 0.9507 (0.9385)	grad_norm 2.6527 (2.2083)	loss_scale 16384.0000 (9174.6306)	mem 8691MB
[2024-07-25 22:24:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000096	 wd 0.0000	time 0.1703 (0.2201)	loss 1.0439 (0.9385)	grad_norm 2.0046 (2.2073)	loss_scale 16384.0000 (9462.8900)	mem 8691MB
[2024-07-25 22:24:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 3 training takes 0:09:15
[2024-07-25 22:24:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 24.922 (24.922)	Loss 0.3853 (0.3853)	Acc@1 91.211 (91.211)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-25 22:24:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.162 Acc@5 97.260
[2024-07-25 22:24:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-25 22:24:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.16%
[2024-07-25 22:24:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saving......
[2024-07-25 22:24:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-25 22:25:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][0/2502]	eta 18:06:11 lr 0.000096	 wd 0.0000	time 26.0477 (26.0477)	loss 0.9727 (0.9727)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-25 22:25:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:19:11 lr 0.000096	 wd 0.0000	time 0.1774 (0.4794)	loss 0.8599 (0.9242)	grad_norm 2.6918 (2.2721)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-25 22:26:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:12:45 lr 0.000096	 wd 0.0000	time 0.1709 (0.3324)	loss 1.0215 (0.9336)	grad_norm 1.9073 (2.1606)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-25 22:26:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:10:23 lr 0.000095	 wd 0.0000	time 0.1677 (0.2833)	loss 0.8672 (0.9332)	grad_norm 1.8938 (2.2176)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-25 22:26:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:09:04 lr 0.000095	 wd 0.0000	time 0.1743 (0.2589)	loss 0.9683 (0.9293)	grad_norm 2.1893 (2.1982)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-25 22:27:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:09:48 lr 0.000095	 wd 0.0000	time 0.1882 (0.2938)	loss 1.0088 (0.9298)	grad_norm 2.4109 (2.1726)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-25 22:27:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:08:45 lr 0.000095	 wd 0.0000	time 0.1829 (0.2761)	loss 0.8789 (0.9320)	grad_norm 2.5088 (2.1682)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-25 22:28:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:07:54 lr 0.000095	 wd 0.0000	time 0.1836 (0.2632)	loss 1.1602 (0.9302)	grad_norm 2.2654 (inf)	loss_scale 8192.0000 (15519.2240)	mem 8691MB
[2024-07-25 22:28:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:12 lr 0.000095	 wd 0.0000	time 0.1942 (0.2540)	loss 0.8369 (0.9293)	grad_norm 1.9769 (inf)	loss_scale 4096.0000 (14134.0125)	mem 8691MB
[2024-07-25 22:28:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:07:02 lr 0.000095	 wd 0.0000	time 0.3372 (0.2636)	loss 0.9897 (0.9304)	grad_norm 1.7069 (inf)	loss_scale 4096.0000 (13019.9156)	mem 8691MB
[2024-07-25 22:29:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:26 lr 0.000095	 wd 0.0000	time 0.1717 (0.2573)	loss 0.8833 (0.9306)	grad_norm 3.2981 (inf)	loss_scale 4096.0000 (12128.4156)	mem 8691MB
[2024-07-25 22:29:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:05:51 lr 0.000095	 wd 0.0000	time 0.1819 (0.2506)	loss 1.0791 (0.9312)	grad_norm 1.8512 (inf)	loss_scale 4096.0000 (11398.8592)	mem 8691MB
[2024-07-25 22:29:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:19 lr 0.000095	 wd 0.0000	time 0.1717 (0.2450)	loss 0.8735 (0.9314)	grad_norm 2.2144 (inf)	loss_scale 4096.0000 (10790.7943)	mem 8691MB
[2024-07-25 22:30:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:04:54 lr 0.000095	 wd 0.0000	time 0.4787 (0.2449)	loss 0.7905 (0.9304)	grad_norm 2.0198 (inf)	loss_scale 4096.0000 (10276.2060)	mem 8691MB
[2024-07-25 22:30:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:32 lr 0.000094	 wd 0.0000	time 0.1713 (0.2475)	loss 0.9185 (0.9296)	grad_norm 2.2832 (inf)	loss_scale 4096.0000 (9835.0778)	mem 8691MB
[2024-07-25 22:31:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:03 lr 0.000094	 wd 0.0000	time 0.1742 (0.2434)	loss 0.8130 (0.9300)	grad_norm 1.7100 (inf)	loss_scale 4096.0000 (9452.7275)	mem 8691MB
[2024-07-25 22:31:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:36 lr 0.000094	 wd 0.0000	time 0.1694 (0.2396)	loss 0.9707 (0.9303)	grad_norm 2.8567 (inf)	loss_scale 4096.0000 (9118.1412)	mem 8691MB
[2024-07-25 22:31:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:10 lr 0.000094	 wd 0.0000	time 0.2777 (0.2372)	loss 0.9463 (0.9305)	grad_norm 1.7235 (inf)	loss_scale 4096.0000 (8822.8948)	mem 8691MB
[2024-07-25 22:32:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:45 lr 0.000094	 wd 0.0000	time 0.2953 (0.2364)	loss 1.0107 (0.9315)	grad_norm 2.1414 (inf)	loss_scale 4096.0000 (8560.4353)	mem 8691MB
[2024-07-25 22:32:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:21 lr 0.000094	 wd 0.0000	time 0.1755 (0.2343)	loss 0.8750 (0.9313)	grad_norm 1.7748 (inf)	loss_scale 4096.0000 (8325.5886)	mem 8691MB
[2024-07-25 22:32:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:01:56 lr 0.000094	 wd 0.0000	time 0.1683 (0.2320)	loss 0.7964 (0.9307)	grad_norm 2.0154 (inf)	loss_scale 4096.0000 (8114.2149)	mem 8691MB
[2024-07-25 22:32:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:32 lr 0.000094	 wd 0.0000	time 0.1982 (0.2299)	loss 0.8472 (0.9307)	grad_norm 2.6274 (inf)	loss_scale 4096.0000 (7922.9624)	mem 8691MB
[2024-07-25 22:33:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:09 lr 0.000094	 wd 0.0000	time 0.1788 (0.2287)	loss 0.9478 (0.9304)	grad_norm 2.1861 (inf)	loss_scale 4096.0000 (7749.0886)	mem 8691MB
[2024-07-25 22:33:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:46 lr 0.000094	 wd 0.0000	time 0.1807 (0.2283)	loss 0.9214 (0.9306)	grad_norm 3.5431 (inf)	loss_scale 4096.0000 (7590.3277)	mem 8691MB
[2024-07-25 22:34:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:23 lr 0.000093	 wd 0.0000	time 0.1690 (0.2267)	loss 0.8647 (0.9305)	grad_norm 2.2337 (inf)	loss_scale 4096.0000 (7444.7913)	mem 8691MB
[2024-07-25 22:34:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000093	 wd 0.0000	time 0.1695 (0.2248)	loss 0.8120 (0.9306)	grad_norm 1.8912 (inf)	loss_scale 4096.0000 (7310.8932)	mem 8691MB
[2024-07-25 22:34:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 4 training takes 0:09:26
[2024-07-25 22:34:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 32.690 (32.690)	Loss 0.3794 (0.3794)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-25 22:35:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.346 Acc@5 97.282
[2024-07-25 22:35:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.3%
[2024-07-25 22:35:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.35%
[2024-07-25 22:35:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saving......
[2024-07-25 22:35:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-25 22:35:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][0/2502]	eta 11:50:17 lr 0.000093	 wd 0.0000	time 17.0336 (17.0336)	loss 1.0498 (1.0498)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:35:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:14:08 lr 0.000093	 wd 0.0000	time 0.1721 (0.3533)	loss 0.8535 (0.9255)	grad_norm 1.6784 (2.0355)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:36:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:10:17 lr 0.000093	 wd 0.0000	time 0.1791 (0.2682)	loss 0.8667 (0.9308)	grad_norm 2.9326 (2.0975)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:36:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:09:30 lr 0.000093	 wd 0.0000	time 0.3555 (0.2589)	loss 0.8862 (0.9295)	grad_norm 1.9569 (2.1057)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:37:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:43 lr 0.000093	 wd 0.0000	time 0.1961 (0.2775)	loss 0.8188 (0.9274)	grad_norm 2.0948 (2.1068)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:37:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:08:38 lr 0.000093	 wd 0.0000	time 0.1891 (0.2591)	loss 0.9551 (0.9263)	grad_norm 2.6996 (2.1117)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:37:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:07:48 lr 0.000093	 wd 0.0000	time 0.1686 (0.2465)	loss 1.1719 (0.9290)	grad_norm 1.9799 (2.1142)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:38:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:15 lr 0.000093	 wd 0.0000	time 0.3498 (0.2417)	loss 0.9785 (0.9281)	grad_norm 1.9539 (2.1268)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:38:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:05 lr 0.000093	 wd 0.0000	time 0.1675 (0.2502)	loss 0.9336 (0.9285)	grad_norm 2.5473 (2.1220)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:38:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:29 lr 0.000092	 wd 0.0000	time 0.1730 (0.2431)	loss 0.9014 (0.9284)	grad_norm 1.9772 (2.1288)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:39:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:05:56 lr 0.000092	 wd 0.0000	time 0.1692 (0.2371)	loss 0.8286 (0.9288)	grad_norm 2.0557 (2.1390)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:39:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:25 lr 0.000092	 wd 0.0000	time 0.1918 (0.2323)	loss 0.8257 (0.9296)	grad_norm 2.2782 (2.1405)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:39:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:03 lr 0.000092	 wd 0.0000	time 1.1341 (0.2330)	loss 1.0547 (0.9295)	grad_norm 2.2849 (2.1401)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:40:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:35 lr 0.000092	 wd 0.0000	time 0.1722 (0.2294)	loss 0.9116 (0.9293)	grad_norm 1.6294 (2.1317)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:40:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:09 lr 0.000092	 wd 0.0000	time 0.1696 (0.2266)	loss 0.9473 (0.9282)	grad_norm 2.3775 (2.1287)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:40:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:03:44 lr 0.000092	 wd 0.0000	time 0.1719 (0.2239)	loss 0.9351 (0.9280)	grad_norm 3.9173 (2.1249)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:41:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:20 lr 0.000092	 wd 0.0000	time 0.1863 (0.2218)	loss 0.8594 (0.9274)	grad_norm 2.0748 (2.1292)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:41:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:02:58 lr 0.000092	 wd 0.0000	time 0.1707 (0.2220)	loss 1.0342 (0.9273)	grad_norm 1.8266 (2.1326)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:41:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:34 lr 0.000091	 wd 0.0000	time 0.1923 (0.2206)	loss 0.9062 (0.9271)	grad_norm 1.7452 (2.1363)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:42:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:11 lr 0.000091	 wd 0.0000	time 0.1752 (0.2189)	loss 1.0762 (0.9275)	grad_norm 1.9760 (2.1423)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:42:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:01:49 lr 0.000091	 wd 0.0000	time 0.1736 (0.2174)	loss 1.0947 (0.9272)	grad_norm 1.8802 (2.1426)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:42:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:26 lr 0.000091	 wd 0.0000	time 0.2177 (0.2162)	loss 0.9380 (0.9264)	grad_norm 2.0774 (2.1430)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:43:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:05 lr 0.000091	 wd 0.0000	time 0.1988 (0.2161)	loss 0.9521 (0.9262)	grad_norm 2.1647 (2.1384)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-25 22:43:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:43 lr 0.000091	 wd 0.0000	time 0.1794 (0.2151)	loss 0.7847 (0.9257)	grad_norm 2.8356 (2.1405)	loss_scale 8192.0000 (4263.3290)	mem 8691MB
[2024-07-25 22:43:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:21 lr 0.000091	 wd 0.0000	time 0.1779 (0.2140)	loss 0.9570 (0.9254)	grad_norm 2.3551 (2.1422)	loss_scale 8192.0000 (4426.9554)	mem 8691MB
[2024-07-25 22:44:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000091	 wd 0.0000	time 0.1669 (0.2126)	loss 0.9258 (0.9256)	grad_norm 1.6926 (2.1404)	loss_scale 8192.0000 (4577.4970)	mem 8691MB
[2024-07-25 22:44:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 5 training takes 0:08:55
[2024-07-25 22:44:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 37.798 (37.798)	Loss 0.3784 (0.3784)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-25 22:45:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.450 Acc@5 97.352
[2024-07-25 22:45:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.5%
[2024-07-25 22:45:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.45%
[2024-07-25 22:45:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saving......
[2024-07-25 22:45:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-25 22:45:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][0/2502]	eta 10:53:52 lr 0.000091	 wd 0.0000	time 15.6805 (15.6805)	loss 0.9819 (0.9819)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:45:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:13:35 lr 0.000090	 wd 0.0000	time 0.1754 (0.3396)	loss 0.8965 (0.9229)	grad_norm 1.9124 (2.0793)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:45:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:10:03 lr 0.000090	 wd 0.0000	time 0.1776 (0.2621)	loss 0.8096 (0.9202)	grad_norm 2.6266 (2.0836)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:46:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:10:58 lr 0.000090	 wd 0.0000	time 0.1889 (0.2993)	loss 0.9531 (0.9224)	grad_norm 1.9497 (2.0824)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:46:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:09:33 lr 0.000090	 wd 0.0000	time 0.1674 (0.2729)	loss 0.9082 (0.9228)	grad_norm 1.4317 (2.0915)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:47:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:08:31 lr 0.000090	 wd 0.0000	time 0.1646 (0.2555)	loss 0.9893 (0.9217)	grad_norm 1.6271 (2.0794)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:47:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:07:43 lr 0.000090	 wd 0.0000	time 0.1714 (0.2435)	loss 1.0195 (0.9217)	grad_norm 2.1758 (2.0914)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:47:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:07:22 lr 0.000090	 wd 0.0000	time 0.5778 (0.2456)	loss 0.9009 (0.9233)	grad_norm 1.7413 (2.0833)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:48:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:06:59 lr 0.000090	 wd 0.0000	time 0.1743 (0.2464)	loss 0.8530 (0.9246)	grad_norm 1.7816 (2.0963)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:48:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:06:23 lr 0.000089	 wd 0.0000	time 0.2137 (0.2397)	loss 0.9097 (0.9247)	grad_norm 1.9240 (2.1196)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:49:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:05:51 lr 0.000089	 wd 0.0000	time 0.1714 (0.2340)	loss 0.8784 (0.9256)	grad_norm 1.5696 (2.1127)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:49:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:22 lr 0.000089	 wd 0.0000	time 0.1912 (0.2299)	loss 0.8066 (0.9244)	grad_norm 1.5051 (2.1114)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:49:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:09 lr 0.000089	 wd 0.0000	time 0.1893 (0.2375)	loss 0.7432 (0.9244)	grad_norm 1.7933 (2.1094)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:50:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:04:40 lr 0.000089	 wd 0.0000	time 0.1860 (0.2335)	loss 0.9365 (0.9254)	grad_norm 1.8663 (2.1122)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:50:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:13 lr 0.000089	 wd 0.0000	time 0.1726 (0.2299)	loss 1.1348 (0.9240)	grad_norm 2.5453 (2.1067)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:50:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:03:47 lr 0.000089	 wd 0.0000	time 0.1820 (0.2269)	loss 0.7739 (0.9241)	grad_norm 1.8958 (2.1092)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:51:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:23 lr 0.000089	 wd 0.0000	time 0.2102 (0.2254)	loss 0.9351 (0.9237)	grad_norm 2.2539 (2.1143)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:51:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:00 lr 0.000088	 wd 0.0000	time 0.2377 (0.2252)	loss 1.0098 (0.9225)	grad_norm 1.7411 (2.1144)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:51:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:36 lr 0.000088	 wd 0.0000	time 0.1805 (0.2233)	loss 0.7734 (0.9214)	grad_norm 1.8552 (2.1196)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:52:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:13 lr 0.000088	 wd 0.0000	time 0.1731 (0.2214)	loss 1.0459 (0.9212)	grad_norm 2.6872 (2.1168)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:52:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:01:50 lr 0.000088	 wd 0.0000	time 0.2061 (0.2197)	loss 1.1182 (0.9223)	grad_norm 1.7264 (2.1170)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:52:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:27 lr 0.000088	 wd 0.0000	time 0.1997 (0.2186)	loss 0.9155 (0.9225)	grad_norm 3.4520 (2.1231)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:53:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:06 lr 0.000088	 wd 0.0000	time 0.1908 (0.2190)	loss 0.9854 (0.9227)	grad_norm 3.0861 (2.1228)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:53:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:43 lr 0.000088	 wd 0.0000	time 0.2086 (0.2177)	loss 0.9600 (0.9227)	grad_norm 2.5275 (2.1239)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:53:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:22 lr 0.000087	 wd 0.0000	time 0.1711 (0.2165)	loss 0.9009 (0.9221)	grad_norm 2.0479 (2.1222)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:54:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000087	 wd 0.0000	time 0.1676 (0.2149)	loss 0.8335 (0.9218)	grad_norm 1.8975 (2.1243)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:54:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 6 training takes 0:09:01
[2024-07-25 22:54:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 38.500 (38.500)	Loss 0.3706 (0.3706)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-25 22:55:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.484 Acc@5 97.340
[2024-07-25 22:55:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.5%
[2024-07-25 22:55:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.48%
[2024-07-25 22:55:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saving......
[2024-07-25 22:55:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-25 22:55:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][0/2502]	eta 10:40:54 lr 0.000087	 wd 0.0000	time 15.3696 (15.3696)	loss 1.0566 (1.0566)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:55:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:13:39 lr 0.000087	 wd 0.0000	time 0.1778 (0.3411)	loss 1.0303 (0.9308)	grad_norm 1.8773 (2.1922)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:56:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:11:39 lr 0.000087	 wd 0.0000	time 0.4240 (0.3038)	loss 0.9619 (0.9172)	grad_norm 1.6789 (2.1355)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:56:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:10:50 lr 0.000087	 wd 0.0000	time 0.1853 (0.2953)	loss 0.9385 (0.9166)	grad_norm 2.4518 (2.0746)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:56:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:09:22 lr 0.000087	 wd 0.0000	time 0.1941 (0.2678)	loss 0.9951 (0.9174)	grad_norm 2.4097 (2.0960)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:57:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:08:22 lr 0.000087	 wd 0.0000	time 0.1836 (0.2509)	loss 0.8926 (0.9161)	grad_norm 2.0057 (2.0975)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:57:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:07:39 lr 0.000086	 wd 0.0000	time 0.1957 (0.2416)	loss 0.8726 (0.9170)	grad_norm 1.7801 (2.0796)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:57:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:07:30 lr 0.000086	 wd 0.0000	time 0.1759 (0.2497)	loss 0.8525 (0.9159)	grad_norm 1.9409 (2.0794)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:58:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:06:51 lr 0.000086	 wd 0.0000	time 0.1789 (0.2419)	loss 0.9038 (0.9165)	grad_norm 1.9573 (2.0811)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:58:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:06:17 lr 0.000086	 wd 0.0000	time 0.1731 (0.2354)	loss 0.7568 (0.9173)	grad_norm 2.1588 (2.0762)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:58:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:05:45 lr 0.000086	 wd 0.0000	time 0.1936 (0.2302)	loss 0.8774 (0.9181)	grad_norm 1.6452 (2.0762)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:59:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:37 lr 0.000086	 wd 0.0000	time 0.6421 (0.2405)	loss 0.8335 (0.9171)	grad_norm 1.9697 (2.0802)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 22:59:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:09 lr 0.000086	 wd 0.0000	time 0.1806 (0.2374)	loss 0.8052 (0.9176)	grad_norm 1.9805 (2.0874)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:00:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:04:40 lr 0.000085	 wd 0.0000	time 0.1798 (0.2333)	loss 0.9761 (0.9170)	grad_norm 1.7387 (2.0745)	loss_scale 16384.0000 (8809.0761)	mem 8691MB
[2024-07-25 23:00:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:13 lr 0.000085	 wd 0.0000	time 0.1718 (0.2296)	loss 0.9263 (0.9181)	grad_norm 1.9856 (2.0700)	loss_scale 16384.0000 (9349.7559)	mem 8691MB
[2024-07-25 23:00:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:03:47 lr 0.000085	 wd 0.0000	time 0.2085 (0.2270)	loss 0.8403 (0.9175)	grad_norm 2.1430 (2.0773)	loss_scale 16384.0000 (9818.3931)	mem 8691MB
[2024-07-25 23:01:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:23 lr 0.000085	 wd 0.0000	time 0.1856 (0.2256)	loss 0.9956 (0.9180)	grad_norm 2.0934 (2.0809)	loss_scale 16384.0000 (10228.4872)	mem 8691MB
[2024-07-25 23:01:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:02:59 lr 0.000085	 wd 0.0000	time 0.1867 (0.2235)	loss 0.8335 (0.9178)	grad_norm 2.1125 (inf)	loss_scale 8192.0000 (10349.5638)	mem 8691MB
[2024-07-25 23:01:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:35 lr 0.000085	 wd 0.0000	time 0.1778 (0.2216)	loss 0.8501 (0.9169)	grad_norm 1.7169 (inf)	loss_scale 8192.0000 (10229.7657)	mem 8691MB
[2024-07-25 23:01:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:12 lr 0.000085	 wd 0.0000	time 0.1818 (0.2197)	loss 1.0312 (0.9178)	grad_norm 2.1986 (inf)	loss_scale 8192.0000 (10122.5713)	mem 8691MB
[2024-07-25 23:02:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:01:49 lr 0.000084	 wd 0.0000	time 0.2071 (0.2188)	loss 0.8242 (0.9174)	grad_norm 1.8430 (inf)	loss_scale 8192.0000 (10026.0910)	mem 8691MB
[2024-07-25 23:02:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:28 lr 0.000084	 wd 0.0000	time 0.1820 (0.2194)	loss 0.9331 (0.9178)	grad_norm 1.9801 (inf)	loss_scale 8192.0000 (9938.7949)	mem 8691MB
[2024-07-25 23:03:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:05 lr 0.000084	 wd 0.0000	time 0.1866 (0.2183)	loss 0.8540 (0.9175)	grad_norm 2.6055 (inf)	loss_scale 8192.0000 (9859.4312)	mem 8691MB
[2024-07-25 23:03:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:43 lr 0.000084	 wd 0.0000	time 0.1703 (0.2170)	loss 0.9805 (0.9173)	grad_norm 2.4453 (inf)	loss_scale 8192.0000 (9786.9657)	mem 8691MB
[2024-07-25 23:03:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:21 lr 0.000084	 wd 0.0000	time 0.1892 (0.2156)	loss 0.8545 (0.9178)	grad_norm 1.7575 (inf)	loss_scale 8192.0000 (9720.5364)	mem 8691MB
[2024-07-25 23:03:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000084	 wd 0.0000	time 0.1702 (0.2142)	loss 0.8521 (0.9182)	grad_norm 3.0812 (inf)	loss_scale 8192.0000 (9659.4194)	mem 8691MB
[2024-07-25 23:04:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 7 training takes 0:09:00
[2024-07-25 23:04:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 37.644 (37.644)	Loss 0.3665 (0.3665)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-25 23:04:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.588 Acc@5 97.364
[2024-07-25 23:04:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-25 23:04:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.59%
[2024-07-25 23:04:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saving......
[2024-07-25 23:04:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-25 23:05:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][0/2502]	eta 10:36:52 lr 0.000084	 wd 0.0000	time 15.2727 (15.2727)	loss 1.0127 (1.0127)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:05:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:13:57 lr 0.000083	 wd 0.0000	time 0.1961 (0.3486)	loss 0.8799 (0.9279)	grad_norm 3.0260 (2.1407)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:05:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:12:40 lr 0.000083	 wd 0.0000	time 0.1905 (0.3304)	loss 0.9204 (0.9216)	grad_norm 2.0541 (2.1138)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:06:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:10:20 lr 0.000083	 wd 0.0000	time 0.1755 (0.2820)	loss 0.9434 (0.9158)	grad_norm 2.0219 (2.0956)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:06:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:09:01 lr 0.000083	 wd 0.0000	time 0.1820 (0.2578)	loss 0.9448 (0.9158)	grad_norm 1.7111 (2.0823)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:06:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:08:06 lr 0.000083	 wd 0.0000	time 0.1785 (0.2429)	loss 0.9321 (0.9165)	grad_norm 1.6477 (2.0595)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:07:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:08 lr 0.000083	 wd 0.0000	time 0.6784 (0.2569)	loss 0.8037 (0.9164)	grad_norm 2.2775 (2.0537)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:07:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:42 lr 0.000083	 wd 0.0000	time 0.1874 (0.2564)	loss 1.0244 (0.9147)	grad_norm 2.0439 (2.0676)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:08:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:01 lr 0.000082	 wd 0.0000	time 0.1765 (0.2476)	loss 1.0020 (0.9159)	grad_norm 1.8123 (2.0709)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:08:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:25 lr 0.000082	 wd 0.0000	time 0.1697 (0.2404)	loss 1.0176 (0.9153)	grad_norm 1.6450 (2.0651)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:08:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:05:56 lr 0.000082	 wd 0.0000	time 0.3543 (0.2371)	loss 0.9863 (0.9164)	grad_norm 1.5865 (2.0854)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:09:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:41 lr 0.000082	 wd 0.0000	time 0.1824 (0.2435)	loss 0.9160 (0.9167)	grad_norm 1.9596 (2.0860)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:09:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:10 lr 0.000082	 wd 0.0000	time 0.1661 (0.2387)	loss 0.9058 (0.9170)	grad_norm 2.1652 (2.0823)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:09:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:41 lr 0.000082	 wd 0.0000	time 0.1984 (0.2344)	loss 0.8481 (0.9177)	grad_norm 2.1269 (2.0774)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:10:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:14 lr 0.000081	 wd 0.0000	time 0.2485 (0.2311)	loss 0.8843 (0.9184)	grad_norm 1.5419 (2.0754)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:10:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:03:52 lr 0.000081	 wd 0.0000	time 0.1900 (0.2323)	loss 0.8037 (0.9182)	grad_norm 2.3121 (2.0747)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:10:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:27 lr 0.000081	 wd 0.0000	time 0.1859 (0.2296)	loss 1.0264 (0.9183)	grad_norm 1.6657 (2.0715)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:11:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:02 lr 0.000081	 wd 0.0000	time 0.1811 (0.2272)	loss 0.8340 (0.9187)	grad_norm 1.6050 (2.0776)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:11:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:37 lr 0.000081	 wd 0.0000	time 0.1762 (0.2249)	loss 0.8496 (0.9194)	grad_norm 4.3349 (2.0810)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:11:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:14 lr 0.000081	 wd 0.0000	time 0.1683 (0.2233)	loss 0.7827 (0.9186)	grad_norm 2.7623 (2.0810)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:12:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:52 lr 0.000080	 wd 0.0000	time 0.1774 (0.2234)	loss 0.9780 (0.9184)	grad_norm 1.8030 (2.0821)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:12:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:29 lr 0.000080	 wd 0.0000	time 0.1703 (0.2228)	loss 1.0518 (0.9186)	grad_norm 1.5637 (2.0831)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:12:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:06 lr 0.000080	 wd 0.0000	time 0.1810 (0.2212)	loss 0.9355 (0.9185)	grad_norm 2.4584 (2.0858)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:13:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:44 lr 0.000080	 wd 0.0000	time 0.2020 (0.2198)	loss 0.9585 (0.9180)	grad_norm 2.4306 (2.0856)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:13:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:22 lr 0.000080	 wd 0.0000	time 0.1982 (0.2187)	loss 0.9736 (0.9181)	grad_norm 3.7682 (2.0910)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:13:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000080	 wd 0.0000	time 0.1666 (0.2172)	loss 1.0684 (0.9182)	grad_norm 2.0672 (2.0884)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:14:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 8 training takes 0:09:12
[2024-07-25 23:14:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 23.805 (23.805)	Loss 0.3718 (0.3718)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-25 23:14:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.600 Acc@5 97.416
[2024-07-25 23:14:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-25 23:14:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.60%
[2024-07-25 23:14:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saving......
[2024-07-25 23:14:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-25 23:14:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][0/2502]	eta 10:56:12 lr 0.000080	 wd 0.0000	time 15.7363 (15.7363)	loss 0.8472 (0.8472)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:15:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:15:41 lr 0.000079	 wd 0.0000	time 0.3658 (0.3919)	loss 0.9004 (0.9093)	grad_norm 1.9980 (2.0210)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:15:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:13:03 lr 0.000079	 wd 0.0000	time 0.1788 (0.3406)	loss 0.8315 (0.9092)	grad_norm 3.0912 (2.0309)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:16:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:34 lr 0.000079	 wd 0.0000	time 0.1952 (0.2884)	loss 0.9443 (0.9155)	grad_norm 2.0536 (2.0313)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:16:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:11 lr 0.000079	 wd 0.0000	time 0.1843 (0.2623)	loss 0.8047 (0.9129)	grad_norm 1.9550 (2.0203)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:16:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:08:17 lr 0.000079	 wd 0.0000	time 0.2607 (0.2487)	loss 0.8071 (0.9117)	grad_norm 1.9035 (2.0058)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:17:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:34 lr 0.000079	 wd 0.0000	time 0.1961 (0.2704)	loss 0.8633 (0.9102)	grad_norm 1.7289 (2.0220)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:17:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:45 lr 0.000078	 wd 0.0000	time 0.1867 (0.2581)	loss 0.9619 (0.9108)	grad_norm 1.5631 (2.0236)	loss_scale 16384.0000 (8823.0528)	mem 8691MB
[2024-07-25 23:18:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:03 lr 0.000078	 wd 0.0000	time 0.1811 (0.2491)	loss 1.0303 (0.9115)	grad_norm 1.7425 (2.0193)	loss_scale 16384.0000 (9766.9913)	mem 8691MB
[2024-07-25 23:18:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:28 lr 0.000078	 wd 0.0000	time 0.2178 (0.2426)	loss 1.0283 (0.9125)	grad_norm 1.5076 (2.0291)	loss_scale 16384.0000 (10501.3984)	mem 8691MB
[2024-07-25 23:18:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:14 lr 0.000078	 wd 0.0000	time 0.1676 (0.2491)	loss 0.9336 (0.9129)	grad_norm 2.0671 (2.0339)	loss_scale 16384.0000 (11089.0709)	mem 8691MB
[2024-07-25 23:19:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:41 lr 0.000078	 wd 0.0000	time 0.1864 (0.2434)	loss 0.9478 (0.9122)	grad_norm 2.1746 (2.0435)	loss_scale 16384.0000 (11569.9909)	mem 8691MB
[2024-07-25 23:19:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:10 lr 0.000078	 wd 0.0000	time 0.1732 (0.2385)	loss 0.9434 (0.9133)	grad_norm 1.8240 (2.0340)	loss_scale 16384.0000 (11970.8243)	mem 8691MB
[2024-07-25 23:19:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:41 lr 0.000077	 wd 0.0000	time 0.1725 (0.2341)	loss 0.9058 (0.9135)	grad_norm 1.9602 (2.0299)	loss_scale 16384.0000 (12310.0384)	mem 8691MB
[2024-07-25 23:20:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:17 lr 0.000077	 wd 0.0000	time 0.3207 (0.2338)	loss 0.9697 (0.9135)	grad_norm 1.8112 (2.0208)	loss_scale 16384.0000 (12600.8280)	mem 8691MB
[2024-07-25 23:20:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:03:59 lr 0.000077	 wd 0.0000	time 0.1998 (0.2388)	loss 0.9380 (0.9145)	grad_norm 1.9731 (2.0204)	loss_scale 16384.0000 (12852.8714)	mem 8691MB
[2024-07-25 23:20:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:32 lr 0.000077	 wd 0.0000	time 0.1778 (0.2354)	loss 0.9043 (0.9131)	grad_norm 2.0029 (2.0201)	loss_scale 16384.0000 (13073.4291)	mem 8691MB
[2024-07-25 23:21:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:06 lr 0.000077	 wd 0.0000	time 0.1959 (0.2324)	loss 0.8799 (0.9128)	grad_norm 1.3605 (2.0197)	loss_scale 16384.0000 (13268.0541)	mem 8691MB
[2024-07-25 23:21:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:41 lr 0.000077	 wd 0.0000	time 0.1999 (0.2300)	loss 0.9224 (0.9129)	grad_norm 1.8363 (inf)	loss_scale 8192.0000 (13104.4708)	mem 8691MB
[2024-07-25 23:21:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:18 lr 0.000076	 wd 0.0000	time 0.1686 (0.2298)	loss 0.9380 (0.9131)	grad_norm 2.6378 (inf)	loss_scale 8192.0000 (12846.0558)	mem 8691MB
[2024-07-25 23:22:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:01:54 lr 0.000076	 wd 0.0000	time 0.1802 (0.2285)	loss 0.8765 (0.9138)	grad_norm 1.8774 (inf)	loss_scale 8192.0000 (12613.4693)	mem 8691MB
[2024-07-25 23:22:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:31 lr 0.000076	 wd 0.0000	time 0.1700 (0.2267)	loss 0.8843 (0.9138)	grad_norm 1.6947 (inf)	loss_scale 8192.0000 (12403.0233)	mem 8691MB
[2024-07-25 23:22:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:07 lr 0.000076	 wd 0.0000	time 0.1837 (0.2249)	loss 0.7236 (0.9135)	grad_norm 2.3413 (inf)	loss_scale 8192.0000 (12211.7001)	mem 8691MB
[2024-07-25 23:23:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:45 lr 0.000076	 wd 0.0000	time 0.1882 (0.2234)	loss 0.8613 (0.9134)	grad_norm 1.9879 (inf)	loss_scale 8192.0000 (12037.0065)	mem 8691MB
[2024-07-25 23:23:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:22 lr 0.000075	 wd 0.0000	time 0.1717 (0.2230)	loss 0.9565 (0.9135)	grad_norm 1.9991 (inf)	loss_scale 8192.0000 (11876.8646)	mem 8691MB
[2024-07-25 23:23:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000075	 wd 0.0000	time 0.1693 (0.2214)	loss 0.8779 (0.9140)	grad_norm 1.6047 (inf)	loss_scale 8192.0000 (11729.5290)	mem 8691MB
[2024-07-25 23:24:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 9 training takes 0:09:18
[2024-07-25 23:24:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 19.370 (19.370)	Loss 0.3674 (0.3674)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-25 23:24:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.630 Acc@5 97.422
[2024-07-25 23:24:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-25 23:24:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.63%
[2024-07-25 23:24:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saving......
[2024-07-25 23:24:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-25 23:24:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][0/2502]	eta 12:58:47 lr 0.000075	 wd 0.0000	time 18.6762 (18.6762)	loss 1.0410 (1.0410)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:25:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:18:26 lr 0.000075	 wd 0.0000	time 0.1785 (0.4607)	loss 1.0137 (0.9290)	grad_norm 2.3287 (2.0466)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:25:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:12:24 lr 0.000075	 wd 0.0000	time 0.1793 (0.3235)	loss 0.9263 (0.9214)	grad_norm 2.7500 (2.0706)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:25:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:09 lr 0.000075	 wd 0.0000	time 0.1727 (0.2768)	loss 0.9102 (0.9184)	grad_norm 2.1384 (2.0379)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:26:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:08:52 lr 0.000075	 wd 0.0000	time 0.1701 (0.2533)	loss 0.8867 (0.9176)	grad_norm 2.3027 (2.0760)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:26:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:08:17 lr 0.000074	 wd 0.0000	time 0.3354 (0.2485)	loss 0.8159 (0.9186)	grad_norm 1.8328 (2.0864)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:27:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:10 lr 0.000074	 wd 0.0000	time 0.1833 (0.2578)	loss 0.8706 (0.9182)	grad_norm 1.9137 (2.0817)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:27:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:26 lr 0.000074	 wd 0.0000	time 0.1826 (0.2477)	loss 0.8101 (0.9157)	grad_norm 1.9682 (2.0735)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:27:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:06:48 lr 0.000074	 wd 0.0000	time 0.1900 (0.2398)	loss 0.8931 (0.9166)	grad_norm 1.9371 (2.0716)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:28:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:16 lr 0.000074	 wd 0.0000	time 0.2391 (0.2348)	loss 0.8496 (0.9155)	grad_norm 1.6103 (2.0688)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:28:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:05:48 lr 0.000073	 wd 0.0000	time 0.1705 (0.2323)	loss 0.9985 (0.9144)	grad_norm 1.5688 (2.0741)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:28:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:19 lr 0.000073	 wd 0.0000	time 0.1817 (0.2282)	loss 0.9824 (0.9144)	grad_norm 2.4805 (2.0806)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:29:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:04:52 lr 0.000073	 wd 0.0000	time 0.1877 (0.2250)	loss 1.0156 (0.9138)	grad_norm 2.0357 (2.0713)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:29:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:26 lr 0.000073	 wd 0.0000	time 0.1748 (0.2219)	loss 0.8833 (0.9138)	grad_norm 1.8572 (2.0627)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:29:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:02 lr 0.000073	 wd 0.0000	time 0.1955 (0.2199)	loss 0.8779 (0.9141)	grad_norm 2.2013 (2.0684)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:30:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:03:48 lr 0.000073	 wd 0.0000	time 0.1679 (0.2284)	loss 0.9468 (0.9141)	grad_norm 2.1437 (2.0620)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:30:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:23 lr 0.000072	 wd 0.0000	time 0.1932 (0.2257)	loss 0.7251 (0.9135)	grad_norm 1.8244 (2.0731)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:30:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:02:59 lr 0.000072	 wd 0.0000	time 0.1732 (0.2233)	loss 0.8701 (0.9133)	grad_norm 2.8253 (2.0668)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:31:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:35 lr 0.000072	 wd 0.0000	time 0.1957 (0.2212)	loss 1.0107 (0.9132)	grad_norm 2.3309 (2.0681)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:31:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:12 lr 0.000072	 wd 0.0000	time 0.1857 (0.2199)	loss 0.9663 (0.9144)	grad_norm 1.5569 (2.0673)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:31:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:50 lr 0.000072	 wd 0.0000	time 0.2053 (0.2205)	loss 1.0801 (0.9148)	grad_norm 2.0801 (2.0693)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:32:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:28 lr 0.000071	 wd 0.0000	time 0.1800 (0.2191)	loss 0.9028 (0.9149)	grad_norm 2.2372 (2.0729)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:32:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:05 lr 0.000071	 wd 0.0000	time 0.1662 (0.2176)	loss 0.9126 (0.9151)	grad_norm 2.3283 (2.0673)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:32:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:43 lr 0.000071	 wd 0.0000	time 0.1812 (0.2164)	loss 0.9873 (0.9146)	grad_norm 2.1430 (2.0655)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:33:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:22 lr 0.000071	 wd 0.0000	time 0.1646 (0.2162)	loss 0.9863 (0.9149)	grad_norm 2.8411 (2.0618)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:33:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000071	 wd 0.0000	time 0.1684 (0.2149)	loss 0.7920 (0.9143)	grad_norm 1.6193 (2.0636)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:33:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 10 training takes 0:09:04
[2024-07-25 23:33:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 18.826 (18.826)	Loss 0.3726 (0.3726)	Acc@1 91.016 (91.016)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-25 23:34:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.738 Acc@5 97.434
[2024-07-25 23:34:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-25 23:34:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.74%
[2024-07-25 23:34:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saving......
[2024-07-25 23:34:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-25 23:34:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][0/2502]	eta 11:59:18 lr 0.000071	 wd 0.0000	time 17.2497 (17.2497)	loss 0.8872 (0.8872)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:34:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:19:17 lr 0.000070	 wd 0.0000	time 0.1690 (0.4820)	loss 0.8682 (0.9147)	grad_norm 2.5460 (2.0675)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:35:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:12:49 lr 0.000070	 wd 0.0000	time 0.1977 (0.3343)	loss 0.9204 (0.9142)	grad_norm 2.0961 (2.0562)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:35:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:10:26 lr 0.000070	 wd 0.0000	time 0.1865 (0.2844)	loss 0.9253 (0.9099)	grad_norm 2.2348 (2.0230)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:35:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:09:04 lr 0.000070	 wd 0.0000	time 0.1947 (0.2592)	loss 0.8799 (0.9073)	grad_norm 1.7774 (2.0150)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:36:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:08:17 lr 0.000070	 wd 0.0000	time 0.2440 (0.2486)	loss 0.9146 (0.9048)	grad_norm 1.8926 (2.0018)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:36:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:00 lr 0.000069	 wd 0.0000	time 0.1844 (0.2526)	loss 1.0000 (0.9060)	grad_norm 2.4422 (1.9968)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:36:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:07:18 lr 0.000069	 wd 0.0000	time 0.1645 (0.2432)	loss 0.8799 (0.9076)	grad_norm 2.7363 (1.9983)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:37:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:06:41 lr 0.000069	 wd 0.0000	time 0.1692 (0.2356)	loss 1.0361 (0.9078)	grad_norm 1.6227 (1.9992)	loss_scale 16384.0000 (8989.7228)	mem 8691MB
[2024-07-25 23:37:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:06:08 lr 0.000069	 wd 0.0000	time 0.1861 (0.2301)	loss 0.9131 (0.9109)	grad_norm 2.1273 (2.0030)	loss_scale 16384.0000 (9810.3973)	mem 8691MB
[2024-07-25 23:38:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:05:50 lr 0.000069	 wd 0.0000	time 0.1661 (0.2336)	loss 0.8862 (0.9110)	grad_norm 2.4676 (2.0105)	loss_scale 16384.0000 (10467.1009)	mem 8691MB
[2024-07-25 23:38:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:29 lr 0.000069	 wd 0.0000	time 0.1803 (0.2353)	loss 0.9351 (0.9105)	grad_norm 1.8509 (inf)	loss_scale 8192.0000 (10930.1072)	mem 8691MB
[2024-07-25 23:38:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:00 lr 0.000068	 wd 0.0000	time 0.1701 (0.2311)	loss 1.0068 (0.9105)	grad_norm 2.3082 (inf)	loss_scale 8192.0000 (10702.1216)	mem 8691MB
[2024-07-25 23:39:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:04:33 lr 0.000068	 wd 0.0000	time 0.1848 (0.2274)	loss 0.8818 (0.9112)	grad_norm 2.2164 (inf)	loss_scale 8192.0000 (10509.1837)	mem 8691MB
[2024-07-25 23:39:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:07 lr 0.000068	 wd 0.0000	time 0.1996 (0.2250)	loss 0.9062 (0.9113)	grad_norm 2.0733 (inf)	loss_scale 8192.0000 (10343.7887)	mem 8691MB
[2024-07-25 23:39:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:03:44 lr 0.000068	 wd 0.0000	time 0.1842 (0.2244)	loss 0.8237 (0.9105)	grad_norm 1.5603 (inf)	loss_scale 8192.0000 (10200.4317)	mem 8691MB
[2024-07-25 23:40:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:20 lr 0.000068	 wd 0.0000	time 0.1832 (0.2223)	loss 0.7700 (0.9105)	grad_norm 1.9326 (inf)	loss_scale 8192.0000 (10074.9831)	mem 8691MB
[2024-07-25 23:40:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:02:56 lr 0.000067	 wd 0.0000	time 0.1777 (0.2202)	loss 0.9521 (0.9097)	grad_norm 1.9624 (inf)	loss_scale 8192.0000 (9964.2845)	mem 8691MB
[2024-07-25 23:40:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:33 lr 0.000067	 wd 0.0000	time 0.2054 (0.2183)	loss 0.8804 (0.9103)	grad_norm 2.2198 (inf)	loss_scale 8192.0000 (9865.8790)	mem 8691MB
[2024-07-25 23:41:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:10 lr 0.000067	 wd 0.0000	time 0.2236 (0.2170)	loss 0.8418 (0.9107)	grad_norm 2.1568 (inf)	loss_scale 8192.0000 (9777.8264)	mem 8691MB
[2024-07-25 23:41:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:01:49 lr 0.000067	 wd 0.0000	time 0.3113 (0.2179)	loss 0.7031 (0.9106)	grad_norm 2.9439 (inf)	loss_scale 8192.0000 (9698.5747)	mem 8691MB
[2024-07-25 23:41:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:27 lr 0.000067	 wd 0.0000	time 0.2008 (0.2169)	loss 1.0273 (0.9103)	grad_norm 2.1770 (inf)	loss_scale 8192.0000 (9626.8672)	mem 8691MB
[2024-07-25 23:42:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:05 lr 0.000066	 wd 0.0000	time 0.1815 (0.2156)	loss 0.9639 (0.9105)	grad_norm 1.8184 (inf)	loss_scale 8192.0000 (9561.6756)	mem 8691MB
[2024-07-25 23:42:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:43 lr 0.000066	 wd 0.0000	time 0.1724 (0.2143)	loss 0.9521 (0.9105)	grad_norm 1.9996 (inf)	loss_scale 8192.0000 (9502.1504)	mem 8691MB
[2024-07-25 23:42:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:21 lr 0.000066	 wd 0.0000	time 0.1810 (0.2136)	loss 0.8560 (0.9102)	grad_norm 2.5800 (inf)	loss_scale 8192.0000 (9447.5835)	mem 8691MB
[2024-07-25 23:43:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000066	 wd 0.0000	time 0.1711 (0.2128)	loss 0.9673 (0.9100)	grad_norm 2.5973 (inf)	loss_scale 8192.0000 (9397.3802)	mem 8691MB
[2024-07-25 23:43:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 11 training takes 0:09:03
[2024-07-25 23:43:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 21.200 (21.200)	Loss 0.3638 (0.3638)	Acc@1 91.016 (91.016)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-25 23:43:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.678 Acc@5 97.422
[2024-07-25 23:43:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-25 23:43:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.74%
[2024-07-25 23:44:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][0/2502]	eta 11:41:45 lr 0.000066	 wd 0.0000	time 16.8289 (16.8289)	loss 0.8799 (0.8799)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:44:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:19:19 lr 0.000066	 wd 0.0000	time 0.1798 (0.4829)	loss 0.8560 (0.9062)	grad_norm 1.7969 (1.9695)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:44:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:12:48 lr 0.000065	 wd 0.0000	time 0.1791 (0.3340)	loss 0.8594 (0.9050)	grad_norm 1.5568 (1.9630)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:45:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:24 lr 0.000065	 wd 0.0000	time 0.1702 (0.2835)	loss 0.8105 (0.9134)	grad_norm 3.8784 (2.0288)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:45:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:02 lr 0.000065	 wd 0.0000	time 0.1739 (0.2583)	loss 0.8677 (0.9135)	grad_norm 1.7434 (2.0517)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:45:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:08:20 lr 0.000065	 wd 0.0000	time 0.3156 (0.2498)	loss 0.9150 (0.9151)	grad_norm 2.2204 (2.0374)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:46:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:08:14 lr 0.000065	 wd 0.0000	time 0.1705 (0.2599)	loss 0.9565 (0.9125)	grad_norm 1.7138 (2.0195)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:46:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:29 lr 0.000064	 wd 0.0000	time 0.1936 (0.2494)	loss 0.8794 (0.9133)	grad_norm 2.2370 (2.0183)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:47:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:06:50 lr 0.000064	 wd 0.0000	time 0.1726 (0.2412)	loss 1.1035 (0.9129)	grad_norm 1.7252 (2.0146)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:47:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:17 lr 0.000064	 wd 0.0000	time 0.2282 (0.2354)	loss 1.0400 (0.9124)	grad_norm 1.6302 (2.0181)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:47:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:02 lr 0.000064	 wd 0.0000	time 0.2015 (0.2416)	loss 0.8682 (0.9127)	grad_norm 2.1190 (2.0193)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:48:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:31 lr 0.000064	 wd 0.0000	time 0.1741 (0.2366)	loss 0.8467 (0.9138)	grad_norm 1.7626 (2.0188)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:48:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:02 lr 0.000063	 wd 0.0000	time 0.1828 (0.2323)	loss 0.9658 (0.9139)	grad_norm 2.1281 (2.0194)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:48:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:34 lr 0.000063	 wd 0.0000	time 0.1779 (0.2284)	loss 0.9189 (0.9137)	grad_norm 2.2394 (2.0387)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:49:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:12 lr 0.000063	 wd 0.0000	time 0.3785 (0.2294)	loss 1.1055 (0.9139)	grad_norm 2.4931 (2.0401)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:49:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:03:55 lr 0.000063	 wd 0.0000	time 0.1744 (0.2350)	loss 0.9385 (0.9142)	grad_norm 1.9570 (2.0457)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:50:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:29 lr 0.000063	 wd 0.0000	time 0.1873 (0.2319)	loss 0.9375 (0.9132)	grad_norm 2.1030 (2.0424)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:50:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:03 lr 0.000062	 wd 0.0000	time 0.1729 (0.2290)	loss 1.0176 (0.9130)	grad_norm 1.7674 (2.0397)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:50:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:39 lr 0.000062	 wd 0.0000	time 0.1774 (0.2269)	loss 0.7979 (0.9130)	grad_norm 2.1837 (2.0377)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:51:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:16 lr 0.000062	 wd 0.0000	time 0.1892 (0.2266)	loss 0.8560 (0.9132)	grad_norm 1.8240 (2.0370)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:51:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:01:53 lr 0.000062	 wd 0.0000	time 0.1715 (0.2254)	loss 0.8809 (0.9135)	grad_norm 2.0768 (2.0345)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:51:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:29 lr 0.000062	 wd 0.0000	time 0.1868 (0.2237)	loss 1.0117 (0.9140)	grad_norm 1.8841 (2.0346)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:51:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:07 lr 0.000061	 wd 0.0000	time 0.1920 (0.2221)	loss 1.0283 (0.9139)	grad_norm 2.0486 (2.0353)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:52:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:44 lr 0.000061	 wd 0.0000	time 0.1838 (0.2209)	loss 0.8306 (0.9136)	grad_norm 2.0238 (2.0374)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:52:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:22 lr 0.000061	 wd 0.0000	time 0.1677 (0.2209)	loss 0.8647 (0.9133)	grad_norm 1.9486 (2.0422)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:52:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000061	 wd 0.0000	time 0.1735 (0.2195)	loss 0.8457 (0.9133)	grad_norm 2.3027 (2.0441)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:53:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 12 training takes 0:09:17
[2024-07-25 23:53:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 18.652 (18.652)	Loss 0.3677 (0.3677)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-25 23:53:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.680 Acc@5 97.448
[2024-07-25 23:53:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-25 23:53:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.74%
[2024-07-25 23:54:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][0/2502]	eta 22:55:33 lr 0.000061	 wd 0.0000	time 32.9870 (32.9870)	loss 0.7646 (0.7646)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-25 23:54:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:20:39 lr 0.000061	 wd 0.0000	time 0.1747 (0.5159)	loss 0.8218 (0.9090)	grad_norm 1.8978 (2.0323)	loss_scale 16384.0000 (9327.5248)	mem 8691MB
[2024-07-25 23:54:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:13:26 lr 0.000060	 wd 0.0000	time 0.1767 (0.3503)	loss 0.7788 (0.9068)	grad_norm 2.3421 (2.0550)	loss_scale 16384.0000 (12838.2090)	mem 8691MB
[2024-07-25 23:55:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:10:48 lr 0.000060	 wd 0.0000	time 0.1796 (0.2944)	loss 0.8838 (0.9023)	grad_norm 1.7633 (2.0752)	loss_scale 16384.0000 (14016.2126)	mem 8691MB
[2024-07-25 23:55:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:09:44 lr 0.000060	 wd 0.0000	time 0.2864 (0.2779)	loss 0.9663 (0.9068)	grad_norm 1.6354 (inf)	loss_scale 8192.0000 (13299.2319)	mem 8691MB
[2024-07-25 23:56:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:09:34 lr 0.000060	 wd 0.0000	time 0.1759 (0.2870)	loss 0.8936 (0.9051)	grad_norm 2.1552 (inf)	loss_scale 8192.0000 (12279.8244)	mem 8691MB
[2024-07-25 23:56:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:33 lr 0.000060	 wd 0.0000	time 0.1771 (0.2702)	loss 0.9160 (0.9038)	grad_norm 2.0833 (inf)	loss_scale 8192.0000 (11599.6539)	mem 8691MB
[2024-07-25 23:56:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:07:45 lr 0.000059	 wd 0.0000	time 0.1692 (0.2585)	loss 0.8506 (0.9038)	grad_norm 2.0630 (inf)	loss_scale 8192.0000 (11113.5407)	mem 8691MB
[2024-07-25 23:57:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:05 lr 0.000059	 wd 0.0000	time 0.2709 (0.2502)	loss 0.9297 (0.9039)	grad_norm 1.7134 (inf)	loss_scale 8192.0000 (10748.8040)	mem 8691MB
[2024-07-25 23:57:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:07:01 lr 0.000059	 wd 0.0000	time 0.1847 (0.2631)	loss 0.8984 (0.9053)	grad_norm 2.5413 (inf)	loss_scale 8192.0000 (10465.0300)	mem 8691MB
[2024-07-25 23:58:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:23 lr 0.000059	 wd 0.0000	time 0.1755 (0.2555)	loss 0.9399 (0.9073)	grad_norm 1.6908 (inf)	loss_scale 8192.0000 (10237.9540)	mem 8691MB
[2024-07-25 23:58:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:49 lr 0.000059	 wd 0.0000	time 0.1835 (0.2496)	loss 0.9028 (0.9070)	grad_norm 1.4842 (inf)	loss_scale 8192.0000 (10052.1272)	mem 8691MB
[2024-07-25 23:58:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:18 lr 0.000058	 wd 0.0000	time 0.2552 (0.2444)	loss 1.0312 (0.9067)	grad_norm 1.6207 (inf)	loss_scale 8192.0000 (9897.2456)	mem 8691MB
[2024-07-25 23:58:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:04:51 lr 0.000058	 wd 0.0000	time 0.2208 (0.2422)	loss 0.9868 (0.9070)	grad_norm 1.7331 (inf)	loss_scale 8192.0000 (9766.1737)	mem 8691MB
[2024-07-25 23:59:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:23 lr 0.000058	 wd 0.0000	time 0.1825 (0.2395)	loss 0.9419 (0.9061)	grad_norm 2.2854 (inf)	loss_scale 8192.0000 (9653.8130)	mem 8691MB
[2024-07-25 23:59:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:03:56 lr 0.000058	 wd 0.0000	time 0.1777 (0.2361)	loss 0.8613 (0.9073)	grad_norm 1.6280 (inf)	loss_scale 8192.0000 (9556.4237)	mem 8691MB
[2024-07-25 23:59:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:30 lr 0.000058	 wd 0.0000	time 0.1720 (0.2330)	loss 0.7456 (0.9078)	grad_norm 1.5967 (inf)	loss_scale 8192.0000 (9471.2005)	mem 8691MB
[2024-07-26 00:00:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:04 lr 0.000057	 wd 0.0000	time 0.1771 (0.2305)	loss 0.8735 (0.9085)	grad_norm 2.8343 (inf)	loss_scale 8192.0000 (9395.9976)	mem 8691MB
[2024-07-26 00:00:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:41 lr 0.000057	 wd 0.0000	time 0.1694 (0.2303)	loss 0.9312 (0.9090)	grad_norm 1.8507 (inf)	loss_scale 8192.0000 (9329.1460)	mem 8691MB
[2024-07-26 00:00:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:17 lr 0.000057	 wd 0.0000	time 0.1861 (0.2285)	loss 0.7803 (0.9083)	grad_norm 2.0516 (inf)	loss_scale 8192.0000 (9269.3277)	mem 8691MB
[2024-07-26 00:01:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:53 lr 0.000057	 wd 0.0000	time 0.1722 (0.2266)	loss 0.9282 (0.9080)	grad_norm 2.4468 (inf)	loss_scale 8192.0000 (9215.4883)	mem 8691MB
[2024-07-26 00:01:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:30 lr 0.000057	 wd 0.0000	time 0.2027 (0.2247)	loss 0.9209 (0.9084)	grad_norm 2.3522 (inf)	loss_scale 8192.0000 (9166.7739)	mem 8691MB
[2024-07-26 00:01:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:07 lr 0.000056	 wd 0.0000	time 0.2072 (0.2233)	loss 0.8413 (0.9080)	grad_norm 2.4246 (inf)	loss_scale 8192.0000 (9122.4861)	mem 8691MB
[2024-07-26 00:02:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:45 lr 0.000056	 wd 0.0000	time 0.1915 (0.2228)	loss 0.9541 (0.9080)	grad_norm 1.5726 (inf)	loss_scale 8192.0000 (9082.0478)	mem 8691MB
[2024-07-26 00:02:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:22 lr 0.000056	 wd 0.0000	time 0.1751 (0.2217)	loss 0.8896 (0.9082)	grad_norm 2.0457 (inf)	loss_scale 8192.0000 (9044.9779)	mem 8691MB
[2024-07-26 00:02:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000056	 wd 0.0000	time 0.1679 (0.2200)	loss 0.8477 (0.9079)	grad_norm 1.8836 (inf)	loss_scale 8192.0000 (9010.8725)	mem 8691MB
[2024-07-26 00:03:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 13 training takes 0:09:19
[2024-07-26 00:03:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 23.896 (23.896)	Loss 0.3674 (0.3674)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-26 00:04:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.760 Acc@5 97.498
[2024-07-26 00:04:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-26 00:04:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.76%
[2024-07-26 00:04:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saving......
[2024-07-26 00:04:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-26 00:04:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][0/2502]	eta 12:28:11 lr 0.000056	 wd 0.0000	time 17.9423 (17.9423)	loss 0.8652 (0.8652)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:04:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:14:57 lr 0.000055	 wd 0.0000	time 0.1807 (0.3737)	loss 0.8965 (0.9104)	grad_norm 2.2670 (2.0933)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:04:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:10:43 lr 0.000055	 wd 0.0000	time 0.1884 (0.2796)	loss 0.9004 (0.9033)	grad_norm 1.9915 (2.0562)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:05:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:10:50 lr 0.000055	 wd 0.0000	time 0.2369 (0.2955)	loss 0.9536 (0.9058)	grad_norm 2.3918 (2.0509)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:05:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:09:43 lr 0.000055	 wd 0.0000	time 0.1689 (0.2775)	loss 1.1074 (0.9064)	grad_norm 1.4289 (2.0298)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:06:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:08:39 lr 0.000055	 wd 0.0000	time 0.1850 (0.2595)	loss 0.9214 (0.9053)	grad_norm 1.9140 (2.0175)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:06:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:07:49 lr 0.000054	 wd 0.0000	time 0.1784 (0.2467)	loss 0.8418 (0.9071)	grad_norm 1.4947 (2.0416)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:06:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:16 lr 0.000054	 wd 0.0000	time 0.2573 (0.2424)	loss 0.8091 (0.9089)	grad_norm 1.4103 (2.0275)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:07:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:02 lr 0.000054	 wd 0.0000	time 0.2087 (0.2481)	loss 0.9263 (0.9068)	grad_norm 1.9092 (2.0211)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:07:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:26 lr 0.000054	 wd 0.0000	time 0.1714 (0.2412)	loss 0.9990 (0.9063)	grad_norm 1.4940 (2.0136)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:07:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:05:53 lr 0.000054	 wd 0.0000	time 0.1772 (0.2356)	loss 1.0156 (0.9060)	grad_norm 1.5401 (2.0105)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:08:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:24 lr 0.000053	 wd 0.0000	time 0.2305 (0.2316)	loss 0.7939 (0.9065)	grad_norm 2.2908 (2.0123)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:08:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:13 lr 0.000053	 wd 0.0000	time 0.1910 (0.2408)	loss 0.9634 (0.9071)	grad_norm 2.1440 (2.0094)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:09:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:04:44 lr 0.000053	 wd 0.0000	time 0.1827 (0.2366)	loss 0.9600 (0.9068)	grad_norm 1.7240 (2.0070)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:09:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:16 lr 0.000053	 wd 0.0000	time 0.1885 (0.2329)	loss 0.8696 (0.9062)	grad_norm 2.7735 (2.0098)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:09:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:03:49 lr 0.000053	 wd 0.0000	time 0.1954 (0.2295)	loss 0.9780 (0.9059)	grad_norm 1.8156 (2.0127)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:10:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:25 lr 0.000052	 wd 0.0000	time 0.1917 (0.2275)	loss 0.9478 (0.9063)	grad_norm 1.7327 (2.0157)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:10:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:02 lr 0.000052	 wd 0.0000	time 0.1795 (0.2275)	loss 1.0371 (0.9064)	grad_norm 2.1037 (2.0161)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:10:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:38 lr 0.000052	 wd 0.0000	time 0.2081 (0.2255)	loss 0.9937 (0.9064)	grad_norm 1.9921 (2.0210)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:11:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:14 lr 0.000052	 wd 0.0000	time 0.1733 (0.2235)	loss 0.9106 (0.9064)	grad_norm 1.6976 (2.0220)	loss_scale 16384.0000 (8476.4145)	mem 8691MB
[2024-07-26 00:11:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:01:51 lr 0.000052	 wd 0.0000	time 0.1815 (0.2216)	loss 0.9629 (0.9066)	grad_norm 1.9740 (2.0304)	loss_scale 16384.0000 (8871.5962)	mem 8691MB
[2024-07-26 00:11:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:28 lr 0.000051	 wd 0.0000	time 0.1742 (0.2207)	loss 0.9277 (0.9073)	grad_norm 2.0164 (2.0297)	loss_scale 16384.0000 (9229.1594)	mem 8691MB
[2024-07-26 00:12:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:06 lr 0.000051	 wd 0.0000	time 0.1762 (0.2210)	loss 0.8291 (0.9080)	grad_norm 1.5745 (2.0281)	loss_scale 16384.0000 (9554.2317)	mem 8691MB
[2024-07-26 00:12:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:44 lr 0.000051	 wd 0.0000	time 0.2070 (0.2197)	loss 0.9722 (0.9082)	grad_norm 2.4008 (2.0235)	loss_scale 16384.0000 (9851.0491)	mem 8691MB
[2024-07-26 00:12:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:22 lr 0.000051	 wd 0.0000	time 0.1715 (0.2184)	loss 0.9199 (0.9084)	grad_norm 1.7009 (2.0223)	loss_scale 16384.0000 (10123.1420)	mem 8691MB
[2024-07-26 00:13:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000051	 wd 0.0000	time 0.1700 (0.2168)	loss 0.8647 (0.9084)	grad_norm 1.7181 (2.0239)	loss_scale 16384.0000 (10373.4762)	mem 8691MB
[2024-07-26 00:13:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 14 training takes 0:09:09
[2024-07-26 00:13:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 37.812 (37.812)	Loss 0.3647 (0.3647)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-26 00:14:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.838 Acc@5 97.476
[2024-07-26 00:14:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-26 00:14:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.84%
[2024-07-26 00:14:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saving......
[2024-07-26 00:14:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-26 00:14:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][0/2502]	eta 10:12:42 lr 0.000051	 wd 0.0000	time 14.6934 (14.6934)	loss 0.7827 (0.7827)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 00:14:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:13:49 lr 0.000050	 wd 0.0000	time 0.2511 (0.3455)	loss 0.9028 (0.9073)	grad_norm 1.7889 (2.0062)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 00:15:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:13:20 lr 0.000050	 wd 0.0000	time 0.1756 (0.3476)	loss 1.1260 (0.9087)	grad_norm 1.7607 (2.0494)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 00:15:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:10:47 lr 0.000050	 wd 0.0000	time 0.1823 (0.2940)	loss 0.8496 (0.9092)	grad_norm 1.9664 (2.0589)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 00:15:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:09:20 lr 0.000050	 wd 0.0000	time 0.1820 (0.2665)	loss 0.7290 (0.9093)	grad_norm 1.7259 (2.0424)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 00:16:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:08:19 lr 0.000049	 wd 0.0000	time 0.1889 (0.2496)	loss 0.8662 (0.9094)	grad_norm 2.0154 (2.0397)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 00:16:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:08:20 lr 0.000049	 wd 0.0000	time 0.7662 (0.2629)	loss 0.8291 (0.9091)	grad_norm 1.6533 (2.0381)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 00:17:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:47 lr 0.000049	 wd 0.0000	time 0.2077 (0.2597)	loss 0.9233 (0.9084)	grad_norm 1.5865 (2.0381)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 00:17:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:07:06 lr 0.000049	 wd 0.0000	time 0.1744 (0.2505)	loss 0.8994 (0.9080)	grad_norm 1.9068 (2.0308)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 00:17:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:29 lr 0.000049	 wd 0.0000	time 0.1920 (0.2430)	loss 0.8799 (0.9081)	grad_norm 1.8487 (2.0258)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 00:18:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:05:58 lr 0.000048	 wd 0.0000	time 0.2384 (0.2389)	loss 0.8501 (0.9084)	grad_norm 2.2804 (2.0326)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 00:18:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:31 lr 0.000048	 wd 0.0000	time 0.1870 (0.2363)	loss 0.9634 (0.9067)	grad_norm 2.1202 (2.0255)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 00:18:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:02 lr 0.000048	 wd 0.0000	time 0.1919 (0.2323)	loss 0.7588 (0.9067)	grad_norm 1.9120 (2.0283)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 00:19:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:04:35 lr 0.000048	 wd 0.0000	time 0.1827 (0.2290)	loss 0.9448 (0.9071)	grad_norm 1.9305 (2.0367)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 00:19:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:08 lr 0.000048	 wd 0.0000	time 0.1729 (0.2259)	loss 0.8853 (0.9069)	grad_norm 1.6169 (inf)	loss_scale 8192.0000 (16231.9714)	mem 8691MB
[2024-07-26 00:19:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:03:47 lr 0.000047	 wd 0.0000	time 0.4107 (0.2274)	loss 0.8760 (0.9063)	grad_norm 2.1507 (inf)	loss_scale 8192.0000 (15696.3304)	mem 8691MB
[2024-07-26 00:20:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:28 lr 0.000047	 wd 0.0000	time 0.1702 (0.2308)	loss 0.9229 (0.9061)	grad_norm 2.3741 (inf)	loss_scale 8192.0000 (15227.6027)	mem 8691MB
[2024-07-26 00:20:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:02 lr 0.000047	 wd 0.0000	time 0.1825 (0.2281)	loss 0.9077 (0.9057)	grad_norm 1.6139 (inf)	loss_scale 8192.0000 (14813.9871)	mem 8691MB
[2024-07-26 00:20:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:38 lr 0.000047	 wd 0.0000	time 0.1651 (0.2257)	loss 0.9902 (0.9068)	grad_norm 2.4061 (inf)	loss_scale 8192.0000 (14446.3032)	mem 8691MB
[2024-07-26 00:21:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:14 lr 0.000047	 wd 0.0000	time 0.1851 (0.2239)	loss 1.0176 (0.9068)	grad_norm 1.9958 (inf)	loss_scale 8192.0000 (14117.3025)	mem 8691MB
[2024-07-26 00:21:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:01:52 lr 0.000046	 wd 0.0000	time 0.1784 (0.2241)	loss 1.0254 (0.9068)	grad_norm 2.4391 (inf)	loss_scale 8192.0000 (13821.1854)	mem 8691MB
[2024-07-26 00:21:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:29 lr 0.000046	 wd 0.0000	time 0.1718 (0.2228)	loss 0.9746 (0.9065)	grad_norm 1.6628 (inf)	loss_scale 8192.0000 (13553.2565)	mem 8691MB
[2024-07-26 00:22:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:06 lr 0.000046	 wd 0.0000	time 0.1671 (0.2213)	loss 0.8706 (0.9068)	grad_norm 2.1845 (inf)	loss_scale 8192.0000 (13309.6738)	mem 8691MB
[2024-07-26 00:22:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:44 lr 0.000046	 wd 0.0000	time 0.1853 (0.2198)	loss 1.0430 (0.9065)	grad_norm 2.7178 (inf)	loss_scale 8192.0000 (13087.2629)	mem 8691MB
[2024-07-26 00:22:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:22 lr 0.000046	 wd 0.0000	time 0.1744 (0.2189)	loss 0.8770 (0.9063)	grad_norm 1.9256 (inf)	loss_scale 8192.0000 (12883.3786)	mem 8691MB
[2024-07-26 00:23:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000045	 wd 0.0000	time 0.1704 (0.2175)	loss 1.1025 (0.9067)	grad_norm 1.7719 (inf)	loss_scale 8192.0000 (12695.7985)	mem 8691MB
[2024-07-26 00:23:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 15 training takes 0:09:19
[2024-07-26 00:23:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_15.pth saving......
[2024-07-26 00:23:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_15.pth saved !!!
[2024-07-26 00:23:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 19.847 (19.847)	Loss 0.3645 (0.3645)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-26 00:24:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.798 Acc@5 97.478
[2024-07-26 00:24:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-26 00:24:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.84%
[2024-07-26 00:24:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][0/2502]	eta 14:11:59 lr 0.000045	 wd 0.0000	time 20.4315 (20.4315)	loss 0.8198 (0.8198)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:24:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:17:27 lr 0.000045	 wd 0.0000	time 0.2306 (0.4362)	loss 1.1016 (0.9180)	grad_norm 1.7753 (2.0312)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:25:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:11:55 lr 0.000045	 wd 0.0000	time 0.1791 (0.3109)	loss 0.9502 (0.9152)	grad_norm 2.1902 (2.0471)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:25:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:09:53 lr 0.000045	 wd 0.0000	time 0.1699 (0.2695)	loss 0.8999 (0.9143)	grad_norm 1.5308 (2.0333)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:25:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:08:41 lr 0.000045	 wd 0.0000	time 0.1820 (0.2482)	loss 0.9727 (0.9116)	grad_norm 1.7569 (2.0475)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:26:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:07:55 lr 0.000044	 wd 0.0000	time 0.2761 (0.2376)	loss 0.8726 (0.9096)	grad_norm 2.0975 (2.0805)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:26:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:02 lr 0.000044	 wd 0.0000	time 0.1851 (0.2538)	loss 0.9795 (0.9109)	grad_norm 2.0451 (2.0962)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:27:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:20 lr 0.000044	 wd 0.0000	time 0.1713 (0.2444)	loss 0.9434 (0.9099)	grad_norm 1.9566 (2.0969)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:27:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:06:43 lr 0.000044	 wd 0.0000	time 0.1784 (0.2371)	loss 1.0459 (0.9089)	grad_norm 2.1682 (2.0881)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:27:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:11 lr 0.000043	 wd 0.0000	time 0.1869 (0.2317)	loss 0.8491 (0.9104)	grad_norm 4.1414 (2.0921)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:28:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:06:02 lr 0.000043	 wd 0.0000	time 0.1948 (0.2412)	loss 0.9272 (0.9119)	grad_norm 1.9800 (2.0851)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:28:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:31 lr 0.000043	 wd 0.0000	time 0.1905 (0.2365)	loss 0.8228 (0.9106)	grad_norm 2.1305 (2.0896)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:28:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:02 lr 0.000043	 wd 0.0000	time 0.1712 (0.2322)	loss 1.0146 (0.9113)	grad_norm 1.7819 (2.0886)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:29:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:04:34 lr 0.000043	 wd 0.0000	time 0.1916 (0.2283)	loss 0.8896 (0.9097)	grad_norm 1.6861 (2.0846)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:29:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:09 lr 0.000042	 wd 0.0000	time 0.1781 (0.2261)	loss 0.8638 (0.9087)	grad_norm 1.9560 (2.0764)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:29:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:03:50 lr 0.000042	 wd 0.0000	time 0.1895 (0.2300)	loss 0.9419 (0.9084)	grad_norm 1.6348 (2.0764)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:30:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:24 lr 0.000042	 wd 0.0000	time 0.1772 (0.2271)	loss 0.8862 (0.9084)	grad_norm 1.9144 (2.0744)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:30:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:00 lr 0.000042	 wd 0.0000	time 0.1846 (0.2247)	loss 0.7891 (0.9088)	grad_norm 1.8891 (2.0710)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:30:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:36 lr 0.000042	 wd 0.0000	time 0.1895 (0.2226)	loss 0.9712 (0.9091)	grad_norm 1.7823 (2.0621)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:31:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:13 lr 0.000041	 wd 0.0000	time 0.1909 (0.2214)	loss 0.9961 (0.9092)	grad_norm 2.1750 (2.0556)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:31:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:01:51 lr 0.000041	 wd 0.0000	time 0.1879 (0.2217)	loss 0.8403 (0.9086)	grad_norm 1.5891 (2.0578)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:31:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:28 lr 0.000041	 wd 0.0000	time 0.1834 (0.2201)	loss 0.8232 (0.9082)	grad_norm 1.6068 (2.0538)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:32:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:06 lr 0.000041	 wd 0.0000	time 0.1829 (0.2186)	loss 0.8228 (0.9084)	grad_norm 1.6223 (2.0545)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:32:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:43 lr 0.000041	 wd 0.0000	time 0.1906 (0.2174)	loss 0.9536 (0.9082)	grad_norm 2.4404 (2.0563)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:32:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:22 lr 0.000040	 wd 0.0000	time 0.1862 (0.2173)	loss 0.7783 (0.9078)	grad_norm 1.6703 (2.0545)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:33:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1695 (0.2158)	loss 0.8872 (0.9075)	grad_norm 2.0724 (2.0569)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:33:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 16 training takes 0:09:09
[2024-07-26 00:33:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 22.485 (22.485)	Loss 0.3623 (0.3623)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-26 00:34:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.808 Acc@5 97.512
[2024-07-26 00:34:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-26 00:34:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.84%
[2024-07-26 00:34:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][0/2502]	eta 22:52:59 lr 0.000040	 wd 0.0000	time 32.9257 (32.9257)	loss 0.8398 (0.8398)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:34:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:20:54 lr 0.000040	 wd 0.0000	time 0.1907 (0.5222)	loss 0.9893 (0.9044)	grad_norm 1.5413 (2.0935)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:35:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:13:36 lr 0.000040	 wd 0.0000	time 0.1931 (0.3546)	loss 1.0625 (0.9119)	grad_norm 1.4901 (2.0751)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:35:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:55 lr 0.000040	 wd 0.0000	time 0.1757 (0.2977)	loss 0.9263 (0.9114)	grad_norm 1.7419 (2.0750)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 00:35:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:09:47 lr 0.000039	 wd 0.0000	time 0.3393 (0.2796)	loss 0.8784 (0.9045)	grad_norm 2.0209 (2.0840)	loss_scale 16384.0000 (8804.8678)	mem 8691MB
[2024-07-26 00:36:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:10:03 lr 0.000039	 wd 0.0000	time 0.1721 (0.3017)	loss 0.8179 (0.9063)	grad_norm 1.9526 (2.0812)	loss_scale 16384.0000 (10317.6687)	mem 8691MB
[2024-07-26 00:36:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:57 lr 0.000039	 wd 0.0000	time 0.1763 (0.2825)	loss 0.9536 (0.9080)	grad_norm 2.1057 (2.0964)	loss_scale 16384.0000 (11327.0416)	mem 8691MB
[2024-07-26 00:37:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:08:03 lr 0.000039	 wd 0.0000	time 0.1874 (0.2685)	loss 0.7974 (0.9066)	grad_norm 1.7743 (2.0893)	loss_scale 16384.0000 (12048.4337)	mem 8691MB
[2024-07-26 00:37:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:07:22 lr 0.000039	 wd 0.0000	time 0.2898 (0.2602)	loss 0.8179 (0.9064)	grad_norm 2.0425 (2.0894)	loss_scale 16384.0000 (12589.7029)	mem 8691MB
[2024-07-26 00:38:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:07:06 lr 0.000038	 wd 0.0000	time 0.1863 (0.2665)	loss 0.8545 (0.9066)	grad_norm 2.1319 (2.0842)	loss_scale 16384.0000 (13010.8235)	mem 8691MB
[2024-07-26 00:38:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:27 lr 0.000038	 wd 0.0000	time 0.1993 (0.2583)	loss 0.9561 (0.9059)	grad_norm 1.9046 (inf)	loss_scale 8192.0000 (12889.5105)	mem 8691MB
[2024-07-26 00:38:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:52 lr 0.000038	 wd 0.0000	time 0.1691 (0.2515)	loss 0.9438 (0.9075)	grad_norm 1.6417 (inf)	loss_scale 8192.0000 (12462.8520)	mem 8691MB
[2024-07-26 00:38:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:20 lr 0.000038	 wd 0.0000	time 0.2270 (0.2461)	loss 0.9282 (0.9082)	grad_norm 1.8365 (inf)	loss_scale 8192.0000 (12107.2440)	mem 8691MB
[2024-07-26 00:39:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:05:04 lr 0.000038	 wd 0.0000	time 0.2076 (0.2529)	loss 1.0176 (0.9066)	grad_norm 1.9912 (inf)	loss_scale 8192.0000 (11806.3028)	mem 8691MB
[2024-07-26 00:39:47 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:33 lr 0.000037	 wd 0.0000	time 0.1708 (0.2482)	loss 0.8369 (0.9072)	grad_norm 1.5805 (inf)	loss_scale 8192.0000 (11548.3226)	mem 8691MB
[2024-07-26 00:40:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:04:04 lr 0.000037	 wd 0.0000	time 0.1779 (0.2438)	loss 0.8833 (0.9074)	grad_norm 1.9150 (inf)	loss_scale 8192.0000 (11324.7169)	mem 8691MB
[2024-07-26 00:40:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:36 lr 0.000037	 wd 0.0000	time 0.1742 (0.2400)	loss 0.8174 (0.9070)	grad_norm 2.2688 (inf)	loss_scale 8192.0000 (11129.0443)	mem 8691MB
[2024-07-26 00:40:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:10 lr 0.000037	 wd 0.0000	time 0.1808 (0.2377)	loss 1.1729 (0.9072)	grad_norm 2.2887 (inf)	loss_scale 8192.0000 (10956.3786)	mem 8691MB
[2024-07-26 00:41:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:46 lr 0.000037	 wd 0.0000	time 0.1716 (0.2369)	loss 0.8730 (0.9076)	grad_norm 1.5771 (inf)	loss_scale 8192.0000 (10802.8873)	mem 8691MB
[2024-07-26 00:41:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:21 lr 0.000036	 wd 0.0000	time 0.2007 (0.2347)	loss 0.8296 (0.9077)	grad_norm 2.7165 (inf)	loss_scale 8192.0000 (10665.5445)	mem 8691MB
[2024-07-26 00:41:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:01:56 lr 0.000036	 wd 0.0000	time 0.1732 (0.2324)	loss 0.8965 (0.9072)	grad_norm 2.7348 (inf)	loss_scale 4096.0000 (10521.4593)	mem 8691MB
[2024-07-26 00:42:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:32 lr 0.000036	 wd 0.0000	time 0.1875 (0.2302)	loss 0.9258 (0.9072)	grad_norm 2.5732 (inf)	loss_scale 4096.0000 (10215.6307)	mem 8691MB
[2024-07-26 00:42:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:09 lr 0.000036	 wd 0.0000	time 0.1794 (0.2287)	loss 0.9521 (0.9073)	grad_norm 2.4907 (inf)	loss_scale 4096.0000 (9937.5920)	mem 8691MB
[2024-07-26 00:42:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:46 lr 0.000036	 wd 0.0000	time 0.1934 (0.2281)	loss 0.9043 (0.9070)	grad_norm 2.2740 (inf)	loss_scale 4096.0000 (9683.7201)	mem 8691MB
[2024-07-26 00:43:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:23 lr 0.000035	 wd 0.0000	time 0.2097 (0.2265)	loss 0.8154 (0.9078)	grad_norm 2.0388 (inf)	loss_scale 4096.0000 (9450.9954)	mem 8691MB
[2024-07-26 00:43:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1693 (0.2246)	loss 1.0723 (0.9082)	grad_norm 2.2127 (inf)	loss_scale 4096.0000 (9236.8812)	mem 8691MB
[2024-07-26 00:43:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 17 training takes 0:09:29
[2024-07-26 00:44:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 43.816 (43.816)	Loss 0.3677 (0.3677)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-26 00:44:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.790 Acc@5 97.476
[2024-07-26 00:44:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-26 00:44:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.84%
[2024-07-26 00:44:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][0/2502]	eta 11:38:31 lr 0.000035	 wd 0.0000	time 16.7513 (16.7513)	loss 0.9238 (0.9238)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:45:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:13:58 lr 0.000035	 wd 0.0000	time 0.1695 (0.3493)	loss 0.8984 (0.8972)	grad_norm 1.9326 (2.2494)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:45:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:10:38 lr 0.000035	 wd 0.0000	time 0.2681 (0.2774)	loss 1.0215 (0.8978)	grad_norm 1.7418 (2.1343)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:46:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:11:12 lr 0.000035	 wd 0.0000	time 0.1765 (0.3053)	loss 0.9658 (0.9030)	grad_norm 1.7501 (2.1154)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:46:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:09:38 lr 0.000034	 wd 0.0000	time 0.1707 (0.2750)	loss 0.9331 (0.9065)	grad_norm 2.0735 (2.1262)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:46:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:08:34 lr 0.000034	 wd 0.0000	time 0.1810 (0.2568)	loss 0.8438 (0.9069)	grad_norm 2.2161 (2.1213)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:47:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:07:46 lr 0.000034	 wd 0.0000	time 0.1943 (0.2454)	loss 0.8188 (0.9050)	grad_norm 2.3027 (2.1276)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:47:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:07:40 lr 0.000034	 wd 0.0000	time 0.2016 (0.2558)	loss 1.0850 (0.9046)	grad_norm 1.9803 (2.1167)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:47:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:00 lr 0.000034	 wd 0.0000	time 0.1801 (0.2472)	loss 0.9780 (0.9026)	grad_norm 2.7559 (2.1143)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:48:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:06:24 lr 0.000033	 wd 0.0000	time 0.1704 (0.2403)	loss 0.9272 (0.9025)	grad_norm 2.5310 (2.1062)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:48:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:05:51 lr 0.000033	 wd 0.0000	time 0.1770 (0.2343)	loss 0.8101 (0.9021)	grad_norm 2.0088 (2.1068)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:48:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:29 lr 0.000033	 wd 0.0000	time 0.3723 (0.2352)	loss 0.9136 (0.9034)	grad_norm 1.7231 (2.1042)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:49:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:16 lr 0.000033	 wd 0.0000	time 0.1887 (0.2431)	loss 1.1895 (0.9029)	grad_norm 1.9414 (2.0974)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:49:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:04:46 lr 0.000033	 wd 0.0000	time 0.1841 (0.2386)	loss 0.8374 (0.9039)	grad_norm 1.9410 (2.0860)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:50:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:18 lr 0.000032	 wd 0.0000	time 0.1703 (0.2348)	loss 0.8843 (0.9033)	grad_norm 2.2619 (2.0804)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:50:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:03:52 lr 0.000032	 wd 0.0000	time 0.3021 (0.2325)	loss 0.8633 (0.9037)	grad_norm 2.2133 (2.0790)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:50:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:35 lr 0.000032	 wd 0.0000	time 0.1813 (0.2387)	loss 0.8901 (0.9036)	grad_norm 2.6419 (2.0748)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:51:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:08 lr 0.000032	 wd 0.0000	time 0.1856 (0.2355)	loss 1.0430 (0.9037)	grad_norm 2.2575 (2.0791)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:51:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:43 lr 0.000032	 wd 0.0000	time 0.1716 (0.2326)	loss 0.9663 (0.9040)	grad_norm 1.8190 (2.0773)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:51:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:18 lr 0.000032	 wd 0.0000	time 0.2197 (0.2304)	loss 1.0889 (0.9042)	grad_norm 1.9798 (2.0757)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:52:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:01:55 lr 0.000031	 wd 0.0000	time 0.1733 (0.2302)	loss 1.0469 (0.9050)	grad_norm 1.9127 (2.0729)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:52:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:31 lr 0.000031	 wd 0.0000	time 0.1832 (0.2288)	loss 0.7798 (0.9049)	grad_norm 2.2395 (2.0792)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:52:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:08 lr 0.000031	 wd 0.0000	time 0.1797 (0.2269)	loss 0.8359 (0.9054)	grad_norm 1.6484 (2.0782)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:53:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:45 lr 0.000031	 wd 0.0000	time 0.1684 (0.2252)	loss 0.8091 (0.9057)	grad_norm 2.6906 (2.0792)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:53:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:22 lr 0.000031	 wd 0.0000	time 0.2072 (0.2238)	loss 0.9277 (0.9055)	grad_norm 1.7214 (2.0808)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:53:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000030	 wd 0.0000	time 0.1707 (0.2222)	loss 0.8877 (0.9058)	grad_norm 1.8898 (2.0828)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:54:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 18 training takes 0:09:28
[2024-07-26 00:54:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 26.311 (26.311)	Loss 0.3669 (0.3669)	Acc@1 91.211 (91.211)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-26 00:54:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.778 Acc@5 97.482
[2024-07-26 00:54:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-26 00:54:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.84%
[2024-07-26 00:55:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][0/2502]	eta 13:27:38 lr 0.000030	 wd 0.0000	time 19.3681 (19.3681)	loss 0.8066 (0.8066)	grad_norm 0.0000 (0.0000)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:55:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:17:34 lr 0.000030	 wd 0.0000	time 0.1690 (0.4392)	loss 1.0850 (0.9145)	grad_norm 1.5643 (2.0513)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:55:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:12:04 lr 0.000030	 wd 0.0000	time 0.1886 (0.3147)	loss 0.8003 (0.9125)	grad_norm 2.3165 (2.0260)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:56:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:09:57 lr 0.000030	 wd 0.0000	time 0.1761 (0.2713)	loss 0.8525 (0.9106)	grad_norm 1.5892 (2.0393)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:56:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:08:44 lr 0.000030	 wd 0.0000	time 0.1700 (0.2494)	loss 0.9790 (0.9090)	grad_norm 1.8838 (2.0476)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:56:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:07:56 lr 0.000029	 wd 0.0000	time 0.2115 (0.2379)	loss 0.9326 (0.9076)	grad_norm 2.1205 (2.0681)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:57:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:12 lr 0.000029	 wd 0.0000	time 0.1913 (0.2590)	loss 0.8755 (0.9074)	grad_norm 1.6582 (2.0792)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:57:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:07:28 lr 0.000029	 wd 0.0000	time 0.1956 (0.2488)	loss 0.9570 (0.9077)	grad_norm 2.1285 (2.0688)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:57:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:06:49 lr 0.000029	 wd 0.0000	time 0.1714 (0.2409)	loss 0.8086 (0.9069)	grad_norm 1.9393 (2.0584)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:58:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:06:16 lr 0.000029	 wd 0.0000	time 0.1946 (0.2348)	loss 0.8267 (0.9056)	grad_norm 2.2886 (2.0467)	loss_scale 4096.0000 (4096.0000)	mem 8691MB
[2024-07-26 00:58:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:09 lr 0.000028	 wd 0.0000	time 0.2328 (0.2457)	loss 0.8193 (0.9056)	grad_norm 2.1600 (2.0572)	loss_scale 8192.0000 (4153.2867)	mem 8691MB
[2024-07-26 00:59:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:38 lr 0.000028	 wd 0.0000	time 0.1729 (0.2412)	loss 0.9438 (0.9061)	grad_norm 1.8607 (2.0696)	loss_scale 8192.0000 (4520.1090)	mem 8691MB
[2024-07-26 00:59:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:07 lr 0.000028	 wd 0.0000	time 0.1878 (0.2364)	loss 0.9062 (0.9066)	grad_norm 2.0132 (2.0709)	loss_scale 8192.0000 (4825.8451)	mem 8691MB
[2024-07-26 00:59:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:04:39 lr 0.000028	 wd 0.0000	time 0.1767 (0.2323)	loss 0.7476 (0.9068)	grad_norm 1.8272 (2.0640)	loss_scale 8192.0000 (5084.5811)	mem 8691MB
[2024-07-26 01:00:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:17 lr 0.000028	 wd 0.0000	time 0.4108 (0.2340)	loss 0.8452 (0.9073)	grad_norm 2.0308 (2.0661)	loss_scale 8192.0000 (5306.3812)	mem 8691MB
[2024-07-26 01:00:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:03:57 lr 0.000028	 wd 0.0000	time 0.1676 (0.2375)	loss 0.9507 (0.9078)	grad_norm 2.5575 (2.0623)	loss_scale 8192.0000 (5498.6276)	mem 8691MB
[2024-07-26 01:01:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:31 lr 0.000027	 wd 0.0000	time 0.1989 (0.2343)	loss 0.8647 (0.9076)	grad_norm 1.7305 (2.0619)	loss_scale 8192.0000 (5666.8582)	mem 8691MB
[2024-07-26 01:01:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:05 lr 0.000027	 wd 0.0000	time 0.1668 (0.2314)	loss 0.8213 (0.9073)	grad_norm 1.8903 (2.0564)	loss_scale 8192.0000 (5815.3086)	mem 8691MB
[2024-07-26 01:01:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:41 lr 0.000027	 wd 0.0000	time 0.2153 (0.2295)	loss 0.7656 (0.9077)	grad_norm 1.9119 (2.0591)	loss_scale 8192.0000 (5947.2737)	mem 8691MB
[2024-07-26 01:02:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:18 lr 0.000027	 wd 0.0000	time 0.2619 (0.2293)	loss 0.8979 (0.9073)	grad_norm 2.6583 (2.0593)	loss_scale 8192.0000 (6065.3551)	mem 8691MB
[2024-07-26 01:02:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:54 lr 0.000027	 wd 0.0000	time 0.1800 (0.2277)	loss 0.9888 (0.9066)	grad_norm 2.4787 (2.0576)	loss_scale 8192.0000 (6171.6342)	mem 8691MB
[2024-07-26 01:02:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:30 lr 0.000026	 wd 0.0000	time 0.1903 (0.2259)	loss 1.0537 (0.9061)	grad_norm 1.6053 (2.0586)	loss_scale 8192.0000 (6267.7963)	mem 8691MB
[2024-07-26 01:02:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:07 lr 0.000026	 wd 0.0000	time 0.1879 (0.2241)	loss 0.8926 (0.9057)	grad_norm 2.6144 (2.0564)	loss_scale 8192.0000 (6355.2204)	mem 8691MB
[2024-07-26 01:03:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:45 lr 0.000026	 wd 0.0000	time 0.1892 (0.2231)	loss 0.9312 (0.9061)	grad_norm 2.0466 (2.0569)	loss_scale 8192.0000 (6435.0456)	mem 8691MB
[2024-07-26 01:03:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:22 lr 0.000026	 wd 0.0000	time 0.2119 (0.2224)	loss 1.0967 (0.9056)	grad_norm 2.5313 (2.0551)	loss_scale 8192.0000 (6508.2216)	mem 8691MB
[2024-07-26 01:03:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1701 (0.2209)	loss 0.8354 (0.9053)	grad_norm 1.8673 (2.0560)	loss_scale 8192.0000 (6575.5458)	mem 8691MB
[2024-07-26 01:04:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 19 training takes 0:09:19
[2024-07-26 01:04:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 20.541 (20.541)	Loss 0.3667 (0.3667)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-26 01:04:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.836 Acc@5 97.490
[2024-07-26 01:04:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-26 01:04:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.84%
[2024-07-26 01:05:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][0/2502]	eta 23:54:27 lr 0.000026	 wd 0.0000	time 34.3997 (34.3997)	loss 1.0117 (1.0117)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:05:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:21:21 lr 0.000026	 wd 0.0000	time 0.1916 (0.5334)	loss 1.0176 (0.9185)	grad_norm 2.0969 (2.0278)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:05:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:13:45 lr 0.000025	 wd 0.0000	time 0.1757 (0.3587)	loss 1.0244 (0.9113)	grad_norm 1.9762 (2.0201)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:06:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:11:01 lr 0.000025	 wd 0.0000	time 0.1879 (0.3002)	loss 0.8008 (0.9092)	grad_norm 2.4893 (2.0273)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:06:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:09:53 lr 0.000025	 wd 0.0000	time 0.3212 (0.2822)	loss 0.8110 (0.9042)	grad_norm 1.8834 (2.0172)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:07:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:09:33 lr 0.000025	 wd 0.0000	time 0.1857 (0.2867)	loss 0.9058 (0.9058)	grad_norm 1.7949 (1.9984)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:07:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:08:33 lr 0.000025	 wd 0.0000	time 0.1668 (0.2698)	loss 0.8647 (0.9054)	grad_norm 2.2924 (2.0057)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:07:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:43 lr 0.000025	 wd 0.0000	time 0.1705 (0.2575)	loss 0.8154 (0.9046)	grad_norm 1.5618 (2.0121)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:08:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:07:03 lr 0.000024	 wd 0.0000	time 0.2418 (0.2490)	loss 0.8926 (0.9053)	grad_norm 1.8451 (2.0079)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:08:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:56 lr 0.000024	 wd 0.0000	time 0.2160 (0.2600)	loss 1.0439 (0.9053)	grad_norm 1.7285 (2.0140)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:08:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:19 lr 0.000024	 wd 0.0000	time 0.1800 (0.2527)	loss 0.8477 (0.9068)	grad_norm 1.6619 (2.0091)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:09:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:45 lr 0.000024	 wd 0.0000	time 0.1903 (0.2464)	loss 0.8159 (0.9063)	grad_norm 2.5523 (2.0162)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:09:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:14 lr 0.000024	 wd 0.0000	time 0.1971 (0.2412)	loss 0.7754 (0.9057)	grad_norm 1.8308 (2.0165)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:10:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:04:57 lr 0.000023	 wd 0.0000	time 0.2171 (0.2478)	loss 0.8384 (0.9045)	grad_norm 2.0664 (2.0119)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:10:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:28 lr 0.000023	 wd 0.0000	time 0.1792 (0.2438)	loss 0.9038 (0.9048)	grad_norm 1.8724 (2.0081)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:10:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:04:00 lr 0.000023	 wd 0.0000	time 0.1932 (0.2399)	loss 0.9473 (0.9043)	grad_norm 1.7128 (2.0087)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:11:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:33 lr 0.000023	 wd 0.0000	time 0.1849 (0.2363)	loss 0.9561 (0.9035)	grad_norm 1.7870 (2.0133)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:11:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:07 lr 0.000023	 wd 0.0000	time 0.1945 (0.2337)	loss 1.1211 (0.9035)	grad_norm 1.5571 (2.0141)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:11:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:43 lr 0.000023	 wd 0.0000	time 0.1999 (0.2333)	loss 0.9336 (0.9034)	grad_norm 2.3394 (2.0169)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:12:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:19 lr 0.000022	 wd 0.0000	time 0.1825 (0.2312)	loss 0.9131 (0.9037)	grad_norm 1.7645 (2.0177)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:12:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:01:55 lr 0.000022	 wd 0.0000	time 0.2061 (0.2291)	loss 0.9692 (0.9036)	grad_norm 3.5418 (2.0225)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:12:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:31 lr 0.000022	 wd 0.0000	time 0.1747 (0.2271)	loss 0.9585 (0.9040)	grad_norm 2.1889 (2.0298)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:13:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:08 lr 0.000022	 wd 0.0000	time 0.1975 (0.2257)	loss 0.9409 (0.9038)	grad_norm 1.9680 (2.0296)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:13:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:45 lr 0.000022	 wd 0.0000	time 0.1886 (0.2253)	loss 0.8926 (0.9044)	grad_norm 1.7174 (2.0315)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:13:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:22 lr 0.000022	 wd 0.0000	time 0.1860 (0.2240)	loss 0.8584 (0.9047)	grad_norm 2.1802 (2.0292)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:13:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1702 (0.2223)	loss 0.8574 (0.9047)	grad_norm 1.5854 (2.0331)	loss_scale 16384.0000 (8244.4078)	mem 8691MB
[2024-07-26 01:14:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 20 training takes 0:09:24
[2024-07-26 01:14:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 38.305 (38.305)	Loss 0.3672 (0.3672)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-26 01:15:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.830 Acc@5 97.504
[2024-07-26 01:15:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-26 01:15:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.84%
[2024-07-26 01:15:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][0/2502]	eta 11:50:33 lr 0.000021	 wd 0.0000	time 17.0396 (17.0396)	loss 0.9385 (0.9385)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 01:15:45 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:14:09 lr 0.000021	 wd 0.0000	time 0.1800 (0.3538)	loss 0.8813 (0.9076)	grad_norm 1.6241 (2.1211)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 01:16:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:10:23 lr 0.000021	 wd 0.0000	time 0.2208 (0.2709)	loss 0.8618 (0.9113)	grad_norm 1.6861 (2.0661)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 01:16:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:11:08 lr 0.000021	 wd 0.0000	time 0.1706 (0.3036)	loss 0.8418 (0.9051)	grad_norm 1.5927 (2.0439)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 01:16:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:09:37 lr 0.000021	 wd 0.0000	time 0.2022 (0.2748)	loss 0.7998 (0.9027)	grad_norm 1.7054 (2.0572)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 01:17:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:08:33 lr 0.000021	 wd 0.0000	time 0.1721 (0.2567)	loss 1.0010 (0.9037)	grad_norm 1.5826 (2.0470)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 01:17:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:07:45 lr 0.000020	 wd 0.0000	time 0.1812 (0.2447)	loss 0.9614 (0.9036)	grad_norm 1.6662 (2.0415)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 01:18:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:07:40 lr 0.000020	 wd 0.0000	time 0.1706 (0.2557)	loss 0.9116 (0.9038)	grad_norm 1.9415 (2.0332)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 01:18:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:02 lr 0.000020	 wd 0.0000	time 0.1671 (0.2480)	loss 0.9365 (0.9036)	grad_norm 1.8304 (2.0304)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 01:18:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:26 lr 0.000020	 wd 0.0000	time 0.1839 (0.2413)	loss 0.8550 (0.9031)	grad_norm 1.8846 (2.0346)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 01:19:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:05:53 lr 0.000020	 wd 0.0000	time 0.1805 (0.2355)	loss 0.8130 (0.9024)	grad_norm 2.2612 (inf)	loss_scale 8192.0000 (15925.7063)	mem 8691MB
[2024-07-26 01:19:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:05:24 lr 0.000020	 wd 0.0000	time 0.1944 (0.2317)	loss 0.8491 (0.9031)	grad_norm 1.9602 (inf)	loss_scale 8192.0000 (15223.2807)	mem 8691MB
[2024-07-26 01:19:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:05 lr 0.000019	 wd 0.0000	time 0.1874 (0.2344)	loss 0.9463 (0.9032)	grad_norm 2.4669 (inf)	loss_scale 8192.0000 (14637.8285)	mem 8691MB
[2024-07-26 01:20:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:37 lr 0.000019	 wd 0.0000	time 0.1762 (0.2306)	loss 1.0029 (0.9031)	grad_norm 1.5246 (inf)	loss_scale 8192.0000 (14142.3766)	mem 8691MB
[2024-07-26 01:20:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:10 lr 0.000019	 wd 0.0000	time 0.1847 (0.2274)	loss 0.8394 (0.9032)	grad_norm 2.5489 (inf)	loss_scale 8192.0000 (13717.6531)	mem 8691MB
[2024-07-26 01:20:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:03:44 lr 0.000019	 wd 0.0000	time 0.1802 (0.2245)	loss 0.8623 (0.9028)	grad_norm 2.0991 (inf)	loss_scale 8192.0000 (13349.5217)	mem 8691MB
[2024-07-26 01:21:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:22 lr 0.000019	 wd 0.0000	time 0.3877 (0.2249)	loss 0.8823 (0.9020)	grad_norm 1.6909 (inf)	loss_scale 8192.0000 (13027.3779)	mem 8691MB
[2024-07-26 01:21:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:03 lr 0.000019	 wd 0.0000	time 0.1751 (0.2285)	loss 0.8999 (0.9015)	grad_norm 1.8849 (inf)	loss_scale 8192.0000 (12743.1111)	mem 8691MB
[2024-07-26 01:21:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:38 lr 0.000018	 wd 0.0000	time 0.1762 (0.2261)	loss 0.9023 (0.9011)	grad_norm 2.4429 (inf)	loss_scale 8192.0000 (12490.4120)	mem 8691MB
[2024-07-26 01:22:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:14 lr 0.000018	 wd 0.0000	time 0.1877 (0.2240)	loss 0.7573 (0.9005)	grad_norm 2.2009 (inf)	loss_scale 8192.0000 (12264.2988)	mem 8691MB
[2024-07-26 01:22:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:51 lr 0.000018	 wd 0.0000	time 0.1945 (0.2222)	loss 0.8521 (0.9005)	grad_norm 2.1794 (inf)	loss_scale 8192.0000 (12060.7856)	mem 8691MB
[2024-07-26 01:22:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:29 lr 0.000018	 wd 0.0000	time 0.1724 (0.2224)	loss 0.8442 (0.9005)	grad_norm 2.2547 (inf)	loss_scale 8192.0000 (11876.6454)	mem 8691MB
[2024-07-26 01:23:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:06 lr 0.000018	 wd 0.0000	time 0.2260 (0.2214)	loss 0.7261 (0.9006)	grad_norm 1.6793 (inf)	loss_scale 8192.0000 (11709.2376)	mem 8691MB
[2024-07-26 01:23:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:44 lr 0.000018	 wd 0.0000	time 0.1812 (0.2199)	loss 0.9731 (0.9013)	grad_norm 2.0400 (inf)	loss_scale 8192.0000 (11556.3807)	mem 8691MB
[2024-07-26 01:23:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:22 lr 0.000018	 wd 0.0000	time 0.1711 (0.2185)	loss 0.8882 (0.9014)	grad_norm 1.6824 (inf)	loss_scale 8192.0000 (11416.2566)	mem 8691MB
[2024-07-26 01:24:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000017	 wd 0.0000	time 0.1699 (0.2170)	loss 0.9277 (0.9018)	grad_norm 1.9832 (inf)	loss_scale 8192.0000 (11287.3379)	mem 8691MB
[2024-07-26 01:24:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 21 training takes 0:09:09
[2024-07-26 01:24:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 39.603 (39.603)	Loss 0.3665 (0.3665)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-26 01:25:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.812 Acc@5 97.524
[2024-07-26 01:25:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-26 01:25:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.84%
[2024-07-26 01:25:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][0/2502]	eta 11:26:54 lr 0.000017	 wd 0.0000	time 16.4726 (16.4726)	loss 0.9814 (0.9814)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:25:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:14:18 lr 0.000017	 wd 0.0000	time 0.2767 (0.3573)	loss 1.0117 (0.9129)	grad_norm 1.7902 (2.0980)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:26:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:11:58 lr 0.000017	 wd 0.0000	time 0.1737 (0.3123)	loss 0.7954 (0.9097)	grad_norm 1.9736 (2.0560)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:26:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:09:52 lr 0.000017	 wd 0.0000	time 0.1952 (0.2691)	loss 0.9868 (0.9055)	grad_norm 2.5794 (2.0749)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:26:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:08:41 lr 0.000017	 wd 0.0000	time 0.1842 (0.2480)	loss 0.9199 (0.9079)	grad_norm 1.7200 (2.0682)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:27:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:07:50 lr 0.000017	 wd 0.0000	time 0.1726 (0.2348)	loss 1.0186 (0.9083)	grad_norm 2.3895 (2.0785)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:27:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:07:30 lr 0.000016	 wd 0.0000	time 0.3840 (0.2367)	loss 1.0469 (0.9101)	grad_norm 2.4544 (2.0595)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:28:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:19 lr 0.000016	 wd 0.0000	time 0.2120 (0.2437)	loss 0.8989 (0.9103)	grad_norm 2.1421 (2.0553)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:28:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:06:42 lr 0.000016	 wd 0.0000	time 0.2154 (0.2365)	loss 0.8687 (0.9109)	grad_norm 2.0800 (2.0541)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:28:44 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:09 lr 0.000016	 wd 0.0000	time 0.1849 (0.2307)	loss 0.8936 (0.9094)	grad_norm 2.1321 (2.0463)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:29:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:05:41 lr 0.000016	 wd 0.0000	time 0.2402 (0.2272)	loss 0.7949 (0.9099)	grad_norm 2.0859 (2.0460)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:29:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:34 lr 0.000016	 wd 0.0000	time 0.1701 (0.2386)	loss 0.8745 (0.9100)	grad_norm 1.8647 (2.0589)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:29:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:04 lr 0.000016	 wd 0.0000	time 0.1737 (0.2340)	loss 0.8755 (0.9101)	grad_norm 2.2670 (2.0623)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:30:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:04:36 lr 0.000015	 wd 0.0000	time 0.1685 (0.2302)	loss 0.9189 (0.9095)	grad_norm 2.2990 (2.0579)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:30:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:10 lr 0.000015	 wd 0.0000	time 0.1764 (0.2271)	loss 0.8291 (0.9097)	grad_norm 2.0352 (2.0647)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:30:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:03:45 lr 0.000015	 wd 0.0000	time 0.1754 (0.2248)	loss 0.6602 (0.9098)	grad_norm 1.8223 (2.0592)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:31:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:22 lr 0.000015	 wd 0.0000	time 0.1779 (0.2243)	loss 1.0381 (0.9095)	grad_norm 2.0176 (2.0550)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:31:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:02:58 lr 0.000015	 wd 0.0000	time 0.1758 (0.2222)	loss 0.7822 (0.9086)	grad_norm 2.1845 (2.0515)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:31:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:34 lr 0.000015	 wd 0.0000	time 0.1909 (0.2202)	loss 1.0557 (0.9076)	grad_norm 2.4373 (2.0465)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:32:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:11 lr 0.000015	 wd 0.0000	time 0.2031 (0.2186)	loss 1.0273 (0.9083)	grad_norm 1.5392 (2.0511)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:32:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:49 lr 0.000014	 wd 0.0000	time 1.1473 (0.2190)	loss 0.9795 (0.9080)	grad_norm 2.1036 (2.0512)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:32:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:27 lr 0.000014	 wd 0.0000	time 0.1876 (0.2179)	loss 0.8564 (0.9081)	grad_norm 2.1048 (2.0581)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:33:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:05 lr 0.000014	 wd 0.0000	time 0.1761 (0.2166)	loss 0.7285 (0.9074)	grad_norm 1.9382 (2.0631)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:33:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:43 lr 0.000014	 wd 0.0000	time 0.1848 (0.2154)	loss 0.9170 (0.9070)	grad_norm 2.1039 (2.0638)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:33:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:21 lr 0.000014	 wd 0.0000	time 0.2050 (0.2145)	loss 0.8345 (0.9076)	grad_norm 1.9618 (2.0610)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:34:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1696 (0.2133)	loss 0.9048 (0.9075)	grad_norm 2.2445 (2.0571)	loss_scale 16384.0000 (8381.9784)	mem 8691MB
[2024-07-26 01:34:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 22 training takes 0:09:08
[2024-07-26 01:34:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 28.268 (28.268)	Loss 0.3630 (0.3630)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-26 01:35:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.842 Acc@5 97.498
[2024-07-26 01:35:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-26 01:35:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.84%
[2024-07-26 01:35:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saving......
[2024-07-26 01:35:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-26 01:35:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][0/2502]	eta 12:00:12 lr 0.000014	 wd 0.0000	time 17.2711 (17.2711)	loss 0.9258 (0.9258)	grad_norm 0.0000 (0.0000)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 01:35:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:17:26 lr 0.000014	 wd 0.0000	time 0.1680 (0.4356)	loss 0.9272 (0.8994)	grad_norm 2.2874 (2.1610)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 01:36:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:11:54 lr 0.000013	 wd 0.0000	time 0.2022 (0.3102)	loss 0.8301 (0.8967)	grad_norm 2.3898 (2.0874)	loss_scale 16384.0000 (16384.0000)	mem 8691MB
[2024-07-26 01:36:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:09:50 lr 0.000013	 wd 0.0000	time 0.1836 (0.2683)	loss 0.8696 (0.8981)	grad_norm 1.8141 (inf)	loss_scale 8192.0000 (14696.6113)	mem 8691MB
[2024-07-26 01:36:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:08:38 lr 0.000013	 wd 0.0000	time 0.1695 (0.2468)	loss 1.0039 (0.9025)	grad_norm 1.9456 (inf)	loss_scale 8192.0000 (13074.5137)	mem 8691MB
[2024-07-26 01:37:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:07:53 lr 0.000013	 wd 0.0000	time 0.2382 (0.2366)	loss 1.0186 (0.9064)	grad_norm 3.0566 (inf)	loss_scale 8192.0000 (12099.9601)	mem 8691MB
[2024-07-26 01:37:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:07:57 lr 0.000013	 wd 0.0000	time 0.1984 (0.2512)	loss 0.9688 (0.9060)	grad_norm 2.4088 (inf)	loss_scale 8192.0000 (11449.7171)	mem 8691MB
[2024-07-26 01:37:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:15 lr 0.000013	 wd 0.0000	time 0.1709 (0.2416)	loss 0.9839 (0.9074)	grad_norm 1.6041 (inf)	loss_scale 8192.0000 (10984.9929)	mem 8691MB
[2024-07-26 01:38:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:06:39 lr 0.000013	 wd 0.0000	time 0.1757 (0.2346)	loss 0.9077 (0.9061)	grad_norm 1.8809 (inf)	loss_scale 8192.0000 (10636.3046)	mem 8691MB
[2024-07-26 01:38:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:06:07 lr 0.000012	 wd 0.0000	time 0.2184 (0.2292)	loss 1.1250 (0.9060)	grad_norm 1.8956 (inf)	loss_scale 8192.0000 (10365.0166)	mem 8691MB
[2024-07-26 01:39:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:05:57 lr 0.000012	 wd 0.0000	time 0.1874 (0.2382)	loss 0.8135 (0.9067)	grad_norm 2.3846 (inf)	loss_scale 8192.0000 (10147.9321)	mem 8691MB
[2024-07-26 01:39:27 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:27 lr 0.000012	 wd 0.0000	time 0.1875 (0.2336)	loss 0.9028 (0.9048)	grad_norm 2.2782 (inf)	loss_scale 8192.0000 (9970.2816)	mem 8691MB
[2024-07-26 01:39:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:04:59 lr 0.000012	 wd 0.0000	time 0.1908 (0.2297)	loss 0.8247 (0.9050)	grad_norm 1.9397 (inf)	loss_scale 8192.0000 (9822.2148)	mem 8691MB
[2024-07-26 01:40:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:04:31 lr 0.000012	 wd 0.0000	time 0.1788 (0.2260)	loss 0.9976 (0.9038)	grad_norm 1.4925 (inf)	loss_scale 8192.0000 (9696.9101)	mem 8691MB
[2024-07-26 01:40:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:08 lr 0.000012	 wd 0.0000	time 0.4123 (0.2258)	loss 0.9795 (0.9032)	grad_norm 2.2564 (inf)	loss_scale 8192.0000 (9589.4932)	mem 8691MB
[2024-07-26 01:40:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:03:52 lr 0.000012	 wd 0.0000	time 0.1827 (0.2317)	loss 0.9688 (0.9026)	grad_norm 2.5632 (inf)	loss_scale 8192.0000 (9496.3891)	mem 8691MB
[2024-07-26 01:41:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:26 lr 0.000012	 wd 0.0000	time 0.1860 (0.2288)	loss 0.8486 (0.9026)	grad_norm 1.8858 (inf)	loss_scale 8192.0000 (9414.9157)	mem 8691MB
[2024-07-26 01:41:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:01 lr 0.000011	 wd 0.0000	time 0.1866 (0.2261)	loss 0.7358 (0.9028)	grad_norm 1.8945 (inf)	loss_scale 8192.0000 (9343.0218)	mem 8691MB
[2024-07-26 01:41:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:37 lr 0.000011	 wd 0.0000	time 0.2135 (0.2241)	loss 0.9473 (0.9029)	grad_norm 2.2217 (inf)	loss_scale 8192.0000 (9279.1116)	mem 8691MB
[2024-07-26 01:42:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:14 lr 0.000011	 wd 0.0000	time 0.7659 (0.2238)	loss 0.7578 (0.9026)	grad_norm 1.4010 (inf)	loss_scale 8192.0000 (9221.9253)	mem 8691MB
[2024-07-26 01:42:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:01:51 lr 0.000011	 wd 0.0000	time 0.1752 (0.2226)	loss 0.9116 (0.9018)	grad_norm 2.5261 (inf)	loss_scale 8192.0000 (9170.4548)	mem 8691MB
[2024-07-26 01:42:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:28 lr 0.000011	 wd 0.0000	time 0.1648 (0.2210)	loss 0.9077 (0.9023)	grad_norm 2.6527 (inf)	loss_scale 8192.0000 (9123.8839)	mem 8691MB
[2024-07-26 01:43:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:06 lr 0.000011	 wd 0.0000	time 0.1713 (0.2196)	loss 0.9536 (0.9023)	grad_norm 1.5007 (inf)	loss_scale 8192.0000 (9081.5448)	mem 8691MB
[2024-07-26 01:43:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:44 lr 0.000011	 wd 0.0000	time 0.1957 (0.2183)	loss 0.9087 (0.9027)	grad_norm 2.2214 (inf)	loss_scale 8192.0000 (9042.8857)	mem 8691MB
[2024-07-26 01:43:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:22 lr 0.000011	 wd 0.0000	time 0.1774 (0.2178)	loss 0.8857 (0.9028)	grad_norm 2.1214 (inf)	loss_scale 8192.0000 (9007.4469)	mem 8691MB
[2024-07-26 01:44:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1694 (0.2166)	loss 0.9146 (0.9024)	grad_norm 2.0692 (inf)	loss_scale 8192.0000 (8974.8421)	mem 8691MB
[2024-07-26 01:44:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 23 training takes 0:09:12
[2024-07-26 01:44:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 20.474 (20.474)	Loss 0.3650 (0.3650)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-26 01:45:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.834 Acc@5 97.510
[2024-07-26 01:45:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-26 01:45:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.84%
[2024-07-26 01:45:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][0/2502]	eta 22:59:12 lr 0.000010	 wd 0.0000	time 33.0746 (33.0746)	loss 0.8252 (0.8252)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:45:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:20:55 lr 0.000010	 wd 0.0000	time 0.1659 (0.5226)	loss 0.9702 (0.8965)	grad_norm 1.8612 (2.1151)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:46:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:13:32 lr 0.000010	 wd 0.0000	time 0.1863 (0.3531)	loss 0.9570 (0.9009)	grad_norm 1.6092 (2.1017)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:46:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:10:52 lr 0.000010	 wd 0.0000	time 0.1835 (0.2961)	loss 0.8813 (0.9001)	grad_norm 2.4135 (2.1106)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:46:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:09:36 lr 0.000010	 wd 0.0000	time 0.2444 (0.2743)	loss 0.9487 (0.9005)	grad_norm 1.8493 (2.0755)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:47:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:09:26 lr 0.000010	 wd 0.0000	time 0.1749 (0.2831)	loss 0.8994 (0.9018)	grad_norm 2.2771 (2.0701)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:47:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:08:27 lr 0.000010	 wd 0.0000	time 0.1806 (0.2668)	loss 0.8398 (0.9011)	grad_norm 2.0662 (2.0524)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:48:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:07:39 lr 0.000010	 wd 0.0000	time 0.1790 (0.2548)	loss 0.8389 (0.9015)	grad_norm 2.2132 (2.0565)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:48:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:06:59 lr 0.000010	 wd 0.0000	time 0.1769 (0.2463)	loss 0.8262 (0.9027)	grad_norm 2.4676 (2.0556)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:48:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:06:42 lr 0.000009	 wd 0.0000	time 0.1908 (0.2511)	loss 0.9678 (0.9034)	grad_norm 2.6549 (2.0604)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:49:07 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:07 lr 0.000009	 wd 0.0000	time 0.1699 (0.2449)	loss 0.9092 (0.9043)	grad_norm 1.7472 (2.0637)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:49:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:05:35 lr 0.000009	 wd 0.0000	time 0.1715 (0.2394)	loss 0.8223 (0.9027)	grad_norm 2.1747 (2.0637)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:49:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:05 lr 0.000009	 wd 0.0000	time 0.1684 (0.2347)	loss 0.7925 (0.9022)	grad_norm 2.0558 (2.0708)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:50:04 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:04:39 lr 0.000009	 wd 0.0000	time 0.2051 (0.2322)	loss 0.9355 (0.9030)	grad_norm 1.8042 (2.0722)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:50:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:23 lr 0.000009	 wd 0.0000	time 0.2121 (0.2395)	loss 0.9429 (0.9034)	grad_norm 2.1027 (2.0621)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:50:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:03:56 lr 0.000009	 wd 0.0000	time 0.1977 (0.2358)	loss 0.7646 (0.9035)	grad_norm 1.8698 (2.0514)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:51:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:29 lr 0.000009	 wd 0.0000	time 0.1719 (0.2325)	loss 0.8374 (0.9033)	grad_norm 2.2109 (2.0548)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:51:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:04 lr 0.000008	 wd 0.0000	time 0.1712 (0.2299)	loss 0.9648 (0.9039)	grad_norm 1.5922 (2.0557)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:51:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:40 lr 0.000008	 wd 0.0000	time 0.1877 (0.2280)	loss 0.8066 (0.9035)	grad_norm 2.5019 (inf)	loss_scale 8192.0000 (8328.4575)	mem 8691MB
[2024-07-26 01:52:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:17 lr 0.000008	 wd 0.0000	time 0.1896 (0.2282)	loss 0.6758 (0.9038)	grad_norm 1.6917 (inf)	loss_scale 8192.0000 (8321.2793)	mem 8691MB
[2024-07-26 01:52:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:01:53 lr 0.000008	 wd 0.0000	time 0.1891 (0.2263)	loss 0.9165 (0.9034)	grad_norm 2.3833 (inf)	loss_scale 8192.0000 (8314.8186)	mem 8691MB
[2024-07-26 01:52:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:30 lr 0.000008	 wd 0.0000	time 0.1774 (0.2245)	loss 0.8994 (0.9032)	grad_norm 2.1797 (inf)	loss_scale 8192.0000 (8308.9729)	mem 8691MB
[2024-07-26 01:53:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:07 lr 0.000008	 wd 0.0000	time 0.1863 (0.2229)	loss 0.9424 (0.9028)	grad_norm 2.2003 (inf)	loss_scale 8192.0000 (8303.6583)	mem 8691MB
[2024-07-26 01:53:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:45 lr 0.000008	 wd 0.0000	time 0.1825 (0.2231)	loss 0.9883 (0.9028)	grad_norm 2.6502 (inf)	loss_scale 8192.0000 (8298.8057)	mem 8691MB
[2024-07-26 01:53:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:22 lr 0.000008	 wd 0.0000	time 0.1688 (0.2218)	loss 1.0977 (0.9029)	grad_norm 1.6087 (inf)	loss_scale 8192.0000 (8294.3574)	mem 8691MB
[2024-07-26 01:54:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1735 (0.2201)	loss 1.0186 (0.9030)	grad_norm 1.9297 (inf)	loss_scale 8192.0000 (8290.2647)	mem 8691MB
[2024-07-26 01:54:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 24 training takes 0:09:18
[2024-07-26 01:54:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 19.692 (19.692)	Loss 0.3635 (0.3635)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-26 01:54:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.828 Acc@5 97.498
[2024-07-26 01:54:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-26 01:54:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.84%
[2024-07-26 01:55:39 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][0/2502]	eta 1 day, 3:49:32 lr 0.000008	 wd 0.0000	time 40.0369 (40.0369)	loss 0.8828 (0.8828)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:55:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:23:13 lr 0.000008	 wd 0.0000	time 0.1968 (0.5802)	loss 0.9189 (0.9016)	grad_norm 1.9942 (2.0442)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:56:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:14:39 lr 0.000007	 wd 0.0000	time 0.1810 (0.3821)	loss 0.8076 (0.9011)	grad_norm 1.8130 (2.0922)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:56:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:12:23 lr 0.000007	 wd 0.0000	time 0.3069 (0.3375)	loss 0.9785 (0.9030)	grad_norm 1.9681 (2.0418)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:57:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:12:04 lr 0.000007	 wd 0.0000	time 0.1828 (0.3448)	loss 0.9561 (0.9018)	grad_norm 2.1478 (2.0428)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:57:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:10:26 lr 0.000007	 wd 0.0000	time 0.1777 (0.3127)	loss 0.8403 (0.9019)	grad_norm 1.7921 (2.0338)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:57:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:09:14 lr 0.000007	 wd 0.0000	time 0.1815 (0.2915)	loss 0.9517 (0.9021)	grad_norm 1.6612 (2.0366)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:58:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:08:27 lr 0.000007	 wd 0.0000	time 0.2320 (0.2816)	loss 0.9194 (0.9010)	grad_norm 1.7799 (2.0421)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:58:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:07:43 lr 0.000007	 wd 0.0000	time 0.1701 (0.2724)	loss 0.9385 (0.9012)	grad_norm 2.1638 (2.0458)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:58:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:07:00 lr 0.000007	 wd 0.0000	time 0.1818 (0.2626)	loss 0.8608 (0.9009)	grad_norm 1.6930 (2.0441)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:59:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:22 lr 0.000007	 wd 0.0000	time 0.1904 (0.2547)	loss 1.0537 (0.9007)	grad_norm 2.4941 (2.0514)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 01:59:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:48 lr 0.000007	 wd 0.0000	time 0.2213 (0.2487)	loss 0.9053 (0.9003)	grad_norm 1.7482 (2.0546)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:00:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:26 lr 0.000006	 wd 0.0000	time 3.5516 (0.2510)	loss 1.1211 (0.9012)	grad_norm 1.7593 (2.0430)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:00:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:04:59 lr 0.000006	 wd 0.0000	time 0.1797 (0.2496)	loss 0.8638 (0.9014)	grad_norm 2.0055 (2.0447)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:00:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:29 lr 0.000006	 wd 0.0000	time 0.1928 (0.2450)	loss 0.8652 (0.9010)	grad_norm 1.5625 (2.0427)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:01:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:04:01 lr 0.000006	 wd 0.0000	time 0.2177 (0.2408)	loss 0.9448 (0.9015)	grad_norm 2.0174 (2.0446)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:01:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:34 lr 0.000006	 wd 0.0000	time 0.1799 (0.2378)	loss 0.8755 (0.9008)	grad_norm 1.6733 (2.0470)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:01:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:10 lr 0.000006	 wd 0.0000	time 0.1702 (0.2374)	loss 0.8760 (0.9003)	grad_norm 2.6229 (2.0498)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:02:02 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:45 lr 0.000006	 wd 0.0000	time 0.1710 (0.2351)	loss 1.0713 (0.9009)	grad_norm 1.6417 (2.0472)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:02:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:19 lr 0.000006	 wd 0.0000	time 0.1786 (0.2326)	loss 1.2578 (0.9013)	grad_norm 1.8369 (2.0519)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:02:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:01:55 lr 0.000006	 wd 0.0000	time 0.1706 (0.2303)	loss 1.0137 (0.9009)	grad_norm 1.7200 (2.0519)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:02:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:31 lr 0.000006	 wd 0.0000	time 0.1884 (0.2285)	loss 0.9673 (0.9009)	grad_norm 1.7888 (2.0466)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:03:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:08 lr 0.000006	 wd 0.0000	time 0.2975 (0.2282)	loss 0.8721 (0.8999)	grad_norm 2.0235 (2.0466)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:03:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:45 lr 0.000005	 wd 0.0000	time 0.1654 (0.2267)	loss 0.8389 (0.8998)	grad_norm 1.9660 (2.0478)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:03:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:22 lr 0.000005	 wd 0.0000	time 0.1769 (0.2251)	loss 0.8286 (0.8997)	grad_norm 1.7674 (2.0456)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:04:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000005	 wd 0.0000	time 0.1690 (0.2232)	loss 0.8755 (0.8995)	grad_norm 1.7813 (2.0473)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:04:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 25 training takes 0:09:26
[2024-07-26 02:05:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 40.860 (40.860)	Loss 0.3635 (0.3635)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-26 02:05:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.842 Acc@5 97.494
[2024-07-26 02:05:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-26 02:05:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.84%
[2024-07-26 02:05:24 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saving......
[2024-07-26 02:05:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-26 02:05:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][0/2502]	eta 10:36:03 lr 0.000005	 wd 0.0000	time 15.2534 (15.2534)	loss 0.8848 (0.8848)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:05:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:13:24 lr 0.000005	 wd 0.0000	time 0.1850 (0.3349)	loss 0.9922 (0.9001)	grad_norm 2.1226 (2.0864)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:06:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:12:33 lr 0.000005	 wd 0.0000	time 0.2251 (0.3274)	loss 0.8784 (0.9032)	grad_norm 2.1970 (2.0761)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:06:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:10:41 lr 0.000005	 wd 0.0000	time 0.2028 (0.2912)	loss 0.8491 (0.9030)	grad_norm 2.0498 (2.0793)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:07:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:09:15 lr 0.000005	 wd 0.0000	time 0.1852 (0.2642)	loss 0.9858 (0.9010)	grad_norm 2.0082 (2.0852)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:07:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:08:16 lr 0.000005	 wd 0.0000	time 0.2129 (0.2481)	loss 0.9844 (0.9020)	grad_norm 1.7682 (2.0752)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:07:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:07:40 lr 0.000005	 wd 0.0000	time 0.1974 (0.2421)	loss 0.8755 (0.9018)	grad_norm 2.2111 (2.0739)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:08:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:34 lr 0.000005	 wd 0.0000	time 0.1859 (0.2520)	loss 1.0908 (0.9004)	grad_norm 1.6518 (2.0778)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:08:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:06:54 lr 0.000005	 wd 0.0000	time 0.1699 (0.2437)	loss 0.8804 (0.9001)	grad_norm 1.9430 (2.0806)	loss_scale 16384.0000 (8580.6342)	mem 8691MB
[2024-07-26 02:08:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:06:19 lr 0.000005	 wd 0.0000	time 0.1680 (0.2372)	loss 0.8848 (0.8993)	grad_norm 1.8054 (2.0821)	loss_scale 16384.0000 (9446.7125)	mem 8691MB
[2024-07-26 02:09:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:05:48 lr 0.000004	 wd 0.0000	time 0.1969 (0.2322)	loss 0.9937 (0.8993)	grad_norm 1.9548 (2.0810)	loss_scale 16384.0000 (10139.7483)	mem 8691MB
[2024-07-26 02:09:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:26 lr 0.000004	 wd 0.0000	time 0.1708 (0.2326)	loss 0.9307 (0.8993)	grad_norm 2.1009 (2.0826)	loss_scale 16384.0000 (10706.8919)	mem 8691MB
[2024-07-26 02:09:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:04:57 lr 0.000004	 wd 0.0000	time 0.1733 (0.2286)	loss 0.8179 (0.9001)	grad_norm 1.7534 (2.0805)	loss_scale 16384.0000 (11179.5903)	mem 8691MB
[2024-07-26 02:10:18 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:04:30 lr 0.000004	 wd 0.0000	time 0.1732 (0.2254)	loss 0.7705 (0.9004)	grad_norm 1.7918 (2.0791)	loss_scale 16384.0000 (11579.6218)	mem 8691MB
[2024-07-26 02:10:37 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:05 lr 0.000004	 wd 0.0000	time 0.1748 (0.2227)	loss 1.0273 (0.9009)	grad_norm 1.9223 (2.0773)	loss_scale 16384.0000 (11922.5468)	mem 8691MB
[2024-07-26 02:10:56 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:03:40 lr 0.000004	 wd 0.0000	time 0.1754 (0.2205)	loss 0.8364 (0.9010)	grad_norm 2.6525 (inf)	loss_scale 8192.0000 (11750.4171)	mem 8691MB
[2024-07-26 02:11:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:19 lr 0.000004	 wd 0.0000	time 0.1708 (0.2213)	loss 0.7974 (0.9002)	grad_norm 1.8339 (inf)	loss_scale 8192.0000 (11528.1549)	mem 8691MB
[2024-07-26 02:11:38 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:02:56 lr 0.000004	 wd 0.0000	time 0.1837 (0.2196)	loss 0.8096 (0.8998)	grad_norm 1.8674 (inf)	loss_scale 8192.0000 (11332.0259)	mem 8691MB
[2024-07-26 02:11:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:32 lr 0.000004	 wd 0.0000	time 0.1832 (0.2178)	loss 0.9146 (0.9000)	grad_norm 1.5326 (inf)	loss_scale 8192.0000 (11157.6768)	mem 8691MB
[2024-07-26 02:12:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:10 lr 0.000004	 wd 0.0000	time 0.1936 (0.2162)	loss 0.8149 (0.8999)	grad_norm 2.0183 (inf)	loss_scale 8192.0000 (11001.6707)	mem 8691MB
[2024-07-26 02:12:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:01:47 lr 0.000004	 wd 0.0000	time 0.1981 (0.2151)	loss 0.9766 (0.9002)	grad_norm 2.0329 (inf)	loss_scale 8192.0000 (10861.2574)	mem 8691MB
[2024-07-26 02:12:58 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:26 lr 0.000004	 wd 0.0000	time 0.1823 (0.2155)	loss 0.9238 (0.9005)	grad_norm 1.8021 (inf)	loss_scale 8192.0000 (10734.2104)	mem 8691MB
[2024-07-26 02:13:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:04 lr 0.000004	 wd 0.0000	time 0.2065 (0.2147)	loss 0.8809 (0.9007)	grad_norm 2.1519 (inf)	loss_scale 8192.0000 (10618.7079)	mem 8691MB
[2024-07-26 02:13:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:43 lr 0.000004	 wd 0.0000	time 0.1860 (0.2135)	loss 0.7993 (0.9007)	grad_norm 2.3977 (inf)	loss_scale 8192.0000 (10513.2447)	mem 8691MB
[2024-07-26 02:13:55 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:21 lr 0.000003	 wd 0.0000	time 0.1704 (0.2123)	loss 0.9556 (0.9011)	grad_norm 2.2185 (inf)	loss_scale 8192.0000 (10416.5664)	mem 8691MB
[2024-07-26 02:14:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1698 (0.2111)	loss 0.8076 (0.9016)	grad_norm 2.4945 (inf)	loss_scale 8192.0000 (10327.6194)	mem 8691MB
[2024-07-26 02:14:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 26 training takes 0:08:55
[2024-07-26 02:15:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 41.262 (41.262)	Loss 0.3643 (0.3643)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-26 02:15:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.868 Acc@5 97.506
[2024-07-26 02:15:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-26 02:15:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.87%
[2024-07-26 02:15:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saving......
[2024-07-26 02:15:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-26 02:15:36 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][0/2502]	eta 10:49:16 lr 0.000003	 wd 0.0000	time 15.5701 (15.5701)	loss 0.8389 (0.8389)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:15:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:15:10 lr 0.000003	 wd 0.0000	time 0.2371 (0.3792)	loss 0.9043 (0.9054)	grad_norm 2.2395 (2.0434)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:16:25 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:12:11 lr 0.000003	 wd 0.0000	time 0.1830 (0.3176)	loss 0.8911 (0.9013)	grad_norm 1.8343 (2.0660)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:16:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:10:01 lr 0.000003	 wd 0.0000	time 0.1768 (0.2730)	loss 0.9248 (0.8975)	grad_norm 1.8846 (2.0463)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:17:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:08:46 lr 0.000003	 wd 0.0000	time 0.1826 (0.2507)	loss 0.8721 (0.8976)	grad_norm 1.6345 (2.0279)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:17:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:07:55 lr 0.000003	 wd 0.0000	time 0.1902 (0.2377)	loss 0.8252 (0.8963)	grad_norm 1.9990 (2.0189)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:17:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:06 lr 0.000003	 wd 0.0000	time 0.1821 (0.2555)	loss 0.8638 (0.8998)	grad_norm 1.7457 (2.0262)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:18:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:24 lr 0.000003	 wd 0.0000	time 0.1729 (0.2468)	loss 0.9180 (0.9013)	grad_norm 2.0761 (2.0270)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:18:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:06:46 lr 0.000003	 wd 0.0000	time 0.1896 (0.2389)	loss 0.9292 (0.9000)	grad_norm 1.6612 (2.0301)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:18:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:12 lr 0.000003	 wd 0.0000	time 0.1811 (0.2328)	loss 0.8433 (0.9016)	grad_norm 1.9294 (2.0370)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:19:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:05:47 lr 0.000003	 wd 0.0000	time 0.3109 (0.2315)	loss 0.9790 (0.9008)	grad_norm 1.9543 (2.0454)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:19:43 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:34 lr 0.000003	 wd 0.0000	time 0.1727 (0.2383)	loss 0.8086 (0.9004)	grad_norm 3.8199 (2.0480)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:20:01 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:04 lr 0.000003	 wd 0.0000	time 0.1858 (0.2338)	loss 0.8652 (0.8992)	grad_norm 2.5403 (2.0481)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:20:20 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:36 lr 0.000003	 wd 0.0000	time 0.1817 (0.2299)	loss 0.9146 (0.8991)	grad_norm 2.3582 (2.0461)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:20:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:11 lr 0.000003	 wd 0.0000	time 0.3121 (0.2279)	loss 0.7798 (0.8992)	grad_norm 1.7753 (2.0415)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:21:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:03:56 lr 0.000003	 wd 0.0000	time 0.1996 (0.2364)	loss 0.9712 (0.8997)	grad_norm 1.8381 (2.0350)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:21:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:30 lr 0.000003	 wd 0.0000	time 0.1833 (0.2332)	loss 0.8691 (0.9002)	grad_norm 1.8758 (2.0303)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:21:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:04 lr 0.000002	 wd 0.0000	time 0.1711 (0.2302)	loss 0.9800 (0.8998)	grad_norm 1.8937 (2.0299)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:22:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:40 lr 0.000002	 wd 0.0000	time 0.1966 (0.2279)	loss 0.8496 (0.9000)	grad_norm 1.8536 (2.0285)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:22:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:16 lr 0.000002	 wd 0.0000	time 2.1139 (0.2273)	loss 0.9238 (0.8999)	grad_norm 1.7829 (2.0262)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:22:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:53 lr 0.000002	 wd 0.0000	time 0.1825 (0.2260)	loss 0.7451 (0.8994)	grad_norm 1.6657 (2.0254)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:23:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:30 lr 0.000002	 wd 0.0000	time 0.1793 (0.2243)	loss 1.1250 (0.9009)	grad_norm 2.9248 (2.0318)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:23:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:07 lr 0.000002	 wd 0.0000	time 0.1844 (0.2226)	loss 0.8096 (0.9009)	grad_norm 1.9173 (2.0313)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:23:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:44 lr 0.000002	 wd 0.0000	time 0.1912 (0.2212)	loss 0.9492 (0.9014)	grad_norm 1.9416 (2.0330)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:24:11 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:22 lr 0.000002	 wd 0.0000	time 0.2011 (0.2209)	loss 0.9307 (0.9014)	grad_norm 1.8768 (2.0347)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:24:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1699 (0.2195)	loss 0.8423 (0.9016)	grad_norm 2.2400 (2.0346)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:24:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 27 training takes 0:09:19
[2024-07-26 02:25:03 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 22.887 (22.887)	Loss 0.3643 (0.3643)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-26 02:25:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.834 Acc@5 97.510
[2024-07-26 02:25:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-26 02:25:21 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.87%
[2024-07-26 02:25:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][0/2502]	eta 1 day, 1:01:14 lr 0.000002	 wd 0.0000	time 36.0011 (36.0011)	loss 0.8677 (0.8677)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:26:16 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:21:45 lr 0.000002	 wd 0.0000	time 0.1666 (0.5437)	loss 0.9668 (0.9144)	grad_norm 2.4282 (2.0085)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:26:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:13:58 lr 0.000002	 wd 0.0000	time 0.1919 (0.3644)	loss 0.9795 (0.9079)	grad_norm 3.8247 (2.0369)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:26:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:11:08 lr 0.000002	 wd 0.0000	time 0.1769 (0.3038)	loss 0.9580 (0.9075)	grad_norm 1.7818 (2.0393)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:27:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:10:07 lr 0.000002	 wd 0.0000	time 0.3356 (0.2892)	loss 0.7690 (0.9038)	grad_norm 1.6608 (2.0321)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:27:46 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:09:40 lr 0.000002	 wd 0.0000	time 0.1767 (0.2901)	loss 0.9639 (0.9046)	grad_norm 1.9632 (2.0188)	loss_scale 16384.0000 (9663.6168)	mem 8691MB
[2024-07-26 02:28:05 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:39 lr 0.000002	 wd 0.0000	time 0.2012 (0.2729)	loss 0.9434 (0.9041)	grad_norm 2.0524 (2.0118)	loss_scale 16384.0000 (10781.8170)	mem 8691MB
[2024-07-26 02:28:23 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:48 lr 0.000002	 wd 0.0000	time 0.1836 (0.2601)	loss 0.8672 (0.9034)	grad_norm 2.3462 (2.0165)	loss_scale 16384.0000 (11580.9872)	mem 8691MB
[2024-07-26 02:28:42 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:08 lr 0.000002	 wd 0.0000	time 0.1948 (0.2516)	loss 0.8950 (0.9029)	grad_norm 1.9899 (2.0192)	loss_scale 16384.0000 (12180.6142)	mem 8691MB
[2024-07-26 02:29:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:54 lr 0.000002	 wd 0.0000	time 0.1861 (0.2586)	loss 0.9409 (0.9012)	grad_norm 2.7971 (2.0218)	loss_scale 16384.0000 (12647.1387)	mem 8691MB
[2024-07-26 02:29:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:17 lr 0.000002	 wd 0.0000	time 0.1831 (0.2513)	loss 0.9351 (0.9010)	grad_norm 1.8437 (2.0188)	loss_scale 16384.0000 (13020.4515)	mem 8691MB
[2024-07-26 02:29:51 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:44 lr 0.000002	 wd 0.0000	time 0.1802 (0.2454)	loss 0.8481 (0.9005)	grad_norm 1.8541 (2.0130)	loss_scale 16384.0000 (13325.9510)	mem 8691MB
[2024-07-26 02:30:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:12 lr 0.000002	 wd 0.0000	time 0.1798 (0.2402)	loss 0.9629 (0.8997)	grad_norm 1.9738 (2.0093)	loss_scale 16384.0000 (13580.5762)	mem 8691MB
[2024-07-26 02:30:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:04:47 lr 0.000002	 wd 0.0000	time 0.2997 (0.2396)	loss 0.8345 (0.8997)	grad_norm 2.0004 (2.0100)	loss_scale 16384.0000 (13796.0584)	mem 8691MB
[2024-07-26 02:30:57 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:24 lr 0.000002	 wd 0.0000	time 0.1729 (0.2397)	loss 0.8564 (0.8995)	grad_norm 2.0926 (2.0079)	loss_scale 16384.0000 (13980.7794)	mem 8691MB
[2024-07-26 02:31:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:03:56 lr 0.000002	 wd 0.0000	time 0.1791 (0.2360)	loss 0.8447 (0.8992)	grad_norm 1.4814 (inf)	loss_scale 8192.0000 (14009.9027)	mem 8691MB
[2024-07-26 02:31:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:30 lr 0.000002	 wd 0.0000	time 0.1794 (0.2328)	loss 0.8091 (0.8993)	grad_norm 1.6297 (inf)	loss_scale 8192.0000 (13646.5109)	mem 8691MB
[2024-07-26 02:31:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:04 lr 0.000001	 wd 0.0000	time 0.2286 (0.2303)	loss 0.7715 (0.8996)	grad_norm 1.6649 (inf)	loss_scale 8192.0000 (13325.8460)	mem 8691MB
[2024-07-26 02:32:15 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:41 lr 0.000001	 wd 0.0000	time 0.1784 (0.2302)	loss 0.7944 (0.8997)	grad_norm 2.0580 (inf)	loss_scale 8192.0000 (13040.7907)	mem 8691MB
[2024-07-26 02:32:35 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:17 lr 0.000001	 wd 0.0000	time 0.2138 (0.2287)	loss 0.9180 (0.8998)	grad_norm 1.8053 (inf)	loss_scale 8192.0000 (12785.7254)	mem 8691MB
[2024-07-26 02:32:54 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:01:53 lr 0.000001	 wd 0.0000	time 0.1797 (0.2267)	loss 0.8589 (0.8994)	grad_norm 1.8369 (inf)	loss_scale 8192.0000 (12556.1539)	mem 8691MB
[2024-07-26 02:33:13 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:30 lr 0.000001	 wd 0.0000	time 0.1716 (0.2248)	loss 0.9668 (0.8998)	grad_norm 2.1536 (inf)	loss_scale 8192.0000 (12348.4360)	mem 8691MB
[2024-07-26 02:33:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:07 lr 0.000001	 wd 0.0000	time 0.1952 (0.2233)	loss 0.9556 (0.8996)	grad_norm 2.1609 (inf)	loss_scale 8192.0000 (12159.5929)	mem 8691MB
[2024-07-26 02:33:53 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:45 lr 0.000001	 wd 0.0000	time 0.1864 (0.2228)	loss 0.8359 (0.9001)	grad_norm 1.7990 (inf)	loss_scale 8192.0000 (11987.1638)	mem 8691MB
[2024-07-26 02:34:14 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:22 lr 0.000001	 wd 0.0000	time 0.1830 (0.2219)	loss 0.9785 (0.9002)	grad_norm 2.6560 (inf)	loss_scale 8192.0000 (11829.0979)	mem 8691MB
[2024-07-26 02:34:32 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1697 (0.2203)	loss 0.8940 (0.9006)	grad_norm 2.0156 (inf)	loss_scale 8192.0000 (11683.6721)	mem 8691MB
[2024-07-26 02:34:40 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 28 training takes 0:09:19
[2024-07-26 02:35:00 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 19.509 (19.509)	Loss 0.3635 (0.3635)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-26 02:35:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.860 Acc@5 97.520
[2024-07-26 02:35:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-26 02:35:19 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.87%
[2024-07-26 02:35:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][0/2502]	eta 23:29:07 lr 0.000001	 wd 0.0000	time 33.7921 (33.7921)	loss 0.8496 (0.8496)	grad_norm 0.0000 (0.0000)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:36:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:21:01 lr 0.000001	 wd 0.0000	time 0.1748 (0.5250)	loss 1.0625 (0.9009)	grad_norm 1.8474 (1.9190)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:36:30 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:13:35 lr 0.000001	 wd 0.0000	time 0.1811 (0.3544)	loss 0.8750 (0.9101)	grad_norm 1.8722 (1.9746)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:36:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:11:05 lr 0.000001	 wd 0.0000	time 0.2243 (0.3021)	loss 0.8438 (0.9073)	grad_norm 2.1254 (2.0173)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:37:22 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:10:47 lr 0.000001	 wd 0.0000	time 0.1891 (0.3079)	loss 0.8003 (0.9090)	grad_norm 2.0551 (2.0445)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:37:41 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:09:27 lr 0.000001	 wd 0.0000	time 0.1702 (0.2835)	loss 0.8599 (0.9082)	grad_norm 2.1128 (2.0260)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:37:59 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:27 lr 0.000001	 wd 0.0000	time 0.1709 (0.2670)	loss 0.8491 (0.9044)	grad_norm 1.8426 (2.0284)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:38:17 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:39 lr 0.000001	 wd 0.0000	time 0.1963 (0.2552)	loss 0.9019 (0.9019)	grad_norm 1.8844 (2.0204)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:38:52 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:07:33 lr 0.000001	 wd 0.0000	time 0.2362 (0.2665)	loss 0.7407 (0.9041)	grad_norm 1.9744 (2.0219)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:39:12 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:06:55 lr 0.000001	 wd 0.0000	time 0.1785 (0.2591)	loss 0.8730 (0.9038)	grad_norm 3.0858 (2.0272)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:39:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:18 lr 0.000001	 wd 0.0000	time 0.1838 (0.2518)	loss 0.8286 (0.9034)	grad_norm 2.1030 (2.0260)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:39:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:44 lr 0.000001	 wd 0.0000	time 0.1835 (0.2456)	loss 0.9297 (0.9034)	grad_norm 2.1911 (2.0277)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:40:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:15 lr 0.000001	 wd 0.0000	time 0.1996 (0.2421)	loss 0.8154 (0.9021)	grad_norm 1.9320 (2.0240)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:40:31 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:04:48 lr 0.000001	 wd 0.0000	time 0.1701 (0.2404)	loss 0.7900 (0.9031)	grad_norm 1.9245 (2.0190)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:40:50 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:21 lr 0.000001	 wd 0.0000	time 0.1839 (0.2369)	loss 1.0371 (0.9032)	grad_norm 2.0598 (2.0176)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:41:09 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:03:53 lr 0.000001	 wd 0.0000	time 0.1719 (0.2335)	loss 0.7861 (0.9028)	grad_norm 2.1703 (2.0129)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:41:28 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:27 lr 0.000001	 wd 0.0000	time 0.1778 (0.2306)	loss 0.8652 (0.9026)	grad_norm 2.0525 (2.0168)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:41:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:03 lr 0.000001	 wd 0.0000	time 0.1750 (0.2286)	loss 1.0811 (0.9032)	grad_norm 1.7992 (2.0205)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:42:10 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:40 lr 0.000001	 wd 0.0000	time 0.1707 (0.2282)	loss 0.7783 (0.9035)	grad_norm 1.8611 (2.0207)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:42:29 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:16 lr 0.000001	 wd 0.0000	time 0.1825 (0.2263)	loss 0.8345 (0.9043)	grad_norm 2.1641 (2.0205)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:42:48 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:01:52 lr 0.000001	 wd 0.0000	time 0.1950 (0.2244)	loss 0.9707 (0.9044)	grad_norm 2.2428 (2.0209)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:43:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:29 lr 0.000001	 wd 0.0000	time 0.2050 (0.2227)	loss 0.8677 (0.9043)	grad_norm 2.2512 (2.0200)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:43:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:06 lr 0.000001	 wd 0.0000	time 0.1926 (0.2215)	loss 1.0088 (0.9038)	grad_norm 1.4291 (2.0214)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:43:49 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:44 lr 0.000001	 wd 0.0000	time 0.1755 (0.2216)	loss 0.8481 (0.9037)	grad_norm 2.5012 (2.0227)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:44:08 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:22 lr 0.000001	 wd 0.0000	time 0.1704 (0.2203)	loss 0.8804 (0.9038)	grad_norm 1.8079 (2.0188)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:44:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1686 (0.2187)	loss 1.0908 (0.9036)	grad_norm 1.9030 (2.0155)	loss_scale 8192.0000 (8192.0000)	mem 8691MB
[2024-07-26 02:44:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 29 training takes 0:09:14
[2024-07-26 02:44:33 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 145): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_29.pth saving......
[2024-07-26 02:44:34 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 147): INFO pretrain/diffusion-ft/convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_conv_b_step_stage0/ckpt_epoch_29.pth saved !!!
[2024-07-26 02:45:06 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 32.465 (32.465)	Loss 0.3633 (0.3633)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 8691MB
[2024-07-26 02:45:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.842 Acc@5 97.516
[2024-07-26 02:45:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-26 02:45:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.87%
[2024-07-26 02:45:26 convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 189): INFO Training time 5:01:18
