[2024-08-02 08:59:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 366): INFO Full config saved to pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/config.json
[2024-08-02 08:59:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_convnext_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 27
    - 3
    DIMS:
    - 128
    - 256
    - 512
    - 1024
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: fullfinetune
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_conv_b_sequence_corss1
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 0.0001
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 0.8
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.0e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 1.0e-08

[2024-08-02 08:59:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/diffusion_finetune/convnext/adapter_convnext/diffusion_ft_adapter_convnext_base_224_22kto1k_sequence_crosslayer_process1.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/diffusion-ft", "tag": "diffusion_ft_adapter_conv_b_sequence_corss1", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-08-02 08:59:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 108): INFO Creating model:adapter_convnext_diffusion_finetune/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft
[2024-08-02 08:59:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 110): INFO Adapter_ConvNeXt_Diffusion_Finetune(
  (uma): UMA(filter_strategy1=18, filter_strategy2=6,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): Identity()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (12): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (13): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (14): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (15): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (16): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (17): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (18): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (19): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (20): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (21): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (22): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (23): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (24): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (25): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (26): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (memory_downsampling): ModuleList()
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-08-02 08:59:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 113): INFO number of params: 6284296
[2024-08-02 08:59:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 150): INFO no checkpoint found in pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1, ignoring auto resume
[2024-08-02 08:59:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth for fine-tuning......
[2024-08-02 08:59:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 127): WARNING <All keys matched successfully>
[2024-08-02 08:59:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth'
[2024-08-02 09:00:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 63.938 (63.938)	Loss 0.3564 (0.3564)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 3082MB
[2024-08-02 09:00:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.168 Acc@5 97.602
[2024-08-02 09:00:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 162): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-02 09:00:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 168): INFO Start training
[2024-08-02 09:01:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][0/2502]	eta 17:09:18 lr 0.000100	 wd 0.0000	time 24.6835 (24.6835)	loss 0.8623 (0.8623)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 7964MB
[2024-08-02 09:01:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:22:43 lr 0.000100	 wd 0.0000	time 0.1822 (0.5675)	loss 0.8267 (0.8746)	grad_norm 0.4194 (nan)	loss_scale 32768.0000 (33092.4356)	mem 7964MB
[2024-08-02 09:02:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:14:53 lr 0.000100	 wd 0.0000	time 0.2099 (0.3880)	loss 0.8403 (0.8812)	grad_norm 0.3946 (nan)	loss_scale 32768.0000 (32931.0249)	mem 7964MB
[2024-08-02 09:02:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:02 lr 0.000100	 wd 0.0000	time 0.2012 (0.3283)	loss 0.9009 (0.8846)	grad_norm 0.4222 (nan)	loss_scale 32768.0000 (32876.8638)	mem 7964MB
[2024-08-02 09:02:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:33 lr 0.000100	 wd 0.0000	time 0.2046 (0.3015)	loss 1.2451 (0.8841)	grad_norm 0.3912 (nan)	loss_scale 32768.0000 (32849.7157)	mem 7964MB
[2024-08-02 09:03:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:10:22 lr 0.000100	 wd 0.0000	time 0.1926 (0.3109)	loss 0.8140 (0.8841)	grad_norm 0.3724 (nan)	loss_scale 32768.0000 (32833.4052)	mem 7964MB
[2024-08-02 09:03:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:20 lr 0.000100	 wd 0.0000	time 0.2261 (0.2946)	loss 0.9561 (0.8843)	grad_norm 0.3870 (nan)	loss_scale 32768.0000 (32822.5225)	mem 7964MB
[2024-08-02 09:04:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:29 lr 0.000100	 wd 0.0000	time 0.1905 (0.2825)	loss 0.8442 (0.8813)	grad_norm 0.3630 (nan)	loss_scale 32768.0000 (32814.7447)	mem 7964MB
[2024-08-02 09:04:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:49 lr 0.000100	 wd 0.0000	time 0.3048 (0.2759)	loss 0.9141 (0.8827)	grad_norm 0.3581 (nan)	loss_scale 32768.0000 (32808.9089)	mem 7964MB
[2024-08-02 09:05:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:35 lr 0.000100	 wd 0.0000	time 0.1870 (0.2843)	loss 1.0723 (0.8814)	grad_norm 0.3780 (nan)	loss_scale 32768.0000 (32804.3685)	mem 7964MB
[2024-08-02 09:05:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:06:56 lr 0.000100	 wd 0.0000	time 0.2471 (0.2772)	loss 0.8887 (0.8814)	grad_norm 0.3846 (nan)	loss_scale 32768.0000 (32800.7353)	mem 7964MB
[2024-08-02 09:05:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:20 lr 0.000100	 wd 0.0000	time 0.1806 (0.2711)	loss 0.8076 (0.8811)	grad_norm 0.3943 (nan)	loss_scale 32768.0000 (32797.7620)	mem 7964MB
[2024-08-02 09:06:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:48 lr 0.000100	 wd 0.0000	time 0.2213 (0.2675)	loss 0.7603 (0.8813)	grad_norm 0.3827 (nan)	loss_scale 32768.0000 (32795.2839)	mem 7964MB
[2024-08-02 09:06:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:19 lr 0.000100	 wd 0.0000	time 0.2002 (0.2659)	loss 0.8521 (0.8826)	grad_norm 0.3947 (nan)	loss_scale 32768.0000 (32793.1868)	mem 7964MB
[2024-08-02 09:07:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:49 lr 0.000100	 wd 0.0000	time 0.1991 (0.2625)	loss 0.8818 (0.8829)	grad_norm 0.3983 (nan)	loss_scale 32768.0000 (32791.3890)	mem 7964MB
[2024-08-02 09:07:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:19 lr 0.000100	 wd 0.0000	time 0.1851 (0.2594)	loss 0.9385 (0.8834)	grad_norm 0.3927 (nan)	loss_scale 32768.0000 (32789.8308)	mem 7964MB
[2024-08-02 09:07:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:51 lr 0.000100	 wd 0.0000	time 0.1948 (0.2567)	loss 1.0479 (0.8842)	grad_norm 0.3991 (nan)	loss_scale 32768.0000 (32788.4672)	mem 7964MB
[2024-08-02 09:08:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:26 lr 0.000100	 wd 0.0000	time 0.2188 (0.2570)	loss 0.8652 (0.8843)	grad_norm 0.3715 (nan)	loss_scale 32768.0000 (32787.2640)	mem 7964MB
[2024-08-02 09:08:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:02:58 lr 0.000100	 wd 0.0000	time 0.1989 (0.2550)	loss 0.8706 (0.8842)	grad_norm 0.4188 (nan)	loss_scale 32768.0000 (32786.1943)	mem 7964MB
[2024-08-02 09:08:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:32 lr 0.000100	 wd 0.0000	time 0.2006 (0.2529)	loss 0.9766 (0.8844)	grad_norm 0.3701 (nan)	loss_scale 32768.0000 (32785.2372)	mem 7964MB
[2024-08-02 09:09:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:06 lr 0.000100	 wd 0.0000	time 0.2193 (0.2512)	loss 0.9238 (0.8845)	grad_norm 0.3903 (nan)	loss_scale 32768.0000 (32784.3758)	mem 7964MB
[2024-08-02 09:09:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:40 lr 0.000100	 wd 0.0000	time 0.2166 (0.2507)	loss 0.8496 (0.8849)	grad_norm 0.3773 (nan)	loss_scale 32768.0000 (32783.5964)	mem 7964MB
[2024-08-02 09:10:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:15 lr 0.000100	 wd 0.0000	time 0.1905 (0.2496)	loss 1.0049 (0.8846)	grad_norm 0.3856 (nan)	loss_scale 32768.0000 (32782.8878)	mem 7964MB
[2024-08-02 09:10:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:50 lr 0.000100	 wd 0.0000	time 0.2162 (0.2481)	loss 0.9902 (0.8845)	grad_norm 0.3972 (nan)	loss_scale 32768.0000 (32782.2408)	mem 7964MB
[2024-08-02 09:10:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:25 lr 0.000100	 wd 0.0000	time 0.2363 (0.2466)	loss 1.0381 (0.8846)	grad_norm 0.3816 (nan)	loss_scale 32768.0000 (32781.6476)	mem 7964MB
[2024-08-02 09:11:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000100	 wd 0.0000	time 0.1614 (0.2446)	loss 0.8608 (0.8844)	grad_norm 0.3720 (nan)	loss_scale 32768.0000 (32781.1020)	mem 7964MB
[2024-08-02 09:11:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 0 training takes 0:10:16
[2024-08-02 09:11:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_0.pth saving......
[2024-08-02 09:11:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_0.pth saved !!!
[2024-08-02 09:12:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 53.789 (53.789)	Loss 0.3643 (0.3643)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 09:12:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.104 Acc@5 97.604
[2024-08-02 09:12:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-08-02 09:12:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.10%
[2024-08-02 09:12:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saving......
[2024-08-02 09:12:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-02 09:12:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][0/2502]	eta 20:50:46 lr 0.000100	 wd 0.0000	time 29.9947 (29.9947)	loss 0.7690 (0.7690)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:13:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:21:42 lr 0.000100	 wd 0.0000	time 0.1865 (0.5422)	loss 0.8296 (0.8704)	grad_norm 0.3800 (0.3773)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:13:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:14:24 lr 0.000100	 wd 0.0000	time 0.1783 (0.3757)	loss 0.8018 (0.8768)	grad_norm 0.3740 (0.3770)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:13:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:45 lr 0.000100	 wd 0.0000	time 0.1990 (0.3206)	loss 0.9072 (0.8779)	grad_norm 0.3834 (0.3778)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:14:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:10:25 lr 0.000100	 wd 0.0000	time 0.2079 (0.2978)	loss 0.8838 (0.8790)	grad_norm 0.3934 (0.3790)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:14:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:09:25 lr 0.000100	 wd 0.0000	time 0.1955 (0.2825)	loss 0.7964 (0.8773)	grad_norm 0.3765 (0.3793)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:15:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:08:33 lr 0.000100	 wd 0.0000	time 0.1868 (0.2701)	loss 0.9028 (0.8788)	grad_norm 0.3919 (0.3789)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:15:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:07:51 lr 0.000100	 wd 0.0000	time 0.2111 (0.2617)	loss 0.8257 (0.8779)	grad_norm 0.3802 (0.3788)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:15:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:16 lr 0.000100	 wd 0.0000	time 0.2139 (0.2562)	loss 1.0234 (0.8792)	grad_norm 0.3763 (0.3785)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:16:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:00 lr 0.000099	 wd 0.0000	time 0.1899 (0.2626)	loss 0.8691 (0.8790)	grad_norm 0.3758 (0.3783)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:16:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:26 lr 0.000099	 wd 0.0000	time 0.2010 (0.2575)	loss 0.8911 (0.8792)	grad_norm 0.3784 (0.3784)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:17:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:05:55 lr 0.000099	 wd 0.0000	time 0.1917 (0.2533)	loss 0.9458 (0.8804)	grad_norm 0.3925 (0.3785)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:17:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:25 lr 0.000099	 wd 0.0000	time 0.2084 (0.2502)	loss 0.8379 (0.8805)	grad_norm 0.3915 (0.3788)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:17:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:05 lr 0.000099	 wd 0.0000	time 0.1761 (0.2538)	loss 0.8721 (0.8813)	grad_norm 0.3811 (0.3789)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:18:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:36 lr 0.000099	 wd 0.0000	time 0.2163 (0.2507)	loss 0.8745 (0.8815)	grad_norm 0.3819 (0.3789)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:18:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:08 lr 0.000099	 wd 0.0000	time 0.1986 (0.2484)	loss 0.8975 (0.8825)	grad_norm 0.3750 (0.3790)	loss_scale 65536.0000 (32811.6616)	mem 7964MB
[2024-08-02 09:18:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:42 lr 0.000099	 wd 0.0000	time 0.1903 (0.2462)	loss 0.8232 (0.8822)	grad_norm 0.3475 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-02 09:19:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:16 lr 0.000099	 wd 0.0000	time 0.2183 (0.2451)	loss 0.7715 (0.8824)	grad_norm 0.3803 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-02 09:19:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:52 lr 0.000099	 wd 0.0000	time 0.2798 (0.2453)	loss 0.9536 (0.8825)	grad_norm 0.3643 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-02 09:20:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:26 lr 0.000099	 wd 0.0000	time 0.2190 (0.2437)	loss 0.9082 (0.8829)	grad_norm 0.3622 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-02 09:20:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:01 lr 0.000099	 wd 0.0000	time 0.1809 (0.2422)	loss 0.7837 (0.8829)	grad_norm 0.3863 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-02 09:20:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:37 lr 0.000099	 wd 0.0000	time 0.2156 (0.2414)	loss 0.8296 (0.8829)	grad_norm 0.3939 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-02 09:21:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:12 lr 0.000099	 wd 0.0000	time 0.1936 (0.2416)	loss 0.7720 (0.8822)	grad_norm 0.3519 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-02 09:21:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:48 lr 0.000099	 wd 0.0000	time 0.1989 (0.2404)	loss 0.9253 (0.8830)	grad_norm 0.3771 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-02 09:21:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:24 lr 0.000099	 wd 0.0000	time 0.1933 (0.2393)	loss 0.9067 (0.8831)	grad_norm 0.3862 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-02 09:22:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000099	 wd 0.0000	time 0.1580 (0.2375)	loss 0.9087 (0.8834)	grad_norm 0.3911 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 09:22:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 1 training takes 0:09:58
[2024-08-02 09:23:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 40.028 (40.028)	Loss 0.3657 (0.3657)	Acc@1 91.211 (91.211)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 09:23:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.016 Acc@5 97.624
[2024-08-02 09:23:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-08-02 09:23:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.10%
[2024-08-02 09:23:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][0/2502]	eta 11:45:17 lr 0.000099	 wd 0.0000	time 16.9134 (16.9134)	loss 0.7827 (0.7827)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:23:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:15:07 lr 0.000099	 wd 0.0000	time 0.2291 (0.3779)	loss 0.9702 (0.8811)	grad_norm 0.3792 (0.3725)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:24:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:12:50 lr 0.000099	 wd 0.0000	time 0.1998 (0.3347)	loss 0.9282 (0.8787)	grad_norm 0.3829 (0.3734)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:24:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:10:45 lr 0.000099	 wd 0.0000	time 0.2154 (0.2930)	loss 0.8013 (0.8751)	grad_norm 0.3800 (0.3741)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:25:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:09:30 lr 0.000099	 wd 0.0000	time 0.1938 (0.2716)	loss 0.9507 (0.8766)	grad_norm 0.3616 (0.3748)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:25:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:08:36 lr 0.000099	 wd 0.0000	time 0.1788 (0.2580)	loss 0.9219 (0.8828)	grad_norm 0.3901 (0.3748)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:25:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:03 lr 0.000099	 wd 0.0000	time 0.2204 (0.2541)	loss 0.7959 (0.8827)	grad_norm 0.3774 (0.3747)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:26:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:07:35 lr 0.000099	 wd 0.0000	time 0.1809 (0.2529)	loss 0.8740 (0.8822)	grad_norm 0.3720 (0.3748)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:26:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:00 lr 0.000099	 wd 0.0000	time 0.1952 (0.2474)	loss 0.7896 (0.8805)	grad_norm 0.3763 (0.3748)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:26:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:30 lr 0.000098	 wd 0.0000	time 0.2109 (0.2437)	loss 0.9238 (0.8807)	grad_norm 0.3994 (0.3750)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:27:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:03 lr 0.000098	 wd 0.0000	time 0.2043 (0.2421)	loss 0.7969 (0.8798)	grad_norm 0.3666 (0.3749)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:27:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:39 lr 0.000098	 wd 0.0000	time 0.1970 (0.2421)	loss 0.9102 (0.8797)	grad_norm 0.3829 (0.3753)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:28:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:12 lr 0.000098	 wd 0.0000	time 0.2337 (0.2400)	loss 1.0312 (0.8801)	grad_norm 0.3874 (0.3753)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:28:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:04:46 lr 0.000098	 wd 0.0000	time 0.2170 (0.2381)	loss 0.8882 (0.8810)	grad_norm 0.3972 (0.3753)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:28:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:20 lr 0.000098	 wd 0.0000	time 0.1930 (0.2367)	loss 0.9355 (0.8812)	grad_norm 0.3659 (0.3752)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:29:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:03:58 lr 0.000098	 wd 0.0000	time 0.1728 (0.2381)	loss 1.0547 (0.8817)	grad_norm 0.3736 (0.3753)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:29:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:33 lr 0.000098	 wd 0.0000	time 0.2112 (0.2370)	loss 0.9238 (0.8813)	grad_norm 0.3761 (0.3755)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:29:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:08 lr 0.000098	 wd 0.0000	time 0.1726 (0.2356)	loss 0.8784 (0.8820)	grad_norm 0.3784 (0.3755)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:30:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:44 lr 0.000098	 wd 0.0000	time 0.2012 (0.2344)	loss 0.8730 (0.8819)	grad_norm 0.3568 (0.3756)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:30:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:21 lr 0.000098	 wd 0.0000	time 0.2093 (0.2342)	loss 0.7793 (0.8823)	grad_norm 0.3730 (0.3758)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:31:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:01:57 lr 0.000098	 wd 0.0000	time 0.2260 (0.2347)	loss 0.8867 (0.8824)	grad_norm 0.3538 (0.3757)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:31:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:33 lr 0.000098	 wd 0.0000	time 0.2079 (0.2338)	loss 0.9536 (0.8830)	grad_norm 0.3814 (0.3758)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:31:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:10 lr 0.000098	 wd 0.0000	time 0.2139 (0.2328)	loss 0.8687 (0.8829)	grad_norm 0.3739 (0.3756)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:32:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:46 lr 0.000098	 wd 0.0000	time 0.2148 (0.2326)	loss 0.8291 (0.8827)	grad_norm 0.3898 (0.3757)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:32:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:23 lr 0.000098	 wd 0.0000	time 0.2103 (0.2330)	loss 0.8696 (0.8830)	grad_norm 0.3758 (0.3757)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:32:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000098	 wd 0.0000	time 0.1584 (0.2314)	loss 0.8779 (0.8826)	grad_norm 0.3831 (0.3757)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:32:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 2 training takes 0:09:43
[2024-08-02 09:33:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 22.511 (22.511)	Loss 0.3608 (0.3608)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 09:33:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.166 Acc@5 97.622
[2024-08-02 09:33:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-02 09:33:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.17%
[2024-08-02 09:33:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saving......
[2024-08-02 09:33:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-02 09:34:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][0/2502]	eta 22:45:14 lr 0.000098	 wd 0.0000	time 32.7397 (32.7397)	loss 0.7358 (0.7358)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:34:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:21:30 lr 0.000098	 wd 0.0000	time 0.1920 (0.5373)	loss 0.9985 (0.8792)	grad_norm 0.3946 (0.3798)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:34:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:14:16 lr 0.000097	 wd 0.0000	time 0.1940 (0.3722)	loss 1.0176 (0.8751)	grad_norm 0.3897 (0.3777)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:35:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:11:39 lr 0.000097	 wd 0.0000	time 0.2012 (0.3176)	loss 1.0156 (0.8764)	grad_norm 0.3730 (0.3771)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:35:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:10:48 lr 0.000097	 wd 0.0000	time 0.2055 (0.3084)	loss 0.9600 (0.8760)	grad_norm 0.3574 (0.3763)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:35:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:09:38 lr 0.000097	 wd 0.0000	time 0.2028 (0.2889)	loss 0.8911 (0.8774)	grad_norm nan (nan)	loss_scale 32768.0000 (32898.8104)	mem 7964MB
[2024-08-02 09:36:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:08:44 lr 0.000097	 wd 0.0000	time 0.2398 (0.2760)	loss 0.8203 (0.8778)	grad_norm 0.4003 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7964MB
[2024-08-02 09:36:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:08:00 lr 0.000097	 wd 0.0000	time 0.1977 (0.2668)	loss 0.9102 (0.8791)	grad_norm 0.3747 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7964MB
[2024-08-02 09:37:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:26 lr 0.000097	 wd 0.0000	time 0.2081 (0.2624)	loss 0.8477 (0.8781)	grad_norm 0.3916 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7964MB
[2024-08-02 09:37:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:06:56 lr 0.000097	 wd 0.0000	time 0.2042 (0.2597)	loss 0.8994 (0.8787)	grad_norm 0.3774 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7964MB
[2024-08-02 09:37:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:23 lr 0.000097	 wd 0.0000	time 0.1817 (0.2551)	loss 1.0361 (0.8803)	grad_norm 0.4035 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7964MB
[2024-08-02 09:38:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:05:52 lr 0.000097	 wd 0.0000	time 0.1930 (0.2512)	loss 0.7861 (0.8797)	grad_norm 0.3867 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7964MB
[2024-08-02 09:38:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:23 lr 0.000097	 wd 0.0000	time 0.2138 (0.2484)	loss 0.9277 (0.8791)	grad_norm 0.3679 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7964MB
[2024-08-02 09:38:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:04:58 lr 0.000097	 wd 0.0000	time 0.1842 (0.2482)	loss 0.9678 (0.8803)	grad_norm 0.3595 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7964MB
[2024-08-02 09:39:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:31 lr 0.000097	 wd 0.0000	time 0.2023 (0.2460)	loss 0.8374 (0.8801)	grad_norm 0.3609 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7964MB
[2024-08-02 09:39:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:04 lr 0.000097	 wd 0.0000	time 0.2004 (0.2437)	loss 0.8096 (0.8811)	grad_norm 0.3559 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-02 09:39:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:38 lr 0.000096	 wd 0.0000	time 0.2045 (0.2417)	loss 0.8262 (0.8804)	grad_norm 0.3748 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-02 09:40:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:13 lr 0.000096	 wd 0.0000	time 0.2642 (0.2411)	loss 0.9321 (0.8803)	grad_norm 0.3760 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-02 09:40:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:49 lr 0.000096	 wd 0.0000	time 0.1965 (0.2413)	loss 0.8740 (0.8803)	grad_norm 0.3504 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-02 09:41:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:24 lr 0.000096	 wd 0.0000	time 0.2077 (0.2398)	loss 0.8965 (0.8799)	grad_norm 0.3651 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-02 09:41:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:01:59 lr 0.000096	 wd 0.0000	time 0.1927 (0.2385)	loss 0.8398 (0.8804)	grad_norm 0.3675 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-02 09:41:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:35 lr 0.000096	 wd 0.0000	time 0.1991 (0.2378)	loss 0.7002 (0.8799)	grad_norm 0.3865 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-02 09:42:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:11 lr 0.000096	 wd 0.0000	time 0.1808 (0.2381)	loss 0.8140 (0.8797)	grad_norm 0.3773 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-02 09:42:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:47 lr 0.000096	 wd 0.0000	time 0.1840 (0.2372)	loss 0.9536 (0.8800)	grad_norm 0.3759 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-02 09:42:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:24 lr 0.000096	 wd 0.0000	time 0.1894 (0.2363)	loss 0.8149 (0.8800)	grad_norm 0.3670 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-02 09:43:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000096	 wd 0.0000	time 0.1731 (0.2344)	loss 0.8047 (0.8806)	grad_norm 0.3902 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 09:43:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 3 training takes 0:09:50
[2024-08-02 09:43:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 37.136 (37.136)	Loss 0.3662 (0.3662)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 09:44:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.210 Acc@5 97.632
[2024-08-02 09:44:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-02 09:44:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.21%
[2024-08-02 09:44:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saving......
[2024-08-02 09:44:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-02 09:44:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][0/2502]	eta 10:44:12 lr 0.000096	 wd 0.0000	time 15.4488 (15.4488)	loss 0.8848 (0.8848)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:44:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:14:27 lr 0.000096	 wd 0.0000	time 0.2119 (0.3613)	loss 0.7905 (0.8848)	grad_norm 0.3775 (0.3762)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:45:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:11:28 lr 0.000096	 wd 0.0000	time 0.3264 (0.2989)	loss 0.9048 (0.8816)	grad_norm 0.3507 (0.3756)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:45:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:10:01 lr 0.000095	 wd 0.0000	time 0.1998 (0.2732)	loss 0.8838 (0.8813)	grad_norm 0.3931 (0.3760)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:45:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:08:59 lr 0.000095	 wd 0.0000	time 0.2132 (0.2566)	loss 0.8623 (0.8766)	grad_norm 0.3595 (0.3763)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:46:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:08:13 lr 0.000095	 wd 0.0000	time 0.1801 (0.2466)	loss 0.9404 (0.8784)	grad_norm 0.3679 (0.3764)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:46:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:07:42 lr 0.000095	 wd 0.0000	time 0.2341 (0.2431)	loss 0.8481 (0.8806)	grad_norm 0.3981 (0.3765)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:47:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:07:16 lr 0.000095	 wd 0.0000	time 0.2156 (0.2425)	loss 0.9800 (0.8771)	grad_norm 0.3655 (0.3763)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:47:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:06:46 lr 0.000095	 wd 0.0000	time 0.1749 (0.2390)	loss 0.8467 (0.8772)	grad_norm 0.3849 (0.3762)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:47:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:06:18 lr 0.000095	 wd 0.0000	time 0.2265 (0.2361)	loss 0.8462 (0.8784)	grad_norm 0.3788 (0.3762)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:48:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:05:51 lr 0.000095	 wd 0.0000	time 0.2337 (0.2338)	loss 0.9082 (0.8783)	grad_norm 0.3789 (0.3764)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:48:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:05:29 lr 0.000095	 wd 0.0000	time 0.1881 (0.2349)	loss 0.9331 (0.8799)	grad_norm 0.3921 (0.3766)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:48:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:04 lr 0.000095	 wd 0.0000	time 0.2020 (0.2336)	loss 0.7280 (0.8798)	grad_norm 0.3616 (0.3764)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:49:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:04:38 lr 0.000095	 wd 0.0000	time 0.2114 (0.2320)	loss 0.8394 (0.8792)	grad_norm 0.3736 (0.3763)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:49:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:13 lr 0.000094	 wd 0.0000	time 0.1901 (0.2304)	loss 0.8789 (0.8788)	grad_norm 0.3812 (0.3765)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:49:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:03:50 lr 0.000094	 wd 0.0000	time 0.2149 (0.2305)	loss 0.7397 (0.8789)	grad_norm 0.3749 (0.3766)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:50:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:28 lr 0.000094	 wd 0.0000	time 0.2356 (0.2314)	loss 0.8330 (0.8787)	grad_norm 0.3677 (0.3766)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:50:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:04 lr 0.000094	 wd 0.0000	time 0.2442 (0.2305)	loss 1.0645 (0.8785)	grad_norm 0.3772 (0.3766)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:51:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:41 lr 0.000094	 wd 0.0000	time 0.1704 (0.2295)	loss 0.9199 (0.8789)	grad_norm 0.3751 (0.3765)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:51:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:18 lr 0.000094	 wd 0.0000	time 0.2459 (0.2294)	loss 0.8975 (0.8788)	grad_norm 0.3690 (0.3764)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:51:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:01:55 lr 0.000094	 wd 0.0000	time 0.1834 (0.2301)	loss 0.7524 (0.8784)	grad_norm nan (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-02 09:52:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:32 lr 0.000094	 wd 0.0000	time 0.1892 (0.2295)	loss 0.8271 (0.8792)	grad_norm 0.3937 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-02 09:52:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:09 lr 0.000094	 wd 0.0000	time 0.2043 (0.2289)	loss 0.9790 (0.8788)	grad_norm 0.3428 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-02 09:52:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:46 lr 0.000094	 wd 0.0000	time 0.2331 (0.2283)	loss 0.8491 (0.8792)	grad_norm 0.3768 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-02 09:53:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:23 lr 0.000093	 wd 0.0000	time 0.1876 (0.2287)	loss 0.8228 (0.8794)	grad_norm 0.3501 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-02 09:53:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000093	 wd 0.0000	time 0.1606 (0.2274)	loss 0.7729 (0.8794)	grad_norm 0.3663 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 09:53:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 4 training takes 0:09:33
[2024-08-02 09:54:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 18.571 (18.571)	Loss 0.3516 (0.3516)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 09:54:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.184 Acc@5 97.602
[2024-08-02 09:54:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-02 09:54:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.21%
[2024-08-02 09:54:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][0/2502]	eta 13:18:36 lr 0.000093	 wd 0.0000	time 19.1513 (19.1513)	loss 0.8594 (0.8594)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:55:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:17:05 lr 0.000093	 wd 0.0000	time 0.1914 (0.4271)	loss 0.9229 (0.8689)	grad_norm 0.3958 (0.3771)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:55:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:12:13 lr 0.000093	 wd 0.0000	time 0.1876 (0.3187)	loss 0.8008 (0.8732)	grad_norm 0.3848 (0.3791)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:55:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:20 lr 0.000093	 wd 0.0000	time 0.1839 (0.2819)	loss 0.9844 (0.8714)	grad_norm 0.3682 (0.3780)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:56:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:13 lr 0.000093	 wd 0.0000	time 0.2024 (0.2635)	loss 0.9282 (0.8714)	grad_norm 0.3837 (0.3788)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:56:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:08:35 lr 0.000093	 wd 0.0000	time 0.2186 (0.2573)	loss 0.8262 (0.8719)	grad_norm 0.3957 (0.3784)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:56:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:07:59 lr 0.000093	 wd 0.0000	time 0.2226 (0.2519)	loss 0.8643 (0.8748)	grad_norm 0.3831 (0.3783)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:57:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:23 lr 0.000093	 wd 0.0000	time 0.1789 (0.2460)	loss 0.7744 (0.8743)	grad_norm 0.4036 (0.3782)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:57:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:06:51 lr 0.000093	 wd 0.0000	time 0.1936 (0.2418)	loss 0.8364 (0.8741)	grad_norm 0.3857 (0.3784)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:57:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:23 lr 0.000092	 wd 0.0000	time 0.2040 (0.2395)	loss 0.9165 (0.8745)	grad_norm 0.3748 (0.3783)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:58:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:00 lr 0.000092	 wd 0.0000	time 0.1749 (0.2403)	loss 0.9194 (0.8763)	grad_norm 0.3747 (0.3784)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:58:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:33 lr 0.000092	 wd 0.0000	time 0.1785 (0.2381)	loss 0.8149 (0.8775)	grad_norm 0.3731 (0.3785)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:59:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:07 lr 0.000092	 wd 0.0000	time 0.1861 (0.2360)	loss 0.9033 (0.8782)	grad_norm 0.3708 (0.3786)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:59:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:41 lr 0.000092	 wd 0.0000	time 0.2100 (0.2343)	loss 0.9546 (0.8777)	grad_norm 0.3891 (0.3783)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 09:59:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:19 lr 0.000092	 wd 0.0000	time 1.2050 (0.2350)	loss 0.8633 (0.8770)	grad_norm 0.3862 (0.3783)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:00:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:03:54 lr 0.000092	 wd 0.0000	time 0.2092 (0.2340)	loss 0.8521 (0.8776)	grad_norm 0.3747 (0.3782)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:00:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:29 lr 0.000092	 wd 0.0000	time 0.1671 (0.2327)	loss 0.7847 (0.8781)	grad_norm 0.4026 (0.3783)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:00:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:05 lr 0.000092	 wd 0.0000	time 0.1703 (0.2315)	loss 0.8721 (0.8786)	grad_norm 0.3749 (0.3785)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:01:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:42 lr 0.000091	 wd 0.0000	time 0.2045 (0.2310)	loss 0.8735 (0.8780)	grad_norm 0.3871 (0.3786)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:01:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:19 lr 0.000091	 wd 0.0000	time 0.2639 (0.2319)	loss 0.8452 (0.8778)	grad_norm 0.3722 (0.3787)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:02:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:01:56 lr 0.000091	 wd 0.0000	time 0.1961 (0.2312)	loss 0.9688 (0.8783)	grad_norm 0.3870 (0.3788)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:02:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:32 lr 0.000091	 wd 0.0000	time 0.2054 (0.2305)	loss 0.9502 (0.8778)	grad_norm 0.3893 (0.3789)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:02:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:09 lr 0.000091	 wd 0.0000	time 0.2323 (0.2300)	loss 0.9702 (0.8778)	grad_norm 0.3758 (0.3788)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:03:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:46 lr 0.000091	 wd 0.0000	time 0.1896 (0.2304)	loss 0.7583 (0.8776)	grad_norm 0.4079 (0.3789)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:03:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:23 lr 0.000091	 wd 0.0000	time 0.2124 (0.2301)	loss 0.7871 (0.8773)	grad_norm 0.3900 (0.3789)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:03:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000091	 wd 0.0000	time 0.1811 (0.2284)	loss 0.7651 (0.8768)	grad_norm 0.3807 (0.3788)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:03:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 5 training takes 0:09:35
[2024-08-02 10:04:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 21.608 (21.608)	Loss 0.3567 (0.3567)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 10:04:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.240 Acc@5 97.632
[2024-08-02 10:04:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-02 10:04:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.24%
[2024-08-02 10:04:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saving......
[2024-08-02 10:04:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-02 10:04:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][0/2502]	eta 20:53:18 lr 0.000091	 wd 0.0000	time 30.0554 (30.0554)	loss 0.9248 (0.9248)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:05:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:20:06 lr 0.000090	 wd 0.0000	time 0.1835 (0.5023)	loss 0.8486 (0.8871)	grad_norm 0.3996 (0.3779)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:05:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:13:36 lr 0.000090	 wd 0.0000	time 0.2100 (0.3547)	loss 0.7896 (0.8802)	grad_norm 0.3824 (0.3783)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:06:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:11:30 lr 0.000090	 wd 0.0000	time 0.2416 (0.3135)	loss 0.8882 (0.8802)	grad_norm 0.3814 (0.3789)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:06:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:10:16 lr 0.000090	 wd 0.0000	time 0.2094 (0.2935)	loss 0.8599 (0.8787)	grad_norm 0.3658 (0.3792)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:06:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:09:13 lr 0.000090	 wd 0.0000	time 0.1820 (0.2764)	loss 0.9268 (0.8785)	grad_norm 0.3654 (0.3794)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:07:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:08:25 lr 0.000090	 wd 0.0000	time 0.2271 (0.2656)	loss 0.8838 (0.8778)	grad_norm 0.3972 (0.3799)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:07:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:07:45 lr 0.000090	 wd 0.0000	time 0.1986 (0.2585)	loss 0.9873 (0.8777)	grad_norm 0.3862 (0.3803)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:07:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:16 lr 0.000090	 wd 0.0000	time 0.2032 (0.2563)	loss 0.7222 (0.8780)	grad_norm 0.3721 (0.3802)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:08:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:06:44 lr 0.000089	 wd 0.0000	time 0.2212 (0.2522)	loss 0.8770 (0.8775)	grad_norm 0.3563 (0.3802)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:08:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:12 lr 0.000089	 wd 0.0000	time 0.2080 (0.2481)	loss 0.8330 (0.8784)	grad_norm 0.3780 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7964MB
[2024-08-02 10:08:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:43 lr 0.000089	 wd 0.0000	time 0.2238 (0.2447)	loss 0.8027 (0.8770)	grad_norm 0.3780 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7964MB
[2024-08-02 10:09:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:16 lr 0.000089	 wd 0.0000	time 0.2474 (0.2435)	loss 0.8418 (0.8771)	grad_norm 0.3864 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7964MB
[2024-08-02 10:09:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:04:51 lr 0.000089	 wd 0.0000	time 0.1769 (0.2429)	loss 0.7627 (0.8765)	grad_norm 0.3730 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7964MB
[2024-08-02 10:10:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:25 lr 0.000089	 wd 0.0000	time 0.1807 (0.2408)	loss 0.8931 (0.8761)	grad_norm 0.3734 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7964MB
[2024-08-02 10:10:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:03:59 lr 0.000089	 wd 0.0000	time 0.1681 (0.2388)	loss 0.7754 (0.8760)	grad_norm 0.3719 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-02 10:10:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:34 lr 0.000089	 wd 0.0000	time 0.2044 (0.2378)	loss 0.7935 (0.8755)	grad_norm 0.3670 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-02 10:11:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:11 lr 0.000088	 wd 0.0000	time 0.2118 (0.2383)	loss 0.8462 (0.8743)	grad_norm 0.3725 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-02 10:11:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:46 lr 0.000088	 wd 0.0000	time 0.2406 (0.2372)	loss 0.8193 (0.8742)	grad_norm 0.3749 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-02 10:11:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:22 lr 0.000088	 wd 0.0000	time 0.2167 (0.2361)	loss 0.8853 (0.8746)	grad_norm 0.3762 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-02 10:12:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:01:58 lr 0.000088	 wd 0.0000	time 0.2156 (0.2351)	loss 0.9165 (0.8753)	grad_norm 0.3836 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-02 10:12:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:34 lr 0.000088	 wd 0.0000	time 0.2133 (0.2353)	loss 0.8008 (0.8752)	grad_norm 0.3816 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-02 10:13:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:10 lr 0.000088	 wd 0.0000	time 0.1959 (0.2348)	loss 0.8896 (0.8746)	grad_norm 0.3819 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-02 10:13:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:47 lr 0.000088	 wd 0.0000	time 0.1926 (0.2340)	loss 0.8237 (0.8746)	grad_norm 0.3724 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-02 10:13:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:23 lr 0.000087	 wd 0.0000	time 0.1999 (0.2331)	loss 0.8833 (0.8752)	grad_norm 0.3563 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-02 10:14:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000087	 wd 0.0000	time 0.1613 (0.2316)	loss 0.7812 (0.8758)	grad_norm 0.3912 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 10:14:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 6 training takes 0:09:43
[2024-08-02 10:14:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 37.633 (37.633)	Loss 0.3552 (0.3552)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 10:15:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.152 Acc@5 97.636
[2024-08-02 10:15:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-02 10:15:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.24%
[2024-08-02 10:15:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][0/2502]	eta 11:26:57 lr 0.000087	 wd 0.0000	time 16.4738 (16.4738)	loss 0.8677 (0.8677)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:15:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:15:22 lr 0.000087	 wd 0.0000	time 0.3033 (0.3839)	loss 0.9517 (0.8744)	grad_norm 0.3746 (0.3805)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:16:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:11:57 lr 0.000087	 wd 0.0000	time 0.1653 (0.3118)	loss 0.8628 (0.8722)	grad_norm 0.3629 (0.3821)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:16:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:10:11 lr 0.000087	 wd 0.0000	time 0.2047 (0.2777)	loss 0.8340 (0.8694)	grad_norm 0.3877 (0.3815)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:16:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:09:08 lr 0.000087	 wd 0.0000	time 0.1857 (0.2608)	loss 0.8672 (0.8740)	grad_norm 0.4102 (0.3822)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:17:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:08:19 lr 0.000087	 wd 0.0000	time 0.1855 (0.2497)	loss 0.7725 (0.8718)	grad_norm 0.3486 (0.3821)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:17:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:07:49 lr 0.000086	 wd 0.0000	time 0.1757 (0.2471)	loss 0.9810 (0.8741)	grad_norm 0.3621 (0.3820)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:17:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:07:22 lr 0.000086	 wd 0.0000	time 0.2247 (0.2454)	loss 0.7876 (0.8737)	grad_norm 0.3511 (0.3821)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:18:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:06:50 lr 0.000086	 wd 0.0000	time 0.2181 (0.2411)	loss 0.8154 (0.8725)	grad_norm 0.3705 (0.3820)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:18:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:06:20 lr 0.000086	 wd 0.0000	time 0.2061 (0.2377)	loss 0.8394 (0.8735)	grad_norm 0.3772 (0.3820)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:19:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:05:55 lr 0.000086	 wd 0.0000	time 0.2447 (0.2368)	loss 0.7671 (0.8734)	grad_norm 0.3919 (0.3817)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:19:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:32 lr 0.000086	 wd 0.0000	time 0.2396 (0.2370)	loss 0.7812 (0.8729)	grad_norm 0.3841 (0.3818)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:19:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:06 lr 0.000086	 wd 0.0000	time 0.1886 (0.2350)	loss 0.9028 (0.8723)	grad_norm 0.3796 (0.3817)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:20:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:04:40 lr 0.000085	 wd 0.0000	time 0.1927 (0.2333)	loss 0.9165 (0.8719)	grad_norm 0.3608 (0.3817)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:20:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:15 lr 0.000085	 wd 0.0000	time 0.2062 (0.2319)	loss 0.7651 (0.8723)	grad_norm 0.3843 (0.3820)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:20:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:03:52 lr 0.000085	 wd 0.0000	time 0.2665 (0.2323)	loss 0.8433 (0.8720)	grad_norm 0.3944 (0.3820)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:21:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:29 lr 0.000085	 wd 0.0000	time 0.1910 (0.2317)	loss 0.8750 (0.8718)	grad_norm 0.3742 (0.3820)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:21:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:05 lr 0.000085	 wd 0.0000	time 0.1985 (0.2307)	loss 0.9878 (0.8715)	grad_norm 0.3607 (0.3820)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:21:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:41 lr 0.000085	 wd 0.0000	time 0.1882 (0.2298)	loss 0.8457 (0.8716)	grad_norm 0.3760 (0.3819)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:22:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:18 lr 0.000085	 wd 0.0000	time 0.2008 (0.2295)	loss 0.9175 (0.8715)	grad_norm 0.3744 (0.3820)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:22:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:01:55 lr 0.000084	 wd 0.0000	time 0.2052 (0.2308)	loss 0.8340 (0.8711)	grad_norm 0.3891 (0.3819)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:23:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:32 lr 0.000084	 wd 0.0000	time 0.2145 (0.2301)	loss 1.0205 (0.8721)	grad_norm 0.3965 (0.3821)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:23:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:09 lr 0.000084	 wd 0.0000	time 0.1847 (0.2293)	loss 0.6943 (0.8714)	grad_norm 0.4047 (0.3821)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:23:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:46 lr 0.000084	 wd 0.0000	time 0.2154 (0.2290)	loss 0.9541 (0.8714)	grad_norm 0.3775 (0.3822)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:24:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:23 lr 0.000084	 wd 0.0000	time 0.2124 (0.2296)	loss 0.9570 (0.8717)	grad_norm 0.3912 (0.3822)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:24:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000084	 wd 0.0000	time 0.1645 (0.2281)	loss 0.8716 (0.8722)	grad_norm 0.3979 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 10:24:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 7 training takes 0:09:34
[2024-08-02 10:24:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 18.663 (18.663)	Loss 0.3525 (0.3525)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 10:25:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.184 Acc@5 97.638
[2024-08-02 10:25:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-02 10:25:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.24%
[2024-08-02 10:25:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][0/2502]	eta 19:54:54 lr 0.000084	 wd 0.0000	time 28.6548 (28.6548)	loss 0.7827 (0.7827)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:26:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:20:26 lr 0.000083	 wd 0.0000	time 0.2038 (0.5106)	loss 0.8452 (0.8753)	grad_norm 0.3761 (0.3852)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:26:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:13:45 lr 0.000083	 wd 0.0000	time 0.1893 (0.3586)	loss 0.8555 (0.8741)	grad_norm 0.3821 (0.3843)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:26:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:11:19 lr 0.000083	 wd 0.0000	time 0.1913 (0.3084)	loss 0.8315 (0.8701)	grad_norm 0.4013 (0.3836)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:27:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:10:05 lr 0.000083	 wd 0.0000	time 0.1949 (0.2879)	loss 0.9658 (0.8716)	grad_norm 0.3780 (0.3831)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:27:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:09:32 lr 0.000083	 wd 0.0000	time 0.1901 (0.2861)	loss 0.8145 (0.8728)	grad_norm 0.3815 (0.3834)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:27:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:38 lr 0.000083	 wd 0.0000	time 0.1932 (0.2726)	loss 0.8501 (0.8727)	grad_norm 0.4037 (0.3829)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:28:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:55 lr 0.000083	 wd 0.0000	time 0.1949 (0.2639)	loss 0.8726 (0.8721)	grad_norm 0.3989 (0.3829)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:28:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:19 lr 0.000082	 wd 0.0000	time 0.1937 (0.2583)	loss 0.7520 (0.8716)	grad_norm 0.3819 (0.3830)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:29:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:50 lr 0.000082	 wd 0.0000	time 0.2299 (0.2563)	loss 1.0020 (0.8726)	grad_norm 0.3748 (0.3830)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:29:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:19 lr 0.000082	 wd 0.0000	time 0.1909 (0.2525)	loss 1.0293 (0.8733)	grad_norm 0.3792 (0.3831)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:29:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:48 lr 0.000082	 wd 0.0000	time 0.1932 (0.2488)	loss 0.9312 (0.8729)	grad_norm 0.3882 (0.3833)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:30:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:19 lr 0.000082	 wd 0.0000	time 0.2021 (0.2457)	loss 0.8179 (0.8726)	grad_norm 0.3786 (0.3832)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:30:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:54 lr 0.000082	 wd 0.0000	time 0.2284 (0.2447)	loss 0.8188 (0.8728)	grad_norm 0.3881 (0.3836)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:30:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:29 lr 0.000081	 wd 0.0000	time 0.1930 (0.2444)	loss 0.8228 (0.8727)	grad_norm 0.3764 (0.3834)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:31:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:04:02 lr 0.000081	 wd 0.0000	time 0.2216 (0.2423)	loss 0.8560 (0.8724)	grad_norm 0.3990 (0.3836)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:31:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:36 lr 0.000081	 wd 0.0000	time 0.1901 (0.2404)	loss 0.9600 (0.8719)	grad_norm 0.3798 (0.3836)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:31:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:12 lr 0.000081	 wd 0.0000	time 0.1968 (0.2394)	loss 0.8564 (0.8727)	grad_norm 0.3707 (0.3838)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:32:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:48 lr 0.000081	 wd 0.0000	time 0.2987 (0.2400)	loss 0.8623 (0.8731)	grad_norm 0.3934 (0.3837)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:32:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:23 lr 0.000081	 wd 0.0000	time 0.1968 (0.2388)	loss 0.7798 (0.8726)	grad_norm 0.3638 (0.3838)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:33:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:59 lr 0.000080	 wd 0.0000	time 0.1822 (0.2377)	loss 0.7998 (0.8728)	grad_norm 0.4110 (0.3838)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:33:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:35 lr 0.000080	 wd 0.0000	time 0.2132 (0.2368)	loss 0.8882 (0.8730)	grad_norm 0.3892 (0.3839)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:33:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:11 lr 0.000080	 wd 0.0000	time 0.1910 (0.2368)	loss 0.8115 (0.8725)	grad_norm 0.3862 (0.3840)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:34:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:47 lr 0.000080	 wd 0.0000	time 0.2225 (0.2359)	loss 0.9487 (0.8723)	grad_norm 0.3741 (0.3841)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:34:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:23 lr 0.000080	 wd 0.0000	time 0.2370 (0.2350)	loss 0.9595 (0.8722)	grad_norm 0.3994 (0.3842)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:34:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000080	 wd 0.0000	time 0.1616 (0.2331)	loss 0.9033 (0.8723)	grad_norm 0.3892 (0.3843)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:34:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 8 training takes 0:09:47
[2024-08-02 10:35:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 36.794 (36.794)	Loss 0.3560 (0.3560)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 10:35:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.226 Acc@5 97.628
[2024-08-02 10:35:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-02 10:35:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.24%
[2024-08-02 10:36:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][0/2502]	eta 11:20:05 lr 0.000080	 wd 0.0000	time 16.3090 (16.3090)	loss 0.8589 (0.8589)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:36:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:14:43 lr 0.000079	 wd 0.0000	time 0.1865 (0.3680)	loss 0.9736 (0.8668)	grad_norm 0.3955 (0.3844)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:36:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:11:28 lr 0.000079	 wd 0.0000	time 0.2717 (0.2992)	loss 0.7354 (0.8644)	grad_norm 0.3736 (0.3850)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:37:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:58 lr 0.000079	 wd 0.0000	time 0.1825 (0.2991)	loss 0.9253 (0.8665)	grad_norm 0.3609 (0.3853)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:37:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:40 lr 0.000079	 wd 0.0000	time 0.1675 (0.2762)	loss 0.8638 (0.8660)	grad_norm 0.3663 (0.3856)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:37:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:08:45 lr 0.000079	 wd 0.0000	time 0.2049 (0.2623)	loss 0.6714 (0.8710)	grad_norm 0.3906 (0.3857)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:38:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:06 lr 0.000079	 wd 0.0000	time 0.2083 (0.2559)	loss 0.7070 (0.8689)	grad_norm 0.3966 (0.3851)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:38:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:36 lr 0.000078	 wd 0.0000	time 0.1843 (0.2533)	loss 0.9268 (0.8697)	grad_norm 0.3949 (0.3852)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:39:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:02 lr 0.000078	 wd 0.0000	time 0.2020 (0.2485)	loss 0.9053 (0.8706)	grad_norm 0.3605 (0.3852)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:39:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:31 lr 0.000078	 wd 0.0000	time 0.1863 (0.2443)	loss 1.0195 (0.8713)	grad_norm 0.3852 (0.3851)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:39:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:01 lr 0.000078	 wd 0.0000	time 0.2058 (0.2408)	loss 0.9653 (0.8718)	grad_norm 0.3910 (0.3849)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:40:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:36 lr 0.000078	 wd 0.0000	time 0.2583 (0.2402)	loss 0.8018 (0.8718)	grad_norm 0.4024 (0.3848)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:40:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:11 lr 0.000078	 wd 0.0000	time 0.1860 (0.2389)	loss 0.9482 (0.8716)	grad_norm 0.3948 (0.3848)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:40:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:44 lr 0.000077	 wd 0.0000	time 0.1870 (0.2367)	loss 0.9380 (0.8720)	grad_norm 0.3626 (0.3846)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:41:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:18 lr 0.000077	 wd 0.0000	time 0.1845 (0.2349)	loss 0.8784 (0.8724)	grad_norm 0.3712 (0.3848)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:41:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:03:54 lr 0.000077	 wd 0.0000	time 0.1972 (0.2342)	loss 0.9170 (0.8726)	grad_norm 0.4037 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-02 10:42:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:31 lr 0.000077	 wd 0.0000	time 0.2067 (0.2348)	loss 0.8838 (0.8721)	grad_norm 0.3714 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-02 10:42:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:07 lr 0.000077	 wd 0.0000	time 0.2211 (0.2337)	loss 0.8242 (0.8729)	grad_norm 0.3646 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-02 10:42:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:43 lr 0.000077	 wd 0.0000	time 0.2034 (0.2327)	loss 0.7202 (0.8727)	grad_norm 0.3934 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-02 10:43:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:19 lr 0.000076	 wd 0.0000	time 0.2114 (0.2318)	loss 0.9165 (0.8729)	grad_norm 0.3802 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-02 10:43:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:01:56 lr 0.000076	 wd 0.0000	time 0.2495 (0.2326)	loss 0.9082 (0.8737)	grad_norm 0.3765 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-02 10:43:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:33 lr 0.000076	 wd 0.0000	time 0.1792 (0.2323)	loss 1.0225 (0.8742)	grad_norm 0.3657 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-02 10:44:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:09 lr 0.000076	 wd 0.0000	time 0.1953 (0.2314)	loss 0.9033 (0.8744)	grad_norm 0.3838 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-02 10:44:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:46 lr 0.000076	 wd 0.0000	time 0.1825 (0.2305)	loss 0.8618 (0.8740)	grad_norm 0.4168 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-02 10:44:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:23 lr 0.000075	 wd 0.0000	time 0.2090 (0.2304)	loss 0.8188 (0.8740)	grad_norm 0.3888 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-02 10:45:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000075	 wd 0.0000	time 0.1961 (0.2295)	loss 0.8613 (0.8741)	grad_norm 0.3646 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 10:45:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 9 training takes 0:09:39
[2024-08-02 10:45:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 18.959 (18.959)	Loss 0.3506 (0.3506)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 10:45:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.150 Acc@5 97.642
[2024-08-02 10:45:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-08-02 10:45:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.24%
[2024-08-02 10:46:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][0/2502]	eta 13:02:28 lr 0.000075	 wd 0.0000	time 18.7644 (18.7644)	loss 1.0215 (1.0215)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:46:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:17:11 lr 0.000075	 wd 0.0000	time 0.1872 (0.4296)	loss 0.7031 (0.8839)	grad_norm 0.3881 (0.3869)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:47:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:12:20 lr 0.000075	 wd 0.0000	time 0.1836 (0.3219)	loss 0.9375 (0.8764)	grad_norm 0.4000 (0.3869)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:47:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:26 lr 0.000075	 wd 0.0000	time 0.1876 (0.2846)	loss 0.8350 (0.8726)	grad_norm 0.3792 (0.3870)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:47:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:17 lr 0.000075	 wd 0.0000	time 0.2114 (0.2653)	loss 0.9019 (0.8708)	grad_norm 0.3987 (0.3871)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:48:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:08:34 lr 0.000074	 wd 0.0000	time 0.2023 (0.2572)	loss 0.7651 (0.8722)	grad_norm 0.3993 (0.3876)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:48:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:02 lr 0.000074	 wd 0.0000	time 0.2130 (0.2535)	loss 0.9370 (0.8712)	grad_norm 0.3818 (0.3872)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:48:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:26 lr 0.000074	 wd 0.0000	time 0.1729 (0.2478)	loss 0.8047 (0.8701)	grad_norm 0.3679 (0.3873)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:49:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:06:53 lr 0.000074	 wd 0.0000	time 0.1767 (0.2429)	loss 0.8667 (0.8706)	grad_norm 0.3799 (0.3878)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:49:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:24 lr 0.000074	 wd 0.0000	time 0.2008 (0.2402)	loss 0.8257 (0.8714)	grad_norm 0.3854 (0.3876)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:49:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:01 lr 0.000073	 wd 0.0000	time 0.3840 (0.2407)	loss 0.8066 (0.8715)	grad_norm 0.3853 (0.3877)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:50:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:34 lr 0.000073	 wd 0.0000	time 0.1824 (0.2383)	loss 0.7852 (0.8715)	grad_norm 0.3890 (0.3876)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:50:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:07 lr 0.000073	 wd 0.0000	time 0.2108 (0.2362)	loss 0.9614 (0.8713)	grad_norm 0.3761 (0.3878)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:51:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:41 lr 0.000073	 wd 0.0000	time 0.1805 (0.2342)	loss 0.8618 (0.8713)	grad_norm 0.3945 (0.3880)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:51:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:17 lr 0.000073	 wd 0.0000	time 0.1895 (0.2340)	loss 0.7866 (0.8712)	grad_norm 0.4144 (0.3879)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:51:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:03:54 lr 0.000073	 wd 0.0000	time 0.1956 (0.2340)	loss 0.8384 (0.8710)	grad_norm 0.4048 (0.3877)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:52:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:29 lr 0.000072	 wd 0.0000	time 0.2316 (0.2327)	loss 0.7637 (0.8713)	grad_norm 0.3694 (0.3876)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:52:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:05 lr 0.000072	 wd 0.0000	time 0.2169 (0.2316)	loss 0.8774 (0.8715)	grad_norm 0.3761 (0.3876)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:52:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:42 lr 0.000072	 wd 0.0000	time 0.2023 (0.2310)	loss 0.9458 (0.8714)	grad_norm 0.4037 (0.3877)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:53:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:19 lr 0.000072	 wd 0.0000	time 0.2153 (0.2314)	loss 0.9370 (0.8714)	grad_norm 0.3930 (0.3878)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:53:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:55 lr 0.000072	 wd 0.0000	time 0.1925 (0.2308)	loss 0.8687 (0.8718)	grad_norm 0.3925 (0.3880)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:54:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:32 lr 0.000071	 wd 0.0000	time 0.1809 (0.2299)	loss 0.8574 (0.8717)	grad_norm 0.4047 (0.3879)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:54:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:09 lr 0.000071	 wd 0.0000	time 0.2762 (0.2292)	loss 0.8687 (0.8722)	grad_norm 0.3817 (0.3879)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:54:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:46 lr 0.000071	 wd 0.0000	time 0.1956 (0.2298)	loss 0.9282 (0.8718)	grad_norm 0.3820 (0.3879)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:55:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:23 lr 0.000071	 wd 0.0000	time 0.1959 (0.2296)	loss 0.8613 (0.8722)	grad_norm 0.3809 (0.3879)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:55:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000071	 wd 0.0000	time 0.1605 (0.2280)	loss 0.9824 (0.8717)	grad_norm 0.3885 (0.3880)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:55:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 10 training takes 0:09:34
[2024-08-02 10:55:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 18.162 (18.162)	Loss 0.3552 (0.3552)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 10:56:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.226 Acc@5 97.652
[2024-08-02 10:56:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-02 10:56:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.24%
[2024-08-02 10:56:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][0/2502]	eta 1 day, 0:01:32 lr 0.000071	 wd 0.0000	time 34.5694 (34.5694)	loss 0.8018 (0.8018)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:56:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:22:24 lr 0.000070	 wd 0.0000	time 0.1767 (0.5599)	loss 0.8867 (0.8668)	grad_norm 0.3861 (0.3887)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:57:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:14:44 lr 0.000070	 wd 0.0000	time 0.1912 (0.3842)	loss 0.8970 (0.8691)	grad_norm 0.4049 (0.3890)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:57:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:12:02 lr 0.000070	 wd 0.0000	time 0.2412 (0.3283)	loss 0.9800 (0.8701)	grad_norm 0.4022 (0.3897)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:58:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:10:38 lr 0.000070	 wd 0.0000	time 0.2366 (0.3037)	loss 0.9395 (0.8681)	grad_norm 0.3976 (0.3893)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 10:58:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:09:29 lr 0.000070	 wd 0.0000	time 0.1853 (0.2845)	loss 0.7627 (0.8675)	grad_norm 0.3770 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7964MB
[2024-08-02 10:58:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:37 lr 0.000069	 wd 0.0000	time 0.2024 (0.2721)	loss 1.0537 (0.8658)	grad_norm 0.3830 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7964MB
[2024-08-02 10:59:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:07:54 lr 0.000069	 wd 0.0000	time 0.2089 (0.2632)	loss 0.8677 (0.8682)	grad_norm 0.3928 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7964MB
[2024-08-02 10:59:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:07:21 lr 0.000069	 wd 0.0000	time 0.2125 (0.2595)	loss 0.8984 (0.8692)	grad_norm 0.3934 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7964MB
[2024-08-02 10:59:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:06:50 lr 0.000069	 wd 0.0000	time 0.1890 (0.2565)	loss 0.9888 (0.8695)	grad_norm 0.4007 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7964MB
[2024-08-02 11:00:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:18 lr 0.000069	 wd 0.0000	time 0.1994 (0.2522)	loss 0.8242 (0.8708)	grad_norm 0.3877 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7964MB
[2024-08-02 11:00:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:48 lr 0.000069	 wd 0.0000	time 0.2390 (0.2486)	loss 0.7954 (0.8712)	grad_norm 0.3854 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7964MB
[2024-08-02 11:00:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:20 lr 0.000068	 wd 0.0000	time 0.1963 (0.2464)	loss 0.9346 (0.8715)	grad_norm 0.3942 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7964MB
[2024-08-02 11:01:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:04:56 lr 0.000068	 wd 0.0000	time 0.1738 (0.2465)	loss 0.7397 (0.8718)	grad_norm 0.3766 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7964MB
[2024-08-02 11:01:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:29 lr 0.000068	 wd 0.0000	time 0.2184 (0.2443)	loss 0.8457 (0.8723)	grad_norm 0.4140 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7964MB
[2024-08-02 11:02:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:04:02 lr 0.000068	 wd 0.0000	time 0.2335 (0.2422)	loss 0.9556 (0.8721)	grad_norm 0.3974 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-02 11:02:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:36 lr 0.000068	 wd 0.0000	time 0.2055 (0.2404)	loss 0.9238 (0.8721)	grad_norm 0.4211 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-02 11:02:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:13 lr 0.000067	 wd 0.0000	time 0.1814 (0.2408)	loss 0.7842 (0.8724)	grad_norm 0.3931 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-02 11:03:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:48 lr 0.000067	 wd 0.0000	time 0.2161 (0.2397)	loss 1.1074 (0.8731)	grad_norm 0.3867 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-02 11:03:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:23 lr 0.000067	 wd 0.0000	time 0.1969 (0.2384)	loss 0.7705 (0.8736)	grad_norm 0.3764 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-02 11:03:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:01:59 lr 0.000067	 wd 0.0000	time 0.1826 (0.2372)	loss 0.9165 (0.8733)	grad_norm 0.3855 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-02 11:04:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:35 lr 0.000067	 wd 0.0000	time 0.2095 (0.2365)	loss 0.8506 (0.8730)	grad_norm 0.4063 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-02 11:04:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:11 lr 0.000066	 wd 0.0000	time 0.1587 (0.2367)	loss 0.8970 (0.8730)	grad_norm 0.4025 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-02 11:05:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:47 lr 0.000066	 wd 0.0000	time 0.1892 (0.2356)	loss 0.8672 (0.8731)	grad_norm 0.3893 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-02 11:05:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:23 lr 0.000066	 wd 0.0000	time 0.2021 (0.2347)	loss 0.8735 (0.8734)	grad_norm 0.3816 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-02 11:05:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000066	 wd 0.0000	time 0.1650 (0.2330)	loss 1.0479 (0.8726)	grad_norm 0.3970 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 11:05:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 11 training takes 0:09:47
[2024-08-02 11:06:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 37.974 (37.974)	Loss 0.3511 (0.3511)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 11:06:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.210 Acc@5 97.634
[2024-08-02 11:06:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-02 11:06:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.24%
[2024-08-02 11:06:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][0/2502]	eta 11:29:25 lr 0.000066	 wd 0.0000	time 16.5328 (16.5328)	loss 0.8979 (0.8979)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:07:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:14:56 lr 0.000066	 wd 0.0000	time 0.2408 (0.3734)	loss 0.8198 (0.8601)	grad_norm 0.4071 (0.3928)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:07:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:12:54 lr 0.000065	 wd 0.0000	time 0.2038 (0.3364)	loss 0.8535 (0.8662)	grad_norm 0.3949 (0.3910)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:08:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:47 lr 0.000065	 wd 0.0000	time 0.1851 (0.2943)	loss 0.9038 (0.8756)	grad_norm 0.4240 (0.3912)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:08:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:32 lr 0.000065	 wd 0.0000	time 0.1919 (0.2725)	loss 0.8369 (0.8770)	grad_norm 0.3829 (0.3914)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:08:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:08:38 lr 0.000065	 wd 0.0000	time 0.1851 (0.2591)	loss 0.7598 (0.8761)	grad_norm 0.3912 (0.3911)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:09:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:08:05 lr 0.000065	 wd 0.0000	time 0.2647 (0.2551)	loss 0.7695 (0.8760)	grad_norm 0.3946 (0.3914)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:09:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:31 lr 0.000064	 wd 0.0000	time 0.2162 (0.2504)	loss 0.8086 (0.8756)	grad_norm 0.3813 (0.3910)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:09:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:06:58 lr 0.000064	 wd 0.0000	time 0.1965 (0.2457)	loss 0.8931 (0.8744)	grad_norm 0.3792 (0.3908)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:10:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:27 lr 0.000064	 wd 0.0000	time 0.2180 (0.2418)	loss 0.7954 (0.8737)	grad_norm 0.4035 (0.3913)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:10:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:00 lr 0.000064	 wd 0.0000	time 0.2880 (0.2399)	loss 0.9146 (0.8737)	grad_norm 0.3860 (0.3913)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:11:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:37 lr 0.000064	 wd 0.0000	time 0.2939 (0.2405)	loss 0.7378 (0.8736)	grad_norm 0.3768 (0.3912)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:11:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:10 lr 0.000063	 wd 0.0000	time 0.1884 (0.2386)	loss 0.8857 (0.8729)	grad_norm 0.3977 (0.3912)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:11:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:44 lr 0.000063	 wd 0.0000	time 0.2085 (0.2367)	loss 0.7832 (0.8731)	grad_norm 0.4043 (0.3908)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:12:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:18 lr 0.000063	 wd 0.0000	time 0.1986 (0.2349)	loss 0.9336 (0.8732)	grad_norm 0.3874 (0.3908)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:12:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:03:56 lr 0.000063	 wd 0.0000	time 0.1862 (0.2361)	loss 0.8276 (0.8741)	grad_norm 0.3910 (0.3910)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:12:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:31 lr 0.000063	 wd 0.0000	time 0.1899 (0.2350)	loss 0.8672 (0.8735)	grad_norm 0.3801 (0.3909)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:13:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:07 lr 0.000062	 wd 0.0000	time 0.1804 (0.2337)	loss 0.8467 (0.8736)	grad_norm 0.3796 (0.3912)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:13:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:43 lr 0.000062	 wd 0.0000	time 0.1839 (0.2324)	loss 0.7983 (0.8737)	grad_norm 0.3880 (0.3915)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:14:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:19 lr 0.000062	 wd 0.0000	time 0.2387 (0.2321)	loss 0.8330 (0.8734)	grad_norm 0.3906 (0.3914)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:14:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:01:56 lr 0.000062	 wd 0.0000	time 0.1853 (0.2328)	loss 0.8223 (0.8737)	grad_norm 0.3968 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-02 11:14:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:33 lr 0.000062	 wd 0.0000	time 0.2180 (0.2320)	loss 0.8428 (0.8741)	grad_norm 0.3938 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-02 11:15:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:09 lr 0.000061	 wd 0.0000	time 0.1717 (0.2312)	loss 0.8955 (0.8743)	grad_norm 0.4019 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-02 11:15:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:46 lr 0.000061	 wd 0.0000	time 0.1869 (0.2309)	loss 0.8740 (0.8739)	grad_norm 0.3659 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-02 11:15:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:23 lr 0.000061	 wd 0.0000	time 0.1998 (0.2312)	loss 0.8589 (0.8732)	grad_norm 0.3941 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-02 11:16:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000061	 wd 0.0000	time 0.1783 (0.2298)	loss 0.8984 (0.8730)	grad_norm 0.3994 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 11:16:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 12 training takes 0:09:39
[2024-08-02 11:16:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 19.125 (19.125)	Loss 0.3491 (0.3491)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 11:16:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.224 Acc@5 97.678
[2024-08-02 11:16:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-02 11:16:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.24%
[2024-08-02 11:17:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][0/2502]	eta 18:10:08 lr 0.000061	 wd 0.0000	time 26.1425 (26.1425)	loss 0.8335 (0.8335)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:17:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:19:41 lr 0.000061	 wd 0.0000	time 0.1845 (0.4920)	loss 0.7852 (0.8621)	grad_norm 0.3832 (0.3886)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:18:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:13:26 lr 0.000060	 wd 0.0000	time 0.1996 (0.3501)	loss 0.7827 (0.8706)	grad_norm 0.4010 (0.3894)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:18:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:11:08 lr 0.000060	 wd 0.0000	time 0.1946 (0.3036)	loss 0.7793 (0.8648)	grad_norm 0.4000 (0.3901)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:18:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:09:54 lr 0.000060	 wd 0.0000	time 0.2737 (0.2828)	loss 0.7515 (0.8662)	grad_norm 0.4035 (0.3908)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:19:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:09:06 lr 0.000060	 wd 0.0000	time 0.2075 (0.2727)	loss 0.8408 (0.8668)	grad_norm 0.3881 (0.3914)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:19:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:18 lr 0.000060	 wd 0.0000	time 0.2155 (0.2621)	loss 0.7988 (0.8677)	grad_norm 0.3861 (0.3922)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:19:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:07:40 lr 0.000059	 wd 0.0000	time 0.2060 (0.2554)	loss 1.0039 (0.8681)	grad_norm 0.4241 (0.3922)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:20:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:05 lr 0.000059	 wd 0.0000	time 0.2534 (0.2499)	loss 0.8999 (0.8682)	grad_norm 0.3941 (0.3923)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:20:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:06:37 lr 0.000059	 wd 0.0000	time 0.1984 (0.2484)	loss 0.9155 (0.8691)	grad_norm 0.3844 (0.3928)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:20:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:11 lr 0.000059	 wd 0.0000	time 0.1912 (0.2471)	loss 0.9536 (0.8701)	grad_norm 0.4009 (0.3931)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:21:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:42 lr 0.000059	 wd 0.0000	time 0.1827 (0.2440)	loss 0.8486 (0.8696)	grad_norm 0.3858 (0.3929)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:21:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:14 lr 0.000058	 wd 0.0000	time 0.1998 (0.2412)	loss 0.9536 (0.8699)	grad_norm 0.4079 (0.3929)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:22:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:04:48 lr 0.000058	 wd 0.0000	time 0.2065 (0.2398)	loss 0.8750 (0.8705)	grad_norm 0.4045 (0.3931)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:22:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:23 lr 0.000058	 wd 0.0000	time 0.1966 (0.2394)	loss 1.0381 (0.8702)	grad_norm 0.3805 (0.3932)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:22:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:03:58 lr 0.000058	 wd 0.0000	time 0.1983 (0.2376)	loss 0.8867 (0.8703)	grad_norm 0.4028 (0.3933)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:23:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:33 lr 0.000058	 wd 0.0000	time 0.1963 (0.2362)	loss 0.8149 (0.8707)	grad_norm 0.3729 (0.3934)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:23:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:08 lr 0.000057	 wd 0.0000	time 0.2172 (0.2349)	loss 0.8130 (0.8707)	grad_norm 0.3801 (0.3934)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:23:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:45 lr 0.000057	 wd 0.0000	time 0.2794 (0.2356)	loss 0.8428 (0.8708)	grad_norm 0.4147 (0.3936)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:24:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:21 lr 0.000057	 wd 0.0000	time 0.2127 (0.2353)	loss 0.7969 (0.8696)	grad_norm 0.4099 (0.3936)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:24:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:57 lr 0.000057	 wd 0.0000	time 0.1939 (0.2343)	loss 0.8506 (0.8704)	grad_norm 0.3791 (0.3937)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:25:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:33 lr 0.000057	 wd 0.0000	time 0.2147 (0.2332)	loss 0.8613 (0.8709)	grad_norm 0.3565 (0.3936)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:25:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:10 lr 0.000056	 wd 0.0000	time 0.2142 (0.2329)	loss 0.9478 (0.8710)	grad_norm 0.4089 (0.3936)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:25:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:47 lr 0.000056	 wd 0.0000	time 0.1941 (0.2332)	loss 0.8027 (0.8706)	grad_norm 0.3864 (0.3936)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:26:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:23 lr 0.000056	 wd 0.0000	time 0.1758 (0.2325)	loss 0.8804 (0.8710)	grad_norm 0.3689 (0.3937)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:26:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000056	 wd 0.0000	time 0.1658 (0.2308)	loss 0.8062 (0.8710)	grad_norm 0.3852 (0.3937)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:26:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 13 training takes 0:09:41
[2024-08-02 11:27:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 31.978 (31.978)	Loss 0.3494 (0.3494)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 11:27:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.280 Acc@5 97.692
[2024-08-02 11:27:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-02 11:27:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.28%
[2024-08-02 11:27:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saving......
[2024-08-02 11:27:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-02 11:27:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][0/2502]	eta 11:31:42 lr 0.000056	 wd 0.0000	time 16.5876 (16.5876)	loss 0.9668 (0.9668)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:27:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:14:57 lr 0.000055	 wd 0.0000	time 0.1943 (0.3736)	loss 0.8438 (0.8676)	grad_norm 0.3982 (0.3952)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:28:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:11:15 lr 0.000055	 wd 0.0000	time 0.1872 (0.2936)	loss 0.8320 (0.8687)	grad_norm 0.3859 (0.3949)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:28:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:10:17 lr 0.000055	 wd 0.0000	time 0.1980 (0.2806)	loss 1.1064 (0.8711)	grad_norm 0.3850 (0.3940)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:29:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:09:14 lr 0.000055	 wd 0.0000	time 0.2227 (0.2640)	loss 1.0713 (0.8702)	grad_norm 0.3881 (0.3950)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:29:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:08:28 lr 0.000055	 wd 0.0000	time 0.2006 (0.2538)	loss 0.9209 (0.8702)	grad_norm 0.3730 (0.3947)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:29:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:07:48 lr 0.000054	 wd 0.0000	time 0.1836 (0.2463)	loss 0.8369 (0.8705)	grad_norm 0.4278 (0.3950)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:30:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:20 lr 0.000054	 wd 0.0000	time 0.1872 (0.2444)	loss 0.7915 (0.8695)	grad_norm 0.3951 (0.3956)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:30:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:06:52 lr 0.000054	 wd 0.0000	time 0.2064 (0.2423)	loss 0.7920 (0.8697)	grad_norm 0.3855 (0.3955)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:30:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:22 lr 0.000054	 wd 0.0000	time 0.1837 (0.2390)	loss 0.8604 (0.8694)	grad_norm 0.4174 (0.3956)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:31:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:05:55 lr 0.000054	 wd 0.0000	time 0.1961 (0.2367)	loss 0.9111 (0.8687)	grad_norm 0.4264 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7964MB
[2024-08-02 11:31:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:29 lr 0.000053	 wd 0.0000	time 0.2153 (0.2351)	loss 0.8301 (0.8685)	grad_norm 0.3752 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7964MB
[2024-08-02 11:32:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:06 lr 0.000053	 wd 0.0000	time 0.3676 (0.2353)	loss 0.8652 (0.8684)	grad_norm 0.4004 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7964MB
[2024-08-02 11:32:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:04:41 lr 0.000053	 wd 0.0000	time 0.2168 (0.2339)	loss 1.0605 (0.8682)	grad_norm 0.4061 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7964MB
[2024-08-02 11:32:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:16 lr 0.000053	 wd 0.0000	time 0.1994 (0.2325)	loss 0.9004 (0.8685)	grad_norm 0.3748 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7964MB
[2024-08-02 11:33:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:03:51 lr 0.000053	 wd 0.0000	time 0.1731 (0.2311)	loss 0.8477 (0.8689)	grad_norm 0.4021 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-02 11:33:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:28 lr 0.000052	 wd 0.0000	time 0.2085 (0.2310)	loss 0.8525 (0.8686)	grad_norm 0.4083 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-02 11:33:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:05 lr 0.000052	 wd 0.0000	time 0.2282 (0.2316)	loss 1.0137 (0.8691)	grad_norm 0.4289 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-02 11:34:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:41 lr 0.000052	 wd 0.0000	time 0.2209 (0.2305)	loss 0.6890 (0.8693)	grad_norm 0.3924 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-02 11:34:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:18 lr 0.000052	 wd 0.0000	time 0.1778 (0.2297)	loss 0.8271 (0.8691)	grad_norm 0.3930 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-02 11:35:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:01:55 lr 0.000052	 wd 0.0000	time 0.1905 (0.2295)	loss 0.7886 (0.8690)	grad_norm 0.3967 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-02 11:35:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:32 lr 0.000051	 wd 0.0000	time 0.1748 (0.2302)	loss 0.9121 (0.8691)	grad_norm 0.3898 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-02 11:35:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:09 lr 0.000051	 wd 0.0000	time 0.1806 (0.2296)	loss 0.8652 (0.8697)	grad_norm 0.3836 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-02 11:36:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:46 lr 0.000051	 wd 0.0000	time 0.2274 (0.2289)	loss 0.8433 (0.8695)	grad_norm 0.4043 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-02 11:36:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:23 lr 0.000051	 wd 0.0000	time 0.1888 (0.2284)	loss 0.9570 (0.8701)	grad_norm 0.3996 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-02 11:36:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000051	 wd 0.0000	time 0.1674 (0.2272)	loss 0.8789 (0.8703)	grad_norm 0.4032 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 11:36:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 14 training takes 0:09:35
[2024-08-02 11:37:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 23.288 (23.288)	Loss 0.3467 (0.3467)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 11:37:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.242 Acc@5 97.666
[2024-08-02 11:37:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-02 11:37:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.28%
[2024-08-02 11:37:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][0/2502]	eta 10:56:38 lr 0.000051	 wd 0.0000	time 15.7468 (15.7468)	loss 0.7905 (0.7905)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:38:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:15:35 lr 0.000050	 wd 0.0000	time 0.1783 (0.3895)	loss 0.9761 (0.8757)	grad_norm 0.4023 (0.3955)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:38:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:12:06 lr 0.000050	 wd 0.0000	time 0.1888 (0.3157)	loss 1.0078 (0.8717)	grad_norm 0.3988 (0.3976)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:38:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:10:17 lr 0.000050	 wd 0.0000	time 0.1875 (0.2805)	loss 0.9180 (0.8702)	grad_norm 0.3884 (0.3977)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:39:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:09:12 lr 0.000050	 wd 0.0000	time 0.1924 (0.2630)	loss 1.0107 (0.8714)	grad_norm 0.4080 (0.3977)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:39:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:08:23 lr 0.000049	 wd 0.0000	time 0.1770 (0.2515)	loss 0.7808 (0.8732)	grad_norm 0.4057 (0.3981)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:40:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:07:52 lr 0.000049	 wd 0.0000	time 0.2005 (0.2485)	loss 0.8369 (0.8726)	grad_norm 0.4132 (0.3977)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:40:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:23 lr 0.000049	 wd 0.0000	time 0.2088 (0.2464)	loss 0.8130 (0.8700)	grad_norm 0.3988 (0.3979)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:40:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:06:51 lr 0.000049	 wd 0.0000	time 0.2122 (0.2421)	loss 1.0215 (0.8704)	grad_norm 0.4048 (0.3979)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:41:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:21 lr 0.000049	 wd 0.0000	time 0.1780 (0.2384)	loss 0.7988 (0.8705)	grad_norm 0.4159 (0.3983)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:41:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:05:56 lr 0.000048	 wd 0.0000	time 0.2397 (0.2375)	loss 0.9180 (0.8701)	grad_norm 0.3890 (0.3985)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:41:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:33 lr 0.000048	 wd 0.0000	time 0.1739 (0.2378)	loss 0.9058 (0.8681)	grad_norm 0.4178 (0.3980)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:42:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:06 lr 0.000048	 wd 0.0000	time 0.2214 (0.2358)	loss 0.8013 (0.8691)	grad_norm 0.3841 (0.3978)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:42:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:04:41 lr 0.000048	 wd 0.0000	time 0.1909 (0.2338)	loss 0.9067 (0.8686)	grad_norm 0.3859 (0.3981)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:42:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:16 lr 0.000048	 wd 0.0000	time 0.2225 (0.2326)	loss 0.7817 (0.8691)	grad_norm 0.4058 (0.3982)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:43:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:03:53 lr 0.000047	 wd 0.0000	time 0.1609 (0.2328)	loss 0.9175 (0.8686)	grad_norm 0.3914 (0.3984)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:43:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:29 lr 0.000047	 wd 0.0000	time 0.1800 (0.2320)	loss 0.9302 (0.8686)	grad_norm 0.3952 (0.3986)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:44:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:05 lr 0.000047	 wd 0.0000	time 0.1869 (0.2308)	loss 0.7852 (0.8689)	grad_norm 0.3833 (0.3986)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:44:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:41 lr 0.000047	 wd 0.0000	time 0.1968 (0.2297)	loss 1.0156 (0.8695)	grad_norm 0.4313 (0.3986)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:44:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:18 lr 0.000047	 wd 0.0000	time 0.2082 (0.2296)	loss 0.9487 (0.8689)	grad_norm 0.4110 (0.3986)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:45:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:01:55 lr 0.000046	 wd 0.0000	time 0.1768 (0.2304)	loss 1.0215 (0.8698)	grad_norm 0.4299 (0.3985)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:45:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:32 lr 0.000046	 wd 0.0000	time 0.2351 (0.2298)	loss 0.8281 (0.8697)	grad_norm 0.3906 (0.3984)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:45:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:09 lr 0.000046	 wd 0.0000	time 0.2184 (0.2290)	loss 0.9116 (0.8700)	grad_norm 0.3897 (0.3983)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:46:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:46 lr 0.000046	 wd 0.0000	time 0.2031 (0.2288)	loss 0.8848 (0.8700)	grad_norm 0.4228 (0.3984)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:46:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:23 lr 0.000046	 wd 0.0000	time 0.1882 (0.2292)	loss 0.8979 (0.8700)	grad_norm 0.3970 (0.3986)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:47:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000045	 wd 0.0000	time 0.1582 (0.2277)	loss 1.0645 (0.8703)	grad_norm 0.4000 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 11:47:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 15 training takes 0:09:34
[2024-08-02 11:47:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_15.pth saving......
[2024-08-02 11:47:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_15.pth saved !!!
[2024-08-02 11:47:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 17.912 (17.912)	Loss 0.3530 (0.3530)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 11:47:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.300 Acc@5 97.692
[2024-08-02 11:47:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-02 11:47:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.30%
[2024-08-02 11:47:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saving......
[2024-08-02 11:47:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-02 11:48:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][0/2502]	eta 22:07:25 lr 0.000045	 wd 0.0000	time 31.8326 (31.8326)	loss 0.7466 (0.7466)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:48:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:21:10 lr 0.000045	 wd 0.0000	time 0.1876 (0.5290)	loss 0.9712 (0.8806)	grad_norm 0.4075 (0.4014)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:48:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:14:08 lr 0.000045	 wd 0.0000	time 0.1993 (0.3687)	loss 0.8696 (0.8705)	grad_norm 0.4144 (0.3999)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:49:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:11:34 lr 0.000045	 wd 0.0000	time 0.1739 (0.3152)	loss 0.9116 (0.8711)	grad_norm 0.3913 (0.3987)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:49:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:10:31 lr 0.000045	 wd 0.0000	time 0.2839 (0.3006)	loss 0.8906 (0.8704)	grad_norm 0.4049 (0.3988)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:50:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:09:56 lr 0.000044	 wd 0.0000	time 0.1792 (0.2978)	loss 0.9692 (0.8701)	grad_norm 0.3864 (0.3989)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:50:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:57 lr 0.000044	 wd 0.0000	time 0.1808 (0.2828)	loss 0.9155 (0.8704)	grad_norm 0.3913 (0.3993)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:50:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:08:09 lr 0.000044	 wd 0.0000	time 0.1918 (0.2717)	loss 0.8921 (0.8709)	grad_norm 0.3953 (0.3991)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:51:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:07:34 lr 0.000044	 wd 0.0000	time 0.2284 (0.2673)	loss 0.8730 (0.8702)	grad_norm 0.3997 (0.3991)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:51:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:07:05 lr 0.000043	 wd 0.0000	time 0.2024 (0.2658)	loss 0.7949 (0.8718)	grad_norm 0.4006 (0.3994)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:52:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:06:30 lr 0.000043	 wd 0.0000	time 0.1784 (0.2601)	loss 0.8579 (0.8719)	grad_norm 0.4081 (0.3997)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:52:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:58 lr 0.000043	 wd 0.0000	time 0.2360 (0.2558)	loss 0.9561 (0.8723)	grad_norm 0.4149 (0.3999)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:52:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:29 lr 0.000043	 wd 0.0000	time 0.2001 (0.2528)	loss 0.8979 (0.8719)	grad_norm 0.4036 (0.3997)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:53:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:05:02 lr 0.000043	 wd 0.0000	time 0.3210 (0.2518)	loss 0.9678 (0.8713)	grad_norm 0.4009 (0.3998)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:53:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:34 lr 0.000042	 wd 0.0000	time 0.2201 (0.2491)	loss 0.7803 (0.8706)	grad_norm 0.3787 (0.3998)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:53:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:04:07 lr 0.000042	 wd 0.0000	time 0.2152 (0.2466)	loss 0.8101 (0.8702)	grad_norm 0.3766 (0.4000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:54:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:40 lr 0.000042	 wd 0.0000	time 0.2059 (0.2443)	loss 0.7832 (0.8700)	grad_norm 0.3970 (0.3999)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:54:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:15 lr 0.000042	 wd 0.0000	time 0.2073 (0.2434)	loss 0.8589 (0.8698)	grad_norm 0.4032 (0.4001)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:54:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:50 lr 0.000042	 wd 0.0000	time 0.2187 (0.2431)	loss 1.0156 (0.8699)	grad_norm 0.3825 (0.4002)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:55:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:25 lr 0.000041	 wd 0.0000	time 0.2086 (0.2417)	loss 0.9751 (0.8690)	grad_norm 0.3979 (0.4001)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:55:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:02:00 lr 0.000041	 wd 0.0000	time 0.2377 (0.2402)	loss 0.8350 (0.8688)	grad_norm 0.4038 (0.4001)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:56:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:36 lr 0.000041	 wd 0.0000	time 0.2098 (0.2393)	loss 0.6748 (0.8684)	grad_norm 0.3928 (0.4003)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:56:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:12 lr 0.000041	 wd 0.0000	time 0.2934 (0.2393)	loss 0.7769 (0.8685)	grad_norm 0.3979 (0.4003)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:56:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:48 lr 0.000041	 wd 0.0000	time 0.1884 (0.2383)	loss 0.6772 (0.8679)	grad_norm 0.4197 (0.4002)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:57:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:24 lr 0.000040	 wd 0.0000	time 0.1871 (0.2372)	loss 0.7715 (0.8678)	grad_norm 0.4053 (0.4001)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:57:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1630 (0.2353)	loss 0.8330 (0.8675)	grad_norm 0.4381 (0.4002)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:57:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 16 training takes 0:09:53
[2024-08-02 11:58:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 38.010 (38.010)	Loss 0.3501 (0.3501)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 11:58:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.230 Acc@5 97.658
[2024-08-02 11:58:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-02 11:58:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.30%
[2024-08-02 11:58:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][0/2502]	eta 10:50:27 lr 0.000040	 wd 0.0000	time 15.5987 (15.5987)	loss 0.7607 (0.7607)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:59:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:14:53 lr 0.000040	 wd 0.0000	time 0.2235 (0.3721)	loss 0.9717 (0.8682)	grad_norm 0.3800 (0.3992)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:59:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:12:21 lr 0.000040	 wd 0.0000	time 0.2042 (0.3221)	loss 0.8545 (0.8720)	grad_norm 0.3710 (0.4001)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 11:59:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:29 lr 0.000040	 wd 0.0000	time 0.1888 (0.2859)	loss 0.8813 (0.8683)	grad_norm 0.4226 (0.4007)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:00:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:09:20 lr 0.000039	 wd 0.0000	time 0.1937 (0.2666)	loss 0.9355 (0.8668)	grad_norm 0.3837 (0.4008)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:00:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:08:30 lr 0.000039	 wd 0.0000	time 0.2054 (0.2550)	loss 0.7471 (0.8649)	grad_norm 0.4369 (0.4009)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:00:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:07:56 lr 0.000039	 wd 0.0000	time 0.2649 (0.2508)	loss 0.8013 (0.8663)	grad_norm 0.4221 (0.4012)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:01:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:28 lr 0.000039	 wd 0.0000	time 0.1990 (0.2488)	loss 0.8838 (0.8654)	grad_norm 0.4041 (0.4012)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:01:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:06:56 lr 0.000039	 wd 0.0000	time 0.2039 (0.2445)	loss 0.7769 (0.8659)	grad_norm 0.3878 (0.4012)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:02:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:25 lr 0.000038	 wd 0.0000	time 0.1845 (0.2408)	loss 0.9780 (0.8662)	grad_norm 0.3919 (0.4009)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:02:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:05:58 lr 0.000038	 wd 0.0000	time 0.2218 (0.2384)	loss 0.9170 (0.8663)	grad_norm 0.4015 (0.4011)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:02:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:35 lr 0.000038	 wd 0.0000	time 0.1903 (0.2396)	loss 0.7368 (0.8676)	grad_norm 0.4019 (0.4012)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:03:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:09 lr 0.000038	 wd 0.0000	time 0.1995 (0.2374)	loss 0.7637 (0.8691)	grad_norm 0.4160 (0.4015)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:03:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:04:43 lr 0.000038	 wd 0.0000	time 0.2027 (0.2355)	loss 0.9043 (0.8684)	grad_norm 0.3783 (0.4014)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:03:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:17 lr 0.000037	 wd 0.0000	time 0.2038 (0.2336)	loss 0.8965 (0.8693)	grad_norm 0.3755 (0.4015)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:04:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:03:53 lr 0.000037	 wd 0.0000	time 0.2017 (0.2333)	loss 0.8579 (0.8691)	grad_norm 0.4003 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-02 12:04:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:30 lr 0.000037	 wd 0.0000	time 0.2063 (0.2335)	loss 1.0176 (0.8689)	grad_norm 0.4219 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-02 12:04:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:06 lr 0.000037	 wd 0.0000	time 0.1891 (0.2323)	loss 1.0049 (0.8690)	grad_norm 0.4013 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-02 12:05:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:42 lr 0.000037	 wd 0.0000	time 0.2199 (0.2312)	loss 0.7617 (0.8705)	grad_norm 0.4040 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-02 12:05:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:18 lr 0.000036	 wd 0.0000	time 0.2041 (0.2307)	loss 0.7461 (0.8709)	grad_norm 0.3946 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-02 12:06:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:01:56 lr 0.000036	 wd 0.0000	time 0.1939 (0.2319)	loss 0.7959 (0.8705)	grad_norm 0.3931 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-02 12:06:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:32 lr 0.000036	 wd 0.0000	time 0.1832 (0.2310)	loss 0.7964 (0.8699)	grad_norm 0.3916 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-02 12:06:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:09 lr 0.000036	 wd 0.0000	time 0.1816 (0.2302)	loss 0.9287 (0.8698)	grad_norm 0.4032 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-02 12:07:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:46 lr 0.000036	 wd 0.0000	time 0.2045 (0.2296)	loss 0.9028 (0.8694)	grad_norm 0.3915 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-02 12:07:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:23 lr 0.000035	 wd 0.0000	time 0.1852 (0.2297)	loss 0.8286 (0.8697)	grad_norm 0.4014 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-02 12:07:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1673 (0.2283)	loss 0.9087 (0.8700)	grad_norm 0.3935 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 12:07:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 17 training takes 0:09:36
[2024-08-02 12:08:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 19.794 (19.794)	Loss 0.3484 (0.3484)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 12:08:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.294 Acc@5 97.680
[2024-08-02 12:08:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-02 12:08:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.30%
[2024-08-02 12:08:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][0/2502]	eta 14:19:04 lr 0.000035	 wd 0.0000	time 20.6014 (20.6014)	loss 0.9009 (0.9009)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:09:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:17:53 lr 0.000035	 wd 0.0000	time 0.1872 (0.4468)	loss 0.9766 (0.8721)	grad_norm 0.4100 (0.4030)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:09:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:12:36 lr 0.000035	 wd 0.0000	time 0.1907 (0.3288)	loss 0.8315 (0.8680)	grad_norm 0.4164 (0.4027)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:09:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:10:36 lr 0.000035	 wd 0.0000	time 0.1985 (0.2893)	loss 0.9023 (0.8721)	grad_norm 0.4004 (0.4036)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:10:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:09:24 lr 0.000034	 wd 0.0000	time 0.2015 (0.2685)	loss 0.8003 (0.8734)	grad_norm 0.4089 (0.4033)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:10:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:08:43 lr 0.000034	 wd 0.0000	time 0.1940 (0.2613)	loss 0.6973 (0.8730)	grad_norm 0.3984 (0.4023)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:11:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:08:06 lr 0.000034	 wd 0.0000	time 0.2599 (0.2555)	loss 0.9360 (0.8697)	grad_norm 0.4128 (0.4025)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:11:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:07:29 lr 0.000034	 wd 0.0000	time 0.2362 (0.2493)	loss 0.9326 (0.8668)	grad_norm 0.3826 (0.4021)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:11:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:06:56 lr 0.000034	 wd 0.0000	time 0.2036 (0.2445)	loss 1.0576 (0.8651)	grad_norm 0.3901 (0.4021)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:12:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:06:27 lr 0.000033	 wd 0.0000	time 0.2419 (0.2420)	loss 0.9419 (0.8657)	grad_norm 0.4134 (0.4023)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:12:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:04 lr 0.000033	 wd 0.0000	time 0.2083 (0.2428)	loss 0.8374 (0.8666)	grad_norm 0.4019 (0.4024)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:12:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:36 lr 0.000033	 wd 0.0000	time 0.1924 (0.2400)	loss 0.7856 (0.8677)	grad_norm 0.3950 (0.4023)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:13:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:09 lr 0.000033	 wd 0.0000	time 0.1801 (0.2377)	loss 0.8892 (0.8672)	grad_norm 0.3952 (0.4024)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:13:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:04:43 lr 0.000033	 wd 0.0000	time 0.1928 (0.2358)	loss 0.8721 (0.8686)	grad_norm 0.3978 (0.4026)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:14:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:19 lr 0.000032	 wd 0.0000	time 0.1664 (0.2359)	loss 0.9849 (0.8680)	grad_norm 0.4082 (0.4028)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:14:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:03:55 lr 0.000032	 wd 0.0000	time 0.1768 (0.2348)	loss 0.8398 (0.8689)	grad_norm 0.4120 (0.4027)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:14:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:30 lr 0.000032	 wd 0.0000	time 0.2311 (0.2335)	loss 0.8584 (0.8682)	grad_norm 0.4020 (0.4029)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:15:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:06 lr 0.000032	 wd 0.0000	time 0.1903 (0.2321)	loss 0.9712 (0.8684)	grad_norm 0.4160 (0.4029)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:15:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:42 lr 0.000032	 wd 0.0000	time 0.2334 (0.2316)	loss 0.8276 (0.8684)	grad_norm 0.4219 (0.4030)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:15:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:20 lr 0.000032	 wd 0.0000	time 0.1893 (0.2333)	loss 0.8203 (0.8681)	grad_norm 0.4077 (0.4032)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:16:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:01:56 lr 0.000031	 wd 0.0000	time 0.1809 (0.2324)	loss 0.8740 (0.8687)	grad_norm 0.3774 (0.4033)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:16:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:33 lr 0.000031	 wd 0.0000	time 0.1953 (0.2315)	loss 0.7324 (0.8688)	grad_norm 0.4100 (0.4034)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:17:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:09 lr 0.000031	 wd 0.0000	time 0.1819 (0.2310)	loss 0.8813 (0.8686)	grad_norm 0.3939 (0.4036)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:17:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:46 lr 0.000031	 wd 0.0000	time 0.1986 (0.2315)	loss 0.7515 (0.8689)	grad_norm 0.3757 (0.4036)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:17:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:23 lr 0.000031	 wd 0.0000	time 0.2070 (0.2310)	loss 0.8638 (0.8690)	grad_norm 0.4088 (0.4038)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:18:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000030	 wd 0.0000	time 0.1653 (0.2293)	loss 0.8604 (0.8690)	grad_norm 0.4073 (0.4038)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:18:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 18 training takes 0:09:38
[2024-08-02 12:18:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 32.672 (32.672)	Loss 0.3491 (0.3491)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 12:19:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.270 Acc@5 97.680
[2024-08-02 12:19:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-02 12:19:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.30%
[2024-08-02 12:19:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][0/2502]	eta 11:54:02 lr 0.000030	 wd 0.0000	time 17.1233 (17.1233)	loss 0.8560 (0.8560)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:19:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:15:09 lr 0.000030	 wd 0.0000	time 0.1962 (0.3784)	loss 1.0156 (0.8607)	grad_norm 0.4053 (0.4042)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:20:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:11:14 lr 0.000030	 wd 0.0000	time 0.1973 (0.2932)	loss 0.6870 (0.8584)	grad_norm 0.4295 (0.4041)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:20:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:10:56 lr 0.000030	 wd 0.0000	time 0.2375 (0.2982)	loss 0.9707 (0.8636)	grad_norm 0.4064 (0.4039)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:20:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:09:42 lr 0.000030	 wd 0.0000	time 0.1849 (0.2769)	loss 0.8154 (0.8660)	grad_norm 0.3879 (0.4036)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:21:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:08:46 lr 0.000029	 wd 0.0000	time 0.2149 (0.2630)	loss 0.9346 (0.8659)	grad_norm 0.4060 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7964MB
[2024-08-02 12:21:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:02 lr 0.000029	 wd 0.0000	time 0.2016 (0.2536)	loss 0.7441 (0.8676)	grad_norm 0.3938 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7964MB
[2024-08-02 12:21:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:07:32 lr 0.000029	 wd 0.0000	time 0.2337 (0.2509)	loss 0.9727 (0.8687)	grad_norm 0.3956 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7964MB
[2024-08-02 12:22:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:07:04 lr 0.000029	 wd 0.0000	time 0.1973 (0.2492)	loss 0.8481 (0.8699)	grad_norm 0.4133 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7964MB
[2024-08-02 12:22:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:06:32 lr 0.000029	 wd 0.0000	time 0.1729 (0.2449)	loss 0.8491 (0.8696)	grad_norm 0.4013 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7964MB
[2024-08-02 12:23:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:02 lr 0.000028	 wd 0.0000	time 0.1900 (0.2416)	loss 0.9473 (0.8702)	grad_norm 0.3983 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7964MB
[2024-08-02 12:23:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:36 lr 0.000028	 wd 0.0000	time 0.2135 (0.2397)	loss 0.8159 (0.8695)	grad_norm 0.4086 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7964MB
[2024-08-02 12:23:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:11 lr 0.000028	 wd 0.0000	time 0.1889 (0.2395)	loss 0.8491 (0.8696)	grad_norm 0.4097 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7964MB
[2024-08-02 12:24:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:04:45 lr 0.000028	 wd 0.0000	time 0.2025 (0.2375)	loss 0.8179 (0.8702)	grad_norm 0.3986 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7964MB
[2024-08-02 12:24:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:19 lr 0.000028	 wd 0.0000	time 0.1735 (0.2357)	loss 0.8223 (0.8696)	grad_norm 0.4019 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7964MB
[2024-08-02 12:24:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:03:54 lr 0.000028	 wd 0.0000	time 0.1725 (0.2341)	loss 0.8750 (0.8700)	grad_norm 0.3845 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-02 12:25:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:30 lr 0.000027	 wd 0.0000	time 0.2273 (0.2337)	loss 0.8701 (0.8704)	grad_norm 0.4310 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-02 12:25:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:07 lr 0.000027	 wd 0.0000	time 0.1921 (0.2339)	loss 0.9756 (0.8703)	grad_norm 0.3992 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-02 12:26:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:43 lr 0.000027	 wd 0.0000	time 0.2233 (0.2328)	loss 0.7959 (0.8706)	grad_norm 0.3988 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-02 12:26:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:19 lr 0.000027	 wd 0.0000	time 0.2183 (0.2317)	loss 0.8320 (0.8707)	grad_norm 0.3994 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-02 12:26:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:56 lr 0.000027	 wd 0.0000	time 0.2255 (0.2314)	loss 0.9121 (0.8704)	grad_norm 0.4058 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-02 12:27:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:33 lr 0.000026	 wd 0.0000	time 0.2240 (0.2319)	loss 0.9639 (0.8701)	grad_norm 0.4056 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-02 12:27:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:09 lr 0.000026	 wd 0.0000	time 0.2030 (0.2313)	loss 0.8682 (0.8695)	grad_norm 0.4481 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-02 12:27:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:46 lr 0.000026	 wd 0.0000	time 0.1871 (0.2305)	loss 0.8945 (0.8692)	grad_norm 0.4058 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-02 12:28:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:23 lr 0.000026	 wd 0.0000	time 0.2051 (0.2298)	loss 0.9365 (0.8692)	grad_norm 0.4175 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-02 12:28:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1681 (0.2285)	loss 0.7017 (0.8691)	grad_norm 0.4073 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 12:28:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 19 training takes 0:09:41
[2024-08-02 12:29:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 21.124 (21.124)	Loss 0.3513 (0.3513)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 12:29:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.302 Acc@5 97.708
[2024-08-02 12:29:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-02 12:29:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.30%
[2024-08-02 12:29:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saving......
[2024-08-02 12:29:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-02 12:29:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][0/2502]	eta 11:39:26 lr 0.000026	 wd 0.0000	time 16.7730 (16.7730)	loss 0.8335 (0.8335)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:30:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:16:20 lr 0.000026	 wd 0.0000	time 0.3693 (0.4081)	loss 0.9780 (0.8724)	grad_norm 0.4034 (0.4085)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:30:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:12:56 lr 0.000025	 wd 0.0000	time 0.1745 (0.3373)	loss 0.9253 (0.8637)	grad_norm 0.4099 (0.4076)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:30:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:10:46 lr 0.000025	 wd 0.0000	time 0.1930 (0.2937)	loss 0.7437 (0.8599)	grad_norm 0.4126 (0.4076)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:31:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:09:31 lr 0.000025	 wd 0.0000	time 0.2103 (0.2721)	loss 0.8618 (0.8607)	grad_norm 0.4146 (0.4072)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:31:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:08:41 lr 0.000025	 wd 0.0000	time 0.2032 (0.2606)	loss 0.8535 (0.8597)	grad_norm 0.3906 (0.4079)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:31:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:08:09 lr 0.000025	 wd 0.0000	time 0.2098 (0.2573)	loss 0.7769 (0.8603)	grad_norm 0.4120 (0.4073)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:32:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:32 lr 0.000025	 wd 0.0000	time 0.1892 (0.2513)	loss 0.7729 (0.8607)	grad_norm 0.3937 (0.4075)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:32:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:06:59 lr 0.000024	 wd 0.0000	time 0.1870 (0.2464)	loss 0.9790 (0.8613)	grad_norm 0.3898 (0.4074)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:32:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:28 lr 0.000024	 wd 0.0000	time 0.2222 (0.2424)	loss 0.7349 (0.8614)	grad_norm 0.3876 (0.4075)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:33:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:03 lr 0.000024	 wd 0.0000	time 0.1958 (0.2418)	loss 0.7974 (0.8610)	grad_norm 0.3995 (0.4072)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:33:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:37 lr 0.000024	 wd 0.0000	time 0.1995 (0.2407)	loss 0.7856 (0.8613)	grad_norm 0.3932 (0.4072)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:34:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:10 lr 0.000024	 wd 0.0000	time 0.2038 (0.2383)	loss 0.7261 (0.8611)	grad_norm 0.3926 (0.4072)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:34:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:04:44 lr 0.000023	 wd 0.0000	time 0.2052 (0.2363)	loss 0.8765 (0.8612)	grad_norm 0.4079 (0.4069)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:34:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:19 lr 0.000023	 wd 0.0000	time 0.2153 (0.2353)	loss 0.9106 (0.8616)	grad_norm 0.4187 (0.4069)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:35:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:03:56 lr 0.000023	 wd 0.0000	time 0.1856 (0.2357)	loss 0.9492 (0.8613)	grad_norm 0.4097 (0.4068)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:35:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:31 lr 0.000023	 wd 0.0000	time 0.1607 (0.2344)	loss 0.9121 (0.8607)	grad_norm 0.4161 (0.4070)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:35:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:06 lr 0.000023	 wd 0.0000	time 0.1731 (0.2332)	loss 0.9375 (0.8608)	grad_norm 0.4029 (0.4068)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:36:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:42 lr 0.000023	 wd 0.0000	time 0.1999 (0.2322)	loss 0.7930 (0.8615)	grad_norm 0.4043 (0.4069)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:36:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:20 lr 0.000022	 wd 0.0000	time 0.2006 (0.2330)	loss 0.9917 (0.8621)	grad_norm 0.4191 (0.4069)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:37:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:01:56 lr 0.000022	 wd 0.0000	time 0.1814 (0.2327)	loss 0.8877 (0.8620)	grad_norm 0.3926 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-02 12:37:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:33 lr 0.000022	 wd 0.0000	time 0.1839 (0.2318)	loss 0.9126 (0.8625)	grad_norm 0.4148 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-02 12:37:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:09 lr 0.000022	 wd 0.0000	time 0.2073 (0.2309)	loss 0.8716 (0.8631)	grad_norm 0.4101 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-02 12:38:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:46 lr 0.000022	 wd 0.0000	time 0.1948 (0.2307)	loss 0.8120 (0.8639)	grad_norm 0.4305 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-02 12:38:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:23 lr 0.000022	 wd 0.0000	time 0.1666 (0.2310)	loss 0.8281 (0.8641)	grad_norm 0.4089 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-02 12:38:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1667 (0.2294)	loss 0.7759 (0.8639)	grad_norm 0.3903 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 12:38:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 20 training takes 0:09:39
[2024-08-02 12:39:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 18.274 (18.274)	Loss 0.3501 (0.3501)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 12:39:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.308 Acc@5 97.700
[2024-08-02 12:39:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-02 12:39:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.31%
[2024-08-02 12:39:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saving......
[2024-08-02 12:39:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-02 12:40:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][0/2502]	eta 21:06:18 lr 0.000021	 wd 0.0000	time 30.3671 (30.3671)	loss 0.8989 (0.8989)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:40:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:20:25 lr 0.000021	 wd 0.0000	time 0.1742 (0.5104)	loss 0.8833 (0.8771)	grad_norm 0.4009 (0.4075)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:40:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:13:45 lr 0.000021	 wd 0.0000	time 0.2000 (0.3588)	loss 0.9141 (0.8699)	grad_norm 0.3956 (0.4070)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:41:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:11:17 lr 0.000021	 wd 0.0000	time 0.1869 (0.3075)	loss 0.9087 (0.8675)	grad_norm 0.4048 (0.4076)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:41:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:10:11 lr 0.000021	 wd 0.0000	time 0.2039 (0.2909)	loss 0.9824 (0.8672)	grad_norm 0.4060 (0.4071)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:41:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:09:12 lr 0.000021	 wd 0.0000	time 0.2359 (0.2761)	loss 0.8149 (0.8674)	grad_norm 0.3976 (0.4074)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:42:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:24 lr 0.000020	 wd 0.0000	time 0.1864 (0.2653)	loss 0.8584 (0.8665)	grad_norm 0.4167 (0.4078)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:42:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:07:43 lr 0.000020	 wd 0.0000	time 0.2068 (0.2574)	loss 0.9956 (0.8666)	grad_norm 0.4241 (0.4077)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:42:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:11 lr 0.000020	 wd 0.0000	time 0.2246 (0.2538)	loss 0.9004 (0.8668)	grad_norm 0.4345 (0.4078)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:43:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:44 lr 0.000020	 wd 0.0000	time 0.2582 (0.2522)	loss 0.8110 (0.8679)	grad_norm 0.4023 (0.4075)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:43:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:13 lr 0.000020	 wd 0.0000	time 0.1892 (0.2485)	loss 0.8257 (0.8673)	grad_norm 0.3831 (0.4075)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:44:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:05:43 lr 0.000020	 wd 0.0000	time 0.1859 (0.2453)	loss 0.8750 (0.8678)	grad_norm 0.3985 (0.4076)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:44:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:15 lr 0.000019	 wd 0.0000	time 0.2025 (0.2426)	loss 0.8262 (0.8690)	grad_norm 0.4020 (0.4076)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:44:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:52 lr 0.000019	 wd 0.0000	time 0.2115 (0.2430)	loss 0.9419 (0.8685)	grad_norm 0.3928 (0.4075)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:45:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:25 lr 0.000019	 wd 0.0000	time 0.1960 (0.2412)	loss 0.8867 (0.8685)	grad_norm 0.4058 (0.4074)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:45:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:03:59 lr 0.000019	 wd 0.0000	time 0.1958 (0.2395)	loss 0.9121 (0.8683)	grad_norm 0.4031 (0.4073)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:45:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:34 lr 0.000019	 wd 0.0000	time 0.1996 (0.2377)	loss 0.8975 (0.8677)	grad_norm 0.4185 (0.4075)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:46:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:09 lr 0.000019	 wd 0.0000	time 0.1907 (0.2368)	loss 0.8774 (0.8683)	grad_norm 0.4047 (0.4076)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:46:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:46 lr 0.000018	 wd 0.0000	time 0.2603 (0.2374)	loss 0.8784 (0.8684)	grad_norm 0.4035 (0.4077)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:47:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:22 lr 0.000018	 wd 0.0000	time 0.2048 (0.2362)	loss 0.8950 (0.8686)	grad_norm 0.4016 (0.4078)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:47:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:57 lr 0.000018	 wd 0.0000	time 0.1694 (0.2350)	loss 0.7441 (0.8683)	grad_norm 0.4133 (0.4079)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:47:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:34 lr 0.000018	 wd 0.0000	time 0.1798 (0.2343)	loss 0.7676 (0.8677)	grad_norm 0.3910 (0.4081)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:48:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:10 lr 0.000018	 wd 0.0000	time 0.1761 (0.2344)	loss 0.7803 (0.8672)	grad_norm 0.4097 (0.4081)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:48:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:47 lr 0.000018	 wd 0.0000	time 0.1591 (0.2336)	loss 0.9336 (0.8672)	grad_norm 0.4067 (0.4081)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:48:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:23 lr 0.000018	 wd 0.0000	time 0.1938 (0.2327)	loss 0.8584 (0.8672)	grad_norm 0.4001 (0.4083)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:49:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000017	 wd 0.0000	time 0.1976 (0.2309)	loss 0.8960 (0.8673)	grad_norm 0.3765 (0.4083)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:49:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 21 training takes 0:09:43
[2024-08-02 12:49:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 35.209 (35.209)	Loss 0.3469 (0.3469)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 12:50:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.330 Acc@5 97.696
[2024-08-02 12:50:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-02 12:50:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.33%
[2024-08-02 12:50:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saving......
[2024-08-02 12:50:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-02 12:50:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][0/2502]	eta 11:03:36 lr 0.000017	 wd 0.0000	time 15.9137 (15.9137)	loss 0.8237 (0.8237)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:50:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:14:21 lr 0.000017	 wd 0.0000	time 0.1884 (0.3586)	loss 0.9043 (0.8722)	grad_norm 0.4157 (0.4111)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:51:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:12:05 lr 0.000017	 wd 0.0000	time 0.3805 (0.3152)	loss 0.8032 (0.8682)	grad_norm 0.3977 (0.4093)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:51:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:10:42 lr 0.000017	 wd 0.0000	time 0.1712 (0.2919)	loss 0.8633 (0.8675)	grad_norm 0.4039 (0.4095)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:51:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:09:28 lr 0.000017	 wd 0.0000	time 0.1981 (0.2706)	loss 0.7974 (0.8726)	grad_norm 0.4011 (0.4098)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:52:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:08:35 lr 0.000017	 wd 0.0000	time 0.1871 (0.2576)	loss 0.6968 (0.8705)	grad_norm 0.3907 (0.4092)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:52:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:02 lr 0.000016	 wd 0.0000	time 0.3471 (0.2535)	loss 0.9248 (0.8717)	grad_norm 0.3887 (0.4093)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:53:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:47 lr 0.000016	 wd 0.0000	time 0.1814 (0.2597)	loss 0.9756 (0.8701)	grad_norm 0.3953 (0.4097)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:53:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:07:11 lr 0.000016	 wd 0.0000	time 0.1891 (0.2533)	loss 0.8779 (0.8702)	grad_norm 0.3962 (0.4095)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:53:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:37 lr 0.000016	 wd 0.0000	time 0.1890 (0.2482)	loss 0.8291 (0.8702)	grad_norm 0.3892 (0.4098)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 12:54:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:09 lr 0.000016	 wd 0.0000	time 0.2327 (0.2458)	loss 0.8857 (0.8698)	grad_norm 0.3927 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7964MB
[2024-08-02 12:54:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:44 lr 0.000016	 wd 0.0000	time 0.2225 (0.2456)	loss 0.7681 (0.8684)	grad_norm 0.3906 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7964MB
[2024-08-02 12:54:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:16 lr 0.000016	 wd 0.0000	time 0.1819 (0.2429)	loss 0.8447 (0.8688)	grad_norm 0.4061 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7964MB
[2024-08-02 12:55:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:04:49 lr 0.000015	 wd 0.0000	time 0.1786 (0.2406)	loss 0.8638 (0.8675)	grad_norm 0.4046 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7964MB
[2024-08-02 12:55:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:22 lr 0.000015	 wd 0.0000	time 0.1928 (0.2386)	loss 0.8530 (0.8672)	grad_norm 0.4071 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7964MB
[2024-08-02 12:56:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:03:59 lr 0.000015	 wd 0.0000	time 0.1797 (0.2386)	loss 0.6880 (0.8672)	grad_norm 0.3979 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-02 12:56:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:34 lr 0.000015	 wd 0.0000	time 0.2224 (0.2381)	loss 0.8140 (0.8674)	grad_norm 0.4088 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-02 12:56:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:09 lr 0.000015	 wd 0.0000	time 0.1936 (0.2365)	loss 0.8843 (0.8669)	grad_norm 0.4172 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-02 12:57:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:45 lr 0.000015	 wd 0.0000	time 0.1691 (0.2351)	loss 0.9209 (0.8669)	grad_norm 0.4062 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-02 12:57:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:21 lr 0.000015	 wd 0.0000	time 0.2133 (0.2346)	loss 0.8823 (0.8674)	grad_norm 0.4059 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-02 12:57:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:58 lr 0.000014	 wd 0.0000	time 0.2153 (0.2355)	loss 0.9551 (0.8671)	grad_norm 0.3764 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-02 12:58:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:34 lr 0.000014	 wd 0.0000	time 0.2129 (0.2345)	loss 0.8086 (0.8674)	grad_norm 0.4103 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-02 12:58:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:10 lr 0.000014	 wd 0.0000	time 0.1866 (0.2338)	loss 0.6870 (0.8674)	grad_norm 0.4045 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-02 12:59:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:47 lr 0.000014	 wd 0.0000	time 0.2543 (0.2333)	loss 0.9307 (0.8673)	grad_norm 0.4067 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-02 12:59:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:23 lr 0.000014	 wd 0.0000	time 0.1611 (0.2338)	loss 0.7607 (0.8674)	grad_norm 0.4080 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-02 12:59:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1703 (0.2321)	loss 0.8232 (0.8669)	grad_norm 0.4242 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 12:59:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 22 training takes 0:09:48
[2024-08-02 13:00:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 19.025 (19.025)	Loss 0.3467 (0.3467)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 13:00:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.382 Acc@5 97.694
[2024-08-02 13:00:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-08-02 13:00:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.38%
[2024-08-02 13:00:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saving......
[2024-08-02 13:00:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-02 13:01:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][0/2502]	eta 21:41:27 lr 0.000014	 wd 0.0000	time 31.2099 (31.2099)	loss 0.7720 (0.7720)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:01:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:21:25 lr 0.000014	 wd 0.0000	time 0.1853 (0.5350)	loss 0.8730 (0.8664)	grad_norm 0.4159 (0.4120)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:01:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:14:12 lr 0.000013	 wd 0.0000	time 0.1719 (0.3704)	loss 0.9302 (0.8635)	grad_norm 0.4366 (0.4101)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:02:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:11:35 lr 0.000013	 wd 0.0000	time 0.1747 (0.3159)	loss 0.7642 (0.8619)	grad_norm 0.3997 (0.4099)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:02:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:10:22 lr 0.000013	 wd 0.0000	time 0.2337 (0.2960)	loss 0.9785 (0.8634)	grad_norm 0.4090 (0.4106)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:02:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:09:22 lr 0.000013	 wd 0.0000	time 0.1849 (0.2810)	loss 0.8779 (0.8672)	grad_norm 0.3986 (0.4109)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:03:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:08:31 lr 0.000013	 wd 0.0000	time 0.1932 (0.2690)	loss 0.8911 (0.8682)	grad_norm 0.4170 (0.4110)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:03:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:49 lr 0.000013	 wd 0.0000	time 0.1844 (0.2604)	loss 0.9502 (0.8689)	grad_norm 0.3926 (0.4106)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:03:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:07:16 lr 0.000013	 wd 0.0000	time 0.2447 (0.2564)	loss 0.9780 (0.8685)	grad_norm 0.4063 (0.4103)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:04:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:06:46 lr 0.000012	 wd 0.0000	time 0.1945 (0.2541)	loss 1.0977 (0.8669)	grad_norm 0.4086 (0.4102)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:04:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:15 lr 0.000012	 wd 0.0000	time 0.1693 (0.2499)	loss 0.7349 (0.8673)	grad_norm 0.4122 (0.4102)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:05:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:45 lr 0.000012	 wd 0.0000	time 0.1856 (0.2465)	loss 0.7148 (0.8664)	grad_norm 0.4209 (0.4102)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:05:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:17 lr 0.000012	 wd 0.0000	time 0.2133 (0.2437)	loss 0.9312 (0.8668)	grad_norm 0.3881 (0.4102)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:05:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:04:52 lr 0.000012	 wd 0.0000	time 0.2333 (0.2436)	loss 0.9316 (0.8670)	grad_norm 0.4320 (0.4103)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:06:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:26 lr 0.000012	 wd 0.0000	time 0.1677 (0.2420)	loss 0.9346 (0.8674)	grad_norm 0.4099 (0.4104)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:06:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:04:00 lr 0.000012	 wd 0.0000	time 0.1707 (0.2401)	loss 0.7480 (0.8681)	grad_norm 0.4205 (0.4104)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:06:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:34 lr 0.000012	 wd 0.0000	time 0.1966 (0.2382)	loss 0.8823 (0.8682)	grad_norm 0.3982 (0.4105)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:07:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:10 lr 0.000011	 wd 0.0000	time 0.2032 (0.2374)	loss 0.7847 (0.8679)	grad_norm 0.4024 (0.4106)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:07:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:46 lr 0.000011	 wd 0.0000	time 0.1880 (0.2377)	loss 0.8838 (0.8682)	grad_norm 0.3975 (0.4107)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:08:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:22 lr 0.000011	 wd 0.0000	time 0.1724 (0.2365)	loss 0.7861 (0.8677)	grad_norm 0.4039 (0.4106)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:08:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:01:58 lr 0.000011	 wd 0.0000	time 0.2046 (0.2354)	loss 0.9746 (0.8674)	grad_norm 0.4041 (0.4106)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:08:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:34 lr 0.000011	 wd 0.0000	time 0.2020 (0.2347)	loss 1.0215 (0.8675)	grad_norm 0.3750 (0.4105)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:09:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:11 lr 0.000011	 wd 0.0000	time 0.2734 (0.2356)	loss 0.9414 (0.8669)	grad_norm 0.4294 (0.4104)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:09:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:47 lr 0.000011	 wd 0.0000	time 0.1931 (0.2348)	loss 0.8584 (0.8670)	grad_norm 0.4112 (0.4103)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:09:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:23 lr 0.000011	 wd 0.0000	time 0.2017 (0.2339)	loss 0.8711 (0.8672)	grad_norm 0.4017 (0.4104)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:10:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1627 (0.2322)	loss 0.7954 (0.8670)	grad_norm 0.4136 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 13:10:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 23 training takes 0:09:49
[2024-08-02 13:10:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 35.833 (35.833)	Loss 0.3479 (0.3479)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 13:11:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.352 Acc@5 97.684
[2024-08-02 13:11:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-08-02 13:11:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.38%
[2024-08-02 13:11:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][0/2502]	eta 11:09:30 lr 0.000010	 wd 0.0000	time 16.0555 (16.0555)	loss 0.8652 (0.8652)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:11:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:14:51 lr 0.000010	 wd 0.0000	time 0.2036 (0.3712)	loss 0.9736 (0.8621)	grad_norm 0.3902 (0.4113)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:12:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:11:56 lr 0.000010	 wd 0.0000	time 0.2055 (0.3112)	loss 0.8853 (0.8641)	grad_norm 0.4171 (0.4101)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:12:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:10:10 lr 0.000010	 wd 0.0000	time 0.2241 (0.2774)	loss 0.7871 (0.8671)	grad_norm 0.4380 (0.4104)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:13:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:09:06 lr 0.000010	 wd 0.0000	time 0.1980 (0.2599)	loss 0.7290 (0.8685)	grad_norm 0.3989 (0.4102)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:13:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:08:17 lr 0.000010	 wd 0.0000	time 0.1927 (0.2487)	loss 0.8730 (0.8704)	grad_norm 0.4592 (0.4104)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:13:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:07:48 lr 0.000010	 wd 0.0000	time 0.2223 (0.2463)	loss 0.8887 (0.8683)	grad_norm 0.3851 (0.4109)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:14:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:07:20 lr 0.000010	 wd 0.0000	time 0.1812 (0.2444)	loss 0.8242 (0.8678)	grad_norm 0.3989 (0.4103)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:14:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:06:48 lr 0.000010	 wd 0.0000	time 0.1967 (0.2400)	loss 0.7993 (0.8669)	grad_norm 0.4167 (0.4102)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:14:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:06:18 lr 0.000009	 wd 0.0000	time 0.1717 (0.2365)	loss 0.9355 (0.8677)	grad_norm 0.4171 (0.4101)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:15:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:05:52 lr 0.000009	 wd 0.0000	time 0.2461 (0.2350)	loss 0.8071 (0.8686)	grad_norm 0.4113 (0.4101)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:15:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:05:31 lr 0.000009	 wd 0.0000	time 0.2189 (0.2361)	loss 0.8115 (0.8684)	grad_norm 0.4036 (0.4105)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:15:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:05 lr 0.000009	 wd 0.0000	time 0.1925 (0.2348)	loss 0.8271 (0.8681)	grad_norm 0.3820 (0.4106)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:16:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:04:40 lr 0.000009	 wd 0.0000	time 0.1974 (0.2331)	loss 0.7256 (0.8667)	grad_norm 0.4108 (0.4104)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:16:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:15 lr 0.000009	 wd 0.0000	time 0.1852 (0.2315)	loss 0.7700 (0.8671)	grad_norm 0.3953 (0.4104)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:17:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:03:51 lr 0.000009	 wd 0.0000	time 0.2136 (0.2312)	loss 0.8203 (0.8671)	grad_norm 0.4074 (0.4104)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:17:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:29 lr 0.000009	 wd 0.0000	time 0.1940 (0.2320)	loss 0.8950 (0.8671)	grad_norm 0.3988 (0.4106)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:17:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:05 lr 0.000008	 wd 0.0000	time 0.1826 (0.2308)	loss 0.9507 (0.8674)	grad_norm 0.4236 (0.4105)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:18:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:41 lr 0.000008	 wd 0.0000	time 0.1952 (0.2297)	loss 0.7695 (0.8677)	grad_norm 0.4003 (0.4105)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:18:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:18 lr 0.000008	 wd 0.0000	time 0.2163 (0.2293)	loss 0.7451 (0.8673)	grad_norm 0.3892 (0.4106)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:18:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:01:55 lr 0.000008	 wd 0.0000	time 0.2592 (0.2304)	loss 0.7109 (0.8672)	grad_norm 0.4135 (0.4108)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:19:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:32 lr 0.000008	 wd 0.0000	time 0.1959 (0.2295)	loss 0.9600 (0.8670)	grad_norm 0.4164 (0.4108)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:19:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:09 lr 0.000008	 wd 0.0000	time 0.2145 (0.2289)	loss 0.8608 (0.8668)	grad_norm 0.4025 (0.4109)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:20:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:46 lr 0.000008	 wd 0.0000	time 0.2188 (0.2285)	loss 0.9019 (0.8670)	grad_norm 0.3889 (0.4108)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:20:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:23 lr 0.000008	 wd 0.0000	time 0.1814 (0.2287)	loss 1.0352 (0.8668)	grad_norm 0.4004 (0.4106)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:20:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1695 (0.2274)	loss 0.9829 (0.8667)	grad_norm 0.3970 (0.4107)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:20:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 24 training takes 0:09:37
[2024-08-02 13:21:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 19.137 (19.137)	Loss 0.3484 (0.3484)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 13:21:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.348 Acc@5 97.684
[2024-08-02 13:21:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-02 13:21:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.38%
[2024-08-02 13:22:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][0/2502]	eta 22:31:25 lr 0.000008	 wd 0.0000	time 32.4083 (32.4083)	loss 0.8652 (0.8652)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:22:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:21:14 lr 0.000008	 wd 0.0000	time 0.1762 (0.5304)	loss 0.8218 (0.8815)	grad_norm 0.3968 (0.4130)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:22:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:14:09 lr 0.000007	 wd 0.0000	time 0.1948 (0.3689)	loss 0.8096 (0.8781)	grad_norm 0.4084 (0.4114)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:23:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:11:32 lr 0.000007	 wd 0.0000	time 0.2026 (0.3147)	loss 0.8779 (0.8706)	grad_norm 0.4099 (0.4109)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:23:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:10:57 lr 0.000007	 wd 0.0000	time 0.2145 (0.3127)	loss 0.7373 (0.8713)	grad_norm 0.4094 (0.4113)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:23:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:09:48 lr 0.000007	 wd 0.0000	time 0.1802 (0.2941)	loss 0.8530 (0.8707)	grad_norm 0.3843 (0.4111)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:24:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:51 lr 0.000007	 wd 0.0000	time 0.2107 (0.2796)	loss 0.7290 (0.8701)	grad_norm 0.4299 (0.4111)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:24:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:08:05 lr 0.000007	 wd 0.0000	time 0.1872 (0.2692)	loss 0.8184 (0.8691)	grad_norm 0.4146 (0.4111)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:25:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:07:29 lr 0.000007	 wd 0.0000	time 0.2309 (0.2644)	loss 0.9731 (0.8687)	grad_norm 0.4093 (0.4111)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:25:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:06:57 lr 0.000007	 wd 0.0000	time 0.1780 (0.2606)	loss 0.7231 (0.8685)	grad_norm 0.4063 (0.4110)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:25:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:24 lr 0.000007	 wd 0.0000	time 0.2046 (0.2557)	loss 0.9189 (0.8689)	grad_norm 0.4357 (0.4114)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:26:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:52 lr 0.000007	 wd 0.0000	time 0.1885 (0.2517)	loss 0.9937 (0.8684)	grad_norm 0.4168 (0.4115)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:26:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:24 lr 0.000006	 wd 0.0000	time 0.2346 (0.2490)	loss 0.9985 (0.8691)	grad_norm 0.4174 (0.4114)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:26:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:04:58 lr 0.000006	 wd 0.0000	time 0.1925 (0.2484)	loss 0.8696 (0.8680)	grad_norm 0.3966 (0.4114)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:27:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:31 lr 0.000006	 wd 0.0000	time 0.2052 (0.2462)	loss 0.9380 (0.8678)	grad_norm 0.3960 (0.4113)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:27:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:04:04 lr 0.000006	 wd 0.0000	time 0.1881 (0.2439)	loss 0.9634 (0.8686)	grad_norm 0.4046 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-02 13:27:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:38 lr 0.000006	 wd 0.0000	time 0.2304 (0.2419)	loss 0.7388 (0.8681)	grad_norm 0.3927 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-02 13:28:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:13 lr 0.000006	 wd 0.0000	time 0.2084 (0.2412)	loss 0.8164 (0.8689)	grad_norm 0.3987 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-02 13:28:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:49 lr 0.000006	 wd 0.0000	time 0.1885 (0.2414)	loss 0.9019 (0.8684)	grad_norm 0.3884 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-02 13:29:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:24 lr 0.000006	 wd 0.0000	time 0.1823 (0.2400)	loss 0.9883 (0.8683)	grad_norm 0.4020 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-02 13:29:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:01:59 lr 0.000006	 wd 0.0000	time 0.2241 (0.2387)	loss 1.0039 (0.8683)	grad_norm 0.4092 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-02 13:29:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:35 lr 0.000006	 wd 0.0000	time 0.2006 (0.2379)	loss 0.8911 (0.8678)	grad_norm 0.3990 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-02 13:30:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:11 lr 0.000006	 wd 0.0000	time 0.1781 (0.2383)	loss 0.8267 (0.8676)	grad_norm 0.3877 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-02 13:30:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:47 lr 0.000005	 wd 0.0000	time 0.2116 (0.2373)	loss 0.7812 (0.8674)	grad_norm 0.4024 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-02 13:30:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:24 lr 0.000005	 wd 0.0000	time 0.2123 (0.2363)	loss 0.8174 (0.8674)	grad_norm 0.3978 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-02 13:31:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000005	 wd 0.0000	time 0.1612 (0.2343)	loss 0.8735 (0.8677)	grad_norm 0.4134 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 13:31:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 25 training takes 0:09:53
[2024-08-02 13:32:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 41.122 (41.122)	Loss 0.3484 (0.3484)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 13:32:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.344 Acc@5 97.708
[2024-08-02 13:32:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-02 13:32:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.38%
[2024-08-02 13:32:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][0/2502]	eta 11:32:42 lr 0.000005	 wd 0.0000	time 16.6118 (16.6118)	loss 1.0225 (1.0225)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:33:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:15:44 lr 0.000005	 wd 0.0000	time 0.2522 (0.3931)	loss 0.7739 (0.8763)	grad_norm 0.4048 (0.4165)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:33:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:12:36 lr 0.000005	 wd 0.0000	time 0.1907 (0.3288)	loss 0.8501 (0.8725)	grad_norm 0.4222 (0.4146)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:33:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:10:35 lr 0.000005	 wd 0.0000	time 0.1888 (0.2885)	loss 0.8672 (0.8736)	grad_norm 0.4341 (0.4143)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:34:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:09:24 lr 0.000005	 wd 0.0000	time 0.2169 (0.2686)	loss 0.8867 (0.8709)	grad_norm 0.4131 (0.4132)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:34:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:08:35 lr 0.000005	 wd 0.0000	time 0.2310 (0.2574)	loss 0.8120 (0.8690)	grad_norm 0.3774 (0.4125)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:34:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:08:07 lr 0.000005	 wd 0.0000	time 0.1922 (0.2561)	loss 0.8423 (0.8698)	grad_norm 0.4137 (0.4126)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:35:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:30 lr 0.000005	 wd 0.0000	time 0.2106 (0.2498)	loss 0.8169 (0.8678)	grad_norm 0.3979 (0.4121)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:35:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:06:57 lr 0.000005	 wd 0.0000	time 0.1958 (0.2453)	loss 0.8511 (0.8689)	grad_norm 0.4231 (0.4121)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:36:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:06:26 lr 0.000005	 wd 0.0000	time 0.2151 (0.2411)	loss 0.7852 (0.8674)	grad_norm 0.4164 (0.4122)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:36:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:01 lr 0.000004	 wd 0.0000	time 0.2064 (0.2408)	loss 0.9497 (0.8678)	grad_norm 0.3960 (0.4123)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:36:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:37 lr 0.000004	 wd 0.0000	time 0.2095 (0.2408)	loss 0.9609 (0.8685)	grad_norm 0.3941 (0.4121)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:37:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:10 lr 0.000004	 wd 0.0000	time 0.2123 (0.2385)	loss 0.8950 (0.8682)	grad_norm 0.4155 (0.4122)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:37:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:04:44 lr 0.000004	 wd 0.0000	time 0.1917 (0.2364)	loss 0.7412 (0.8685)	grad_norm 0.4007 (0.4122)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:37:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:19 lr 0.000004	 wd 0.0000	time 0.1963 (0.2357)	loss 0.9644 (0.8682)	grad_norm 0.4097 (0.4122)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:38:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:03:56 lr 0.000004	 wd 0.0000	time 0.2693 (0.2360)	loss 0.8516 (0.8685)	grad_norm 0.4010 (0.4123)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:38:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:31 lr 0.000004	 wd 0.0000	time 0.1822 (0.2345)	loss 0.7339 (0.8676)	grad_norm 0.3821 (0.4122)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:39:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:07 lr 0.000004	 wd 0.0000	time 0.2225 (0.2332)	loss 0.8501 (0.8683)	grad_norm 0.3979 (0.4121)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:39:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:42 lr 0.000004	 wd 0.0000	time 0.2435 (0.2321)	loss 0.9111 (0.8688)	grad_norm 0.4033 (0.4122)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:39:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:20 lr 0.000004	 wd 0.0000	time 0.3099 (0.2327)	loss 0.8545 (0.8681)	grad_norm 0.4026 (0.4120)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:40:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:01:56 lr 0.000004	 wd 0.0000	time 0.1972 (0.2329)	loss 0.9238 (0.8680)	grad_norm 0.4150 (0.4120)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:40:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:33 lr 0.000004	 wd 0.0000	time 0.1904 (0.2320)	loss 0.8906 (0.8682)	grad_norm 0.4237 (0.4121)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:40:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:09 lr 0.000004	 wd 0.0000	time 0.2310 (0.2312)	loss 0.9341 (0.8682)	grad_norm 0.4109 (0.4120)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:41:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:46 lr 0.000004	 wd 0.0000	time 0.1966 (0.2310)	loss 0.8413 (0.8679)	grad_norm 0.4195 (0.4119)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:41:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:23 lr 0.000003	 wd 0.0000	time 0.1803 (0.2312)	loss 0.8623 (0.8683)	grad_norm 0.4260 (0.4120)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:41:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1695 (0.2295)	loss 0.9224 (0.8683)	grad_norm 0.4052 (0.4120)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:42:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 26 training takes 0:09:43
[2024-08-02 13:42:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 20.255 (20.255)	Loss 0.3477 (0.3477)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 13:42:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.346 Acc@5 97.702
[2024-08-02 13:42:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-02 13:42:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.38%
[2024-08-02 13:43:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][0/2502]	eta 22:59:56 lr 0.000003	 wd 0.0000	time 33.0920 (33.0920)	loss 0.9180 (0.9180)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:43:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:21:34 lr 0.000003	 wd 0.0000	time 0.2079 (0.5389)	loss 0.8726 (0.8723)	grad_norm 0.4118 (0.4112)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:44:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:14:18 lr 0.000003	 wd 0.0000	time 0.1772 (0.3730)	loss 0.7202 (0.8674)	grad_norm 0.4227 (0.4113)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:44:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:12:02 lr 0.000003	 wd 0.0000	time 0.2412 (0.3281)	loss 0.8833 (0.8677)	grad_norm 0.4319 (0.4121)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:44:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:10:38 lr 0.000003	 wd 0.0000	time 0.1944 (0.3035)	loss 0.8066 (0.8665)	grad_norm 0.4063 (0.4122)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:45:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:09:28 lr 0.000003	 wd 0.0000	time 0.1884 (0.2837)	loss 0.7402 (0.8657)	grad_norm 0.4449 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7964MB
[2024-08-02 13:45:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:36 lr 0.000003	 wd 0.0000	time 0.1814 (0.2714)	loss 0.8110 (0.8681)	grad_norm 0.4194 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7964MB
[2024-08-02 13:45:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:55 lr 0.000003	 wd 0.0000	time 0.2254 (0.2636)	loss 0.8242 (0.8675)	grad_norm 0.4321 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7964MB
[2024-08-02 13:46:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:24 lr 0.000003	 wd 0.0000	time 0.2296 (0.2613)	loss 0.8955 (0.8670)	grad_norm 0.3958 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7964MB
[2024-08-02 13:46:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:49 lr 0.000003	 wd 0.0000	time 0.1817 (0.2559)	loss 0.7183 (0.8667)	grad_norm 0.4000 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7964MB
[2024-08-02 13:46:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:17 lr 0.000003	 wd 0.0000	time 0.2062 (0.2514)	loss 0.8750 (0.8662)	grad_norm 0.3971 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7964MB
[2024-08-02 13:47:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:47 lr 0.000003	 wd 0.0000	time 0.2255 (0.2476)	loss 0.7666 (0.8663)	grad_norm 0.4188 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7964MB
[2024-08-02 13:47:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:20 lr 0.000003	 wd 0.0000	time 0.1877 (0.2465)	loss 0.8872 (0.8654)	grad_norm 0.4032 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7964MB
[2024-08-02 13:48:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:55 lr 0.000003	 wd 0.0000	time 0.2450 (0.2457)	loss 0.8540 (0.8655)	grad_norm 0.4269 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7964MB
[2024-08-02 13:48:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:28 lr 0.000003	 wd 0.0000	time 0.1885 (0.2433)	loss 0.8057 (0.8654)	grad_norm 0.4105 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7964MB
[2024-08-02 13:48:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:04:01 lr 0.000003	 wd 0.0000	time 0.1722 (0.2412)	loss 0.9575 (0.8655)	grad_norm 0.3997 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-02 13:49:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:36 lr 0.000003	 wd 0.0000	time 0.2144 (0.2399)	loss 0.8848 (0.8655)	grad_norm 0.4022 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-02 13:49:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:12 lr 0.000002	 wd 0.0000	time 0.1675 (0.2404)	loss 0.8804 (0.8657)	grad_norm 0.4150 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-02 13:49:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:47 lr 0.000002	 wd 0.0000	time 0.2131 (0.2390)	loss 0.7544 (0.8661)	grad_norm 0.4126 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-02 13:50:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:23 lr 0.000002	 wd 0.0000	time 0.2107 (0.2378)	loss 0.7964 (0.8662)	grad_norm 0.4071 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-02 13:50:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:58 lr 0.000002	 wd 0.0000	time 0.2175 (0.2368)	loss 0.7578 (0.8659)	grad_norm 0.3909 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-02 13:51:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:35 lr 0.000002	 wd 0.0000	time 0.1803 (0.2378)	loss 0.9927 (0.8668)	grad_norm 0.4330 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-02 13:51:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:11 lr 0.000002	 wd 0.0000	time 0.2010 (0.2369)	loss 0.7412 (0.8663)	grad_norm 0.4096 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-02 13:51:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:47 lr 0.000002	 wd 0.0000	time 0.1896 (0.2360)	loss 0.8267 (0.8666)	grad_norm 0.4096 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-02 13:52:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:23 lr 0.000002	 wd 0.0000	time 0.2196 (0.2351)	loss 0.8804 (0.8662)	grad_norm 0.4227 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-02 13:52:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1676 (0.2336)	loss 0.8486 (0.8665)	grad_norm 0.4024 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 13:52:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 27 training takes 0:09:53
[2024-08-02 13:53:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 28.835 (28.835)	Loss 0.3484 (0.3484)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 13:53:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.346 Acc@5 97.694
[2024-08-02 13:53:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-02 13:53:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.38%
[2024-08-02 13:53:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][0/2502]	eta 10:59:41 lr 0.000002	 wd 0.0000	time 15.8201 (15.8201)	loss 0.8447 (0.8447)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:54:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:16:40 lr 0.000002	 wd 0.0000	time 0.3887 (0.4167)	loss 0.8789 (0.8629)	grad_norm 0.4290 (0.4132)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:54:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:12:46 lr 0.000002	 wd 0.0000	time 0.2137 (0.3329)	loss 0.8247 (0.8689)	grad_norm 0.4146 (0.4127)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:54:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:10:42 lr 0.000002	 wd 0.0000	time 0.2070 (0.2918)	loss 0.9756 (0.8701)	grad_norm 0.4118 (0.4126)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:55:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:09:29 lr 0.000002	 wd 0.0000	time 0.1781 (0.2709)	loss 0.7773 (0.8651)	grad_norm 0.4100 (0.4126)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:55:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:08:43 lr 0.000002	 wd 0.0000	time 0.2667 (0.2615)	loss 0.8628 (0.8674)	grad_norm 0.4098 (0.4129)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:56:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:07 lr 0.000002	 wd 0.0000	time 0.2316 (0.2566)	loss 0.9043 (0.8687)	grad_norm 0.4055 (0.4123)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:56:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:33 lr 0.000002	 wd 0.0000	time 0.2225 (0.2518)	loss 0.8398 (0.8676)	grad_norm 0.4056 (0.4122)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:56:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:06:59 lr 0.000002	 wd 0.0000	time 0.1854 (0.2465)	loss 0.8384 (0.8683)	grad_norm 0.3995 (0.4124)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:57:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:29 lr 0.000002	 wd 0.0000	time 0.2105 (0.2428)	loss 0.8154 (0.8683)	grad_norm 0.4130 (0.4124)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:57:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:05 lr 0.000002	 wd 0.0000	time 0.2700 (0.2433)	loss 0.8213 (0.8681)	grad_norm 0.3921 (0.4124)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:57:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:38 lr 0.000002	 wd 0.0000	time 0.1773 (0.2415)	loss 0.8101 (0.8664)	grad_norm 0.4166 (0.4123)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:58:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:11 lr 0.000002	 wd 0.0000	time 0.2188 (0.2392)	loss 0.8467 (0.8664)	grad_norm 0.4203 (0.4125)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:58:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:04:44 lr 0.000002	 wd 0.0000	time 0.1904 (0.2370)	loss 0.9551 (0.8668)	grad_norm 0.4215 (0.4125)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:58:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:20 lr 0.000002	 wd 0.0000	time 0.1819 (0.2365)	loss 0.7900 (0.8660)	grad_norm 0.4085 (0.4124)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:59:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:03:57 lr 0.000002	 wd 0.0000	time 0.1875 (0.2365)	loss 0.7847 (0.8662)	grad_norm 0.4230 (0.4126)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 13:59:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:31 lr 0.000002	 wd 0.0000	time 0.1949 (0.2349)	loss 1.0029 (0.8666)	grad_norm 0.4226 (0.4124)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:00:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:07 lr 0.000001	 wd 0.0000	time 0.2183 (0.2336)	loss 0.9180 (0.8666)	grad_norm 0.4341 (0.4123)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:00:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:43 lr 0.000001	 wd 0.0000	time 0.2106 (0.2327)	loss 0.7559 (0.8662)	grad_norm 0.4298 (0.4125)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:00:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:20 lr 0.000001	 wd 0.0000	time 0.1746 (0.2332)	loss 0.8540 (0.8672)	grad_norm 0.4073 (0.4127)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:01:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:01:56 lr 0.000001	 wd 0.0000	time 0.2000 (0.2327)	loss 0.7852 (0.8664)	grad_norm 0.4063 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-02 14:01:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:33 lr 0.000001	 wd 0.0000	time 0.2082 (0.2317)	loss 0.8384 (0.8662)	grad_norm 0.4372 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-02 14:01:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:09 lr 0.000001	 wd 0.0000	time 0.1837 (0.2309)	loss 0.8853 (0.8657)	grad_norm 0.4238 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-02 14:02:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:46 lr 0.000001	 wd 0.0000	time 0.2121 (0.2314)	loss 0.8110 (0.8655)	grad_norm 0.4004 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-02 14:02:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:23 lr 0.000001	 wd 0.0000	time 0.1884 (0.2310)	loss 0.9609 (0.8651)	grad_norm 0.4154 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-02 14:03:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1598 (0.2294)	loss 0.8394 (0.8652)	grad_norm 0.3964 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 14:03:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 28 training takes 0:09:42
[2024-08-02 14:03:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 18.660 (18.660)	Loss 0.3484 (0.3484)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 14:03:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.346 Acc@5 97.694
[2024-08-02 14:03:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-02 14:03:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.38%
[2024-08-02 14:04:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][0/2502]	eta 21:32:28 lr 0.000001	 wd 0.0000	time 30.9944 (30.9944)	loss 0.9360 (0.9360)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:04:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:20:41 lr 0.000001	 wd 0.0000	time 0.1700 (0.5170)	loss 0.8335 (0.8744)	grad_norm 0.4212 (0.4143)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:04:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:13:50 lr 0.000001	 wd 0.0000	time 0.1692 (0.3606)	loss 0.8823 (0.8740)	grad_norm 0.4312 (0.4133)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:05:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:11:34 lr 0.000001	 wd 0.0000	time 0.2015 (0.3152)	loss 0.8330 (0.8741)	grad_norm 0.4111 (0.4122)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:05:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:10:14 lr 0.000001	 wd 0.0000	time 0.1843 (0.2921)	loss 0.8628 (0.8737)	grad_norm 0.4077 (0.4122)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:06:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:09:10 lr 0.000001	 wd 0.0000	time 0.2025 (0.2751)	loss 0.8203 (0.8732)	grad_norm 0.4224 (0.4133)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:06:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:21 lr 0.000001	 wd 0.0000	time 0.1838 (0.2638)	loss 0.7412 (0.8724)	grad_norm 0.4240 (0.4126)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:06:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:44 lr 0.000001	 wd 0.0000	time 0.2323 (0.2580)	loss 0.8369 (0.8714)	grad_norm 0.3968 (0.4128)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:07:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:07:15 lr 0.000001	 wd 0.0000	time 0.2168 (0.2557)	loss 0.8062 (0.8718)	grad_norm 0.3910 (0.4127)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:07:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:06:43 lr 0.000001	 wd 0.0000	time 0.1872 (0.2521)	loss 0.8599 (0.8718)	grad_norm 0.4186 (0.4128)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:07:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:12 lr 0.000001	 wd 0.0000	time 0.2309 (0.2480)	loss 0.8091 (0.8723)	grad_norm 0.4325 (0.4127)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:08:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:42 lr 0.000001	 wd 0.0000	time 0.2035 (0.2446)	loss 0.9751 (0.8718)	grad_norm 0.3961 (0.4126)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:08:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:16 lr 0.000001	 wd 0.0000	time 0.2478 (0.2433)	loss 0.7476 (0.8706)	grad_norm 0.4195 (0.4128)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:09:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:04:53 lr 0.000001	 wd 0.0000	time 0.2076 (0.2439)	loss 0.8823 (0.8705)	grad_norm 0.4254 (0.4130)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:09:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:26 lr 0.000001	 wd 0.0000	time 0.2365 (0.2416)	loss 0.9497 (0.8702)	grad_norm 0.4279 (0.4129)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:09:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:03:59 lr 0.000001	 wd 0.0000	time 0.1996 (0.2395)	loss 0.8003 (0.8689)	grad_norm 0.4153 (0.4129)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:10:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:34 lr 0.000001	 wd 0.0000	time 0.2086 (0.2383)	loss 0.8936 (0.8683)	grad_norm 0.4178 (0.4129)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:10:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:11 lr 0.000001	 wd 0.0000	time 0.1756 (0.2387)	loss 0.9082 (0.8671)	grad_norm 0.4209 (0.4128)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:10:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:46 lr 0.000001	 wd 0.0000	time 0.2040 (0.2375)	loss 0.7539 (0.8665)	grad_norm 0.3940 (0.4127)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:11:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:22 lr 0.000001	 wd 0.0000	time 0.2308 (0.2363)	loss 0.7109 (0.8665)	grad_norm 0.4236 (0.4128)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:11:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:01:58 lr 0.000001	 wd 0.0000	time 0.2413 (0.2353)	loss 0.8364 (0.8669)	grad_norm 0.4249 (0.4126)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:12:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:35 lr 0.000001	 wd 0.0000	time 0.2628 (0.2364)	loss 0.7939 (0.8670)	grad_norm 0.3922 (0.4126)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:12:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:11 lr 0.000001	 wd 0.0000	time 0.1642 (0.2361)	loss 0.7573 (0.8665)	grad_norm 0.4084 (0.4126)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:12:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:47 lr 0.000001	 wd 0.0000	time 0.1883 (0.2352)	loss 0.7100 (0.8668)	grad_norm 0.4319 (0.4127)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:13:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:23 lr 0.000001	 wd 0.0000	time 0.1732 (0.2342)	loss 0.7681 (0.8667)	grad_norm 0.4311 (0.4128)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:13:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1762 (0.2328)	loss 0.9487 (0.8666)	grad_norm 0.4193 (0.4128)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 14:13:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 249): INFO EPOCH 29 training takes 0:09:49
[2024-08-02 14:13:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_29.pth saving......
[2024-08-02 14:13:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft/diffusion_ft_adapter_conv_b_sequence_corss1/ckpt_epoch_29.pth saved !!!
[2024-08-02 14:14:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 31.407 (31.407)	Loss 0.3489 (0.3489)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 14:14:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 296): INFO  * Acc@1 85.354 Acc@5 97.698
[2024-08-02 14:14:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-08-02 14:14:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 182): INFO Max accuracy: 85.38%
[2024-08-02 14:14:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_crosslayer_process1-efficient-ft] (main.py 189): INFO Training time 5:13:32
