[2024-07-31 09:56:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 366): INFO Full config saved to pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/config.json
[2024-07-31 09:56:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_convnext_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 27
    - 3
    DIMS:
    - 128
    - 256
    - 512
    - 1024
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: sequence_stage1
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_conv_b_sequence_stage1
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 0.0001
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 0.8
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.0e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 1.0e-08

[2024-07-31 09:56:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/diffusion_finetune/convnext/adapter_convnext/diffusion_ft_adapter_convnext_base_224_22kto1k_sequence_stage_process1.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/diffusion-ft", "tag": "diffusion_ft_adapter_conv_b_sequence_stage1", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-31 09:56:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 108): INFO Creating model:adapter_convnext_diffusion_finetune/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1
[2024-07-31 09:57:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 110): INFO Adapter_ConvNeXt_Diffusion_Finetune(
  (uma): UMA(filter_strategy1=18, filter_strategy2=6,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): Identity()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (12): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (13): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (14): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (15): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (16): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (17): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (18): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (19): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (20): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (21): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (22): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (23): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (24): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (25): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (26): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (memory_downsampling): ModuleList()
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-31 09:57:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 113): INFO number of params: 1151368
[2024-07-31 09:57:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 150): INFO no checkpoint found in pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1, ignoring auto resume
[2024-07-31 09:57:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth for fine-tuning......
[2024-07-31 09:57:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 127): WARNING <All keys matched successfully>
[2024-07-31 09:57:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth'
[2024-07-31 09:58:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 72.443 (72.443)	Loss 0.3606 (0.3606)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 3055MB
[2024-07-31 09:58:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.816 Acc@5 97.462
[2024-07-31 09:58:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 162): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-31 09:58:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 168): INFO Start training
[2024-07-31 09:58:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][0/2502]	eta 15:02:05 lr 0.000100	 wd 0.0000	time 21.6329 (21.6329)	loss 0.8906 (0.8906)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 7518MB
[2024-07-31 09:59:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:17:42 lr 0.000100	 wd 0.0000	time 0.3037 (0.4423)	loss 0.8491 (0.8947)	grad_norm 0.2995 (nan)	loss_scale 32768.0000 (33092.4356)	mem 7518MB
[2024-07-31 09:59:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:14:43 lr 0.000100	 wd 0.0000	time 0.1807 (0.3838)	loss 0.8726 (0.9001)	grad_norm 0.2836 (nan)	loss_scale 32768.0000 (32931.0249)	mem 7518MB
[2024-07-31 10:00:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:11:37 lr 0.000100	 wd 0.0000	time 0.1877 (0.3169)	loss 0.9243 (0.9032)	grad_norm 0.2980 (nan)	loss_scale 32768.0000 (32876.8638)	mem 7518MB
[2024-07-31 10:00:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:09:56 lr 0.000100	 wd 0.0000	time 0.1799 (0.2836)	loss 1.2451 (0.9031)	grad_norm 0.2947 (nan)	loss_scale 32768.0000 (32849.7157)	mem 7518MB
[2024-07-31 10:00:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:08:48 lr 0.000100	 wd 0.0000	time 0.1753 (0.2642)	loss 0.8296 (0.9031)	grad_norm 0.2755 (nan)	loss_scale 32768.0000 (32833.4052)	mem 7518MB
[2024-07-31 10:01:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:20 lr 0.000100	 wd 0.0000	time 0.2219 (0.2948)	loss 0.9946 (0.9031)	grad_norm 0.2868 (nan)	loss_scale 32768.0000 (32822.5225)	mem 7518MB
[2024-07-31 10:01:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:23 lr 0.000100	 wd 0.0000	time 0.1972 (0.2793)	loss 0.8491 (0.9001)	grad_norm 0.2783 (nan)	loss_scale 32768.0000 (32814.7447)	mem 7518MB
[2024-07-31 10:02:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:35 lr 0.000100	 wd 0.0000	time 0.1630 (0.2675)	loss 0.9199 (0.9013)	grad_norm 0.2676 (nan)	loss_scale 32768.0000 (32808.9089)	mem 7518MB
[2024-07-31 10:02:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:06:55 lr 0.000100	 wd 0.0000	time 0.2271 (0.2594)	loss 1.0762 (0.9000)	grad_norm 0.2744 (nan)	loss_scale 32768.0000 (32804.3685)	mem 7518MB
[2024-07-31 10:02:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:06:26 lr 0.000100	 wd 0.0000	time 0.1947 (0.2573)	loss 0.8843 (0.9000)	grad_norm 0.2936 (nan)	loss_scale 32768.0000 (32800.7353)	mem 7518MB
[2024-07-31 10:03:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:05:53 lr 0.000100	 wd 0.0000	time 0.1841 (0.2524)	loss 0.8340 (0.8997)	grad_norm 0.2953 (nan)	loss_scale 32768.0000 (32797.7620)	mem 7518MB
[2024-07-31 10:03:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:21 lr 0.000100	 wd 0.0000	time 0.1928 (0.2471)	loss 0.7812 (0.8997)	grad_norm 0.2758 (nan)	loss_scale 32768.0000 (32795.2839)	mem 7518MB
[2024-07-31 10:03:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:04:51 lr 0.000100	 wd 0.0000	time 0.1851 (0.2423)	loss 0.8687 (0.9011)	grad_norm 0.2850 (nan)	loss_scale 32768.0000 (32793.1868)	mem 7518MB
[2024-07-31 10:04:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:24 lr 0.000100	 wd 0.0000	time 0.2934 (0.2402)	loss 0.8960 (0.9013)	grad_norm 0.2943 (nan)	loss_scale 32768.0000 (32791.3890)	mem 7518MB
[2024-07-31 10:04:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:04 lr 0.000100	 wd 0.0000	time 0.1946 (0.2439)	loss 0.9692 (0.9019)	grad_norm 0.2975 (nan)	loss_scale 32768.0000 (32789.8308)	mem 7518MB
[2024-07-31 10:05:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:36 lr 0.000100	 wd 0.0000	time 0.1904 (0.2401)	loss 1.0879 (0.9027)	grad_norm 0.2890 (nan)	loss_scale 32768.0000 (32788.4672)	mem 7518MB
[2024-07-31 10:05:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:09 lr 0.000100	 wd 0.0000	time 0.1850 (0.2369)	loss 0.8862 (0.9029)	grad_norm 0.2857 (nan)	loss_scale 32768.0000 (32787.2640)	mem 7518MB
[2024-07-31 10:05:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:02:44 lr 0.000100	 wd 0.0000	time 0.2000 (0.2342)	loss 0.8657 (0.9027)	grad_norm 0.3168 (nan)	loss_scale 32768.0000 (32786.1943)	mem 7518MB
[2024-07-31 10:06:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:20 lr 0.000100	 wd 0.0000	time 0.2986 (0.2332)	loss 1.0088 (0.9030)	grad_norm 0.2751 (nan)	loss_scale 32768.0000 (32785.2372)	mem 7518MB
[2024-07-31 10:06:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:01:56 lr 0.000100	 wd 0.0000	time 0.1852 (0.2330)	loss 0.9375 (0.9032)	grad_norm 0.2978 (nan)	loss_scale 32768.0000 (32784.3758)	mem 7518MB
[2024-07-31 10:06:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:32 lr 0.000100	 wd 0.0000	time 0.2029 (0.2309)	loss 0.9077 (0.9035)	grad_norm 0.2815 (nan)	loss_scale 32768.0000 (32783.5964)	mem 7518MB
[2024-07-31 10:07:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:09 lr 0.000100	 wd 0.0000	time 0.1758 (0.2289)	loss 1.0264 (0.9033)	grad_norm 0.2907 (nan)	loss_scale 32768.0000 (32782.8878)	mem 7518MB
[2024-07-31 10:07:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:45 lr 0.000100	 wd 0.0000	time 0.1773 (0.2273)	loss 1.0186 (0.9032)	grad_norm 0.2941 (nan)	loss_scale 32768.0000 (32782.2408)	mem 7518MB
[2024-07-31 10:07:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:23 lr 0.000100	 wd 0.0000	time 0.1770 (0.2272)	loss 1.0850 (0.9034)	grad_norm 0.2844 (nan)	loss_scale 32768.0000 (32781.6476)	mem 7518MB
[2024-07-31 10:08:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000100	 wd 0.0000	time 0.1506 (0.2253)	loss 0.8857 (0.9032)	grad_norm 0.2792 (nan)	loss_scale 32768.0000 (32781.1020)	mem 7518MB
[2024-07-31 10:08:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 0 training takes 0:09:28
[2024-07-31 10:08:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_0.pth saving......
[2024-07-31 10:08:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_0.pth saved !!!
[2024-07-31 10:08:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 25.744 (25.744)	Loss 0.3684 (0.3684)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 10:08:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.752 Acc@5 97.452
[2024-07-31 10:08:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-31 10:08:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.75%
[2024-07-31 10:08:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-31 10:08:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-31 10:09:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][0/2502]	eta 23:18:16 lr 0.000100	 wd 0.0000	time 33.5318 (33.5318)	loss 0.7793 (0.7793)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:09:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:21:34 lr 0.000100	 wd 0.0000	time 0.1937 (0.5389)	loss 0.8374 (0.8890)	grad_norm 0.2848 (0.2826)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:09:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:13:49 lr 0.000100	 wd 0.0000	time 0.1738 (0.3605)	loss 0.7896 (0.8954)	grad_norm 0.2789 (0.2819)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:10:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:02 lr 0.000100	 wd 0.0000	time 0.1743 (0.3008)	loss 0.9473 (0.8970)	grad_norm 0.2825 (0.2816)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:10:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:09:41 lr 0.000100	 wd 0.0000	time 0.3137 (0.2766)	loss 0.8999 (0.8982)	grad_norm 0.2862 (0.2824)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:11:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:10:10 lr 0.000100	 wd 0.0000	time 0.1616 (0.3050)	loss 0.8281 (0.8969)	grad_norm 0.2887 (0.2829)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:11:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:09:01 lr 0.000100	 wd 0.0000	time 0.1900 (0.2846)	loss 0.9229 (0.8986)	grad_norm 0.2936 (0.2828)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:11:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:06 lr 0.000100	 wd 0.0000	time 0.2076 (0.2699)	loss 0.8423 (0.8978)	grad_norm 0.2825 (0.2828)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:12:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:23 lr 0.000100	 wd 0.0000	time 0.2103 (0.2604)	loss 1.0469 (0.8993)	grad_norm 0.2785 (0.2824)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:12:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:09 lr 0.000099	 wd 0.0000	time 0.1814 (0.2680)	loss 0.8691 (0.8990)	grad_norm 0.2794 (0.2822)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:13:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:29 lr 0.000099	 wd 0.0000	time 0.1777 (0.2596)	loss 0.9053 (0.8991)	grad_norm 0.2838 (0.2822)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:13:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:05:53 lr 0.000099	 wd 0.0000	time 0.1753 (0.2522)	loss 0.9878 (0.9002)	grad_norm 0.2891 (0.2824)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:13:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:20 lr 0.000099	 wd 0.0000	time 0.1791 (0.2464)	loss 0.8638 (0.9002)	grad_norm 0.2885 (0.2826)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:14:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:06 lr 0.000099	 wd 0.0000	time 0.2305 (0.2551)	loss 0.8735 (0.9009)	grad_norm 0.2908 (0.2828)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:14:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:35 lr 0.000099	 wd 0.0000	time 0.1676 (0.2503)	loss 0.9092 (0.9012)	grad_norm 0.2764 (0.2827)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:14:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:06 lr 0.000099	 wd 0.0000	time 0.1852 (0.2458)	loss 0.8940 (0.9022)	grad_norm 0.2770 (0.2828)	loss_scale 65536.0000 (32811.6616)	mem 7518MB
[2024-07-31 10:15:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:38 lr 0.000099	 wd 0.0000	time 0.1760 (0.2418)	loss 0.8345 (0.9020)	grad_norm 0.2592 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7518MB
[2024-07-31 10:15:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:12 lr 0.000099	 wd 0.0000	time 0.3024 (0.2401)	loss 0.7871 (0.9021)	grad_norm 0.2858 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7518MB
[2024-07-31 10:15:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:48 lr 0.000099	 wd 0.0000	time 0.1929 (0.2401)	loss 1.0215 (0.9021)	grad_norm 0.2743 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7518MB
[2024-07-31 10:16:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:23 lr 0.000099	 wd 0.0000	time 0.1734 (0.2376)	loss 0.9258 (0.9024)	grad_norm 0.2713 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7518MB
[2024-07-31 10:16:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:01:58 lr 0.000099	 wd 0.0000	time 0.1869 (0.2351)	loss 0.7974 (0.9025)	grad_norm 0.2962 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7518MB
[2024-07-31 10:16:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:33 lr 0.000099	 wd 0.0000	time 0.2404 (0.2330)	loss 0.8540 (0.9024)	grad_norm 0.2898 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7518MB
[2024-07-31 10:17:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:10 lr 0.000099	 wd 0.0000	time 0.2759 (0.2322)	loss 0.7842 (0.9018)	grad_norm 0.2643 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7518MB
[2024-07-31 10:17:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:46 lr 0.000099	 wd 0.0000	time 0.1830 (0.2318)	loss 0.9575 (0.9026)	grad_norm 0.2770 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7518MB
[2024-07-31 10:17:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:23 lr 0.000099	 wd 0.0000	time 0.1943 (0.2299)	loss 0.9277 (0.9027)	grad_norm 0.2872 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7518MB
[2024-07-31 10:18:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000099	 wd 0.0000	time 0.1489 (0.2275)	loss 0.9312 (0.9031)	grad_norm 0.2855 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7518MB
[2024-07-31 10:18:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 1 training takes 0:09:33
[2024-07-31 10:19:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 44.568 (44.568)	Loss 0.3669 (0.3669)	Acc@1 91.211 (91.211)	Acc@5 98.633 (98.633)	Mem 7518MB
[2024-07-31 10:19:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.766 Acc@5 97.460
[2024-07-31 10:19:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-31 10:19:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.77%
[2024-07-31 10:19:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-31 10:19:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-31 10:19:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][0/2502]	eta 11:04:35 lr 0.000099	 wd 0.0000	time 15.9376 (15.9376)	loss 0.8057 (0.8057)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:19:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:13:36 lr 0.000099	 wd 0.0000	time 0.1906 (0.3401)	loss 1.0010 (0.9021)	grad_norm 0.2877 (0.2807)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:20:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:10:12 lr 0.000099	 wd 0.0000	time 0.2039 (0.2662)	loss 0.9824 (0.9002)	grad_norm 0.2925 (0.2804)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:20:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:11:22 lr 0.000099	 wd 0.0000	time 0.2465 (0.3101)	loss 0.8379 (0.8958)	grad_norm 0.2985 (0.2803)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:21:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:09:47 lr 0.000099	 wd 0.0000	time 0.1650 (0.2797)	loss 0.9727 (0.8971)	grad_norm 0.2666 (0.2803)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:21:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:08:41 lr 0.000099	 wd 0.0000	time 0.1771 (0.2603)	loss 0.9375 (0.9033)	grad_norm 0.2861 (0.2804)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:21:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:07:51 lr 0.000099	 wd 0.0000	time 0.1904 (0.2479)	loss 0.8188 (0.9032)	grad_norm 0.2871 (0.2800)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:22:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:07:54 lr 0.000099	 wd 0.0000	time 0.2248 (0.2634)	loss 0.8765 (0.9028)	grad_norm 0.2864 (0.2801)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:22:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:11 lr 0.000099	 wd 0.0000	time 0.1649 (0.2538)	loss 0.8164 (0.9012)	grad_norm 0.2805 (0.2800)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:22:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:33 lr 0.000098	 wd 0.0000	time 0.2048 (0.2459)	loss 0.9434 (0.9012)	grad_norm 0.2973 (0.2800)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:23:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:05:59 lr 0.000098	 wd 0.0000	time 0.1825 (0.2392)	loss 0.8276 (0.9003)	grad_norm 0.2760 (0.2797)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:23:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:53 lr 0.000098	 wd 0.0000	time 0.2694 (0.2524)	loss 0.9302 (0.9004)	grad_norm 0.2801 (0.2798)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:24:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:27 lr 0.000098	 wd 0.0000	time 0.1883 (0.2517)	loss 1.0596 (0.9007)	grad_norm 0.2894 (0.2797)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:24:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:04:56 lr 0.000098	 wd 0.0000	time 0.1757 (0.2465)	loss 0.9180 (0.9016)	grad_norm 0.2851 (0.2797)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:24:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:26 lr 0.000098	 wd 0.0000	time 0.1932 (0.2419)	loss 0.9590 (0.9018)	grad_norm 0.2668 (0.2796)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:25:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:00 lr 0.000098	 wd 0.0000	time 0.1773 (0.2399)	loss 1.0859 (0.9023)	grad_norm 0.2686 (0.2796)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:25:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:35 lr 0.000098	 wd 0.0000	time 0.1645 (0.2387)	loss 0.9570 (0.9020)	grad_norm 0.2785 (0.2797)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:25:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:09 lr 0.000098	 wd 0.0000	time 0.1617 (0.2357)	loss 0.9136 (0.9027)	grad_norm 0.2890 (0.2798)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:26:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:43 lr 0.000098	 wd 0.0000	time 0.1913 (0.2329)	loss 0.8809 (0.9026)	grad_norm 0.2722 (0.2799)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:26:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:18 lr 0.000098	 wd 0.0000	time 0.1841 (0.2307)	loss 0.8101 (0.9031)	grad_norm 0.2809 (0.2800)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:26:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:01:55 lr 0.000098	 wd 0.0000	time 0.1844 (0.2302)	loss 0.9111 (0.9031)	grad_norm 0.2677 (0.2800)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:27:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:32 lr 0.000098	 wd 0.0000	time 0.1744 (0.2298)	loss 0.9849 (0.9037)	grad_norm 0.2798 (0.2800)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:27:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:08 lr 0.000098	 wd 0.0000	time 0.1695 (0.2278)	loss 0.8901 (0.9035)	grad_norm 0.2767 (0.2798)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:27:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:45 lr 0.000098	 wd 0.0000	time 0.2046 (0.2260)	loss 0.8428 (0.9034)	grad_norm 0.2937 (0.2798)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:28:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:22 lr 0.000098	 wd 0.0000	time 0.2017 (0.2247)	loss 0.8804 (0.9038)	grad_norm 0.2900 (0.2798)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:28:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000098	 wd 0.0000	time 0.1514 (0.2229)	loss 0.9072 (0.9035)	grad_norm 0.2890 (0.2799)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:28:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 2 training takes 0:09:27
[2024-07-31 10:29:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 27.402 (27.402)	Loss 0.3640 (0.3640)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 10:29:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.794 Acc@5 97.476
[2024-07-31 10:29:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-31 10:29:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.79%
[2024-07-31 10:29:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-31 10:29:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-31 10:29:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][0/2502]	eta 10:21:05 lr 0.000098	 wd 0.0000	time 14.8943 (14.8943)	loss 0.7500 (0.7500)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:30:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:16:10 lr 0.000098	 wd 0.0000	time 0.4050 (0.4040)	loss 1.0078 (0.9011)	grad_norm 0.2914 (0.2820)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:30:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:13:13 lr 0.000097	 wd 0.0000	time 0.1824 (0.3446)	loss 1.0361 (0.8971)	grad_norm 0.2829 (0.2808)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:30:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:10:40 lr 0.000097	 wd 0.0000	time 0.1784 (0.2907)	loss 1.0459 (0.8984)	grad_norm 0.2933 (0.2807)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:31:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:09:14 lr 0.000097	 wd 0.0000	time 0.1508 (0.2637)	loss 1.0215 (0.8978)	grad_norm 0.2691 (0.2800)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:31:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:08:20 lr 0.000097	 wd 0.0000	time 0.3200 (0.2502)	loss 0.9292 (0.8993)	grad_norm nan (nan)	loss_scale 32768.0000 (32898.8104)	mem 7518MB
[2024-07-31 10:32:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:08:49 lr 0.000097	 wd 0.0000	time 0.1829 (0.2785)	loss 0.8491 (0.8998)	grad_norm 0.3058 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7518MB
[2024-07-31 10:32:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:07:57 lr 0.000097	 wd 0.0000	time 0.1902 (0.2650)	loss 0.9424 (0.9008)	grad_norm 0.2822 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7518MB
[2024-07-31 10:32:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:13 lr 0.000097	 wd 0.0000	time 0.1776 (0.2547)	loss 0.8789 (0.8994)	grad_norm 0.2840 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7518MB
[2024-07-31 10:33:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:06:37 lr 0.000097	 wd 0.0000	time 0.1905 (0.2481)	loss 0.9253 (0.9000)	grad_norm 0.2845 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7518MB
[2024-07-31 10:33:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:22 lr 0.000097	 wd 0.0000	time 0.1797 (0.2546)	loss 1.0752 (0.9018)	grad_norm 0.2946 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7518MB
[2024-07-31 10:33:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:05:47 lr 0.000097	 wd 0.0000	time 0.1907 (0.2481)	loss 0.7998 (0.9013)	grad_norm 0.2946 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7518MB
[2024-07-31 10:34:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:15 lr 0.000097	 wd 0.0000	time 0.1768 (0.2423)	loss 0.9453 (0.9005)	grad_norm 0.2746 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7518MB
[2024-07-31 10:34:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:04:45 lr 0.000097	 wd 0.0000	time 0.2038 (0.2379)	loss 0.9922 (0.9016)	grad_norm 0.2699 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7518MB
[2024-07-31 10:35:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:29 lr 0.000097	 wd 0.0000	time 0.1500 (0.2444)	loss 0.8647 (0.9014)	grad_norm 0.2715 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7518MB
[2024-07-31 10:35:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:01 lr 0.000097	 wd 0.0000	time 0.1557 (0.2408)	loss 0.8247 (0.9024)	grad_norm 0.2696 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7518MB
[2024-07-31 10:35:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:33 lr 0.000096	 wd 0.0000	time 0.1804 (0.2371)	loss 0.8789 (0.9016)	grad_norm 0.2899 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7518MB
[2024-07-31 10:36:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:07 lr 0.000096	 wd 0.0000	time 0.1949 (0.2340)	loss 0.9307 (0.9015)	grad_norm 0.2852 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7518MB
[2024-07-31 10:36:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:42 lr 0.000096	 wd 0.0000	time 0.2312 (0.2318)	loss 0.9033 (0.9015)	grad_norm 0.2661 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7518MB
[2024-07-31 10:36:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:19 lr 0.000096	 wd 0.0000	time 0.1552 (0.2320)	loss 0.9136 (0.9011)	grad_norm 0.2710 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7518MB
[2024-07-31 10:37:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:01:55 lr 0.000096	 wd 0.0000	time 0.1711 (0.2304)	loss 0.8755 (0.9015)	grad_norm 0.2682 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7518MB
[2024-07-31 10:37:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:31 lr 0.000096	 wd 0.0000	time 0.1723 (0.2284)	loss 0.7383 (0.9012)	grad_norm 0.2853 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7518MB
[2024-07-31 10:37:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:08 lr 0.000096	 wd 0.0000	time 0.1940 (0.2265)	loss 0.8535 (0.9008)	grad_norm 0.2812 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7518MB
[2024-07-31 10:38:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:45 lr 0.000096	 wd 0.0000	time 0.2117 (0.2255)	loss 0.9844 (0.9010)	grad_norm 0.2786 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7518MB
[2024-07-31 10:38:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:22 lr 0.000096	 wd 0.0000	time 0.1823 (0.2255)	loss 0.8359 (0.9011)	grad_norm 0.2721 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7518MB
[2024-07-31 10:38:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000096	 wd 0.0000	time 0.1503 (0.2233)	loss 0.8296 (0.9017)	grad_norm 0.2890 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7518MB
[2024-07-31 10:38:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 3 training takes 0:09:22
[2024-07-31 10:39:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 23.477 (23.477)	Loss 0.3655 (0.3655)	Acc@1 91.211 (91.211)	Acc@5 98.633 (98.633)	Mem 7518MB
[2024-07-31 10:39:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.794 Acc@5 97.446
[2024-07-31 10:39:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-31 10:39:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.79%
[2024-07-31 10:39:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-31 10:39:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-31 10:39:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][0/2502]	eta 22:15:51 lr 0.000096	 wd 0.0000	time 32.0349 (32.0349)	loss 0.9194 (0.9194)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:40:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:20:24 lr 0.000096	 wd 0.0000	time 0.1676 (0.5097)	loss 0.8086 (0.9057)	grad_norm 0.2767 (0.2799)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:40:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:13:17 lr 0.000096	 wd 0.0000	time 0.1652 (0.3463)	loss 0.9214 (0.9031)	grad_norm 0.2643 (0.2792)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:40:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:10:42 lr 0.000095	 wd 0.0000	time 0.1902 (0.2918)	loss 0.9019 (0.9032)	grad_norm 0.2935 (0.2796)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:41:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:09:23 lr 0.000095	 wd 0.0000	time 0.2153 (0.2682)	loss 0.8745 (0.8982)	grad_norm 0.2740 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:41:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:09:39 lr 0.000095	 wd 0.0000	time 0.1653 (0.2897)	loss 0.9565 (0.8998)	grad_norm 0.2683 (0.2793)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:42:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:08:43 lr 0.000095	 wd 0.0000	time 0.2018 (0.2753)	loss 0.8618 (0.9024)	grad_norm 0.2914 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:42:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:07:52 lr 0.000095	 wd 0.0000	time 0.1778 (0.2623)	loss 1.0068 (0.8993)	grad_norm 0.2768 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:42:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:12 lr 0.000095	 wd 0.0000	time 0.2221 (0.2539)	loss 0.8740 (0.8998)	grad_norm 0.2908 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:43:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:07:07 lr 0.000095	 wd 0.0000	time 0.1996 (0.2668)	loss 0.8696 (0.9009)	grad_norm 0.2855 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:43:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:27 lr 0.000095	 wd 0.0000	time 0.1719 (0.2583)	loss 0.9160 (0.9011)	grad_norm 0.2793 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:44:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:05:52 lr 0.000095	 wd 0.0000	time 0.1824 (0.2516)	loss 0.9644 (0.9027)	grad_norm 0.2901 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:44:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:20 lr 0.000095	 wd 0.0000	time 0.1970 (0.2461)	loss 0.7583 (0.9025)	grad_norm 0.2737 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:44:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:05:01 lr 0.000095	 wd 0.0000	time 0.2074 (0.2509)	loss 0.8462 (0.9017)	grad_norm 0.2754 (0.2784)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:45:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:31 lr 0.000094	 wd 0.0000	time 0.1854 (0.2462)	loss 0.9229 (0.9012)	grad_norm 0.2846 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:45:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:02 lr 0.000094	 wd 0.0000	time 0.1903 (0.2419)	loss 0.7778 (0.9014)	grad_norm 0.2785 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:45:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:34 lr 0.000094	 wd 0.0000	time 0.1885 (0.2382)	loss 0.8511 (0.9013)	grad_norm 0.2770 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:46:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:08 lr 0.000094	 wd 0.0000	time 0.1722 (0.2356)	loss 1.0771 (0.9011)	grad_norm 0.2774 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:46:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:45 lr 0.000094	 wd 0.0000	time 0.2057 (0.2351)	loss 0.9551 (0.9016)	grad_norm 0.2755 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:46:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:20 lr 0.000094	 wd 0.0000	time 0.1805 (0.2331)	loss 0.9170 (0.9014)	grad_norm 0.2771 (0.2785)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:47:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:01:55 lr 0.000094	 wd 0.0000	time 0.1771 (0.2307)	loss 0.7817 (0.9010)	grad_norm nan (nan)	loss_scale 32768.0000 (32800.7516)	mem 7518MB
[2024-07-31 10:47:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:31 lr 0.000094	 wd 0.0000	time 0.1860 (0.2286)	loss 0.8350 (0.9019)	grad_norm 0.2933 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7518MB
[2024-07-31 10:47:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:08 lr 0.000094	 wd 0.0000	time 0.1946 (0.2275)	loss 1.0059 (0.9014)	grad_norm 0.2580 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7518MB
[2024-07-31 10:48:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:45 lr 0.000094	 wd 0.0000	time 0.1756 (0.2274)	loss 0.8784 (0.9016)	grad_norm 0.2752 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7518MB
[2024-07-31 10:48:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:23 lr 0.000093	 wd 0.0000	time 0.1650 (0.2259)	loss 0.8428 (0.9019)	grad_norm 0.2625 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7518MB
[2024-07-31 10:48:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000093	 wd 0.0000	time 0.1497 (0.2236)	loss 0.7700 (0.9019)	grad_norm 0.2804 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7518MB
[2024-07-31 10:48:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 4 training takes 0:09:23
[2024-07-31 10:49:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 25.810 (25.810)	Loss 0.3613 (0.3613)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 10:49:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.778 Acc@5 97.458
[2024-07-31 10:49:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-31 10:49:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.79%
[2024-07-31 10:49:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][0/2502]	eta 17:26:15 lr 0.000093	 wd 0.0000	time 25.0900 (25.0900)	loss 0.8896 (0.8896)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:50:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:17:09 lr 0.000093	 wd 0.0000	time 0.1529 (0.4284)	loss 0.9224 (0.8927)	grad_norm 0.2890 (0.2782)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:50:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:11:40 lr 0.000093	 wd 0.0000	time 0.1966 (0.3045)	loss 0.8071 (0.8963)	grad_norm 0.2815 (0.2790)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:50:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:09:46 lr 0.000093	 wd 0.0000	time 0.2501 (0.2664)	loss 1.0146 (0.8952)	grad_norm 0.2807 (0.2784)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:51:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:54 lr 0.000093	 wd 0.0000	time 0.2093 (0.2827)	loss 0.9512 (0.8946)	grad_norm 0.2830 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:51:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:08:47 lr 0.000093	 wd 0.0000	time 0.1664 (0.2635)	loss 0.8594 (0.8944)	grad_norm 0.2999 (0.2785)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:51:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:07:55 lr 0.000093	 wd 0.0000	time 0.1681 (0.2498)	loss 0.8569 (0.8974)	grad_norm 0.2809 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:52:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:11 lr 0.000093	 wd 0.0000	time 0.1645 (0.2394)	loss 0.8140 (0.8967)	grad_norm 0.2967 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:52:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:06 lr 0.000093	 wd 0.0000	time 3.0660 (0.2506)	loss 0.8594 (0.8966)	grad_norm 0.2762 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:53:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:41 lr 0.000092	 wd 0.0000	time 0.1748 (0.2508)	loss 0.9331 (0.8972)	grad_norm 0.2829 (0.2789)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:53:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:06 lr 0.000092	 wd 0.0000	time 0.1884 (0.2443)	loss 0.9258 (0.8991)	grad_norm 0.2729 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:53:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:34 lr 0.000092	 wd 0.0000	time 0.1719 (0.2387)	loss 0.8408 (0.9003)	grad_norm 0.2792 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:54:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:08 lr 0.000092	 wd 0.0000	time 0.3266 (0.2367)	loss 0.9204 (0.9008)	grad_norm 0.2732 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:54:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:53 lr 0.000092	 wd 0.0000	time 0.1559 (0.2442)	loss 0.9790 (0.9001)	grad_norm 0.2907 (0.2789)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:55:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:24 lr 0.000092	 wd 0.0000	time 0.1776 (0.2399)	loss 0.8613 (0.8994)	grad_norm 0.2918 (0.2789)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:55:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:03:56 lr 0.000092	 wd 0.0000	time 0.1634 (0.2359)	loss 0.8711 (0.9001)	grad_norm 0.2872 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:55:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:30 lr 0.000092	 wd 0.0000	time 0.2208 (0.2333)	loss 0.8164 (0.9008)	grad_norm 0.2898 (0.2789)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:56:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:10 lr 0.000092	 wd 0.0000	time 0.1745 (0.2380)	loss 0.8916 (0.9012)	grad_norm 0.2623 (0.2790)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:56:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:44 lr 0.000091	 wd 0.0000	time 0.1722 (0.2350)	loss 0.9146 (0.9006)	grad_norm 0.2829 (0.2790)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:56:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:19 lr 0.000091	 wd 0.0000	time 0.2043 (0.2325)	loss 0.8828 (0.9004)	grad_norm 0.2708 (0.2790)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:57:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:01:55 lr 0.000091	 wd 0.0000	time 0.2002 (0.2302)	loss 0.9834 (0.9010)	grad_norm 0.2845 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:57:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:32 lr 0.000091	 wd 0.0000	time 0.1733 (0.2292)	loss 1.0205 (0.9005)	grad_norm 0.2809 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:57:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:09 lr 0.000091	 wd 0.0000	time 0.1654 (0.2288)	loss 1.0088 (0.9005)	grad_norm 0.2792 (0.2790)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:58:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:45 lr 0.000091	 wd 0.0000	time 0.1645 (0.2271)	loss 0.7705 (0.9003)	grad_norm 0.2906 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:58:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:22 lr 0.000091	 wd 0.0000	time 0.1855 (0.2254)	loss 0.7983 (0.8999)	grad_norm 0.2889 (0.2792)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:58:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000091	 wd 0.0000	time 0.1528 (0.2230)	loss 0.8013 (0.8994)	grad_norm 0.2783 (0.2792)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 10:58:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 5 training takes 0:09:22
[2024-07-31 10:59:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 36.527 (36.527)	Loss 0.3589 (0.3589)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 10:59:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.802 Acc@5 97.490
[2024-07-31 10:59:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-31 10:59:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.80%
[2024-07-31 10:59:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-31 10:59:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-31 10:59:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][0/2502]	eta 11:22:47 lr 0.000091	 wd 0.0000	time 16.3738 (16.3738)	loss 0.9419 (0.9419)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:00:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:13:35 lr 0.000090	 wd 0.0000	time 0.1570 (0.3395)	loss 0.8726 (0.9093)	grad_norm 0.2960 (0.2793)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:00:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:10:40 lr 0.000090	 wd 0.0000	time 0.3506 (0.2782)	loss 0.8154 (0.9031)	grad_norm 0.2926 (0.2798)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:01:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:10:31 lr 0.000090	 wd 0.0000	time 0.1681 (0.2868)	loss 0.9170 (0.9036)	grad_norm 0.2846 (0.2799)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:01:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:09:08 lr 0.000090	 wd 0.0000	time 0.1835 (0.2608)	loss 0.8618 (0.9019)	grad_norm 0.2691 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:01:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:08:09 lr 0.000090	 wd 0.0000	time 0.1718 (0.2447)	loss 0.9282 (0.9015)	grad_norm 0.2626 (0.2793)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:02:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:07:25 lr 0.000090	 wd 0.0000	time 0.2144 (0.2340)	loss 0.8926 (0.9015)	grad_norm 0.2961 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:02:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:07:29 lr 0.000090	 wd 0.0000	time 0.1954 (0.2492)	loss 1.0029 (0.9015)	grad_norm 0.2822 (0.2796)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:02:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:06:51 lr 0.000090	 wd 0.0000	time 0.1734 (0.2420)	loss 0.7500 (0.9016)	grad_norm 0.2799 (0.2793)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:03:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:06:17 lr 0.000089	 wd 0.0000	time 0.1865 (0.2356)	loss 0.8936 (0.9009)	grad_norm 0.2718 (0.2792)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:03:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:05:45 lr 0.000089	 wd 0.0000	time 0.1587 (0.2299)	loss 0.8525 (0.9021)	grad_norm 0.2843 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7518MB
[2024-07-31 11:03:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:26 lr 0.000089	 wd 0.0000	time 0.4232 (0.2328)	loss 0.8296 (0.9008)	grad_norm 0.2730 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7518MB
[2024-07-31 11:04:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:10 lr 0.000089	 wd 0.0000	time 0.1586 (0.2385)	loss 0.8706 (0.9008)	grad_norm 0.2731 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7518MB
[2024-07-31 11:04:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:04:41 lr 0.000089	 wd 0.0000	time 0.1728 (0.2343)	loss 0.8057 (0.9002)	grad_norm 0.2712 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7518MB
[2024-07-31 11:05:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:13 lr 0.000089	 wd 0.0000	time 0.1802 (0.2305)	loss 0.9380 (0.8997)	grad_norm 0.2708 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7518MB
[2024-07-31 11:05:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:03:48 lr 0.000089	 wd 0.0000	time 0.2062 (0.2278)	loss 0.7939 (0.8997)	grad_norm 0.2765 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7518MB
[2024-07-31 11:05:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:25 lr 0.000089	 wd 0.0000	time 0.1863 (0.2274)	loss 0.8071 (0.8991)	grad_norm 0.2678 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7518MB
[2024-07-31 11:06:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:00 lr 0.000088	 wd 0.0000	time 0.1984 (0.2255)	loss 0.8750 (0.8979)	grad_norm 0.2705 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7518MB
[2024-07-31 11:06:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:36 lr 0.000088	 wd 0.0000	time 0.1911 (0.2234)	loss 0.8413 (0.8979)	grad_norm 0.2734 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7518MB
[2024-07-31 11:06:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:13 lr 0.000088	 wd 0.0000	time 0.1687 (0.2214)	loss 0.9316 (0.8984)	grad_norm 0.2777 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7518MB
[2024-07-31 11:07:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:01:50 lr 0.000088	 wd 0.0000	time 0.1842 (0.2204)	loss 0.9507 (0.8988)	grad_norm 0.2755 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7518MB
[2024-07-31 11:07:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:28 lr 0.000088	 wd 0.0000	time 0.1562 (0.2208)	loss 0.8037 (0.8988)	grad_norm 0.2834 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7518MB
[2024-07-31 11:07:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:06 lr 0.000088	 wd 0.0000	time 0.1834 (0.2195)	loss 0.9268 (0.8982)	grad_norm 0.2859 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7518MB
[2024-07-31 11:08:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:44 lr 0.000088	 wd 0.0000	time 0.1962 (0.2181)	loss 0.8462 (0.8982)	grad_norm 0.2778 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7518MB
[2024-07-31 11:08:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:22 lr 0.000087	 wd 0.0000	time 0.1713 (0.2166)	loss 0.8926 (0.8987)	grad_norm 0.2693 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7518MB
[2024-07-31 11:08:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000087	 wd 0.0000	time 0.1501 (0.2148)	loss 0.8013 (0.8994)	grad_norm 0.2801 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7518MB
[2024-07-31 11:08:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 6 training takes 0:09:01
[2024-07-31 11:09:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 38.563 (38.563)	Loss 0.3601 (0.3601)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 7518MB
[2024-07-31 11:09:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.816 Acc@5 97.492
[2024-07-31 11:09:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-31 11:09:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-31 11:09:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-31 11:09:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-31 11:09:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][0/2502]	eta 10:57:11 lr 0.000087	 wd 0.0000	time 15.7598 (15.7598)	loss 0.8809 (0.8809)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:10:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:14:15 lr 0.000087	 wd 0.0000	time 0.2989 (0.3560)	loss 0.9902 (0.8988)	grad_norm 0.2711 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:10:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:13:48 lr 0.000087	 wd 0.0000	time 0.2083 (0.3599)	loss 0.8823 (0.8967)	grad_norm 0.2689 (0.2801)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:11:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:11:02 lr 0.000087	 wd 0.0000	time 0.1659 (0.3009)	loss 0.8579 (0.8938)	grad_norm 0.2787 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:11:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:09:30 lr 0.000087	 wd 0.0000	time 0.1613 (0.2712)	loss 0.9048 (0.8982)	grad_norm 0.2951 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:11:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:08:27 lr 0.000087	 wd 0.0000	time 0.2134 (0.2536)	loss 0.7764 (0.8959)	grad_norm 0.2640 (0.2789)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:12:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:09:04 lr 0.000086	 wd 0.0000	time 0.2019 (0.2863)	loss 1.0273 (0.8981)	grad_norm 0.2664 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:12:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:08:10 lr 0.000086	 wd 0.0000	time 0.1828 (0.2724)	loss 0.8315 (0.8978)	grad_norm 0.2617 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:13:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:07:24 lr 0.000086	 wd 0.0000	time 0.1789 (0.2613)	loss 0.8301 (0.8969)	grad_norm 0.2704 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:13:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:06:47 lr 0.000086	 wd 0.0000	time 0.2401 (0.2545)	loss 0.8799 (0.8978)	grad_norm 0.2818 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:13:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:35 lr 0.000086	 wd 0.0000	time 0.1714 (0.2630)	loss 0.7905 (0.8976)	grad_norm 0.2824 (0.2785)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:14:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:58 lr 0.000086	 wd 0.0000	time 0.1710 (0.2557)	loss 0.7935 (0.8972)	grad_norm 0.2839 (0.2785)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:14:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:25 lr 0.000086	 wd 0.0000	time 0.1696 (0.2497)	loss 0.9312 (0.8966)	grad_norm 0.2888 (0.2785)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:14:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:04:53 lr 0.000085	 wd 0.0000	time 0.1846 (0.2445)	loss 0.9419 (0.8961)	grad_norm 0.2671 (0.2785)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:15:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:27 lr 0.000085	 wd 0.0000	time 0.1859 (0.2423)	loss 0.7964 (0.8964)	grad_norm 0.2842 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:15:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:01 lr 0.000085	 wd 0.0000	time 0.1846 (0.2408)	loss 0.8569 (0.8960)	grad_norm 0.2929 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:15:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:34 lr 0.000085	 wd 0.0000	time 0.1846 (0.2374)	loss 0.9019 (0.8957)	grad_norm 0.2775 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:16:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:07 lr 0.000085	 wd 0.0000	time 0.1622 (0.2344)	loss 1.0264 (0.8954)	grad_norm 0.2687 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:16:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:42 lr 0.000085	 wd 0.0000	time 0.2135 (0.2319)	loss 0.8408 (0.8955)	grad_norm 0.2661 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:16:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:19 lr 0.000085	 wd 0.0000	time 1.1397 (0.2318)	loss 0.9214 (0.8954)	grad_norm 0.2760 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:17:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:01:55 lr 0.000084	 wd 0.0000	time 0.1829 (0.2306)	loss 0.8564 (0.8949)	grad_norm 0.2823 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:17:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:31 lr 0.000084	 wd 0.0000	time 0.1753 (0.2286)	loss 1.0342 (0.8959)	grad_norm 0.2842 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:17:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:08 lr 0.000084	 wd 0.0000	time 0.1869 (0.2266)	loss 0.7207 (0.8952)	grad_norm 0.2860 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:18:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:45 lr 0.000084	 wd 0.0000	time 0.2140 (0.2251)	loss 0.9854 (0.8953)	grad_norm 0.2850 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:18:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:22 lr 0.000084	 wd 0.0000	time 0.1746 (0.2246)	loss 0.9644 (0.8955)	grad_norm 0.2822 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:18:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000084	 wd 0.0000	time 0.1520 (0.2227)	loss 0.8862 (0.8959)	grad_norm 0.2870 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7518MB
[2024-07-31 11:18:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 7 training takes 0:09:22
[2024-07-31 11:19:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 18.918 (18.918)	Loss 0.3569 (0.3569)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7518MB
[2024-07-31 11:19:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.804 Acc@5 97.480
[2024-07-31 11:19:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-31 11:19:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-31 11:19:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][0/2502]	eta 11:50:54 lr 0.000084	 wd 0.0000	time 17.0480 (17.0480)	loss 0.8203 (0.8203)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:20:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:19:39 lr 0.000083	 wd 0.0000	time 0.1708 (0.4910)	loss 0.8760 (0.9015)	grad_norm 0.2795 (0.2807)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:20:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:12:54 lr 0.000083	 wd 0.0000	time 0.1863 (0.3364)	loss 0.8862 (0.9004)	grad_norm 0.2705 (0.2798)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:20:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:10:28 lr 0.000083	 wd 0.0000	time 0.1674 (0.2852)	loss 0.8799 (0.8963)	grad_norm 0.2964 (0.2789)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:21:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:09:04 lr 0.000083	 wd 0.0000	time 0.1816 (0.2590)	loss 0.9995 (0.8970)	grad_norm 0.2739 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:21:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:08:27 lr 0.000083	 wd 0.0000	time 0.2836 (0.2534)	loss 0.8286 (0.8977)	grad_norm 0.2797 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:22:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:16 lr 0.000083	 wd 0.0000	time 0.1765 (0.2611)	loss 0.8716 (0.8972)	grad_norm 0.2928 (0.2784)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:22:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:30 lr 0.000083	 wd 0.0000	time 0.1603 (0.2498)	loss 0.9097 (0.8965)	grad_norm 0.2942 (0.2785)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:22:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:06:50 lr 0.000082	 wd 0.0000	time 0.1666 (0.2415)	loss 0.7749 (0.8963)	grad_norm 0.2855 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:23:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:17 lr 0.000082	 wd 0.0000	time 0.2252 (0.2355)	loss 1.0312 (0.8975)	grad_norm 0.2684 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:23:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:06 lr 0.000082	 wd 0.0000	time 0.1828 (0.2439)	loss 1.0518 (0.8980)	grad_norm 0.2698 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:23:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:34 lr 0.000082	 wd 0.0000	time 0.1741 (0.2384)	loss 1.0000 (0.8979)	grad_norm 0.2903 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:24:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:04 lr 0.000082	 wd 0.0000	time 0.1839 (0.2339)	loss 0.8687 (0.8978)	grad_norm 0.2743 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:24:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:36 lr 0.000082	 wd 0.0000	time 0.1768 (0.2299)	loss 0.8364 (0.8979)	grad_norm 0.2763 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:24:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:13 lr 0.000081	 wd 0.0000	time 0.3084 (0.2299)	loss 0.8545 (0.8977)	grad_norm 0.2675 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:25:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:03:56 lr 0.000081	 wd 0.0000	time 0.1846 (0.2358)	loss 0.8706 (0.8975)	grad_norm 0.2932 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:25:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:29 lr 0.000081	 wd 0.0000	time 0.1653 (0.2323)	loss 0.9863 (0.8969)	grad_norm 0.2760 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:26:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:03 lr 0.000081	 wd 0.0000	time 0.1773 (0.2293)	loss 0.8765 (0.8977)	grad_norm 0.2649 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:26:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:39 lr 0.000081	 wd 0.0000	time 0.1924 (0.2273)	loss 0.8887 (0.8981)	grad_norm 0.2856 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:26:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:16 lr 0.000081	 wd 0.0000	time 0.1784 (0.2275)	loss 0.7954 (0.8975)	grad_norm 0.2595 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:27:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:53 lr 0.000080	 wd 0.0000	time 0.1815 (0.2260)	loss 0.8452 (0.8977)	grad_norm 0.3053 (0.2789)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:27:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:30 lr 0.000080	 wd 0.0000	time 0.1856 (0.2241)	loss 0.9121 (0.8979)	grad_norm 0.2860 (0.2789)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:27:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:07 lr 0.000080	 wd 0.0000	time 0.1724 (0.2223)	loss 0.8672 (0.8974)	grad_norm 0.2907 (0.2789)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:28:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:44 lr 0.000080	 wd 0.0000	time 0.2090 (0.2213)	loss 0.9990 (0.8972)	grad_norm 0.2770 (0.2789)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:28:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:22 lr 0.000080	 wd 0.0000	time 0.1574 (0.2209)	loss 0.9854 (0.8972)	grad_norm 0.2844 (0.2790)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:28:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000080	 wd 0.0000	time 0.1508 (0.2190)	loss 0.9497 (0.8972)	grad_norm 0.2815 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:28:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 8 training takes 0:09:12
[2024-07-31 11:29:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 21.571 (21.571)	Loss 0.3613 (0.3613)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7518MB
[2024-07-31 11:29:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.810 Acc@5 97.466
[2024-07-31 11:29:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-31 11:29:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-31 11:29:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][0/2502]	eta 15:55:24 lr 0.000080	 wd 0.0000	time 22.9113 (22.9113)	loss 0.8936 (0.8936)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:30:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:17:44 lr 0.000079	 wd 0.0000	time 0.1874 (0.4431)	loss 0.9722 (0.8920)	grad_norm 0.2798 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:30:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:12:00 lr 0.000079	 wd 0.0000	time 0.1645 (0.3129)	loss 0.7764 (0.8903)	grad_norm 0.2736 (0.2796)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:30:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:09:53 lr 0.000079	 wd 0.0000	time 0.1817 (0.2696)	loss 0.9575 (0.8919)	grad_norm 0.2600 (0.2803)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:30:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:08:40 lr 0.000079	 wd 0.0000	time 0.1880 (0.2478)	loss 0.8750 (0.8915)	grad_norm 0.2647 (0.2804)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:31:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:08:15 lr 0.000079	 wd 0.0000	time 0.3586 (0.2474)	loss 0.7012 (0.8963)	grad_norm 0.2835 (0.2803)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:31:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:03 lr 0.000079	 wd 0.0000	time 0.1672 (0.2542)	loss 0.7324 (0.8939)	grad_norm 0.2962 (0.2800)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:32:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:19 lr 0.000078	 wd 0.0000	time 0.1903 (0.2439)	loss 0.9692 (0.8948)	grad_norm 0.2828 (0.2801)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:32:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:06:42 lr 0.000078	 wd 0.0000	time 0.1801 (0.2362)	loss 0.9199 (0.8959)	grad_norm 0.2637 (0.2799)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:32:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:09 lr 0.000078	 wd 0.0000	time 0.2207 (0.2309)	loss 1.0742 (0.8965)	grad_norm 0.2763 (0.2798)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:33:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:09 lr 0.000078	 wd 0.0000	time 0.1839 (0.2461)	loss 0.9526 (0.8969)	grad_norm 0.2834 (0.2797)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:33:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:36 lr 0.000078	 wd 0.0000	time 0.1675 (0.2402)	loss 0.8066 (0.8970)	grad_norm 0.2932 (0.2796)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:33:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:06 lr 0.000078	 wd 0.0000	time 0.1826 (0.2353)	loss 0.9761 (0.8967)	grad_norm 0.2890 (0.2796)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:34:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:38 lr 0.000077	 wd 0.0000	time 0.2149 (0.2314)	loss 0.9375 (0.8969)	grad_norm 0.2671 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:34:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:12 lr 0.000077	 wd 0.0000	time 0.2142 (0.2293)	loss 0.9121 (0.8974)	grad_norm 0.2688 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:34:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:03:48 lr 0.000077	 wd 0.0000	time 0.1970 (0.2284)	loss 0.9819 (0.8976)	grad_norm 0.2845 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7518MB
[2024-07-31 11:35:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:23 lr 0.000077	 wd 0.0000	time 0.1672 (0.2257)	loss 0.9180 (0.8972)	grad_norm 0.2685 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7518MB
[2024-07-31 11:35:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:02:58 lr 0.000077	 wd 0.0000	time 0.1812 (0.2232)	loss 0.8301 (0.8979)	grad_norm 0.2641 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7518MB
[2024-07-31 11:35:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:35 lr 0.000077	 wd 0.0000	time 0.1717 (0.2213)	loss 0.7339 (0.8977)	grad_norm 0.2800 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7518MB
[2024-07-31 11:36:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:13 lr 0.000076	 wd 0.0000	time 0.4102 (0.2218)	loss 0.9375 (0.8978)	grad_norm 0.2785 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7518MB
[2024-07-31 11:36:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:01:50 lr 0.000076	 wd 0.0000	time 0.2011 (0.2206)	loss 0.9087 (0.8986)	grad_norm 0.2667 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7518MB
[2024-07-31 11:36:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:28 lr 0.000076	 wd 0.0000	time 0.1891 (0.2190)	loss 1.0371 (0.8991)	grad_norm 0.2710 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7518MB
[2024-07-31 11:37:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:05 lr 0.000076	 wd 0.0000	time 0.1853 (0.2174)	loss 0.9219 (0.8994)	grad_norm 0.2703 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7518MB
[2024-07-31 11:37:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:43 lr 0.000076	 wd 0.0000	time 0.1723 (0.2162)	loss 0.8970 (0.8990)	grad_norm 0.2978 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7518MB
[2024-07-31 11:37:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:22 lr 0.000075	 wd 0.0000	time 0.1592 (0.2161)	loss 0.8208 (0.8990)	grad_norm 0.2815 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7518MB
[2024-07-31 11:38:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000075	 wd 0.0000	time 0.1487 (0.2146)	loss 0.8638 (0.8990)	grad_norm 0.2688 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7518MB
[2024-07-31 11:38:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 9 training takes 0:09:01
[2024-07-31 11:38:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 20.047 (20.047)	Loss 0.3562 (0.3562)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7518MB
[2024-07-31 11:38:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.812 Acc@5 97.504
[2024-07-31 11:38:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-31 11:38:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-31 11:39:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][0/2502]	eta 15:42:03 lr 0.000075	 wd 0.0000	time 22.5913 (22.5913)	loss 1.0566 (1.0566)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:39:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:20:26 lr 0.000075	 wd 0.0000	time 0.1758 (0.5108)	loss 0.7573 (0.9129)	grad_norm 0.2755 (0.2800)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:40:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:13:17 lr 0.000075	 wd 0.0000	time 0.1706 (0.3464)	loss 0.9854 (0.9044)	grad_norm 0.2884 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:40:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:42 lr 0.000075	 wd 0.0000	time 0.1750 (0.2919)	loss 0.8887 (0.8991)	grad_norm 0.2744 (0.2792)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:40:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:14 lr 0.000075	 wd 0.0000	time 0.1837 (0.2638)	loss 0.9238 (0.8977)	grad_norm 0.2817 (0.2793)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:41:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:08:37 lr 0.000074	 wd 0.0000	time 0.2962 (0.2585)	loss 0.7847 (0.8988)	grad_norm 0.2877 (0.2796)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:41:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:20 lr 0.000074	 wd 0.0000	time 0.1580 (0.2633)	loss 0.9556 (0.8975)	grad_norm 0.2862 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:41:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:33 lr 0.000074	 wd 0.0000	time 0.1918 (0.2518)	loss 0.8252 (0.8961)	grad_norm 0.2714 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:42:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:06:53 lr 0.000074	 wd 0.0000	time 0.2031 (0.2432)	loss 0.8770 (0.8965)	grad_norm 0.2754 (0.2797)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:42:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:20 lr 0.000074	 wd 0.0000	time 0.3023 (0.2376)	loss 0.8613 (0.8970)	grad_norm 0.2768 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:42:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:08 lr 0.000073	 wd 0.0000	time 0.1752 (0.2455)	loss 0.8462 (0.8972)	grad_norm 0.2773 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:43:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:36 lr 0.000073	 wd 0.0000	time 0.1867 (0.2398)	loss 0.7979 (0.8972)	grad_norm 0.2686 (0.2793)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:43:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:05 lr 0.000073	 wd 0.0000	time 0.1648 (0.2350)	loss 1.0361 (0.8971)	grad_norm 0.2713 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:43:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:37 lr 0.000073	 wd 0.0000	time 0.1726 (0.2309)	loss 0.9116 (0.8971)	grad_norm 0.2795 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:44:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:17 lr 0.000073	 wd 0.0000	time 0.9703 (0.2340)	loss 0.8013 (0.8970)	grad_norm 0.2866 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:44:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:03:55 lr 0.000073	 wd 0.0000	time 0.1746 (0.2352)	loss 0.8706 (0.8968)	grad_norm 0.2914 (0.2793)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:45:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:29 lr 0.000072	 wd 0.0000	time 0.1864 (0.2318)	loss 0.7949 (0.8970)	grad_norm 0.2729 (0.2793)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:45:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:03 lr 0.000072	 wd 0.0000	time 0.1606 (0.2288)	loss 0.8926 (0.8973)	grad_norm 0.2681 (0.2793)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:45:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:39 lr 0.000072	 wd 0.0000	time 0.2152 (0.2267)	loss 0.9536 (0.8972)	grad_norm 0.2959 (0.2793)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:46:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:16 lr 0.000072	 wd 0.0000	time 0.1911 (0.2272)	loss 0.9839 (0.8971)	grad_norm 0.2859 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:46:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:53 lr 0.000072	 wd 0.0000	time 0.1917 (0.2259)	loss 0.8760 (0.8975)	grad_norm 0.2745 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:46:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:30 lr 0.000071	 wd 0.0000	time 0.1907 (0.2241)	loss 0.8691 (0.8976)	grad_norm 0.2978 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:47:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:07 lr 0.000071	 wd 0.0000	time 0.1911 (0.2222)	loss 0.8672 (0.8980)	grad_norm 0.2724 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:47:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:44 lr 0.000071	 wd 0.0000	time 0.2385 (0.2215)	loss 0.9419 (0.8976)	grad_norm 0.2709 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:47:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:22 lr 0.000071	 wd 0.0000	time 0.2163 (0.2213)	loss 0.9121 (0.8981)	grad_norm 0.2690 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:47:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000071	 wd 0.0000	time 0.1496 (0.2193)	loss 1.0068 (0.8976)	grad_norm 0.2849 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:48:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 10 training takes 0:09:13
[2024-07-31 11:48:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 22.486 (22.486)	Loss 0.3633 (0.3633)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 7518MB
[2024-07-31 11:48:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.796 Acc@5 97.482
[2024-07-31 11:48:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-31 11:48:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-31 11:49:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][0/2502]	eta 19:40:04 lr 0.000071	 wd 0.0000	time 28.2991 (28.2991)	loss 0.7993 (0.7993)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:49:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:20:07 lr 0.000070	 wd 0.0000	time 0.2054 (0.5027)	loss 0.9121 (0.8915)	grad_norm 0.2769 (0.2799)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:49:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:13:07 lr 0.000070	 wd 0.0000	time 0.1662 (0.3423)	loss 0.9268 (0.8938)	grad_norm 0.2958 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:50:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:10:36 lr 0.000070	 wd 0.0000	time 0.1815 (0.2892)	loss 1.0195 (0.8951)	grad_norm 0.2804 (0.2799)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:50:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:09:13 lr 0.000070	 wd 0.0000	time 0.1726 (0.2632)	loss 0.9619 (0.8934)	grad_norm 0.2918 (0.2799)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:51:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:09:26 lr 0.000070	 wd 0.0000	time 0.1787 (0.2831)	loss 0.8047 (0.8930)	grad_norm 0.2680 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7518MB
[2024-07-31 11:51:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:28 lr 0.000069	 wd 0.0000	time 0.1991 (0.2674)	loss 1.0625 (0.8915)	grad_norm 0.2846 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7518MB
[2024-07-31 11:51:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:07:40 lr 0.000069	 wd 0.0000	time 0.1922 (0.2556)	loss 0.8838 (0.8941)	grad_norm 0.2831 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7518MB
[2024-07-31 11:51:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:06:59 lr 0.000069	 wd 0.0000	time 0.1791 (0.2465)	loss 0.9360 (0.8950)	grad_norm 0.2762 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7518MB
[2024-07-31 11:52:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:06:41 lr 0.000069	 wd 0.0000	time 2.6005 (0.2509)	loss 1.0117 (0.8954)	grad_norm 0.2929 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7518MB
[2024-07-31 11:52:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:16 lr 0.000069	 wd 0.0000	time 0.1825 (0.2505)	loss 0.8442 (0.8966)	grad_norm 0.2779 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7518MB
[2024-07-31 11:53:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:42 lr 0.000069	 wd 0.0000	time 0.1858 (0.2444)	loss 0.8252 (0.8969)	grad_norm 0.2783 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7518MB
[2024-07-31 11:53:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:11 lr 0.000068	 wd 0.0000	time 0.1772 (0.2391)	loss 0.9644 (0.8971)	grad_norm 0.2795 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7518MB
[2024-07-31 11:53:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:04:42 lr 0.000068	 wd 0.0000	time 0.2458 (0.2353)	loss 0.7759 (0.8973)	grad_norm 0.2696 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7518MB
[2024-07-31 11:54:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:23 lr 0.000068	 wd 0.0000	time 0.1956 (0.2391)	loss 0.8550 (0.8980)	grad_norm 0.2885 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7518MB
[2024-07-31 11:54:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:03:55 lr 0.000068	 wd 0.0000	time 0.1773 (0.2352)	loss 0.9512 (0.8977)	grad_norm 0.2900 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7518MB
[2024-07-31 11:54:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:29 lr 0.000068	 wd 0.0000	time 0.1595 (0.2320)	loss 0.9385 (0.8979)	grad_norm 0.2910 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7518MB
[2024-07-31 11:55:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:03 lr 0.000067	 wd 0.0000	time 0.1751 (0.2291)	loss 0.8057 (0.8980)	grad_norm 0.2797 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7518MB
[2024-07-31 11:55:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:39 lr 0.000067	 wd 0.0000	time 0.1879 (0.2275)	loss 1.1182 (0.8988)	grad_norm 0.2731 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7518MB
[2024-07-31 11:55:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:16 lr 0.000067	 wd 0.0000	time 0.1746 (0.2276)	loss 0.7886 (0.8993)	grad_norm 0.2681 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7518MB
[2024-07-31 11:56:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:01:53 lr 0.000067	 wd 0.0000	time 0.1799 (0.2258)	loss 0.9302 (0.8989)	grad_norm 0.2688 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7518MB
[2024-07-31 11:56:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:30 lr 0.000067	 wd 0.0000	time 0.1949 (0.2239)	loss 0.8789 (0.8988)	grad_norm 0.2946 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7518MB
[2024-07-31 11:56:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:07 lr 0.000066	 wd 0.0000	time 0.2044 (0.2222)	loss 0.9243 (0.8987)	grad_norm 0.2789 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7518MB
[2024-07-31 11:57:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:44 lr 0.000066	 wd 0.0000	time 0.1845 (0.2214)	loss 0.8647 (0.8987)	grad_norm 0.2818 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7518MB
[2024-07-31 11:57:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:22 lr 0.000066	 wd 0.0000	time 0.1519 (0.2213)	loss 0.8931 (0.8991)	grad_norm 0.2783 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7518MB
[2024-07-31 11:57:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000066	 wd 0.0000	time 0.1489 (0.2191)	loss 1.0762 (0.8983)	grad_norm 0.2782 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7518MB
[2024-07-31 11:57:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 11 training takes 0:09:13
[2024-07-31 11:58:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 18.848 (18.848)	Loss 0.3604 (0.3604)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 7518MB
[2024-07-31 11:58:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.868 Acc@5 97.474
[2024-07-31 11:58:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 11:58:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.87%
[2024-07-31 11:58:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-31 11:58:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-31 11:58:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][0/2502]	eta 22:37:17 lr 0.000066	 wd 0.0000	time 32.5490 (32.5490)	loss 0.9370 (0.9370)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:59:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:21:03 lr 0.000066	 wd 0.0000	time 0.1793 (0.5259)	loss 0.8403 (0.8873)	grad_norm 0.2804 (0.2806)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:59:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:13:36 lr 0.000065	 wd 0.0000	time 0.1827 (0.3546)	loss 0.8691 (0.8931)	grad_norm 0.2756 (0.2796)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 11:59:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:52 lr 0.000065	 wd 0.0000	time 0.1783 (0.2965)	loss 0.9268 (0.9029)	grad_norm 0.3083 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:00:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:49 lr 0.000065	 wd 0.0000	time 0.3277 (0.2804)	loss 0.8682 (0.9045)	grad_norm 0.2771 (0.2796)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:00:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:09:28 lr 0.000065	 wd 0.0000	time 0.1854 (0.2839)	loss 0.7886 (0.9028)	grad_norm 0.2838 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:01:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:08:28 lr 0.000065	 wd 0.0000	time 0.1795 (0.2673)	loss 0.7993 (0.9029)	grad_norm 0.2833 (0.2797)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:01:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:39 lr 0.000064	 wd 0.0000	time 0.1690 (0.2550)	loss 0.8330 (0.9024)	grad_norm 0.2766 (0.2797)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:01:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:06:59 lr 0.000064	 wd 0.0000	time 0.2116 (0.2465)	loss 0.9419 (0.9010)	grad_norm 0.2679 (0.2798)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:02:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:55 lr 0.000064	 wd 0.0000	time 0.2035 (0.2592)	loss 0.8374 (0.9003)	grad_norm 0.2868 (0.2800)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:02:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:17 lr 0.000064	 wd 0.0000	time 0.1654 (0.2517)	loss 0.9414 (0.9006)	grad_norm 0.2711 (0.2800)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:02:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:43 lr 0.000064	 wd 0.0000	time 0.1816 (0.2453)	loss 0.7695 (0.9005)	grad_norm 0.2749 (0.2799)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:03:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:12 lr 0.000063	 wd 0.0000	time 0.2114 (0.2401)	loss 0.9009 (0.8996)	grad_norm 0.2914 (0.2800)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:03:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:45 lr 0.000063	 wd 0.0000	time 0.2097 (0.2376)	loss 0.8091 (0.8997)	grad_norm 0.2975 (0.2798)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:03:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:19 lr 0.000063	 wd 0.0000	time 0.1799 (0.2359)	loss 0.9663 (0.8999)	grad_norm 0.2773 (0.2798)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:04:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:03:53 lr 0.000063	 wd 0.0000	time 0.1871 (0.2326)	loss 0.8857 (0.9007)	grad_norm 0.2856 (0.2798)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:04:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:27 lr 0.000063	 wd 0.0000	time 0.1729 (0.2296)	loss 0.8696 (0.9000)	grad_norm 0.2695 (0.2798)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:04:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:01 lr 0.000062	 wd 0.0000	time 0.1797 (0.2269)	loss 0.8711 (0.9000)	grad_norm 0.2720 (0.2798)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:05:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:38 lr 0.000062	 wd 0.0000	time 0.1885 (0.2255)	loss 0.8154 (0.9002)	grad_norm 0.2991 (0.2800)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:05:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:15 lr 0.000062	 wd 0.0000	time 0.1802 (0.2257)	loss 0.8633 (0.8999)	grad_norm 0.2713 (0.2799)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:05:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:01:52 lr 0.000062	 wd 0.0000	time 0.1705 (0.2239)	loss 0.8418 (0.9001)	grad_norm 0.2900 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7518MB
[2024-07-31 12:06:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:29 lr 0.000062	 wd 0.0000	time 0.1698 (0.2221)	loss 0.8604 (0.9005)	grad_norm 0.2860 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7518MB
[2024-07-31 12:06:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:06 lr 0.000061	 wd 0.0000	time 0.1833 (0.2205)	loss 0.9248 (0.9007)	grad_norm 0.2879 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7518MB
[2024-07-31 12:06:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:44 lr 0.000061	 wd 0.0000	time 0.7732 (0.2208)	loss 0.8789 (0.9004)	grad_norm 0.2579 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7518MB
[2024-07-31 12:07:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:22 lr 0.000061	 wd 0.0000	time 0.1982 (0.2198)	loss 0.8921 (0.8997)	grad_norm 0.2793 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7518MB
[2024-07-31 12:07:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000061	 wd 0.0000	time 0.1493 (0.2177)	loss 0.9043 (0.8995)	grad_norm 0.2826 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7518MB
[2024-07-31 12:07:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 12 training takes 0:09:12
[2024-07-31 12:07:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 18.895 (18.895)	Loss 0.3577 (0.3577)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 12:08:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.838 Acc@5 97.468
[2024-07-31 12:08:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-31 12:08:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.87%
[2024-07-31 12:08:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][0/2502]	eta 1 day, 2:13:57 lr 0.000061	 wd 0.0000	time 37.7448 (37.7448)	loss 0.8765 (0.8765)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:09:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:22:20 lr 0.000061	 wd 0.0000	time 0.1694 (0.5582)	loss 0.8052 (0.8901)	grad_norm 0.2719 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:09:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:14:08 lr 0.000060	 wd 0.0000	time 0.1642 (0.3685)	loss 0.8057 (0.8996)	grad_norm 0.2876 (0.2797)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:09:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:11:23 lr 0.000060	 wd 0.0000	time 0.2192 (0.3105)	loss 0.7998 (0.8936)	grad_norm 0.2869 (0.2797)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:10:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:11:11 lr 0.000060	 wd 0.0000	time 0.1679 (0.3193)	loss 0.7871 (0.8945)	grad_norm 0.2864 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:10:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:09:44 lr 0.000060	 wd 0.0000	time 0.2029 (0.2919)	loss 0.8574 (0.8946)	grad_norm 0.2740 (0.2798)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:11:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:40 lr 0.000060	 wd 0.0000	time 0.1582 (0.2739)	loss 0.8135 (0.8959)	grad_norm 0.2788 (0.2803)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:11:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:07:49 lr 0.000059	 wd 0.0000	time 0.2092 (0.2606)	loss 1.0146 (0.8962)	grad_norm 0.2985 (0.2802)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:11:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:42 lr 0.000059	 wd 0.0000	time 0.3413 (0.2718)	loss 0.9429 (0.8961)	grad_norm 0.2786 (0.2800)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:12:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:07:02 lr 0.000059	 wd 0.0000	time 0.1838 (0.2639)	loss 0.9224 (0.8969)	grad_norm 0.2877 (0.2802)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:12:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:24 lr 0.000059	 wd 0.0000	time 0.1900 (0.2557)	loss 1.0049 (0.8980)	grad_norm 0.2809 (0.2804)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:12:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:48 lr 0.000059	 wd 0.0000	time 0.1618 (0.2488)	loss 0.8696 (0.8975)	grad_norm 0.2768 (0.2803)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:13:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:19 lr 0.000058	 wd 0.0000	time 0.3208 (0.2452)	loss 0.9937 (0.8977)	grad_norm 0.2863 (0.2802)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:13:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:04:59 lr 0.000058	 wd 0.0000	time 0.1663 (0.2494)	loss 0.9116 (0.8982)	grad_norm 0.2829 (0.2803)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:13:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:29 lr 0.000058	 wd 0.0000	time 0.1996 (0.2446)	loss 1.0830 (0.8980)	grad_norm 0.2737 (0.2803)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:14:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:04:00 lr 0.000058	 wd 0.0000	time 0.1762 (0.2404)	loss 0.9082 (0.8981)	grad_norm 0.2853 (0.2804)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:14:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:33 lr 0.000058	 wd 0.0000	time 0.1963 (0.2371)	loss 0.8574 (0.8986)	grad_norm 0.2988 (0.2804)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:14:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:09 lr 0.000057	 wd 0.0000	time 2.1323 (0.2363)	loss 0.8647 (0.8987)	grad_norm 0.2759 (0.2804)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:15:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:44 lr 0.000057	 wd 0.0000	time 0.2078 (0.2343)	loss 0.8521 (0.8987)	grad_norm 0.2940 (0.2805)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:15:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:19 lr 0.000057	 wd 0.0000	time 0.1882 (0.2317)	loss 0.8169 (0.8975)	grad_norm 0.2895 (0.2805)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:15:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:55 lr 0.000057	 wd 0.0000	time 0.2202 (0.2296)	loss 0.8862 (0.8981)	grad_norm 0.2719 (0.2806)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:16:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:31 lr 0.000057	 wd 0.0000	time 0.2120 (0.2277)	loss 0.9014 (0.8986)	grad_norm 0.2569 (0.2805)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:16:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:08 lr 0.000056	 wd 0.0000	time 0.1776 (0.2278)	loss 0.9824 (0.8986)	grad_norm 0.2888 (0.2805)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:16:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:45 lr 0.000056	 wd 0.0000	time 0.1593 (0.2265)	loss 0.8271 (0.8981)	grad_norm 0.2827 (0.2805)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:17:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:22 lr 0.000056	 wd 0.0000	time 0.1911 (0.2249)	loss 0.8936 (0.8986)	grad_norm 0.2735 (0.2805)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:17:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000056	 wd 0.0000	time 0.1507 (0.2225)	loss 0.8496 (0.8986)	grad_norm 0.2725 (0.2805)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:17:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 13 training takes 0:09:24
[2024-07-31 12:18:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 40.865 (40.865)	Loss 0.3586 (0.3586)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 12:18:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.854 Acc@5 97.504
[2024-07-31 12:18:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 12:18:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.87%
[2024-07-31 12:18:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][0/2502]	eta 11:44:10 lr 0.000056	 wd 0.0000	time 16.8868 (16.8868)	loss 0.9873 (0.9873)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:19:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:13:57 lr 0.000055	 wd 0.0000	time 0.1754 (0.3488)	loss 0.8696 (0.8927)	grad_norm 0.2853 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:19:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:11:22 lr 0.000055	 wd 0.0000	time 0.3720 (0.2964)	loss 0.8652 (0.8953)	grad_norm 0.2703 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:20:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:10:49 lr 0.000055	 wd 0.0000	time 0.1820 (0.2949)	loss 1.1631 (0.8986)	grad_norm 0.2717 (0.2792)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:20:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:09:19 lr 0.000055	 wd 0.0000	time 0.1909 (0.2663)	loss 1.1084 (0.8976)	grad_norm 0.2729 (0.2801)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:20:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:08:18 lr 0.000055	 wd 0.0000	time 0.1731 (0.2491)	loss 0.9365 (0.8973)	grad_norm 0.2592 (0.2797)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:21:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:07:34 lr 0.000054	 wd 0.0000	time 0.2018 (0.2389)	loss 0.8711 (0.8980)	grad_norm 0.2970 (0.2799)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:21:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:40 lr 0.000054	 wd 0.0000	time 0.2649 (0.2553)	loss 0.8115 (0.8972)	grad_norm 0.2804 (0.2803)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:21:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:06:59 lr 0.000054	 wd 0.0000	time 0.2003 (0.2465)	loss 0.8037 (0.8972)	grad_norm 0.2727 (0.2802)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:22:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:23 lr 0.000054	 wd 0.0000	time 0.1822 (0.2397)	loss 0.8931 (0.8969)	grad_norm 0.2958 (0.2803)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:22:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:05:51 lr 0.000054	 wd 0.0000	time 0.1887 (0.2338)	loss 0.9268 (0.8962)	grad_norm 0.2996 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7518MB
[2024-07-31 12:23:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:38 lr 0.000053	 wd 0.0000	time 0.1553 (0.2413)	loss 0.8403 (0.8959)	grad_norm 0.2667 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7518MB
[2024-07-31 12:23:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:08 lr 0.000053	 wd 0.0000	time 0.2024 (0.2370)	loss 0.8896 (0.8959)	grad_norm 0.2866 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7518MB
[2024-07-31 12:23:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:04:39 lr 0.000053	 wd 0.0000	time 0.1997 (0.2327)	loss 1.0928 (0.8957)	grad_norm 0.2839 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7518MB
[2024-07-31 12:24:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:12 lr 0.000053	 wd 0.0000	time 0.1854 (0.2290)	loss 0.8979 (0.8958)	grad_norm 0.2672 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7518MB
[2024-07-31 12:24:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:03:47 lr 0.000053	 wd 0.0000	time 0.2336 (0.2266)	loss 0.8721 (0.8961)	grad_norm 0.2789 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7518MB
[2024-07-31 12:24:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:25 lr 0.000052	 wd 0.0000	time 0.1595 (0.2280)	loss 0.9028 (0.8956)	grad_norm 0.2817 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7518MB
[2024-07-31 12:25:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:00 lr 0.000052	 wd 0.0000	time 0.1721 (0.2254)	loss 1.0732 (0.8961)	grad_norm 0.2962 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7518MB
[2024-07-31 12:25:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:36 lr 0.000052	 wd 0.0000	time 0.1818 (0.2232)	loss 0.7114 (0.8963)	grad_norm 0.2822 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7518MB
[2024-07-31 12:25:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:13 lr 0.000052	 wd 0.0000	time 0.1986 (0.2212)	loss 0.8394 (0.8960)	grad_norm 0.2756 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7518MB
[2024-07-31 12:26:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:01:50 lr 0.000052	 wd 0.0000	time 0.1974 (0.2200)	loss 0.8325 (0.8959)	grad_norm 0.2801 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7518MB
[2024-07-31 12:26:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:28 lr 0.000051	 wd 0.0000	time 0.1764 (0.2204)	loss 0.9482 (0.8959)	grad_norm 0.2688 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7518MB
[2024-07-31 12:26:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:06 lr 0.000051	 wd 0.0000	time 0.1748 (0.2193)	loss 0.8882 (0.8966)	grad_norm 0.2725 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7518MB
[2024-07-31 12:27:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:43 lr 0.000051	 wd 0.0000	time 0.1913 (0.2178)	loss 0.8491 (0.8963)	grad_norm 0.2840 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7518MB
[2024-07-31 12:27:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:22 lr 0.000051	 wd 0.0000	time 0.1813 (0.2164)	loss 0.9868 (0.8968)	grad_norm 0.2868 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7518MB
[2024-07-31 12:27:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000051	 wd 0.0000	time 0.1485 (0.2145)	loss 0.9370 (0.8971)	grad_norm 0.2809 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7518MB
[2024-07-31 12:27:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 14 training takes 0:09:05
[2024-07-31 12:28:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 36.156 (36.156)	Loss 0.3564 (0.3564)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 12:28:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.864 Acc@5 97.450
[2024-07-31 12:28:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 12:28:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.87%
[2024-07-31 12:28:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][0/2502]	eta 11:11:41 lr 0.000051	 wd 0.0000	time 16.1076 (16.1076)	loss 0.8262 (0.8262)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:29:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:15:05 lr 0.000050	 wd 0.0000	time 0.2985 (0.3770)	loss 0.9873 (0.9052)	grad_norm 0.2768 (0.2802)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:29:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:12:03 lr 0.000050	 wd 0.0000	time 0.1652 (0.3144)	loss 1.0078 (0.9010)	grad_norm 0.2795 (0.2810)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:30:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:09:55 lr 0.000050	 wd 0.0000	time 0.1962 (0.2706)	loss 0.9375 (0.8983)	grad_norm 0.2699 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:30:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:08:41 lr 0.000050	 wd 0.0000	time 0.1756 (0.2482)	loss 1.0195 (0.8994)	grad_norm 0.2890 (0.2811)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:30:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:07:49 lr 0.000049	 wd 0.0000	time 0.1856 (0.2344)	loss 0.8184 (0.9012)	grad_norm 0.2852 (0.2815)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:31:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:07:55 lr 0.000049	 wd 0.0000	time 0.1883 (0.2501)	loss 0.8442 (0.9007)	grad_norm 0.2978 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:31:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:15 lr 0.000049	 wd 0.0000	time 0.2136 (0.2419)	loss 0.8413 (0.8978)	grad_norm 0.2837 (0.2811)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:31:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:06:39 lr 0.000049	 wd 0.0000	time 0.1623 (0.2346)	loss 1.0342 (0.8983)	grad_norm 0.2912 (0.2811)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:32:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:05 lr 0.000049	 wd 0.0000	time 0.1627 (0.2283)	loss 0.8223 (0.8986)	grad_norm 0.2834 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:32:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:05:39 lr 0.000048	 wd 0.0000	time 0.3657 (0.2263)	loss 0.9424 (0.8982)	grad_norm 0.2766 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:33:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:30 lr 0.000048	 wd 0.0000	time 0.1960 (0.2361)	loss 0.9551 (0.8960)	grad_norm 0.2884 (0.2809)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:33:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:01 lr 0.000048	 wd 0.0000	time 0.1764 (0.2316)	loss 0.8174 (0.8970)	grad_norm 0.2748 (0.2808)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:33:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:04:33 lr 0.000048	 wd 0.0000	time 0.1702 (0.2277)	loss 0.9253 (0.8966)	grad_norm 0.2710 (0.2809)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:33:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:07 lr 0.000048	 wd 0.0000	time 0.1779 (0.2247)	loss 0.8228 (0.8970)	grad_norm 0.2881 (0.2809)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:34:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:03:45 lr 0.000047	 wd 0.0000	time 0.3229 (0.2246)	loss 0.9653 (0.8965)	grad_norm 0.2741 (0.2811)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:34:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:20 lr 0.000047	 wd 0.0000	time 0.1951 (0.2227)	loss 0.9722 (0.8967)	grad_norm 0.2807 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:34:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:02:56 lr 0.000047	 wd 0.0000	time 0.1951 (0.2205)	loss 0.8257 (0.8970)	grad_norm 0.2757 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:35:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:33 lr 0.000047	 wd 0.0000	time 0.1995 (0.2185)	loss 1.0547 (0.8975)	grad_norm 0.2907 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:35:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:10 lr 0.000047	 wd 0.0000	time 0.1728 (0.2170)	loss 0.9819 (0.8970)	grad_norm 0.2903 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:35:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:01:49 lr 0.000046	 wd 0.0000	time 0.1784 (0.2175)	loss 1.0312 (0.8979)	grad_norm 0.3032 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:36:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:27 lr 0.000046	 wd 0.0000	time 0.1662 (0.2169)	loss 0.8726 (0.8977)	grad_norm 0.2694 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:36:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:05 lr 0.000046	 wd 0.0000	time 0.1758 (0.2156)	loss 0.9111 (0.8980)	grad_norm 0.2773 (0.2811)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:36:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:43 lr 0.000046	 wd 0.0000	time 0.1671 (0.2143)	loss 0.9253 (0.8980)	grad_norm 0.2982 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:37:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:21 lr 0.000046	 wd 0.0000	time 0.3208 (0.2136)	loss 0.9468 (0.8979)	grad_norm 0.2872 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:37:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000045	 wd 0.0000	time 0.1504 (0.2126)	loss 1.1094 (0.8983)	grad_norm 0.2795 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7518MB
[2024-07-31 12:37:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 15 training takes 0:09:05
[2024-07-31 12:37:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_15.pth saving......
[2024-07-31 12:37:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_15.pth saved !!!
[2024-07-31 12:38:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 26.716 (26.716)	Loss 0.3584 (0.3584)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 12:38:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.888 Acc@5 97.502
[2024-07-31 12:38:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 12:38:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.89%
[2024-07-31 12:38:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-31 12:38:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-31 12:38:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][0/2502]	eta 12:14:23 lr 0.000045	 wd 0.0000	time 17.6111 (17.6111)	loss 0.7642 (0.7642)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:39:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:16:51 lr 0.000045	 wd 0.0000	time 0.1582 (0.4213)	loss 1.0010 (0.9120)	grad_norm 0.2846 (0.2843)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:39:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:11:41 lr 0.000045	 wd 0.0000	time 0.1977 (0.3046)	loss 0.8940 (0.8990)	grad_norm 0.2917 (0.2825)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:39:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:09:40 lr 0.000045	 wd 0.0000	time 0.1706 (0.2636)	loss 0.9634 (0.9006)	grad_norm 0.2746 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:40:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:08:30 lr 0.000045	 wd 0.0000	time 0.1831 (0.2430)	loss 0.9326 (0.9001)	grad_norm 0.2867 (0.2811)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:40:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:07:57 lr 0.000044	 wd 0.0000	time 0.3745 (0.2383)	loss 0.9990 (0.8997)	grad_norm 0.2799 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:41:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:15 lr 0.000044	 wd 0.0000	time 0.1796 (0.2605)	loss 0.9575 (0.8997)	grad_norm 0.2824 (0.2813)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:41:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:29 lr 0.000044	 wd 0.0000	time 0.1955 (0.2493)	loss 0.9209 (0.8997)	grad_norm 0.2759 (0.2813)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:41:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:06:49 lr 0.000044	 wd 0.0000	time 0.1856 (0.2408)	loss 0.8906 (0.8993)	grad_norm 0.2715 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:42:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:16 lr 0.000043	 wd 0.0000	time 0.2234 (0.2353)	loss 0.8120 (0.9006)	grad_norm 0.2960 (0.2815)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:42:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:05:53 lr 0.000043	 wd 0.0000	time 0.1814 (0.2354)	loss 0.8774 (0.9008)	grad_norm 0.2819 (0.2816)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:42:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:23 lr 0.000043	 wd 0.0000	time 0.1696 (0.2310)	loss 0.9956 (0.9010)	grad_norm 0.2914 (0.2817)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:43:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:04:56 lr 0.000043	 wd 0.0000	time 0.1764 (0.2274)	loss 0.8994 (0.9005)	grad_norm 0.2825 (0.2816)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:43:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:04:29 lr 0.000043	 wd 0.0000	time 0.1818 (0.2242)	loss 0.9868 (0.8999)	grad_norm 0.2804 (0.2816)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:43:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:05 lr 0.000042	 wd 0.0000	time 0.2568 (0.2224)	loss 0.8242 (0.8992)	grad_norm 0.2714 (0.2815)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:44:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:03:43 lr 0.000042	 wd 0.0000	time 0.1742 (0.2230)	loss 0.8491 (0.8988)	grad_norm 0.2612 (0.2815)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:44:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:19 lr 0.000042	 wd 0.0000	time 0.1799 (0.2208)	loss 0.8276 (0.8988)	grad_norm 0.2809 (0.2814)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:44:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:02:55 lr 0.000042	 wd 0.0000	time 0.1785 (0.2188)	loss 0.8799 (0.8985)	grad_norm 0.2851 (0.2816)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:45:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:32 lr 0.000042	 wd 0.0000	time 0.2294 (0.2170)	loss 1.0674 (0.8987)	grad_norm 0.2628 (0.2816)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:45:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:10 lr 0.000041	 wd 0.0000	time 0.1848 (0.2160)	loss 1.0195 (0.8977)	grad_norm 0.2890 (0.2815)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:45:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:01:48 lr 0.000041	 wd 0.0000	time 0.2826 (0.2165)	loss 0.8765 (0.8974)	grad_norm 0.2868 (0.2814)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:46:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:26 lr 0.000041	 wd 0.0000	time 0.1735 (0.2154)	loss 0.6992 (0.8970)	grad_norm 0.2767 (0.2815)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:46:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:04 lr 0.000041	 wd 0.0000	time 0.1781 (0.2141)	loss 0.7891 (0.8969)	grad_norm 0.2830 (0.2815)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:46:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:42 lr 0.000041	 wd 0.0000	time 0.1685 (0.2128)	loss 0.6992 (0.8963)	grad_norm 0.2933 (0.2815)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:47:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:21 lr 0.000040	 wd 0.0000	time 0.1920 (0.2124)	loss 0.8008 (0.8962)	grad_norm 0.2863 (0.2814)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:47:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1498 (0.2110)	loss 0.8740 (0.8960)	grad_norm 0.3022 (0.2814)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:47:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 16 training takes 0:08:58
[2024-07-31 12:47:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 19.914 (19.914)	Loss 0.3589 (0.3589)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 12:48:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.844 Acc@5 97.474
[2024-07-31 12:48:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-31 12:48:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.89%
[2024-07-31 12:48:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][0/2502]	eta 15:50:40 lr 0.000040	 wd 0.0000	time 22.7978 (22.7978)	loss 0.7783 (0.7783)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:49:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:21:05 lr 0.000040	 wd 0.0000	time 0.1548 (0.5267)	loss 0.9814 (0.8985)	grad_norm 0.2678 (0.2808)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:49:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:13:36 lr 0.000040	 wd 0.0000	time 0.1578 (0.3546)	loss 0.8755 (0.9014)	grad_norm 0.2715 (0.2811)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:49:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:54 lr 0.000040	 wd 0.0000	time 0.1792 (0.2971)	loss 0.8916 (0.8977)	grad_norm 0.3013 (0.2813)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:49:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:09:23 lr 0.000039	 wd 0.0000	time 0.1613 (0.2681)	loss 0.9575 (0.8961)	grad_norm 0.2746 (0.2816)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:50:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:08:52 lr 0.000039	 wd 0.0000	time 0.4048 (0.2662)	loss 0.7773 (0.8941)	grad_norm 0.3028 (0.2816)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:50:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:24 lr 0.000039	 wd 0.0000	time 0.1618 (0.2650)	loss 0.8223 (0.8956)	grad_norm 0.2947 (0.2818)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:51:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:36 lr 0.000039	 wd 0.0000	time 0.1602 (0.2532)	loss 0.9170 (0.8948)	grad_norm 0.2791 (0.2818)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:51:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:06:55 lr 0.000039	 wd 0.0000	time 0.1511 (0.2440)	loss 0.8174 (0.8947)	grad_norm 0.2779 (0.2816)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:51:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:23 lr 0.000038	 wd 0.0000	time 0.3344 (0.2392)	loss 0.9941 (0.8952)	grad_norm 0.2741 (0.2813)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:52:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:24 lr 0.000038	 wd 0.0000	time 0.1720 (0.2561)	loss 0.9468 (0.8953)	grad_norm 0.2849 (0.2813)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:52:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:49 lr 0.000038	 wd 0.0000	time 0.1884 (0.2494)	loss 0.7759 (0.8966)	grad_norm 0.2778 (0.2814)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:53:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:17 lr 0.000038	 wd 0.0000	time 0.1674 (0.2437)	loss 0.7935 (0.8979)	grad_norm 0.2951 (0.2816)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:53:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:04:47 lr 0.000038	 wd 0.0000	time 0.2095 (0.2394)	loss 0.9326 (0.8971)	grad_norm 0.2697 (0.2815)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:53:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:21 lr 0.000037	 wd 0.0000	time 0.1877 (0.2377)	loss 0.9277 (0.8979)	grad_norm 0.2658 (0.2815)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:54:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:03:55 lr 0.000037	 wd 0.0000	time 0.1792 (0.2350)	loss 0.8931 (0.8977)	grad_norm 0.2893 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7518MB
[2024-07-31 12:54:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:29 lr 0.000037	 wd 0.0000	time 0.1836 (0.2320)	loss 1.0791 (0.8976)	grad_norm 0.2874 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7518MB
[2024-07-31 12:54:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:03 lr 0.000037	 wd 0.0000	time 0.1932 (0.2293)	loss 1.0508 (0.8977)	grad_norm 0.2822 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7518MB
[2024-07-31 12:54:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:39 lr 0.000037	 wd 0.0000	time 0.2101 (0.2272)	loss 0.8159 (0.8990)	grad_norm 0.2946 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7518MB
[2024-07-31 12:55:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:17 lr 0.000036	 wd 0.0000	time 0.1753 (0.2277)	loss 0.7769 (0.8994)	grad_norm 0.2799 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7518MB
[2024-07-31 12:55:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:01:53 lr 0.000036	 wd 0.0000	time 0.1782 (0.2260)	loss 0.8188 (0.8990)	grad_norm 0.2781 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7518MB
[2024-07-31 12:56:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:30 lr 0.000036	 wd 0.0000	time 0.1843 (0.2242)	loss 0.8291 (0.8984)	grad_norm 0.2690 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7518MB
[2024-07-31 12:56:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:07 lr 0.000036	 wd 0.0000	time 0.1762 (0.2223)	loss 0.9849 (0.8983)	grad_norm 0.2760 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7518MB
[2024-07-31 12:56:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:44 lr 0.000036	 wd 0.0000	time 0.2113 (0.2210)	loss 0.9434 (0.8979)	grad_norm 0.2755 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7518MB
[2024-07-31 12:57:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:22 lr 0.000035	 wd 0.0000	time 0.2349 (0.2214)	loss 0.8315 (0.8982)	grad_norm 0.2808 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7518MB
[2024-07-31 12:57:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1505 (0.2194)	loss 0.9487 (0.8985)	grad_norm 0.2818 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7518MB
[2024-07-31 12:57:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 17 training takes 0:09:16
[2024-07-31 12:57:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 23.894 (23.894)	Loss 0.3564 (0.3564)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 12:58:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.890 Acc@5 97.478
[2024-07-31 12:58:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 12:58:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.89%
[2024-07-31 12:58:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-31 12:58:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-31 12:58:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][0/2502]	eta 1 day, 0:10:40 lr 0.000035	 wd 0.0000	time 34.7884 (34.7884)	loss 0.9209 (0.9209)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:59:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:21:16 lr 0.000035	 wd 0.0000	time 0.1719 (0.5312)	loss 1.0195 (0.9039)	grad_norm 0.2952 (0.2841)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:59:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:13:42 lr 0.000035	 wd 0.0000	time 0.1626 (0.3571)	loss 0.8716 (0.8976)	grad_norm 0.2879 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 12:59:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:10:56 lr 0.000035	 wd 0.0000	time 0.1859 (0.2981)	loss 0.9380 (0.9009)	grad_norm 0.2779 (0.2830)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:00:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:10:38 lr 0.000034	 wd 0.0000	time 0.1567 (0.3038)	loss 0.8081 (0.9027)	grad_norm 0.2939 (0.2827)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:00:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:09:46 lr 0.000034	 wd 0.0000	time 0.2010 (0.2930)	loss 0.7246 (0.9026)	grad_norm 0.2806 (0.2821)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:00:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:08:42 lr 0.000034	 wd 0.0000	time 0.1969 (0.2747)	loss 0.9551 (0.8985)	grad_norm 0.2864 (0.2821)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:01:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:07:50 lr 0.000034	 wd 0.0000	time 0.1687 (0.2609)	loss 0.9463 (0.8957)	grad_norm 0.2716 (0.2818)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:01:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:13 lr 0.000034	 wd 0.0000	time 0.3644 (0.2548)	loss 1.0830 (0.8939)	grad_norm 0.2693 (0.2816)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:02:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:06:56 lr 0.000033	 wd 0.0000	time 0.1882 (0.2601)	loss 0.9692 (0.8945)	grad_norm 0.2964 (0.2816)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:02:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:19 lr 0.000033	 wd 0.0000	time 0.1620 (0.2524)	loss 0.8647 (0.8953)	grad_norm 0.2872 (0.2817)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:02:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:44 lr 0.000033	 wd 0.0000	time 0.1626 (0.2458)	loss 0.8198 (0.8966)	grad_norm 0.2687 (0.2816)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:02:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:13 lr 0.000033	 wd 0.0000	time 0.1926 (0.2408)	loss 0.9150 (0.8962)	grad_norm 0.2811 (0.2817)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:03:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:04:57 lr 0.000033	 wd 0.0000	time 0.2124 (0.2477)	loss 0.8906 (0.8975)	grad_norm 0.2735 (0.2818)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:03:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:28 lr 0.000032	 wd 0.0000	time 0.1781 (0.2432)	loss 1.0361 (0.8968)	grad_norm 0.2887 (0.2818)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:04:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:03:59 lr 0.000032	 wd 0.0000	time 0.1922 (0.2391)	loss 0.8799 (0.8977)	grad_norm 0.2902 (0.2818)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:04:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:32 lr 0.000032	 wd 0.0000	time 0.1853 (0.2356)	loss 0.9043 (0.8968)	grad_norm 0.2855 (0.2819)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:04:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:07 lr 0.000032	 wd 0.0000	time 0.2412 (0.2336)	loss 0.9780 (0.8970)	grad_norm 0.2874 (0.2819)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:05:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:43 lr 0.000032	 wd 0.0000	time 0.1573 (0.2335)	loss 0.8472 (0.8969)	grad_norm 0.2959 (0.2820)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:05:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:19 lr 0.000032	 wd 0.0000	time 0.2060 (0.2311)	loss 0.8452 (0.8966)	grad_norm 0.2978 (0.2821)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:05:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:01:54 lr 0.000031	 wd 0.0000	time 0.2020 (0.2289)	loss 0.9038 (0.8972)	grad_norm 0.2771 (0.2821)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:06:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:31 lr 0.000031	 wd 0.0000	time 0.2160 (0.2275)	loss 0.7544 (0.8974)	grad_norm 0.2919 (0.2822)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:06:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:08 lr 0.000031	 wd 0.0000	time 0.1918 (0.2262)	loss 0.9189 (0.8973)	grad_norm 0.2817 (0.2822)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:06:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:45 lr 0.000031	 wd 0.0000	time 0.2237 (0.2260)	loss 0.7817 (0.8977)	grad_norm 0.2830 (0.2822)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:07:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:22 lr 0.000031	 wd 0.0000	time 0.2031 (0.2245)	loss 0.9136 (0.8979)	grad_norm 0.2838 (0.2823)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:07:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000030	 wd 0.0000	time 0.1499 (0.2222)	loss 0.8667 (0.8979)	grad_norm 0.2821 (0.2823)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:07:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 18 training takes 0:09:25
[2024-07-31 13:08:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 42.637 (42.637)	Loss 0.3564 (0.3564)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 13:08:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.886 Acc@5 97.470
[2024-07-31 13:08:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 13:08:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.89%
[2024-07-31 13:08:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][0/2502]	eta 11:34:01 lr 0.000030	 wd 0.0000	time 16.6433 (16.6433)	loss 0.8818 (0.8818)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:09:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:13:56 lr 0.000030	 wd 0.0000	time 0.1626 (0.3482)	loss 1.0205 (0.8892)	grad_norm 0.2811 (0.2825)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:09:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:10:28 lr 0.000030	 wd 0.0000	time 0.1636 (0.2732)	loss 0.7236 (0.8869)	grad_norm 0.2914 (0.2822)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:10:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:10:23 lr 0.000030	 wd 0.0000	time 0.1647 (0.2833)	loss 0.9883 (0.8924)	grad_norm 0.2901 (0.2822)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:10:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:09:02 lr 0.000030	 wd 0.0000	time 0.1651 (0.2583)	loss 0.8438 (0.8943)	grad_norm 0.2703 (0.2821)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:10:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:08:06 lr 0.000029	 wd 0.0000	time 0.1838 (0.2431)	loss 0.9478 (0.8943)	grad_norm 0.2793 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7518MB
[2024-07-31 13:10:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:07:23 lr 0.000029	 wd 0.0000	time 0.2337 (0.2333)	loss 0.7769 (0.8957)	grad_norm 0.2867 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7518MB
[2024-07-31 13:11:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:07:25 lr 0.000029	 wd 0.0000	time 0.2089 (0.2473)	loss 0.9990 (0.8970)	grad_norm 0.2785 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7518MB
[2024-07-31 13:11:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:06:49 lr 0.000029	 wd 0.0000	time 0.2140 (0.2406)	loss 0.8818 (0.8984)	grad_norm 0.2800 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7518MB
[2024-07-31 13:12:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:06:14 lr 0.000029	 wd 0.0000	time 0.1843 (0.2341)	loss 0.8867 (0.8985)	grad_norm 0.2825 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7518MB
[2024-07-31 13:12:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:05:43 lr 0.000028	 wd 0.0000	time 0.1806 (0.2287)	loss 0.9380 (0.8992)	grad_norm 0.2806 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7518MB
[2024-07-31 13:12:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:18 lr 0.000028	 wd 0.0000	time 0.2388 (0.2269)	loss 0.8433 (0.8988)	grad_norm 0.2850 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7518MB
[2024-07-31 13:13:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:03 lr 0.000028	 wd 0.0000	time 0.1977 (0.2333)	loss 0.8740 (0.8989)	grad_norm 0.2813 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7518MB
[2024-07-31 13:13:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:04:35 lr 0.000028	 wd 0.0000	time 0.1884 (0.2293)	loss 0.8584 (0.8994)	grad_norm 0.2885 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7518MB
[2024-07-31 13:13:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:08 lr 0.000028	 wd 0.0000	time 0.2087 (0.2259)	loss 0.8574 (0.8990)	grad_norm 0.2733 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7518MB
[2024-07-31 13:14:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:03:43 lr 0.000028	 wd 0.0000	time 0.1788 (0.2231)	loss 0.9004 (0.8994)	grad_norm 0.2669 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7518MB
[2024-07-31 13:14:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:20 lr 0.000027	 wd 0.0000	time 0.2134 (0.2221)	loss 0.9082 (0.8998)	grad_norm 0.3003 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7518MB
[2024-07-31 13:14:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:02:58 lr 0.000027	 wd 0.0000	time 0.1653 (0.2220)	loss 1.0137 (0.8998)	grad_norm 0.2778 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7518MB
[2024-07-31 13:15:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:34 lr 0.000027	 wd 0.0000	time 0.1981 (0.2201)	loss 0.8413 (0.9002)	grad_norm 0.2741 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7518MB
[2024-07-31 13:15:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:11 lr 0.000027	 wd 0.0000	time 0.2042 (0.2183)	loss 0.8735 (0.9003)	grad_norm 0.2887 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7518MB
[2024-07-31 13:15:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:48 lr 0.000027	 wd 0.0000	time 0.1739 (0.2169)	loss 0.9775 (0.9001)	grad_norm 0.2862 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7518MB
[2024-07-31 13:16:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:26 lr 0.000026	 wd 0.0000	time 0.3814 (0.2162)	loss 1.0039 (0.8998)	grad_norm 0.2778 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7518MB
[2024-07-31 13:16:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:05 lr 0.000026	 wd 0.0000	time 0.1555 (0.2166)	loss 0.8770 (0.8992)	grad_norm 0.3090 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7518MB
[2024-07-31 13:16:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:43 lr 0.000026	 wd 0.0000	time 0.1889 (0.2153)	loss 0.9336 (0.8989)	grad_norm 0.2801 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7518MB
[2024-07-31 13:17:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:21 lr 0.000026	 wd 0.0000	time 0.1741 (0.2139)	loss 0.9751 (0.8988)	grad_norm 0.2969 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7518MB
[2024-07-31 13:17:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1506 (0.2120)	loss 0.7197 (0.8988)	grad_norm 0.2886 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7518MB
[2024-07-31 13:17:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 19 training takes 0:08:59
[2024-07-31 13:18:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 41.018 (41.018)	Loss 0.3569 (0.3569)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 13:18:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.892 Acc@5 97.472
[2024-07-31 13:18:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 13:18:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.89%
[2024-07-31 13:18:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-31 13:18:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-31 13:18:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][0/2502]	eta 11:10:38 lr 0.000026	 wd 0.0000	time 16.0827 (16.0827)	loss 0.8486 (0.8486)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:19:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:15:23 lr 0.000026	 wd 0.0000	time 0.2897 (0.3844)	loss 1.0293 (0.9018)	grad_norm 0.2840 (0.2832)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:19:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:12:44 lr 0.000025	 wd 0.0000	time 0.1688 (0.3322)	loss 0.9502 (0.8928)	grad_norm 0.2820 (0.2825)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:20:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:10:21 lr 0.000025	 wd 0.0000	time 0.1617 (0.2820)	loss 0.7651 (0.8890)	grad_norm 0.2875 (0.2824)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:20:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:08:59 lr 0.000025	 wd 0.0000	time 0.1666 (0.2566)	loss 0.8872 (0.8899)	grad_norm 0.2834 (0.2825)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:20:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:08:03 lr 0.000025	 wd 0.0000	time 0.1769 (0.2416)	loss 0.8662 (0.8896)	grad_norm 0.2716 (0.2830)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:21:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:08:15 lr 0.000025	 wd 0.0000	time 0.2272 (0.2606)	loss 0.8232 (0.8903)	grad_norm 0.2790 (0.2827)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:21:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:31 lr 0.000025	 wd 0.0000	time 0.1624 (0.2508)	loss 0.7915 (0.8908)	grad_norm 0.2732 (0.2828)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:21:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:06:52 lr 0.000024	 wd 0.0000	time 0.1758 (0.2424)	loss 1.0117 (0.8913)	grad_norm 0.2776 (0.2827)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:22:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:17 lr 0.000024	 wd 0.0000	time 0.1731 (0.2357)	loss 0.7803 (0.8914)	grad_norm 0.2789 (0.2827)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:22:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:05:55 lr 0.000024	 wd 0.0000	time 0.3175 (0.2367)	loss 0.8262 (0.8909)	grad_norm 0.2782 (0.2824)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:23:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:35 lr 0.000024	 wd 0.0000	time 0.2045 (0.2393)	loss 0.8086 (0.8910)	grad_norm 0.2754 (0.2823)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:23:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:05 lr 0.000024	 wd 0.0000	time 0.1926 (0.2347)	loss 0.7549 (0.8910)	grad_norm 0.2744 (0.2824)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:23:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:04:37 lr 0.000023	 wd 0.0000	time 0.1626 (0.2306)	loss 0.8960 (0.8908)	grad_norm 0.2792 (0.2824)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:23:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:10 lr 0.000023	 wd 0.0000	time 0.1806 (0.2276)	loss 0.9253 (0.8913)	grad_norm 0.2972 (0.2825)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:24:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:03:56 lr 0.000023	 wd 0.0000	time 0.1677 (0.2365)	loss 0.9883 (0.8909)	grad_norm 0.2915 (0.2824)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:24:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:30 lr 0.000023	 wd 0.0000	time 0.1842 (0.2331)	loss 0.9312 (0.8903)	grad_norm 0.2938 (0.2825)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:25:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:04 lr 0.000023	 wd 0.0000	time 0.1830 (0.2301)	loss 0.9785 (0.8903)	grad_norm 0.2892 (0.2824)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:25:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:39 lr 0.000023	 wd 0.0000	time 0.2010 (0.2275)	loss 0.8208 (0.8909)	grad_norm 0.2909 (0.2824)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:25:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:16 lr 0.000022	 wd 0.0000	time 0.2022 (0.2260)	loss 1.0137 (0.8916)	grad_norm 0.2881 (0.2825)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:26:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:01:53 lr 0.000022	 wd 0.0000	time 0.1811 (0.2264)	loss 0.9194 (0.8916)	grad_norm 0.2798 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7518MB
[2024-07-31 13:26:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:30 lr 0.000022	 wd 0.0000	time 0.1900 (0.2246)	loss 0.9424 (0.8921)	grad_norm 0.2959 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7518MB
[2024-07-31 13:26:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:07 lr 0.000022	 wd 0.0000	time 0.1873 (0.2228)	loss 0.9048 (0.8927)	grad_norm 0.2864 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7518MB
[2024-07-31 13:27:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:44 lr 0.000022	 wd 0.0000	time 0.1912 (0.2213)	loss 0.8164 (0.8935)	grad_norm 0.2991 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7518MB
[2024-07-31 13:27:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:22 lr 0.000022	 wd 0.0000	time 0.1654 (0.2215)	loss 0.8481 (0.8937)	grad_norm 0.2843 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7518MB
[2024-07-31 13:27:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1502 (0.2194)	loss 0.8008 (0.8935)	grad_norm 0.2652 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7518MB
[2024-07-31 13:27:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 20 training takes 0:09:19
[2024-07-31 13:28:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 24.035 (24.035)	Loss 0.3574 (0.3574)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 13:28:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.900 Acc@5 97.476
[2024-07-31 13:28:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 13:28:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.90%
[2024-07-31 13:28:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-31 13:28:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-31 13:29:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][0/2502]	eta 23:30:43 lr 0.000021	 wd 0.0000	time 33.8305 (33.8305)	loss 0.9360 (0.9360)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:29:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:20:45 lr 0.000021	 wd 0.0000	time 0.1805 (0.5186)	loss 0.9180 (0.9053)	grad_norm 0.2835 (0.2842)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:29:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:13:26 lr 0.000021	 wd 0.0000	time 0.1724 (0.3503)	loss 0.9355 (0.8993)	grad_norm 0.2763 (0.2830)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:30:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:10:46 lr 0.000021	 wd 0.0000	time 0.1537 (0.2936)	loss 0.9370 (0.8970)	grad_norm 0.2856 (0.2832)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:30:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:09:36 lr 0.000021	 wd 0.0000	time 0.3741 (0.2742)	loss 1.0049 (0.8969)	grad_norm 0.2795 (0.2828)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:31:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:09:35 lr 0.000021	 wd 0.0000	time 0.1648 (0.2876)	loss 0.8267 (0.8972)	grad_norm 0.2820 (0.2830)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:31:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:34 lr 0.000020	 wd 0.0000	time 0.1842 (0.2703)	loss 0.9116 (0.8968)	grad_norm 0.2916 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:31:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:07:44 lr 0.000020	 wd 0.0000	time 0.1774 (0.2578)	loss 1.0186 (0.8968)	grad_norm 0.2943 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:32:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:04 lr 0.000020	 wd 0.0000	time 0.2362 (0.2494)	loss 0.9312 (0.8967)	grad_norm 0.2994 (0.2830)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:32:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:56 lr 0.000020	 wd 0.0000	time 0.1642 (0.2598)	loss 0.8491 (0.8976)	grad_norm 0.2724 (0.2828)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:32:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:18 lr 0.000020	 wd 0.0000	time 0.1741 (0.2522)	loss 0.8672 (0.8971)	grad_norm 0.2706 (0.2828)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:33:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:05:44 lr 0.000020	 wd 0.0000	time 0.1642 (0.2456)	loss 0.9277 (0.8976)	grad_norm 0.2717 (0.2828)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:33:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:12 lr 0.000019	 wd 0.0000	time 0.1931 (0.2401)	loss 0.8623 (0.8990)	grad_norm 0.2760 (0.2829)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:34:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:58 lr 0.000019	 wd 0.0000	time 0.1787 (0.2482)	loss 0.9526 (0.8986)	grad_norm 0.2666 (0.2829)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:34:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:28 lr 0.000019	 wd 0.0000	time 0.1802 (0.2438)	loss 0.9150 (0.8985)	grad_norm 0.2687 (0.2827)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:34:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:04:00 lr 0.000019	 wd 0.0000	time 0.1632 (0.2397)	loss 0.9473 (0.8983)	grad_norm 0.2720 (0.2827)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:35:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:33 lr 0.000019	 wd 0.0000	time 0.1900 (0.2362)	loss 0.9307 (0.8978)	grad_norm 0.2923 (0.2827)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:35:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:07 lr 0.000019	 wd 0.0000	time 0.1767 (0.2338)	loss 0.8936 (0.8983)	grad_norm 0.2741 (0.2829)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:35:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:43 lr 0.000018	 wd 0.0000	time 0.1629 (0.2330)	loss 0.8965 (0.8982)	grad_norm 0.2804 (0.2829)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:36:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:19 lr 0.000018	 wd 0.0000	time 0.2598 (0.2311)	loss 0.8950 (0.8982)	grad_norm 0.2764 (0.2828)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:36:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:54 lr 0.000018	 wd 0.0000	time 0.1880 (0.2289)	loss 0.7686 (0.8981)	grad_norm 0.2930 (0.2828)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:36:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:31 lr 0.000018	 wd 0.0000	time 0.1946 (0.2268)	loss 0.7842 (0.8975)	grad_norm 0.2752 (0.2830)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:36:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:08 lr 0.000018	 wd 0.0000	time 0.2184 (0.2254)	loss 0.8130 (0.8970)	grad_norm 0.2928 (0.2830)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:37:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:45 lr 0.000018	 wd 0.0000	time 0.2063 (0.2250)	loss 0.9448 (0.8970)	grad_norm 0.2736 (0.2829)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:37:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:22 lr 0.000018	 wd 0.0000	time 0.1781 (0.2238)	loss 0.8843 (0.8969)	grad_norm 0.2753 (0.2829)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:37:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000017	 wd 0.0000	time 0.1496 (0.2215)	loss 0.9141 (0.8971)	grad_norm 0.2607 (0.2829)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:38:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 21 training takes 0:09:20
[2024-07-31 13:38:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 20.374 (20.374)	Loss 0.3564 (0.3564)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 13:38:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.928 Acc@5 97.474
[2024-07-31 13:38:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 13:38:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.93%
[2024-07-31 13:38:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-31 13:38:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-31 13:39:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][0/2502]	eta 21:55:36 lr 0.000017	 wd 0.0000	time 31.5494 (31.5494)	loss 0.8535 (0.8535)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:39:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:19:51 lr 0.000017	 wd 0.0000	time 0.1771 (0.4962)	loss 0.9224 (0.9014)	grad_norm 0.2828 (0.2821)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:39:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:12:59 lr 0.000017	 wd 0.0000	time 0.1757 (0.3387)	loss 0.8013 (0.8968)	grad_norm 0.2744 (0.2816)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:40:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:12:47 lr 0.000017	 wd 0.0000	time 0.3815 (0.3487)	loss 0.8887 (0.8959)	grad_norm 0.2791 (0.2821)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:40:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:11:17 lr 0.000017	 wd 0.0000	time 0.1633 (0.3221)	loss 0.8428 (0.9007)	grad_norm 0.2704 (0.2821)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:41:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:09:49 lr 0.000017	 wd 0.0000	time 0.1894 (0.2945)	loss 0.7148 (0.8988)	grad_norm 0.2712 (0.2820)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:41:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:43 lr 0.000016	 wd 0.0000	time 0.1664 (0.2755)	loss 0.9468 (0.8999)	grad_norm 0.2709 (0.2821)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:42:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:08:31 lr 0.000016	 wd 0.0000	time 0.1551 (0.2836)	loss 0.9951 (0.8986)	grad_norm 0.2716 (0.2824)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:42:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:07:43 lr 0.000016	 wd 0.0000	time 0.1514 (0.2722)	loss 0.9165 (0.8989)	grad_norm 0.2781 (0.2824)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:42:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:59 lr 0.000016	 wd 0.0000	time 0.1678 (0.2621)	loss 0.8643 (0.8987)	grad_norm 0.2695 (0.2825)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:43:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:21 lr 0.000016	 wd 0.0000	time 0.1642 (0.2538)	loss 0.9170 (0.8986)	grad_norm 0.2723 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7518MB
[2024-07-31 13:43:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:48 lr 0.000016	 wd 0.0000	time 0.2237 (0.2486)	loss 0.8037 (0.8972)	grad_norm 0.2727 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7518MB
[2024-07-31 13:43:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:30 lr 0.000016	 wd 0.0000	time 0.1663 (0.2539)	loss 0.8604 (0.8975)	grad_norm 0.2912 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7518MB
[2024-07-31 13:44:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:04:58 lr 0.000015	 wd 0.0000	time 0.1820 (0.2485)	loss 0.8848 (0.8961)	grad_norm 0.2812 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7518MB
[2024-07-31 13:44:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:28 lr 0.000015	 wd 0.0000	time 0.1631 (0.2437)	loss 0.8740 (0.8959)	grad_norm 0.2874 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7518MB
[2024-07-31 13:44:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:04:00 lr 0.000015	 wd 0.0000	time 0.1517 (0.2397)	loss 0.6948 (0.8960)	grad_norm 0.2757 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7518MB
[2024-07-31 13:45:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:34 lr 0.000015	 wd 0.0000	time 0.1714 (0.2378)	loss 0.8740 (0.8962)	grad_norm 0.2826 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7518MB
[2024-07-31 13:45:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:09 lr 0.000015	 wd 0.0000	time 0.1769 (0.2367)	loss 0.9087 (0.8957)	grad_norm 0.2837 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7518MB
[2024-07-31 13:45:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:44 lr 0.000015	 wd 0.0000	time 0.1797 (0.2340)	loss 0.9819 (0.8957)	grad_norm 0.2800 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7518MB
[2024-07-31 13:46:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:19 lr 0.000015	 wd 0.0000	time 0.1732 (0.2315)	loss 0.9263 (0.8962)	grad_norm 0.2791 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7518MB
[2024-07-31 13:46:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:55 lr 0.000014	 wd 0.0000	time 0.1786 (0.2292)	loss 0.9844 (0.8960)	grad_norm 0.2561 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7518MB
[2024-07-31 13:46:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:31 lr 0.000014	 wd 0.0000	time 0.2101 (0.2278)	loss 0.8359 (0.8964)	grad_norm 0.2879 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7518MB
[2024-07-31 13:47:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:08 lr 0.000014	 wd 0.0000	time 0.2340 (0.2281)	loss 0.6982 (0.8963)	grad_norm 0.2841 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7518MB
[2024-07-31 13:47:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:45 lr 0.000014	 wd 0.0000	time 0.1688 (0.2263)	loss 0.9517 (0.8963)	grad_norm 0.2808 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7518MB
[2024-07-31 13:47:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:22 lr 0.000014	 wd 0.0000	time 0.1785 (0.2246)	loss 0.7817 (0.8965)	grad_norm 0.2817 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7518MB
[2024-07-31 13:48:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1507 (0.2222)	loss 0.8550 (0.8960)	grad_norm 0.2890 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7518MB
[2024-07-31 13:48:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 22 training takes 0:09:22
[2024-07-31 13:48:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 36.094 (36.094)	Loss 0.3567 (0.3567)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 13:49:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.934 Acc@5 97.480
[2024-07-31 13:49:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 13:49:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.93%
[2024-07-31 13:49:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-31 13:49:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-31 13:49:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][0/2502]	eta 11:16:16 lr 0.000014	 wd 0.0000	time 16.2175 (16.2175)	loss 0.7754 (0.7754)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:49:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:13:55 lr 0.000014	 wd 0.0000	time 0.1961 (0.3479)	loss 0.8804 (0.8938)	grad_norm 0.2840 (0.2836)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:50:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:12:08 lr 0.000013	 wd 0.0000	time 0.1863 (0.3165)	loss 0.9541 (0.8912)	grad_norm 0.2970 (0.2826)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:50:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:10:02 lr 0.000013	 wd 0.0000	time 0.1742 (0.2735)	loss 0.7944 (0.8899)	grad_norm 0.2722 (0.2826)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:50:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:08:46 lr 0.000013	 wd 0.0000	time 0.1736 (0.2504)	loss 1.0088 (0.8919)	grad_norm 0.2847 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:51:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:07:53 lr 0.000013	 wd 0.0000	time 0.1938 (0.2364)	loss 0.9170 (0.8963)	grad_norm 0.2747 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:51:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:07:17 lr 0.000013	 wd 0.0000	time 0.3127 (0.2298)	loss 0.9048 (0.8972)	grad_norm 0.2790 (0.2829)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:51:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:15 lr 0.000013	 wd 0.0000	time 0.1867 (0.2415)	loss 0.9756 (0.8979)	grad_norm 0.2693 (0.2826)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:52:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:06:38 lr 0.000013	 wd 0.0000	time 0.1630 (0.2343)	loss 0.9995 (0.8974)	grad_norm 0.2883 (0.2826)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:52:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:06:06 lr 0.000012	 wd 0.0000	time 0.1941 (0.2288)	loss 1.1250 (0.8958)	grad_norm 0.2854 (0.2826)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:52:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:05:36 lr 0.000012	 wd 0.0000	time 0.1825 (0.2237)	loss 0.7563 (0.8962)	grad_norm 0.2848 (0.2826)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:53:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:18 lr 0.000012	 wd 0.0000	time 0.4700 (0.2273)	loss 0.7554 (0.8953)	grad_norm 0.2931 (0.2828)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:53:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:00 lr 0.000012	 wd 0.0000	time 0.1718 (0.2307)	loss 0.9424 (0.8957)	grad_norm 0.2727 (0.2828)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:54:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:04:32 lr 0.000012	 wd 0.0000	time 0.1762 (0.2269)	loss 0.9644 (0.8957)	grad_norm 0.3025 (0.2829)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:54:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:06 lr 0.000012	 wd 0.0000	time 0.1748 (0.2236)	loss 0.9595 (0.8961)	grad_norm 0.2862 (0.2830)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:54:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:03:42 lr 0.000012	 wd 0.0000	time 0.2230 (0.2217)	loss 0.7803 (0.8968)	grad_norm 0.2891 (0.2830)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:55:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:24 lr 0.000012	 wd 0.0000	time 0.1831 (0.2270)	loss 0.8999 (0.8968)	grad_norm 0.2694 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:55:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:00 lr 0.000011	 wd 0.0000	time 0.1757 (0.2245)	loss 0.7979 (0.8966)	grad_norm 0.2845 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:55:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:35 lr 0.000011	 wd 0.0000	time 0.1750 (0.2221)	loss 0.9189 (0.8969)	grad_norm 0.2817 (0.2832)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:56:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:12 lr 0.000011	 wd 0.0000	time 0.1882 (0.2201)	loss 0.8159 (0.8965)	grad_norm 0.2754 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:56:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:01:50 lr 0.000011	 wd 0.0000	time 0.1831 (0.2193)	loss 0.9868 (0.8963)	grad_norm 0.2827 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:56:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:28 lr 0.000011	 wd 0.0000	time 0.1657 (0.2197)	loss 1.0342 (0.8963)	grad_norm 0.2660 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:57:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:05 lr 0.000011	 wd 0.0000	time 0.1631 (0.2183)	loss 0.9771 (0.8958)	grad_norm 0.2887 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:57:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:43 lr 0.000011	 wd 0.0000	time 0.1925 (0.2169)	loss 0.9038 (0.8960)	grad_norm 0.2839 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:57:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:21 lr 0.000011	 wd 0.0000	time 0.2158 (0.2157)	loss 0.8916 (0.8960)	grad_norm 0.2760 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:58:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1493 (0.2140)	loss 0.8154 (0.8959)	grad_norm 0.2809 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7518MB
[2024-07-31 13:58:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 23 training takes 0:09:04
[2024-07-31 13:58:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 29.868 (29.868)	Loss 0.3562 (0.3562)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 13:58:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.904 Acc@5 97.488
[2024-07-31 13:58:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 13:58:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.93%
[2024-07-31 13:59:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][0/2502]	eta 10:57:28 lr 0.000010	 wd 0.0000	time 15.7669 (15.7669)	loss 0.9272 (0.9272)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 13:59:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:16:33 lr 0.000010	 wd 0.0000	time 0.3319 (0.4136)	loss 1.0186 (0.8927)	grad_norm 0.2705 (0.2841)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:00:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:12:30 lr 0.000010	 wd 0.0000	time 0.1691 (0.3261)	loss 0.8911 (0.8945)	grad_norm 0.2762 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:00:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:10:10 lr 0.000010	 wd 0.0000	time 0.1851 (0.2774)	loss 0.8345 (0.8974)	grad_norm 0.3018 (0.2828)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:00:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:08:53 lr 0.000010	 wd 0.0000	time 0.1978 (0.2538)	loss 0.7529 (0.8986)	grad_norm 0.2848 (0.2827)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:00:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:08:00 lr 0.000010	 wd 0.0000	time 0.1921 (0.2398)	loss 0.9209 (0.9007)	grad_norm 0.3029 (0.2830)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:01:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:08:14 lr 0.000010	 wd 0.0000	time 0.2343 (0.2600)	loss 0.9272 (0.8982)	grad_norm 0.2760 (0.2835)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:01:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:07:29 lr 0.000010	 wd 0.0000	time 0.1807 (0.2497)	loss 0.8521 (0.8971)	grad_norm 0.2821 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:02:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:06:50 lr 0.000010	 wd 0.0000	time 0.1697 (0.2412)	loss 0.8193 (0.8963)	grad_norm 0.2904 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:02:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:06:15 lr 0.000009	 wd 0.0000	time 0.1986 (0.2343)	loss 0.9360 (0.8968)	grad_norm 0.2893 (0.2830)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:03:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:05 lr 0.000009	 wd 0.0000	time 0.1708 (0.2435)	loss 0.8423 (0.8976)	grad_norm 0.2938 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:03:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:05:34 lr 0.000009	 wd 0.0000	time 0.1771 (0.2386)	loss 0.8550 (0.8974)	grad_norm 0.2818 (0.2832)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:03:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:04 lr 0.000009	 wd 0.0000	time 0.1675 (0.2340)	loss 0.8540 (0.8971)	grad_norm 0.2555 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:03:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:04:36 lr 0.000009	 wd 0.0000	time 0.1851 (0.2299)	loss 0.7495 (0.8956)	grad_norm 0.2869 (0.2832)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:04:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:10 lr 0.000009	 wd 0.0000	time 0.1869 (0.2272)	loss 0.7998 (0.8959)	grad_norm 0.2759 (0.2832)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:04:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:03:48 lr 0.000009	 wd 0.0000	time 0.1731 (0.2276)	loss 0.8345 (0.8958)	grad_norm 0.2755 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:05:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:23 lr 0.000009	 wd 0.0000	time 0.1932 (0.2252)	loss 0.9219 (0.8957)	grad_norm 0.2738 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:05:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:02:58 lr 0.000008	 wd 0.0000	time 0.1844 (0.2229)	loss 0.9956 (0.8962)	grad_norm 0.2851 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:05:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:34 lr 0.000008	 wd 0.0000	time 0.1697 (0.2206)	loss 0.8027 (0.8966)	grad_norm 0.2707 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:05:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:11 lr 0.000008	 wd 0.0000	time 0.1845 (0.2193)	loss 0.7603 (0.8963)	grad_norm 0.2708 (0.2832)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:06:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:01:50 lr 0.000008	 wd 0.0000	time 0.1513 (0.2196)	loss 0.7354 (0.8963)	grad_norm 0.2850 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:06:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:27 lr 0.000008	 wd 0.0000	time 0.1677 (0.2183)	loss 0.9976 (0.8959)	grad_norm 0.2819 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:06:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:05 lr 0.000008	 wd 0.0000	time 0.1780 (0.2169)	loss 0.8740 (0.8958)	grad_norm 0.2781 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:07:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:43 lr 0.000008	 wd 0.0000	time 0.2048 (0.2156)	loss 0.9531 (0.8961)	grad_norm 0.2714 (0.2832)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:07:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:21 lr 0.000008	 wd 0.0000	time 0.1669 (0.2150)	loss 1.0967 (0.8960)	grad_norm 0.2715 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:07:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1503 (0.2133)	loss 0.9995 (0.8959)	grad_norm 0.2753 (0.2832)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:08:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 24 training takes 0:09:08
[2024-07-31 14:08:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 20.637 (20.637)	Loss 0.3574 (0.3574)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 14:08:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.930 Acc@5 97.480
[2024-07-31 14:08:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 14:08:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.93%
[2024-07-31 14:09:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][0/2502]	eta 14:29:58 lr 0.000008	 wd 0.0000	time 20.8626 (20.8626)	loss 0.8730 (0.8730)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:09:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:18:50 lr 0.000008	 wd 0.0000	time 0.1755 (0.4706)	loss 0.8628 (0.9112)	grad_norm 0.2723 (0.2842)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:09:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:12:33 lr 0.000007	 wd 0.0000	time 0.1949 (0.3272)	loss 0.8608 (0.9078)	grad_norm 0.2801 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:10:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:10:13 lr 0.000007	 wd 0.0000	time 0.1600 (0.2786)	loss 0.9287 (0.9001)	grad_norm 0.2889 (0.2830)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:10:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:08:53 lr 0.000007	 wd 0.0000	time 0.1816 (0.2536)	loss 0.7666 (0.9009)	grad_norm 0.2887 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:10:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:08:19 lr 0.000007	 wd 0.0000	time 0.3117 (0.2494)	loss 0.8750 (0.9003)	grad_norm 0.2674 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:11:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:18 lr 0.000007	 wd 0.0000	time 0.1729 (0.2622)	loss 0.7715 (0.8998)	grad_norm 0.2889 (0.2829)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:11:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:07:32 lr 0.000007	 wd 0.0000	time 0.2056 (0.2510)	loss 0.8506 (0.8989)	grad_norm 0.2877 (0.2829)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:12:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:06:52 lr 0.000007	 wd 0.0000	time 0.1906 (0.2423)	loss 0.9878 (0.8984)	grad_norm 0.2850 (0.2829)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:12:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:06:19 lr 0.000007	 wd 0.0000	time 0.1992 (0.2369)	loss 0.7275 (0.8982)	grad_norm 0.2825 (0.2829)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:12:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:02 lr 0.000007	 wd 0.0000	time 0.1680 (0.2412)	loss 0.9766 (0.8985)	grad_norm 0.2999 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:13:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:30 lr 0.000007	 wd 0.0000	time 0.1610 (0.2359)	loss 1.0420 (0.8979)	grad_norm 0.2897 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:13:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:01 lr 0.000006	 wd 0.0000	time 0.1649 (0.2313)	loss 1.0225 (0.8990)	grad_norm 0.2821 (0.2830)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:13:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:04:33 lr 0.000006	 wd 0.0000	time 0.1869 (0.2276)	loss 0.8979 (0.8980)	grad_norm 0.2752 (0.2830)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:14:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:09 lr 0.000006	 wd 0.0000	time 0.3049 (0.2268)	loss 0.9365 (0.8977)	grad_norm 0.2664 (0.2829)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:14:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:03:50 lr 0.000006	 wd 0.0000	time 0.1948 (0.2298)	loss 1.0020 (0.8985)	grad_norm 0.2742 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7518MB
[2024-07-31 14:14:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:24 lr 0.000006	 wd 0.0000	time 0.1542 (0.2267)	loss 0.7671 (0.8981)	grad_norm 0.2724 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7518MB
[2024-07-31 14:15:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:02:59 lr 0.000006	 wd 0.0000	time 0.1682 (0.2242)	loss 0.8486 (0.8989)	grad_norm 0.2804 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7518MB
[2024-07-31 14:15:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:36 lr 0.000006	 wd 0.0000	time 0.2145 (0.2222)	loss 0.9263 (0.8984)	grad_norm 0.2747 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7518MB
[2024-07-31 14:15:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:13 lr 0.000006	 wd 0.0000	time 1.7574 (0.2223)	loss 1.0449 (0.8985)	grad_norm 0.2773 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7518MB
[2024-07-31 14:16:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:01:51 lr 0.000006	 wd 0.0000	time 0.1651 (0.2215)	loss 1.0361 (0.8984)	grad_norm 0.2754 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7518MB
[2024-07-31 14:16:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:28 lr 0.000006	 wd 0.0000	time 0.1667 (0.2198)	loss 0.9155 (0.8978)	grad_norm 0.2714 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7518MB
[2024-07-31 14:16:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:05 lr 0.000006	 wd 0.0000	time 0.1624 (0.2182)	loss 0.8389 (0.8974)	grad_norm 0.2629 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7518MB
[2024-07-31 14:17:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:43 lr 0.000005	 wd 0.0000	time 0.2034 (0.2169)	loss 0.7891 (0.8972)	grad_norm 0.2816 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7518MB
[2024-07-31 14:17:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:22 lr 0.000005	 wd 0.0000	time 0.1722 (0.2170)	loss 0.8584 (0.8972)	grad_norm 0.2706 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7518MB
[2024-07-31 14:17:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000005	 wd 0.0000	time 0.1494 (0.2154)	loss 0.8765 (0.8975)	grad_norm 0.2877 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7518MB
[2024-07-31 14:17:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 25 training takes 0:09:07
[2024-07-31 14:18:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 18.646 (18.646)	Loss 0.3564 (0.3564)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 14:18:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.908 Acc@5 97.480
[2024-07-31 14:18:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 14:18:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.93%
[2024-07-31 14:19:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][0/2502]	eta 1 day, 0:08:24 lr 0.000005	 wd 0.0000	time 34.7342 (34.7342)	loss 1.0371 (1.0371)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:19:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:21:27 lr 0.000005	 wd 0.0000	time 0.1920 (0.5360)	loss 0.7979 (0.9062)	grad_norm 0.2851 (0.2855)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:19:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:13:45 lr 0.000005	 wd 0.0000	time 0.1703 (0.3587)	loss 0.8945 (0.9031)	grad_norm 0.2852 (0.2845)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:20:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:10:59 lr 0.000005	 wd 0.0000	time 0.2032 (0.2994)	loss 0.8716 (0.9037)	grad_norm 0.3025 (0.2848)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:20:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:09:37 lr 0.000005	 wd 0.0000	time 0.2588 (0.2748)	loss 0.9160 (0.9016)	grad_norm 0.3021 (0.2843)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:20:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:09:37 lr 0.000005	 wd 0.0000	time 0.1650 (0.2886)	loss 0.8525 (0.8995)	grad_norm 0.2680 (0.2838)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:21:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:08:35 lr 0.000005	 wd 0.0000	time 0.1957 (0.2711)	loss 0.8750 (0.9002)	grad_norm 0.2836 (0.2840)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:21:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:45 lr 0.000005	 wd 0.0000	time 0.1606 (0.2583)	loss 0.8511 (0.8979)	grad_norm 0.2762 (0.2840)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:21:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:07:03 lr 0.000005	 wd 0.0000	time 0.2171 (0.2488)	loss 0.8896 (0.8990)	grad_norm 0.2889 (0.2838)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:22:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:06:55 lr 0.000005	 wd 0.0000	time 0.2023 (0.2593)	loss 0.7852 (0.8975)	grad_norm 0.2912 (0.2837)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:22:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:19 lr 0.000004	 wd 0.0000	time 0.1806 (0.2524)	loss 0.9458 (0.8978)	grad_norm 0.2788 (0.2836)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:23:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:44 lr 0.000004	 wd 0.0000	time 0.1587 (0.2460)	loss 0.9883 (0.8985)	grad_norm 0.2757 (0.2837)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:23:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:13 lr 0.000004	 wd 0.0000	time 0.1828 (0.2404)	loss 0.9331 (0.8982)	grad_norm 0.2716 (0.2836)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:23:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:04:46 lr 0.000004	 wd 0.0000	time 0.3433 (0.2383)	loss 0.7866 (0.8986)	grad_norm 0.2840 (0.2836)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:24:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:27 lr 0.000004	 wd 0.0000	time 0.1642 (0.2430)	loss 0.9824 (0.8982)	grad_norm 0.2788 (0.2837)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:24:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:03:59 lr 0.000004	 wd 0.0000	time 0.1751 (0.2387)	loss 0.8740 (0.8985)	grad_norm 0.2753 (0.2838)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:24:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:32 lr 0.000004	 wd 0.0000	time 0.1660 (0.2352)	loss 0.7559 (0.8975)	grad_norm 0.2750 (0.2838)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:25:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:06 lr 0.000004	 wd 0.0000	time 0.2659 (0.2325)	loss 0.8647 (0.8983)	grad_norm 0.2799 (0.2838)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:25:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:43 lr 0.000004	 wd 0.0000	time 0.1989 (0.2326)	loss 0.9331 (0.8987)	grad_norm 0.2793 (0.2838)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:25:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:18 lr 0.000004	 wd 0.0000	time 0.1842 (0.2307)	loss 0.9019 (0.8981)	grad_norm 0.2816 (0.2837)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:26:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:01:54 lr 0.000004	 wd 0.0000	time 0.1717 (0.2285)	loss 0.9448 (0.8980)	grad_norm 0.2828 (0.2837)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:26:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:30 lr 0.000004	 wd 0.0000	time 0.1622 (0.2263)	loss 0.9116 (0.8982)	grad_norm 0.2906 (0.2837)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:26:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:07 lr 0.000004	 wd 0.0000	time 0.2600 (0.2247)	loss 0.9487 (0.8981)	grad_norm 0.2870 (0.2836)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:27:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:45 lr 0.000004	 wd 0.0000	time 0.1617 (0.2246)	loss 0.8667 (0.8978)	grad_norm 0.2863 (0.2835)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:27:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:22 lr 0.000003	 wd 0.0000	time 0.1985 (0.2235)	loss 0.8916 (0.8982)	grad_norm 0.2890 (0.2836)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:27:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1498 (0.2213)	loss 0.9517 (0.8982)	grad_norm 0.2776 (0.2835)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:27:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 26 training takes 0:09:22
[2024-07-31 14:28:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 24.168 (24.168)	Loss 0.3569 (0.3569)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 14:28:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.918 Acc@5 97.488
[2024-07-31 14:28:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 14:28:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.93%
[2024-07-31 14:29:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][0/2502]	eta 17:01:34 lr 0.000003	 wd 0.0000	time 24.4981 (24.4981)	loss 0.9492 (0.9492)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:29:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:17:01 lr 0.000003	 wd 0.0000	time 0.1564 (0.4253)	loss 0.9155 (0.9038)	grad_norm 0.2783 (0.2827)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:29:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:11:42 lr 0.000003	 wd 0.0000	time 0.1800 (0.3053)	loss 0.7295 (0.8975)	grad_norm 0.2924 (0.2825)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:30:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:10:22 lr 0.000003	 wd 0.0000	time 0.3663 (0.2826)	loss 0.9141 (0.8981)	grad_norm 0.2927 (0.2829)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:30:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:10:17 lr 0.000003	 wd 0.0000	time 0.1725 (0.2940)	loss 0.8389 (0.8970)	grad_norm 0.2832 (0.2830)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:31:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:09:04 lr 0.000003	 wd 0.0000	time 0.1806 (0.2720)	loss 0.7847 (0.8964)	grad_norm 0.3022 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7518MB
[2024-07-31 14:31:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:08 lr 0.000003	 wd 0.0000	time 0.1842 (0.2568)	loss 0.8252 (0.8985)	grad_norm 0.2914 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7518MB
[2024-07-31 14:31:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:26 lr 0.000003	 wd 0.0000	time 0.2069 (0.2476)	loss 0.8276 (0.8979)	grad_norm 0.2920 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7518MB
[2024-07-31 14:32:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:22 lr 0.000003	 wd 0.0000	time 0.1760 (0.2602)	loss 0.9131 (0.8970)	grad_norm 0.2701 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7518MB
[2024-07-31 14:32:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:42 lr 0.000003	 wd 0.0000	time 0.1687 (0.2514)	loss 0.7783 (0.8965)	grad_norm 0.2719 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7518MB
[2024-07-31 14:32:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:07 lr 0.000003	 wd 0.0000	time 0.1566 (0.2445)	loss 0.9097 (0.8960)	grad_norm 0.2738 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7518MB
[2024-07-31 14:33:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:34 lr 0.000003	 wd 0.0000	time 0.1885 (0.2389)	loss 0.7866 (0.8959)	grad_norm 0.2902 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7518MB
[2024-07-31 14:33:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:21 lr 0.000003	 wd 0.0000	time 0.2036 (0.2472)	loss 0.9048 (0.8951)	grad_norm 0.2822 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7518MB
[2024-07-31 14:34:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:51 lr 0.000003	 wd 0.0000	time 0.1951 (0.2424)	loss 0.8521 (0.8952)	grad_norm 0.2929 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7518MB
[2024-07-31 14:34:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:22 lr 0.000003	 wd 0.0000	time 0.1775 (0.2381)	loss 0.8208 (0.8953)	grad_norm 0.2767 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7518MB
[2024-07-31 14:34:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:03:54 lr 0.000003	 wd 0.0000	time 0.2037 (0.2342)	loss 0.9976 (0.8952)	grad_norm 0.2845 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7518MB
[2024-07-31 14:34:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:29 lr 0.000003	 wd 0.0000	time 0.1923 (0.2321)	loss 0.9077 (0.8953)	grad_norm 0.2770 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7518MB
[2024-07-31 14:35:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:05 lr 0.000002	 wd 0.0000	time 0.2950 (0.2316)	loss 0.8828 (0.8955)	grad_norm 0.2883 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7518MB
[2024-07-31 14:35:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:40 lr 0.000002	 wd 0.0000	time 0.1856 (0.2292)	loss 0.7920 (0.8960)	grad_norm 0.2785 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7518MB
[2024-07-31 14:35:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:16 lr 0.000002	 wd 0.0000	time 0.1621 (0.2269)	loss 0.8247 (0.8961)	grad_norm 0.2793 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7518MB
[2024-07-31 14:36:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:52 lr 0.000002	 wd 0.0000	time 0.1726 (0.2248)	loss 0.7642 (0.8957)	grad_norm 0.2754 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7518MB
[2024-07-31 14:36:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:29 lr 0.000002	 wd 0.0000	time 0.1618 (0.2238)	loss 1.0400 (0.8967)	grad_norm 0.3019 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7518MB
[2024-07-31 14:36:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:07 lr 0.000002	 wd 0.0000	time 0.2100 (0.2240)	loss 0.7432 (0.8962)	grad_norm 0.2757 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7518MB
[2024-07-31 14:37:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:44 lr 0.000002	 wd 0.0000	time 0.1619 (0.2224)	loss 0.8501 (0.8965)	grad_norm 0.2910 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7518MB
[2024-07-31 14:37:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:22 lr 0.000002	 wd 0.0000	time 0.1869 (0.2210)	loss 0.9077 (0.8961)	grad_norm 0.2895 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7518MB
[2024-07-31 14:37:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1497 (0.2187)	loss 0.8926 (0.8963)	grad_norm 0.2786 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7518MB
[2024-07-31 14:38:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 27 training takes 0:09:16
[2024-07-31 14:38:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 36.836 (36.836)	Loss 0.3567 (0.3567)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 14:38:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.928 Acc@5 97.482
[2024-07-31 14:38:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 14:38:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.93%
[2024-07-31 14:39:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][0/2502]	eta 11:01:37 lr 0.000002	 wd 0.0000	time 15.8663 (15.8663)	loss 0.8579 (0.8579)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:39:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:13:45 lr 0.000002	 wd 0.0000	time 0.1959 (0.3438)	loss 0.9023 (0.8895)	grad_norm 0.2934 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:40:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:12:48 lr 0.000002	 wd 0.0000	time 0.1949 (0.3340)	loss 0.8818 (0.8968)	grad_norm 0.2936 (0.2836)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:40:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:10:31 lr 0.000002	 wd 0.0000	time 0.1823 (0.2867)	loss 0.9858 (0.8994)	grad_norm 0.2780 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:40:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:09:06 lr 0.000002	 wd 0.0000	time 0.1965 (0.2600)	loss 0.7988 (0.8945)	grad_norm 0.2819 (0.2832)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:41:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:08:08 lr 0.000002	 wd 0.0000	time 0.1841 (0.2441)	loss 0.8833 (0.8968)	grad_norm 0.2790 (0.2835)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:41:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:07:30 lr 0.000002	 wd 0.0000	time 0.2359 (0.2369)	loss 0.9336 (0.8980)	grad_norm 0.2899 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:41:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:22 lr 0.000002	 wd 0.0000	time 0.1854 (0.2458)	loss 0.8760 (0.8972)	grad_norm 0.2828 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:42:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:06:45 lr 0.000002	 wd 0.0000	time 0.1776 (0.2382)	loss 0.8726 (0.8982)	grad_norm 0.2811 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:42:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:11 lr 0.000002	 wd 0.0000	time 0.1807 (0.2320)	loss 0.8481 (0.8979)	grad_norm 0.2841 (0.2834)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:42:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:05:40 lr 0.000002	 wd 0.0000	time 0.1909 (0.2269)	loss 0.8838 (0.8977)	grad_norm 0.2699 (0.2832)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:43:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:34 lr 0.000002	 wd 0.0000	time 0.1902 (0.2385)	loss 0.8267 (0.8961)	grad_norm 0.2893 (0.2832)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:43:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:05 lr 0.000002	 wd 0.0000	time 0.1921 (0.2344)	loss 0.9009 (0.8963)	grad_norm 0.2979 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:43:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:04:36 lr 0.000002	 wd 0.0000	time 0.1735 (0.2304)	loss 0.9844 (0.8967)	grad_norm 0.2956 (0.2832)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:44:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:09 lr 0.000002	 wd 0.0000	time 0.1838 (0.2268)	loss 0.8052 (0.8959)	grad_norm 0.2784 (0.2832)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:44:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:03:45 lr 0.000002	 wd 0.0000	time 0.2438 (0.2250)	loss 0.7881 (0.8961)	grad_norm 0.2935 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:44:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:23 lr 0.000002	 wd 0.0000	time 0.2652 (0.2256)	loss 1.0410 (0.8964)	grad_norm 0.2994 (0.2830)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:45:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:02:59 lr 0.000001	 wd 0.0000	time 0.1712 (0.2236)	loss 0.9443 (0.8964)	grad_norm 0.2968 (0.2830)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:45:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:35 lr 0.000001	 wd 0.0000	time 0.2032 (0.2214)	loss 0.7852 (0.8960)	grad_norm 0.2865 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:45:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:12 lr 0.000001	 wd 0.0000	time 0.1991 (0.2194)	loss 0.8989 (0.8968)	grad_norm 0.2869 (0.2832)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:46:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:01:49 lr 0.000001	 wd 0.0000	time 0.2246 (0.2185)	loss 0.8232 (0.8959)	grad_norm 0.2768 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7518MB
[2024-07-31 14:46:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:28 lr 0.000001	 wd 0.0000	time 0.2284 (0.2191)	loss 0.8584 (0.8957)	grad_norm 0.2921 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7518MB
[2024-07-31 14:46:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:05 lr 0.000001	 wd 0.0000	time 0.1889 (0.2179)	loss 0.9087 (0.8952)	grad_norm 0.2903 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7518MB
[2024-07-31 14:47:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:43 lr 0.000001	 wd 0.0000	time 0.1494 (0.2165)	loss 0.8047 (0.8950)	grad_norm 0.2758 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7518MB
[2024-07-31 14:47:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:21 lr 0.000001	 wd 0.0000	time 0.1793 (0.2152)	loss 0.9805 (0.8946)	grad_norm 0.2934 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7518MB
[2024-07-31 14:47:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1498 (0.2135)	loss 0.8760 (0.8948)	grad_norm 0.2669 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7518MB
[2024-07-31 14:48:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 28 training takes 0:09:03
[2024-07-31 14:48:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 36.263 (36.263)	Loss 0.3567 (0.3567)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 14:48:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.930 Acc@5 97.488
[2024-07-31 14:48:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 14:48:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.93%
[2024-07-31 14:49:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][0/2502]	eta 11:04:26 lr 0.000001	 wd 0.0000	time 15.9340 (15.9340)	loss 0.9619 (0.9619)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:49:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:18:52 lr 0.000001	 wd 0.0000	time 0.2429 (0.4713)	loss 0.8696 (0.9043)	grad_norm 0.2967 (0.2839)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:50:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:12:40 lr 0.000001	 wd 0.0000	time 0.1642 (0.3304)	loss 0.9097 (0.9045)	grad_norm 0.2996 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:50:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:10:20 lr 0.000001	 wd 0.0000	time 0.2064 (0.2816)	loss 0.8574 (0.9044)	grad_norm 0.2887 (0.2827)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:50:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:08:59 lr 0.000001	 wd 0.0000	time 0.1777 (0.2566)	loss 0.8682 (0.9036)	grad_norm 0.2802 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:51:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:08:16 lr 0.000001	 wd 0.0000	time 0.2778 (0.2479)	loss 0.8501 (0.9031)	grad_norm 0.2879 (0.2837)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:51:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:18 lr 0.000001	 wd 0.0000	time 0.1798 (0.2620)	loss 0.7637 (0.9020)	grad_norm 0.2898 (0.2832)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:51:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:32 lr 0.000001	 wd 0.0000	time 0.1651 (0.2509)	loss 0.8657 (0.9009)	grad_norm 0.2714 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:52:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:06:52 lr 0.000001	 wd 0.0000	time 0.1627 (0.2423)	loss 0.8350 (0.9012)	grad_norm 0.2809 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:52:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:06:18 lr 0.000001	 wd 0.0000	time 0.1805 (0.2362)	loss 0.8721 (0.9014)	grad_norm 0.2947 (0.2835)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:53:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:08 lr 0.000001	 wd 0.0000	time 0.1655 (0.2454)	loss 0.8433 (0.9015)	grad_norm 0.2895 (0.2834)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:53:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:36 lr 0.000001	 wd 0.0000	time 0.1683 (0.2398)	loss 1.0391 (0.9010)	grad_norm 0.2693 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:53:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:05 lr 0.000001	 wd 0.0000	time 0.1959 (0.2349)	loss 0.7681 (0.8998)	grad_norm 0.2839 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:53:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:04:37 lr 0.000001	 wd 0.0000	time 0.1759 (0.2307)	loss 0.9053 (0.8998)	grad_norm 0.2819 (0.2835)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:54:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:13 lr 0.000001	 wd 0.0000	time 0.2666 (0.2299)	loss 0.9883 (0.8996)	grad_norm 0.2911 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:54:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:03:49 lr 0.000001	 wd 0.0000	time 0.1660 (0.2292)	loss 0.8262 (0.8982)	grad_norm 0.2834 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:54:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:24 lr 0.000001	 wd 0.0000	time 0.1996 (0.2266)	loss 0.9326 (0.8976)	grad_norm 0.2895 (0.2834)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:55:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:02:59 lr 0.000001	 wd 0.0000	time 0.1725 (0.2241)	loss 0.9365 (0.8966)	grad_norm 0.2928 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:55:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:35 lr 0.000001	 wd 0.0000	time 0.1932 (0.2220)	loss 0.8008 (0.8961)	grad_norm 0.2645 (0.2834)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:55:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:13 lr 0.000001	 wd 0.0000	time 0.1906 (0.2210)	loss 0.7461 (0.8962)	grad_norm 0.2848 (0.2834)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:56:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:01:51 lr 0.000001	 wd 0.0000	time 0.1456 (0.2218)	loss 0.8569 (0.8965)	grad_norm 0.2908 (0.2834)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:56:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:28 lr 0.000001	 wd 0.0000	time 0.1586 (0.2203)	loss 0.8242 (0.8967)	grad_norm 0.2679 (0.2834)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:56:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:06 lr 0.000001	 wd 0.0000	time 0.1830 (0.2187)	loss 0.7710 (0.8961)	grad_norm 0.2832 (0.2833)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:57:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:43 lr 0.000001	 wd 0.0000	time 0.2091 (0.2174)	loss 0.7383 (0.8964)	grad_norm 0.2921 (0.2834)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:57:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:22 lr 0.000001	 wd 0.0000	time 0.1775 (0.2166)	loss 0.7925 (0.8963)	grad_norm 0.2883 (0.2834)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:57:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1529 (0.2157)	loss 0.9590 (0.8960)	grad_norm 0.2911 (0.2834)	loss_scale 32768.0000 (32768.0000)	mem 7518MB
[2024-07-31 14:58:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 249): INFO EPOCH 29 training takes 0:09:11
[2024-07-31 14:58:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_29.pth saving......
[2024-07-31 14:58:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_29.pth saved !!!
[2024-07-31 14:58:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 289): INFO Test: [0/98]	Time 18.459 (18.459)	Loss 0.3567 (0.3567)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7518MB
[2024-07-31 14:58:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 296): INFO  * Acc@1 84.930 Acc@5 97.484
[2024-07-31 14:58:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 14:58:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 182): INFO Max accuracy: 84.93%
[2024-07-31 14:58:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1] (main.py 189): INFO Training time 5:00:06
