[2024-07-30 09:25:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 366): INFO Full config saved to pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/config.json
[2024-07-30 09:25:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_convnext_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 27
    - 3
    DIMS:
    - 128
    - 256
    - 512
    - 1024
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: stage2
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_conv_b_sequence_stage2
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 0.0001
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 0.8
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.0e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 1.0e-08

[2024-07-30 09:25:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/diffusion_finetune/convnext/adapter_convnext/diffusion_ft_adapter_convnext_base_224_22kto1k_step_stage_process2.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/diffusion-ft", "tag": "diffusion_ft_adapter_conv_b_sequence_stage2", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-30 09:25:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 108): INFO Creating model:adapter_convnext_diffusion_finetune/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2
[2024-07-30 09:25:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 110): INFO Adapter_ConvNeXt_Diffusion_Finetune(
  (uma): UMA(filter_strategy1=18, filter_strategy2=6,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): Identity()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (12): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (13): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (14): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (15): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (16): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (17): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (18): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (19): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (20): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (21): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (22): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (23): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (24): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (25): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (26): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (memory_downsampling): ModuleList()
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-30 09:25:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 113): INFO number of params: 4583272
[2024-07-30 09:25:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 150): INFO no checkpoint found in pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2, ignoring auto resume
[2024-07-30 09:25:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth for fine-tuning......
[2024-07-30 09:25:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 127): WARNING <All keys matched successfully>
[2024-07-30 09:25:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth'
[2024-07-30 09:26:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 78.511 (78.511)	Loss 0.3579 (0.3579)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 3075MB
[2024-07-30 09:27:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.918 Acc@5 97.490
[2024-07-30 09:27:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 162): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 09:27:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 168): INFO Start training
[2024-07-30 09:27:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][0/2502]	eta 16:01:22 lr 0.000100	 wd 0.0000	time 23.0544 (23.0544)	loss 0.8760 (0.8760)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 5928MB
[2024-07-30 09:28:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:18:45 lr 0.000100	 wd 0.0000	time 0.4465 (0.4686)	loss 0.8291 (0.8832)	grad_norm 0.3386 (nan)	loss_scale 32768.0000 (33092.4356)	mem 5928MB
[2024-07-30 09:28:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:16:27 lr 0.000100	 wd 0.0000	time 0.1704 (0.4291)	loss 0.8594 (0.8885)	grad_norm 0.3187 (nan)	loss_scale 32768.0000 (32931.0249)	mem 5928MB
[2024-07-30 09:29:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:42 lr 0.000100	 wd 0.0000	time 0.1501 (0.3464)	loss 0.9077 (0.8918)	grad_norm 0.3350 (nan)	loss_scale 32768.0000 (32876.8638)	mem 5928MB
[2024-07-30 09:29:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:38 lr 0.000100	 wd 0.0000	time 0.1448 (0.3036)	loss 1.2412 (0.8917)	grad_norm 0.3140 (nan)	loss_scale 32768.0000 (32849.7157)	mem 5928MB
[2024-07-30 09:29:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:09:30 lr 0.000100	 wd 0.0000	time 0.3518 (0.2848)	loss 0.8154 (0.8917)	grad_norm 0.3021 (nan)	loss_scale 32768.0000 (32833.4052)	mem 5928MB
[2024-07-30 09:30:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:43 lr 0.000100	 wd 0.0000	time 0.1653 (0.3070)	loss 0.9819 (0.8915)	grad_norm 0.3071 (nan)	loss_scale 32768.0000 (32822.5225)	mem 5928MB
[2024-07-30 09:30:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:41 lr 0.000100	 wd 0.0000	time 0.1735 (0.2894)	loss 0.8359 (0.8884)	grad_norm 0.2897 (nan)	loss_scale 32768.0000 (32814.7447)	mem 5928MB
[2024-07-30 09:31:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:49 lr 0.000100	 wd 0.0000	time 0.1752 (0.2756)	loss 0.9189 (0.8896)	grad_norm 0.2898 (nan)	loss_scale 32768.0000 (32808.9089)	mem 5928MB
[2024-07-30 09:31:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:19 lr 0.000100	 wd 0.0000	time 0.4233 (0.2741)	loss 1.0684 (0.8882)	grad_norm 0.3066 (nan)	loss_scale 32768.0000 (32804.3685)	mem 5928MB
[2024-07-30 09:32:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:07:05 lr 0.000100	 wd 0.0000	time 0.1705 (0.2830)	loss 0.8784 (0.8881)	grad_norm 0.3032 (nan)	loss_scale 32768.0000 (32800.7353)	mem 5928MB
[2024-07-30 09:32:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:23 lr 0.000100	 wd 0.0000	time 0.1891 (0.2737)	loss 0.8042 (0.8878)	grad_norm 0.3167 (nan)	loss_scale 32768.0000 (32797.7620)	mem 5928MB
[2024-07-30 09:32:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:45 lr 0.000100	 wd 0.0000	time 0.1518 (0.2657)	loss 0.7690 (0.8878)	grad_norm 0.3043 (nan)	loss_scale 32768.0000 (32795.2839)	mem 5928MB
[2024-07-30 09:33:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:18 lr 0.000100	 wd 0.0000	time 0.4793 (0.2648)	loss 0.8579 (0.8892)	grad_norm 0.3102 (nan)	loss_scale 32768.0000 (32793.1868)	mem 5928MB
[2024-07-30 09:33:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:53 lr 0.000100	 wd 0.0000	time 0.1503 (0.2666)	loss 0.8809 (0.8893)	grad_norm 0.3138 (nan)	loss_scale 32768.0000 (32791.3890)	mem 5928MB
[2024-07-30 09:34:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:21 lr 0.000100	 wd 0.0000	time 0.1573 (0.2605)	loss 0.9600 (0.8899)	grad_norm 0.3038 (nan)	loss_scale 32768.0000 (32789.8308)	mem 5928MB
[2024-07-30 09:34:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:50 lr 0.000100	 wd 0.0000	time 0.1970 (0.2555)	loss 1.0625 (0.8907)	grad_norm 0.3093 (nan)	loss_scale 32768.0000 (32788.4672)	mem 5928MB
[2024-07-30 09:34:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:22 lr 0.000100	 wd 0.0000	time 0.1937 (0.2520)	loss 0.8804 (0.8908)	grad_norm 0.2942 (nan)	loss_scale 32768.0000 (32787.2640)	mem 5928MB
[2024-07-30 09:35:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:02:56 lr 0.000100	 wd 0.0000	time 0.1295 (0.2513)	loss 0.8662 (0.8907)	grad_norm 0.3251 (nan)	loss_scale 32768.0000 (32786.1943)	mem 5928MB
[2024-07-30 09:35:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:29 lr 0.000100	 wd 0.0000	time 0.2022 (0.2490)	loss 0.9780 (0.8909)	grad_norm 0.2989 (nan)	loss_scale 32768.0000 (32785.2372)	mem 5928MB
[2024-07-30 09:35:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:03 lr 0.000100	 wd 0.0000	time 0.1577 (0.2459)	loss 0.9341 (0.8910)	grad_norm 0.3150 (nan)	loss_scale 32768.0000 (32784.3758)	mem 5928MB
[2024-07-30 09:36:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:37 lr 0.000100	 wd 0.0000	time 0.1540 (0.2430)	loss 0.8887 (0.8913)	grad_norm 0.2996 (nan)	loss_scale 32768.0000 (32783.5964)	mem 5928MB
[2024-07-30 09:36:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:12 lr 0.000100	 wd 0.0000	time 0.1962 (0.2412)	loss 1.0078 (0.8911)	grad_norm 0.3069 (nan)	loss_scale 32768.0000 (32782.8878)	mem 5928MB
[2024-07-30 09:36:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:48 lr 0.000100	 wd 0.0000	time 0.1718 (0.2407)	loss 1.0068 (0.8909)	grad_norm 0.3134 (nan)	loss_scale 32768.0000 (32782.2408)	mem 5928MB
[2024-07-30 09:37:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:24 lr 0.000100	 wd 0.0000	time 0.1644 (0.2385)	loss 1.0566 (0.8911)	grad_norm 0.3000 (nan)	loss_scale 32768.0000 (32781.6476)	mem 5928MB
[2024-07-30 09:37:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000100	 wd 0.0000	time 0.1234 (0.2352)	loss 0.8789 (0.8909)	grad_norm 0.2889 (nan)	loss_scale 32768.0000 (32781.1020)	mem 5928MB
[2024-07-30 09:37:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 0 training takes 0:09:52
[2024-07-30 09:37:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_0.pth saving......
[2024-07-30 09:37:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_0.pth saved !!!
[2024-07-30 09:38:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 63.993 (63.993)	Loss 0.3677 (0.3677)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 09:38:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.920 Acc@5 97.526
[2024-07-30 09:38:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 09:38:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.92%
[2024-07-30 09:38:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-30 09:38:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-30 09:38:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][0/2502]	eta 11:27:04 lr 0.000100	 wd 0.0000	time 16.4765 (16.4765)	loss 0.7695 (0.7695)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:39:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:13:46 lr 0.000100	 wd 0.0000	time 0.1528 (0.3442)	loss 0.8296 (0.8769)	grad_norm 0.3036 (0.2989)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:39:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:13:00 lr 0.000100	 wd 0.0000	time 0.1989 (0.3389)	loss 0.7852 (0.8829)	grad_norm 0.2936 (0.2989)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:40:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:10:50 lr 0.000100	 wd 0.0000	time 0.1871 (0.2952)	loss 0.9204 (0.8846)	grad_norm 0.2977 (0.2993)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:40:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:09:18 lr 0.000100	 wd 0.0000	time 0.1917 (0.2659)	loss 0.8823 (0.8857)	grad_norm 0.3066 (0.3001)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:40:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:08:16 lr 0.000100	 wd 0.0000	time 0.1811 (0.2479)	loss 0.8237 (0.8844)	grad_norm 0.2950 (0.3001)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:41:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:07:40 lr 0.000100	 wd 0.0000	time 0.3357 (0.2419)	loss 0.9043 (0.8861)	grad_norm 0.3100 (0.2999)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:41:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:02 lr 0.000100	 wd 0.0000	time 0.1625 (0.2680)	loss 0.8320 (0.8853)	grad_norm 0.2949 (0.2999)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:42:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:17 lr 0.000100	 wd 0.0000	time 0.1643 (0.2572)	loss 1.0283 (0.8867)	grad_norm 0.2950 (0.2998)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:42:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:06:37 lr 0.000099	 wd 0.0000	time 0.1936 (0.2484)	loss 0.8682 (0.8867)	grad_norm 0.3051 (0.2997)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:42:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:09 lr 0.000099	 wd 0.0000	time 0.3453 (0.2460)	loss 0.8833 (0.8868)	grad_norm 0.3001 (0.2998)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:43:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:05:51 lr 0.000099	 wd 0.0000	time 0.1328 (0.2508)	loss 0.9668 (0.8878)	grad_norm 0.3110 (0.2999)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:43:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:18 lr 0.000099	 wd 0.0000	time 0.1765 (0.2447)	loss 0.8481 (0.8878)	grad_norm 0.3031 (0.3000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:43:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:04:47 lr 0.000099	 wd 0.0000	time 0.1665 (0.2394)	loss 0.8608 (0.8884)	grad_norm 0.3017 (0.3000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:44:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:19 lr 0.000099	 wd 0.0000	time 0.1912 (0.2355)	loss 0.8770 (0.8887)	grad_norm 0.3035 (0.3000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:44:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:01 lr 0.000099	 wd 0.0000	time 0.1545 (0.2415)	loss 0.8862 (0.8897)	grad_norm 0.2974 (0.3000)	loss_scale 65536.0000 (32811.6616)	mem 5928MB
[2024-07-30 09:45:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:34 lr 0.000099	 wd 0.0000	time 0.1778 (0.2376)	loss 0.8237 (0.8894)	grad_norm 0.2836 (nan)	loss_scale 32768.0000 (32808.9344)	mem 5928MB
[2024-07-30 09:45:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:07 lr 0.000099	 wd 0.0000	time 0.1575 (0.2343)	loss 0.7812 (0.8895)	grad_norm 0.2973 (nan)	loss_scale 32768.0000 (32806.5279)	mem 5928MB
[2024-07-30 09:45:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:42 lr 0.000099	 wd 0.0000	time 0.1720 (0.2315)	loss 0.9844 (0.8894)	grad_norm 0.2909 (nan)	loss_scale 32768.0000 (32804.3887)	mem 5928MB
[2024-07-30 09:45:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:18 lr 0.000099	 wd 0.0000	time 0.2007 (0.2298)	loss 0.9048 (0.8898)	grad_norm 0.2864 (nan)	loss_scale 32768.0000 (32802.4745)	mem 5928MB
[2024-07-30 09:46:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:01:55 lr 0.000099	 wd 0.0000	time 0.1455 (0.2298)	loss 0.7896 (0.8897)	grad_norm 0.3012 (nan)	loss_scale 32768.0000 (32800.7516)	mem 5928MB
[2024-07-30 09:46:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:31 lr 0.000099	 wd 0.0000	time 0.1700 (0.2281)	loss 0.8398 (0.8896)	grad_norm 0.3146 (nan)	loss_scale 32768.0000 (32799.1928)	mem 5928MB
[2024-07-30 09:46:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:08 lr 0.000099	 wd 0.0000	time 0.1783 (0.2263)	loss 0.7725 (0.8890)	grad_norm 0.2814 (nan)	loss_scale 32768.0000 (32797.7756)	mem 5928MB
[2024-07-30 09:47:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:45 lr 0.000099	 wd 0.0000	time 0.2213 (0.2245)	loss 0.9360 (0.8898)	grad_norm 0.3010 (nan)	loss_scale 32768.0000 (32796.4815)	mem 5928MB
[2024-07-30 09:47:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:22 lr 0.000099	 wd 0.0000	time 0.1644 (0.2237)	loss 0.9131 (0.8899)	grad_norm 0.3089 (nan)	loss_scale 32768.0000 (32795.2953)	mem 5928MB
[2024-07-30 09:47:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000099	 wd 0.0000	time 0.1419 (0.2220)	loss 0.9092 (0.8902)	grad_norm 0.3060 (nan)	loss_scale 32768.0000 (32794.2039)	mem 5928MB
[2024-07-30 09:48:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 1 training takes 0:09:22
[2024-07-30 09:48:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 24.272 (24.272)	Loss 0.3665 (0.3665)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 09:48:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 84.872 Acc@5 97.534
[2024-07-30 09:48:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 09:48:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 84.92%
[2024-07-30 09:48:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][0/2502]	eta 12:23:15 lr 0.000099	 wd 0.0000	time 17.8238 (17.8238)	loss 0.7983 (0.7983)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:49:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:19:35 lr 0.000099	 wd 0.0000	time 0.2734 (0.4895)	loss 0.9800 (0.8875)	grad_norm 0.2966 (0.2955)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:49:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:13:22 lr 0.000099	 wd 0.0000	time 0.1656 (0.3485)	loss 0.9487 (0.8860)	grad_norm 0.2954 (0.2966)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:50:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:10:42 lr 0.000099	 wd 0.0000	time 0.1629 (0.2919)	loss 0.8154 (0.8820)	grad_norm 0.3076 (0.2968)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:50:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:09:12 lr 0.000099	 wd 0.0000	time 0.1578 (0.2629)	loss 0.9712 (0.8835)	grad_norm 0.2885 (0.2975)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:50:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:08:20 lr 0.000099	 wd 0.0000	time 0.2260 (0.2498)	loss 0.9316 (0.8896)	grad_norm 0.3098 (0.2975)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:51:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:22 lr 0.000099	 wd 0.0000	time 0.1964 (0.2644)	loss 0.7983 (0.8894)	grad_norm 0.3007 (0.2974)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:51:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:07:34 lr 0.000099	 wd 0.0000	time 0.1619 (0.2523)	loss 0.8652 (0.8890)	grad_norm 0.2993 (0.2974)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:51:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:06:54 lr 0.000099	 wd 0.0000	time 0.1970 (0.2433)	loss 0.7959 (0.8874)	grad_norm 0.2993 (0.2974)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:52:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:18 lr 0.000098	 wd 0.0000	time 0.2076 (0.2361)	loss 0.9238 (0.8874)	grad_norm 0.3224 (0.2976)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:52:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:15 lr 0.000098	 wd 0.0000	time 0.1926 (0.2502)	loss 0.7993 (0.8865)	grad_norm 0.2939 (0.2976)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:53:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:42 lr 0.000098	 wd 0.0000	time 0.1727 (0.2446)	loss 0.9131 (0.8866)	grad_norm 0.3004 (0.2978)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:53:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:11 lr 0.000098	 wd 0.0000	time 0.2049 (0.2391)	loss 1.0361 (0.8869)	grad_norm 0.3048 (0.2978)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:53:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:04:41 lr 0.000098	 wd 0.0000	time 0.1717 (0.2343)	loss 0.8901 (0.8878)	grad_norm 0.3116 (0.2978)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:54:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:16 lr 0.000098	 wd 0.0000	time 0.1609 (0.2324)	loss 0.9302 (0.8880)	grad_norm 0.2947 (0.2978)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:54:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:03:52 lr 0.000098	 wd 0.0000	time 0.1680 (0.2321)	loss 1.0684 (0.8884)	grad_norm 0.2975 (0.2978)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:54:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:26 lr 0.000098	 wd 0.0000	time 0.1705 (0.2290)	loss 0.9487 (0.8880)	grad_norm 0.2969 (0.2980)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:55:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:01 lr 0.000098	 wd 0.0000	time 0.1596 (0.2264)	loss 0.8945 (0.8888)	grad_norm 0.3015 (0.2980)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:55:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:37 lr 0.000098	 wd 0.0000	time 0.2122 (0.2239)	loss 0.8721 (0.8886)	grad_norm 0.2753 (0.2980)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:55:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:14 lr 0.000098	 wd 0.0000	time 0.1758 (0.2233)	loss 0.8076 (0.8892)	grad_norm 0.2962 (0.2982)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:56:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:01:52 lr 0.000098	 wd 0.0000	time 0.1467 (0.2237)	loss 0.9072 (0.8892)	grad_norm 0.2879 (0.2982)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:56:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:29 lr 0.000098	 wd 0.0000	time 0.1991 (0.2220)	loss 0.9702 (0.8899)	grad_norm 0.3050 (0.2983)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:56:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:06 lr 0.000098	 wd 0.0000	time 0.1591 (0.2203)	loss 0.8789 (0.8897)	grad_norm 0.2969 (0.2982)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:57:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:44 lr 0.000098	 wd 0.0000	time 0.1679 (0.2188)	loss 0.8237 (0.8896)	grad_norm 0.3044 (0.2983)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:57:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:22 lr 0.000098	 wd 0.0000	time 0.4180 (0.2190)	loss 0.8638 (0.8899)	grad_norm 0.2963 (0.2983)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:57:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000098	 wd 0.0000	time 0.1277 (0.2169)	loss 0.8975 (0.8896)	grad_norm 0.3060 (0.2983)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:57:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 2 training takes 0:09:08
[2024-07-30 09:58:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 25.604 (25.604)	Loss 0.3640 (0.3640)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 09:58:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.086 Acc@5 97.544
[2024-07-30 09:58:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-30 09:58:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.09%
[2024-07-30 09:58:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-30 09:58:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-30 09:58:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][0/2502]	eta 12:58:15 lr 0.000098	 wd 0.0000	time 18.6633 (18.6633)	loss 0.7451 (0.7451)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:59:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:16:35 lr 0.000098	 wd 0.0000	time 0.1939 (0.4146)	loss 1.0098 (0.8869)	grad_norm 0.3039 (0.3006)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:59:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:11:32 lr 0.000097	 wd 0.0000	time 0.1674 (0.3006)	loss 1.0234 (0.8832)	grad_norm 0.3123 (0.3001)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 09:59:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:09:32 lr 0.000097	 wd 0.0000	time 0.1586 (0.2600)	loss 1.0332 (0.8845)	grad_norm 0.2933 (0.2996)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:00:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:08:23 lr 0.000097	 wd 0.0000	time 0.1496 (0.2394)	loss 0.9927 (0.8838)	grad_norm 0.2861 (0.2990)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:00:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:07:49 lr 0.000097	 wd 0.0000	time 0.3114 (0.2343)	loss 0.9062 (0.8851)	grad_norm nan (nan)	loss_scale 32768.0000 (32898.8104)	mem 5928MB
[2024-07-30 10:01:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:08:14 lr 0.000097	 wd 0.0000	time 0.2095 (0.2601)	loss 0.8296 (0.8854)	grad_norm 0.3140 (nan)	loss_scale 32768.0000 (32877.0449)	mem 5928MB
[2024-07-30 10:01:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:07:28 lr 0.000097	 wd 0.0000	time 0.1782 (0.2490)	loss 0.9282 (0.8865)	grad_norm 0.2980 (nan)	loss_scale 32768.0000 (32861.4893)	mem 5928MB
[2024-07-30 10:01:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:06:49 lr 0.000097	 wd 0.0000	time 0.1858 (0.2404)	loss 0.8589 (0.8852)	grad_norm 0.3105 (nan)	loss_scale 32768.0000 (32849.8177)	mem 5928MB
[2024-07-30 10:01:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:06:16 lr 0.000097	 wd 0.0000	time 0.2041 (0.2349)	loss 0.9033 (0.8857)	grad_norm 0.3032 (nan)	loss_scale 32768.0000 (32840.7370)	mem 5928MB
[2024-07-30 10:02:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:09 lr 0.000097	 wd 0.0000	time 0.1881 (0.2461)	loss 1.0566 (0.8875)	grad_norm 0.3149 (nan)	loss_scale 32768.0000 (32833.4705)	mem 5928MB
[2024-07-30 10:02:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:05:36 lr 0.000097	 wd 0.0000	time 0.1695 (0.2399)	loss 0.7822 (0.8870)	grad_norm 0.3093 (nan)	loss_scale 32768.0000 (32827.5241)	mem 5928MB
[2024-07-30 10:03:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:05 lr 0.000097	 wd 0.0000	time 0.1676 (0.2347)	loss 0.9375 (0.8863)	grad_norm 0.2904 (nan)	loss_scale 32768.0000 (32822.5679)	mem 5928MB
[2024-07-30 10:03:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:04:36 lr 0.000097	 wd 0.0000	time 0.1850 (0.2300)	loss 0.9839 (0.8875)	grad_norm 0.2867 (nan)	loss_scale 32768.0000 (32818.3736)	mem 5928MB
[2024-07-30 10:03:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:20 lr 0.000097	 wd 0.0000	time 0.1266 (0.2360)	loss 0.8540 (0.8873)	grad_norm 0.2879 (nan)	loss_scale 32768.0000 (32814.7780)	mem 5928MB
[2024-07-30 10:04:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:03:53 lr 0.000097	 wd 0.0000	time 0.1750 (0.2325)	loss 0.8208 (0.8883)	grad_norm 0.2861 (nan)	loss_scale 32768.0000 (32811.6616)	mem 5928MB
[2024-07-30 10:04:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:26 lr 0.000096	 wd 0.0000	time 0.1703 (0.2293)	loss 0.8696 (0.8876)	grad_norm 0.3065 (nan)	loss_scale 32768.0000 (32808.9344)	mem 5928MB
[2024-07-30 10:04:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:01 lr 0.000096	 wd 0.0000	time 0.1596 (0.2264)	loss 0.9238 (0.8874)	grad_norm 0.3007 (nan)	loss_scale 32768.0000 (32806.5279)	mem 5928MB
[2024-07-30 10:05:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:37 lr 0.000096	 wd 0.0000	time 0.1831 (0.2244)	loss 0.8896 (0.8875)	grad_norm 0.2846 (nan)	loss_scale 32768.0000 (32804.3887)	mem 5928MB
[2024-07-30 10:05:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:15 lr 0.000096	 wd 0.0000	time 0.1752 (0.2248)	loss 0.8945 (0.8870)	grad_norm 0.2892 (nan)	loss_scale 32768.0000 (32802.4745)	mem 5928MB
[2024-07-30 10:05:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:01:52 lr 0.000096	 wd 0.0000	time 0.1571 (0.2234)	loss 0.8657 (0.8875)	grad_norm 0.2929 (nan)	loss_scale 32768.0000 (32800.7516)	mem 5928MB
[2024-07-30 10:06:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:29 lr 0.000096	 wd 0.0000	time 0.1915 (0.2216)	loss 0.7192 (0.8870)	grad_norm 0.2976 (nan)	loss_scale 32768.0000 (32799.1928)	mem 5928MB
[2024-07-30 10:06:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:06 lr 0.000096	 wd 0.0000	time 0.1534 (0.2199)	loss 0.8359 (0.8867)	grad_norm 0.3034 (nan)	loss_scale 32768.0000 (32797.7756)	mem 5928MB
[2024-07-30 10:06:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:44 lr 0.000096	 wd 0.0000	time 0.1888 (0.2188)	loss 0.9585 (0.8870)	grad_norm 0.3021 (nan)	loss_scale 32768.0000 (32796.4815)	mem 5928MB
[2024-07-30 10:07:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:22 lr 0.000096	 wd 0.0000	time 0.1851 (0.2186)	loss 0.8340 (0.8870)	grad_norm 0.2929 (nan)	loss_scale 32768.0000 (32795.2953)	mem 5928MB
[2024-07-30 10:07:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000096	 wd 0.0000	time 0.1261 (0.2164)	loss 0.8149 (0.8876)	grad_norm 0.3063 (nan)	loss_scale 32768.0000 (32794.2039)	mem 5928MB
[2024-07-30 10:07:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 3 training takes 0:09:06
[2024-07-30 10:07:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 23.797 (23.797)	Loss 0.3696 (0.3696)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 5928MB
[2024-07-30 10:08:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.034 Acc@5 97.556
[2024-07-30 10:08:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-30 10:08:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.09%
[2024-07-30 10:08:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][0/2502]	eta 18:06:44 lr 0.000096	 wd 0.0000	time 26.0609 (26.0609)	loss 0.8906 (0.8906)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:08:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:19:01 lr 0.000096	 wd 0.0000	time 0.1472 (0.4753)	loss 0.7900 (0.8916)	grad_norm 0.2989 (0.2993)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:09:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:12:33 lr 0.000096	 wd 0.0000	time 0.1648 (0.3272)	loss 0.9219 (0.8885)	grad_norm 0.2822 (0.2988)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:09:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:10:14 lr 0.000095	 wd 0.0000	time 0.2030 (0.2790)	loss 0.8892 (0.8885)	grad_norm 0.3076 (0.2991)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:09:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:08:52 lr 0.000095	 wd 0.0000	time 0.1593 (0.2534)	loss 0.8706 (0.8838)	grad_norm 0.2860 (0.2993)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:10:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:09:04 lr 0.000095	 wd 0.0000	time 0.2057 (0.2722)	loss 0.9448 (0.8856)	grad_norm 0.2955 (0.2993)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:10:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:08:24 lr 0.000095	 wd 0.0000	time 0.1872 (0.2651)	loss 0.8379 (0.8878)	grad_norm 0.3043 (0.2993)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:11:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:07:36 lr 0.000095	 wd 0.0000	time 0.1658 (0.2533)	loss 0.9883 (0.8848)	grad_norm 0.2925 (0.2993)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:11:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:06:55 lr 0.000095	 wd 0.0000	time 0.1937 (0.2438)	loss 0.8589 (0.8851)	grad_norm 0.3061 (0.2992)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:11:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:06:31 lr 0.000095	 wd 0.0000	time 0.4176 (0.2445)	loss 0.8599 (0.8864)	grad_norm 0.3056 (0.2993)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:12:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:18 lr 0.000095	 wd 0.0000	time 0.1498 (0.2522)	loss 0.9121 (0.8864)	grad_norm 0.3022 (0.2995)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:12:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:05:44 lr 0.000095	 wd 0.0000	time 0.1561 (0.2457)	loss 0.9380 (0.8881)	grad_norm 0.3104 (0.2996)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:12:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:12 lr 0.000095	 wd 0.0000	time 0.1786 (0.2398)	loss 0.7437 (0.8879)	grad_norm 0.2952 (0.2996)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:13:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:04:43 lr 0.000095	 wd 0.0000	time 0.1739 (0.2360)	loss 0.8438 (0.8872)	grad_norm 0.3000 (0.2996)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:13:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:21 lr 0.000094	 wd 0.0000	time 0.1492 (0.2370)	loss 0.8984 (0.8868)	grad_norm 0.3021 (0.2998)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:13:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:03:54 lr 0.000094	 wd 0.0000	time 0.1897 (0.2335)	loss 0.7505 (0.8869)	grad_norm 0.3031 (0.2999)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:14:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:27 lr 0.000094	 wd 0.0000	time 0.1755 (0.2302)	loss 0.8438 (0.8868)	grad_norm 0.2908 (0.2999)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:14:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:02 lr 0.000094	 wd 0.0000	time 0.1721 (0.2273)	loss 1.0742 (0.8865)	grad_norm 0.3065 (0.2999)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:14:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:38 lr 0.000094	 wd 0.0000	time 0.2375 (0.2257)	loss 0.9346 (0.8870)	grad_norm 0.2888 (0.2999)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:15:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:16 lr 0.000094	 wd 0.0000	time 0.1540 (0.2260)	loss 0.8955 (0.8869)	grad_norm 0.2915 (0.2999)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:15:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:01:52 lr 0.000094	 wd 0.0000	time 0.1525 (0.2244)	loss 0.7793 (0.8864)	grad_norm nan (nan)	loss_scale 32768.0000 (32800.7516)	mem 5928MB
[2024-07-30 10:15:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:29 lr 0.000094	 wd 0.0000	time 0.2159 (0.2226)	loss 0.8296 (0.8872)	grad_norm 0.3138 (nan)	loss_scale 32768.0000 (32799.1928)	mem 5928MB
[2024-07-30 10:16:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:06 lr 0.000094	 wd 0.0000	time 0.1690 (0.2208)	loss 0.9897 (0.8867)	grad_norm 0.2758 (nan)	loss_scale 32768.0000 (32797.7756)	mem 5928MB
[2024-07-30 10:16:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:44 lr 0.000094	 wd 0.0000	time 0.2144 (0.2199)	loss 0.8589 (0.8870)	grad_norm 0.2997 (nan)	loss_scale 32768.0000 (32796.4815)	mem 5928MB
[2024-07-30 10:16:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:22 lr 0.000093	 wd 0.0000	time 0.1733 (0.2200)	loss 0.8340 (0.8873)	grad_norm 0.2877 (nan)	loss_scale 32768.0000 (32795.2953)	mem 5928MB
[2024-07-30 10:17:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000093	 wd 0.0000	time 0.1256 (0.2175)	loss 0.7676 (0.8873)	grad_norm 0.3057 (nan)	loss_scale 32768.0000 (32794.2039)	mem 5928MB
[2024-07-30 10:17:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 4 training takes 0:09:08
[2024-07-30 10:17:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 23.336 (23.336)	Loss 0.3623 (0.3623)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 10:17:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.092 Acc@5 97.562
[2024-07-30 10:17:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-30 10:17:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.09%
[2024-07-30 10:17:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-30 10:17:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-30 10:18:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][0/2502]	eta 23:17:33 lr 0.000093	 wd 0.0000	time 33.5144 (33.5144)	loss 0.8691 (0.8691)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:18:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:20:47 lr 0.000093	 wd 0.0000	time 0.1521 (0.5195)	loss 0.9263 (0.8774)	grad_norm 0.3157 (0.3004)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:19:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:13:22 lr 0.000093	 wd 0.0000	time 0.1963 (0.3487)	loss 0.7876 (0.8818)	grad_norm 0.3046 (0.3019)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:19:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:42 lr 0.000093	 wd 0.0000	time 0.2013 (0.2916)	loss 0.9966 (0.8806)	grad_norm 0.2913 (0.3011)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:19:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:23 lr 0.000093	 wd 0.0000	time 0.1710 (0.2680)	loss 0.9414 (0.8800)	grad_norm 0.3090 (0.3016)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:20:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:09:11 lr 0.000093	 wd 0.0000	time 0.1670 (0.2755)	loss 0.8413 (0.8800)	grad_norm 0.3168 (0.3014)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:20:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:14 lr 0.000093	 wd 0.0000	time 0.1674 (0.2598)	loss 0.8481 (0.8829)	grad_norm 0.3013 (0.3014)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:20:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:26 lr 0.000093	 wd 0.0000	time 0.1832 (0.2480)	loss 0.7969 (0.8822)	grad_norm 0.3178 (0.3015)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:21:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:06:47 lr 0.000093	 wd 0.0000	time 0.1773 (0.2391)	loss 0.8379 (0.8819)	grad_norm 0.3097 (0.3016)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:21:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:25 lr 0.000092	 wd 0.0000	time 0.3511 (0.2404)	loss 0.9258 (0.8825)	grad_norm 0.3012 (0.3018)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:21:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:03 lr 0.000092	 wd 0.0000	time 0.1451 (0.2423)	loss 0.9258 (0.8845)	grad_norm 0.2955 (0.3018)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:22:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:31 lr 0.000092	 wd 0.0000	time 0.1792 (0.2365)	loss 0.8252 (0.8856)	grad_norm 0.2989 (0.3019)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:22:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:01 lr 0.000092	 wd 0.0000	time 0.1591 (0.2317)	loss 0.9141 (0.8862)	grad_norm 0.2958 (0.3020)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:22:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:34 lr 0.000092	 wd 0.0000	time 0.1888 (0.2282)	loss 0.9570 (0.8856)	grad_norm 0.3134 (0.3017)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:23:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:12 lr 0.000092	 wd 0.0000	time 0.1770 (0.2293)	loss 0.8613 (0.8848)	grad_norm 0.3059 (0.3017)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:23:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:03:46 lr 0.000092	 wd 0.0000	time 0.1557 (0.2265)	loss 0.8540 (0.8855)	grad_norm 0.2969 (0.3018)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:23:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:21 lr 0.000092	 wd 0.0000	time 0.1677 (0.2235)	loss 0.8135 (0.8861)	grad_norm 0.3104 (0.3019)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:24:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:02:57 lr 0.000092	 wd 0.0000	time 0.1464 (0.2211)	loss 0.8838 (0.8865)	grad_norm 0.2969 (0.3020)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:24:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:33 lr 0.000091	 wd 0.0000	time 0.1944 (0.2193)	loss 0.8770 (0.8858)	grad_norm 0.3091 (0.3021)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:24:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:12 lr 0.000091	 wd 0.0000	time 0.1613 (0.2201)	loss 0.8721 (0.8856)	grad_norm 0.3016 (0.3022)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:25:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:01:49 lr 0.000091	 wd 0.0000	time 0.1654 (0.2190)	loss 0.9663 (0.8862)	grad_norm 0.3074 (0.3023)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:25:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:27 lr 0.000091	 wd 0.0000	time 0.1761 (0.2173)	loss 0.9878 (0.8857)	grad_norm 0.3118 (0.3024)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:25:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:05 lr 0.000091	 wd 0.0000	time 0.1508 (0.2158)	loss 0.9995 (0.8857)	grad_norm 0.3057 (0.3024)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:26:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:43 lr 0.000091	 wd 0.0000	time 0.1673 (0.2150)	loss 0.7549 (0.8855)	grad_norm 0.3170 (0.3025)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:26:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:21 lr 0.000091	 wd 0.0000	time 0.1759 (0.2153)	loss 0.7905 (0.8851)	grad_norm 0.3116 (0.3025)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:26:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000091	 wd 0.0000	time 0.1319 (0.2134)	loss 0.7764 (0.8847)	grad_norm 0.2956 (0.3025)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:26:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 5 training takes 0:08:58
[2024-07-30 10:27:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 18.818 (18.818)	Loss 0.3594 (0.3594)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 5928MB
[2024-07-30 10:27:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.096 Acc@5 97.576
[2024-07-30 10:27:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-30 10:27:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.10%
[2024-07-30 10:27:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-30 10:27:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-30 10:27:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][0/2502]	eta 13:45:00 lr 0.000091	 wd 0.0000	time 19.7846 (19.7846)	loss 0.9360 (0.9360)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:28:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:18:59 lr 0.000090	 wd 0.0000	time 0.1686 (0.4745)	loss 0.8755 (0.8949)	grad_norm 0.3175 (0.3026)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:28:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:12:31 lr 0.000090	 wd 0.0000	time 0.1498 (0.3266)	loss 0.8013 (0.8886)	grad_norm 0.3015 (0.3025)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:28:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:10:11 lr 0.000090	 wd 0.0000	time 0.1545 (0.2777)	loss 0.8945 (0.8883)	grad_norm 0.3051 (0.3028)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:29:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:08:52 lr 0.000090	 wd 0.0000	time 0.1494 (0.2532)	loss 0.8594 (0.8867)	grad_norm 0.2975 (0.3030)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:29:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:08:11 lr 0.000090	 wd 0.0000	time 0.2485 (0.2453)	loss 0.9233 (0.8864)	grad_norm 0.2969 (0.3031)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:30:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:08:10 lr 0.000090	 wd 0.0000	time 0.1820 (0.2580)	loss 0.8911 (0.8860)	grad_norm 0.3125 (0.3033)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:30:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:07:25 lr 0.000090	 wd 0.0000	time 0.1838 (0.2470)	loss 0.9897 (0.8860)	grad_norm 0.3112 (0.3037)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:30:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:06:45 lr 0.000090	 wd 0.0000	time 0.1859 (0.2384)	loss 0.7310 (0.8862)	grad_norm 0.3020 (0.3035)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:30:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:06:12 lr 0.000089	 wd 0.0000	time 0.2000 (0.2326)	loss 0.8799 (0.8856)	grad_norm 0.2870 (0.3035)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:31:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:01 lr 0.000089	 wd 0.0000	time 0.1641 (0.2410)	loss 0.8481 (0.8866)	grad_norm 0.3031 (nan)	loss_scale 32768.0000 (32833.4705)	mem 5928MB
[2024-07-30 10:31:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:30 lr 0.000089	 wd 0.0000	time 0.1471 (0.2354)	loss 0.8174 (0.8854)	grad_norm 0.3058 (nan)	loss_scale 32768.0000 (32827.5241)	mem 5928MB
[2024-07-30 10:32:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:00 lr 0.000089	 wd 0.0000	time 0.2194 (0.2308)	loss 0.8472 (0.8855)	grad_norm 0.3044 (nan)	loss_scale 32768.0000 (32822.5679)	mem 5928MB
[2024-07-30 10:32:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:04:32 lr 0.000089	 wd 0.0000	time 0.1680 (0.2266)	loss 0.7861 (0.8849)	grad_norm 0.2997 (nan)	loss_scale 32768.0000 (32818.3736)	mem 5928MB
[2024-07-30 10:32:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:08 lr 0.000089	 wd 0.0000	time 0.2330 (0.2253)	loss 0.9155 (0.8844)	grad_norm 0.3018 (nan)	loss_scale 32768.0000 (32814.7780)	mem 5928MB
[2024-07-30 10:33:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:03:45 lr 0.000089	 wd 0.0000	time 0.1824 (0.2250)	loss 0.7891 (0.8844)	grad_norm 0.2985 (nan)	loss_scale 32768.0000 (32811.6616)	mem 5928MB
[2024-07-30 10:33:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:20 lr 0.000089	 wd 0.0000	time 0.1410 (0.2226)	loss 0.7944 (0.8840)	grad_norm 0.2941 (nan)	loss_scale 32768.0000 (32808.9344)	mem 5928MB
[2024-07-30 10:33:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:02:56 lr 0.000088	 wd 0.0000	time 0.1927 (0.2203)	loss 0.8501 (0.8827)	grad_norm 0.2939 (nan)	loss_scale 32768.0000 (32806.5279)	mem 5928MB
[2024-07-30 10:33:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:33 lr 0.000088	 wd 0.0000	time 0.1769 (0.2181)	loss 0.8179 (0.8826)	grad_norm 0.3047 (nan)	loss_scale 32768.0000 (32804.3887)	mem 5928MB
[2024-07-30 10:34:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:10 lr 0.000088	 wd 0.0000	time 0.2158 (0.2172)	loss 0.9062 (0.8831)	grad_norm 0.3020 (nan)	loss_scale 32768.0000 (32802.4745)	mem 5928MB
[2024-07-30 10:34:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:01:49 lr 0.000088	 wd 0.0000	time 0.1704 (0.2179)	loss 0.9336 (0.8837)	grad_norm 0.3091 (nan)	loss_scale 32768.0000 (32800.7516)	mem 5928MB
[2024-07-30 10:35:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:27 lr 0.000088	 wd 0.0000	time 0.1777 (0.2166)	loss 0.8037 (0.8836)	grad_norm 0.3015 (nan)	loss_scale 32768.0000 (32799.1928)	mem 5928MB
[2024-07-30 10:35:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:04 lr 0.000088	 wd 0.0000	time 0.1565 (0.2152)	loss 0.8960 (0.8830)	grad_norm 0.3061 (nan)	loss_scale 32768.0000 (32797.7756)	mem 5928MB
[2024-07-30 10:35:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:43 lr 0.000088	 wd 0.0000	time 0.1738 (0.2138)	loss 0.8374 (0.8830)	grad_norm 0.3055 (nan)	loss_scale 32768.0000 (32796.4815)	mem 5928MB
[2024-07-30 10:35:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:21 lr 0.000087	 wd 0.0000	time 0.1751 (0.2134)	loss 0.8765 (0.8837)	grad_norm 0.2893 (nan)	loss_scale 32768.0000 (32795.2953)	mem 5928MB
[2024-07-30 10:36:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000087	 wd 0.0000	time 0.1376 (0.2123)	loss 0.7822 (0.8842)	grad_norm 0.3140 (nan)	loss_scale 32768.0000 (32794.2039)	mem 5928MB
[2024-07-30 10:36:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 6 training takes 0:08:56
[2024-07-30 10:36:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 19.377 (19.377)	Loss 0.3606 (0.3606)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 5928MB
[2024-07-30 10:36:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.064 Acc@5 97.582
[2024-07-30 10:36:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-30 10:36:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.10%
[2024-07-30 10:37:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][0/2502]	eta 11:44:58 lr 0.000087	 wd 0.0000	time 16.9057 (16.9057)	loss 0.8486 (0.8486)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:37:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:16:10 lr 0.000087	 wd 0.0000	time 0.2357 (0.4040)	loss 0.9717 (0.8818)	grad_norm 0.3024 (0.3051)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:37:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:12:30 lr 0.000087	 wd 0.0000	time 0.1578 (0.3261)	loss 0.8735 (0.8800)	grad_norm 0.2957 (0.3065)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:38:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:10:08 lr 0.000087	 wd 0.0000	time 0.1546 (0.2765)	loss 0.8306 (0.8776)	grad_norm 0.3180 (0.3061)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:38:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:08:50 lr 0.000087	 wd 0.0000	time 0.1495 (0.2523)	loss 0.8979 (0.8825)	grad_norm 0.3301 (0.3062)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:38:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:07:54 lr 0.000087	 wd 0.0000	time 0.1670 (0.2370)	loss 0.7783 (0.8802)	grad_norm 0.2772 (0.3061)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:39:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:03 lr 0.000086	 wd 0.0000	time 0.2853 (0.2543)	loss 0.9956 (0.8824)	grad_norm 0.2888 (0.3059)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:39:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:07:28 lr 0.000086	 wd 0.0000	time 0.1751 (0.2490)	loss 0.8042 (0.8821)	grad_norm 0.2835 (0.3060)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:40:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:06:48 lr 0.000086	 wd 0.0000	time 0.1787 (0.2403)	loss 0.8340 (0.8812)	grad_norm 0.2990 (0.3060)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:40:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:06:13 lr 0.000086	 wd 0.0000	time 0.1462 (0.2333)	loss 0.8477 (0.8822)	grad_norm 0.3054 (0.3060)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:40:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:05:46 lr 0.000086	 wd 0.0000	time 0.2628 (0.2310)	loss 0.7690 (0.8820)	grad_norm 0.3203 (0.3060)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:41:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:32 lr 0.000086	 wd 0.0000	time 0.1543 (0.2369)	loss 0.7856 (0.8815)	grad_norm 0.2982 (0.3060)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:41:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:01 lr 0.000086	 wd 0.0000	time 0.1653 (0.2319)	loss 0.9214 (0.8809)	grad_norm 0.3047 (0.3058)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:41:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:04:33 lr 0.000085	 wd 0.0000	time 0.1505 (0.2279)	loss 0.9229 (0.8805)	grad_norm 0.2862 (0.3058)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:42:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:07 lr 0.000085	 wd 0.0000	time 0.1980 (0.2245)	loss 0.7808 (0.8808)	grad_norm 0.3089 (0.3060)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:42:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:03:50 lr 0.000085	 wd 0.0000	time 0.2075 (0.2298)	loss 0.8501 (0.8805)	grad_norm 0.3157 (0.3060)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:42:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:24 lr 0.000085	 wd 0.0000	time 0.1865 (0.2267)	loss 0.8999 (0.8803)	grad_norm 0.3011 (0.3059)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:43:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:02:59 lr 0.000085	 wd 0.0000	time 0.1454 (0.2239)	loss 1.0117 (0.8801)	grad_norm 0.2965 (0.3060)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:43:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:35 lr 0.000085	 wd 0.0000	time 0.1534 (0.2216)	loss 0.8486 (0.8801)	grad_norm 0.3018 (0.3060)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:43:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:12 lr 0.000085	 wd 0.0000	time 0.1841 (0.2202)	loss 0.9077 (0.8799)	grad_norm 0.3019 (0.3061)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:44:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:01:50 lr 0.000084	 wd 0.0000	time 0.1608 (0.2208)	loss 0.8350 (0.8795)	grad_norm 0.3121 (0.3061)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:44:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:28 lr 0.000084	 wd 0.0000	time 0.1583 (0.2194)	loss 1.0244 (0.8805)	grad_norm 0.3244 (0.3063)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:44:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:05 lr 0.000084	 wd 0.0000	time 0.1887 (0.2180)	loss 0.7056 (0.8798)	grad_norm 0.3289 (0.3063)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:45:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:43 lr 0.000084	 wd 0.0000	time 0.1429 (0.2164)	loss 0.9575 (0.8798)	grad_norm 0.3068 (0.3063)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:45:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:21 lr 0.000084	 wd 0.0000	time 0.2025 (0.2155)	loss 0.9565 (0.8801)	grad_norm 0.3151 (0.3064)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:45:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000084	 wd 0.0000	time 0.1282 (0.2137)	loss 0.8838 (0.8806)	grad_norm 0.3216 (nan)	loss_scale 32768.0000 (32794.2039)	mem 5928MB
[2024-07-30 10:45:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 7 training takes 0:09:04
[2024-07-30 10:46:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 21.723 (21.723)	Loss 0.3564 (0.3564)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 10:46:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.066 Acc@5 97.560
[2024-07-30 10:46:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-30 10:46:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.10%
[2024-07-30 10:46:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][0/2502]	eta 11:03:42 lr 0.000084	 wd 0.0000	time 15.9161 (15.9161)	loss 0.8042 (0.8042)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:47:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:14:53 lr 0.000083	 wd 0.0000	time 0.2950 (0.3720)	loss 0.8706 (0.8846)	grad_norm 0.3004 (0.3078)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:47:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:12:12 lr 0.000083	 wd 0.0000	time 0.1529 (0.3180)	loss 0.8696 (0.8831)	grad_norm 0.3071 (0.3075)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:47:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:09:57 lr 0.000083	 wd 0.0000	time 0.1891 (0.2713)	loss 0.8574 (0.8792)	grad_norm 0.3214 (0.3073)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:48:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:08:42 lr 0.000083	 wd 0.0000	time 0.1801 (0.2485)	loss 0.9702 (0.8804)	grad_norm 0.3083 (0.3070)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:48:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:07:48 lr 0.000083	 wd 0.0000	time 0.1648 (0.2342)	loss 0.8203 (0.8813)	grad_norm 0.3097 (0.3072)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:49:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:06 lr 0.000083	 wd 0.0000	time 0.1806 (0.2555)	loss 0.8569 (0.8810)	grad_norm 0.3185 (0.3069)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:49:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:35 lr 0.000083	 wd 0.0000	time 0.1564 (0.2528)	loss 0.8911 (0.8805)	grad_norm 0.3171 (0.3070)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:49:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:06:55 lr 0.000082	 wd 0.0000	time 0.1697 (0.2438)	loss 0.7598 (0.8801)	grad_norm 0.3009 (0.3069)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:50:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:18 lr 0.000082	 wd 0.0000	time 0.1751 (0.2366)	loss 1.0029 (0.8812)	grad_norm 0.3011 (0.3070)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:50:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:05:55 lr 0.000082	 wd 0.0000	time 0.3385 (0.2364)	loss 1.0273 (0.8819)	grad_norm 0.3072 (0.3071)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:50:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:36 lr 0.000082	 wd 0.0000	time 0.1547 (0.2400)	loss 0.9766 (0.8816)	grad_norm 0.3118 (0.3073)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:51:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:05 lr 0.000082	 wd 0.0000	time 0.1931 (0.2346)	loss 0.8345 (0.8814)	grad_norm 0.3016 (0.3072)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:51:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:36 lr 0.000082	 wd 0.0000	time 0.1474 (0.2301)	loss 0.8271 (0.8816)	grad_norm 0.3120 (0.3075)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:51:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:10 lr 0.000081	 wd 0.0000	time 0.1958 (0.2269)	loss 0.8320 (0.8814)	grad_norm 0.3065 (0.3074)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:52:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:03:48 lr 0.000081	 wd 0.0000	time 1.2835 (0.2284)	loss 0.8647 (0.8813)	grad_norm 0.3196 (0.3076)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:52:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:23 lr 0.000081	 wd 0.0000	time 0.1532 (0.2256)	loss 0.9766 (0.8808)	grad_norm 0.3000 (0.3075)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:52:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:02:58 lr 0.000081	 wd 0.0000	time 0.1413 (0.2231)	loss 0.8555 (0.8816)	grad_norm 0.2986 (0.3077)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:53:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:34 lr 0.000081	 wd 0.0000	time 0.1603 (0.2207)	loss 0.8794 (0.8821)	grad_norm 0.3130 (0.3078)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:53:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:11 lr 0.000081	 wd 0.0000	time 0.2046 (0.2192)	loss 0.7822 (0.8815)	grad_norm 0.2931 (0.3078)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:53:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:50 lr 0.000080	 wd 0.0000	time 0.1714 (0.2206)	loss 0.8203 (0.8816)	grad_norm 0.3294 (0.3078)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:54:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:28 lr 0.000080	 wd 0.0000	time 0.2232 (0.2190)	loss 0.8828 (0.8819)	grad_norm 0.3083 (0.3079)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:54:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:05 lr 0.000080	 wd 0.0000	time 0.1794 (0.2176)	loss 0.8286 (0.8814)	grad_norm 0.3094 (0.3080)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:54:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:43 lr 0.000080	 wd 0.0000	time 0.1674 (0.2160)	loss 0.9785 (0.8812)	grad_norm 0.3065 (0.3081)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:55:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:21 lr 0.000080	 wd 0.0000	time 0.1954 (0.2150)	loss 0.9644 (0.8812)	grad_norm 0.3164 (0.3082)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:55:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000080	 wd 0.0000	time 0.1290 (0.2130)	loss 0.9097 (0.8812)	grad_norm 0.3068 (0.3083)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:55:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 8 training takes 0:09:02
[2024-07-30 10:55:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 21.148 (21.148)	Loss 0.3616 (0.3616)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 5928MB
[2024-07-30 10:56:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.034 Acc@5 97.578
[2024-07-30 10:56:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-30 10:56:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.10%
[2024-07-30 10:56:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][0/2502]	eta 11:34:14 lr 0.000080	 wd 0.0000	time 16.6483 (16.6483)	loss 0.8628 (0.8628)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:56:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:14:47 lr 0.000079	 wd 0.0000	time 0.2934 (0.3695)	loss 0.9688 (0.8762)	grad_norm 0.3182 (0.3084)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:57:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:13:08 lr 0.000079	 wd 0.0000	time 0.1811 (0.3424)	loss 0.7471 (0.8745)	grad_norm 0.3014 (0.3086)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:57:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:32 lr 0.000079	 wd 0.0000	time 0.1560 (0.2872)	loss 0.9395 (0.8763)	grad_norm 0.2990 (0.3090)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:57:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:07 lr 0.000079	 wd 0.0000	time 0.1715 (0.2602)	loss 0.8696 (0.8758)	grad_norm 0.2991 (0.3091)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:58:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:08:06 lr 0.000079	 wd 0.0000	time 0.2016 (0.2431)	loss 0.6768 (0.8805)	grad_norm 0.3162 (0.3092)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:58:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:17 lr 0.000079	 wd 0.0000	time 0.2825 (0.2616)	loss 0.7212 (0.8781)	grad_norm 0.3160 (0.3088)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:59:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:41 lr 0.000078	 wd 0.0000	time 0.1458 (0.2561)	loss 0.9531 (0.8790)	grad_norm 0.3160 (0.3088)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:59:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:06:59 lr 0.000078	 wd 0.0000	time 0.1405 (0.2467)	loss 0.8975 (0.8800)	grad_norm 0.2911 (0.3089)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 10:59:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:22 lr 0.000078	 wd 0.0000	time 0.1599 (0.2390)	loss 1.0342 (0.8806)	grad_norm 0.3129 (0.3089)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:00:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:00 lr 0.000078	 wd 0.0000	time 0.3021 (0.2401)	loss 0.9590 (0.8810)	grad_norm 0.3097 (0.3088)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:00:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:38 lr 0.000078	 wd 0.0000	time 0.1913 (0.2412)	loss 0.8022 (0.8810)	grad_norm 0.3165 (0.3089)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:00:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:06 lr 0.000078	 wd 0.0000	time 0.1959 (0.2357)	loss 0.9614 (0.8807)	grad_norm 0.3197 (0.3090)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:01:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:38 lr 0.000077	 wd 0.0000	time 0.1755 (0.2316)	loss 0.9395 (0.8810)	grad_norm 0.2977 (0.3089)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:01:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:11 lr 0.000077	 wd 0.0000	time 0.2013 (0.2283)	loss 0.8789 (0.8814)	grad_norm 0.2989 (0.3091)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:01:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:03:53 lr 0.000077	 wd 0.0000	time 0.1777 (0.2333)	loss 0.9409 (0.8816)	grad_norm 0.3211 (nan)	loss_scale 32768.0000 (32811.6616)	mem 5928MB
[2024-07-30 11:02:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:27 lr 0.000077	 wd 0.0000	time 0.1700 (0.2299)	loss 0.8838 (0.8811)	grad_norm 0.3023 (nan)	loss_scale 32768.0000 (32808.9344)	mem 5928MB
[2024-07-30 11:02:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:01 lr 0.000077	 wd 0.0000	time 0.2131 (0.2269)	loss 0.8174 (0.8819)	grad_norm 0.2962 (nan)	loss_scale 32768.0000 (32806.5279)	mem 5928MB
[2024-07-30 11:02:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:37 lr 0.000077	 wd 0.0000	time 0.1817 (0.2242)	loss 0.7192 (0.8817)	grad_norm 0.3188 (nan)	loss_scale 32768.0000 (32804.3887)	mem 5928MB
[2024-07-30 11:03:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:14 lr 0.000076	 wd 0.0000	time 0.2036 (0.2228)	loss 0.9199 (0.8819)	grad_norm 0.3054 (nan)	loss_scale 32768.0000 (32802.4745)	mem 5928MB
[2024-07-30 11:03:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:01:51 lr 0.000076	 wd 0.0000	time 0.1791 (0.2228)	loss 0.9160 (0.8827)	grad_norm 0.3038 (nan)	loss_scale 32768.0000 (32800.7516)	mem 5928MB
[2024-07-30 11:03:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:29 lr 0.000076	 wd 0.0000	time 0.1786 (0.2215)	loss 1.0293 (0.8832)	grad_norm 0.2966 (nan)	loss_scale 32768.0000 (32799.1928)	mem 5928MB
[2024-07-30 11:04:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:06 lr 0.000076	 wd 0.0000	time 0.1641 (0.2199)	loss 0.9102 (0.8835)	grad_norm 0.3099 (nan)	loss_scale 32768.0000 (32797.7756)	mem 5928MB
[2024-07-30 11:04:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:44 lr 0.000076	 wd 0.0000	time 0.1728 (0.2182)	loss 0.8682 (0.8831)	grad_norm 0.3304 (nan)	loss_scale 32768.0000 (32796.4815)	mem 5928MB
[2024-07-30 11:04:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:22 lr 0.000075	 wd 0.0000	time 0.2083 (0.2174)	loss 0.8281 (0.8831)	grad_norm 0.3120 (nan)	loss_scale 32768.0000 (32795.2953)	mem 5928MB
[2024-07-30 11:05:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000075	 wd 0.0000	time 0.1270 (0.2151)	loss 0.8608 (0.8831)	grad_norm 0.2946 (nan)	loss_scale 32768.0000 (32794.2039)	mem 5928MB
[2024-07-30 11:05:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 9 training takes 0:09:07
[2024-07-30 11:05:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 20.238 (20.238)	Loss 0.3572 (0.3572)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 11:05:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.066 Acc@5 97.588
[2024-07-30 11:05:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-30 11:05:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.10%
[2024-07-30 11:06:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][0/2502]	eta 14:19:48 lr 0.000075	 wd 0.0000	time 20.6188 (20.6188)	loss 1.0303 (1.0303)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:06:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:18:00 lr 0.000075	 wd 0.0000	time 0.3848 (0.4498)	loss 0.7305 (0.8956)	grad_norm 0.3177 (0.3106)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:07:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:13:52 lr 0.000075	 wd 0.0000	time 0.1651 (0.3614)	loss 0.9614 (0.8873)	grad_norm 0.3199 (0.3106)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:07:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:59 lr 0.000075	 wd 0.0000	time 0.1921 (0.2995)	loss 0.8726 (0.8829)	grad_norm 0.2980 (0.3109)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:07:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:25 lr 0.000075	 wd 0.0000	time 0.1646 (0.2692)	loss 0.9185 (0.8817)	grad_norm 0.3137 (0.3109)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:07:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:08:23 lr 0.000074	 wd 0.0000	time 0.2329 (0.2515)	loss 0.7729 (0.8829)	grad_norm 0.3243 (0.3111)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:08:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:33 lr 0.000074	 wd 0.0000	time 0.2077 (0.2697)	loss 0.9419 (0.8816)	grad_norm 0.3079 (0.3109)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:08:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:43 lr 0.000074	 wd 0.0000	time 0.1445 (0.2572)	loss 0.8047 (0.8802)	grad_norm 0.3031 (0.3110)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:09:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:07:01 lr 0.000074	 wd 0.0000	time 0.1609 (0.2474)	loss 0.8706 (0.8806)	grad_norm 0.3128 (0.3115)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:09:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:23 lr 0.000074	 wd 0.0000	time 0.1808 (0.2394)	loss 0.8394 (0.8811)	grad_norm 0.3139 (0.3114)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:09:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:00 lr 0.000073	 wd 0.0000	time 0.3894 (0.2399)	loss 0.8276 (0.8813)	grad_norm 0.3135 (0.3115)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:10:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:38 lr 0.000073	 wd 0.0000	time 0.1755 (0.2414)	loss 0.7993 (0.8812)	grad_norm 0.3147 (0.3114)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:10:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:07 lr 0.000073	 wd 0.0000	time 0.1516 (0.2360)	loss 1.0088 (0.8811)	grad_norm 0.3061 (0.3116)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:10:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:38 lr 0.000073	 wd 0.0000	time 0.1650 (0.2318)	loss 0.8911 (0.8811)	grad_norm 0.3133 (0.3117)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:11:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:11 lr 0.000073	 wd 0.0000	time 0.1787 (0.2287)	loss 0.7866 (0.8809)	grad_norm 0.3366 (0.3116)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:11:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:03:49 lr 0.000073	 wd 0.0000	time 0.1734 (0.2292)	loss 0.8594 (0.8806)	grad_norm 0.3120 (0.3114)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:11:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:24 lr 0.000072	 wd 0.0000	time 0.1599 (0.2266)	loss 0.7710 (0.8810)	grad_norm 0.3042 (0.3114)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:12:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:02:59 lr 0.000072	 wd 0.0000	time 0.2040 (0.2240)	loss 0.8940 (0.8812)	grad_norm 0.3040 (0.3114)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:12:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:35 lr 0.000072	 wd 0.0000	time 0.1683 (0.2217)	loss 0.9448 (0.8810)	grad_norm 0.3255 (0.3116)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:12:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:12 lr 0.000072	 wd 0.0000	time 0.1857 (0.2199)	loss 0.9536 (0.8809)	grad_norm 0.3154 (0.3116)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:13:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:50 lr 0.000072	 wd 0.0000	time 0.1608 (0.2200)	loss 0.8818 (0.8814)	grad_norm 0.3163 (0.3117)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:13:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:28 lr 0.000071	 wd 0.0000	time 0.1616 (0.2192)	loss 0.8667 (0.8813)	grad_norm 0.3219 (0.3117)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:13:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:05 lr 0.000071	 wd 0.0000	time 0.1632 (0.2175)	loss 0.8784 (0.8818)	grad_norm 0.3054 (0.3117)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:14:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:43 lr 0.000071	 wd 0.0000	time 0.2115 (0.2160)	loss 0.9316 (0.8815)	grad_norm 0.3075 (0.3117)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:14:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:21 lr 0.000071	 wd 0.0000	time 0.2150 (0.2150)	loss 0.8823 (0.8819)	grad_norm 0.3003 (0.3117)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:14:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000071	 wd 0.0000	time 0.1275 (0.2131)	loss 0.9951 (0.8813)	grad_norm 0.3165 (0.3118)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:14:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 10 training takes 0:09:02
[2024-07-30 11:15:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 23.424 (23.424)	Loss 0.3650 (0.3650)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 11:15:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.126 Acc@5 97.560
[2024-07-30 11:15:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-30 11:15:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.13%
[2024-07-30 11:15:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-30 11:15:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-30 11:15:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][0/2502]	eta 10:25:10 lr 0.000071	 wd 0.0000	time 14.9924 (14.9924)	loss 0.7896 (0.7896)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:16:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:13:59 lr 0.000070	 wd 0.0000	time 0.2895 (0.3496)	loss 0.8945 (0.8750)	grad_norm 0.3143 (0.3125)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:16:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:12:16 lr 0.000070	 wd 0.0000	time 0.1639 (0.3201)	loss 0.8960 (0.8776)	grad_norm 0.3153 (0.3121)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:16:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:10:00 lr 0.000070	 wd 0.0000	time 0.1514 (0.2726)	loss 0.9990 (0.8791)	grad_norm 0.3206 (0.3128)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:17:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:08:43 lr 0.000070	 wd 0.0000	time 0.1595 (0.2493)	loss 0.9453 (0.8775)	grad_norm 0.3152 (0.3128)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:17:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:07:49 lr 0.000070	 wd 0.0000	time 0.1834 (0.2346)	loss 0.7939 (0.8769)	grad_norm 0.3059 (nan)	loss_scale 32768.0000 (32898.8104)	mem 5928MB
[2024-07-30 11:17:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:07:19 lr 0.000069	 wd 0.0000	time 0.1725 (0.2309)	loss 1.0586 (0.8752)	grad_norm 0.3100 (nan)	loss_scale 32768.0000 (32877.0449)	mem 5928MB
[2024-07-30 11:18:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:06:51 lr 0.000069	 wd 0.0000	time 0.2140 (0.2283)	loss 0.8687 (0.8778)	grad_norm 0.3161 (nan)	loss_scale 32768.0000 (32861.4893)	mem 5928MB
[2024-07-30 11:18:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:06:19 lr 0.000069	 wd 0.0000	time 0.1829 (0.2227)	loss 0.9087 (0.8788)	grad_norm 0.3171 (nan)	loss_scale 32768.0000 (32849.8177)	mem 5928MB
[2024-07-30 11:18:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:05:49 lr 0.000069	 wd 0.0000	time 0.1619 (0.2182)	loss 0.9863 (0.8790)	grad_norm 0.3284 (nan)	loss_scale 32768.0000 (32840.7370)	mem 5928MB
[2024-07-30 11:19:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:05:22 lr 0.000069	 wd 0.0000	time 0.1712 (0.2145)	loss 0.8301 (0.8803)	grad_norm 0.3177 (nan)	loss_scale 32768.0000 (32833.4705)	mem 5928MB
[2024-07-30 11:19:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:02 lr 0.000069	 wd 0.0000	time 0.1990 (0.2160)	loss 0.8101 (0.8806)	grad_norm 0.3072 (nan)	loss_scale 32768.0000 (32827.5241)	mem 5928MB
[2024-07-30 11:19:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:04:41 lr 0.000068	 wd 0.0000	time 0.1403 (0.2160)	loss 0.9556 (0.8809)	grad_norm 0.3180 (nan)	loss_scale 32768.0000 (32822.5679)	mem 5928MB
[2024-07-30 11:20:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:04:16 lr 0.000068	 wd 0.0000	time 0.1491 (0.2136)	loss 0.7578 (0.8812)	grad_norm 0.3036 (nan)	loss_scale 32768.0000 (32818.3736)	mem 5928MB
[2024-07-30 11:20:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:03:52 lr 0.000068	 wd 0.0000	time 0.1590 (0.2113)	loss 0.8491 (0.8818)	grad_norm 0.3282 (nan)	loss_scale 32768.0000 (32814.7780)	mem 5928MB
[2024-07-30 11:20:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:03:29 lr 0.000068	 wd 0.0000	time 0.2003 (0.2091)	loss 0.9463 (0.8815)	grad_norm 0.3178 (nan)	loss_scale 32768.0000 (32811.6616)	mem 5928MB
[2024-07-30 11:21:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:08 lr 0.000068	 wd 0.0000	time 0.1564 (0.2086)	loss 0.9287 (0.8816)	grad_norm 0.3418 (nan)	loss_scale 32768.0000 (32808.9344)	mem 5928MB
[2024-07-30 11:21:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:02:47 lr 0.000067	 wd 0.0000	time 0.1811 (0.2093)	loss 0.8013 (0.8819)	grad_norm 0.3202 (nan)	loss_scale 32768.0000 (32806.5279)	mem 5928MB
[2024-07-30 11:21:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:26 lr 0.000067	 wd 0.0000	time 0.1922 (0.2080)	loss 1.1104 (0.8827)	grad_norm 0.3105 (nan)	loss_scale 32768.0000 (32804.3887)	mem 5928MB
[2024-07-30 11:21:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:04 lr 0.000067	 wd 0.0000	time 0.1995 (0.2067)	loss 0.7783 (0.8831)	grad_norm 0.3026 (nan)	loss_scale 32768.0000 (32802.4745)	mem 5928MB
[2024-07-30 11:22:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:01:43 lr 0.000067	 wd 0.0000	time 0.1426 (0.2056)	loss 0.9209 (0.8827)	grad_norm 0.3108 (nan)	loss_scale 32768.0000 (32800.7516)	mem 5928MB
[2024-07-30 11:22:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:22 lr 0.000067	 wd 0.0000	time 0.2143 (0.2055)	loss 0.8755 (0.8825)	grad_norm 0.3293 (nan)	loss_scale 32768.0000 (32799.1928)	mem 5928MB
[2024-07-30 11:23:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:02 lr 0.000066	 wd 0.0000	time 0.1666 (0.2060)	loss 0.9077 (0.8824)	grad_norm 0.3194 (nan)	loss_scale 32768.0000 (32797.7756)	mem 5928MB
[2024-07-30 11:23:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:41 lr 0.000066	 wd 0.0000	time 0.1512 (0.2051)	loss 0.8530 (0.8824)	grad_norm 0.3093 (nan)	loss_scale 32768.0000 (32796.4815)	mem 5928MB
[2024-07-30 11:23:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:20 lr 0.000066	 wd 0.0000	time 0.1560 (0.2043)	loss 0.8823 (0.8828)	grad_norm 0.3143 (nan)	loss_scale 32768.0000 (32795.2953)	mem 5928MB
[2024-07-30 11:23:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000066	 wd 0.0000	time 0.1335 (0.2023)	loss 1.0518 (0.8820)	grad_norm 0.3179 (nan)	loss_scale 32768.0000 (32794.2039)	mem 5928MB
[2024-07-30 11:23:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 11 training takes 0:08:30
[2024-07-30 11:24:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 40.037 (40.037)	Loss 0.3606 (0.3606)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 11:24:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.146 Acc@5 97.582
[2024-07-30 11:24:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-30 11:24:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.15%
[2024-07-30 11:24:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-30 11:24:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-30 11:25:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][0/2502]	eta 9:54:57 lr 0.000066	 wd 0.0000	time 14.2675 (14.2675)	loss 0.9102 (0.9102)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:25:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:13:25 lr 0.000066	 wd 0.0000	time 0.1638 (0.3354)	loss 0.8208 (0.8697)	grad_norm 0.3266 (0.3161)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:25:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:11:06 lr 0.000065	 wd 0.0000	time 0.4998 (0.2894)	loss 0.8555 (0.8762)	grad_norm 0.3155 (0.3148)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:26:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:48 lr 0.000065	 wd 0.0000	time 0.1714 (0.2946)	loss 0.9150 (0.8856)	grad_norm 0.3323 (0.3147)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:26:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:17 lr 0.000065	 wd 0.0000	time 0.1840 (0.2653)	loss 0.8462 (0.8872)	grad_norm 0.3071 (0.3148)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:26:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:08:15 lr 0.000065	 wd 0.0000	time 0.1692 (0.2476)	loss 0.7632 (0.8860)	grad_norm 0.3097 (0.3145)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:27:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:07:29 lr 0.000065	 wd 0.0000	time 0.1710 (0.2365)	loss 0.7812 (0.8860)	grad_norm 0.3167 (0.3148)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:27:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:37 lr 0.000064	 wd 0.0000	time 0.1933 (0.2538)	loss 0.8213 (0.8856)	grad_norm 0.3087 (0.3145)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:28:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:06:57 lr 0.000064	 wd 0.0000	time 0.1673 (0.2455)	loss 0.9082 (0.8844)	grad_norm 0.3096 (0.3144)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:28:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:21 lr 0.000064	 wd 0.0000	time 0.1762 (0.2383)	loss 0.8081 (0.8838)	grad_norm 0.3190 (0.3146)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:28:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:05:48 lr 0.000064	 wd 0.0000	time 0.1707 (0.2321)	loss 0.9146 (0.8840)	grad_norm 0.3094 (0.3148)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:29:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:28 lr 0.000064	 wd 0.0000	time 0.4131 (0.2344)	loss 0.7539 (0.8839)	grad_norm 0.2993 (0.3147)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:29:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:05 lr 0.000063	 wd 0.0000	time 0.1600 (0.2344)	loss 0.8965 (0.8832)	grad_norm 0.3226 (0.3148)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:29:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:36 lr 0.000063	 wd 0.0000	time 0.1521 (0.2299)	loss 0.7959 (0.8834)	grad_norm 0.3217 (0.3146)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:30:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:09 lr 0.000063	 wd 0.0000	time 0.2104 (0.2264)	loss 0.9438 (0.8836)	grad_norm 0.3126 (0.3146)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:30:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:03:44 lr 0.000063	 wd 0.0000	time 0.2087 (0.2236)	loss 0.8599 (0.8844)	grad_norm 0.3102 (0.3146)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:30:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:20 lr 0.000063	 wd 0.0000	time 0.1744 (0.2223)	loss 0.8691 (0.8837)	grad_norm 0.3101 (0.3146)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:31:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:02:58 lr 0.000062	 wd 0.0000	time 0.2211 (0.2220)	loss 0.8564 (0.8836)	grad_norm 0.3110 (0.3148)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:31:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:34 lr 0.000062	 wd 0.0000	time 0.1757 (0.2197)	loss 0.7944 (0.8838)	grad_norm 0.3074 (0.3150)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:31:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:11 lr 0.000062	 wd 0.0000	time 0.1719 (0.2179)	loss 0.8452 (0.8835)	grad_norm 0.3137 (0.3151)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:32:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:01:48 lr 0.000062	 wd 0.0000	time 0.1888 (0.2165)	loss 0.8345 (0.8837)	grad_norm 0.3153 (nan)	loss_scale 32768.0000 (32800.7516)	mem 5928MB
[2024-07-30 11:32:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:27 lr 0.000062	 wd 0.0000	time 0.1350 (0.2170)	loss 0.8589 (0.8841)	grad_norm 0.3114 (nan)	loss_scale 32768.0000 (32799.1928)	mem 5928MB
[2024-07-30 11:32:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:05 lr 0.000061	 wd 0.0000	time 0.1874 (0.2161)	loss 0.9077 (0.8842)	grad_norm 0.3261 (nan)	loss_scale 32768.0000 (32797.7756)	mem 5928MB
[2024-07-30 11:33:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:43 lr 0.000061	 wd 0.0000	time 0.2015 (0.2147)	loss 0.8770 (0.8839)	grad_norm 0.2965 (nan)	loss_scale 32768.0000 (32796.4815)	mem 5928MB
[2024-07-30 11:33:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:21 lr 0.000061	 wd 0.0000	time 0.1859 (0.2133)	loss 0.8706 (0.8831)	grad_norm 0.3154 (nan)	loss_scale 32768.0000 (32795.2953)	mem 5928MB
[2024-07-30 11:33:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000061	 wd 0.0000	time 0.1365 (0.2110)	loss 0.8862 (0.8829)	grad_norm 0.3144 (nan)	loss_scale 32768.0000 (32794.2039)	mem 5928MB
[2024-07-30 11:33:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 12 training takes 0:08:52
[2024-07-30 11:34:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 35.583 (35.583)	Loss 0.3594 (0.3594)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 11:34:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.226 Acc@5 97.598
[2024-07-30 11:34:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-30 11:34:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.23%
[2024-07-30 11:34:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-30 11:34:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-30 11:34:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][0/2502]	eta 10:30:43 lr 0.000061	 wd 0.0000	time 15.1254 (15.1254)	loss 0.8472 (0.8472)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:35:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:13:23 lr 0.000061	 wd 0.0000	time 0.1505 (0.3345)	loss 0.7983 (0.8731)	grad_norm 0.3109 (0.3138)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:35:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:11:14 lr 0.000060	 wd 0.0000	time 0.3482 (0.2932)	loss 0.8057 (0.8820)	grad_norm 0.3246 (0.3143)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:35:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:10:25 lr 0.000060	 wd 0.0000	time 0.1407 (0.2840)	loss 0.7876 (0.8762)	grad_norm 0.3193 (0.3147)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:36:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:08:59 lr 0.000060	 wd 0.0000	time 0.1711 (0.2566)	loss 0.7632 (0.8772)	grad_norm 0.3173 (0.3150)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:36:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:08:02 lr 0.000060	 wd 0.0000	time 0.1584 (0.2410)	loss 0.8525 (0.8771)	grad_norm 0.3173 (0.3154)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:36:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:07:18 lr 0.000060	 wd 0.0000	time 0.1987 (0.2304)	loss 0.8022 (0.8782)	grad_norm 0.3186 (0.3161)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:37:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:07:18 lr 0.000059	 wd 0.0000	time 0.1886 (0.2434)	loss 1.0010 (0.8786)	grad_norm 0.3396 (0.3161)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:37:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:06:41 lr 0.000059	 wd 0.0000	time 0.1619 (0.2358)	loss 0.9160 (0.8787)	grad_norm 0.3153 (0.3162)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:38:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:06:07 lr 0.000059	 wd 0.0000	time 0.1584 (0.2294)	loss 0.9155 (0.8795)	grad_norm 0.3136 (0.3165)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:38:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:05:36 lr 0.000059	 wd 0.0000	time 0.1899 (0.2240)	loss 0.9756 (0.8806)	grad_norm 0.3268 (0.3166)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:38:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:11 lr 0.000059	 wd 0.0000	time 0.1828 (0.2221)	loss 0.8496 (0.8800)	grad_norm 0.3208 (0.3165)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:39:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:04:56 lr 0.000058	 wd 0.0000	time 0.1660 (0.2276)	loss 0.9746 (0.8804)	grad_norm 0.3206 (0.3164)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:39:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:04:28 lr 0.000058	 wd 0.0000	time 0.2035 (0.2237)	loss 0.8916 (0.8809)	grad_norm 0.3252 (0.3166)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:39:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:02 lr 0.000058	 wd 0.0000	time 0.1686 (0.2205)	loss 1.0596 (0.8807)	grad_norm 0.3077 (0.3167)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:40:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:03:38 lr 0.000058	 wd 0.0000	time 0.1700 (0.2176)	loss 0.8965 (0.8808)	grad_norm 0.3274 (0.3168)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:40:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:15 lr 0.000058	 wd 0.0000	time 0.2009 (0.2172)	loss 0.8296 (0.8812)	grad_norm 0.3020 (0.3168)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:40:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:02:54 lr 0.000057	 wd 0.0000	time 0.1449 (0.2177)	loss 0.8311 (0.8812)	grad_norm 0.3155 (0.3168)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:41:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:31 lr 0.000057	 wd 0.0000	time 0.1880 (0.2159)	loss 0.8350 (0.8813)	grad_norm 0.3290 (0.3170)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:41:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:09 lr 0.000057	 wd 0.0000	time 0.1936 (0.2144)	loss 0.7983 (0.8801)	grad_norm 0.3294 (0.3170)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:41:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:46 lr 0.000057	 wd 0.0000	time 0.1648 (0.2128)	loss 0.8721 (0.8808)	grad_norm 0.3127 (0.3171)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:41:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:25 lr 0.000057	 wd 0.0000	time 0.1972 (0.2123)	loss 0.8887 (0.8814)	grad_norm 0.2902 (0.3170)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:42:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:04 lr 0.000056	 wd 0.0000	time 0.1787 (0.2124)	loss 0.9580 (0.8815)	grad_norm 0.3283 (0.3171)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:42:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:42 lr 0.000056	 wd 0.0000	time 0.1783 (0.2112)	loss 0.8052 (0.8810)	grad_norm 0.3132 (0.3171)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:42:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:21 lr 0.000056	 wd 0.0000	time 0.2180 (0.2101)	loss 0.8945 (0.8814)	grad_norm 0.3017 (0.3172)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:43:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000056	 wd 0.0000	time 0.1340 (0.2079)	loss 0.8257 (0.8815)	grad_norm 0.3146 (0.3172)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:43:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 13 training takes 0:08:44
[2024-07-30 11:43:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 39.262 (39.262)	Loss 0.3594 (0.3594)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 5928MB
[2024-07-30 11:44:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.146 Acc@5 97.600
[2024-07-30 11:44:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-30 11:44:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.23%
[2024-07-30 11:44:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][0/2502]	eta 11:10:14 lr 0.000056	 wd 0.0000	time 16.0729 (16.0729)	loss 0.9902 (0.9902)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:44:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:13:44 lr 0.000055	 wd 0.0000	time 0.1498 (0.3432)	loss 0.8486 (0.8767)	grad_norm 0.3133 (0.3185)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:45:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:11:08 lr 0.000055	 wd 0.0000	time 0.4500 (0.2905)	loss 0.8457 (0.8781)	grad_norm 0.3074 (0.3181)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:45:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:10:32 lr 0.000055	 wd 0.0000	time 0.1527 (0.2874)	loss 1.1240 (0.8816)	grad_norm 0.3113 (0.3176)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:45:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:09:05 lr 0.000055	 wd 0.0000	time 0.1886 (0.2596)	loss 1.0820 (0.8805)	grad_norm 0.3174 (0.3181)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:46:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:08:06 lr 0.000055	 wd 0.0000	time 0.1831 (0.2431)	loss 0.9150 (0.8804)	grad_norm 0.3022 (0.3179)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:46:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:07:21 lr 0.000054	 wd 0.0000	time 0.2368 (0.2323)	loss 0.8555 (0.8810)	grad_norm 0.3373 (0.3182)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:47:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:25 lr 0.000054	 wd 0.0000	time 0.1804 (0.2470)	loss 0.8018 (0.8801)	grad_norm 0.3172 (0.3186)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:47:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:06:47 lr 0.000054	 wd 0.0000	time 0.1746 (0.2397)	loss 0.8018 (0.8803)	grad_norm 0.3122 (0.3185)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:47:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:13 lr 0.000054	 wd 0.0000	time 0.1624 (0.2331)	loss 0.8652 (0.8800)	grad_norm 0.3354 (0.3186)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:47:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:05:41 lr 0.000054	 wd 0.0000	time 0.1664 (0.2272)	loss 0.9155 (0.8792)	grad_norm 0.3415 (nan)	loss_scale 32768.0000 (32833.4705)	mem 5928MB
[2024-07-30 11:48:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:18 lr 0.000053	 wd 0.0000	time 0.2691 (0.2271)	loss 0.8428 (0.8789)	grad_norm 0.2997 (nan)	loss_scale 32768.0000 (32827.5241)	mem 5928MB
[2024-07-30 11:48:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:00 lr 0.000053	 wd 0.0000	time 0.1554 (0.2311)	loss 0.8789 (0.8788)	grad_norm 0.3262 (nan)	loss_scale 32768.0000 (32822.5679)	mem 5928MB
[2024-07-30 11:49:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:04:32 lr 0.000053	 wd 0.0000	time 0.1721 (0.2270)	loss 1.0674 (0.8785)	grad_norm 0.3203 (nan)	loss_scale 32768.0000 (32818.3736)	mem 5928MB
[2024-07-30 11:49:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:06 lr 0.000053	 wd 0.0000	time 0.1957 (0.2237)	loss 0.9053 (0.8787)	grad_norm 0.3053 (nan)	loss_scale 32768.0000 (32814.7780)	mem 5928MB
[2024-07-30 11:49:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:03:41 lr 0.000053	 wd 0.0000	time 0.1711 (0.2208)	loss 0.8599 (0.8791)	grad_norm 0.3250 (nan)	loss_scale 32768.0000 (32811.6616)	mem 5928MB
[2024-07-30 11:50:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:18 lr 0.000052	 wd 0.0000	time 0.2127 (0.2200)	loss 0.8760 (0.8787)	grad_norm 0.3235 (nan)	loss_scale 32768.0000 (32808.9344)	mem 5928MB
[2024-07-30 11:50:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:02:56 lr 0.000052	 wd 0.0000	time 0.2931 (0.2197)	loss 1.0547 (0.8793)	grad_norm 0.3346 (nan)	loss_scale 32768.0000 (32806.5279)	mem 5928MB
[2024-07-30 11:50:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:32 lr 0.000052	 wd 0.0000	time 0.1699 (0.2176)	loss 0.6958 (0.8794)	grad_norm 0.3143 (nan)	loss_scale 32768.0000 (32804.3887)	mem 5928MB
[2024-07-30 11:51:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:09 lr 0.000052	 wd 0.0000	time 0.1778 (0.2158)	loss 0.8271 (0.8792)	grad_norm 0.3217 (nan)	loss_scale 32768.0000 (32802.4745)	mem 5928MB
[2024-07-30 11:51:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:01:47 lr 0.000052	 wd 0.0000	time 0.1984 (0.2143)	loss 0.8018 (0.8790)	grad_norm 0.3285 (nan)	loss_scale 32768.0000 (32800.7516)	mem 5928MB
[2024-07-30 11:51:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:25 lr 0.000051	 wd 0.0000	time 0.1820 (0.2137)	loss 0.9458 (0.8791)	grad_norm 0.3170 (nan)	loss_scale 32768.0000 (32799.1928)	mem 5928MB
[2024-07-30 11:52:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:04 lr 0.000051	 wd 0.0000	time 0.1448 (0.2141)	loss 0.8711 (0.8797)	grad_norm 0.3080 (nan)	loss_scale 32768.0000 (32797.7756)	mem 5928MB
[2024-07-30 11:52:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:42 lr 0.000051	 wd 0.0000	time 0.1811 (0.2127)	loss 0.8433 (0.8795)	grad_norm 0.3311 (nan)	loss_scale 32768.0000 (32796.4815)	mem 5928MB
[2024-07-30 11:52:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:21 lr 0.000051	 wd 0.0000	time 0.1587 (0.2115)	loss 0.9683 (0.8800)	grad_norm 0.3237 (nan)	loss_scale 32768.0000 (32795.2953)	mem 5928MB
[2024-07-30 11:52:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000051	 wd 0.0000	time 0.1273 (0.2093)	loss 0.9062 (0.8803)	grad_norm 0.3290 (nan)	loss_scale 32768.0000 (32794.2039)	mem 5928MB
[2024-07-30 11:53:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 14 training takes 0:08:50
[2024-07-30 11:53:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 36.855 (36.855)	Loss 0.3538 (0.3538)	Acc@1 92.578 (92.578)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 11:53:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.204 Acc@5 97.574
[2024-07-30 11:53:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-30 11:53:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.23%
[2024-07-30 11:54:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][0/2502]	eta 10:28:48 lr 0.000051	 wd 0.0000	time 15.0793 (15.0793)	loss 0.7979 (0.7979)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:54:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:13:35 lr 0.000050	 wd 0.0000	time 0.1827 (0.3395)	loss 0.9824 (0.8873)	grad_norm 0.3174 (0.3195)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:55:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:12:14 lr 0.000050	 wd 0.0000	time 0.1831 (0.3191)	loss 1.0098 (0.8831)	grad_norm 0.3203 (0.3204)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:55:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:10:09 lr 0.000050	 wd 0.0000	time 0.1631 (0.2767)	loss 0.9302 (0.8811)	grad_norm 0.3164 (0.3203)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:55:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:08:49 lr 0.000050	 wd 0.0000	time 0.1742 (0.2517)	loss 1.0176 (0.8821)	grad_norm 0.3274 (0.3205)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:55:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:07:53 lr 0.000049	 wd 0.0000	time 0.1870 (0.2368)	loss 0.7925 (0.8839)	grad_norm 0.3211 (0.3210)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:56:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:07:15 lr 0.000049	 wd 0.0000	time 0.1787 (0.2288)	loss 0.8423 (0.8835)	grad_norm 0.3198 (0.3208)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:56:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:18 lr 0.000049	 wd 0.0000	time 0.1835 (0.2432)	loss 0.8262 (0.8808)	grad_norm 0.3283 (0.3210)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:57:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:06:39 lr 0.000049	 wd 0.0000	time 0.1739 (0.2350)	loss 1.0176 (0.8811)	grad_norm 0.3291 (0.3210)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:57:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:06 lr 0.000049	 wd 0.0000	time 0.1719 (0.2289)	loss 0.8062 (0.8813)	grad_norm 0.3336 (0.3213)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:57:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:05:35 lr 0.000048	 wd 0.0000	time 0.1481 (0.2236)	loss 0.9399 (0.8809)	grad_norm 0.3173 (0.3214)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:58:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:15 lr 0.000048	 wd 0.0000	time 0.3650 (0.2247)	loss 0.9209 (0.8788)	grad_norm 0.3382 (0.3211)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:58:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:04:57 lr 0.000048	 wd 0.0000	time 0.1637 (0.2284)	loss 0.8076 (0.8797)	grad_norm 0.3107 (0.3209)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:58:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:04:29 lr 0.000048	 wd 0.0000	time 0.1464 (0.2243)	loss 0.9131 (0.8793)	grad_norm 0.3134 (0.3211)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:59:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:03 lr 0.000048	 wd 0.0000	time 0.1636 (0.2210)	loss 0.8047 (0.8798)	grad_norm 0.3251 (0.3211)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:59:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:03:38 lr 0.000047	 wd 0.0000	time 0.1704 (0.2185)	loss 0.9297 (0.8793)	grad_norm 0.3140 (0.3213)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 11:59:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:16 lr 0.000047	 wd 0.0000	time 0.1579 (0.2178)	loss 0.9414 (0.8794)	grad_norm 0.3149 (0.3215)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:00:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:02:54 lr 0.000047	 wd 0.0000	time 0.1635 (0.2176)	loss 0.7949 (0.8796)	grad_norm 0.3149 (0.3215)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:00:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:31 lr 0.000047	 wd 0.0000	time 0.1759 (0.2156)	loss 1.0234 (0.8802)	grad_norm 0.3469 (0.3214)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:00:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:08 lr 0.000047	 wd 0.0000	time 0.2212 (0.2139)	loss 0.9697 (0.8797)	grad_norm 0.3347 (0.3215)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:01:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:01:46 lr 0.000046	 wd 0.0000	time 0.1583 (0.2127)	loss 1.0254 (0.8805)	grad_norm 0.3465 (0.3214)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:01:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:26 lr 0.000046	 wd 0.0000	time 0.1525 (0.2140)	loss 0.8442 (0.8804)	grad_norm 0.3158 (0.3214)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:01:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:04 lr 0.000046	 wd 0.0000	time 0.1715 (0.2130)	loss 0.9009 (0.8806)	grad_norm 0.3160 (0.3213)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:02:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:42 lr 0.000046	 wd 0.0000	time 0.1492 (0.2116)	loss 0.8892 (0.8807)	grad_norm 0.3413 (0.3214)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:02:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:21 lr 0.000046	 wd 0.0000	time 0.1898 (0.2105)	loss 0.9351 (0.8806)	grad_norm 0.3147 (0.3215)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:02:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000045	 wd 0.0000	time 0.1354 (0.2083)	loss 1.0840 (0.8809)	grad_norm 0.3246 (nan)	loss_scale 32768.0000 (32794.2039)	mem 5928MB
[2024-07-30 12:02:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 15 training takes 0:08:49
[2024-07-30 12:02:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_15.pth saving......
[2024-07-30 12:02:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_15.pth saved !!!
[2024-07-30 12:03:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 34.506 (34.506)	Loss 0.3601 (0.3601)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 12:03:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.214 Acc@5 97.610
[2024-07-30 12:03:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-30 12:03:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.23%
[2024-07-30 12:03:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][0/2502]	eta 11:06:54 lr 0.000045	 wd 0.0000	time 15.9931 (15.9931)	loss 0.7476 (0.7476)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:04:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:13:47 lr 0.000045	 wd 0.0000	time 0.2098 (0.3445)	loss 0.9888 (0.8930)	grad_norm 0.3224 (0.3231)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:04:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:12:43 lr 0.000045	 wd 0.0000	time 0.2264 (0.3316)	loss 0.8779 (0.8812)	grad_norm 0.3300 (0.3224)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:05:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:10:21 lr 0.000045	 wd 0.0000	time 0.1443 (0.2821)	loss 0.9185 (0.8823)	grad_norm 0.3212 (0.3215)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:05:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:08:56 lr 0.000045	 wd 0.0000	time 0.1709 (0.2553)	loss 0.9038 (0.8818)	grad_norm 0.3175 (0.3218)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:05:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:08:00 lr 0.000044	 wd 0.0000	time 0.1849 (0.2403)	loss 0.9688 (0.8813)	grad_norm 0.3184 (0.3218)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:06:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:07:32 lr 0.000044	 wd 0.0000	time 0.4077 (0.2381)	loss 0.9341 (0.8815)	grad_norm 0.3184 (0.3220)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:06:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:31 lr 0.000044	 wd 0.0000	time 0.1773 (0.2503)	loss 0.8892 (0.8818)	grad_norm 0.3222 (0.3218)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:06:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:06:50 lr 0.000044	 wd 0.0000	time 0.1784 (0.2414)	loss 0.8755 (0.8811)	grad_norm 0.3183 (0.3219)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:07:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:15 lr 0.000043	 wd 0.0000	time 0.1866 (0.2344)	loss 0.8081 (0.8824)	grad_norm 0.3256 (0.3222)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:07:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:05:44 lr 0.000043	 wd 0.0000	time 0.1904 (0.2291)	loss 0.8506 (0.8825)	grad_norm 0.3292 (0.3224)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:08:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:30 lr 0.000043	 wd 0.0000	time 0.1465 (0.2358)	loss 0.9678 (0.8827)	grad_norm 0.3364 (0.3226)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:08:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:00 lr 0.000043	 wd 0.0000	time 0.1588 (0.2311)	loss 0.8975 (0.8823)	grad_norm 0.3269 (0.3225)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:08:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:04:33 lr 0.000043	 wd 0.0000	time 0.1840 (0.2274)	loss 0.9702 (0.8818)	grad_norm 0.3245 (0.3225)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:08:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:06 lr 0.000042	 wd 0.0000	time 0.1480 (0.2239)	loss 0.7969 (0.8812)	grad_norm 0.3037 (0.3226)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:09:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:03:42 lr 0.000042	 wd 0.0000	time 0.1997 (0.2224)	loss 0.8203 (0.8807)	grad_norm 0.3030 (0.3227)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:09:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:20 lr 0.000042	 wd 0.0000	time 0.2678 (0.2226)	loss 0.8086 (0.8806)	grad_norm 0.3215 (0.3226)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:09:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:02:56 lr 0.000042	 wd 0.0000	time 0.1713 (0.2205)	loss 0.8721 (0.8804)	grad_norm 0.3266 (0.3228)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:10:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:33 lr 0.000042	 wd 0.0000	time 0.1869 (0.2184)	loss 1.0312 (0.8806)	grad_norm 0.3087 (0.3229)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:10:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:10 lr 0.000041	 wd 0.0000	time 0.1684 (0.2165)	loss 0.9966 (0.8796)	grad_norm 0.3111 (0.3228)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:10:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:01:48 lr 0.000041	 wd 0.0000	time 0.2040 (0.2159)	loss 0.8516 (0.8794)	grad_norm 0.3193 (0.3228)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:11:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:27 lr 0.000041	 wd 0.0000	time 0.1648 (0.2166)	loss 0.6958 (0.8791)	grad_norm 0.3242 (0.3229)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:11:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:04 lr 0.000041	 wd 0.0000	time 0.1655 (0.2151)	loss 0.7876 (0.8790)	grad_norm 0.3270 (0.3230)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:11:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:43 lr 0.000041	 wd 0.0000	time 0.1403 (0.2138)	loss 0.6860 (0.8785)	grad_norm 0.3328 (0.3229)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:12:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:21 lr 0.000040	 wd 0.0000	time 0.1600 (0.2124)	loss 0.7793 (0.8784)	grad_norm 0.3261 (0.3229)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:12:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1601 (0.2106)	loss 0.8540 (0.8781)	grad_norm 0.3438 (0.3229)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:12:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 16 training takes 0:08:53
[2024-07-30 12:13:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 34.034 (34.034)	Loss 0.3579 (0.3579)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 12:13:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.182 Acc@5 97.604
[2024-07-30 12:13:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-30 12:13:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.23%
[2024-07-30 12:13:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][0/2502]	eta 10:25:25 lr 0.000040	 wd 0.0000	time 14.9982 (14.9982)	loss 0.7642 (0.7642)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:14:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:15:52 lr 0.000040	 wd 0.0000	time 0.5157 (0.3967)	loss 0.9702 (0.8795)	grad_norm 0.3121 (0.3221)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:14:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:13:31 lr 0.000040	 wd 0.0000	time 0.1807 (0.3524)	loss 0.8540 (0.8827)	grad_norm 0.3088 (0.3229)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:14:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:46 lr 0.000040	 wd 0.0000	time 0.1655 (0.2936)	loss 0.8833 (0.8791)	grad_norm 0.3440 (0.3236)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:15:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:09:15 lr 0.000039	 wd 0.0000	time 0.1572 (0.2643)	loss 0.9355 (0.8775)	grad_norm 0.3119 (0.3239)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:15:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:08:15 lr 0.000039	 wd 0.0000	time 0.1941 (0.2474)	loss 0.7588 (0.8756)	grad_norm 0.3542 (0.3241)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:16:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:38 lr 0.000039	 wd 0.0000	time 0.1526 (0.2727)	loss 0.8081 (0.8771)	grad_norm 0.3426 (0.3245)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:16:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:47 lr 0.000039	 wd 0.0000	time 0.1530 (0.2593)	loss 0.8984 (0.8763)	grad_norm 0.3304 (0.3245)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:16:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:07:04 lr 0.000039	 wd 0.0000	time 0.1736 (0.2494)	loss 0.7959 (0.8766)	grad_norm 0.3096 (0.3246)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:17:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:26 lr 0.000038	 wd 0.0000	time 0.1686 (0.2413)	loss 0.9736 (0.8771)	grad_norm 0.3193 (0.3243)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:17:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:14 lr 0.000038	 wd 0.0000	time 0.1813 (0.2490)	loss 0.9224 (0.8772)	grad_norm 0.3272 (0.3245)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:17:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:41 lr 0.000038	 wd 0.0000	time 0.1578 (0.2433)	loss 0.7451 (0.8785)	grad_norm 0.3259 (0.3246)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:18:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:09 lr 0.000038	 wd 0.0000	time 0.1537 (0.2376)	loss 0.7783 (0.8800)	grad_norm 0.3339 (0.3248)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:18:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:04:40 lr 0.000038	 wd 0.0000	time 0.1483 (0.2332)	loss 0.9199 (0.8792)	grad_norm 0.3094 (0.3248)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:18:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:14 lr 0.000037	 wd 0.0000	time 0.1748 (0.2307)	loss 0.9155 (0.8801)	grad_norm 0.3082 (0.3248)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:19:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:03:50 lr 0.000037	 wd 0.0000	time 0.1520 (0.2303)	loss 0.8701 (0.8798)	grad_norm 0.3168 (nan)	loss_scale 32768.0000 (32811.6616)	mem 5928MB
[2024-07-30 12:19:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:25 lr 0.000037	 wd 0.0000	time 0.1819 (0.2277)	loss 1.0566 (0.8797)	grad_norm 0.3397 (nan)	loss_scale 32768.0000 (32808.9344)	mem 5928MB
[2024-07-30 12:19:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:00 lr 0.000037	 wd 0.0000	time 0.1664 (0.2250)	loss 1.0195 (0.8798)	grad_norm 0.3275 (nan)	loss_scale 32768.0000 (32806.5279)	mem 5928MB
[2024-07-30 12:20:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:36 lr 0.000037	 wd 0.0000	time 0.1735 (0.2227)	loss 0.7886 (0.8811)	grad_norm 0.3262 (nan)	loss_scale 32768.0000 (32804.3887)	mem 5928MB
[2024-07-30 12:20:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:13 lr 0.000036	 wd 0.0000	time 0.1657 (0.2213)	loss 0.7617 (0.8816)	grad_norm 0.3213 (nan)	loss_scale 32768.0000 (32802.4745)	mem 5928MB
[2024-07-30 12:20:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:01:51 lr 0.000036	 wd 0.0000	time 0.1397 (0.2216)	loss 0.8003 (0.8811)	grad_norm 0.3171 (nan)	loss_scale 32768.0000 (32800.7516)	mem 5928MB
[2024-07-30 12:21:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:28 lr 0.000036	 wd 0.0000	time 0.1590 (0.2204)	loss 0.8037 (0.8806)	grad_norm 0.3239 (nan)	loss_scale 32768.0000 (32799.1928)	mem 5928MB
[2024-07-30 12:21:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:06 lr 0.000036	 wd 0.0000	time 0.1493 (0.2188)	loss 0.9385 (0.8804)	grad_norm 0.3283 (nan)	loss_scale 32768.0000 (32797.7756)	mem 5928MB
[2024-07-30 12:21:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:43 lr 0.000036	 wd 0.0000	time 0.1885 (0.2171)	loss 0.9287 (0.8800)	grad_norm 0.3229 (nan)	loss_scale 32768.0000 (32796.4815)	mem 5928MB
[2024-07-30 12:22:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:22 lr 0.000035	 wd 0.0000	time 0.1853 (0.2162)	loss 0.8359 (0.8803)	grad_norm 0.3264 (nan)	loss_scale 32768.0000 (32795.2953)	mem 5928MB
[2024-07-30 12:22:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1279 (0.2145)	loss 0.9326 (0.8806)	grad_norm 0.3203 (nan)	loss_scale 32768.0000 (32794.2039)	mem 5928MB
[2024-07-30 12:22:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 17 training takes 0:09:09
[2024-07-30 12:22:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 20.970 (20.970)	Loss 0.3569 (0.3569)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 12:23:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.206 Acc@5 97.594
[2024-07-30 12:23:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-30 12:23:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.23%
[2024-07-30 12:23:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][0/2502]	eta 10:33:47 lr 0.000035	 wd 0.0000	time 15.1989 (15.1989)	loss 0.9185 (0.9185)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:23:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:17:05 lr 0.000035	 wd 0.0000	time 0.1608 (0.4268)	loss 0.9966 (0.8843)	grad_norm 0.3303 (0.3265)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:24:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:11:41 lr 0.000035	 wd 0.0000	time 0.1478 (0.3047)	loss 0.8540 (0.8795)	grad_norm 0.3340 (0.3261)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:24:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:09:37 lr 0.000035	 wd 0.0000	time 0.1565 (0.2622)	loss 0.9194 (0.8830)	grad_norm 0.3257 (0.3269)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:24:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:08:27 lr 0.000034	 wd 0.0000	time 0.1576 (0.2412)	loss 0.8013 (0.8843)	grad_norm 0.3324 (0.3265)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:25:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:07:39 lr 0.000034	 wd 0.0000	time 0.1639 (0.2294)	loss 0.7056 (0.8843)	grad_norm 0.3220 (0.3257)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:25:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:07:16 lr 0.000034	 wd 0.0000	time 0.2432 (0.2293)	loss 0.9453 (0.8805)	grad_norm 0.3345 (0.3259)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:25:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:06:42 lr 0.000034	 wd 0.0000	time 0.1982 (0.2235)	loss 0.9346 (0.8775)	grad_norm 0.3066 (0.3256)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:26:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:06:11 lr 0.000034	 wd 0.0000	time 0.1725 (0.2185)	loss 1.0703 (0.8758)	grad_norm 0.3173 (0.3254)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:26:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:05:43 lr 0.000033	 wd 0.0000	time 0.1483 (0.2145)	loss 0.9521 (0.8764)	grad_norm 0.3360 (0.3254)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:26:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:05:18 lr 0.000033	 wd 0.0000	time 0.1972 (0.2117)	loss 0.8525 (0.8772)	grad_norm 0.3252 (0.3254)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:27:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:12 lr 0.000033	 wd 0.0000	time 0.1574 (0.2231)	loss 0.7915 (0.8783)	grad_norm 0.3204 (0.3255)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:27:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:04:45 lr 0.000033	 wd 0.0000	time 0.1647 (0.2194)	loss 0.8916 (0.8779)	grad_norm 0.3231 (0.3256)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:27:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:04:20 lr 0.000033	 wd 0.0000	time 0.1443 (0.2164)	loss 0.8691 (0.8791)	grad_norm 0.3253 (0.3257)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:28:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:03:55 lr 0.000032	 wd 0.0000	time 0.1576 (0.2136)	loss 1.0049 (0.8785)	grad_norm 0.3332 (0.3259)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:28:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:03:32 lr 0.000032	 wd 0.0000	time 0.1934 (0.2125)	loss 0.8589 (0.8795)	grad_norm 0.3215 (0.3259)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:28:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:12 lr 0.000032	 wd 0.0000	time 0.2894 (0.2132)	loss 0.8706 (0.8787)	grad_norm 0.3214 (0.3260)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:29:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:02:49 lr 0.000032	 wd 0.0000	time 0.1888 (0.2115)	loss 0.9771 (0.8789)	grad_norm 0.3359 (0.3260)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:29:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:27 lr 0.000032	 wd 0.0000	time 0.1514 (0.2099)	loss 0.8330 (0.8788)	grad_norm 0.3425 (0.3262)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:29:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:05 lr 0.000032	 wd 0.0000	time 0.1772 (0.2083)	loss 0.8340 (0.8785)	grad_norm 0.3337 (0.3263)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:30:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:01:44 lr 0.000031	 wd 0.0000	time 0.2124 (0.2079)	loss 0.8853 (0.8791)	grad_norm 0.3092 (0.3264)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:30:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:23 lr 0.000031	 wd 0.0000	time 0.1543 (0.2086)	loss 0.7363 (0.8793)	grad_norm 0.3331 (0.3265)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:30:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:02 lr 0.000031	 wd 0.0000	time 0.1700 (0.2078)	loss 0.8945 (0.8791)	grad_norm 0.3185 (0.3266)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:31:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:41 lr 0.000031	 wd 0.0000	time 0.1728 (0.2067)	loss 0.7676 (0.8795)	grad_norm 0.3103 (0.3266)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:31:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:20 lr 0.000031	 wd 0.0000	time 0.1718 (0.2056)	loss 0.8877 (0.8796)	grad_norm 0.3315 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:31:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000030	 wd 0.0000	time 0.1247 (0.2038)	loss 0.8682 (0.8797)	grad_norm 0.3312 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:31:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 18 training takes 0:08:37
[2024-07-30 12:32:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 34.607 (34.607)	Loss 0.3574 (0.3574)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 12:32:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.220 Acc@5 97.594
[2024-07-30 12:32:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-30 12:32:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.23%
[2024-07-30 12:33:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][0/2502]	eta 11:26:22 lr 0.000030	 wd 0.0000	time 16.4596 (16.4596)	loss 0.8589 (0.8589)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:33:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:15:02 lr 0.000030	 wd 0.0000	time 0.3414 (0.3756)	loss 1.0059 (0.8712)	grad_norm 0.3215 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:33:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:12:15 lr 0.000030	 wd 0.0000	time 0.1643 (0.3197)	loss 0.6973 (0.8687)	grad_norm 0.3386 (0.3272)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:34:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:09:59 lr 0.000030	 wd 0.0000	time 0.1623 (0.2724)	loss 0.9878 (0.8741)	grad_norm 0.3237 (0.3271)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:34:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:08:42 lr 0.000030	 wd 0.0000	time 0.1456 (0.2486)	loss 0.8247 (0.8762)	grad_norm 0.3072 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:34:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:07:48 lr 0.000029	 wd 0.0000	time 0.1666 (0.2340)	loss 0.9312 (0.8760)	grad_norm 0.3326 (nan)	loss_scale 32768.0000 (32898.8104)	mem 5928MB
[2024-07-30 12:35:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:02 lr 0.000029	 wd 0.0000	time 0.1948 (0.2539)	loss 0.7510 (0.8776)	grad_norm 0.3227 (nan)	loss_scale 32768.0000 (32877.0449)	mem 5928MB
[2024-07-30 12:35:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:07:25 lr 0.000029	 wd 0.0000	time 0.1373 (0.2473)	loss 0.9917 (0.8788)	grad_norm 0.3164 (nan)	loss_scale 32768.0000 (32861.4893)	mem 5928MB
[2024-07-30 12:35:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:06:46 lr 0.000029	 wd 0.0000	time 0.1755 (0.2391)	loss 0.8569 (0.8800)	grad_norm 0.3388 (nan)	loss_scale 32768.0000 (32849.8177)	mem 5928MB
[2024-07-30 12:36:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:06:11 lr 0.000029	 wd 0.0000	time 0.1599 (0.2320)	loss 0.8477 (0.8799)	grad_norm 0.3242 (nan)	loss_scale 32768.0000 (32840.7370)	mem 5928MB
[2024-07-30 12:36:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:05:44 lr 0.000028	 wd 0.0000	time 0.3669 (0.2294)	loss 0.9487 (0.8808)	grad_norm 0.3256 (nan)	loss_scale 32768.0000 (32833.4705)	mem 5928MB
[2024-07-30 12:37:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:31 lr 0.000028	 wd 0.0000	time 0.1544 (0.2368)	loss 0.8433 (0.8802)	grad_norm 0.3310 (nan)	loss_scale 32768.0000 (32827.5241)	mem 5928MB
[2024-07-30 12:37:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:01 lr 0.000028	 wd 0.0000	time 0.1939 (0.2318)	loss 0.8696 (0.8802)	grad_norm 0.3315 (nan)	loss_scale 32768.0000 (32822.5679)	mem 5928MB
[2024-07-30 12:37:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:04:33 lr 0.000028	 wd 0.0000	time 0.1681 (0.2275)	loss 0.8506 (0.8809)	grad_norm 0.3127 (nan)	loss_scale 32768.0000 (32818.3736)	mem 5928MB
[2024-07-30 12:38:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:06 lr 0.000028	 wd 0.0000	time 0.1798 (0.2240)	loss 0.8315 (0.8803)	grad_norm 0.3276 (nan)	loss_scale 32768.0000 (32814.7780)	mem 5928MB
[2024-07-30 12:38:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:03:43 lr 0.000028	 wd 0.0000	time 0.1923 (0.2226)	loss 0.8823 (0.8808)	grad_norm 0.3109 (nan)	loss_scale 32768.0000 (32811.6616)	mem 5928MB
[2024-07-30 12:38:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:20 lr 0.000027	 wd 0.0000	time 0.2276 (0.2222)	loss 0.8901 (0.8811)	grad_norm 0.3415 (nan)	loss_scale 32768.0000 (32808.9344)	mem 5928MB
[2024-07-30 12:39:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:02:56 lr 0.000027	 wd 0.0000	time 0.1830 (0.2197)	loss 0.9839 (0.8811)	grad_norm 0.3240 (nan)	loss_scale 32768.0000 (32806.5279)	mem 5928MB
[2024-07-30 12:39:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:32 lr 0.000027	 wd 0.0000	time 0.1886 (0.2175)	loss 0.8154 (0.8815)	grad_norm 0.3285 (nan)	loss_scale 32768.0000 (32804.3887)	mem 5928MB
[2024-07-30 12:39:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:09 lr 0.000027	 wd 0.0000	time 0.1998 (0.2157)	loss 0.8481 (0.8815)	grad_norm 0.3224 (nan)	loss_scale 32768.0000 (32802.4745)	mem 5928MB
[2024-07-30 12:39:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:47 lr 0.000027	 wd 0.0000	time 0.1915 (0.2150)	loss 0.9302 (0.8813)	grad_norm 0.3205 (nan)	loss_scale 32768.0000 (32800.7516)	mem 5928MB
[2024-07-30 12:40:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:26 lr 0.000026	 wd 0.0000	time 0.2106 (0.2152)	loss 0.9678 (0.8810)	grad_norm 0.3258 (nan)	loss_scale 32768.0000 (32799.1928)	mem 5928MB
[2024-07-30 12:40:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:04 lr 0.000026	 wd 0.0000	time 0.1808 (0.2139)	loss 0.8730 (0.8804)	grad_norm 0.3631 (nan)	loss_scale 32768.0000 (32797.7756)	mem 5928MB
[2024-07-30 12:40:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:42 lr 0.000026	 wd 0.0000	time 0.1651 (0.2126)	loss 0.9087 (0.8801)	grad_norm 0.3278 (nan)	loss_scale 32768.0000 (32796.4815)	mem 5928MB
[2024-07-30 12:41:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:21 lr 0.000026	 wd 0.0000	time 0.1859 (0.2115)	loss 0.9609 (0.8800)	grad_norm 0.3457 (nan)	loss_scale 32768.0000 (32795.2953)	mem 5928MB
[2024-07-30 12:41:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1280 (0.2096)	loss 0.7085 (0.8800)	grad_norm 0.3302 (nan)	loss_scale 32768.0000 (32794.2039)	mem 5928MB
[2024-07-30 12:41:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 19 training takes 0:08:53
[2024-07-30 12:42:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 36.320 (36.320)	Loss 0.3582 (0.3582)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 12:42:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.186 Acc@5 97.608
[2024-07-30 12:42:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-30 12:42:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.23%
[2024-07-30 12:42:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][0/2502]	eta 12:10:18 lr 0.000026	 wd 0.0000	time 17.5134 (17.5134)	loss 0.8301 (0.8301)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:43:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:18:15 lr 0.000026	 wd 0.0000	time 0.1864 (0.4562)	loss 1.0176 (0.8833)	grad_norm 0.3308 (0.3310)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:43:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:12:15 lr 0.000025	 wd 0.0000	time 0.1777 (0.3195)	loss 0.9355 (0.8750)	grad_norm 0.3334 (0.3304)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:43:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:09:59 lr 0.000025	 wd 0.0000	time 0.1503 (0.2724)	loss 0.7544 (0.8709)	grad_norm 0.3356 (0.3302)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:44:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:08:42 lr 0.000025	 wd 0.0000	time 0.1811 (0.2488)	loss 0.8726 (0.8716)	grad_norm 0.3326 (0.3300)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:44:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:08:01 lr 0.000025	 wd 0.0000	time 0.2207 (0.2406)	loss 0.8584 (0.8710)	grad_norm 0.3161 (0.3307)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:45:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:08:18 lr 0.000025	 wd 0.0000	time 0.1898 (0.2622)	loss 0.7939 (0.8717)	grad_norm 0.3299 (0.3303)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:45:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:30 lr 0.000025	 wd 0.0000	time 0.1591 (0.2502)	loss 0.7900 (0.8720)	grad_norm 0.3213 (0.3305)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:45:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:06:51 lr 0.000024	 wd 0.0000	time 0.1758 (0.2417)	loss 1.0146 (0.8726)	grad_norm 0.3190 (0.3304)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:46:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:16 lr 0.000024	 wd 0.0000	time 0.1540 (0.2349)	loss 0.7588 (0.8727)	grad_norm 0.3136 (0.3305)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:46:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:05 lr 0.000024	 wd 0.0000	time 0.2314 (0.2436)	loss 0.8052 (0.8723)	grad_norm 0.3240 (0.3303)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:46:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:33 lr 0.000024	 wd 0.0000	time 0.1836 (0.2376)	loss 0.7915 (0.8725)	grad_norm 0.3252 (0.3302)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:47:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:03 lr 0.000024	 wd 0.0000	time 0.1896 (0.2328)	loss 0.7314 (0.8724)	grad_norm 0.3247 (0.3302)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:47:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:04:34 lr 0.000023	 wd 0.0000	time 0.1619 (0.2285)	loss 0.8862 (0.8724)	grad_norm 0.3287 (0.3299)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:47:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:09 lr 0.000023	 wd 0.0000	time 0.2306 (0.2263)	loss 0.9214 (0.8728)	grad_norm 0.3345 (0.3300)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:48:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:03:47 lr 0.000023	 wd 0.0000	time 0.1710 (0.2270)	loss 0.9751 (0.8724)	grad_norm 0.3288 (0.3299)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:48:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:22 lr 0.000023	 wd 0.0000	time 0.2022 (0.2244)	loss 0.9102 (0.8718)	grad_norm 0.3473 (0.3300)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:48:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:02:57 lr 0.000023	 wd 0.0000	time 0.1781 (0.2218)	loss 0.9595 (0.8718)	grad_norm 0.3185 (0.3298)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:49:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:34 lr 0.000023	 wd 0.0000	time 0.1622 (0.2195)	loss 0.7964 (0.8725)	grad_norm 0.3244 (0.3299)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:49:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:11 lr 0.000022	 wd 0.0000	time 0.2019 (0.2182)	loss 0.9980 (0.8732)	grad_norm 0.3404 (0.3299)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:49:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:01:49 lr 0.000022	 wd 0.0000	time 0.1501 (0.2186)	loss 0.9067 (0.8731)	grad_norm 0.3211 (nan)	loss_scale 32768.0000 (32800.7516)	mem 5928MB
[2024-07-30 12:50:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:27 lr 0.000022	 wd 0.0000	time 0.1477 (0.2172)	loss 0.9248 (0.8736)	grad_norm 0.3325 (nan)	loss_scale 32768.0000 (32799.1928)	mem 5928MB
[2024-07-30 12:50:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:05 lr 0.000022	 wd 0.0000	time 0.1760 (0.2157)	loss 0.8892 (0.8742)	grad_norm 0.3391 (nan)	loss_scale 32768.0000 (32797.7756)	mem 5928MB
[2024-07-30 12:50:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:43 lr 0.000022	 wd 0.0000	time 0.1860 (0.2142)	loss 0.8154 (0.8750)	grad_norm 0.3410 (nan)	loss_scale 32768.0000 (32796.4815)	mem 5928MB
[2024-07-30 12:51:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:21 lr 0.000022	 wd 0.0000	time 0.2156 (0.2136)	loss 0.8296 (0.8752)	grad_norm 0.3307 (nan)	loss_scale 32768.0000 (32795.2953)	mem 5928MB
[2024-07-30 12:51:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1343 (0.2115)	loss 0.7886 (0.8749)	grad_norm 0.3190 (nan)	loss_scale 32768.0000 (32794.2039)	mem 5928MB
[2024-07-30 12:51:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 20 training takes 0:09:03
[2024-07-30 12:51:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 19.619 (19.619)	Loss 0.3591 (0.3591)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 12:52:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.254 Acc@5 97.612
[2024-07-30 12:52:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 12:52:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.25%
[2024-07-30 12:52:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-30 12:52:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-30 12:52:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][0/2502]	eta 13:38:58 lr 0.000021	 wd 0.0000	time 19.6395 (19.6395)	loss 0.9165 (0.9165)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:53:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:17:15 lr 0.000021	 wd 0.0000	time 0.1655 (0.4309)	loss 0.8901 (0.8872)	grad_norm 0.3282 (0.3302)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:53:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:11:47 lr 0.000021	 wd 0.0000	time 0.1838 (0.3073)	loss 0.9272 (0.8802)	grad_norm 0.3245 (0.3295)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:53:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:09:42 lr 0.000021	 wd 0.0000	time 0.1677 (0.2646)	loss 0.9087 (0.8775)	grad_norm 0.3300 (0.3305)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:53:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:08:31 lr 0.000021	 wd 0.0000	time 0.1745 (0.2432)	loss 0.9883 (0.8776)	grad_norm 0.3284 (0.3301)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:54:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:07:53 lr 0.000021	 wd 0.0000	time 0.3101 (0.2363)	loss 0.8247 (0.8779)	grad_norm 0.3174 (0.3304)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:54:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:12 lr 0.000020	 wd 0.0000	time 0.1402 (0.2590)	loss 0.8794 (0.8774)	grad_norm 0.3393 (0.3309)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:55:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:07:25 lr 0.000020	 wd 0.0000	time 0.1243 (0.2471)	loss 1.0137 (0.8777)	grad_norm 0.3413 (0.3309)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:55:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:06:45 lr 0.000020	 wd 0.0000	time 0.1553 (0.2383)	loss 0.9009 (0.8778)	grad_norm 0.3517 (0.3310)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:55:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:12 lr 0.000020	 wd 0.0000	time 0.2009 (0.2322)	loss 0.8345 (0.8788)	grad_norm 0.3243 (0.3309)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:56:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:06 lr 0.000020	 wd 0.0000	time 0.2567 (0.2439)	loss 0.8379 (0.8783)	grad_norm 0.3107 (0.3309)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:56:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:05:33 lr 0.000020	 wd 0.0000	time 0.1728 (0.2381)	loss 0.9014 (0.8788)	grad_norm 0.3260 (0.3308)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:56:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:03 lr 0.000019	 wd 0.0000	time 0.1727 (0.2331)	loss 0.8389 (0.8801)	grad_norm 0.3257 (0.3309)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:57:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:34 lr 0.000019	 wd 0.0000	time 0.1534 (0.2284)	loss 0.9458 (0.8796)	grad_norm 0.3187 (0.3308)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:57:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:09 lr 0.000019	 wd 0.0000	time 0.2018 (0.2266)	loss 0.8945 (0.8796)	grad_norm 0.3254 (0.3307)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:57:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:03:46 lr 0.000019	 wd 0.0000	time 0.2427 (0.2261)	loss 0.9355 (0.8793)	grad_norm 0.3279 (0.3306)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:58:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:21 lr 0.000019	 wd 0.0000	time 0.1347 (0.2234)	loss 0.9121 (0.8788)	grad_norm 0.3411 (0.3307)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:58:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:02:57 lr 0.000019	 wd 0.0000	time 0.1525 (0.2209)	loss 0.8848 (0.8794)	grad_norm 0.3245 (0.3308)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:58:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:33 lr 0.000018	 wd 0.0000	time 0.1533 (0.2187)	loss 0.8931 (0.8794)	grad_norm 0.3263 (0.3309)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:59:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:11 lr 0.000018	 wd 0.0000	time 0.2166 (0.2179)	loss 0.9033 (0.8795)	grad_norm 0.3294 (0.3310)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:59:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:49 lr 0.000018	 wd 0.0000	time 0.1611 (0.2182)	loss 0.7563 (0.8793)	grad_norm 0.3408 (0.3312)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 12:59:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:27 lr 0.000018	 wd 0.0000	time 0.1437 (0.2167)	loss 0.7798 (0.8787)	grad_norm 0.3170 (0.3313)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:00:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:05 lr 0.000018	 wd 0.0000	time 0.2037 (0.2152)	loss 0.7930 (0.8781)	grad_norm 0.3337 (0.3313)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:00:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:43 lr 0.000018	 wd 0.0000	time 0.1885 (0.2139)	loss 0.9336 (0.8781)	grad_norm 0.3260 (0.3313)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:00:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:21 lr 0.000018	 wd 0.0000	time 0.1726 (0.2134)	loss 0.8701 (0.8781)	grad_norm 0.3244 (0.3315)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:01:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000017	 wd 0.0000	time 0.1327 (0.2122)	loss 0.8994 (0.8784)	grad_norm 0.3042 (0.3315)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:01:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 21 training takes 0:09:03
[2024-07-30 13:01:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 19.154 (19.154)	Loss 0.3560 (0.3560)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 13:01:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.250 Acc@5 97.624
[2024-07-30 13:01:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 13:01:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.25%
[2024-07-30 13:02:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][0/2502]	eta 13:11:33 lr 0.000017	 wd 0.0000	time 18.9822 (18.9822)	loss 0.8369 (0.8369)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:02:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:18:43 lr 0.000017	 wd 0.0000	time 0.1508 (0.4676)	loss 0.9141 (0.8825)	grad_norm 0.3310 (0.3333)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:03:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:12:29 lr 0.000017	 wd 0.0000	time 0.1592 (0.3257)	loss 0.8105 (0.8781)	grad_norm 0.3212 (0.3324)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:03:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:10:08 lr 0.000017	 wd 0.0000	time 0.1246 (0.2764)	loss 0.8682 (0.8772)	grad_norm 0.3298 (0.3329)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:03:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:08:48 lr 0.000017	 wd 0.0000	time 0.1593 (0.2514)	loss 0.8159 (0.8822)	grad_norm 0.3198 (0.3331)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:04:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:08:07 lr 0.000017	 wd 0.0000	time 0.2982 (0.2436)	loss 0.7061 (0.8803)	grad_norm 0.3238 (0.3323)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:04:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:17 lr 0.000016	 wd 0.0000	time 0.1849 (0.2614)	loss 0.9175 (0.8818)	grad_norm 0.3173 (0.3323)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:04:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:29 lr 0.000016	 wd 0.0000	time 0.1496 (0.2493)	loss 0.9868 (0.8804)	grad_norm 0.3227 (0.3326)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:05:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:06:49 lr 0.000016	 wd 0.0000	time 0.1488 (0.2404)	loss 0.8901 (0.8804)	grad_norm 0.3274 (0.3324)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:05:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:15 lr 0.000016	 wd 0.0000	time 0.2075 (0.2347)	loss 0.8379 (0.8801)	grad_norm 0.3235 (0.3327)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:06:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:08 lr 0.000016	 wd 0.0000	time 0.1961 (0.2453)	loss 0.9019 (0.8798)	grad_norm 0.3249 (nan)	loss_scale 32768.0000 (32833.4705)	mem 5928MB
[2024-07-30 13:06:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:35 lr 0.000016	 wd 0.0000	time 0.1834 (0.2390)	loss 0.7778 (0.8784)	grad_norm 0.3172 (nan)	loss_scale 32768.0000 (32827.5241)	mem 5928MB
[2024-07-30 13:06:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:04 lr 0.000016	 wd 0.0000	time 0.1309 (0.2338)	loss 0.8477 (0.8787)	grad_norm 0.3255 (nan)	loss_scale 32768.0000 (32822.5679)	mem 5928MB
[2024-07-30 13:06:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:04:35 lr 0.000015	 wd 0.0000	time 0.1328 (0.2293)	loss 0.8716 (0.8774)	grad_norm 0.3380 (nan)	loss_scale 32768.0000 (32818.3736)	mem 5928MB
[2024-07-30 13:07:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:11 lr 0.000015	 wd 0.0000	time 0.2067 (0.2284)	loss 0.8613 (0.8772)	grad_norm 0.3341 (nan)	loss_scale 32768.0000 (32814.7780)	mem 5928MB
[2024-07-30 13:07:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:03:48 lr 0.000015	 wd 0.0000	time 0.1649 (0.2276)	loss 0.6875 (0.8772)	grad_norm 0.3249 (nan)	loss_scale 32768.0000 (32811.6616)	mem 5928MB
[2024-07-30 13:07:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:22 lr 0.000015	 wd 0.0000	time 0.1815 (0.2247)	loss 0.8330 (0.8774)	grad_norm 0.3380 (nan)	loss_scale 32768.0000 (32808.9344)	mem 5928MB
[2024-07-30 13:08:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:02:58 lr 0.000015	 wd 0.0000	time 0.1748 (0.2221)	loss 0.8818 (0.8769)	grad_norm 0.3386 (nan)	loss_scale 32768.0000 (32806.5279)	mem 5928MB
[2024-07-30 13:08:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:34 lr 0.000015	 wd 0.0000	time 0.1745 (0.2198)	loss 0.9370 (0.8769)	grad_norm 0.3274 (nan)	loss_scale 32768.0000 (32804.3887)	mem 5928MB
[2024-07-30 13:08:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:11 lr 0.000015	 wd 0.0000	time 0.2373 (0.2190)	loss 0.8921 (0.8774)	grad_norm 0.3312 (nan)	loss_scale 32768.0000 (32802.4745)	mem 5928MB
[2024-07-30 13:09:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:50 lr 0.000014	 wd 0.0000	time 0.1557 (0.2196)	loss 0.9648 (0.8771)	grad_norm 0.3038 (nan)	loss_scale 32768.0000 (32800.7516)	mem 5928MB
[2024-07-30 13:09:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:27 lr 0.000014	 wd 0.0000	time 0.1684 (0.2179)	loss 0.8198 (0.8775)	grad_norm 0.3330 (nan)	loss_scale 32768.0000 (32799.1928)	mem 5928MB
[2024-07-30 13:09:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:05 lr 0.000014	 wd 0.0000	time 0.1919 (0.2164)	loss 0.6880 (0.8774)	grad_norm 0.3266 (nan)	loss_scale 32768.0000 (32797.7756)	mem 5928MB
[2024-07-30 13:10:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:43 lr 0.000014	 wd 0.0000	time 0.1915 (0.2150)	loss 0.9468 (0.8774)	grad_norm 0.3332 (nan)	loss_scale 32768.0000 (32796.4815)	mem 5928MB
[2024-07-30 13:10:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:21 lr 0.000014	 wd 0.0000	time 0.1637 (0.2144)	loss 0.7666 (0.8775)	grad_norm 0.3349 (nan)	loss_scale 32768.0000 (32795.2953)	mem 5928MB
[2024-07-30 13:10:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1243 (0.2131)	loss 0.8418 (0.8770)	grad_norm 0.3419 (nan)	loss_scale 32768.0000 (32794.2039)	mem 5928MB
[2024-07-30 13:11:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 22 training takes 0:09:05
[2024-07-30 13:11:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 20.617 (20.617)	Loss 0.3550 (0.3550)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 13:11:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.272 Acc@5 97.624
[2024-07-30 13:11:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 13:11:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.27%
[2024-07-30 13:11:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-30 13:11:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-30 13:12:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][0/2502]	eta 18:11:04 lr 0.000014	 wd 0.0000	time 26.1649 (26.1649)	loss 0.7671 (0.7671)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:12:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:19:16 lr 0.000014	 wd 0.0000	time 0.1668 (0.4815)	loss 0.8740 (0.8762)	grad_norm 0.3397 (0.3352)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:12:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:12:38 lr 0.000013	 wd 0.0000	time 0.1610 (0.3294)	loss 0.9399 (0.8734)	grad_norm 0.3529 (0.3336)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:13:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:10:16 lr 0.000013	 wd 0.0000	time 0.1633 (0.2800)	loss 0.7764 (0.8718)	grad_norm 0.3248 (0.3337)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:13:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:08:54 lr 0.000013	 wd 0.0000	time 0.2126 (0.2545)	loss 0.9966 (0.8735)	grad_norm 0.3274 (0.3342)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:13:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:08:43 lr 0.000013	 wd 0.0000	time 0.1822 (0.2615)	loss 0.8970 (0.8775)	grad_norm 0.3160 (0.3344)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:14:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:07:53 lr 0.000013	 wd 0.0000	time 0.1567 (0.2492)	loss 0.8975 (0.8781)	grad_norm 0.3390 (0.3346)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:14:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:09 lr 0.000013	 wd 0.0000	time 0.1550 (0.2385)	loss 0.9795 (0.8789)	grad_norm 0.3238 (0.3342)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:14:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:06:33 lr 0.000013	 wd 0.0000	time 0.1651 (0.2313)	loss 0.9771 (0.8784)	grad_norm 0.3267 (0.3340)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:15:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:06:02 lr 0.000012	 wd 0.0000	time 0.2159 (0.2264)	loss 1.1211 (0.8768)	grad_norm 0.3368 (0.3339)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:15:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:05:51 lr 0.000012	 wd 0.0000	time 0.1502 (0.2341)	loss 0.7471 (0.8772)	grad_norm 0.3314 (0.3339)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:15:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:21 lr 0.000012	 wd 0.0000	time 0.2150 (0.2294)	loss 0.7261 (0.8763)	grad_norm 0.3391 (0.3339)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:16:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:04:53 lr 0.000012	 wd 0.0000	time 0.1672 (0.2251)	loss 0.9434 (0.8767)	grad_norm 0.3196 (0.3339)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:16:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:04:26 lr 0.000012	 wd 0.0000	time 0.1719 (0.2216)	loss 0.9385 (0.8769)	grad_norm 0.3440 (0.3340)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:16:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:02 lr 0.000012	 wd 0.0000	time 0.1897 (0.2199)	loss 0.9453 (0.8773)	grad_norm 0.3352 (0.3340)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:17:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:03:40 lr 0.000012	 wd 0.0000	time 0.1578 (0.2203)	loss 0.7603 (0.8781)	grad_norm 0.3411 (0.3340)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:17:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:16 lr 0.000012	 wd 0.0000	time 0.1832 (0.2181)	loss 0.8867 (0.8782)	grad_norm 0.3278 (0.3341)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:17:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:02:53 lr 0.000011	 wd 0.0000	time 0.1784 (0.2161)	loss 0.7852 (0.8780)	grad_norm 0.3341 (0.3342)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:18:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:30 lr 0.000011	 wd 0.0000	time 0.1461 (0.2141)	loss 0.9097 (0.8783)	grad_norm 0.3283 (0.3343)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:18:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:08 lr 0.000011	 wd 0.0000	time 0.1711 (0.2132)	loss 0.8027 (0.8779)	grad_norm 0.3320 (0.3342)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:18:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:01:47 lr 0.000011	 wd 0.0000	time 0.1628 (0.2140)	loss 0.9839 (0.8776)	grad_norm 0.3299 (0.3341)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:19:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:25 lr 0.000011	 wd 0.0000	time 0.1541 (0.2128)	loss 1.0371 (0.8776)	grad_norm 0.3108 (0.3341)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:19:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:03 lr 0.000011	 wd 0.0000	time 0.1488 (0.2115)	loss 0.9561 (0.8771)	grad_norm 0.3473 (0.3340)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:19:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:42 lr 0.000011	 wd 0.0000	time 0.1574 (0.2101)	loss 0.8696 (0.8772)	grad_norm 0.3310 (0.3340)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:20:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:21 lr 0.000011	 wd 0.0000	time 0.1826 (0.2096)	loss 0.8774 (0.8773)	grad_norm 0.3302 (0.3340)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:20:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1357 (0.2078)	loss 0.8062 (0.8771)	grad_norm 0.3387 (nan)	loss_scale 32768.0000 (32794.2039)	mem 5928MB
[2024-07-30 13:20:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 23 training takes 0:08:55
[2024-07-30 13:20:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 20.589 (20.589)	Loss 0.3562 (0.3562)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 13:21:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.236 Acc@5 97.608
[2024-07-30 13:21:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-30 13:21:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.27%
[2024-07-30 13:21:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][0/2502]	eta 15:20:50 lr 0.000010	 wd 0.0000	time 22.0827 (22.0827)	loss 0.8872 (0.8872)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:22:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:17:55 lr 0.000010	 wd 0.0000	time 0.1870 (0.4479)	loss 0.9883 (0.8725)	grad_norm 0.3152 (0.3351)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:22:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:12:04 lr 0.000010	 wd 0.0000	time 0.1594 (0.3148)	loss 0.8862 (0.8752)	grad_norm 0.3441 (0.3342)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:22:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:09:53 lr 0.000010	 wd 0.0000	time 0.1663 (0.2693)	loss 0.8047 (0.8784)	grad_norm 0.3489 (0.3345)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:22:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:08:37 lr 0.000010	 wd 0.0000	time 0.1446 (0.2461)	loss 0.7378 (0.8794)	grad_norm 0.3229 (0.3344)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:23:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:08:00 lr 0.000010	 wd 0.0000	time 0.3455 (0.2399)	loss 0.8857 (0.8814)	grad_norm 0.3602 (0.3345)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:23:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:08:11 lr 0.000010	 wd 0.0000	time 0.1540 (0.2583)	loss 0.8975 (0.8790)	grad_norm 0.3153 (0.3348)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:24:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:07:25 lr 0.000010	 wd 0.0000	time 0.1746 (0.2470)	loss 0.8354 (0.8781)	grad_norm 0.3261 (0.3343)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:24:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:06:46 lr 0.000010	 wd 0.0000	time 0.1505 (0.2386)	loss 0.8047 (0.8774)	grad_norm 0.3415 (0.3342)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:24:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:06:12 lr 0.000009	 wd 0.0000	time 0.2067 (0.2328)	loss 0.9360 (0.8782)	grad_norm 0.3354 (0.3341)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:25:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:11 lr 0.000009	 wd 0.0000	time 0.1828 (0.2476)	loss 0.8232 (0.8790)	grad_norm 0.3329 (0.3341)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:25:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:05:38 lr 0.000009	 wd 0.0000	time 0.1675 (0.2412)	loss 0.8203 (0.8788)	grad_norm 0.3364 (0.3345)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:26:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:07 lr 0.000009	 wd 0.0000	time 0.1732 (0.2360)	loss 0.8306 (0.8784)	grad_norm 0.3139 (0.3346)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:26:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:04:38 lr 0.000009	 wd 0.0000	time 0.1430 (0.2314)	loss 0.7363 (0.8770)	grad_norm 0.3398 (0.3344)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:26:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:21 lr 0.000009	 wd 0.0000	time 0.2189 (0.2374)	loss 0.7773 (0.8773)	grad_norm 0.3241 (0.3344)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:27:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:03:54 lr 0.000009	 wd 0.0000	time 0.1917 (0.2336)	loss 0.8315 (0.8773)	grad_norm 0.3334 (0.3344)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:27:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:27 lr 0.000009	 wd 0.0000	time 0.1508 (0.2300)	loss 0.9053 (0.8773)	grad_norm 0.3255 (0.3345)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:27:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:02 lr 0.000008	 wd 0.0000	time 0.1652 (0.2270)	loss 0.9639 (0.8776)	grad_norm 0.3414 (0.3346)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:28:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:37 lr 0.000008	 wd 0.0000	time 0.1745 (0.2249)	loss 0.7812 (0.8779)	grad_norm 0.3280 (0.3345)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:28:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:16 lr 0.000008	 wd 0.0000	time 0.1636 (0.2260)	loss 0.7520 (0.8776)	grad_norm 0.3200 (0.3346)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:28:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:01:52 lr 0.000008	 wd 0.0000	time 0.1834 (0.2239)	loss 0.7129 (0.8775)	grad_norm 0.3407 (0.3347)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:29:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:29 lr 0.000008	 wd 0.0000	time 0.1674 (0.2220)	loss 0.9780 (0.8772)	grad_norm 0.3334 (0.3347)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:29:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:06 lr 0.000008	 wd 0.0000	time 0.1700 (0.2201)	loss 0.8687 (0.8771)	grad_norm 0.3277 (0.3347)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:29:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:44 lr 0.000008	 wd 0.0000	time 0.1748 (0.2191)	loss 0.9180 (0.8773)	grad_norm 0.3267 (0.3346)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:30:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:22 lr 0.000008	 wd 0.0000	time 0.1485 (0.2189)	loss 1.0527 (0.8772)	grad_norm 0.3335 (0.3346)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:30:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1448 (0.2166)	loss 0.9893 (0.8771)	grad_norm 0.3214 (0.3346)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:30:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 24 training takes 0:09:11
[2024-07-30 13:30:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 20.562 (20.562)	Loss 0.3574 (0.3574)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 13:31:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.242 Acc@5 97.626
[2024-07-30 13:31:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-30 13:31:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.27%
[2024-07-30 13:31:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][0/2502]	eta 1 day, 0:12:51 lr 0.000008	 wd 0.0000	time 34.8405 (34.8405)	loss 0.8735 (0.8735)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:32:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:20:58 lr 0.000008	 wd 0.0000	time 0.2179 (0.5237)	loss 0.8369 (0.8929)	grad_norm 0.3267 (0.3360)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:32:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:13:25 lr 0.000007	 wd 0.0000	time 0.1467 (0.3500)	loss 0.8257 (0.8887)	grad_norm 0.3340 (0.3352)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:32:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:10:43 lr 0.000007	 wd 0.0000	time 0.2114 (0.2922)	loss 0.9097 (0.8811)	grad_norm 0.3378 (0.3353)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:32:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:09:27 lr 0.000007	 wd 0.0000	time 0.2413 (0.2699)	loss 0.7534 (0.8820)	grad_norm 0.3404 (0.3356)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:33:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:09:00 lr 0.000007	 wd 0.0000	time 0.2103 (0.2700)	loss 0.8628 (0.8812)	grad_norm 0.3190 (0.3354)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:33:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:04 lr 0.000007	 wd 0.0000	time 0.1670 (0.2550)	loss 0.7378 (0.8808)	grad_norm 0.3587 (0.3354)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:34:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:07:19 lr 0.000007	 wd 0.0000	time 0.1628 (0.2441)	loss 0.8340 (0.8799)	grad_norm 0.3347 (0.3352)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:34:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:06:41 lr 0.000007	 wd 0.0000	time 0.1607 (0.2360)	loss 0.9780 (0.8794)	grad_norm 0.3343 (0.3353)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:34:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:06:35 lr 0.000007	 wd 0.0000	time 1.3565 (0.2466)	loss 0.7334 (0.8792)	grad_norm 0.3339 (0.3354)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:35:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:01 lr 0.000007	 wd 0.0000	time 0.1710 (0.2409)	loss 0.9453 (0.8797)	grad_norm 0.3538 (0.3356)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:35:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:29 lr 0.000007	 wd 0.0000	time 0.1771 (0.2350)	loss 0.9937 (0.8791)	grad_norm 0.3314 (0.3356)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:35:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:04:59 lr 0.000006	 wd 0.0000	time 0.1449 (0.2302)	loss 1.0059 (0.8801)	grad_norm 0.3403 (0.3355)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:36:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:04:33 lr 0.000006	 wd 0.0000	time 0.1808 (0.2275)	loss 0.8857 (0.8791)	grad_norm 0.3255 (0.3354)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:36:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:16 lr 0.000006	 wd 0.0000	time 0.1633 (0.2327)	loss 0.9331 (0.8787)	grad_norm 0.3228 (0.3353)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:36:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:03:49 lr 0.000006	 wd 0.0000	time 0.1316 (0.2290)	loss 0.9673 (0.8795)	grad_norm 0.3261 (nan)	loss_scale 32768.0000 (32811.6616)	mem 5928MB
[2024-07-30 13:37:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:23 lr 0.000006	 wd 0.0000	time 0.1604 (0.2259)	loss 0.7461 (0.8791)	grad_norm 0.3254 (nan)	loss_scale 32768.0000 (32808.9344)	mem 5928MB
[2024-07-30 13:37:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:02:58 lr 0.000006	 wd 0.0000	time 0.1707 (0.2231)	loss 0.8164 (0.8798)	grad_norm 0.3241 (nan)	loss_scale 32768.0000 (32806.5279)	mem 5928MB
[2024-07-30 13:37:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:35 lr 0.000006	 wd 0.0000	time 0.1642 (0.2219)	loss 0.8979 (0.8794)	grad_norm 0.3227 (nan)	loss_scale 32768.0000 (32804.3887)	mem 5928MB
[2024-07-30 13:38:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:13 lr 0.000006	 wd 0.0000	time 0.1958 (0.2224)	loss 1.0039 (0.8793)	grad_norm 0.3370 (nan)	loss_scale 32768.0000 (32802.4745)	mem 5928MB
[2024-07-30 13:38:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:01:50 lr 0.000006	 wd 0.0000	time 0.1600 (0.2206)	loss 0.9980 (0.8793)	grad_norm 0.3343 (nan)	loss_scale 32768.0000 (32800.7516)	mem 5928MB
[2024-07-30 13:38:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:27 lr 0.000006	 wd 0.0000	time 0.1608 (0.2189)	loss 0.9043 (0.8787)	grad_norm 0.3303 (nan)	loss_scale 32768.0000 (32799.1928)	mem 5928MB
[2024-07-30 13:39:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:05 lr 0.000006	 wd 0.0000	time 0.2155 (0.2172)	loss 0.8315 (0.8784)	grad_norm 0.3141 (nan)	loss_scale 32768.0000 (32797.7756)	mem 5928MB
[2024-07-30 13:39:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:43 lr 0.000005	 wd 0.0000	time 0.1808 (0.2165)	loss 0.7808 (0.8782)	grad_norm 0.3245 (nan)	loss_scale 32768.0000 (32796.4815)	mem 5928MB
[2024-07-30 13:39:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:22 lr 0.000005	 wd 0.0000	time 0.1836 (0.2164)	loss 0.8340 (0.8782)	grad_norm 0.3254 (nan)	loss_scale 32768.0000 (32795.2953)	mem 5928MB
[2024-07-30 13:40:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000005	 wd 0.0000	time 0.1265 (0.2141)	loss 0.8677 (0.8785)	grad_norm 0.3398 (nan)	loss_scale 32768.0000 (32794.2039)	mem 5928MB
[2024-07-30 13:40:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 25 training takes 0:09:03
[2024-07-30 13:40:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 22.053 (22.053)	Loss 0.3569 (0.3569)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 13:40:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.264 Acc@5 97.624
[2024-07-30 13:40:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 13:40:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.27%
[2024-07-30 13:41:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][0/2502]	eta 1 day, 1:11:57 lr 0.000005	 wd 0.0000	time 36.2578 (36.2578)	loss 1.0146 (1.0146)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:41:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:21:42 lr 0.000005	 wd 0.0000	time 0.1560 (0.5423)	loss 0.7822 (0.8866)	grad_norm 0.3298 (0.3399)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:42:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:13:47 lr 0.000005	 wd 0.0000	time 0.1779 (0.3597)	loss 0.8608 (0.8829)	grad_norm 0.3425 (0.3381)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:42:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:10:58 lr 0.000005	 wd 0.0000	time 0.1988 (0.2989)	loss 0.8560 (0.8838)	grad_norm 0.3502 (0.3378)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:43:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:11:23 lr 0.000005	 wd 0.0000	time 0.2302 (0.3253)	loss 0.9077 (0.8816)	grad_norm 0.3388 (0.3371)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:43:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:09:58 lr 0.000005	 wd 0.0000	time 0.1385 (0.2988)	loss 0.8291 (0.8797)	grad_norm 0.3123 (0.3365)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:43:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:08:50 lr 0.000005	 wd 0.0000	time 0.1626 (0.2790)	loss 0.8638 (0.8805)	grad_norm 0.3366 (0.3365)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:44:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:56 lr 0.000005	 wd 0.0000	time 0.1656 (0.2645)	loss 0.8237 (0.8786)	grad_norm 0.3272 (0.3361)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:44:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:07:21 lr 0.000005	 wd 0.0000	time 0.2224 (0.2596)	loss 0.8574 (0.8796)	grad_norm 0.3463 (0.3360)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:44:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:06:50 lr 0.000005	 wd 0.0000	time 0.1595 (0.2565)	loss 0.7832 (0.8781)	grad_norm 0.3333 (0.3362)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:45:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:13 lr 0.000004	 wd 0.0000	time 0.1828 (0.2484)	loss 0.9600 (0.8785)	grad_norm 0.3246 (0.3362)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:45:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:40 lr 0.000004	 wd 0.0000	time 0.1611 (0.2426)	loss 0.9663 (0.8791)	grad_norm 0.3329 (0.3361)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:45:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:09 lr 0.000004	 wd 0.0000	time 0.1883 (0.2375)	loss 0.9048 (0.8789)	grad_norm 0.3371 (0.3362)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:46:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:04:46 lr 0.000004	 wd 0.0000	time 1.0959 (0.2387)	loss 0.7559 (0.8793)	grad_norm 0.3367 (0.3362)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:46:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:18 lr 0.000004	 wd 0.0000	time 0.1470 (0.2346)	loss 0.9658 (0.8790)	grad_norm 0.3277 (0.3361)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:46:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:03:51 lr 0.000004	 wd 0.0000	time 0.1962 (0.2310)	loss 0.8545 (0.8793)	grad_norm 0.3236 (0.3362)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:46:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:25 lr 0.000004	 wd 0.0000	time 0.1826 (0.2278)	loss 0.7446 (0.8783)	grad_norm 0.3137 (0.3362)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:47:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:00 lr 0.000004	 wd 0.0000	time 0.2030 (0.2254)	loss 0.8569 (0.8791)	grad_norm 0.3301 (0.3361)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:47:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:38 lr 0.000004	 wd 0.0000	time 0.1419 (0.2253)	loss 0.9331 (0.8795)	grad_norm 0.3301 (0.3361)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:48:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:14 lr 0.000004	 wd 0.0000	time 0.1301 (0.2240)	loss 0.8779 (0.8788)	grad_norm 0.3368 (0.3360)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:48:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:01:51 lr 0.000004	 wd 0.0000	time 0.1975 (0.2220)	loss 0.9268 (0.8788)	grad_norm 0.3390 (0.3360)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:48:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:28 lr 0.000004	 wd 0.0000	time 0.1902 (0.2202)	loss 0.9087 (0.8790)	grad_norm 0.3427 (0.3360)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:48:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:06 lr 0.000004	 wd 0.0000	time 0.1695 (0.2188)	loss 0.9434 (0.8789)	grad_norm 0.3319 (0.3359)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:49:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:44 lr 0.000004	 wd 0.0000	time 0.1751 (0.2186)	loss 0.8403 (0.8786)	grad_norm 0.3447 (0.3359)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:49:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:22 lr 0.000003	 wd 0.0000	time 0.2020 (0.2176)	loss 0.8726 (0.8790)	grad_norm 0.3460 (0.3360)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:49:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1421 (0.2151)	loss 0.9312 (0.8790)	grad_norm 0.3349 (0.3360)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:50:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 26 training takes 0:09:05
[2024-07-30 13:50:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 18.193 (18.193)	Loss 0.3567 (0.3567)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 13:50:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.262 Acc@5 97.610
[2024-07-30 13:50:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 13:50:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.27%
[2024-07-30 13:51:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][0/2502]	eta 1 day, 4:56:22 lr 0.000003	 wd 0.0000	time 41.6395 (41.6395)	loss 0.9263 (0.9263)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:51:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:23:34 lr 0.000003	 wd 0.0000	time 0.1815 (0.5887)	loss 0.8872 (0.8836)	grad_norm 0.3329 (0.3346)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:51:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:14:42 lr 0.000003	 wd 0.0000	time 0.1567 (0.3832)	loss 0.7178 (0.8780)	grad_norm 0.3500 (0.3352)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:52:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:11:57 lr 0.000003	 wd 0.0000	time 0.3757 (0.3259)	loss 0.8833 (0.8789)	grad_norm 0.3531 (0.3359)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:52:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:11:52 lr 0.000003	 wd 0.0000	time 0.1667 (0.3391)	loss 0.8237 (0.8779)	grad_norm 0.3331 (0.3362)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 13:53:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:10:19 lr 0.000003	 wd 0.0000	time 0.1889 (0.3096)	loss 0.7607 (0.8771)	grad_norm 0.3596 (nan)	loss_scale 32768.0000 (32898.8104)	mem 5928MB
[2024-07-30 13:53:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:09:06 lr 0.000003	 wd 0.0000	time 0.1436 (0.2875)	loss 0.8105 (0.8793)	grad_norm 0.3470 (nan)	loss_scale 32768.0000 (32877.0449)	mem 5928MB
[2024-07-30 13:53:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:08:13 lr 0.000003	 wd 0.0000	time 0.1951 (0.2740)	loss 0.8271 (0.8788)	grad_norm 0.3533 (nan)	loss_scale 32768.0000 (32861.4893)	mem 5928MB
[2024-07-30 13:54:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:55 lr 0.000003	 wd 0.0000	time 0.1707 (0.2793)	loss 0.8975 (0.8783)	grad_norm 0.3217 (nan)	loss_scale 32768.0000 (32849.8177)	mem 5928MB
[2024-07-30 13:54:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:07:09 lr 0.000003	 wd 0.0000	time 0.1778 (0.2681)	loss 0.7451 (0.8778)	grad_norm 0.3212 (nan)	loss_scale 32768.0000 (32840.7370)	mem 5928MB
[2024-07-30 13:54:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:28 lr 0.000003	 wd 0.0000	time 0.2097 (0.2589)	loss 0.8857 (0.8774)	grad_norm 0.3289 (nan)	loss_scale 32768.0000 (32833.4705)	mem 5928MB
[2024-07-30 13:55:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:52 lr 0.000003	 wd 0.0000	time 0.1448 (0.2513)	loss 0.7734 (0.8774)	grad_norm 0.3453 (nan)	loss_scale 32768.0000 (32827.5241)	mem 5928MB
[2024-07-30 13:55:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:36 lr 0.000003	 wd 0.0000	time 0.1745 (0.2583)	loss 0.8955 (0.8766)	grad_norm 0.3280 (nan)	loss_scale 32768.0000 (32822.5679)	mem 5928MB
[2024-07-30 13:56:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:05:03 lr 0.000003	 wd 0.0000	time 0.1651 (0.2527)	loss 0.8457 (0.8767)	grad_norm 0.3414 (nan)	loss_scale 32768.0000 (32818.3736)	mem 5928MB
[2024-07-30 13:56:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:32 lr 0.000003	 wd 0.0000	time 0.1821 (0.2474)	loss 0.8125 (0.8766)	grad_norm 0.3321 (nan)	loss_scale 32768.0000 (32814.7780)	mem 5928MB
[2024-07-30 13:56:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:04:03 lr 0.000003	 wd 0.0000	time 0.2208 (0.2428)	loss 0.9727 (0.8767)	grad_norm 0.3230 (nan)	loss_scale 32768.0000 (32811.6616)	mem 5928MB
[2024-07-30 13:57:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:36 lr 0.000003	 wd 0.0000	time 0.2422 (0.2396)	loss 0.8804 (0.8767)	grad_norm 0.3354 (nan)	loss_scale 32768.0000 (32808.9344)	mem 5928MB
[2024-07-30 13:57:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:11 lr 0.000002	 wd 0.0000	time 0.1836 (0.2386)	loss 0.8799 (0.8769)	grad_norm 0.3348 (nan)	loss_scale 32768.0000 (32806.5279)	mem 5928MB
[2024-07-30 13:57:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:45 lr 0.000002	 wd 0.0000	time 0.1756 (0.2358)	loss 0.7729 (0.8772)	grad_norm 0.3383 (nan)	loss_scale 32768.0000 (32804.3887)	mem 5928MB
[2024-07-30 13:58:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:20 lr 0.000002	 wd 0.0000	time 0.1415 (0.2330)	loss 0.8159 (0.8774)	grad_norm 0.3317 (nan)	loss_scale 32768.0000 (32802.4745)	mem 5928MB
[2024-07-30 13:58:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:55 lr 0.000002	 wd 0.0000	time 0.1589 (0.2306)	loss 0.7563 (0.8770)	grad_norm 0.3249 (nan)	loss_scale 32768.0000 (32800.7516)	mem 5928MB
[2024-07-30 13:58:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:31 lr 0.000002	 wd 0.0000	time 0.1862 (0.2287)	loss 1.0195 (0.8779)	grad_norm 0.3515 (nan)	loss_scale 32768.0000 (32799.1928)	mem 5928MB
[2024-07-30 13:59:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:08 lr 0.000002	 wd 0.0000	time 0.1927 (0.2284)	loss 0.7349 (0.8774)	grad_norm 0.3291 (nan)	loss_scale 32768.0000 (32797.7756)	mem 5928MB
[2024-07-30 13:59:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:45 lr 0.000002	 wd 0.0000	time 0.1822 (0.2272)	loss 0.8330 (0.8776)	grad_norm 0.3310 (nan)	loss_scale 32768.0000 (32796.4815)	mem 5928MB
[2024-07-30 13:59:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:22 lr 0.000002	 wd 0.0000	time 0.1782 (0.2254)	loss 0.8916 (0.8773)	grad_norm 0.3416 (nan)	loss_scale 32768.0000 (32795.2953)	mem 5928MB
[2024-07-30 13:59:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1243 (0.2226)	loss 0.8623 (0.8775)	grad_norm 0.3291 (nan)	loss_scale 32768.0000 (32794.2039)	mem 5928MB
[2024-07-30 14:00:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 27 training takes 0:09:26
[2024-07-30 14:00:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 45.046 (45.046)	Loss 0.3574 (0.3574)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 14:01:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.266 Acc@5 97.610
[2024-07-30 14:01:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 14:01:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.27%
[2024-07-30 14:01:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][0/2502]	eta 10:38:10 lr 0.000002	 wd 0.0000	time 15.3040 (15.3040)	loss 0.8438 (0.8438)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:01:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:13:36 lr 0.000002	 wd 0.0000	time 0.1652 (0.3400)	loss 0.9004 (0.8731)	grad_norm 0.3359 (0.3371)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:02:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:12:36 lr 0.000002	 wd 0.0000	time 0.2072 (0.3286)	loss 0.8428 (0.8791)	grad_norm 0.3372 (0.3368)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:02:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:10:41 lr 0.000002	 wd 0.0000	time 0.1678 (0.2911)	loss 1.0010 (0.8810)	grad_norm 0.3406 (0.3370)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:02:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:09:12 lr 0.000002	 wd 0.0000	time 0.1528 (0.2628)	loss 0.7788 (0.8760)	grad_norm 0.3331 (0.3371)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:03:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:08:12 lr 0.000002	 wd 0.0000	time 0.1640 (0.2459)	loss 0.8770 (0.8784)	grad_norm 0.3277 (0.3372)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:03:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:07:30 lr 0.000002	 wd 0.0000	time 0.3446 (0.2370)	loss 0.9233 (0.8793)	grad_norm 0.3323 (0.3370)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:03:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:26 lr 0.000002	 wd 0.0000	time 0.1585 (0.2475)	loss 0.8613 (0.8785)	grad_norm 0.3328 (0.3367)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:04:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:06:47 lr 0.000002	 wd 0.0000	time 0.1496 (0.2392)	loss 0.8491 (0.8793)	grad_norm 0.3309 (0.3367)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:04:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:12 lr 0.000002	 wd 0.0000	time 0.1455 (0.2326)	loss 0.8213 (0.8792)	grad_norm 0.3362 (0.3366)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:04:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:05:41 lr 0.000002	 wd 0.0000	time 0.1681 (0.2271)	loss 0.8569 (0.8791)	grad_norm 0.3247 (0.3367)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:05:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:31 lr 0.000002	 wd 0.0000	time 0.1688 (0.2365)	loss 0.8125 (0.8773)	grad_norm 0.3389 (0.3366)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:05:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:04 lr 0.000002	 wd 0.0000	time 0.1651 (0.2337)	loss 0.8569 (0.8773)	grad_norm 0.3406 (0.3367)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:06:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:04:35 lr 0.000002	 wd 0.0000	time 0.1732 (0.2293)	loss 0.9634 (0.8777)	grad_norm 0.3460 (0.3367)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:06:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:08 lr 0.000002	 wd 0.0000	time 0.1973 (0.2255)	loss 0.7964 (0.8770)	grad_norm 0.3295 (0.3366)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:06:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:03:43 lr 0.000002	 wd 0.0000	time 0.1955 (0.2232)	loss 0.7837 (0.8771)	grad_norm 0.3458 (0.3367)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:07:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:21 lr 0.000002	 wd 0.0000	time 0.1610 (0.2230)	loss 1.0117 (0.8774)	grad_norm 0.3408 (0.3366)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:07:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:02:57 lr 0.000001	 wd 0.0000	time 0.1675 (0.2213)	loss 0.9341 (0.8774)	grad_norm 0.3482 (0.3365)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:07:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:33 lr 0.000001	 wd 0.0000	time 0.1598 (0.2191)	loss 0.7617 (0.8771)	grad_norm 0.3483 (0.3367)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:07:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:10 lr 0.000001	 wd 0.0000	time 0.1651 (0.2172)	loss 0.8652 (0.8780)	grad_norm 0.3280 (0.3369)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:08:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:01:48 lr 0.000001	 wd 0.0000	time 0.2128 (0.2162)	loss 0.7959 (0.8773)	grad_norm 0.3273 (nan)	loss_scale 32768.0000 (32800.7516)	mem 5928MB
[2024-07-30 14:08:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:27 lr 0.000001	 wd 0.0000	time 0.1828 (0.2166)	loss 0.8433 (0.8770)	grad_norm 0.3505 (nan)	loss_scale 32768.0000 (32799.1928)	mem 5928MB
[2024-07-30 14:09:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:05 lr 0.000001	 wd 0.0000	time 0.1707 (0.2156)	loss 0.8809 (0.8766)	grad_norm 0.3449 (nan)	loss_scale 32768.0000 (32797.7756)	mem 5928MB
[2024-07-30 14:09:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:43 lr 0.000001	 wd 0.0000	time 0.1776 (0.2142)	loss 0.8018 (0.8763)	grad_norm 0.3366 (nan)	loss_scale 32768.0000 (32796.4815)	mem 5928MB
[2024-07-30 14:09:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:21 lr 0.000001	 wd 0.0000	time 0.1667 (0.2128)	loss 0.9741 (0.8759)	grad_norm 0.3342 (nan)	loss_scale 32768.0000 (32795.2953)	mem 5928MB
[2024-07-30 14:09:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1492 (0.2107)	loss 0.8413 (0.8760)	grad_norm 0.3284 (nan)	loss_scale 32768.0000 (32794.2039)	mem 5928MB
[2024-07-30 14:10:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 28 training takes 0:08:57
[2024-07-30 14:10:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 37.737 (37.737)	Loss 0.3577 (0.3577)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 14:10:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.266 Acc@5 97.610
[2024-07-30 14:10:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 14:10:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.27%
[2024-07-30 14:11:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][0/2502]	eta 11:27:29 lr 0.000001	 wd 0.0000	time 16.4867 (16.4867)	loss 0.9468 (0.9468)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:11:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:15:11 lr 0.000001	 wd 0.0000	time 0.2860 (0.3794)	loss 0.8433 (0.8849)	grad_norm 0.3416 (0.3375)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:12:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:12:35 lr 0.000001	 wd 0.0000	time 0.1524 (0.3280)	loss 0.8955 (0.8847)	grad_norm 0.3505 (0.3371)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:12:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:10:11 lr 0.000001	 wd 0.0000	time 0.1786 (0.2778)	loss 0.8481 (0.8846)	grad_norm 0.3303 (0.3362)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:12:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:08:51 lr 0.000001	 wd 0.0000	time 0.1703 (0.2528)	loss 0.8672 (0.8840)	grad_norm 0.3299 (0.3364)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:12:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:07:55 lr 0.000001	 wd 0.0000	time 0.1670 (0.2374)	loss 0.8364 (0.8837)	grad_norm 0.3445 (0.3370)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:13:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:02 lr 0.000001	 wd 0.0000	time 0.1898 (0.2536)	loss 0.7466 (0.8828)	grad_norm 0.3507 (0.3365)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:13:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:22 lr 0.000001	 wd 0.0000	time 0.1729 (0.2453)	loss 0.8413 (0.8819)	grad_norm 0.3267 (0.3366)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:14:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:06:43 lr 0.000001	 wd 0.0000	time 0.1325 (0.2369)	loss 0.8203 (0.8823)	grad_norm 0.3197 (0.3365)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:14:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:06:08 lr 0.000001	 wd 0.0000	time 0.1855 (0.2303)	loss 0.8647 (0.8824)	grad_norm 0.3457 (0.3367)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:14:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:05:40 lr 0.000001	 wd 0.0000	time 0.2117 (0.2268)	loss 0.8281 (0.8826)	grad_norm 0.3537 (0.3366)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:15:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:27 lr 0.000001	 wd 0.0000	time 0.1458 (0.2335)	loss 1.0020 (0.8822)	grad_norm 0.3240 (0.3366)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:15:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:04:58 lr 0.000001	 wd 0.0000	time 0.1805 (0.2291)	loss 0.7593 (0.8810)	grad_norm 0.3467 (0.3368)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:15:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:04:31 lr 0.000001	 wd 0.0000	time 0.1949 (0.2255)	loss 0.8857 (0.8810)	grad_norm 0.3464 (0.3370)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:16:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:04 lr 0.000001	 wd 0.0000	time 0.2041 (0.2221)	loss 0.9692 (0.8809)	grad_norm 0.3460 (0.3369)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:16:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:03:41 lr 0.000001	 wd 0.0000	time 0.1629 (0.2208)	loss 0.8022 (0.8795)	grad_norm 0.3434 (0.3369)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:16:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:19 lr 0.000001	 wd 0.0000	time 0.1714 (0.2211)	loss 0.9106 (0.8788)	grad_norm 0.3351 (0.3369)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:17:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:02:55 lr 0.000001	 wd 0.0000	time 0.1622 (0.2189)	loss 0.9141 (0.8778)	grad_norm 0.3448 (0.3368)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:17:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:32 lr 0.000001	 wd 0.0000	time 0.1945 (0.2168)	loss 0.7651 (0.8773)	grad_norm 0.3267 (0.3367)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:17:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:09 lr 0.000001	 wd 0.0000	time 0.2002 (0.2149)	loss 0.7192 (0.8773)	grad_norm 0.3509 (0.3368)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:18:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:01:47 lr 0.000001	 wd 0.0000	time 0.1916 (0.2145)	loss 0.8442 (0.8777)	grad_norm 0.3362 (0.3366)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:18:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:26 lr 0.000001	 wd 0.0000	time 0.1538 (0.2150)	loss 0.8076 (0.8779)	grad_norm 0.3219 (0.3366)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:18:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:04 lr 0.000001	 wd 0.0000	time 0.1616 (0.2137)	loss 0.7651 (0.8773)	grad_norm 0.3377 (0.3366)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:19:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:42 lr 0.000001	 wd 0.0000	time 0.2081 (0.2125)	loss 0.7251 (0.8776)	grad_norm 0.3513 (0.3367)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:19:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:21 lr 0.000001	 wd 0.0000	time 0.1741 (0.2112)	loss 0.7749 (0.8775)	grad_norm 0.3471 (0.3367)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:19:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1246 (0.2094)	loss 0.9531 (0.8773)	grad_norm 0.3414 (0.3367)	loss_scale 32768.0000 (32768.0000)	mem 5928MB
[2024-07-30 14:19:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 249): INFO EPOCH 29 training takes 0:08:53
[2024-07-30 14:19:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_29.pth saving......
[2024-07-30 14:19:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_29.pth saved !!!
[2024-07-30 14:20:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 289): INFO Test: [0/98]	Time 30.170 (30.170)	Loss 0.3577 (0.3577)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 5928MB
[2024-07-30 14:20:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 296): INFO  * Acc@1 85.250 Acc@5 97.614
[2024-07-30 14:20:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 14:20:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 182): INFO Max accuracy: 85.27%
[2024-07-30 14:20:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2] (main.py 189): INFO Training time 4:53:12
