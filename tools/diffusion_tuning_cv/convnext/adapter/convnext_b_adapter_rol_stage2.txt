[2024-07-31 15:24:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 366): INFO Full config saved to pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/config.json
[2024-07-31 15:24:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_convnext_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 27
    - 3
    DIMS:
    - 128
    - 256
    - 512
    - 1024
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: sequence_stage2
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_conv_b_sequence_stage2
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 0.0001
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 0.8
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.0e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 1.0e-08

[2024-07-31 15:24:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/diffusion_finetune/convnext/adapter_convnext/diffusion_ft_adapter_convnext_base_224_22kto1k_sequence_stage_process2.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/diffusion-ft", "tag": "diffusion_ft_adapter_conv_b_sequence_stage2", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-31 15:24:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 108): INFO Creating model:adapter_convnext_diffusion_finetune/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2
[2024-07-31 15:24:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 110): INFO Adapter_ConvNeXt_Diffusion_Finetune(
  (uma): UMA(filter_strategy1=18, filter_strategy2=6,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): Identity()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (12): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (13): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (14): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (15): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (16): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (17): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (18): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (19): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (20): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (21): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (22): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (23): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (24): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (25): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (26): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (memory_downsampling): ModuleList()
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-31 15:24:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 113): INFO number of params: 4707592
[2024-07-31 15:24:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 150): INFO no checkpoint found in pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2, ignoring auto resume
[2024-07-31 15:24:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth for fine-tuning......
[2024-07-31 15:24:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 127): WARNING <All keys matched successfully>
[2024-07-31 15:24:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth'
[2024-07-31 15:26:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 70.928 (70.928)	Loss 0.3567 (0.3567)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 3076MB
[2024-07-31 15:26:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.936 Acc@5 97.482
[2024-07-31 15:26:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 162): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 15:26:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 168): INFO Start training
[2024-07-31 15:26:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][0/2502]	eta 15:30:29 lr 0.000100	 wd 0.0000	time 22.3140 (22.3140)	loss 0.8784 (0.8784)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 7951MB
[2024-07-31 15:27:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:22:30 lr 0.000100	 wd 0.0000	time 0.2981 (0.5622)	loss 0.8271 (0.8833)	grad_norm 0.3700 (nan)	loss_scale 32768.0000 (33092.4356)	mem 7951MB
[2024-07-31 15:27:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:15:22 lr 0.000100	 wd 0.0000	time 0.1769 (0.4006)	loss 0.8589 (0.8886)	grad_norm 0.3430 (nan)	loss_scale 32768.0000 (32931.0249)	mem 7951MB
[2024-07-31 15:27:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:18 lr 0.000100	 wd 0.0000	time 0.1974 (0.3356)	loss 0.9082 (0.8919)	grad_norm 0.3695 (nan)	loss_scale 32768.0000 (32876.8638)	mem 7951MB
[2024-07-31 15:28:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:34 lr 0.000100	 wd 0.0000	time 0.2273 (0.3018)	loss 1.2412 (0.8917)	grad_norm 0.3488 (nan)	loss_scale 32768.0000 (32849.7157)	mem 7951MB
[2024-07-31 15:28:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:10:37 lr 0.000100	 wd 0.0000	time 0.2668 (0.3187)	loss 0.8154 (0.8917)	grad_norm 0.3288 (nan)	loss_scale 32768.0000 (32833.4052)	mem 7951MB
[2024-07-31 15:29:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:40 lr 0.000100	 wd 0.0000	time 0.1858 (0.3050)	loss 0.9824 (0.8916)	grad_norm 0.3420 (nan)	loss_scale 32768.0000 (32822.5225)	mem 7951MB
[2024-07-31 15:29:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:44 lr 0.000100	 wd 0.0000	time 0.2019 (0.2910)	loss 0.8335 (0.8886)	grad_norm 0.3183 (nan)	loss_scale 32768.0000 (32814.7447)	mem 7951MB
[2024-07-31 15:30:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:58 lr 0.000100	 wd 0.0000	time 0.2271 (0.2811)	loss 0.9165 (0.8898)	grad_norm 0.3163 (nan)	loss_scale 32768.0000 (32808.9089)	mem 7951MB
[2024-07-31 15:30:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:44 lr 0.000100	 wd 0.0000	time 0.2180 (0.2897)	loss 1.0674 (0.8883)	grad_norm 0.3304 (nan)	loss_scale 32768.0000 (32804.3685)	mem 7951MB
[2024-07-31 15:30:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:07:03 lr 0.000100	 wd 0.0000	time 0.1984 (0.2822)	loss 0.8784 (0.8883)	grad_norm 0.3386 (nan)	loss_scale 32768.0000 (32800.7353)	mem 7951MB
[2024-07-31 15:31:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:26 lr 0.000100	 wd 0.0000	time 0.2017 (0.2753)	loss 0.8042 (0.8879)	grad_norm 0.3533 (nan)	loss_scale 32768.0000 (32797.7620)	mem 7951MB
[2024-07-31 15:31:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:51 lr 0.000100	 wd 0.0000	time 0.2667 (0.2701)	loss 0.7671 (0.8879)	grad_norm 0.3302 (nan)	loss_scale 32768.0000 (32795.2839)	mem 7951MB
[2024-07-31 15:32:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:30 lr 0.000100	 wd 0.0000	time 0.1863 (0.2753)	loss 0.8579 (0.8893)	grad_norm 0.3405 (nan)	loss_scale 32768.0000 (32793.1868)	mem 7951MB
[2024-07-31 15:32:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:57 lr 0.000100	 wd 0.0000	time 0.1831 (0.2703)	loss 0.8828 (0.8894)	grad_norm 0.3478 (nan)	loss_scale 32768.0000 (32791.3890)	mem 7951MB
[2024-07-31 15:32:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:26 lr 0.000100	 wd 0.0000	time 0.1816 (0.2661)	loss 0.9590 (0.8900)	grad_norm 0.3430 (nan)	loss_scale 32768.0000 (32789.8308)	mem 7951MB
[2024-07-31 15:33:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:56 lr 0.000100	 wd 0.0000	time 0.2005 (0.2625)	loss 1.0615 (0.8908)	grad_norm 0.3414 (nan)	loss_scale 32768.0000 (32788.4672)	mem 7951MB
[2024-07-31 15:33:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:29 lr 0.000100	 wd 0.0000	time 0.1983 (0.2616)	loss 0.8804 (0.8909)	grad_norm 0.3288 (nan)	loss_scale 32768.0000 (32787.2640)	mem 7951MB
[2024-07-31 15:34:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:03:02 lr 0.000100	 wd 0.0000	time 0.1936 (0.2594)	loss 0.8667 (0.8908)	grad_norm 0.3696 (nan)	loss_scale 32768.0000 (32786.1943)	mem 7951MB
[2024-07-31 15:34:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:34 lr 0.000100	 wd 0.0000	time 0.2097 (0.2568)	loss 0.9775 (0.8910)	grad_norm 0.3239 (nan)	loss_scale 32768.0000 (32785.2372)	mem 7951MB
[2024-07-31 15:34:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:07 lr 0.000100	 wd 0.0000	time 0.1995 (0.2545)	loss 0.9331 (0.8911)	grad_norm 0.3436 (nan)	loss_scale 32768.0000 (32784.3758)	mem 7951MB
[2024-07-31 15:35:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:41 lr 0.000100	 wd 0.0000	time 0.2113 (0.2531)	loss 0.8887 (0.8914)	grad_norm 0.3253 (nan)	loss_scale 32768.0000 (32783.5964)	mem 7951MB
[2024-07-31 15:35:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:16 lr 0.000100	 wd 0.0000	time 0.1875 (0.2523)	loss 1.0078 (0.8911)	grad_norm 0.3386 (nan)	loss_scale 32768.0000 (32782.8878)	mem 7951MB
[2024-07-31 15:35:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:50 lr 0.000100	 wd 0.0000	time 0.2179 (0.2505)	loss 1.0068 (0.8910)	grad_norm 0.3444 (nan)	loss_scale 32768.0000 (32782.2408)	mem 7951MB
[2024-07-31 15:36:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:25 lr 0.000100	 wd 0.0000	time 0.2233 (0.2487)	loss 1.0566 (0.8912)	grad_norm 0.3325 (nan)	loss_scale 32768.0000 (32781.6476)	mem 7951MB
[2024-07-31 15:36:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000100	 wd 0.0000	time 0.1584 (0.2462)	loss 0.8794 (0.8910)	grad_norm 0.3225 (nan)	loss_scale 32768.0000 (32781.1020)	mem 7951MB
[2024-07-31 15:36:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 0 training takes 0:10:20
[2024-07-31 15:36:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_0.pth saving......
[2024-07-31 15:36:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_0.pth saved !!!
[2024-07-31 15:37:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 55.725 (55.725)	Loss 0.3667 (0.3667)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 15:37:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.962 Acc@5 97.522
[2024-07-31 15:37:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-31 15:37:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.96%
[2024-07-31 15:37:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-31 15:37:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-31 15:38:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][0/2502]	eta 12:54:31 lr 0.000100	 wd 0.0000	time 18.5736 (18.5736)	loss 0.7710 (0.7710)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:38:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:19:13 lr 0.000100	 wd 0.0000	time 0.1739 (0.4804)	loss 0.8301 (0.8768)	grad_norm 0.3337 (0.3289)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:38:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:13:10 lr 0.000100	 wd 0.0000	time 0.1920 (0.3432)	loss 0.7861 (0.8828)	grad_norm 0.3289 (0.3284)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:39:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:10:54 lr 0.000100	 wd 0.0000	time 0.1993 (0.2973)	loss 0.9214 (0.8845)	grad_norm 0.3294 (0.3286)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:39:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:09:34 lr 0.000100	 wd 0.0000	time 0.2034 (0.2735)	loss 0.8828 (0.8857)	grad_norm 0.3366 (0.3297)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:40:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:09:26 lr 0.000100	 wd 0.0000	time 0.2224 (0.2831)	loss 0.8232 (0.8844)	grad_norm 0.3297 (0.3300)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:40:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:08:35 lr 0.000100	 wd 0.0000	time 0.1720 (0.2711)	loss 0.9043 (0.8861)	grad_norm 0.3419 (0.3297)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:40:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:07:50 lr 0.000100	 wd 0.0000	time 0.1775 (0.2611)	loss 0.8286 (0.8853)	grad_norm 0.3284 (0.3298)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:41:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:12 lr 0.000100	 wd 0.0000	time 0.2043 (0.2542)	loss 1.0254 (0.8867)	grad_norm 0.3261 (0.3294)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:41:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:02 lr 0.000099	 wd 0.0000	time 0.2769 (0.2637)	loss 0.8672 (0.8866)	grad_norm 0.3303 (0.3292)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:42:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:28 lr 0.000099	 wd 0.0000	time 0.1882 (0.2586)	loss 0.8862 (0.8867)	grad_norm 0.3322 (0.3292)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:42:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:05:55 lr 0.000099	 wd 0.0000	time 0.1981 (0.2539)	loss 0.9658 (0.8878)	grad_norm 0.3394 (0.3293)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:42:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:25 lr 0.000099	 wd 0.0000	time 0.2146 (0.2497)	loss 0.8467 (0.8877)	grad_norm 0.3339 (0.3296)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:43:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:04:58 lr 0.000099	 wd 0.0000	time 0.2329 (0.2480)	loss 0.8579 (0.8884)	grad_norm 0.3366 (0.3297)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:43:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:32 lr 0.000099	 wd 0.0000	time 0.1916 (0.2475)	loss 0.8843 (0.8887)	grad_norm 0.3298 (0.3297)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:43:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:05 lr 0.000099	 wd 0.0000	time 0.1934 (0.2450)	loss 0.8901 (0.8896)	grad_norm 0.3210 (0.3298)	loss_scale 65536.0000 (32811.6616)	mem 7951MB
[2024-07-31 15:44:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:39 lr 0.000099	 wd 0.0000	time 0.2055 (0.2428)	loss 0.8223 (0.8894)	grad_norm 0.3028 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7951MB
[2024-07-31 15:44:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:13 lr 0.000099	 wd 0.0000	time 0.2310 (0.2412)	loss 0.7832 (0.8894)	grad_norm 0.3316 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7951MB
[2024-07-31 15:45:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:49 lr 0.000099	 wd 0.0000	time 0.1742 (0.2415)	loss 0.9839 (0.8894)	grad_norm 0.3183 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7951MB
[2024-07-31 15:45:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:24 lr 0.000099	 wd 0.0000	time 0.2112 (0.2402)	loss 0.9053 (0.8897)	grad_norm 0.3131 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7951MB
[2024-07-31 15:45:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:01:59 lr 0.000099	 wd 0.0000	time 0.1983 (0.2388)	loss 0.7920 (0.8897)	grad_norm 0.3380 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7951MB
[2024-07-31 15:46:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:35 lr 0.000099	 wd 0.0000	time 0.1837 (0.2373)	loss 0.8379 (0.8896)	grad_norm 0.3405 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7951MB
[2024-07-31 15:46:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:11 lr 0.000099	 wd 0.0000	time 0.3181 (0.2369)	loss 0.7715 (0.8890)	grad_norm 0.3059 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7951MB
[2024-07-31 15:46:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:47 lr 0.000099	 wd 0.0000	time 0.1885 (0.2368)	loss 0.9395 (0.8897)	grad_norm 0.3245 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7951MB
[2024-07-31 15:47:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:24 lr 0.000099	 wd 0.0000	time 0.2031 (0.2357)	loss 0.9121 (0.8898)	grad_norm 0.3351 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7951MB
[2024-07-31 15:47:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000099	 wd 0.0000	time 0.1561 (0.2337)	loss 0.9067 (0.8901)	grad_norm 0.3373 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7951MB
[2024-07-31 15:47:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 1 training takes 0:09:48
[2024-07-31 15:48:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 39.218 (39.218)	Loss 0.3667 (0.3667)	Acc@1 91.211 (91.211)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 15:48:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 84.876 Acc@5 97.562
[2024-07-31 15:48:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-31 15:48:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 84.96%
[2024-07-31 15:48:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][0/2502]	eta 12:01:04 lr 0.000099	 wd 0.0000	time 17.2921 (17.2921)	loss 0.7974 (0.7974)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:49:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:14:57 lr 0.000099	 wd 0.0000	time 0.2085 (0.3737)	loss 0.9810 (0.8878)	grad_norm 0.3320 (0.3253)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:49:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:11:13 lr 0.000099	 wd 0.0000	time 0.2169 (0.2924)	loss 0.9526 (0.8860)	grad_norm 0.3311 (0.3259)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:49:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:10:58 lr 0.000099	 wd 0.0000	time 0.2066 (0.2991)	loss 0.8135 (0.8819)	grad_norm 0.3422 (0.3260)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:50:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:09:38 lr 0.000099	 wd 0.0000	time 0.1927 (0.2752)	loss 0.9707 (0.8834)	grad_norm 0.3113 (0.3266)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:50:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:08:41 lr 0.000099	 wd 0.0000	time 0.1903 (0.2606)	loss 0.9326 (0.8894)	grad_norm 0.3383 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:51:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:07:58 lr 0.000099	 wd 0.0000	time 0.1897 (0.2515)	loss 0.8018 (0.8893)	grad_norm 0.3354 (0.3266)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:51:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:08:03 lr 0.000099	 wd 0.0000	time 0.2590 (0.2686)	loss 0.8672 (0.8889)	grad_norm 0.3294 (0.3267)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:51:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:25 lr 0.000099	 wd 0.0000	time 0.2314 (0.2617)	loss 0.7954 (0.8873)	grad_norm 0.3294 (0.3266)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:52:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:49 lr 0.000098	 wd 0.0000	time 0.1943 (0.2558)	loss 0.9258 (0.8874)	grad_norm 0.3495 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:52:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:18 lr 0.000098	 wd 0.0000	time 0.2297 (0.2519)	loss 0.8027 (0.8864)	grad_norm 0.3229 (0.3266)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:53:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:52 lr 0.000098	 wd 0.0000	time 0.1907 (0.2518)	loss 0.9106 (0.8865)	grad_norm 0.3269 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:53:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:23 lr 0.000098	 wd 0.0000	time 0.1731 (0.2484)	loss 1.0332 (0.8868)	grad_norm 0.3363 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:53:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:04:55 lr 0.000098	 wd 0.0000	time 0.2062 (0.2455)	loss 0.8921 (0.8878)	grad_norm 0.3394 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:54:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:27 lr 0.000098	 wd 0.0000	time 0.2183 (0.2428)	loss 0.9321 (0.8879)	grad_norm 0.3186 (0.3267)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:54:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:02 lr 0.000098	 wd 0.0000	time 0.2377 (0.2422)	loss 1.0635 (0.8884)	grad_norm 0.3204 (0.3267)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:54:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:38 lr 0.000098	 wd 0.0000	time 0.2063 (0.2418)	loss 0.9517 (0.8880)	grad_norm 0.3215 (0.3269)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:55:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:12 lr 0.000098	 wd 0.0000	time 0.1970 (0.2399)	loss 0.8916 (0.8887)	grad_norm 0.3380 (0.3270)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:55:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:47 lr 0.000098	 wd 0.0000	time 0.2039 (0.2382)	loss 0.8711 (0.8885)	grad_norm 0.3102 (0.3271)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:56:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:22 lr 0.000098	 wd 0.0000	time 0.2335 (0.2373)	loss 0.8047 (0.8891)	grad_norm 0.3269 (0.3272)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:56:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:01:59 lr 0.000098	 wd 0.0000	time 0.2157 (0.2376)	loss 0.9067 (0.8891)	grad_norm 0.3113 (0.3271)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:56:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:35 lr 0.000098	 wd 0.0000	time 0.1985 (0.2367)	loss 0.9692 (0.8898)	grad_norm 0.3323 (0.3272)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:57:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:11 lr 0.000098	 wd 0.0000	time 0.1785 (0.2357)	loss 0.8750 (0.8896)	grad_norm 0.3254 (0.3271)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:57:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:47 lr 0.000098	 wd 0.0000	time 0.2130 (0.2347)	loss 0.8281 (0.8895)	grad_norm 0.3416 (0.3271)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:57:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:23 lr 0.000098	 wd 0.0000	time 0.2510 (0.2348)	loss 0.8647 (0.8899)	grad_norm 0.3317 (0.3271)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:58:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000098	 wd 0.0000	time 0.1583 (0.2331)	loss 0.8955 (0.8896)	grad_norm 0.3379 (0.3271)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:58:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 2 training takes 0:09:48
[2024-07-31 15:58:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 23.921 (23.921)	Loss 0.3633 (0.3633)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 15:58:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.088 Acc@5 97.540
[2024-07-31 15:58:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-31 15:58:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.09%
[2024-07-31 15:58:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-31 15:58:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-31 15:59:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][0/2502]	eta 23:31:55 lr 0.000098	 wd 0.0000	time 33.8590 (33.8590)	loss 0.7466 (0.7466)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 15:59:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:22:05 lr 0.000098	 wd 0.0000	time 0.2008 (0.5518)	loss 1.0068 (0.8865)	grad_norm 0.3398 (0.3308)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:00:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:14:29 lr 0.000097	 wd 0.0000	time 0.1726 (0.3777)	loss 1.0264 (0.8829)	grad_norm 0.3365 (0.3294)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:00:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:11:43 lr 0.000097	 wd 0.0000	time 0.1852 (0.3196)	loss 1.0322 (0.8844)	grad_norm 0.3324 (0.3288)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:00:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:10:36 lr 0.000097	 wd 0.0000	time 0.2659 (0.3026)	loss 0.9917 (0.8838)	grad_norm 0.3112 (0.3279)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:01:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:10:10 lr 0.000097	 wd 0.0000	time 0.2205 (0.3049)	loss 0.9038 (0.8850)	grad_norm nan (nan)	loss_scale 32768.0000 (32898.8104)	mem 7951MB
[2024-07-31 16:01:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:09:08 lr 0.000097	 wd 0.0000	time 0.2002 (0.2885)	loss 0.8291 (0.8853)	grad_norm 0.3508 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7951MB
[2024-07-31 16:02:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:08:17 lr 0.000097	 wd 0.0000	time 0.1746 (0.2761)	loss 0.9268 (0.8864)	grad_norm 0.3222 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7951MB
[2024-07-31 16:02:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:42 lr 0.000097	 wd 0.0000	time 0.3401 (0.2717)	loss 0.8594 (0.8851)	grad_norm 0.3362 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7951MB
[2024-07-31 16:03:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:07:23 lr 0.000097	 wd 0.0000	time 0.1684 (0.2771)	loss 0.9038 (0.8857)	grad_norm 0.3312 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7951MB
[2024-07-31 16:03:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:45 lr 0.000097	 wd 0.0000	time 0.1704 (0.2699)	loss 1.0557 (0.8873)	grad_norm 0.3635 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7951MB
[2024-07-31 16:03:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:06:09 lr 0.000097	 wd 0.0000	time 0.1821 (0.2638)	loss 0.7842 (0.8869)	grad_norm 0.3442 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7951MB
[2024-07-31 16:04:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:52 lr 0.000097	 wd 0.0000	time 5.9147 (0.2704)	loss 0.9336 (0.8862)	grad_norm 0.3204 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7951MB
[2024-07-31 16:04:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:05:20 lr 0.000097	 wd 0.0000	time 0.1846 (0.2666)	loss 0.9824 (0.8873)	grad_norm 0.3155 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7951MB
[2024-07-31 16:05:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:49 lr 0.000097	 wd 0.0000	time 0.1721 (0.2623)	loss 0.8506 (0.8871)	grad_norm 0.3192 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7951MB
[2024-07-31 16:05:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:18 lr 0.000097	 wd 0.0000	time 0.1956 (0.2584)	loss 0.8193 (0.8882)	grad_norm 0.3102 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7951MB
[2024-07-31 16:05:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:51 lr 0.000096	 wd 0.0000	time 0.2340 (0.2563)	loss 0.8643 (0.8874)	grad_norm 0.3309 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7951MB
[2024-07-31 16:06:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:25 lr 0.000096	 wd 0.0000	time 0.2281 (0.2559)	loss 0.9272 (0.8873)	grad_norm 0.3325 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7951MB
[2024-07-31 16:06:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:57 lr 0.000096	 wd 0.0000	time 0.2069 (0.2533)	loss 0.8877 (0.8874)	grad_norm 0.3093 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7951MB
[2024-07-31 16:06:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:31 lr 0.000096	 wd 0.0000	time 0.1947 (0.2511)	loss 0.8950 (0.8869)	grad_norm 0.3139 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7951MB
[2024-07-31 16:07:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:05 lr 0.000096	 wd 0.0000	time 0.2373 (0.2494)	loss 0.8599 (0.8874)	grad_norm 0.3172 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7951MB
[2024-07-31 16:07:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:40 lr 0.000096	 wd 0.0000	time 0.1746 (0.2495)	loss 0.7197 (0.8869)	grad_norm 0.3359 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7951MB
[2024-07-31 16:08:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:14 lr 0.000096	 wd 0.0000	time 0.2054 (0.2480)	loss 0.8325 (0.8867)	grad_norm 0.3321 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7951MB
[2024-07-31 16:08:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:49 lr 0.000096	 wd 0.0000	time 0.1771 (0.2464)	loss 0.9619 (0.8869)	grad_norm 0.3317 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7951MB
[2024-07-31 16:08:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:24 lr 0.000096	 wd 0.0000	time 0.2515 (0.2449)	loss 0.8330 (0.8869)	grad_norm 0.3162 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7951MB
[2024-07-31 16:09:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000096	 wd 0.0000	time 0.1586 (0.2429)	loss 0.8130 (0.8875)	grad_norm 0.3351 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7951MB
[2024-07-31 16:09:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 3 training takes 0:10:15
[2024-07-31 16:09:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 29.332 (29.332)	Loss 0.3689 (0.3689)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 7951MB
[2024-07-31 16:09:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.028 Acc@5 97.556
[2024-07-31 16:09:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.0%
[2024-07-31 16:09:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.09%
[2024-07-31 16:10:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][0/2502]	eta 12:08:05 lr 0.000096	 wd 0.0000	time 17.4602 (17.4602)	loss 0.8975 (0.8975)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:10:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:15:44 lr 0.000096	 wd 0.0000	time 0.2505 (0.3932)	loss 0.7930 (0.8916)	grad_norm 0.3269 (0.3281)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:10:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:12:03 lr 0.000096	 wd 0.0000	time 0.1780 (0.3143)	loss 0.9209 (0.8884)	grad_norm 0.3085 (0.3268)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:11:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:10:12 lr 0.000095	 wd 0.0000	time 0.2184 (0.2782)	loss 0.8892 (0.8884)	grad_norm 0.3395 (0.3273)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:11:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:09:06 lr 0.000095	 wd 0.0000	time 0.1882 (0.2598)	loss 0.8677 (0.8838)	grad_norm 0.3135 (0.3276)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:11:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:08:17 lr 0.000095	 wd 0.0000	time 0.1863 (0.2483)	loss 0.9434 (0.8856)	grad_norm 0.3176 (0.3275)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:12:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:07:49 lr 0.000095	 wd 0.0000	time 0.2448 (0.2466)	loss 0.8398 (0.8879)	grad_norm 0.3409 (0.3276)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:12:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:07:19 lr 0.000095	 wd 0.0000	time 0.1862 (0.2440)	loss 0.9854 (0.8847)	grad_norm 0.3235 (0.3275)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:13:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:06:47 lr 0.000095	 wd 0.0000	time 0.2244 (0.2395)	loss 0.8579 (0.8851)	grad_norm 0.3327 (0.3273)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:13:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:06:17 lr 0.000095	 wd 0.0000	time 0.1841 (0.2357)	loss 0.8599 (0.8863)	grad_norm 0.3315 (0.3272)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:13:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:05:51 lr 0.000095	 wd 0.0000	time 0.2206 (0.2343)	loss 0.9121 (0.8864)	grad_norm 0.3283 (0.3275)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:14:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:05:28 lr 0.000095	 wd 0.0000	time 0.1757 (0.2346)	loss 0.9375 (0.8880)	grad_norm 0.3421 (0.3277)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:14:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:02 lr 0.000095	 wd 0.0000	time 0.2040 (0.2325)	loss 0.7427 (0.8878)	grad_norm 0.3195 (0.3276)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:14:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:04:37 lr 0.000095	 wd 0.0000	time 0.1819 (0.2308)	loss 0.8423 (0.8871)	grad_norm 0.3246 (0.3274)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:15:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:12 lr 0.000094	 wd 0.0000	time 0.1973 (0.2293)	loss 0.8984 (0.8867)	grad_norm 0.3335 (0.3276)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:15:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:03:50 lr 0.000094	 wd 0.0000	time 0.1970 (0.2299)	loss 0.7490 (0.8868)	grad_norm 0.3275 (0.3278)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:15:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:26 lr 0.000094	 wd 0.0000	time 0.1801 (0.2291)	loss 0.8433 (0.8867)	grad_norm 0.3207 (0.3278)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:16:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:02 lr 0.000094	 wd 0.0000	time 0.1950 (0.2281)	loss 1.0703 (0.8864)	grad_norm 0.3328 (0.3279)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:16:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:39 lr 0.000094	 wd 0.0000	time 0.1802 (0.2269)	loss 0.9360 (0.8869)	grad_norm 0.3193 (0.3279)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:17:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:16 lr 0.000094	 wd 0.0000	time 0.2391 (0.2267)	loss 0.8955 (0.8868)	grad_norm 0.3187 (0.3278)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:17:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:01:54 lr 0.000094	 wd 0.0000	time 0.2681 (0.2280)	loss 0.7803 (0.8863)	grad_norm nan (nan)	loss_scale 32768.0000 (32800.7516)	mem 7951MB
[2024-07-31 16:17:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:31 lr 0.000094	 wd 0.0000	time 0.1884 (0.2271)	loss 0.8325 (0.8871)	grad_norm 0.3461 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7951MB
[2024-07-31 16:18:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:08 lr 0.000094	 wd 0.0000	time 0.2242 (0.2263)	loss 0.9902 (0.8866)	grad_norm 0.3000 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7951MB
[2024-07-31 16:18:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:45 lr 0.000094	 wd 0.0000	time 0.2336 (0.2258)	loss 0.8599 (0.8870)	grad_norm 0.3283 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7951MB
[2024-07-31 16:18:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:23 lr 0.000093	 wd 0.0000	time 0.1650 (0.2261)	loss 0.8350 (0.8872)	grad_norm 0.3113 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7951MB
[2024-07-31 16:19:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000093	 wd 0.0000	time 0.1567 (0.2245)	loss 0.7681 (0.8872)	grad_norm 0.3262 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7951MB
[2024-07-31 16:19:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 4 training takes 0:09:26
[2024-07-31 16:19:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 19.335 (19.335)	Loss 0.3611 (0.3611)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 16:19:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.112 Acc@5 97.552
[2024-07-31 16:19:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-31 16:19:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.11%
[2024-07-31 16:19:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-31 16:19:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-31 16:20:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][0/2502]	eta 12:55:54 lr 0.000093	 wd 0.0000	time 18.6071 (18.6071)	loss 0.8721 (0.8721)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:20:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:17:07 lr 0.000093	 wd 0.0000	time 0.1927 (0.4278)	loss 0.9253 (0.8771)	grad_norm 0.3457 (0.3282)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:20:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:12:08 lr 0.000093	 wd 0.0000	time 0.1743 (0.3166)	loss 0.7876 (0.8815)	grad_norm 0.3332 (0.3297)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:21:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:13 lr 0.000093	 wd 0.0000	time 0.1751 (0.2787)	loss 0.9985 (0.8804)	grad_norm 0.3233 (0.3290)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:21:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:04 lr 0.000093	 wd 0.0000	time 0.2038 (0.2592)	loss 0.9365 (0.8799)	grad_norm 0.3350 (0.3296)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:21:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:08:26 lr 0.000093	 wd 0.0000	time 0.2024 (0.2532)	loss 0.8403 (0.8800)	grad_norm 0.3477 (0.3292)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:22:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:07:53 lr 0.000093	 wd 0.0000	time 0.2200 (0.2492)	loss 0.8491 (0.8829)	grad_norm 0.3325 (0.3293)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:22:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:17 lr 0.000093	 wd 0.0000	time 0.1884 (0.2429)	loss 0.7964 (0.8822)	grad_norm 0.3500 (0.3294)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:23:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:06:45 lr 0.000093	 wd 0.0000	time 0.1949 (0.2384)	loss 0.8379 (0.8820)	grad_norm 0.3356 (0.3296)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:23:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:17 lr 0.000092	 wd 0.0000	time 0.2434 (0.2358)	loss 0.9272 (0.8825)	grad_norm 0.3321 (0.3297)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:23:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:03 lr 0.000092	 wd 0.0000	time 0.1844 (0.2419)	loss 0.9238 (0.8844)	grad_norm 0.3252 (0.3298)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:24:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:34 lr 0.000092	 wd 0.0000	time 0.1814 (0.2386)	loss 0.8281 (0.8855)	grad_norm 0.3274 (0.3299)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:24:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:06 lr 0.000092	 wd 0.0000	time 0.2093 (0.2357)	loss 0.9121 (0.8862)	grad_norm 0.3212 (0.3300)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:24:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:40 lr 0.000092	 wd 0.0000	time 0.2204 (0.2337)	loss 0.9561 (0.8855)	grad_norm 0.3406 (0.3297)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:25:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:18 lr 0.000092	 wd 0.0000	time 0.1805 (0.2345)	loss 0.8638 (0.8847)	grad_norm 0.3373 (0.3296)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:25:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:03:53 lr 0.000092	 wd 0.0000	time 0.1803 (0.2333)	loss 0.8564 (0.8854)	grad_norm 0.3288 (0.3296)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:26:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:29 lr 0.000092	 wd 0.0000	time 0.2026 (0.2319)	loss 0.8086 (0.8859)	grad_norm 0.3475 (0.3297)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:26:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:04 lr 0.000092	 wd 0.0000	time 0.1949 (0.2304)	loss 0.8818 (0.8864)	grad_norm 0.3197 (0.3299)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:26:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:41 lr 0.000091	 wd 0.0000	time 0.2055 (0.2299)	loss 0.8774 (0.8857)	grad_norm 0.3420 (0.3300)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:27:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:19 lr 0.000091	 wd 0.0000	time 0.2301 (0.2310)	loss 0.8701 (0.8856)	grad_norm 0.3266 (0.3301)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:27:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:01:55 lr 0.000091	 wd 0.0000	time 0.1666 (0.2300)	loss 0.9712 (0.8861)	grad_norm 0.3361 (0.3303)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:27:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:32 lr 0.000091	 wd 0.0000	time 0.2124 (0.2290)	loss 0.9819 (0.8856)	grad_norm 0.3379 (0.3304)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:28:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:08 lr 0.000091	 wd 0.0000	time 0.1859 (0.2284)	loss 0.9990 (0.8856)	grad_norm 0.3319 (0.3303)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:28:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:46 lr 0.000091	 wd 0.0000	time 0.2244 (0.2286)	loss 0.7563 (0.8854)	grad_norm 0.3522 (0.3305)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:28:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:23 lr 0.000091	 wd 0.0000	time 0.1738 (0.2282)	loss 0.7900 (0.8851)	grad_norm 0.3440 (0.3305)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:29:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000091	 wd 0.0000	time 0.1586 (0.2264)	loss 0.7754 (0.8846)	grad_norm 0.3262 (0.3304)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:29:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 5 training takes 0:09:30
[2024-07-31 16:29:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 21.065 (21.065)	Loss 0.3586 (0.3586)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7951MB
[2024-07-31 16:29:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.066 Acc@5 97.578
[2024-07-31 16:29:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-31 16:29:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.11%
[2024-07-31 16:30:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][0/2502]	eta 23:32:42 lr 0.000091	 wd 0.0000	time 33.8777 (33.8777)	loss 0.9355 (0.9355)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:30:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:21:30 lr 0.000090	 wd 0.0000	time 0.2111 (0.5371)	loss 0.8721 (0.8950)	grad_norm 0.3483 (0.3306)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:31:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:14:13 lr 0.000090	 wd 0.0000	time 0.1735 (0.3708)	loss 0.8013 (0.8884)	grad_norm 0.3367 (0.3308)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:31:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:11:48 lr 0.000090	 wd 0.0000	time 0.2514 (0.3216)	loss 0.8911 (0.8881)	grad_norm 0.3333 (0.3310)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:32:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:11:02 lr 0.000090	 wd 0.0000	time 0.1873 (0.3152)	loss 0.8599 (0.8865)	grad_norm 0.3216 (0.3311)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:32:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:09:45 lr 0.000090	 wd 0.0000	time 0.1983 (0.2925)	loss 0.9209 (0.8863)	grad_norm 0.3175 (0.3312)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:32:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:08:47 lr 0.000090	 wd 0.0000	time 0.2343 (0.2774)	loss 0.8921 (0.8859)	grad_norm 0.3477 (0.3315)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:33:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:08:03 lr 0.000090	 wd 0.0000	time 0.1799 (0.2685)	loss 0.9932 (0.8859)	grad_norm 0.3384 (0.3319)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:33:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:40 lr 0.000090	 wd 0.0000	time 0.1749 (0.2705)	loss 0.7329 (0.8861)	grad_norm 0.3295 (0.3316)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:33:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:07:01 lr 0.000089	 wd 0.0000	time 0.1803 (0.2634)	loss 0.8809 (0.8855)	grad_norm 0.3179 (0.3316)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:34:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:26 lr 0.000089	 wd 0.0000	time 0.1855 (0.2576)	loss 0.8481 (0.8865)	grad_norm 0.3342 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7951MB
[2024-07-31 16:34:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:54 lr 0.000089	 wd 0.0000	time 0.1919 (0.2530)	loss 0.8154 (0.8852)	grad_norm 0.3303 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7951MB
[2024-07-31 16:34:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:27 lr 0.000089	 wd 0.0000	time 0.2170 (0.2514)	loss 0.8472 (0.8854)	grad_norm 0.3335 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7951MB
[2024-07-31 16:35:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:04:59 lr 0.000089	 wd 0.0000	time 0.2199 (0.2492)	loss 0.7896 (0.8847)	grad_norm 0.3223 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7951MB
[2024-07-31 16:35:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:31 lr 0.000089	 wd 0.0000	time 0.2024 (0.2462)	loss 0.9141 (0.8843)	grad_norm 0.3218 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7951MB
[2024-07-31 16:36:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:04 lr 0.000089	 wd 0.0000	time 0.2221 (0.2437)	loss 0.7881 (0.8842)	grad_norm 0.3255 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7951MB
[2024-07-31 16:36:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:38 lr 0.000089	 wd 0.0000	time 0.2361 (0.2421)	loss 0.7959 (0.8838)	grad_norm 0.3179 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7951MB
[2024-07-31 16:36:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:14 lr 0.000088	 wd 0.0000	time 0.1926 (0.2420)	loss 0.8477 (0.8826)	grad_norm 0.3253 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7951MB
[2024-07-31 16:37:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:48 lr 0.000088	 wd 0.0000	time 0.2647 (0.2403)	loss 0.8198 (0.8825)	grad_norm 0.3265 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7951MB
[2024-07-31 16:37:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:23 lr 0.000088	 wd 0.0000	time 0.1727 (0.2387)	loss 0.9067 (0.8829)	grad_norm 0.3281 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7951MB
[2024-07-31 16:37:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:01:59 lr 0.000088	 wd 0.0000	time 0.2055 (0.2372)	loss 0.9341 (0.8835)	grad_norm 0.3329 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7951MB
[2024-07-31 16:38:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:35 lr 0.000088	 wd 0.0000	time 0.1764 (0.2370)	loss 0.8032 (0.8835)	grad_norm 0.3321 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7951MB
[2024-07-31 16:38:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:11 lr 0.000088	 wd 0.0000	time 0.2391 (0.2366)	loss 0.8955 (0.8829)	grad_norm 0.3366 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7951MB
[2024-07-31 16:38:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:47 lr 0.000088	 wd 0.0000	time 0.1774 (0.2355)	loss 0.8354 (0.8829)	grad_norm 0.3302 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7951MB
[2024-07-31 16:39:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:23 lr 0.000087	 wd 0.0000	time 0.2110 (0.2343)	loss 0.8784 (0.8835)	grad_norm 0.3112 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7951MB
[2024-07-31 16:39:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000087	 wd 0.0000	time 0.1659 (0.2325)	loss 0.7812 (0.8841)	grad_norm 0.3408 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7951MB
[2024-07-31 16:39:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 6 training takes 0:09:46
[2024-07-31 16:40:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 35.276 (35.276)	Loss 0.3591 (0.3591)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7951MB
[2024-07-31 16:40:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.084 Acc@5 97.582
[2024-07-31 16:40:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-31 16:40:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.11%
[2024-07-31 16:40:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][0/2502]	eta 11:29:30 lr 0.000087	 wd 0.0000	time 16.5350 (16.5350)	loss 0.8516 (0.8516)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:41:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:15:05 lr 0.000087	 wd 0.0000	time 0.2134 (0.3771)	loss 0.9722 (0.8821)	grad_norm 0.3240 (0.3323)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:41:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:12:46 lr 0.000087	 wd 0.0000	time 0.1843 (0.3332)	loss 0.8691 (0.8800)	grad_norm 0.3178 (0.3341)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:41:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:10:37 lr 0.000087	 wd 0.0000	time 0.1898 (0.2896)	loss 0.8330 (0.8775)	grad_norm 0.3488 (0.3336)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:42:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:09:23 lr 0.000087	 wd 0.0000	time 0.1839 (0.2679)	loss 0.8979 (0.8823)	grad_norm 0.3605 (0.3339)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:42:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:08:29 lr 0.000087	 wd 0.0000	time 0.1737 (0.2547)	loss 0.7793 (0.8800)	grad_norm 0.3063 (0.3335)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:43:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:38 lr 0.000086	 wd 0.0000	time 0.1948 (0.2728)	loss 0.9912 (0.8821)	grad_norm 0.3186 (0.3332)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:43:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:07:54 lr 0.000086	 wd 0.0000	time 0.2058 (0.2634)	loss 0.8047 (0.8818)	grad_norm 0.3072 (0.3334)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:43:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:07:16 lr 0.000086	 wd 0.0000	time 0.1713 (0.2562)	loss 0.8296 (0.8810)	grad_norm 0.3267 (0.3334)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:44:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:06:41 lr 0.000086	 wd 0.0000	time 0.2181 (0.2504)	loss 0.8496 (0.8819)	grad_norm 0.3336 (0.3333)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:44:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:23 lr 0.000086	 wd 0.0000	time 0.2170 (0.2556)	loss 0.7686 (0.8818)	grad_norm 0.3421 (0.3332)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:45:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:51 lr 0.000086	 wd 0.0000	time 0.1880 (0.2510)	loss 0.7842 (0.8813)	grad_norm 0.3299 (0.3331)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:45:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:21 lr 0.000086	 wd 0.0000	time 0.2209 (0.2473)	loss 0.9204 (0.8807)	grad_norm 0.3369 (0.3330)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:45:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:04:53 lr 0.000085	 wd 0.0000	time 0.2092 (0.2440)	loss 0.9219 (0.8803)	grad_norm 0.3107 (0.3331)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:46:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:27 lr 0.000085	 wd 0.0000	time 0.2142 (0.2426)	loss 0.7803 (0.8807)	grad_norm 0.3407 (0.3333)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:46:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:02 lr 0.000085	 wd 0.0000	time 0.2001 (0.2420)	loss 0.8530 (0.8804)	grad_norm 0.3502 (0.3333)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:46:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:36 lr 0.000085	 wd 0.0000	time 0.1739 (0.2399)	loss 0.8965 (0.8801)	grad_norm 0.3265 (0.3332)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:47:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:10 lr 0.000085	 wd 0.0000	time 0.1895 (0.2380)	loss 1.0117 (0.8799)	grad_norm 0.3180 (0.3332)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:47:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:46 lr 0.000085	 wd 0.0000	time 0.2026 (0.2365)	loss 0.8481 (0.8799)	grad_norm 0.3241 (0.3333)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:48:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:22 lr 0.000085	 wd 0.0000	time 0.2121 (0.2368)	loss 0.9092 (0.8797)	grad_norm 0.3256 (0.3334)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:48:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:01:58 lr 0.000084	 wd 0.0000	time 0.1566 (0.2358)	loss 0.8359 (0.8793)	grad_norm 0.3396 (0.3333)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:48:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:34 lr 0.000084	 wd 0.0000	time 0.1963 (0.2346)	loss 1.0244 (0.8803)	grad_norm 0.3481 (0.3335)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:49:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:10 lr 0.000084	 wd 0.0000	time 0.1983 (0.2334)	loss 0.7070 (0.8796)	grad_norm 0.3510 (0.3336)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:49:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:47 lr 0.000084	 wd 0.0000	time 0.2071 (0.2330)	loss 0.9546 (0.8797)	grad_norm 0.3361 (0.3336)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:49:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:23 lr 0.000084	 wd 0.0000	time 0.2101 (0.2327)	loss 0.9502 (0.8799)	grad_norm 0.3426 (0.3337)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:50:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000084	 wd 0.0000	time 0.1668 (0.2308)	loss 0.8804 (0.8804)	grad_norm 0.3469 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7951MB
[2024-07-31 16:50:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 7 training takes 0:09:41
[2024-07-31 16:50:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 19.615 (19.615)	Loss 0.3555 (0.3555)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 7951MB
[2024-07-31 16:50:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.094 Acc@5 97.558
[2024-07-31 16:50:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-31 16:50:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.11%
[2024-07-31 16:51:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][0/2502]	eta 23:08:37 lr 0.000084	 wd 0.0000	time 33.3004 (33.3004)	loss 0.8027 (0.8027)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:51:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:21:25 lr 0.000083	 wd 0.0000	time 0.1876 (0.5350)	loss 0.8682 (0.8845)	grad_norm 0.3245 (0.3363)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:51:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:14:08 lr 0.000083	 wd 0.0000	time 0.1801 (0.3685)	loss 0.8711 (0.8831)	grad_norm 0.3304 (0.3353)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:52:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:11:27 lr 0.000083	 wd 0.0000	time 0.2052 (0.3124)	loss 0.8530 (0.8791)	grad_norm 0.3561 (0.3348)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:52:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:10:46 lr 0.000083	 wd 0.0000	time 0.1729 (0.3076)	loss 0.9751 (0.8803)	grad_norm 0.3315 (0.3345)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:53:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:09:36 lr 0.000083	 wd 0.0000	time 0.1847 (0.2879)	loss 0.8169 (0.8812)	grad_norm 0.3335 (0.3346)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:53:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:39 lr 0.000083	 wd 0.0000	time 0.2053 (0.2732)	loss 0.8540 (0.8810)	grad_norm 0.3507 (0.3343)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:53:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:54 lr 0.000083	 wd 0.0000	time 0.2227 (0.2633)	loss 0.8931 (0.8804)	grad_norm 0.3527 (0.3344)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:54:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:20 lr 0.000082	 wd 0.0000	time 0.2363 (0.2587)	loss 0.7578 (0.8801)	grad_norm 0.3328 (0.3345)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:54:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:50 lr 0.000082	 wd 0.0000	time 0.1940 (0.2564)	loss 1.0020 (0.8812)	grad_norm 0.3251 (0.3346)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:54:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:17 lr 0.000082	 wd 0.0000	time 0.1996 (0.2514)	loss 1.0254 (0.8818)	grad_norm 0.3317 (0.3347)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:55:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:47 lr 0.000082	 wd 0.0000	time 0.1848 (0.2477)	loss 0.9668 (0.8815)	grad_norm 0.3418 (0.3348)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:55:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:18 lr 0.000082	 wd 0.0000	time 0.2311 (0.2447)	loss 0.8345 (0.8813)	grad_norm 0.3284 (0.3347)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:56:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:53 lr 0.000082	 wd 0.0000	time 0.2208 (0.2445)	loss 0.8291 (0.8815)	grad_norm 0.3350 (0.3350)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:56:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:26 lr 0.000081	 wd 0.0000	time 0.1845 (0.2422)	loss 0.8354 (0.8813)	grad_norm 0.3277 (0.3348)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:56:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:04:00 lr 0.000081	 wd 0.0000	time 0.2018 (0.2400)	loss 0.8657 (0.8812)	grad_norm 0.3501 (0.3350)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:57:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:34 lr 0.000081	 wd 0.0000	time 0.1901 (0.2379)	loss 0.9775 (0.8808)	grad_norm 0.3325 (0.3349)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:57:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:09 lr 0.000081	 wd 0.0000	time 0.2341 (0.2367)	loss 0.8564 (0.8815)	grad_norm 0.3210 (0.3351)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:57:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:46 lr 0.000081	 wd 0.0000	time 0.1918 (0.2371)	loss 0.8770 (0.8820)	grad_norm 0.3380 (0.3351)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:58:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:21 lr 0.000081	 wd 0.0000	time 0.2044 (0.2356)	loss 0.7847 (0.8814)	grad_norm 0.3130 (0.3351)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:58:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:57 lr 0.000080	 wd 0.0000	time 0.1860 (0.2344)	loss 0.8198 (0.8815)	grad_norm 0.3616 (0.3352)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:58:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:33 lr 0.000080	 wd 0.0000	time 0.2006 (0.2333)	loss 0.8838 (0.8818)	grad_norm 0.3384 (0.3352)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:59:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:10 lr 0.000080	 wd 0.0000	time 0.2577 (0.2335)	loss 0.8325 (0.8813)	grad_norm 0.3418 (0.3354)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 16:59:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:47 lr 0.000080	 wd 0.0000	time 0.1898 (0.2327)	loss 0.9780 (0.8811)	grad_norm 0.3304 (0.3354)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:00:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:23 lr 0.000080	 wd 0.0000	time 0.2108 (0.2317)	loss 0.9663 (0.8811)	grad_norm 0.3450 (0.3355)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:00:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000080	 wd 0.0000	time 0.1564 (0.2298)	loss 0.9160 (0.8811)	grad_norm 0.3375 (0.3356)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:00:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 8 training takes 0:09:39
[2024-07-31 17:01:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 38.094 (38.094)	Loss 0.3606 (0.3606)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7951MB
[2024-07-31 17:01:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.050 Acc@5 97.572
[2024-07-31 17:01:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-31 17:01:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.11%
[2024-07-31 17:01:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][0/2502]	eta 11:41:28 lr 0.000080	 wd 0.0000	time 16.8218 (16.8218)	loss 0.8594 (0.8594)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:01:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:14:39 lr 0.000079	 wd 0.0000	time 0.1798 (0.3663)	loss 0.9702 (0.8761)	grad_norm 0.3442 (0.3353)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:02:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:11:15 lr 0.000079	 wd 0.0000	time 0.2740 (0.2933)	loss 0.7476 (0.8741)	grad_norm 0.3288 (0.3358)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:02:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:40 lr 0.000079	 wd 0.0000	time 0.1758 (0.2910)	loss 0.9424 (0.8760)	grad_norm 0.3186 (0.3366)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:03:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:25 lr 0.000079	 wd 0.0000	time 0.1779 (0.2690)	loss 0.8652 (0.8753)	grad_norm 0.3233 (0.3368)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:03:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:08:30 lr 0.000079	 wd 0.0000	time 0.1759 (0.2552)	loss 0.6772 (0.8801)	grad_norm 0.3433 (0.3368)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:03:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:07:50 lr 0.000079	 wd 0.0000	time 0.2402 (0.2475)	loss 0.7202 (0.8778)	grad_norm 0.3535 (0.3363)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:04:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:28 lr 0.000078	 wd 0.0000	time 0.1864 (0.2491)	loss 0.9536 (0.8787)	grad_norm 0.3431 (0.3363)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:04:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:06:55 lr 0.000078	 wd 0.0000	time 0.1923 (0.2439)	loss 0.8975 (0.8797)	grad_norm 0.3116 (0.3363)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:04:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:23 lr 0.000078	 wd 0.0000	time 0.1948 (0.2397)	loss 1.0381 (0.8804)	grad_norm 0.3372 (0.3361)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:05:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:05:54 lr 0.000078	 wd 0.0000	time 0.1634 (0.2360)	loss 0.9575 (0.8808)	grad_norm 0.3423 (0.3360)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:05:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:30 lr 0.000078	 wd 0.0000	time 0.2398 (0.2356)	loss 0.8047 (0.8808)	grad_norm 0.3518 (0.3360)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:05:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:06 lr 0.000078	 wd 0.0000	time 0.1871 (0.2353)	loss 0.9653 (0.8805)	grad_norm 0.3476 (0.3360)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:06:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:40 lr 0.000077	 wd 0.0000	time 0.2541 (0.2332)	loss 0.9370 (0.8809)	grad_norm 0.3187 (0.3359)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:06:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:14 lr 0.000077	 wd 0.0000	time 0.1894 (0.2314)	loss 0.8804 (0.8812)	grad_norm 0.3246 (0.3361)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:06:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:03:50 lr 0.000077	 wd 0.0000	time 0.1829 (0.2302)	loss 0.9399 (0.8814)	grad_norm 0.3461 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7951MB
[2024-07-31 17:07:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:28 lr 0.000077	 wd 0.0000	time 0.1704 (0.2317)	loss 0.8838 (0.8809)	grad_norm 0.3278 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7951MB
[2024-07-31 17:07:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:04 lr 0.000077	 wd 0.0000	time 0.1972 (0.2307)	loss 0.8203 (0.8817)	grad_norm 0.3173 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7951MB
[2024-07-31 17:08:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:41 lr 0.000077	 wd 0.0000	time 0.1792 (0.2294)	loss 0.7207 (0.8815)	grad_norm 0.3434 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7951MB
[2024-07-31 17:08:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:17 lr 0.000076	 wd 0.0000	time 0.2127 (0.2283)	loss 0.9141 (0.8816)	grad_norm 0.3343 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7951MB
[2024-07-31 17:08:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:01:54 lr 0.000076	 wd 0.0000	time 0.2031 (0.2279)	loss 0.9165 (0.8825)	grad_norm 0.3255 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7951MB
[2024-07-31 17:09:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:31 lr 0.000076	 wd 0.0000	time 0.1812 (0.2287)	loss 1.0254 (0.8830)	grad_norm 0.3201 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7951MB
[2024-07-31 17:09:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:08 lr 0.000076	 wd 0.0000	time 0.1774 (0.2279)	loss 0.9126 (0.8832)	grad_norm 0.3344 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7951MB
[2024-07-31 17:09:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:45 lr 0.000076	 wd 0.0000	time 0.1741 (0.2269)	loss 0.8682 (0.8828)	grad_norm 0.3621 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7951MB
[2024-07-31 17:10:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:23 lr 0.000075	 wd 0.0000	time 0.2221 (0.2265)	loss 0.8252 (0.8828)	grad_norm 0.3347 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7951MB
[2024-07-31 17:10:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000075	 wd 0.0000	time 0.1601 (0.2251)	loss 0.8604 (0.8829)	grad_norm 0.3202 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7951MB
[2024-07-31 17:10:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 9 training takes 0:09:32
[2024-07-31 17:11:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 20.456 (20.456)	Loss 0.3560 (0.3560)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 17:11:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.066 Acc@5 97.606
[2024-07-31 17:11:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-31 17:11:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.11%
[2024-07-31 17:11:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][0/2502]	eta 11:42:53 lr 0.000075	 wd 0.0000	time 16.8558 (16.8558)	loss 1.0303 (1.0303)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:11:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:15:51 lr 0.000075	 wd 0.0000	time 0.2134 (0.3962)	loss 0.7305 (0.8956)	grad_norm 0.3390 (0.3382)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:12:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:12:00 lr 0.000075	 wd 0.0000	time 0.1970 (0.3128)	loss 0.9585 (0.8872)	grad_norm 0.3458 (0.3380)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:12:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:08 lr 0.000075	 wd 0.0000	time 0.1934 (0.2764)	loss 0.8711 (0.8828)	grad_norm 0.3333 (0.3383)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:13:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:01 lr 0.000075	 wd 0.0000	time 0.1936 (0.2575)	loss 0.9160 (0.8816)	grad_norm 0.3451 (0.3385)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:13:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:08:13 lr 0.000074	 wd 0.0000	time 0.2683 (0.2467)	loss 0.7720 (0.8828)	grad_norm 0.3509 (0.3388)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:13:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:07:50 lr 0.000074	 wd 0.0000	time 0.1785 (0.2472)	loss 0.9468 (0.8815)	grad_norm 0.3396 (0.3384)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:14:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:15 lr 0.000074	 wd 0.0000	time 0.2099 (0.2417)	loss 0.8091 (0.8801)	grad_norm 0.3240 (0.3385)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:14:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:06:43 lr 0.000074	 wd 0.0000	time 0.1678 (0.2373)	loss 0.8711 (0.8805)	grad_norm 0.3383 (0.3389)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:14:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:14 lr 0.000074	 wd 0.0000	time 0.1642 (0.2337)	loss 0.8418 (0.8810)	grad_norm 0.3392 (0.3387)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:15:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:05:49 lr 0.000073	 wd 0.0000	time 0.2190 (0.2327)	loss 0.8262 (0.8812)	grad_norm 0.3395 (0.3388)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:15:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:25 lr 0.000073	 wd 0.0000	time 0.1861 (0.2321)	loss 0.7983 (0.8811)	grad_norm 0.3392 (0.3386)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:15:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:04:59 lr 0.000073	 wd 0.0000	time 0.1858 (0.2302)	loss 1.0039 (0.8810)	grad_norm 0.3299 (0.3388)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:16:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:34 lr 0.000073	 wd 0.0000	time 0.1837 (0.2283)	loss 0.8916 (0.8810)	grad_norm 0.3409 (0.3388)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:16:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:10 lr 0.000073	 wd 0.0000	time 0.2162 (0.2269)	loss 0.7876 (0.8808)	grad_norm 0.3586 (0.3387)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:17:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:03:48 lr 0.000073	 wd 0.0000	time 0.1748 (0.2276)	loss 0.8604 (0.8805)	grad_norm 0.3523 (0.3385)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:17:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:24 lr 0.000072	 wd 0.0000	time 0.1797 (0.2268)	loss 0.7725 (0.8809)	grad_norm 0.3262 (0.3384)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:17:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:00 lr 0.000072	 wd 0.0000	time 0.2019 (0.2257)	loss 0.8906 (0.8811)	grad_norm 0.3258 (0.3383)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:18:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:37 lr 0.000072	 wd 0.0000	time 0.1700 (0.2245)	loss 0.9438 (0.8809)	grad_norm 0.3519 (0.3384)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:18:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:15 lr 0.000072	 wd 0.0000	time 0.1866 (0.2243)	loss 0.9512 (0.8808)	grad_norm 0.3454 (0.3385)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:18:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:53 lr 0.000072	 wd 0.0000	time 0.2107 (0.2254)	loss 0.8794 (0.8813)	grad_norm 0.3385 (0.3387)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:19:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:30 lr 0.000071	 wd 0.0000	time 0.1782 (0.2245)	loss 0.8633 (0.8812)	grad_norm 0.3568 (0.3386)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:19:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:07 lr 0.000071	 wd 0.0000	time 0.1795 (0.2237)	loss 0.8755 (0.8817)	grad_norm 0.3295 (0.3386)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:19:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:45 lr 0.000071	 wd 0.0000	time 0.1928 (0.2233)	loss 0.9360 (0.8814)	grad_norm 0.3326 (0.3386)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:20:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:22 lr 0.000071	 wd 0.0000	time 0.1961 (0.2235)	loss 0.8818 (0.8818)	grad_norm 0.3232 (0.3386)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:20:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000071	 wd 0.0000	time 0.1582 (0.2222)	loss 0.9956 (0.8812)	grad_norm 0.3408 (0.3386)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:20:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 10 training takes 0:09:20
[2024-07-31 17:20:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 19.127 (19.127)	Loss 0.3643 (0.3643)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 7951MB
[2024-07-31 17:21:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.134 Acc@5 97.554
[2024-07-31 17:21:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-31 17:21:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.13%
[2024-07-31 17:21:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-31 17:21:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-31 17:21:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][0/2502]	eta 16:37:31 lr 0.000071	 wd 0.0000	time 23.9214 (23.9214)	loss 0.7886 (0.7886)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:21:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:18:35 lr 0.000070	 wd 0.0000	time 0.1686 (0.4642)	loss 0.8950 (0.8749)	grad_norm 0.3426 (0.3389)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:22:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:12:46 lr 0.000070	 wd 0.0000	time 0.1825 (0.3332)	loss 0.8965 (0.8776)	grad_norm 0.3537 (0.3393)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:22:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:10:39 lr 0.000070	 wd 0.0000	time 0.1861 (0.2902)	loss 0.9980 (0.8790)	grad_norm 0.3471 (0.3401)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:22:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:09:23 lr 0.000070	 wd 0.0000	time 0.1917 (0.2682)	loss 0.9458 (0.8775)	grad_norm 0.3433 (0.3399)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:23:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:09:19 lr 0.000070	 wd 0.0000	time 0.2352 (0.2794)	loss 0.7915 (0.8769)	grad_norm 0.3302 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7951MB
[2024-07-31 17:23:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:30 lr 0.000069	 wd 0.0000	time 0.1858 (0.2682)	loss 1.0566 (0.8751)	grad_norm 0.3367 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7951MB
[2024-07-31 17:24:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:07:46 lr 0.000069	 wd 0.0000	time 0.2034 (0.2591)	loss 0.8701 (0.8778)	grad_norm 0.3443 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7951MB
[2024-07-31 17:24:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:07:08 lr 0.000069	 wd 0.0000	time 0.1988 (0.2517)	loss 0.9106 (0.8787)	grad_norm 0.3416 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7951MB
[2024-07-31 17:25:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:06:46 lr 0.000069	 wd 0.0000	time 0.4285 (0.2537)	loss 0.9873 (0.8789)	grad_norm 0.3543 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7951MB
[2024-07-31 17:25:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:22 lr 0.000069	 wd 0.0000	time 0.1844 (0.2543)	loss 0.8306 (0.8802)	grad_norm 0.3397 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7951MB
[2024-07-31 17:25:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:50 lr 0.000069	 wd 0.0000	time 0.2071 (0.2498)	loss 0.8110 (0.8805)	grad_norm 0.3319 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7951MB
[2024-07-31 17:26:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:20 lr 0.000068	 wd 0.0000	time 0.1990 (0.2459)	loss 0.9526 (0.8808)	grad_norm 0.3424 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7951MB
[2024-07-31 17:26:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:04:54 lr 0.000068	 wd 0.0000	time 0.2165 (0.2447)	loss 0.7583 (0.8811)	grad_norm 0.3272 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7951MB
[2024-07-31 17:26:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:28 lr 0.000068	 wd 0.0000	time 0.2273 (0.2439)	loss 0.8511 (0.8817)	grad_norm 0.3597 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7951MB
[2024-07-31 17:27:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:04:01 lr 0.000068	 wd 0.0000	time 0.1874 (0.2413)	loss 0.9512 (0.8815)	grad_norm 0.3524 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7951MB
[2024-07-31 17:27:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:35 lr 0.000068	 wd 0.0000	time 0.1919 (0.2392)	loss 0.9297 (0.8816)	grad_norm 0.3631 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7951MB
[2024-07-31 17:27:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:10 lr 0.000067	 wd 0.0000	time 0.1823 (0.2374)	loss 0.7993 (0.8818)	grad_norm 0.3446 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7951MB
[2024-07-31 17:28:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:46 lr 0.000067	 wd 0.0000	time 0.4478 (0.2374)	loss 1.1094 (0.8826)	grad_norm 0.3358 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7951MB
[2024-07-31 17:28:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:22 lr 0.000067	 wd 0.0000	time 0.1775 (0.2367)	loss 0.7798 (0.8830)	grad_norm 0.3280 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7951MB
[2024-07-31 17:29:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:01:58 lr 0.000067	 wd 0.0000	time 0.1772 (0.2355)	loss 0.9209 (0.8827)	grad_norm 0.3330 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7951MB
[2024-07-31 17:29:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:34 lr 0.000067	 wd 0.0000	time 0.1758 (0.2341)	loss 0.8706 (0.8824)	grad_norm 0.3555 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7951MB
[2024-07-31 17:29:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:10 lr 0.000066	 wd 0.0000	time 0.2177 (0.2335)	loss 0.9082 (0.8823)	grad_norm 0.3459 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7951MB
[2024-07-31 17:30:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:47 lr 0.000066	 wd 0.0000	time 0.1738 (0.2337)	loss 0.8550 (0.8823)	grad_norm 0.3399 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7951MB
[2024-07-31 17:30:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:23 lr 0.000066	 wd 0.0000	time 0.1956 (0.2327)	loss 0.8813 (0.8827)	grad_norm 0.3390 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7951MB
[2024-07-31 17:30:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000066	 wd 0.0000	time 0.1667 (0.2309)	loss 1.0576 (0.8819)	grad_norm 0.3478 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7951MB
[2024-07-31 17:30:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 11 training takes 0:09:41
[2024-07-31 17:31:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 40.403 (40.403)	Loss 0.3596 (0.3596)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 17:31:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.110 Acc@5 97.586
[2024-07-31 17:31:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-07-31 17:31:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.13%
[2024-07-31 17:32:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][0/2502]	eta 11:53:31 lr 0.000066	 wd 0.0000	time 17.1109 (17.1109)	loss 0.9106 (0.9106)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:32:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:14:51 lr 0.000066	 wd 0.0000	time 0.1877 (0.3709)	loss 0.8213 (0.8692)	grad_norm 0.3517 (0.3426)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:32:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:11:07 lr 0.000065	 wd 0.0000	time 0.1972 (0.2898)	loss 0.8569 (0.8759)	grad_norm 0.3436 (0.3412)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:33:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:49 lr 0.000065	 wd 0.0000	time 0.1661 (0.2948)	loss 0.9116 (0.8854)	grad_norm 0.3752 (0.3409)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:33:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:31 lr 0.000065	 wd 0.0000	time 0.1599 (0.2719)	loss 0.8452 (0.8870)	grad_norm 0.3361 (0.3412)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:33:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:08:35 lr 0.000065	 wd 0.0000	time 0.1781 (0.2576)	loss 0.7627 (0.8858)	grad_norm 0.3413 (0.3410)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:34:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:07:52 lr 0.000065	 wd 0.0000	time 0.1915 (0.2485)	loss 0.7783 (0.8859)	grad_norm 0.3444 (0.3413)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:34:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:24 lr 0.000064	 wd 0.0000	time 0.2389 (0.2465)	loss 0.8169 (0.8854)	grad_norm 0.3336 (0.3409)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:35:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:06:55 lr 0.000064	 wd 0.0000	time 0.2171 (0.2441)	loss 0.9111 (0.8842)	grad_norm 0.3343 (0.3408)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:35:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:24 lr 0.000064	 wd 0.0000	time 0.1793 (0.2399)	loss 0.8101 (0.8836)	grad_norm 0.3499 (0.3411)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:35:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:05:54 lr 0.000064	 wd 0.0000	time 0.1920 (0.2363)	loss 0.9126 (0.8837)	grad_norm 0.3313 (0.3413)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:36:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:28 lr 0.000064	 wd 0.0000	time 0.2517 (0.2345)	loss 0.7544 (0.8837)	grad_norm 0.3276 (0.3412)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:36:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:11 lr 0.000063	 wd 0.0000	time 0.1815 (0.2396)	loss 0.8940 (0.8830)	grad_norm 0.3517 (0.3412)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:36:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:44 lr 0.000063	 wd 0.0000	time 0.1754 (0.2370)	loss 0.7949 (0.8832)	grad_norm 0.3551 (0.3410)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:37:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:18 lr 0.000063	 wd 0.0000	time 0.1915 (0.2348)	loss 0.9414 (0.8834)	grad_norm 0.3349 (0.3409)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:37:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:03:53 lr 0.000063	 wd 0.0000	time 0.1719 (0.2330)	loss 0.8608 (0.8842)	grad_norm 0.3432 (0.3410)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:38:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:30 lr 0.000063	 wd 0.0000	time 0.1820 (0.2335)	loss 0.8696 (0.8835)	grad_norm 0.3369 (0.3410)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:38:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:06 lr 0.000062	 wd 0.0000	time 0.2114 (0.2323)	loss 0.8608 (0.8834)	grad_norm 0.3318 (0.3412)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:38:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:42 lr 0.000062	 wd 0.0000	time 0.1911 (0.2310)	loss 0.7983 (0.8836)	grad_norm 0.3415 (0.3415)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:39:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:18 lr 0.000062	 wd 0.0000	time 0.2037 (0.2297)	loss 0.8452 (0.8833)	grad_norm 0.3407 (0.3415)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:39:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:01:55 lr 0.000062	 wd 0.0000	time 0.1859 (0.2293)	loss 0.8345 (0.8835)	grad_norm 0.3527 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7951MB
[2024-07-31 17:39:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:32 lr 0.000062	 wd 0.0000	time 0.1913 (0.2303)	loss 0.8599 (0.8839)	grad_norm 0.3447 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7951MB
[2024-07-31 17:40:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:09 lr 0.000061	 wd 0.0000	time 0.1735 (0.2293)	loss 0.9048 (0.8840)	grad_norm 0.3534 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7951MB
[2024-07-31 17:40:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:46 lr 0.000061	 wd 0.0000	time 0.1953 (0.2285)	loss 0.8784 (0.8837)	grad_norm 0.3179 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7951MB
[2024-07-31 17:40:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:23 lr 0.000061	 wd 0.0000	time 0.2183 (0.2278)	loss 0.8726 (0.8830)	grad_norm 0.3412 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7951MB
[2024-07-31 17:41:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000061	 wd 0.0000	time 0.1580 (0.2264)	loss 0.8896 (0.8827)	grad_norm 0.3459 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7951MB
[2024-07-31 17:41:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 12 training takes 0:09:35
[2024-07-31 17:41:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 25.048 (25.048)	Loss 0.3582 (0.3582)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 17:42:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.228 Acc@5 97.584
[2024-07-31 17:42:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-31 17:42:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.23%
[2024-07-31 17:42:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-31 17:42:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-31 17:42:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][0/2502]	eta 10:44:08 lr 0.000061	 wd 0.0000	time 15.4469 (15.4469)	loss 0.8457 (0.8457)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:42:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:15:39 lr 0.000061	 wd 0.0000	time 0.3576 (0.3911)	loss 0.7959 (0.8727)	grad_norm 0.3327 (0.3409)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:43:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:12:39 lr 0.000060	 wd 0.0000	time 0.2090 (0.3301)	loss 0.8052 (0.8817)	grad_norm 0.3544 (0.3410)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:43:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:10:32 lr 0.000060	 wd 0.0000	time 0.1748 (0.2872)	loss 0.7886 (0.8760)	grad_norm 0.3550 (0.3415)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:43:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:09:18 lr 0.000060	 wd 0.0000	time 0.1948 (0.2659)	loss 0.7617 (0.8771)	grad_norm 0.3507 (0.3416)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:44:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:08:30 lr 0.000060	 wd 0.0000	time 0.2030 (0.2548)	loss 0.8525 (0.8770)	grad_norm 0.3371 (0.3420)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:44:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:19 lr 0.000060	 wd 0.0000	time 0.2221 (0.2628)	loss 0.8018 (0.8780)	grad_norm 0.3394 (0.3428)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:45:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:07:38 lr 0.000059	 wd 0.0000	time 0.2081 (0.2545)	loss 1.0020 (0.8785)	grad_norm 0.3692 (0.3428)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:45:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:01 lr 0.000059	 wd 0.0000	time 0.2020 (0.2479)	loss 0.9160 (0.8786)	grad_norm 0.3401 (0.3429)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:45:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:06:30 lr 0.000059	 wd 0.0000	time 0.2102 (0.2437)	loss 0.9136 (0.8794)	grad_norm 0.3429 (0.3432)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:46:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:09 lr 0.000059	 wd 0.0000	time 0.1750 (0.2458)	loss 0.9712 (0.8805)	grad_norm 0.3500 (0.3433)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:46:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:39 lr 0.000059	 wd 0.0000	time 0.2235 (0.2422)	loss 0.8501 (0.8799)	grad_norm 0.3417 (0.3431)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:46:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:11 lr 0.000058	 wd 0.0000	time 0.2005 (0.2393)	loss 0.9751 (0.8802)	grad_norm 0.3498 (0.3431)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:47:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:04:44 lr 0.000058	 wd 0.0000	time 0.1632 (0.2365)	loss 0.8901 (0.8808)	grad_norm 0.3497 (0.3432)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:47:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:19 lr 0.000058	 wd 0.0000	time 0.2392 (0.2353)	loss 1.0518 (0.8805)	grad_norm 0.3321 (0.3433)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:47:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:03:55 lr 0.000058	 wd 0.0000	time 0.1912 (0.2353)	loss 0.8960 (0.8806)	grad_norm 0.3501 (0.3434)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:48:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:30 lr 0.000058	 wd 0.0000	time 0.1801 (0.2335)	loss 0.8296 (0.8810)	grad_norm 0.3433 (0.3434)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:48:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:06 lr 0.000057	 wd 0.0000	time 0.1843 (0.2321)	loss 0.8315 (0.8811)	grad_norm 0.3360 (0.3435)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:48:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:42 lr 0.000057	 wd 0.0000	time 0.2290 (0.2309)	loss 0.8364 (0.8811)	grad_norm 0.3648 (0.3436)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:49:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:19 lr 0.000057	 wd 0.0000	time 0.2944 (0.2315)	loss 0.7974 (0.8800)	grad_norm 0.3580 (0.3436)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:49:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:55 lr 0.000057	 wd 0.0000	time 0.1875 (0.2309)	loss 0.8726 (0.8807)	grad_norm 0.3327 (0.3437)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:50:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:32 lr 0.000057	 wd 0.0000	time 0.2059 (0.2298)	loss 0.8882 (0.8812)	grad_norm 0.3100 (0.3436)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:50:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:09 lr 0.000056	 wd 0.0000	time 0.2311 (0.2288)	loss 0.9556 (0.8813)	grad_norm 0.3536 (0.3436)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:50:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:46 lr 0.000056	 wd 0.0000	time 0.1849 (0.2284)	loss 0.8086 (0.8808)	grad_norm 0.3375 (0.3437)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:51:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:23 lr 0.000056	 wd 0.0000	time 0.2124 (0.2284)	loss 0.8896 (0.8812)	grad_norm 0.3267 (0.3437)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:51:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000056	 wd 0.0000	time 0.1609 (0.2267)	loss 0.8237 (0.8813)	grad_norm 0.3359 (0.3437)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:51:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 13 training takes 0:09:31
[2024-07-31 17:51:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 19.750 (19.750)	Loss 0.3584 (0.3584)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7951MB
[2024-07-31 17:52:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.168 Acc@5 97.586
[2024-07-31 17:52:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-31 17:52:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.23%
[2024-07-31 17:52:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][0/2502]	eta 22:40:04 lr 0.000056	 wd 0.0000	time 32.6158 (32.6158)	loss 0.9873 (0.9873)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:52:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:21:18 lr 0.000055	 wd 0.0000	time 0.1675 (0.5321)	loss 0.8506 (0.8764)	grad_norm 0.3455 (0.3444)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:53:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:14:05 lr 0.000055	 wd 0.0000	time 0.1915 (0.3675)	loss 0.8467 (0.8779)	grad_norm 0.3329 (0.3439)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:53:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:11:26 lr 0.000055	 wd 0.0000	time 0.2018 (0.3115)	loss 1.1260 (0.8815)	grad_norm 0.3340 (0.3436)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:54:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:10:11 lr 0.000055	 wd 0.0000	time 0.1905 (0.2911)	loss 1.0811 (0.8805)	grad_norm 0.3420 (0.3444)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:54:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:09:11 lr 0.000055	 wd 0.0000	time 0.1861 (0.2753)	loss 0.9165 (0.8804)	grad_norm 0.3210 (0.3441)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:54:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:08:21 lr 0.000054	 wd 0.0000	time 0.1709 (0.2639)	loss 0.8545 (0.8810)	grad_norm 0.3683 (0.3445)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:55:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:40 lr 0.000054	 wd 0.0000	time 0.2094 (0.2555)	loss 0.8027 (0.8801)	grad_norm 0.3440 (0.3449)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:55:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:05 lr 0.000054	 wd 0.0000	time 0.2370 (0.2498)	loss 0.8037 (0.8803)	grad_norm 0.3319 (0.3449)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:55:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:42 lr 0.000054	 wd 0.0000	time 0.1730 (0.2511)	loss 0.8672 (0.8799)	grad_norm 0.3620 (0.3450)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 17:56:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:06:10 lr 0.000054	 wd 0.0000	time 0.2082 (0.2467)	loss 0.9165 (0.8792)	grad_norm 0.3742 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7951MB
[2024-07-31 17:56:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:40 lr 0.000053	 wd 0.0000	time 0.1731 (0.2429)	loss 0.8408 (0.8789)	grad_norm 0.3241 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7951MB
[2024-07-31 17:56:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:11 lr 0.000053	 wd 0.0000	time 0.2015 (0.2396)	loss 0.8745 (0.8788)	grad_norm 0.3523 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7951MB
[2024-07-31 17:57:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:04:47 lr 0.000053	 wd 0.0000	time 0.2094 (0.2390)	loss 1.0684 (0.8784)	grad_norm 0.3506 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7951MB
[2024-07-31 17:57:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:22 lr 0.000053	 wd 0.0000	time 0.2039 (0.2384)	loss 0.9028 (0.8787)	grad_norm 0.3289 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7951MB
[2024-07-31 17:58:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:03:56 lr 0.000053	 wd 0.0000	time 0.1615 (0.2363)	loss 0.8613 (0.8790)	grad_norm 0.3487 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7951MB
[2024-07-31 17:58:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:31 lr 0.000052	 wd 0.0000	time 0.1927 (0.2345)	loss 0.8745 (0.8786)	grad_norm 0.3503 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7951MB
[2024-07-31 17:58:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:06 lr 0.000052	 wd 0.0000	time 0.2232 (0.2330)	loss 1.0498 (0.8791)	grad_norm 0.3643 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7951MB
[2024-07-31 17:59:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:43 lr 0.000052	 wd 0.0000	time 0.1796 (0.2334)	loss 0.6963 (0.8793)	grad_norm 0.3432 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7951MB
[2024-07-31 17:59:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:20 lr 0.000052	 wd 0.0000	time 0.1949 (0.2328)	loss 0.8276 (0.8790)	grad_norm 0.3442 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7951MB
[2024-07-31 17:59:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:01:56 lr 0.000052	 wd 0.0000	time 0.2053 (0.2317)	loss 0.7993 (0.8789)	grad_norm 0.3478 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7951MB
[2024-07-31 18:00:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:32 lr 0.000051	 wd 0.0000	time 0.2029 (0.2306)	loss 0.9419 (0.8789)	grad_norm 0.3366 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7951MB
[2024-07-31 18:00:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:09 lr 0.000051	 wd 0.0000	time 0.2104 (0.2303)	loss 0.8662 (0.8796)	grad_norm 0.3329 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7951MB
[2024-07-31 18:00:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:46 lr 0.000051	 wd 0.0000	time 0.1994 (0.2303)	loss 0.8467 (0.8794)	grad_norm 0.3610 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7951MB
[2024-07-31 18:01:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:23 lr 0.000051	 wd 0.0000	time 0.1958 (0.2293)	loss 0.9673 (0.8799)	grad_norm 0.3525 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7951MB
[2024-07-31 18:01:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000051	 wd 0.0000	time 0.1567 (0.2275)	loss 0.9033 (0.8801)	grad_norm 0.3482 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7951MB
[2024-07-31 18:01:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 14 training takes 0:09:33
[2024-07-31 18:02:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 37.844 (37.844)	Loss 0.3525 (0.3525)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 18:02:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.202 Acc@5 97.570
[2024-07-31 18:02:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-31 18:02:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.23%
[2024-07-31 18:02:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][0/2502]	eta 11:50:30 lr 0.000051	 wd 0.0000	time 17.0385 (17.0385)	loss 0.8013 (0.8013)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:03:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:14:41 lr 0.000050	 wd 0.0000	time 0.1795 (0.3671)	loss 0.9790 (0.8871)	grad_norm 0.3479 (0.3456)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:03:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:10:58 lr 0.000050	 wd 0.0000	time 0.2653 (0.2861)	loss 1.0107 (0.8830)	grad_norm 0.3451 (0.3470)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:03:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:09:53 lr 0.000050	 wd 0.0000	time 0.1700 (0.2697)	loss 0.9297 (0.8809)	grad_norm 0.3366 (0.3472)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:04:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:08:58 lr 0.000050	 wd 0.0000	time 0.1878 (0.2562)	loss 1.0186 (0.8819)	grad_norm 0.3552 (0.3472)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:04:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:08:10 lr 0.000049	 wd 0.0000	time 0.1865 (0.2451)	loss 0.7900 (0.8836)	grad_norm 0.3494 (0.3475)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:04:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:07:32 lr 0.000049	 wd 0.0000	time 0.2092 (0.2379)	loss 0.8452 (0.8833)	grad_norm 0.3552 (0.3472)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:05:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:05 lr 0.000049	 wd 0.0000	time 0.3224 (0.2362)	loss 0.8257 (0.8805)	grad_norm 0.3500 (0.3473)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:05:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:06:40 lr 0.000049	 wd 0.0000	time 0.2300 (0.2355)	loss 1.0205 (0.8810)	grad_norm 0.3572 (0.3473)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:06:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:12 lr 0.000049	 wd 0.0000	time 0.1937 (0.2326)	loss 0.8062 (0.8811)	grad_norm 0.3645 (0.3477)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:06:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:05:45 lr 0.000048	 wd 0.0000	time 0.1967 (0.2300)	loss 0.9434 (0.8806)	grad_norm 0.3406 (0.3477)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:06:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:19 lr 0.000048	 wd 0.0000	time 0.2302 (0.2280)	loss 0.9194 (0.8785)	grad_norm 0.3591 (0.3473)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:07:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:04:59 lr 0.000048	 wd 0.0000	time 0.1974 (0.2298)	loss 0.8037 (0.8795)	grad_norm 0.3354 (0.3471)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:07:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:04:34 lr 0.000048	 wd 0.0000	time 0.2715 (0.2283)	loss 0.9131 (0.8791)	grad_norm 0.3385 (0.3473)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:07:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:09 lr 0.000048	 wd 0.0000	time 0.1946 (0.2267)	loss 0.8057 (0.8796)	grad_norm 0.3538 (0.3474)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:08:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:03:45 lr 0.000047	 wd 0.0000	time 0.2038 (0.2251)	loss 0.9326 (0.8790)	grad_norm 0.3421 (0.3475)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:08:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:22 lr 0.000047	 wd 0.0000	time 0.2053 (0.2246)	loss 0.9429 (0.8792)	grad_norm 0.3411 (0.3478)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:08:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:00 lr 0.000047	 wd 0.0000	time 0.2004 (0.2251)	loss 0.7969 (0.8794)	grad_norm 0.3380 (0.3477)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:09:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:37 lr 0.000047	 wd 0.0000	time 0.2024 (0.2243)	loss 1.0205 (0.8800)	grad_norm 0.3745 (0.3477)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:09:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:14 lr 0.000047	 wd 0.0000	time 0.1927 (0.2234)	loss 0.9712 (0.8795)	grad_norm 0.3586 (0.3477)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:09:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:01:51 lr 0.000046	 wd 0.0000	time 0.2007 (0.2227)	loss 1.0244 (0.8803)	grad_norm 0.3796 (0.3477)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:10:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:29 lr 0.000046	 wd 0.0000	time 0.2179 (0.2232)	loss 0.8462 (0.8802)	grad_norm 0.3400 (0.3477)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:10:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:07 lr 0.000046	 wd 0.0000	time 0.1869 (0.2233)	loss 0.8989 (0.8804)	grad_norm 0.3398 (0.3475)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:11:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:44 lr 0.000046	 wd 0.0000	time 0.2073 (0.2227)	loss 0.8887 (0.8805)	grad_norm 0.3673 (0.3477)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:11:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:22 lr 0.000046	 wd 0.0000	time 0.1995 (0.2219)	loss 0.9370 (0.8804)	grad_norm 0.3441 (0.3478)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:11:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000045	 wd 0.0000	time 0.1672 (0.2206)	loss 1.0859 (0.8807)	grad_norm 0.3503 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7951MB
[2024-07-31 18:11:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 15 training takes 0:09:16
[2024-07-31 18:11:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_15.pth saving......
[2024-07-31 18:11:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_15.pth saved !!!
[2024-07-31 18:12:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 36.436 (36.436)	Loss 0.3589 (0.3589)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 18:12:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.244 Acc@5 97.606
[2024-07-31 18:12:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-31 18:12:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.24%
[2024-07-31 18:12:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-31 18:12:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-31 18:12:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][0/2502]	eta 11:12:35 lr 0.000045	 wd 0.0000	time 16.1294 (16.1294)	loss 0.7471 (0.7471)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:13:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:15:12 lr 0.000045	 wd 0.0000	time 0.2715 (0.3798)	loss 0.9922 (0.8927)	grad_norm 0.3574 (0.3511)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:13:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:12:23 lr 0.000045	 wd 0.0000	time 0.1822 (0.3232)	loss 0.8765 (0.8810)	grad_norm 0.3576 (0.3497)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:14:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:10:22 lr 0.000045	 wd 0.0000	time 0.1625 (0.2825)	loss 0.9199 (0.8819)	grad_norm 0.3479 (0.3482)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:14:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:09:12 lr 0.000045	 wd 0.0000	time 0.1982 (0.2629)	loss 0.9038 (0.8815)	grad_norm 0.3479 (0.3482)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:14:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:08:24 lr 0.000044	 wd 0.0000	time 0.2401 (0.2518)	loss 0.9673 (0.8809)	grad_norm 0.3439 (0.3484)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:15:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:02 lr 0.000044	 wd 0.0000	time 0.1986 (0.2534)	loss 0.9385 (0.8812)	grad_norm 0.3496 (0.3487)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:15:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:24 lr 0.000044	 wd 0.0000	time 0.2000 (0.2468)	loss 0.8950 (0.8815)	grad_norm 0.3438 (0.3486)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:15:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:06:51 lr 0.000044	 wd 0.0000	time 0.2001 (0.2417)	loss 0.8740 (0.8808)	grad_norm 0.3460 (0.3485)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:16:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:20 lr 0.000043	 wd 0.0000	time 0.2180 (0.2377)	loss 0.8047 (0.8822)	grad_norm 0.3579 (0.3488)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:16:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:05:54 lr 0.000043	 wd 0.0000	time 0.1819 (0.2358)	loss 0.8525 (0.8823)	grad_norm 0.3558 (0.3491)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:16:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:30 lr 0.000043	 wd 0.0000	time 0.1799 (0.2356)	loss 0.9688 (0.8825)	grad_norm 0.3597 (0.3492)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:17:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:03 lr 0.000043	 wd 0.0000	time 0.1702 (0.2334)	loss 0.8955 (0.8821)	grad_norm 0.3511 (0.3490)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:17:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:04:37 lr 0.000043	 wd 0.0000	time 0.2269 (0.2312)	loss 0.9717 (0.8816)	grad_norm 0.3517 (0.3491)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:18:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:13 lr 0.000042	 wd 0.0000	time 0.2292 (0.2296)	loss 0.7935 (0.8810)	grad_norm 0.3233 (0.3491)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:18:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:03:51 lr 0.000042	 wd 0.0000	time 0.1559 (0.2307)	loss 0.8208 (0.8805)	grad_norm 0.3261 (0.3492)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:18:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:27 lr 0.000042	 wd 0.0000	time 0.2004 (0.2297)	loss 0.8022 (0.8804)	grad_norm 0.3478 (0.3491)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:19:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:03 lr 0.000042	 wd 0.0000	time 0.1595 (0.2284)	loss 0.8701 (0.8802)	grad_norm 0.3527 (0.3493)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:19:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:39 lr 0.000042	 wd 0.0000	time 0.1872 (0.2271)	loss 1.0293 (0.8803)	grad_norm 0.3309 (0.3494)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:19:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:16 lr 0.000041	 wd 0.0000	time 0.2114 (0.2267)	loss 0.9976 (0.8794)	grad_norm 0.3445 (0.3493)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:20:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:01:54 lr 0.000041	 wd 0.0000	time 0.2086 (0.2279)	loss 0.8501 (0.8792)	grad_norm 0.3517 (0.3493)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:20:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:31 lr 0.000041	 wd 0.0000	time 0.1870 (0.2272)	loss 0.6973 (0.8788)	grad_norm 0.3503 (0.3494)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:20:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:08 lr 0.000041	 wd 0.0000	time 0.2003 (0.2262)	loss 0.7905 (0.8788)	grad_norm 0.3500 (0.3494)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:21:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:45 lr 0.000041	 wd 0.0000	time 0.2149 (0.2256)	loss 0.6846 (0.8782)	grad_norm 0.3681 (0.3493)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:21:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:23 lr 0.000040	 wd 0.0000	time 0.2074 (0.2256)	loss 0.7778 (0.8781)	grad_norm 0.3520 (0.3492)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:22:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1700 (0.2244)	loss 0.8521 (0.8778)	grad_norm 0.3815 (0.3493)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:22:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 16 training takes 0:09:26
[2024-07-31 18:22:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 19.731 (19.731)	Loss 0.3569 (0.3569)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 18:22:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.208 Acc@5 97.612
[2024-07-31 18:22:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-31 18:22:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.24%
[2024-07-31 18:22:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][0/2502]	eta 14:16:10 lr 0.000040	 wd 0.0000	time 20.5317 (20.5317)	loss 0.7666 (0.7666)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:23:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:18:28 lr 0.000040	 wd 0.0000	time 0.2028 (0.4613)	loss 0.9731 (0.8794)	grad_norm 0.3322 (0.3491)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:23:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:12:47 lr 0.000040	 wd 0.0000	time 0.1849 (0.3332)	loss 0.8560 (0.8824)	grad_norm 0.3323 (0.3495)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:24:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:37 lr 0.000040	 wd 0.0000	time 0.1813 (0.2893)	loss 0.8794 (0.8787)	grad_norm 0.3770 (0.3499)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:24:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:09:21 lr 0.000039	 wd 0.0000	time 0.2106 (0.2673)	loss 0.9336 (0.8772)	grad_norm 0.3346 (0.3501)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:24:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:08:39 lr 0.000039	 wd 0.0000	time 0.1833 (0.2594)	loss 0.7568 (0.8753)	grad_norm 0.3878 (0.3501)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:25:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:07:59 lr 0.000039	 wd 0.0000	time 0.1843 (0.2522)	loss 0.8066 (0.8768)	grad_norm 0.3705 (0.3504)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:25:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:22 lr 0.000039	 wd 0.0000	time 0.1863 (0.2455)	loss 0.8960 (0.8761)	grad_norm 0.3492 (0.3504)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:25:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:06:49 lr 0.000039	 wd 0.0000	time 0.2362 (0.2407)	loss 0.7949 (0.8763)	grad_norm 0.3374 (0.3504)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:26:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:21 lr 0.000038	 wd 0.0000	time 0.2394 (0.2380)	loss 0.9756 (0.8768)	grad_norm 0.3442 (0.3501)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:26:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:05:57 lr 0.000038	 wd 0.0000	time 0.2184 (0.2382)	loss 0.9233 (0.8769)	grad_norm 0.3497 (0.3502)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:26:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:30 lr 0.000038	 wd 0.0000	time 0.2127 (0.2357)	loss 0.7451 (0.8782)	grad_norm 0.3439 (0.3502)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:27:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:03 lr 0.000038	 wd 0.0000	time 0.1834 (0.2332)	loss 0.7783 (0.8797)	grad_norm 0.3694 (0.3505)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:27:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:04:37 lr 0.000038	 wd 0.0000	time 0.1919 (0.2311)	loss 0.9209 (0.8789)	grad_norm 0.3267 (0.3504)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:27:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:14 lr 0.000037	 wd 0.0000	time 0.1952 (0.2307)	loss 0.9189 (0.8798)	grad_norm 0.3295 (0.3504)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:28:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:03:51 lr 0.000037	 wd 0.0000	time 0.1973 (0.2310)	loss 0.8691 (0.8795)	grad_norm 0.3470 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7951MB
[2024-07-31 18:28:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:27 lr 0.000037	 wd 0.0000	time 0.1853 (0.2296)	loss 1.0557 (0.8794)	grad_norm 0.3684 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7951MB
[2024-07-31 18:29:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:03 lr 0.000037	 wd 0.0000	time 0.1783 (0.2282)	loss 1.0176 (0.8795)	grad_norm 0.3519 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7951MB
[2024-07-31 18:29:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:39 lr 0.000037	 wd 0.0000	time 0.2256 (0.2274)	loss 0.7822 (0.8808)	grad_norm 0.3619 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7951MB
[2024-07-31 18:29:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:17 lr 0.000036	 wd 0.0000	time 0.2186 (0.2287)	loss 0.7593 (0.8813)	grad_norm 0.3457 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7951MB
[2024-07-31 18:30:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:01:54 lr 0.000036	 wd 0.0000	time 0.1856 (0.2281)	loss 0.8018 (0.8808)	grad_norm 0.3440 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7951MB
[2024-07-31 18:30:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:31 lr 0.000036	 wd 0.0000	time 0.1830 (0.2271)	loss 0.8027 (0.8802)	grad_norm 0.3417 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7951MB
[2024-07-31 18:30:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:08 lr 0.000036	 wd 0.0000	time 0.2225 (0.2262)	loss 0.9380 (0.8801)	grad_norm 0.3502 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7951MB
[2024-07-31 18:31:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:45 lr 0.000036	 wd 0.0000	time 0.4850 (0.2267)	loss 0.9307 (0.8797)	grad_norm 0.3466 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7951MB
[2024-07-31 18:31:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:23 lr 0.000035	 wd 0.0000	time 0.1911 (0.2262)	loss 0.8369 (0.8800)	grad_norm 0.3498 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7951MB
[2024-07-31 18:31:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1589 (0.2245)	loss 0.9331 (0.8803)	grad_norm 0.3440 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7951MB
[2024-07-31 18:32:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 17 training takes 0:09:26
[2024-07-31 18:32:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 17.925 (17.925)	Loss 0.3555 (0.3555)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 18:32:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.240 Acc@5 97.596
[2024-07-31 18:32:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-31 18:32:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.24%
[2024-07-31 18:33:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][0/2502]	eta 23:28:46 lr 0.000035	 wd 0.0000	time 33.7837 (33.7837)	loss 0.9131 (0.9131)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:33:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:21:40 lr 0.000035	 wd 0.0000	time 0.1763 (0.5416)	loss 0.9980 (0.8846)	grad_norm 0.3607 (0.3531)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:33:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:14:18 lr 0.000035	 wd 0.0000	time 0.1862 (0.3728)	loss 0.8525 (0.8797)	grad_norm 0.3640 (0.3521)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:34:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:11:37 lr 0.000035	 wd 0.0000	time 0.2355 (0.3166)	loss 0.9194 (0.8832)	grad_norm 0.3507 (0.3529)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:34:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:11:01 lr 0.000034	 wd 0.0000	time 0.1935 (0.3148)	loss 0.7988 (0.8844)	grad_norm 0.3673 (0.3525)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:35:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:09:45 lr 0.000034	 wd 0.0000	time 0.2011 (0.2925)	loss 0.7031 (0.8843)	grad_norm 0.3460 (0.3516)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:35:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:08:47 lr 0.000034	 wd 0.0000	time 0.1848 (0.2774)	loss 0.9458 (0.8805)	grad_norm 0.3627 (0.3517)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:35:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:08:00 lr 0.000034	 wd 0.0000	time 0.2402 (0.2666)	loss 0.9399 (0.8775)	grad_norm 0.3346 (0.3514)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:36:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:26 lr 0.000034	 wd 0.0000	time 0.2643 (0.2626)	loss 1.0732 (0.8758)	grad_norm 0.3388 (0.3511)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:36:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:06:54 lr 0.000033	 wd 0.0000	time 0.1927 (0.2586)	loss 0.9526 (0.8764)	grad_norm 0.3602 (0.3512)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:36:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:20 lr 0.000033	 wd 0.0000	time 0.1868 (0.2532)	loss 0.8477 (0.8771)	grad_norm 0.3552 (0.3514)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:37:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:49 lr 0.000033	 wd 0.0000	time 0.1843 (0.2491)	loss 0.7925 (0.8782)	grad_norm 0.3450 (0.3513)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:37:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:20 lr 0.000033	 wd 0.0000	time 0.2073 (0.2462)	loss 0.8965 (0.8778)	grad_norm 0.3465 (0.3514)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:37:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:04:55 lr 0.000033	 wd 0.0000	time 0.3121 (0.2454)	loss 0.8730 (0.8791)	grad_norm 0.3466 (0.3515)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:38:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:27 lr 0.000032	 wd 0.0000	time 0.2392 (0.2429)	loss 1.0029 (0.8784)	grad_norm 0.3578 (0.3517)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:38:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:04:00 lr 0.000032	 wd 0.0000	time 0.1926 (0.2404)	loss 0.8579 (0.8794)	grad_norm 0.3571 (0.3516)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:38:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:34 lr 0.000032	 wd 0.0000	time 0.1710 (0.2380)	loss 0.8696 (0.8787)	grad_norm 0.3495 (0.3517)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:39:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:10 lr 0.000032	 wd 0.0000	time 0.2126 (0.2372)	loss 0.9761 (0.8788)	grad_norm 0.3653 (0.3518)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:39:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:46 lr 0.000032	 wd 0.0000	time 0.1703 (0.2377)	loss 0.8320 (0.8787)	grad_norm 0.3699 (0.3519)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:40:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:22 lr 0.000032	 wd 0.0000	time 0.2186 (0.2361)	loss 0.8311 (0.8784)	grad_norm 0.3599 (0.3520)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:40:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:01:57 lr 0.000031	 wd 0.0000	time 0.1807 (0.2347)	loss 0.8828 (0.8790)	grad_norm 0.3299 (0.3521)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:40:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:33 lr 0.000031	 wd 0.0000	time 0.2354 (0.2338)	loss 0.7378 (0.8791)	grad_norm 0.3609 (0.3522)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:41:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:10 lr 0.000031	 wd 0.0000	time 0.2007 (0.2343)	loss 0.8906 (0.8789)	grad_norm 0.3471 (0.3523)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:41:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:47 lr 0.000031	 wd 0.0000	time 0.1840 (0.2333)	loss 0.7642 (0.8793)	grad_norm 0.3324 (0.3523)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:41:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:23 lr 0.000031	 wd 0.0000	time 0.1873 (0.2322)	loss 0.8862 (0.8795)	grad_norm 0.3591 (0.3525)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:42:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000030	 wd 0.0000	time 0.1591 (0.2303)	loss 0.8677 (0.8795)	grad_norm 0.3551 (0.3525)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:42:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 18 training takes 0:09:40
[2024-07-31 18:42:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 40.263 (40.263)	Loss 0.3560 (0.3560)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 18:43:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.226 Acc@5 97.598
[2024-07-31 18:43:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-31 18:43:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.24%
[2024-07-31 18:43:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][0/2502]	eta 10:34:34 lr 0.000030	 wd 0.0000	time 15.2176 (15.2176)	loss 0.8574 (0.8574)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:43:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:14:26 lr 0.000030	 wd 0.0000	time 0.2287 (0.3607)	loss 1.0059 (0.8714)	grad_norm 0.3511 (0.3528)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:44:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:12:24 lr 0.000030	 wd 0.0000	time 1.5797 (0.3235)	loss 0.6943 (0.8687)	grad_norm 0.3679 (0.3527)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:44:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:10:28 lr 0.000030	 wd 0.0000	time 0.1997 (0.2856)	loss 0.9917 (0.8740)	grad_norm 0.3536 (0.3528)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:44:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:09:17 lr 0.000030	 wd 0.0000	time 0.1808 (0.2650)	loss 0.8237 (0.8761)	grad_norm 0.3396 (0.3525)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:45:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:08:24 lr 0.000029	 wd 0.0000	time 0.1817 (0.2521)	loss 0.9331 (0.8759)	grad_norm 0.3583 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7951MB
[2024-07-31 18:45:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:07:49 lr 0.000029	 wd 0.0000	time 0.2588 (0.2471)	loss 0.7539 (0.8774)	grad_norm 0.3502 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7951MB
[2024-07-31 18:46:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:07:21 lr 0.000029	 wd 0.0000	time 0.1864 (0.2452)	loss 0.9937 (0.8787)	grad_norm 0.3447 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7951MB
[2024-07-31 18:46:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:06:49 lr 0.000029	 wd 0.0000	time 0.1936 (0.2406)	loss 0.8550 (0.8798)	grad_norm 0.3592 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7951MB
[2024-07-31 18:46:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:06:19 lr 0.000029	 wd 0.0000	time 0.1799 (0.2366)	loss 0.8535 (0.8797)	grad_norm 0.3536 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7951MB
[2024-07-31 18:47:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:05:51 lr 0.000028	 wd 0.0000	time 0.1698 (0.2338)	loss 0.9487 (0.8806)	grad_norm 0.3497 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7951MB
[2024-07-31 18:47:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:27 lr 0.000028	 wd 0.0000	time 0.2740 (0.2335)	loss 0.8403 (0.8800)	grad_norm 0.3565 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7951MB
[2024-07-31 18:47:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:03 lr 0.000028	 wd 0.0000	time 0.2047 (0.2328)	loss 0.8677 (0.8801)	grad_norm 0.3548 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7951MB
[2024-07-31 18:48:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:04:37 lr 0.000028	 wd 0.0000	time 0.1733 (0.2309)	loss 0.8516 (0.8807)	grad_norm 0.3490 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7951MB
[2024-07-31 18:48:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:12 lr 0.000028	 wd 0.0000	time 0.1641 (0.2289)	loss 0.8311 (0.8801)	grad_norm 0.3543 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7951MB
[2024-07-31 18:48:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:03:48 lr 0.000028	 wd 0.0000	time 0.1746 (0.2279)	loss 0.8770 (0.8806)	grad_norm 0.3374 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7951MB
[2024-07-31 18:49:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:26 lr 0.000027	 wd 0.0000	time 0.1911 (0.2287)	loss 0.8892 (0.8810)	grad_norm 0.3744 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7951MB
[2024-07-31 18:49:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:02 lr 0.000027	 wd 0.0000	time 0.2012 (0.2277)	loss 0.9849 (0.8810)	grad_norm 0.3492 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7951MB
[2024-07-31 18:49:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:39 lr 0.000027	 wd 0.0000	time 0.1842 (0.2266)	loss 0.8145 (0.8813)	grad_norm 0.3575 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7951MB
[2024-07-31 18:50:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:15 lr 0.000027	 wd 0.0000	time 0.2123 (0.2257)	loss 0.8501 (0.8813)	grad_norm 0.3539 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7951MB
[2024-07-31 18:50:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:54 lr 0.000027	 wd 0.0000	time 0.2249 (0.2271)	loss 0.9326 (0.8811)	grad_norm 0.3460 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7951MB
[2024-07-31 18:51:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:31 lr 0.000026	 wd 0.0000	time 0.1884 (0.2267)	loss 0.9702 (0.8808)	grad_norm 0.3509 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7951MB
[2024-07-31 18:51:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:08 lr 0.000026	 wd 0.0000	time 0.2077 (0.2258)	loss 0.8740 (0.8803)	grad_norm 0.3887 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7951MB
[2024-07-31 18:51:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:45 lr 0.000026	 wd 0.0000	time 0.1923 (0.2248)	loss 0.9136 (0.8799)	grad_norm 0.3488 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7951MB
[2024-07-31 18:52:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:22 lr 0.000026	 wd 0.0000	time 0.2025 (0.2246)	loss 0.9590 (0.8798)	grad_norm 0.3705 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7951MB
[2024-07-31 18:52:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1588 (0.2238)	loss 0.7075 (0.8798)	grad_norm 0.3550 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7951MB
[2024-07-31 18:52:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 19 training takes 0:09:28
[2024-07-31 18:52:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 19.195 (19.195)	Loss 0.3572 (0.3572)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 18:53:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.258 Acc@5 97.608
[2024-07-31 18:53:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-31 18:53:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.26%
[2024-07-31 18:53:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-31 18:53:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-31 18:53:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][0/2502]	eta 11:17:29 lr 0.000026	 wd 0.0000	time 16.2469 (16.2469)	loss 0.8311 (0.8311)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:53:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:15:34 lr 0.000026	 wd 0.0000	time 0.1885 (0.3889)	loss 1.0186 (0.8825)	grad_norm 0.3567 (0.3569)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:54:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:11:41 lr 0.000025	 wd 0.0000	time 0.1782 (0.3046)	loss 0.9351 (0.8745)	grad_norm 0.3616 (0.3560)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:54:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:09:56 lr 0.000025	 wd 0.0000	time 0.2092 (0.2709)	loss 0.7520 (0.8706)	grad_norm 0.3586 (0.3556)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:54:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:08:53 lr 0.000025	 wd 0.0000	time 0.1662 (0.2537)	loss 0.8760 (0.8713)	grad_norm 0.3631 (0.3557)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:55:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:08:11 lr 0.000025	 wd 0.0000	time 0.2520 (0.2457)	loss 0.8564 (0.8706)	grad_norm 0.3384 (0.3563)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:55:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:07:56 lr 0.000025	 wd 0.0000	time 0.1803 (0.2506)	loss 0.7915 (0.8713)	grad_norm 0.3545 (0.3559)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:56:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:19 lr 0.000025	 wd 0.0000	time 0.1566 (0.2437)	loss 0.7881 (0.8717)	grad_norm 0.3482 (0.3559)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:56:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:06:46 lr 0.000024	 wd 0.0000	time 0.1990 (0.2390)	loss 1.0117 (0.8723)	grad_norm 0.3444 (0.3559)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:56:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:16 lr 0.000024	 wd 0.0000	time 0.1920 (0.2353)	loss 0.7588 (0.8723)	grad_norm 0.3419 (0.3560)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:57:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:05:59 lr 0.000024	 wd 0.0000	time 0.2126 (0.2392)	loss 0.8062 (0.8719)	grad_norm 0.3515 (0.3557)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:57:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:31 lr 0.000024	 wd 0.0000	time 0.1887 (0.2362)	loss 0.7949 (0.8722)	grad_norm 0.3430 (0.3557)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:57:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:04 lr 0.000024	 wd 0.0000	time 0.1943 (0.2338)	loss 0.7305 (0.8721)	grad_norm 0.3501 (0.3557)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:58:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:04:38 lr 0.000023	 wd 0.0000	time 0.1674 (0.2315)	loss 0.8877 (0.8721)	grad_norm 0.3538 (0.3554)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:58:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:14 lr 0.000023	 wd 0.0000	time 0.1979 (0.2308)	loss 0.9233 (0.8726)	grad_norm 0.3702 (0.3554)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:58:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:03:52 lr 0.000023	 wd 0.0000	time 0.1960 (0.2316)	loss 0.9741 (0.8722)	grad_norm 0.3579 (0.3553)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:59:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:27 lr 0.000023	 wd 0.0000	time 0.1919 (0.2301)	loss 0.9067 (0.8715)	grad_norm 0.3713 (0.3555)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 18:59:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:03 lr 0.000023	 wd 0.0000	time 0.1644 (0.2287)	loss 0.9565 (0.8715)	grad_norm 0.3496 (0.3553)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:00:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:39 lr 0.000023	 wd 0.0000	time 0.2353 (0.2278)	loss 0.7959 (0.8722)	grad_norm 0.3505 (0.3553)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:00:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:18 lr 0.000022	 wd 0.0000	time 0.1821 (0.2295)	loss 1.0000 (0.8729)	grad_norm 0.3670 (0.3554)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:00:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:01:54 lr 0.000022	 wd 0.0000	time 0.1732 (0.2284)	loss 0.9058 (0.8728)	grad_norm 0.3477 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7951MB
[2024-07-31 19:01:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:31 lr 0.000022	 wd 0.0000	time 0.1881 (0.2275)	loss 0.9287 (0.8733)	grad_norm 0.3681 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7951MB
[2024-07-31 19:01:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:08 lr 0.000022	 wd 0.0000	time 0.2374 (0.2265)	loss 0.8887 (0.8739)	grad_norm 0.3604 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7951MB
[2024-07-31 19:01:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:45 lr 0.000022	 wd 0.0000	time 0.2229 (0.2263)	loss 0.8164 (0.8747)	grad_norm 0.3777 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7951MB
[2024-07-31 19:02:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:23 lr 0.000022	 wd 0.0000	time 0.1811 (0.2266)	loss 0.8286 (0.8749)	grad_norm 0.3567 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7951MB
[2024-07-31 19:02:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1583 (0.2250)	loss 0.7896 (0.8747)	grad_norm 0.3376 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7951MB
[2024-07-31 19:02:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 20 training takes 0:09:29
[2024-07-31 19:02:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 17.931 (17.931)	Loss 0.3577 (0.3577)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 19:03:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.278 Acc@5 97.620
[2024-07-31 19:03:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-31 19:03:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.28%
[2024-07-31 19:03:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-31 19:03:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-31 19:03:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][0/2502]	eta 21:12:34 lr 0.000021	 wd 0.0000	time 30.5174 (30.5174)	loss 0.9189 (0.9189)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:04:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:20:12 lr 0.000021	 wd 0.0000	time 0.1981 (0.5049)	loss 0.8906 (0.8866)	grad_norm 0.3547 (0.3564)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:04:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:13:34 lr 0.000021	 wd 0.0000	time 0.1990 (0.3536)	loss 0.9268 (0.8798)	grad_norm 0.3481 (0.3557)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:04:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:11:05 lr 0.000021	 wd 0.0000	time 0.2034 (0.3024)	loss 0.9097 (0.8772)	grad_norm 0.3539 (0.3563)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:05:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:10:29 lr 0.000021	 wd 0.0000	time 0.2349 (0.2994)	loss 0.9888 (0.8772)	grad_norm 0.3536 (0.3556)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:05:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:09:23 lr 0.000021	 wd 0.0000	time 0.1722 (0.2813)	loss 0.8247 (0.8776)	grad_norm 0.3429 (0.3560)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:05:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:30 lr 0.000020	 wd 0.0000	time 0.2010 (0.2682)	loss 0.8774 (0.8771)	grad_norm 0.3693 (0.3564)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:06:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:07:46 lr 0.000020	 wd 0.0000	time 0.1871 (0.2591)	loss 1.0117 (0.8774)	grad_norm 0.3737 (0.3564)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:06:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:14 lr 0.000020	 wd 0.0000	time 0.2325 (0.2552)	loss 0.9048 (0.8776)	grad_norm 0.3860 (0.3564)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:07:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:45 lr 0.000020	 wd 0.0000	time 0.2152 (0.2531)	loss 0.8311 (0.8786)	grad_norm 0.3466 (0.3562)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:07:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:13 lr 0.000020	 wd 0.0000	time 0.1907 (0.2486)	loss 0.8354 (0.8780)	grad_norm 0.3404 (0.3561)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:07:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:05:43 lr 0.000020	 wd 0.0000	time 0.1771 (0.2447)	loss 0.9009 (0.8786)	grad_norm 0.3457 (0.3562)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:08:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:14 lr 0.000019	 wd 0.0000	time 0.2409 (0.2418)	loss 0.8398 (0.8798)	grad_norm 0.3497 (0.3563)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:08:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:50 lr 0.000019	 wd 0.0000	time 0.1921 (0.2418)	loss 0.9502 (0.8793)	grad_norm 0.3422 (0.3562)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:08:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:24 lr 0.000019	 wd 0.0000	time 0.1817 (0.2396)	loss 0.8936 (0.8793)	grad_norm 0.3475 (0.3560)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:09:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:03:58 lr 0.000019	 wd 0.0000	time 0.2010 (0.2376)	loss 0.9351 (0.8791)	grad_norm 0.3492 (0.3559)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:09:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:32 lr 0.000019	 wd 0.0000	time 0.1783 (0.2355)	loss 0.9087 (0.8785)	grad_norm 0.3659 (0.3561)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:09:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:08 lr 0.000019	 wd 0.0000	time 0.2146 (0.2347)	loss 0.8857 (0.8791)	grad_norm 0.3476 (0.3562)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:10:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:44 lr 0.000018	 wd 0.0000	time 0.1732 (0.2347)	loss 0.8926 (0.8791)	grad_norm 0.3484 (0.3563)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:10:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:20 lr 0.000018	 wd 0.0000	time 0.1968 (0.2333)	loss 0.9048 (0.8792)	grad_norm 0.3514 (0.3563)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:11:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:56 lr 0.000018	 wd 0.0000	time 0.2146 (0.2320)	loss 0.7544 (0.8790)	grad_norm 0.3648 (0.3565)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:11:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:32 lr 0.000018	 wd 0.0000	time 0.2225 (0.2310)	loss 0.7769 (0.8784)	grad_norm 0.3433 (0.3567)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:11:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:09 lr 0.000018	 wd 0.0000	time 0.1608 (0.2314)	loss 0.7920 (0.8779)	grad_norm 0.3671 (0.3567)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:12:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:46 lr 0.000018	 wd 0.0000	time 0.1972 (0.2309)	loss 0.9365 (0.8779)	grad_norm 0.3516 (0.3567)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:12:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:23 lr 0.000018	 wd 0.0000	time 0.1702 (0.2299)	loss 0.8721 (0.8779)	grad_norm 0.3483 (0.3568)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:12:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000017	 wd 0.0000	time 0.1547 (0.2281)	loss 0.8955 (0.8780)	grad_norm 0.3237 (0.3568)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:12:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 21 training takes 0:09:40
[2024-07-31 19:13:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 36.901 (36.901)	Loss 0.3545 (0.3545)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 19:13:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.254 Acc@5 97.612
[2024-07-31 19:13:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-31 19:13:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.28%
[2024-07-31 19:14:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][0/2502]	eta 10:40:56 lr 0.000017	 wd 0.0000	time 15.3703 (15.3703)	loss 0.8369 (0.8369)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:14:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:14:29 lr 0.000017	 wd 0.0000	time 0.2389 (0.3618)	loss 0.9131 (0.8822)	grad_norm 0.3541 (0.3586)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:14:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:11:46 lr 0.000017	 wd 0.0000	time 0.2066 (0.3068)	loss 0.8105 (0.8777)	grad_norm 0.3492 (0.3576)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:15:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:10:02 lr 0.000017	 wd 0.0000	time 0.2041 (0.2736)	loss 0.8701 (0.8769)	grad_norm 0.3514 (0.3580)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:15:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:08:57 lr 0.000017	 wd 0.0000	time 0.1839 (0.2555)	loss 0.8140 (0.8819)	grad_norm 0.3425 (0.3580)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:15:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:08:13 lr 0.000017	 wd 0.0000	time 0.2567 (0.2465)	loss 0.7046 (0.8801)	grad_norm 0.3467 (0.3574)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:16:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:07:40 lr 0.000016	 wd 0.0000	time 0.2831 (0.2423)	loss 0.9199 (0.8815)	grad_norm 0.3407 (0.3575)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:16:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:14 lr 0.000016	 wd 0.0000	time 0.1995 (0.2411)	loss 0.9888 (0.8800)	grad_norm 0.3460 (0.3579)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:17:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:06:42 lr 0.000016	 wd 0.0000	time 0.1993 (0.2367)	loss 0.8867 (0.8800)	grad_norm 0.3500 (0.3577)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:17:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:13 lr 0.000016	 wd 0.0000	time 0.2152 (0.2334)	loss 0.8374 (0.8798)	grad_norm 0.3395 (0.3579)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:17:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:05:46 lr 0.000016	 wd 0.0000	time 0.2162 (0.2307)	loss 0.9004 (0.8795)	grad_norm 0.3460 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7951MB
[2024-07-31 19:18:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:24 lr 0.000016	 wd 0.0000	time 0.3547 (0.2312)	loss 0.7798 (0.8781)	grad_norm 0.3408 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7951MB
[2024-07-31 19:18:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:00 lr 0.000016	 wd 0.0000	time 0.1831 (0.2306)	loss 0.8481 (0.8784)	grad_norm 0.3556 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7951MB
[2024-07-31 19:18:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:04:35 lr 0.000015	 wd 0.0000	time 0.2088 (0.2288)	loss 0.8701 (0.8771)	grad_norm 0.3586 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7951MB
[2024-07-31 19:19:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:10 lr 0.000015	 wd 0.0000	time 0.1792 (0.2269)	loss 0.8599 (0.8769)	grad_norm 0.3627 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7951MB
[2024-07-31 19:19:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:03:46 lr 0.000015	 wd 0.0000	time 0.2012 (0.2264)	loss 0.6885 (0.8769)	grad_norm 0.3500 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7951MB
[2024-07-31 19:19:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:24 lr 0.000015	 wd 0.0000	time 0.1689 (0.2273)	loss 0.8345 (0.8771)	grad_norm 0.3611 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7951MB
[2024-07-31 19:20:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:01 lr 0.000015	 wd 0.0000	time 0.2119 (0.2262)	loss 0.8813 (0.8766)	grad_norm 0.3690 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7951MB
[2024-07-31 19:20:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:37 lr 0.000015	 wd 0.0000	time 0.1794 (0.2250)	loss 0.9351 (0.8766)	grad_norm 0.3519 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7951MB
[2024-07-31 19:21:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:14 lr 0.000015	 wd 0.0000	time 0.1689 (0.2242)	loss 0.8887 (0.8771)	grad_norm 0.3553 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7951MB
[2024-07-31 19:21:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:53 lr 0.000014	 wd 0.0000	time 0.1977 (0.2253)	loss 0.9609 (0.8768)	grad_norm 0.3240 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7951MB
[2024-07-31 19:21:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:30 lr 0.000014	 wd 0.0000	time 0.2177 (0.2252)	loss 0.8208 (0.8772)	grad_norm 0.3632 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7951MB
[2024-07-31 19:22:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:07 lr 0.000014	 wd 0.0000	time 0.1854 (0.2245)	loss 0.6870 (0.8771)	grad_norm 0.3500 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7951MB
[2024-07-31 19:22:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:45 lr 0.000014	 wd 0.0000	time 0.1837 (0.2238)	loss 0.9443 (0.8771)	grad_norm 0.3565 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7951MB
[2024-07-31 19:22:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:22 lr 0.000014	 wd 0.0000	time 0.2010 (0.2237)	loss 0.7666 (0.8772)	grad_norm 0.3560 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7951MB
[2024-07-31 19:23:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1580 (0.2226)	loss 0.8413 (0.8768)	grad_norm 0.3719 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7951MB
[2024-07-31 19:23:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 22 training takes 0:09:28
[2024-07-31 19:23:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 19.772 (19.772)	Loss 0.3542 (0.3542)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7951MB
[2024-07-31 19:24:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.284 Acc@5 97.612
[2024-07-31 19:24:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-31 19:24:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.28%
[2024-07-31 19:24:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-31 19:24:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-31 19:24:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][0/2502]	eta 19:14:49 lr 0.000014	 wd 0.0000	time 27.6936 (27.6936)	loss 0.7661 (0.7661)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:24:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:20:22 lr 0.000014	 wd 0.0000	time 0.1999 (0.5089)	loss 0.8770 (0.8760)	grad_norm 0.3630 (0.3603)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:25:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:13:36 lr 0.000013	 wd 0.0000	time 0.1940 (0.3549)	loss 0.9365 (0.8733)	grad_norm 0.3784 (0.3586)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:25:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:11:08 lr 0.000013	 wd 0.0000	time 0.1767 (0.3036)	loss 0.7764 (0.8716)	grad_norm 0.3500 (0.3586)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:25:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:09:52 lr 0.000013	 wd 0.0000	time 0.2115 (0.2817)	loss 1.0000 (0.8732)	grad_norm 0.3611 (0.3593)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:26:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:09:00 lr 0.000013	 wd 0.0000	time 0.1814 (0.2701)	loss 0.8994 (0.8773)	grad_norm 0.3471 (0.3595)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:26:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:08:14 lr 0.000013	 wd 0.0000	time 0.2100 (0.2598)	loss 0.8975 (0.8780)	grad_norm 0.3604 (0.3597)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:27:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:34 lr 0.000013	 wd 0.0000	time 0.1893 (0.2522)	loss 0.9780 (0.8787)	grad_norm 0.3440 (0.3593)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:27:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:06:59 lr 0.000013	 wd 0.0000	time 0.1698 (0.2462)	loss 0.9775 (0.8783)	grad_norm 0.3598 (0.3591)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:27:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:06:31 lr 0.000012	 wd 0.0000	time 0.1985 (0.2445)	loss 1.1230 (0.8766)	grad_norm 0.3594 (0.3591)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:28:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:05 lr 0.000012	 wd 0.0000	time 0.2019 (0.2434)	loss 0.7451 (0.8771)	grad_norm 0.3599 (0.3591)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:28:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:36 lr 0.000012	 wd 0.0000	time 0.1806 (0.2399)	loss 0.7266 (0.8763)	grad_norm 0.3668 (0.3592)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:28:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:08 lr 0.000012	 wd 0.0000	time 0.1920 (0.2370)	loss 0.9399 (0.8767)	grad_norm 0.3451 (0.3592)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:29:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:04:42 lr 0.000012	 wd 0.0000	time 0.2118 (0.2353)	loss 0.9385 (0.8768)	grad_norm 0.3822 (0.3593)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:29:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:19 lr 0.000012	 wd 0.0000	time 0.1837 (0.2354)	loss 0.9453 (0.8772)	grad_norm 0.3545 (0.3593)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:29:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:03:54 lr 0.000012	 wd 0.0000	time 0.1772 (0.2337)	loss 0.7617 (0.8781)	grad_norm 0.3679 (0.3593)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:30:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:29 lr 0.000012	 wd 0.0000	time 0.1646 (0.2319)	loss 0.8867 (0.8782)	grad_norm 0.3496 (0.3594)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:30:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:04 lr 0.000011	 wd 0.0000	time 0.2059 (0.2303)	loss 0.7861 (0.8780)	grad_norm 0.3588 (0.3595)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:30:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:41 lr 0.000011	 wd 0.0000	time 0.2037 (0.2303)	loss 0.9126 (0.8782)	grad_norm 0.3461 (0.3595)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:31:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:18 lr 0.000011	 wd 0.0000	time 0.2007 (0.2306)	loss 0.8042 (0.8778)	grad_norm 0.3502 (0.3594)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:31:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:01:55 lr 0.000011	 wd 0.0000	time 0.2011 (0.2295)	loss 0.9844 (0.8775)	grad_norm 0.3526 (0.3594)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:32:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:31 lr 0.000011	 wd 0.0000	time 0.1933 (0.2284)	loss 1.0361 (0.8776)	grad_norm 0.3333 (0.3593)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:32:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:08 lr 0.000011	 wd 0.0000	time 0.2327 (0.2277)	loss 0.9556 (0.8770)	grad_norm 0.3730 (0.3592)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:32:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:46 lr 0.000011	 wd 0.0000	time 0.3317 (0.2281)	loss 0.8696 (0.8772)	grad_norm 0.3581 (0.3592)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:33:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:23 lr 0.000011	 wd 0.0000	time 0.2488 (0.2273)	loss 0.8745 (0.8773)	grad_norm 0.3532 (0.3592)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:33:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1602 (0.2257)	loss 0.8037 (0.8771)	grad_norm 0.3634 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7951MB
[2024-07-31 19:33:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 23 training takes 0:09:32
[2024-07-31 19:34:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 25.640 (25.640)	Loss 0.3547 (0.3547)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 19:34:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.232 Acc@5 97.602
[2024-07-31 19:34:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-31 19:34:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.28%
[2024-07-31 19:34:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][0/2502]	eta 14:49:28 lr 0.000010	 wd 0.0000	time 21.3302 (21.3302)	loss 0.8867 (0.8867)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:35:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:16:28 lr 0.000010	 wd 0.0000	time 0.2025 (0.4113)	loss 0.9907 (0.8729)	grad_norm 0.3429 (0.3609)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:35:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:11:46 lr 0.000010	 wd 0.0000	time 0.1788 (0.3070)	loss 0.8843 (0.8753)	grad_norm 0.3640 (0.3595)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:35:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:10:54 lr 0.000010	 wd 0.0000	time 0.4338 (0.2974)	loss 0.8057 (0.8784)	grad_norm 0.3815 (0.3594)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:36:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:10:18 lr 0.000010	 wd 0.0000	time 0.1943 (0.2944)	loss 0.7388 (0.8795)	grad_norm 0.3467 (0.3593)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:36:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:09:16 lr 0.000010	 wd 0.0000	time 0.1805 (0.2780)	loss 0.8862 (0.8814)	grad_norm 0.4008 (0.3594)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:37:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:08:23 lr 0.000010	 wd 0.0000	time 0.1826 (0.2647)	loss 0.8979 (0.8790)	grad_norm 0.3392 (0.3599)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:37:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:07:47 lr 0.000010	 wd 0.0000	time 0.2298 (0.2593)	loss 0.8325 (0.8781)	grad_norm 0.3496 (0.3594)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:37:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:07:15 lr 0.000010	 wd 0.0000	time 0.2092 (0.2559)	loss 0.8027 (0.8774)	grad_norm 0.3665 (0.3592)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:38:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:06:41 lr 0.000009	 wd 0.0000	time 0.1583 (0.2504)	loss 0.9375 (0.8782)	grad_norm 0.3683 (0.3591)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:38:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:09 lr 0.000009	 wd 0.0000	time 0.1725 (0.2460)	loss 0.8213 (0.8789)	grad_norm 0.3623 (0.3591)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:38:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:05:40 lr 0.000009	 wd 0.0000	time 0.1808 (0.2426)	loss 0.8188 (0.8787)	grad_norm 0.3579 (0.3595)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:39:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:17 lr 0.000009	 wd 0.0000	time 0.1749 (0.2441)	loss 0.8315 (0.8784)	grad_norm 0.3345 (0.3596)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:39:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:04:49 lr 0.000009	 wd 0.0000	time 0.2090 (0.2411)	loss 0.7339 (0.8769)	grad_norm 0.3647 (0.3595)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:39:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:22 lr 0.000009	 wd 0.0000	time 0.2167 (0.2386)	loss 0.7778 (0.8772)	grad_norm 0.3481 (0.3595)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:40:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:03:56 lr 0.000009	 wd 0.0000	time 0.1613 (0.2363)	loss 0.8311 (0.8772)	grad_norm 0.3547 (0.3595)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:40:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:32 lr 0.000009	 wd 0.0000	time 0.2434 (0.2356)	loss 0.9077 (0.8772)	grad_norm 0.3483 (0.3596)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:41:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:09 lr 0.000008	 wd 0.0000	time 0.1789 (0.2359)	loss 0.9624 (0.8775)	grad_norm 0.3657 (0.3596)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:41:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:44 lr 0.000008	 wd 0.0000	time 0.1936 (0.2344)	loss 0.7798 (0.8778)	grad_norm 0.3508 (0.3596)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:41:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:20 lr 0.000008	 wd 0.0000	time 0.2318 (0.2329)	loss 0.7495 (0.8775)	grad_norm 0.3411 (0.3596)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:42:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:01:56 lr 0.000008	 wd 0.0000	time 0.2066 (0.2320)	loss 0.7148 (0.8774)	grad_norm 0.3657 (0.3598)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:42:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:33 lr 0.000008	 wd 0.0000	time 0.1699 (0.2323)	loss 0.9780 (0.8771)	grad_norm 0.3619 (0.3597)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:42:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:09 lr 0.000008	 wd 0.0000	time 0.1846 (0.2315)	loss 0.8667 (0.8770)	grad_norm 0.3525 (0.3598)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:43:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:46 lr 0.000008	 wd 0.0000	time 0.1893 (0.2305)	loss 0.9185 (0.8772)	grad_norm 0.3442 (0.3597)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:43:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:23 lr 0.000008	 wd 0.0000	time 0.2021 (0.2295)	loss 1.0527 (0.8770)	grad_norm 0.3498 (0.3596)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:43:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1664 (0.2281)	loss 0.9883 (0.8770)	grad_norm 0.3460 (0.3596)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:44:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 24 training takes 0:09:41
[2024-07-31 19:44:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 36.694 (36.694)	Loss 0.3557 (0.3557)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 19:44:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.264 Acc@5 97.626
[2024-07-31 19:44:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-31 19:44:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.28%
[2024-07-31 19:45:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][0/2502]	eta 15:35:14 lr 0.000008	 wd 0.0000	time 22.4278 (22.4278)	loss 0.8691 (0.8691)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:45:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:18:22 lr 0.000008	 wd 0.0000	time 0.1880 (0.4592)	loss 0.8354 (0.8924)	grad_norm 0.3507 (0.3618)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:46:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:12:43 lr 0.000007	 wd 0.0000	time 0.2055 (0.3318)	loss 0.8276 (0.8886)	grad_norm 0.3592 (0.3602)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:46:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:10:34 lr 0.000007	 wd 0.0000	time 0.1778 (0.2883)	loss 0.9082 (0.8809)	grad_norm 0.3634 (0.3600)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:46:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:09:19 lr 0.000007	 wd 0.0000	time 0.1851 (0.2663)	loss 0.7520 (0.8817)	grad_norm 0.3639 (0.3603)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:47:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:08:41 lr 0.000007	 wd 0.0000	time 0.2038 (0.2604)	loss 0.8633 (0.8809)	grad_norm 0.3359 (0.3603)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:47:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:01 lr 0.000007	 wd 0.0000	time 0.1707 (0.2531)	loss 0.7368 (0.8805)	grad_norm 0.3771 (0.3603)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:47:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:07:23 lr 0.000007	 wd 0.0000	time 0.1834 (0.2462)	loss 0.8325 (0.8796)	grad_norm 0.3569 (0.3601)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:48:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:06:50 lr 0.000007	 wd 0.0000	time 0.1918 (0.2410)	loss 0.9810 (0.8791)	grad_norm 0.3630 (0.3603)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:48:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:06:21 lr 0.000007	 wd 0.0000	time 0.2403 (0.2379)	loss 0.7354 (0.8789)	grad_norm 0.3568 (0.3603)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:48:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:05:58 lr 0.000007	 wd 0.0000	time 0.2058 (0.2387)	loss 0.9414 (0.8794)	grad_norm 0.3822 (0.3605)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:49:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:30 lr 0.000007	 wd 0.0000	time 0.2226 (0.2360)	loss 0.9922 (0.8788)	grad_norm 0.3629 (0.3605)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:49:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:04 lr 0.000006	 wd 0.0000	time 0.1812 (0.2336)	loss 1.0059 (0.8798)	grad_norm 0.3647 (0.3604)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:49:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:04:38 lr 0.000006	 wd 0.0000	time 0.2076 (0.2315)	loss 0.8843 (0.8788)	grad_norm 0.3536 (0.3604)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:50:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:14 lr 0.000006	 wd 0.0000	time 0.2183 (0.2312)	loss 0.9321 (0.8784)	grad_norm 0.3441 (0.3603)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:50:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:03:51 lr 0.000006	 wd 0.0000	time 0.1835 (0.2314)	loss 0.9663 (0.8793)	grad_norm 0.3482 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7951MB
[2024-07-31 19:51:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:27 lr 0.000006	 wd 0.0000	time 0.2110 (0.2299)	loss 0.7417 (0.8789)	grad_norm 0.3503 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7951MB
[2024-07-31 19:51:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:03 lr 0.000006	 wd 0.0000	time 0.1955 (0.2284)	loss 0.8159 (0.8796)	grad_norm 0.3533 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7951MB
[2024-07-31 19:51:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:39 lr 0.000006	 wd 0.0000	time 0.1872 (0.2277)	loss 0.8989 (0.8792)	grad_norm 0.3428 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7951MB
[2024-07-31 19:52:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:17 lr 0.000006	 wd 0.0000	time 0.1804 (0.2290)	loss 1.0010 (0.8791)	grad_norm 0.3577 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7951MB
[2024-07-31 19:52:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:01:54 lr 0.000006	 wd 0.0000	time 0.2327 (0.2283)	loss 1.0020 (0.8791)	grad_norm 0.3543 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7951MB
[2024-07-31 19:52:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:31 lr 0.000006	 wd 0.0000	time 0.1963 (0.2273)	loss 0.9053 (0.8786)	grad_norm 0.3496 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7951MB
[2024-07-31 19:53:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:08 lr 0.000006	 wd 0.0000	time 0.2209 (0.2264)	loss 0.8301 (0.8782)	grad_norm 0.3364 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7951MB
[2024-07-31 19:53:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:45 lr 0.000005	 wd 0.0000	time 0.2171 (0.2262)	loss 0.7817 (0.8780)	grad_norm 0.3525 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7951MB
[2024-07-31 19:54:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:23 lr 0.000005	 wd 0.0000	time 0.2998 (0.2264)	loss 0.8345 (0.8780)	grad_norm 0.3457 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7951MB
[2024-07-31 19:54:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000005	 wd 0.0000	time 0.1547 (0.2247)	loss 0.8667 (0.8783)	grad_norm 0.3638 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7951MB
[2024-07-31 19:54:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 25 training takes 0:09:30
[2024-07-31 19:54:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 18.237 (18.237)	Loss 0.3557 (0.3557)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 19:55:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.270 Acc@5 97.610
[2024-07-31 19:55:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-31 19:55:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.28%
[2024-07-31 19:55:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][0/2502]	eta 22:02:33 lr 0.000005	 wd 0.0000	time 31.7159 (31.7159)	loss 1.0215 (1.0215)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:55:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:21:04 lr 0.000005	 wd 0.0000	time 0.2034 (0.5265)	loss 0.7808 (0.8864)	grad_norm 0.3600 (0.3654)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:56:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:13:57 lr 0.000005	 wd 0.0000	time 0.1849 (0.3636)	loss 0.8662 (0.8827)	grad_norm 0.3666 (0.3636)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:56:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:11:33 lr 0.000005	 wd 0.0000	time 0.2409 (0.3151)	loss 0.8604 (0.8837)	grad_norm 0.3827 (0.3635)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:57:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:10:17 lr 0.000005	 wd 0.0000	time 0.2187 (0.2940)	loss 0.9092 (0.8814)	grad_norm 0.3667 (0.3625)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:57:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:09:15 lr 0.000005	 wd 0.0000	time 0.1977 (0.2776)	loss 0.8262 (0.8794)	grad_norm 0.3314 (0.3617)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:57:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:08:23 lr 0.000005	 wd 0.0000	time 0.2072 (0.2650)	loss 0.8628 (0.8803)	grad_norm 0.3589 (0.3617)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:58:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:41 lr 0.000005	 wd 0.0000	time 0.1876 (0.2561)	loss 0.8232 (0.8783)	grad_norm 0.3471 (0.3613)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:58:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:07:10 lr 0.000005	 wd 0.0000	time 0.2106 (0.2530)	loss 0.8584 (0.8794)	grad_norm 0.3676 (0.3612)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:58:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:06:41 lr 0.000005	 wd 0.0000	time 0.1808 (0.2504)	loss 0.7817 (0.8779)	grad_norm 0.3628 (0.3613)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:59:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:06:10 lr 0.000004	 wd 0.0000	time 0.2071 (0.2464)	loss 0.9565 (0.8782)	grad_norm 0.3478 (0.3612)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:59:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:40 lr 0.000004	 wd 0.0000	time 0.2088 (0.2427)	loss 0.9658 (0.8788)	grad_norm 0.3532 (0.3612)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 19:59:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:13 lr 0.000004	 wd 0.0000	time 0.2699 (0.2405)	loss 0.9053 (0.8786)	grad_norm 0.3585 (0.3612)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:00:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:04:48 lr 0.000004	 wd 0.0000	time 0.1977 (0.2401)	loss 0.7568 (0.8790)	grad_norm 0.3564 (0.3612)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:00:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:22 lr 0.000004	 wd 0.0000	time 0.1803 (0.2382)	loss 0.9663 (0.8787)	grad_norm 0.3553 (0.3612)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:00:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:03:56 lr 0.000004	 wd 0.0000	time 0.2033 (0.2362)	loss 0.8550 (0.8790)	grad_norm 0.3484 (0.3613)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:01:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:31 lr 0.000004	 wd 0.0000	time 0.2186 (0.2343)	loss 0.7456 (0.8780)	grad_norm 0.3395 (0.3612)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:01:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:07 lr 0.000004	 wd 0.0000	time 0.1992 (0.2335)	loss 0.8599 (0.8787)	grad_norm 0.3513 (0.3611)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:02:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:43 lr 0.000004	 wd 0.0000	time 0.1993 (0.2335)	loss 0.9331 (0.8792)	grad_norm 0.3562 (0.3613)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:02:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:19 lr 0.000004	 wd 0.0000	time 0.1776 (0.2322)	loss 0.8809 (0.8785)	grad_norm 0.3608 (0.3611)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:02:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:01:55 lr 0.000004	 wd 0.0000	time 0.2076 (0.2310)	loss 0.9282 (0.8785)	grad_norm 0.3609 (0.3611)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:03:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:32 lr 0.000004	 wd 0.0000	time 0.2171 (0.2303)	loss 0.9048 (0.8787)	grad_norm 0.3653 (0.3611)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:03:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:09 lr 0.000004	 wd 0.0000	time 0.1741 (0.2310)	loss 0.9419 (0.8787)	grad_norm 0.3555 (0.3610)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:03:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:46 lr 0.000004	 wd 0.0000	time 0.1888 (0.2303)	loss 0.8389 (0.8784)	grad_norm 0.3660 (0.3610)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:04:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:23 lr 0.000003	 wd 0.0000	time 0.1814 (0.2294)	loss 0.8716 (0.8788)	grad_norm 0.3729 (0.3610)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:04:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1578 (0.2276)	loss 0.9277 (0.8788)	grad_norm 0.3551 (0.3610)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:04:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 26 training takes 0:09:37
[2024-07-31 20:05:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 38.113 (38.113)	Loss 0.3552 (0.3552)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 20:05:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.304 Acc@5 97.612
[2024-07-31 20:05:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-31 20:05:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.30%
[2024-07-31 20:05:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saving......
[2024-07-31 20:05:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth saved !!!
[2024-07-31 20:05:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][0/2502]	eta 10:31:51 lr 0.000003	 wd 0.0000	time 15.1526 (15.1526)	loss 0.9277 (0.9277)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:06:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:14:25 lr 0.000003	 wd 0.0000	time 0.2189 (0.3602)	loss 0.8857 (0.8836)	grad_norm 0.3611 (0.3598)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:06:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:12:32 lr 0.000003	 wd 0.0000	time 0.1660 (0.3267)	loss 0.7192 (0.8778)	grad_norm 0.3747 (0.3602)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:07:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:10:29 lr 0.000003	 wd 0.0000	time 0.2085 (0.2859)	loss 0.8823 (0.8786)	grad_norm 0.3876 (0.3611)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:07:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:09:18 lr 0.000003	 wd 0.0000	time 0.1947 (0.2656)	loss 0.8208 (0.8777)	grad_norm 0.3565 (0.3613)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:07:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:08:24 lr 0.000003	 wd 0.0000	time 0.1776 (0.2520)	loss 0.7603 (0.8768)	grad_norm 0.3926 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7951MB
[2024-07-31 20:08:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:07:53 lr 0.000003	 wd 0.0000	time 0.2448 (0.2492)	loss 0.8130 (0.8791)	grad_norm 0.3684 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7951MB
[2024-07-31 20:08:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:24 lr 0.000003	 wd 0.0000	time 0.2053 (0.2465)	loss 0.8267 (0.8785)	grad_norm 0.3779 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7951MB
[2024-07-31 20:08:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:06:50 lr 0.000003	 wd 0.0000	time 0.2139 (0.2411)	loss 0.9009 (0.8780)	grad_norm 0.3435 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7951MB
[2024-07-31 20:09:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:20 lr 0.000003	 wd 0.0000	time 0.1810 (0.2373)	loss 0.7412 (0.8775)	grad_norm 0.3456 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7951MB
[2024-07-31 20:09:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:05:53 lr 0.000003	 wd 0.0000	time 0.2687 (0.2355)	loss 0.8877 (0.8770)	grad_norm 0.3526 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7951MB
[2024-07-31 20:10:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:30 lr 0.000003	 wd 0.0000	time 0.2346 (0.2355)	loss 0.7764 (0.8770)	grad_norm 0.3705 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7951MB
[2024-07-31 20:10:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:04 lr 0.000003	 wd 0.0000	time 0.1948 (0.2338)	loss 0.8916 (0.8762)	grad_norm 0.3527 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7951MB
[2024-07-31 20:10:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:38 lr 0.000003	 wd 0.0000	time 0.1995 (0.2318)	loss 0.8447 (0.8763)	grad_norm 0.3772 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7951MB
[2024-07-31 20:11:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:13 lr 0.000003	 wd 0.0000	time 0.1646 (0.2300)	loss 0.8120 (0.8763)	grad_norm 0.3537 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7951MB
[2024-07-31 20:11:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:03:50 lr 0.000003	 wd 0.0000	time 0.1976 (0.2297)	loss 0.9736 (0.8763)	grad_norm 0.3543 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7951MB
[2024-07-31 20:11:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:27 lr 0.000003	 wd 0.0000	time 0.1991 (0.2301)	loss 0.8809 (0.8763)	grad_norm 0.3600 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7951MB
[2024-07-31 20:12:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:03 lr 0.000002	 wd 0.0000	time 0.1950 (0.2288)	loss 0.8770 (0.8765)	grad_norm 0.3608 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7951MB
[2024-07-31 20:12:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:39 lr 0.000002	 wd 0.0000	time 0.1930 (0.2274)	loss 0.7710 (0.8769)	grad_norm 0.3575 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7951MB
[2024-07-31 20:12:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:16 lr 0.000002	 wd 0.0000	time 0.2257 (0.2269)	loss 0.8164 (0.8770)	grad_norm 0.3547 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7951MB
[2024-07-31 20:13:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:54 lr 0.000002	 wd 0.0000	time 0.1724 (0.2281)	loss 0.7568 (0.8767)	grad_norm 0.3457 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7951MB
[2024-07-31 20:13:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:31 lr 0.000002	 wd 0.0000	time 0.1911 (0.2272)	loss 1.0225 (0.8776)	grad_norm 0.3826 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7951MB
[2024-07-31 20:13:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:08 lr 0.000002	 wd 0.0000	time 0.1972 (0.2264)	loss 0.7339 (0.8771)	grad_norm 0.3538 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7951MB
[2024-07-31 20:14:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:45 lr 0.000002	 wd 0.0000	time 0.2268 (0.2256)	loss 0.8359 (0.8773)	grad_norm 0.3552 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7951MB
[2024-07-31 20:14:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:23 lr 0.000002	 wd 0.0000	time 0.2064 (0.2260)	loss 0.8901 (0.8770)	grad_norm 0.3668 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7951MB
[2024-07-31 20:15:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1582 (0.2245)	loss 0.8657 (0.8772)	grad_norm 0.3510 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7951MB
[2024-07-31 20:15:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 27 training takes 0:09:32
[2024-07-31 20:15:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 20.124 (20.124)	Loss 0.3564 (0.3564)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 20:15:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.278 Acc@5 97.622
[2024-07-31 20:15:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-31 20:15:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.30%
[2024-07-31 20:16:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][0/2502]	eta 22:00:16 lr 0.000002	 wd 0.0000	time 31.6614 (31.6614)	loss 0.8472 (0.8472)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:16:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:21:14 lr 0.000002	 wd 0.0000	time 0.1892 (0.5304)	loss 0.9014 (0.8727)	grad_norm 0.3798 (0.3619)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:17:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:14:02 lr 0.000002	 wd 0.0000	time 0.1929 (0.3659)	loss 0.8403 (0.8785)	grad_norm 0.3698 (0.3616)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:17:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:11:25 lr 0.000002	 wd 0.0000	time 0.1871 (0.3111)	loss 0.9980 (0.8804)	grad_norm 0.3616 (0.3615)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:17:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:10:10 lr 0.000002	 wd 0.0000	time 0.2644 (0.2905)	loss 0.7803 (0.8755)	grad_norm 0.3605 (0.3616)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:18:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:09:14 lr 0.000002	 wd 0.0000	time 0.2124 (0.2772)	loss 0.8730 (0.8779)	grad_norm 0.3554 (0.3619)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:18:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:23 lr 0.000002	 wd 0.0000	time 0.1911 (0.2648)	loss 0.9194 (0.8789)	grad_norm 0.3624 (0.3615)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:18:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:41 lr 0.000002	 wd 0.0000	time 0.1884 (0.2562)	loss 0.8613 (0.8781)	grad_norm 0.3554 (0.3614)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:19:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:06 lr 0.000002	 wd 0.0000	time 0.2134 (0.2504)	loss 0.8467 (0.8789)	grad_norm 0.3502 (0.3614)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:19:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:39 lr 0.000002	 wd 0.0000	time 0.1805 (0.2492)	loss 0.8208 (0.8788)	grad_norm 0.3571 (0.3614)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:19:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:09 lr 0.000002	 wd 0.0000	time 0.1860 (0.2458)	loss 0.8550 (0.8786)	grad_norm 0.3457 (0.3614)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:20:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:39 lr 0.000002	 wd 0.0000	time 0.2197 (0.2424)	loss 0.8091 (0.8768)	grad_norm 0.3644 (0.3613)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:20:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:11 lr 0.000002	 wd 0.0000	time 0.2063 (0.2392)	loss 0.8550 (0.8769)	grad_norm 0.3723 (0.3615)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:21:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:04:46 lr 0.000002	 wd 0.0000	time 0.2134 (0.2380)	loss 0.9580 (0.8773)	grad_norm 0.3778 (0.3614)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:21:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:22 lr 0.000002	 wd 0.0000	time 0.1735 (0.2384)	loss 0.7974 (0.8765)	grad_norm 0.3534 (0.3613)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:21:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:03:56 lr 0.000002	 wd 0.0000	time 0.1895 (0.2363)	loss 0.7856 (0.8767)	grad_norm 0.3680 (0.3615)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:22:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:31 lr 0.000002	 wd 0.0000	time 0.2033 (0.2344)	loss 1.0156 (0.8770)	grad_norm 0.3700 (0.3613)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:22:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:06 lr 0.000001	 wd 0.0000	time 0.1879 (0.2330)	loss 0.9312 (0.8770)	grad_norm 0.3779 (0.3612)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:22:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:43 lr 0.000001	 wd 0.0000	time 0.1706 (0.2335)	loss 0.7612 (0.8767)	grad_norm 0.3722 (0.3614)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:23:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:19 lr 0.000001	 wd 0.0000	time 0.2286 (0.2325)	loss 0.8647 (0.8776)	grad_norm 0.3542 (0.3617)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:23:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:01:56 lr 0.000001	 wd 0.0000	time 0.1845 (0.2314)	loss 0.7935 (0.8769)	grad_norm 0.3506 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7951MB
[2024-07-31 20:23:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:32 lr 0.000001	 wd 0.0000	time 0.1986 (0.2301)	loss 0.8423 (0.8766)	grad_norm 0.3796 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7951MB
[2024-07-31 20:24:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:09 lr 0.000001	 wd 0.0000	time 0.2103 (0.2298)	loss 0.8813 (0.8762)	grad_norm 0.3765 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7951MB
[2024-07-31 20:24:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:46 lr 0.000001	 wd 0.0000	time 0.1781 (0.2301)	loss 0.8008 (0.8759)	grad_norm 0.3562 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7951MB
[2024-07-31 20:25:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:23 lr 0.000001	 wd 0.0000	time 0.1944 (0.2291)	loss 0.9697 (0.8755)	grad_norm 0.3653 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7951MB
[2024-07-31 20:25:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1631 (0.2274)	loss 0.8418 (0.8756)	grad_norm 0.3489 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7951MB
[2024-07-31 20:25:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 28 training takes 0:09:36
[2024-07-31 20:26:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 39.198 (39.198)	Loss 0.3564 (0.3564)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 20:26:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.270 Acc@5 97.614
[2024-07-31 20:26:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-31 20:26:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.30%
[2024-07-31 20:26:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][0/2502]	eta 10:24:24 lr 0.000001	 wd 0.0000	time 14.9738 (14.9738)	loss 0.9414 (0.9414)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:27:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:14:30 lr 0.000001	 wd 0.0000	time 0.1878 (0.3622)	loss 0.8403 (0.8845)	grad_norm 0.3704 (0.3623)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:27:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:11:12 lr 0.000001	 wd 0.0000	time 0.2817 (0.2922)	loss 0.8960 (0.8843)	grad_norm 0.3800 (0.3617)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:27:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:10:47 lr 0.000001	 wd 0.0000	time 0.1910 (0.2940)	loss 0.8477 (0.8843)	grad_norm 0.3597 (0.3608)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:28:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:09:29 lr 0.000001	 wd 0.0000	time 0.1760 (0.2708)	loss 0.8682 (0.8838)	grad_norm 0.3577 (0.3611)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:28:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:08:34 lr 0.000001	 wd 0.0000	time 0.1804 (0.2571)	loss 0.8369 (0.8835)	grad_norm 0.3688 (0.3619)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:28:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:07:53 lr 0.000001	 wd 0.0000	time 0.2613 (0.2490)	loss 0.7441 (0.8826)	grad_norm 0.3766 (0.3615)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:29:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:27 lr 0.000001	 wd 0.0000	time 0.1932 (0.2486)	loss 0.8394 (0.8816)	grad_norm 0.3459 (0.3616)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:29:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:06:54 lr 0.000001	 wd 0.0000	time 0.2033 (0.2436)	loss 0.8198 (0.8821)	grad_norm 0.3481 (0.3615)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:30:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:06:23 lr 0.000001	 wd 0.0000	time 0.1715 (0.2394)	loss 0.8711 (0.8822)	grad_norm 0.3708 (0.3617)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:30:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:05:54 lr 0.000001	 wd 0.0000	time 0.1875 (0.2359)	loss 0.8276 (0.8824)	grad_norm 0.3810 (0.3616)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:30:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:30 lr 0.000001	 wd 0.0000	time 0.2255 (0.2360)	loss 1.0039 (0.8820)	grad_norm 0.3491 (0.3616)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:31:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:07 lr 0.000001	 wd 0.0000	time 0.1905 (0.2359)	loss 0.7588 (0.8808)	grad_norm 0.3673 (0.3617)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:31:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:04:40 lr 0.000001	 wd 0.0000	time 0.1856 (0.2337)	loss 0.8828 (0.8808)	grad_norm 0.3660 (0.3619)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:31:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:15 lr 0.000001	 wd 0.0000	time 0.1802 (0.2318)	loss 0.9663 (0.8806)	grad_norm 0.3681 (0.3618)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:32:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:03:51 lr 0.000001	 wd 0.0000	time 0.2166 (0.2307)	loss 0.8008 (0.8791)	grad_norm 0.3630 (0.3618)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:32:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:28 lr 0.000001	 wd 0.0000	time 0.3175 (0.2314)	loss 0.9092 (0.8785)	grad_norm 0.3707 (0.3618)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:32:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:04 lr 0.000001	 wd 0.0000	time 0.2227 (0.2302)	loss 0.9146 (0.8775)	grad_norm 0.3698 (0.3617)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:33:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:40 lr 0.000001	 wd 0.0000	time 0.1904 (0.2289)	loss 0.7598 (0.8770)	grad_norm 0.3435 (0.3616)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:33:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:17 lr 0.000001	 wd 0.0000	time 0.2555 (0.2277)	loss 0.7207 (0.8771)	grad_norm 0.3744 (0.3617)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:34:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:01:54 lr 0.000001	 wd 0.0000	time 0.2132 (0.2274)	loss 0.8438 (0.8774)	grad_norm 0.3635 (0.3616)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:34:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:31 lr 0.000001	 wd 0.0000	time 0.1720 (0.2279)	loss 0.8071 (0.8776)	grad_norm 0.3411 (0.3616)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:34:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:08 lr 0.000001	 wd 0.0000	time 0.2068 (0.2270)	loss 0.7632 (0.8770)	grad_norm 0.3610 (0.3615)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:35:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:45 lr 0.000001	 wd 0.0000	time 0.2037 (0.2262)	loss 0.7285 (0.8773)	grad_norm 0.3774 (0.3616)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:35:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:23 lr 0.000001	 wd 0.0000	time 0.2007 (0.2258)	loss 0.7773 (0.8772)	grad_norm 0.3743 (0.3617)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:35:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1600 (0.2244)	loss 0.9517 (0.8770)	grad_norm 0.3668 (0.3617)	loss_scale 32768.0000 (32768.0000)	mem 7951MB
[2024-07-31 20:36:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 249): INFO EPOCH 29 training takes 0:09:36
[2024-07-31 20:36:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_29.pth saving......
[2024-07-31 20:36:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_29.pth saved !!!
[2024-07-31 20:36:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 289): INFO Test: [0/98]	Time 22.732 (22.732)	Loss 0.3564 (0.3564)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 7951MB
[2024-07-31 20:36:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 296): INFO  * Acc@1 85.264 Acc@5 97.614
[2024-07-31 20:36:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-31 20:36:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 182): INFO Max accuracy: 85.30%
[2024-07-31 20:36:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_sequence_stage_process2] (main.py 189): INFO Training time 5:10:28
