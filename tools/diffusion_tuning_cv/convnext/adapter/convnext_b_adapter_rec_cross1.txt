[2024-08-01 14:38:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 366): INFO Full config saved to pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/config.json
[2024-08-01 14:38:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_convnext_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 27
    - 3
    DIMS:
    - 128
    - 256
    - 512
    - 1024
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: part1
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_conv_b_step_corss1
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 0.0001
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 0.8
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.0e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 1.0e-08

[2024-08-01 14:38:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/diffusion_finetune/convnext/adapter_convnext/diffusion_ft_adapter_convnext_base_224_22kto1k_step_crosslayer_process1.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/diffusion-ft", "tag": "diffusion_ft_adapter_conv_b_step_corss1", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-08-01 14:38:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 108): INFO Creating model:adapter_convnext_diffusion_finetune/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1
[2024-08-01 14:38:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 110): INFO Adapter_ConvNeXt_Diffusion_Finetune(
  (uma): UMA(filter_strategy1=18, filter_strategy2=6,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): Identity()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (12): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (13): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (14): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (15): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (16): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (17): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (18): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (19): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (20): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (21): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (22): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (23): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (24): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (25): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (26): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (memory_downsampling): ModuleList()
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-08-01 14:38:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 113): INFO number of params: 3306312
[2024-08-01 14:38:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 150): INFO no checkpoint found in pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1, ignoring auto resume
[2024-08-01 14:38:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth for fine-tuning......
[2024-08-01 14:38:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 127): WARNING <All keys matched successfully>
[2024-08-01 14:38:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process0/diffusion_ft_adapter_conv_b_step_corss0/ckpt_epoch_best.pth'
[2024-08-01 14:39:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 75.141 (75.141)	Loss 0.3564 (0.3564)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 3068MB
[2024-08-01 14:40:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.174 Acc@5 97.602
[2024-08-01 14:40:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 162): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 14:40:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 168): INFO Start training
[2024-08-01 14:40:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][0/2502]	eta 14:04:57 lr 0.000100	 wd 0.0000	time 20.2628 (20.2628)	loss 0.8623 (0.8623)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 7186MB
[2024-08-01 14:40:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:15:57 lr 0.000100	 wd 0.0000	time 0.2031 (0.3988)	loss 0.8237 (0.8736)	grad_norm 0.3172 (nan)	loss_scale 32768.0000 (33092.4356)	mem 7186MB
[2024-08-01 14:41:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:15:24 lr 0.000100	 wd 0.0000	time 0.2483 (0.4017)	loss 0.8428 (0.8798)	grad_norm 0.2967 (nan)	loss_scale 32768.0000 (32931.0249)	mem 7186MB
[2024-08-01 14:41:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:16 lr 0.000100	 wd 0.0000	time 0.1832 (0.3344)	loss 0.8994 (0.8833)	grad_norm 0.3126 (nan)	loss_scale 32768.0000 (32876.8638)	mem 7186MB
[2024-08-01 14:42:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:27 lr 0.000100	 wd 0.0000	time 0.1910 (0.2985)	loss 1.2373 (0.8827)	grad_norm 0.2954 (nan)	loss_scale 32768.0000 (32849.7157)	mem 7186MB
[2024-08-01 14:42:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:09:16 lr 0.000100	 wd 0.0000	time 0.1734 (0.2778)	loss 0.8130 (0.8827)	grad_norm 0.2825 (nan)	loss_scale 32768.0000 (32833.4052)	mem 7186MB
[2024-08-01 14:43:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:25 lr 0.000100	 wd 0.0000	time 0.1951 (0.2975)	loss 0.9478 (0.8829)	grad_norm 0.2926 (nan)	loss_scale 32768.0000 (32822.5225)	mem 7186MB
[2024-08-01 14:43:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:29 lr 0.000100	 wd 0.0000	time 0.1852 (0.2827)	loss 0.8447 (0.8798)	grad_norm 0.2706 (nan)	loss_scale 32768.0000 (32814.7447)	mem 7186MB
[2024-08-01 14:43:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:42 lr 0.000100	 wd 0.0000	time 0.1828 (0.2717)	loss 0.9146 (0.8813)	grad_norm 0.2680 (nan)	loss_scale 32768.0000 (32808.9089)	mem 7186MB
[2024-08-01 14:44:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:02 lr 0.000100	 wd 0.0000	time 0.2016 (0.2636)	loss 1.0674 (0.8799)	grad_norm 0.2807 (nan)	loss_scale 32768.0000 (32804.3685)	mem 7186MB
[2024-08-01 14:44:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:06:56 lr 0.000100	 wd 0.0000	time 0.1777 (0.2775)	loss 0.8936 (0.8799)	grad_norm 0.2868 (nan)	loss_scale 32768.0000 (32800.7353)	mem 7186MB
[2024-08-01 14:45:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:17 lr 0.000100	 wd 0.0000	time 0.1670 (0.2696)	loss 0.8066 (0.8796)	grad_norm 0.2931 (nan)	loss_scale 32768.0000 (32797.7620)	mem 7186MB
[2024-08-01 14:45:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:42 lr 0.000100	 wd 0.0000	time 0.1925 (0.2629)	loss 0.7568 (0.8798)	grad_norm 0.2851 (nan)	loss_scale 32768.0000 (32795.2839)	mem 7186MB
[2024-08-01 14:45:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:09 lr 0.000100	 wd 0.0000	time 0.2280 (0.2577)	loss 0.8511 (0.8811)	grad_norm 0.2931 (nan)	loss_scale 32768.0000 (32793.1868)	mem 7186MB
[2024-08-01 14:46:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:45 lr 0.000100	 wd 0.0000	time 0.1870 (0.2591)	loss 0.8809 (0.8814)	grad_norm 0.2937 (nan)	loss_scale 32768.0000 (32791.3890)	mem 7186MB
[2024-08-01 14:46:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:14 lr 0.000100	 wd 0.0000	time 0.1841 (0.2544)	loss 0.9419 (0.8819)	grad_norm 0.2915 (nan)	loss_scale 32768.0000 (32789.8308)	mem 7186MB
[2024-08-01 14:46:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:45 lr 0.000100	 wd 0.0000	time 0.1685 (0.2505)	loss 1.0488 (0.8826)	grad_norm 0.2936 (nan)	loss_scale 32768.0000 (32788.4672)	mem 7186MB
[2024-08-01 14:47:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:17 lr 0.000100	 wd 0.0000	time 0.1877 (0.2468)	loss 0.8628 (0.8827)	grad_norm 0.2818 (nan)	loss_scale 32768.0000 (32787.2640)	mem 7186MB
[2024-08-01 14:47:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:02:51 lr 0.000100	 wd 0.0000	time 0.1900 (0.2448)	loss 0.8628 (0.8826)	grad_norm 0.3065 (nan)	loss_scale 32768.0000 (32786.1943)	mem 7186MB
[2024-08-01 14:47:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:27 lr 0.000100	 wd 0.0000	time 0.2746 (0.2443)	loss 0.9722 (0.8827)	grad_norm 0.2756 (nan)	loss_scale 32768.0000 (32785.2372)	mem 7186MB
[2024-08-01 14:48:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:01 lr 0.000100	 wd 0.0000	time 0.1833 (0.2419)	loss 0.9199 (0.8829)	grad_norm 0.2916 (nan)	loss_scale 32768.0000 (32784.3758)	mem 7186MB
[2024-08-01 14:48:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:36 lr 0.000100	 wd 0.0000	time 0.1731 (0.2396)	loss 0.8486 (0.8832)	grad_norm 0.2778 (nan)	loss_scale 32768.0000 (32783.5964)	mem 7186MB
[2024-08-01 14:48:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:11 lr 0.000100	 wd 0.0000	time 0.1983 (0.2375)	loss 1.0059 (0.8829)	grad_norm 0.2849 (nan)	loss_scale 32768.0000 (32782.8878)	mem 7186MB
[2024-08-01 14:49:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:47 lr 0.000100	 wd 0.0000	time 0.1552 (0.2375)	loss 0.9854 (0.8827)	grad_norm 0.2937 (nan)	loss_scale 32768.0000 (32782.2408)	mem 7186MB
[2024-08-01 14:49:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:24 lr 0.000100	 wd 0.0000	time 0.1789 (0.2357)	loss 1.0312 (0.8829)	grad_norm 0.2832 (nan)	loss_scale 32768.0000 (32781.6476)	mem 7186MB
[2024-08-01 14:49:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000100	 wd 0.0000	time 0.1490 (0.2331)	loss 0.8540 (0.8827)	grad_norm 0.2743 (nan)	loss_scale 32768.0000 (32781.1020)	mem 7186MB
[2024-08-01 14:49:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 0 training takes 0:09:47
[2024-08-01 14:49:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_0.pth saving......
[2024-08-01 14:49:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_0.pth saved !!!
[2024-08-01 14:51:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 66.549 (66.549)	Loss 0.3643 (0.3643)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 14:51:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.114 Acc@5 97.628
[2024-08-01 14:51:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-08-01 14:51:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.11%
[2024-08-01 14:51:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saving......
[2024-08-01 14:51:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-01 14:51:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][0/2502]	eta 11:42:44 lr 0.000100	 wd 0.0000	time 16.8524 (16.8524)	loss 0.7661 (0.7661)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 14:51:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:14:08 lr 0.000100	 wd 0.0000	time 0.1592 (0.3533)	loss 0.8325 (0.8693)	grad_norm 0.2824 (0.2801)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 14:52:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:12:22 lr 0.000100	 wd 0.0000	time 0.5135 (0.3224)	loss 0.7910 (0.8756)	grad_norm 0.2752 (0.2800)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 14:52:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:19 lr 0.000100	 wd 0.0000	time 0.1834 (0.3087)	loss 0.9102 (0.8765)	grad_norm 0.2781 (0.2803)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 14:53:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:09:44 lr 0.000100	 wd 0.0000	time 0.1980 (0.2782)	loss 0.8823 (0.8777)	grad_norm 0.2892 (0.2811)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 14:53:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:08:38 lr 0.000100	 wd 0.0000	time 0.1766 (0.2591)	loss 0.7969 (0.8760)	grad_norm 0.2799 (0.2814)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 14:53:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:07:53 lr 0.000100	 wd 0.0000	time 0.2355 (0.2489)	loss 0.9009 (0.8775)	grad_norm 0.2910 (0.2813)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 14:54:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:07:51 lr 0.000100	 wd 0.0000	time 0.2000 (0.2618)	loss 0.8174 (0.8767)	grad_norm 0.2864 (0.2813)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 14:54:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:10 lr 0.000100	 wd 0.0000	time 0.1675 (0.2527)	loss 1.0283 (0.8779)	grad_norm 0.2810 (0.2810)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 14:54:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:06:33 lr 0.000099	 wd 0.0000	time 0.1908 (0.2455)	loss 0.8652 (0.8777)	grad_norm 0.2784 (0.2808)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 14:55:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:00 lr 0.000099	 wd 0.0000	time 0.2395 (0.2402)	loss 0.8892 (0.8779)	grad_norm 0.2800 (0.2810)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 14:55:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:05:48 lr 0.000099	 wd 0.0000	time 0.1705 (0.2484)	loss 0.9443 (0.8791)	grad_norm 0.2906 (0.2811)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 14:56:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:16 lr 0.000099	 wd 0.0000	time 0.1639 (0.2433)	loss 0.8345 (0.8791)	grad_norm 0.2870 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 14:56:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:04:47 lr 0.000099	 wd 0.0000	time 0.1820 (0.2389)	loss 0.8691 (0.8799)	grad_norm 0.2814 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 14:56:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:19 lr 0.000099	 wd 0.0000	time 0.1924 (0.2352)	loss 0.8716 (0.8801)	grad_norm 0.2815 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 14:57:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:03:56 lr 0.000099	 wd 0.0000	time 0.3111 (0.2358)	loss 0.8975 (0.8810)	grad_norm 0.2807 (0.2812)	loss_scale 65536.0000 (32811.6616)	mem 7186MB
[2024-08-01 14:57:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:32 lr 0.000099	 wd 0.0000	time 0.2096 (0.2352)	loss 0.8257 (0.8807)	grad_norm 0.2650 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7186MB
[2024-08-01 14:57:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:06 lr 0.000099	 wd 0.0000	time 0.1812 (0.2326)	loss 0.7744 (0.8809)	grad_norm 0.2794 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7186MB
[2024-08-01 14:58:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:41 lr 0.000099	 wd 0.0000	time 0.2033 (0.2303)	loss 0.9487 (0.8810)	grad_norm 0.2692 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7186MB
[2024-08-01 14:58:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:17 lr 0.000099	 wd 0.0000	time 0.1765 (0.2286)	loss 0.9082 (0.8814)	grad_norm 0.2658 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7186MB
[2024-08-01 14:58:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:01:54 lr 0.000099	 wd 0.0000	time 0.1837 (0.2288)	loss 0.7798 (0.8814)	grad_norm 0.2861 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7186MB
[2024-08-01 14:59:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:31 lr 0.000099	 wd 0.0000	time 0.1662 (0.2282)	loss 0.8306 (0.8813)	grad_norm 0.2929 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7186MB
[2024-08-01 14:59:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:08 lr 0.000099	 wd 0.0000	time 0.2150 (0.2266)	loss 0.7632 (0.8807)	grad_norm 0.2590 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7186MB
[2024-08-01 14:59:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:45 lr 0.000099	 wd 0.0000	time 0.1675 (0.2250)	loss 0.9224 (0.8815)	grad_norm 0.2776 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7186MB
[2024-08-01 15:00:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:22 lr 0.000099	 wd 0.0000	time 0.1740 (0.2241)	loss 0.9043 (0.8816)	grad_norm 0.2916 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7186MB
[2024-08-01 15:00:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000099	 wd 0.0000	time 0.1475 (0.2222)	loss 0.9141 (0.8819)	grad_norm 0.2932 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7186MB
[2024-08-01 15:00:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 1 training takes 0:09:25
[2024-08-01 15:01:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 29.618 (29.618)	Loss 0.3621 (0.3621)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 15:01:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.118 Acc@5 97.628
[2024-08-01 15:01:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-08-01 15:01:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.12%
[2024-08-01 15:01:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saving......
[2024-08-01 15:01:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-01 15:01:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][0/2502]	eta 11:22:15 lr 0.000099	 wd 0.0000	time 16.3610 (16.3610)	loss 0.7817 (0.7817)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:02:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:19:05 lr 0.000099	 wd 0.0000	time 0.2374 (0.4768)	loss 0.9790 (0.8806)	grad_norm 0.2779 (0.2774)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:02:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:12:46 lr 0.000099	 wd 0.0000	time 0.1564 (0.3328)	loss 0.9243 (0.8783)	grad_norm 0.2854 (0.2777)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:02:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:10:24 lr 0.000099	 wd 0.0000	time 0.1745 (0.2837)	loss 0.8037 (0.8746)	grad_norm 0.2859 (0.2778)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:03:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:09:04 lr 0.000099	 wd 0.0000	time 0.1683 (0.2591)	loss 0.9497 (0.8761)	grad_norm 0.2658 (0.2783)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:03:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:08:31 lr 0.000099	 wd 0.0000	time 0.4074 (0.2557)	loss 0.9180 (0.8821)	grad_norm 0.2899 (0.2782)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:04:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:35 lr 0.000099	 wd 0.0000	time 0.2001 (0.2710)	loss 0.7954 (0.8819)	grad_norm 0.2755 (0.2779)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:04:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:07:47 lr 0.000099	 wd 0.0000	time 0.1791 (0.2594)	loss 0.8711 (0.8814)	grad_norm 0.2773 (0.2780)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:04:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:05 lr 0.000099	 wd 0.0000	time 0.1776 (0.2502)	loss 0.7866 (0.8797)	grad_norm 0.2786 (0.2778)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:05:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:36 lr 0.000098	 wd 0.0000	time 0.3538 (0.2475)	loss 0.9233 (0.8798)	grad_norm 0.2972 (0.2779)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:05:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:22 lr 0.000098	 wd 0.0000	time 0.1589 (0.2545)	loss 0.7969 (0.8790)	grad_norm 0.2733 (0.2778)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:05:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:48 lr 0.000098	 wd 0.0000	time 0.1908 (0.2485)	loss 0.9155 (0.8790)	grad_norm 0.2855 (0.2780)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:06:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:16 lr 0.000098	 wd 0.0000	time 0.1823 (0.2432)	loss 1.0273 (0.8793)	grad_norm 0.2859 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:06:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:04:48 lr 0.000098	 wd 0.0000	time 0.2288 (0.2399)	loss 0.8965 (0.8802)	grad_norm 0.2900 (0.2782)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:07:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:29 lr 0.000098	 wd 0.0000	time 0.1829 (0.2444)	loss 0.9282 (0.8803)	grad_norm 0.2685 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:07:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:01 lr 0.000098	 wd 0.0000	time 0.1562 (0.2405)	loss 1.0615 (0.8808)	grad_norm 0.2761 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:07:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:34 lr 0.000098	 wd 0.0000	time 0.1654 (0.2374)	loss 0.9180 (0.8804)	grad_norm 0.2796 (0.2782)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:08:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:08 lr 0.000098	 wd 0.0000	time 0.2023 (0.2346)	loss 0.8794 (0.8811)	grad_norm 0.2780 (0.2783)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:08:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:43 lr 0.000098	 wd 0.0000	time 0.1999 (0.2331)	loss 0.8745 (0.8809)	grad_norm 0.2616 (0.2784)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:08:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:20 lr 0.000098	 wd 0.0000	time 0.1828 (0.2330)	loss 0.7773 (0.8813)	grad_norm 0.2771 (0.2785)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:09:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:01:55 lr 0.000098	 wd 0.0000	time 0.1673 (0.2310)	loss 0.8882 (0.8814)	grad_norm 0.2643 (0.2784)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:09:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:32 lr 0.000098	 wd 0.0000	time 0.1790 (0.2293)	loss 0.9531 (0.8820)	grad_norm 0.2837 (0.2784)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:09:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:08 lr 0.000098	 wd 0.0000	time 0.2018 (0.2278)	loss 0.8604 (0.8818)	grad_norm 0.2795 (0.2783)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:10:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:46 lr 0.000098	 wd 0.0000	time 0.2227 (0.2283)	loss 0.8286 (0.8817)	grad_norm 0.2878 (0.2783)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:10:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:23 lr 0.000098	 wd 0.0000	time 0.1984 (0.2268)	loss 0.8662 (0.8820)	grad_norm 0.2770 (0.2783)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:10:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000098	 wd 0.0000	time 0.1488 (0.2245)	loss 0.8823 (0.8816)	grad_norm 0.2813 (0.2783)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:10:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 2 training takes 0:09:26
[2024-08-01 15:11:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 23.326 (23.326)	Loss 0.3594 (0.3594)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 15:11:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.148 Acc@5 97.628
[2024-08-01 15:11:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-08-01 15:11:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.15%
[2024-08-01 15:11:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saving......
[2024-08-01 15:11:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-01 15:12:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][0/2502]	eta 1 day, 1:57:40 lr 0.000098	 wd 0.0000	time 37.3544 (37.3544)	loss 0.7354 (0.7354)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:12:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:22:06 lr 0.000098	 wd 0.0000	time 0.1927 (0.5521)	loss 0.9980 (0.8789)	grad_norm 0.2907 (0.2803)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:12:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:14:09 lr 0.000097	 wd 0.0000	time 0.1789 (0.3690)	loss 1.0156 (0.8748)	grad_norm 0.2908 (0.2796)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:13:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:11:30 lr 0.000097	 wd 0.0000	time 0.2589 (0.3137)	loss 1.0127 (0.8760)	grad_norm 0.2763 (0.2792)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:13:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:11:23 lr 0.000097	 wd 0.0000	time 0.1640 (0.3251)	loss 0.9658 (0.8755)	grad_norm 0.2668 (0.2785)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:13:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:09:56 lr 0.000097	 wd 0.0000	time 0.1895 (0.2979)	loss 0.8965 (0.8770)	grad_norm nan (nan)	loss_scale 32768.0000 (32898.8104)	mem 7186MB
[2024-08-01 15:14:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:08:51 lr 0.000097	 wd 0.0000	time 0.1449 (0.2794)	loss 0.8237 (0.8774)	grad_norm 0.2966 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7186MB
[2024-08-01 15:14:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:07:59 lr 0.000097	 wd 0.0000	time 0.2063 (0.2663)	loss 0.9097 (0.8785)	grad_norm 0.2801 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7186MB
[2024-08-01 15:15:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:51 lr 0.000097	 wd 0.0000	time 0.2328 (0.2769)	loss 0.8530 (0.8776)	grad_norm 0.2863 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7186MB
[2024-08-01 15:15:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:07:09 lr 0.000097	 wd 0.0000	time 0.1868 (0.2681)	loss 0.9014 (0.8782)	grad_norm 0.2814 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7186MB
[2024-08-01 15:15:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:30 lr 0.000097	 wd 0.0000	time 0.1631 (0.2602)	loss 1.0273 (0.8797)	grad_norm 0.2927 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7186MB
[2024-08-01 15:16:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:05:55 lr 0.000097	 wd 0.0000	time 0.2031 (0.2536)	loss 0.7812 (0.8792)	grad_norm 0.2893 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7186MB
[2024-08-01 15:16:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:39 lr 0.000097	 wd 0.0000	time 0.2120 (0.2608)	loss 0.9331 (0.8786)	grad_norm 0.2730 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7186MB
[2024-08-01 15:17:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:05:07 lr 0.000097	 wd 0.0000	time 0.2118 (0.2558)	loss 0.9702 (0.8798)	grad_norm 0.2681 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7186MB
[2024-08-01 15:17:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:36 lr 0.000097	 wd 0.0000	time 0.1865 (0.2510)	loss 0.8428 (0.8795)	grad_norm 0.2644 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7186MB
[2024-08-01 15:17:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:07 lr 0.000097	 wd 0.0000	time 0.1863 (0.2466)	loss 0.8091 (0.8806)	grad_norm 0.2680 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7186MB
[2024-08-01 15:17:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:40 lr 0.000096	 wd 0.0000	time 0.1799 (0.2442)	loss 0.8228 (0.8798)	grad_norm 0.2803 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7186MB
[2024-08-01 15:18:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:15 lr 0.000096	 wd 0.0000	time 0.2647 (0.2434)	loss 0.9307 (0.8797)	grad_norm 0.2771 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7186MB
[2024-08-01 15:18:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:48 lr 0.000096	 wd 0.0000	time 0.1730 (0.2407)	loss 0.8779 (0.8797)	grad_norm 0.2611 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7186MB
[2024-08-01 15:19:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:23 lr 0.000096	 wd 0.0000	time 0.1700 (0.2381)	loss 0.8916 (0.8792)	grad_norm 0.2686 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7186MB
[2024-08-01 15:19:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:01:58 lr 0.000096	 wd 0.0000	time 0.1911 (0.2358)	loss 0.8350 (0.8796)	grad_norm 0.2710 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7186MB
[2024-08-01 15:19:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:34 lr 0.000096	 wd 0.0000	time 0.2313 (0.2348)	loss 0.7021 (0.8792)	grad_norm 0.2781 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7186MB
[2024-08-01 15:20:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:10 lr 0.000096	 wd 0.0000	time 0.3361 (0.2346)	loss 0.8110 (0.8789)	grad_norm 0.2809 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7186MB
[2024-08-01 15:20:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:47 lr 0.000096	 wd 0.0000	time 0.1842 (0.2327)	loss 0.9585 (0.8792)	grad_norm 0.2800 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7186MB
[2024-08-01 15:20:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:23 lr 0.000096	 wd 0.0000	time 0.2048 (0.2310)	loss 0.8140 (0.8792)	grad_norm 0.2714 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7186MB
[2024-08-01 15:21:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000096	 wd 0.0000	time 0.1515 (0.2285)	loss 0.8037 (0.8798)	grad_norm 0.2879 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7186MB
[2024-08-01 15:21:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 3 training takes 0:09:35
[2024-08-01 15:21:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 38.437 (38.437)	Loss 0.3604 (0.3604)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 15:21:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.158 Acc@5 97.630
[2024-08-01 15:21:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 15:21:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.16%
[2024-08-01 15:21:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saving......
[2024-08-01 15:21:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-01 15:22:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][0/2502]	eta 10:53:02 lr 0.000096	 wd 0.0000	time 15.6605 (15.6605)	loss 0.8843 (0.8843)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:22:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:13:42 lr 0.000096	 wd 0.0000	time 0.1984 (0.3423)	loss 0.7949 (0.8846)	grad_norm 0.2771 (0.2779)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:22:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:11:14 lr 0.000096	 wd 0.0000	time 0.2545 (0.2930)	loss 0.9053 (0.8817)	grad_norm 0.2598 (0.2775)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:23:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:10:17 lr 0.000095	 wd 0.0000	time 0.1846 (0.2804)	loss 0.8799 (0.8814)	grad_norm 0.2865 (0.2778)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:23:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:08:58 lr 0.000095	 wd 0.0000	time 0.2041 (0.2564)	loss 0.8584 (0.8766)	grad_norm 0.2646 (0.2779)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:23:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:08:04 lr 0.000095	 wd 0.0000	time 0.1991 (0.2420)	loss 0.9395 (0.8783)	grad_norm 0.2734 (0.2778)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:24:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:07:26 lr 0.000095	 wd 0.0000	time 0.2427 (0.2345)	loss 0.8438 (0.8803)	grad_norm 0.2860 (0.2778)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:24:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:07:27 lr 0.000095	 wd 0.0000	time 0.1935 (0.2483)	loss 0.9829 (0.8769)	grad_norm 0.2708 (0.2776)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:25:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:06:49 lr 0.000095	 wd 0.0000	time 0.1689 (0.2408)	loss 0.8447 (0.8771)	grad_norm 0.2842 (0.2774)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:25:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:06:16 lr 0.000095	 wd 0.0000	time 0.1690 (0.2352)	loss 0.8511 (0.8782)	grad_norm 0.2814 (0.2773)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:25:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:05:45 lr 0.000095	 wd 0.0000	time 0.1929 (0.2301)	loss 0.9058 (0.8782)	grad_norm 0.2790 (0.2774)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:26:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:05:36 lr 0.000095	 wd 0.0000	time 0.1506 (0.2404)	loss 0.9316 (0.8797)	grad_norm 0.2851 (0.2775)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:26:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:08 lr 0.000095	 wd 0.0000	time 0.1741 (0.2366)	loss 0.7256 (0.8795)	grad_norm 0.2720 (0.2774)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:27:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:04:40 lr 0.000095	 wd 0.0000	time 0.1919 (0.2329)	loss 0.8374 (0.8790)	grad_norm 0.2738 (0.2774)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:27:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:12 lr 0.000094	 wd 0.0000	time 0.1640 (0.2295)	loss 0.8804 (0.8786)	grad_norm 0.2834 (0.2775)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:27:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:03:49 lr 0.000094	 wd 0.0000	time 0.3736 (0.2286)	loss 0.7476 (0.8787)	grad_norm 0.2764 (0.2776)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:28:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:30 lr 0.000094	 wd 0.0000	time 0.1637 (0.2336)	loss 0.8301 (0.8786)	grad_norm 0.2743 (0.2775)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:28:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:05 lr 0.000094	 wd 0.0000	time 0.1781 (0.2308)	loss 1.0713 (0.8783)	grad_norm 0.2762 (0.2775)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:28:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:40 lr 0.000094	 wd 0.0000	time 0.1850 (0.2286)	loss 0.9146 (0.8787)	grad_norm 0.2720 (0.2775)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:29:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:16 lr 0.000094	 wd 0.0000	time 0.2121 (0.2270)	loss 0.8936 (0.8786)	grad_norm 0.2728 (0.2774)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:29:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:01:54 lr 0.000094	 wd 0.0000	time 0.1667 (0.2272)	loss 0.7534 (0.8782)	grad_norm nan (nan)	loss_scale 32768.0000 (32800.7516)	mem 7186MB
[2024-08-01 15:29:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:30 lr 0.000094	 wd 0.0000	time 0.1539 (0.2263)	loss 0.8218 (0.8790)	grad_norm 0.2884 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7186MB
[2024-08-01 15:30:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:07 lr 0.000094	 wd 0.0000	time 0.2311 (0.2249)	loss 0.9648 (0.8785)	grad_norm 0.2519 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7186MB
[2024-08-01 15:30:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:45 lr 0.000094	 wd 0.0000	time 0.2138 (0.2233)	loss 0.8457 (0.8789)	grad_norm 0.2786 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7186MB
[2024-08-01 15:30:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:22 lr 0.000093	 wd 0.0000	time 0.2361 (0.2226)	loss 0.8311 (0.8791)	grad_norm 0.2597 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7186MB
[2024-08-01 15:31:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000093	 wd 0.0000	time 0.1477 (0.2208)	loss 0.7720 (0.8791)	grad_norm 0.2762 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7186MB
[2024-08-01 15:31:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 4 training takes 0:09:21
[2024-08-01 15:31:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 23.504 (23.504)	Loss 0.3552 (0.3552)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 15:31:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.148 Acc@5 97.600
[2024-08-01 15:31:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-08-01 15:31:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.16%
[2024-08-01 15:32:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][0/2502]	eta 11:47:28 lr 0.000093	 wd 0.0000	time 16.9659 (16.9659)	loss 0.8623 (0.8623)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:32:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:16:48 lr 0.000093	 wd 0.0000	time 0.3902 (0.4201)	loss 0.9155 (0.8695)	grad_norm 0.2848 (0.2774)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:33:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:12:59 lr 0.000093	 wd 0.0000	time 0.1621 (0.3386)	loss 0.8047 (0.8736)	grad_norm 0.2834 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:33:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:32 lr 0.000093	 wd 0.0000	time 0.1817 (0.2874)	loss 0.9863 (0.8718)	grad_norm 0.2745 (0.2782)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:33:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:10 lr 0.000093	 wd 0.0000	time 0.1737 (0.2620)	loss 0.9287 (0.8717)	grad_norm 0.2840 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:33:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:08:17 lr 0.000093	 wd 0.0000	time 0.1971 (0.2486)	loss 0.8320 (0.8724)	grad_norm 0.2920 (0.2783)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:34:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:25 lr 0.000093	 wd 0.0000	time 0.2611 (0.2660)	loss 0.8687 (0.8753)	grad_norm 0.2800 (0.2784)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:34:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:39 lr 0.000093	 wd 0.0000	time 0.1849 (0.2549)	loss 0.7725 (0.8746)	grad_norm 0.2934 (0.2783)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:35:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:06:59 lr 0.000093	 wd 0.0000	time 0.1792 (0.2465)	loss 0.8408 (0.8745)	grad_norm 0.2786 (0.2784)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:35:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:24 lr 0.000092	 wd 0.0000	time 0.2139 (0.2400)	loss 0.9146 (0.8749)	grad_norm 0.2776 (0.2785)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:36:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:13 lr 0.000092	 wd 0.0000	time 0.1934 (0.2490)	loss 0.9067 (0.8766)	grad_norm 0.2765 (0.2785)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:36:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:41 lr 0.000092	 wd 0.0000	time 0.1666 (0.2438)	loss 0.8110 (0.8777)	grad_norm 0.2780 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:36:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:11 lr 0.000092	 wd 0.0000	time 0.1760 (0.2392)	loss 0.8940 (0.8785)	grad_norm 0.2737 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:37:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:42 lr 0.000092	 wd 0.0000	time 0.1654 (0.2351)	loss 0.9585 (0.8779)	grad_norm 0.2841 (0.2784)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:37:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:17 lr 0.000092	 wd 0.0000	time 0.3006 (0.2337)	loss 0.8530 (0.8772)	grad_norm 0.2850 (0.2784)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:37:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:03:57 lr 0.000092	 wd 0.0000	time 0.1906 (0.2374)	loss 0.8521 (0.8778)	grad_norm 0.2732 (0.2784)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:38:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:31 lr 0.000092	 wd 0.0000	time 0.1882 (0.2342)	loss 0.7832 (0.8782)	grad_norm 0.2902 (0.2784)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:38:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:05 lr 0.000092	 wd 0.0000	time 0.1766 (0.2316)	loss 0.8599 (0.8787)	grad_norm 0.2752 (0.2785)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:38:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:41 lr 0.000091	 wd 0.0000	time 0.2192 (0.2296)	loss 0.8691 (0.8781)	grad_norm 0.2877 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:39:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:18 lr 0.000091	 wd 0.0000	time 0.1751 (0.2295)	loss 0.8462 (0.8779)	grad_norm 0.2746 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:39:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:01:54 lr 0.000091	 wd 0.0000	time 0.1810 (0.2288)	loss 0.9678 (0.8784)	grad_norm 0.2858 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:39:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:31 lr 0.000091	 wd 0.0000	time 0.1989 (0.2271)	loss 0.9609 (0.8779)	grad_norm 0.2850 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:40:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:08 lr 0.000091	 wd 0.0000	time 0.1749 (0.2255)	loss 0.9771 (0.8779)	grad_norm 0.2767 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:40:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:45 lr 0.000091	 wd 0.0000	time 0.3307 (0.2247)	loss 0.7593 (0.8777)	grad_norm 0.2945 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:40:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:22 lr 0.000091	 wd 0.0000	time 0.1813 (0.2249)	loss 0.7817 (0.8774)	grad_norm 0.2881 (0.2788)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:41:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000091	 wd 0.0000	time 0.1489 (0.2230)	loss 0.7695 (0.8768)	grad_norm 0.2763 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:41:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 5 training takes 0:09:22
[2024-08-01 15:41:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 20.434 (20.434)	Loss 0.3523 (0.3523)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 15:41:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.196 Acc@5 97.624
[2024-08-01 15:41:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 15:41:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.20%
[2024-08-01 15:41:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saving......
[2024-08-01 15:41:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-01 15:42:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][0/2502]	eta 16:45:20 lr 0.000091	 wd 0.0000	time 24.1087 (24.1087)	loss 0.9292 (0.9292)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:42:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:18:13 lr 0.000090	 wd 0.0000	time 0.2019 (0.4553)	loss 0.8560 (0.8878)	grad_norm 0.2922 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:42:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:12:20 lr 0.000090	 wd 0.0000	time 0.1552 (0.3217)	loss 0.7910 (0.8807)	grad_norm 0.2813 (0.2789)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:43:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:10:09 lr 0.000090	 wd 0.0000	time 0.1873 (0.2767)	loss 0.8833 (0.8807)	grad_norm 0.2837 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:43:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:08:53 lr 0.000090	 wd 0.0000	time 0.1808 (0.2536)	loss 0.8599 (0.8792)	grad_norm 0.2696 (0.2792)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:43:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:08:26 lr 0.000090	 wd 0.0000	time 0.3688 (0.2528)	loss 0.9204 (0.8790)	grad_norm 0.2676 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:44:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:07:59 lr 0.000090	 wd 0.0000	time 0.2017 (0.2518)	loss 0.8857 (0.8786)	grad_norm 0.2902 (0.2793)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:44:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:07:16 lr 0.000090	 wd 0.0000	time 0.1723 (0.2424)	loss 0.9810 (0.8783)	grad_norm 0.2822 (0.2796)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:44:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:06:40 lr 0.000090	 wd 0.0000	time 0.1810 (0.2353)	loss 0.7207 (0.8785)	grad_norm 0.2765 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:45:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:06:11 lr 0.000089	 wd 0.0000	time 0.2781 (0.2317)	loss 0.8755 (0.8780)	grad_norm 0.2669 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:45:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:09 lr 0.000089	 wd 0.0000	time 0.1891 (0.2461)	loss 0.8291 (0.8789)	grad_norm 0.2771 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7186MB
[2024-08-01 15:46:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:37 lr 0.000089	 wd 0.0000	time 0.1688 (0.2408)	loss 0.8013 (0.8775)	grad_norm 0.2771 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7186MB
[2024-08-01 15:46:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:07 lr 0.000089	 wd 0.0000	time 0.1640 (0.2364)	loss 0.8540 (0.8777)	grad_norm 0.2799 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7186MB
[2024-08-01 15:46:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:04:40 lr 0.000089	 wd 0.0000	time 0.1816 (0.2331)	loss 0.7632 (0.8771)	grad_norm 0.2743 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7186MB
[2024-08-01 15:47:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:22 lr 0.000089	 wd 0.0000	time 0.1755 (0.2378)	loss 0.8931 (0.8766)	grad_norm 0.2746 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7186MB
[2024-08-01 15:47:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:03:54 lr 0.000089	 wd 0.0000	time 0.1869 (0.2344)	loss 0.7798 (0.8765)	grad_norm 0.2768 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7186MB
[2024-08-01 15:48:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:28 lr 0.000089	 wd 0.0000	time 0.2124 (0.2316)	loss 0.7891 (0.8761)	grad_norm 0.2698 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7186MB
[2024-08-01 15:48:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:03 lr 0.000088	 wd 0.0000	time 0.1558 (0.2290)	loss 0.8403 (0.8748)	grad_norm 0.2707 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7186MB
[2024-08-01 15:48:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:39 lr 0.000088	 wd 0.0000	time 0.1829 (0.2278)	loss 0.8179 (0.8747)	grad_norm 0.2780 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7186MB
[2024-08-01 15:49:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:17 lr 0.000088	 wd 0.0000	time 0.2305 (0.2279)	loss 0.8818 (0.8751)	grad_norm 0.2759 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7186MB
[2024-08-01 15:49:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:01:53 lr 0.000088	 wd 0.0000	time 0.1989 (0.2263)	loss 0.9204 (0.8757)	grad_norm 0.2810 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7186MB
[2024-08-01 15:49:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:30 lr 0.000088	 wd 0.0000	time 0.1840 (0.2248)	loss 0.7993 (0.8757)	grad_norm 0.2786 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7186MB
[2024-08-01 15:50:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:07 lr 0.000088	 wd 0.0000	time 0.1908 (0.2233)	loss 0.8936 (0.8751)	grad_norm 0.2816 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7186MB
[2024-08-01 15:50:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:44 lr 0.000088	 wd 0.0000	time 0.1790 (0.2226)	loss 0.8247 (0.8750)	grad_norm 0.2781 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7186MB
[2024-08-01 15:50:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:22 lr 0.000087	 wd 0.0000	time 0.1933 (0.2226)	loss 0.8809 (0.8756)	grad_norm 0.2665 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7186MB
[2024-08-01 15:51:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000087	 wd 0.0000	time 0.1488 (0.2206)	loss 0.7759 (0.8762)	grad_norm 0.2850 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7186MB
[2024-08-01 15:51:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 6 training takes 0:09:15
[2024-08-01 15:51:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 18.549 (18.549)	Loss 0.3538 (0.3538)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 15:51:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.130 Acc@5 97.634
[2024-08-01 15:51:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-08-01 15:51:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.20%
[2024-08-01 15:52:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][0/2502]	eta 23:43:23 lr 0.000087	 wd 0.0000	time 34.1340 (34.1340)	loss 0.8682 (0.8682)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:52:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:21:22 lr 0.000087	 wd 0.0000	time 0.1790 (0.5341)	loss 0.9595 (0.8756)	grad_norm 0.2744 (0.2799)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:52:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:13:49 lr 0.000087	 wd 0.0000	time 0.1738 (0.3603)	loss 0.8677 (0.8733)	grad_norm 0.2695 (0.2809)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:53:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:11:05 lr 0.000087	 wd 0.0000	time 0.2044 (0.3023)	loss 0.8350 (0.8705)	grad_norm 0.2856 (0.2802)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:53:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:09:54 lr 0.000087	 wd 0.0000	time 0.3081 (0.2829)	loss 0.8638 (0.8751)	grad_norm 0.2979 (0.2803)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:54:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:09:32 lr 0.000087	 wd 0.0000	time 0.1721 (0.2859)	loss 0.7725 (0.8729)	grad_norm 0.2552 (0.2802)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:54:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:32 lr 0.000086	 wd 0.0000	time 0.1924 (0.2693)	loss 0.9854 (0.8750)	grad_norm 0.2645 (0.2801)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:54:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:07:43 lr 0.000086	 wd 0.0000	time 0.1643 (0.2575)	loss 0.7925 (0.8746)	grad_norm 0.2577 (0.2802)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:54:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:07:04 lr 0.000086	 wd 0.0000	time 0.2139 (0.2492)	loss 0.8130 (0.8733)	grad_norm 0.2705 (0.2802)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:55:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:07:02 lr 0.000086	 wd 0.0000	time 0.1996 (0.2636)	loss 0.8398 (0.8743)	grad_norm 0.2814 (0.2802)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:55:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:24 lr 0.000086	 wd 0.0000	time 0.1881 (0.2559)	loss 0.7598 (0.8742)	grad_norm 0.2897 (0.2801)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:56:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:50 lr 0.000086	 wd 0.0000	time 0.1751 (0.2498)	loss 0.7783 (0.8737)	grad_norm 0.2844 (0.2802)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:56:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:18 lr 0.000086	 wd 0.0000	time 0.1748 (0.2446)	loss 0.9082 (0.8731)	grad_norm 0.2797 (0.2801)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:57:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:05:04 lr 0.000085	 wd 0.0000	time 0.2859 (0.2532)	loss 0.9180 (0.8727)	grad_norm 0.2687 (0.2802)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:57:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:34 lr 0.000085	 wd 0.0000	time 0.1791 (0.2488)	loss 0.7700 (0.8729)	grad_norm 0.2814 (0.2803)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:57:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:05 lr 0.000085	 wd 0.0000	time 0.1765 (0.2447)	loss 0.8311 (0.8727)	grad_norm 0.2911 (0.2803)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:58:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:37 lr 0.000085	 wd 0.0000	time 0.1975 (0.2411)	loss 0.8813 (0.8725)	grad_norm 0.2760 (0.2803)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:58:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:12 lr 0.000085	 wd 0.0000	time 0.1916 (0.2399)	loss 0.9956 (0.8722)	grad_norm 0.2704 (0.2803)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:58:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:47 lr 0.000085	 wd 0.0000	time 0.1782 (0.2393)	loss 0.8423 (0.8723)	grad_norm 0.2777 (0.2803)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:59:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:22 lr 0.000085	 wd 0.0000	time 0.1823 (0.2369)	loss 0.9204 (0.8722)	grad_norm 0.2776 (0.2804)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:59:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:01:57 lr 0.000084	 wd 0.0000	time 0.1789 (0.2347)	loss 0.8364 (0.8718)	grad_norm 0.2886 (0.2804)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 15:59:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:33 lr 0.000084	 wd 0.0000	time 0.1703 (0.2327)	loss 1.0225 (0.8728)	grad_norm 0.2968 (0.2805)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:00:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:10 lr 0.000084	 wd 0.0000	time 0.1845 (0.2323)	loss 0.6938 (0.8721)	grad_norm 0.2932 (0.2805)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:00:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:46 lr 0.000084	 wd 0.0000	time 0.1736 (0.2313)	loss 0.9590 (0.8721)	grad_norm 0.2769 (0.2805)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:00:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:23 lr 0.000084	 wd 0.0000	time 0.1763 (0.2296)	loss 0.9595 (0.8724)	grad_norm 0.2862 (0.2806)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:01:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000084	 wd 0.0000	time 0.1524 (0.2273)	loss 0.8755 (0.8729)	grad_norm 0.2926 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7186MB
[2024-08-01 16:01:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 7 training takes 0:09:32
[2024-08-01 16:01:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 41.415 (41.415)	Loss 0.3516 (0.3516)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 16:02:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.156 Acc@5 97.634
[2024-08-01 16:02:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 16:02:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.20%
[2024-08-01 16:02:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][0/2502]	eta 11:24:56 lr 0.000084	 wd 0.0000	time 16.4255 (16.4255)	loss 0.7871 (0.7871)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:02:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:13:50 lr 0.000083	 wd 0.0000	time 0.1766 (0.3459)	loss 0.8486 (0.8767)	grad_norm 0.2773 (0.2819)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:02:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:10:23 lr 0.000083	 wd 0.0000	time 0.2286 (0.2710)	loss 0.8599 (0.8756)	grad_norm 0.2808 (0.2817)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:03:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:11:08 lr 0.000083	 wd 0.0000	time 0.2942 (0.3034)	loss 0.8359 (0.8717)	grad_norm 0.2921 (0.2811)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:03:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:09:38 lr 0.000083	 wd 0.0000	time 0.1719 (0.2753)	loss 0.9790 (0.8733)	grad_norm 0.2764 (0.2809)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:04:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:08:36 lr 0.000083	 wd 0.0000	time 0.1928 (0.2578)	loss 0.8203 (0.8744)	grad_norm 0.2836 (0.2811)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:04:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:07:47 lr 0.000083	 wd 0.0000	time 0.2123 (0.2458)	loss 0.8560 (0.8742)	grad_norm 0.2983 (0.2808)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:05:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:51 lr 0.000083	 wd 0.0000	time 0.2410 (0.2617)	loss 0.8779 (0.8735)	grad_norm 0.2916 (0.2808)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:05:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:11 lr 0.000082	 wd 0.0000	time 0.2091 (0.2535)	loss 0.7471 (0.8730)	grad_norm 0.2802 (0.2809)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:05:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:34 lr 0.000082	 wd 0.0000	time 0.1774 (0.2462)	loss 1.0107 (0.8741)	grad_norm 0.2771 (0.2810)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:06:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:00 lr 0.000082	 wd 0.0000	time 0.1798 (0.2400)	loss 1.0293 (0.8748)	grad_norm 0.2762 (0.2810)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:06:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:36 lr 0.000082	 wd 0.0000	time 0.3045 (0.2403)	loss 0.9473 (0.8745)	grad_norm 0.2811 (0.2811)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:06:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:15 lr 0.000082	 wd 0.0000	time 0.1920 (0.2424)	loss 0.8135 (0.8741)	grad_norm 0.2779 (0.2810)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:07:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:46 lr 0.000082	 wd 0.0000	time 0.1678 (0.2381)	loss 0.8184 (0.8743)	grad_norm 0.2810 (0.2812)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:07:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:18 lr 0.000081	 wd 0.0000	time 0.1653 (0.2345)	loss 0.8320 (0.8741)	grad_norm 0.2772 (0.2811)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:07:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:03:52 lr 0.000081	 wd 0.0000	time 0.1848 (0.2321)	loss 0.8550 (0.8738)	grad_norm 0.2921 (0.2813)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:08:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:29 lr 0.000081	 wd 0.0000	time 0.1663 (0.2317)	loss 0.9614 (0.8733)	grad_norm 0.2769 (0.2813)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:08:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:04 lr 0.000081	 wd 0.0000	time 0.1628 (0.2297)	loss 0.8496 (0.8741)	grad_norm 0.2708 (0.2814)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:08:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:39 lr 0.000081	 wd 0.0000	time 0.1761 (0.2275)	loss 0.8662 (0.8745)	grad_norm 0.2928 (0.2814)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:09:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:15 lr 0.000081	 wd 0.0000	time 0.2109 (0.2255)	loss 0.7822 (0.8740)	grad_norm 0.2652 (0.2814)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:09:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:52 lr 0.000080	 wd 0.0000	time 0.2017 (0.2244)	loss 0.8052 (0.8741)	grad_norm 0.2965 (0.2814)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:09:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:30 lr 0.000080	 wd 0.0000	time 0.1518 (0.2248)	loss 0.8882 (0.8744)	grad_norm 0.2816 (0.2815)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:10:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:07 lr 0.000080	 wd 0.0000	time 0.1788 (0.2237)	loss 0.8154 (0.8739)	grad_norm 0.2822 (0.2816)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:10:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:44 lr 0.000080	 wd 0.0000	time 0.1841 (0.2223)	loss 0.9497 (0.8737)	grad_norm 0.2753 (0.2816)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:10:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:22 lr 0.000080	 wd 0.0000	time 0.2176 (0.2209)	loss 0.9668 (0.8736)	grad_norm 0.2879 (0.2817)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:11:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000080	 wd 0.0000	time 0.1506 (0.2192)	loss 0.9106 (0.8737)	grad_norm 0.2860 (0.2817)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:11:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 8 training takes 0:09:12
[2024-08-01 16:11:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 35.166 (35.166)	Loss 0.3538 (0.3538)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 16:12:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.142 Acc@5 97.666
[2024-08-01 16:12:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-08-01 16:12:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.20%
[2024-08-01 16:12:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][0/2502]	eta 11:24:48 lr 0.000080	 wd 0.0000	time 16.4225 (16.4225)	loss 0.8594 (0.8594)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:12:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:14:21 lr 0.000079	 wd 0.0000	time 0.1911 (0.3586)	loss 0.9683 (0.8685)	grad_norm 0.2909 (0.2821)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:13:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:12:33 lr 0.000079	 wd 0.0000	time 0.1731 (0.3274)	loss 0.7388 (0.8663)	grad_norm 0.2761 (0.2825)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:13:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:18 lr 0.000079	 wd 0.0000	time 0.1821 (0.2807)	loss 0.9341 (0.8684)	grad_norm 0.2722 (0.2829)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:13:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:00 lr 0.000079	 wd 0.0000	time 0.1820 (0.2570)	loss 0.8594 (0.8680)	grad_norm 0.2718 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:14:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:08:05 lr 0.000079	 wd 0.0000	time 0.1786 (0.2426)	loss 0.6724 (0.8730)	grad_norm 0.2889 (0.2831)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:14:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:07:54 lr 0.000079	 wd 0.0000	time 0.6929 (0.2494)	loss 0.7100 (0.8707)	grad_norm 0.2870 (0.2826)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:15:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:43 lr 0.000078	 wd 0.0000	time 0.1863 (0.2573)	loss 0.9370 (0.8716)	grad_norm 0.2868 (0.2826)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:15:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:07:03 lr 0.000078	 wd 0.0000	time 0.1505 (0.2491)	loss 0.9082 (0.8725)	grad_norm 0.2652 (0.2826)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:15:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:27 lr 0.000078	 wd 0.0000	time 0.1880 (0.2421)	loss 1.0205 (0.8732)	grad_norm 0.2830 (0.2825)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:16:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:02 lr 0.000078	 wd 0.0000	time 0.4381 (0.2413)	loss 0.9575 (0.8736)	grad_norm 0.2832 (0.2825)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:16:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:43 lr 0.000078	 wd 0.0000	time 0.1847 (0.2448)	loss 0.8018 (0.8736)	grad_norm 0.2924 (0.2824)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:16:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:12 lr 0.000078	 wd 0.0000	time 0.1773 (0.2400)	loss 0.9502 (0.8733)	grad_norm 0.2867 (0.2825)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:17:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:43 lr 0.000077	 wd 0.0000	time 0.1454 (0.2359)	loss 0.9414 (0.8737)	grad_norm 0.2682 (0.2824)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:17:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:17 lr 0.000077	 wd 0.0000	time 0.2167 (0.2333)	loss 0.8809 (0.8741)	grad_norm 0.2712 (0.2824)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:17:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:03:53 lr 0.000077	 wd 0.0000	time 0.1819 (0.2332)	loss 0.9287 (0.8743)	grad_norm 0.2899 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7186MB
[2024-08-01 16:18:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:28 lr 0.000077	 wd 0.0000	time 0.1597 (0.2313)	loss 0.8857 (0.8739)	grad_norm 0.2720 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7186MB
[2024-08-01 16:18:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:03 lr 0.000077	 wd 0.0000	time 0.1821 (0.2289)	loss 0.8198 (0.8746)	grad_norm 0.2673 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7186MB
[2024-08-01 16:18:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:39 lr 0.000077	 wd 0.0000	time 0.1540 (0.2268)	loss 0.7217 (0.8743)	grad_norm 0.2865 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7186MB
[2024-08-01 16:19:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:15 lr 0.000076	 wd 0.0000	time 0.2201 (0.2256)	loss 0.9150 (0.8745)	grad_norm 0.2814 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7186MB
[2024-08-01 16:19:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:01:53 lr 0.000076	 wd 0.0000	time 0.1867 (0.2258)	loss 0.9028 (0.8753)	grad_norm 0.2731 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7186MB
[2024-08-01 16:19:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:30 lr 0.000076	 wd 0.0000	time 0.1945 (0.2246)	loss 1.0176 (0.8758)	grad_norm 0.2703 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7186MB
[2024-08-01 16:20:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:07 lr 0.000076	 wd 0.0000	time 0.1758 (0.2231)	loss 0.9004 (0.8760)	grad_norm 0.2833 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7186MB
[2024-08-01 16:20:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:44 lr 0.000076	 wd 0.0000	time 0.1843 (0.2217)	loss 0.8545 (0.8756)	grad_norm 0.3013 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7186MB
[2024-08-01 16:20:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:22 lr 0.000075	 wd 0.0000	time 0.2049 (0.2212)	loss 0.8159 (0.8756)	grad_norm 0.2850 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7186MB
[2024-08-01 16:21:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000075	 wd 0.0000	time 0.1541 (0.2202)	loss 0.8569 (0.8757)	grad_norm 0.2721 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7186MB
[2024-08-01 16:21:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 9 training takes 0:09:16
[2024-08-01 16:21:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 20.482 (20.482)	Loss 0.3518 (0.3518)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 16:21:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.170 Acc@5 97.640
[2024-08-01 16:21:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 16:21:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.20%
[2024-08-01 16:22:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][0/2502]	eta 12:16:01 lr 0.000075	 wd 0.0000	time 17.6506 (17.6506)	loss 1.0215 (1.0215)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:22:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:19:15 lr 0.000075	 wd 0.0000	time 0.1504 (0.4810)	loss 0.7080 (0.8868)	grad_norm 0.2852 (0.2838)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:23:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:13:04 lr 0.000075	 wd 0.0000	time 0.1993 (0.3410)	loss 0.9438 (0.8794)	grad_norm 0.2930 (0.2837)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:23:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:36 lr 0.000075	 wd 0.0000	time 0.1839 (0.2892)	loss 0.8374 (0.8753)	grad_norm 0.2747 (0.2839)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:23:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:13 lr 0.000075	 wd 0.0000	time 0.1625 (0.2632)	loss 0.8989 (0.8736)	grad_norm 0.2877 (0.2838)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:24:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:08:21 lr 0.000074	 wd 0.0000	time 0.2634 (0.2503)	loss 0.7656 (0.8749)	grad_norm 0.2931 (0.2841)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:24:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:18 lr 0.000074	 wd 0.0000	time 0.2076 (0.2622)	loss 0.9351 (0.8740)	grad_norm 0.2843 (0.2839)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:24:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:33 lr 0.000074	 wd 0.0000	time 0.1842 (0.2517)	loss 0.8086 (0.8729)	grad_norm 0.2697 (0.2840)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:25:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:06:54 lr 0.000074	 wd 0.0000	time 0.1696 (0.2438)	loss 0.8691 (0.8732)	grad_norm 0.2779 (0.2842)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:25:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:19 lr 0.000074	 wd 0.0000	time 0.1913 (0.2372)	loss 0.8345 (0.8740)	grad_norm 0.2839 (0.2842)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:26:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:13 lr 0.000073	 wd 0.0000	time 0.2198 (0.2489)	loss 0.8091 (0.8741)	grad_norm 0.2839 (0.2843)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:26:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:42 lr 0.000073	 wd 0.0000	time 0.1861 (0.2441)	loss 0.7832 (0.8740)	grad_norm 0.2819 (0.2842)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:26:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:11 lr 0.000073	 wd 0.0000	time 0.1856 (0.2394)	loss 0.9741 (0.8738)	grad_norm 0.2779 (0.2842)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:27:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:42 lr 0.000073	 wd 0.0000	time 0.1578 (0.2351)	loss 0.8687 (0.8737)	grad_norm 0.2890 (0.2843)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:27:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:17 lr 0.000073	 wd 0.0000	time 0.2847 (0.2333)	loss 0.7856 (0.8735)	grad_norm 0.3026 (0.2843)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:27:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:03:52 lr 0.000073	 wd 0.0000	time 0.1827 (0.2324)	loss 0.8428 (0.8732)	grad_norm 0.2894 (0.2841)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:28:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:27 lr 0.000072	 wd 0.0000	time 0.2110 (0.2298)	loss 0.7656 (0.8736)	grad_norm 0.2740 (0.2841)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:28:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:02 lr 0.000072	 wd 0.0000	time 0.1888 (0.2276)	loss 0.8760 (0.8738)	grad_norm 0.2777 (0.2841)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:28:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:38 lr 0.000072	 wd 0.0000	time 0.1946 (0.2255)	loss 0.9463 (0.8736)	grad_norm 0.2973 (0.2842)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:29:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:15 lr 0.000072	 wd 0.0000	time 0.1810 (0.2249)	loss 0.9370 (0.8736)	grad_norm 0.2915 (0.2842)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:29:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:53 lr 0.000072	 wd 0.0000	time 0.1889 (0.2255)	loss 0.8721 (0.8740)	grad_norm 0.2885 (0.2843)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:29:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:30 lr 0.000071	 wd 0.0000	time 0.1845 (0.2240)	loss 0.8564 (0.8739)	grad_norm 0.2947 (0.2842)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:30:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:07 lr 0.000071	 wd 0.0000	time 0.2113 (0.2225)	loss 0.8750 (0.8744)	grad_norm 0.2822 (0.2842)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:30:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:44 lr 0.000071	 wd 0.0000	time 0.1940 (0.2214)	loss 0.9224 (0.8740)	grad_norm 0.2789 (0.2842)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:30:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:22 lr 0.000071	 wd 0.0000	time 0.1687 (0.2216)	loss 0.8745 (0.8744)	grad_norm 0.2739 (0.2841)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:31:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000071	 wd 0.0000	time 0.1488 (0.2197)	loss 0.9824 (0.8738)	grad_norm 0.2846 (0.2841)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:31:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 10 training takes 0:09:14
[2024-08-01 16:31:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 22.488 (22.488)	Loss 0.3574 (0.3574)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 16:31:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.148 Acc@5 97.630
[2024-08-01 16:31:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.1%
[2024-08-01 16:31:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.20%
[2024-08-01 16:32:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][0/2502]	eta 13:41:13 lr 0.000071	 wd 0.0000	time 19.6937 (19.6937)	loss 0.7959 (0.7959)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:32:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:17:37 lr 0.000070	 wd 0.0000	time 0.2075 (0.4404)	loss 0.8887 (0.8687)	grad_norm 0.2838 (0.2845)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:32:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:12:06 lr 0.000070	 wd 0.0000	time 0.1765 (0.3158)	loss 0.8887 (0.8715)	grad_norm 0.2921 (0.2844)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:33:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:10:01 lr 0.000070	 wd 0.0000	time 0.1697 (0.2729)	loss 0.9839 (0.8724)	grad_norm 0.2892 (0.2848)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:33:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:08:48 lr 0.000070	 wd 0.0000	time 0.1855 (0.2514)	loss 0.9351 (0.8704)	grad_norm 0.2919 (0.2848)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:33:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:08:12 lr 0.000070	 wd 0.0000	time 0.2888 (0.2460)	loss 0.7710 (0.8698)	grad_norm 0.2792 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7186MB
[2024-08-01 16:34:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:05 lr 0.000069	 wd 0.0000	time 0.1815 (0.2555)	loss 1.0557 (0.8681)	grad_norm 0.2822 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7186MB
[2024-08-01 16:34:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:07:22 lr 0.000069	 wd 0.0000	time 0.1526 (0.2456)	loss 0.8652 (0.8705)	grad_norm 0.2908 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7186MB
[2024-08-01 16:34:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:06:45 lr 0.000069	 wd 0.0000	time 0.1598 (0.2383)	loss 0.8955 (0.8714)	grad_norm 0.2867 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7186MB
[2024-08-01 16:35:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:06:14 lr 0.000069	 wd 0.0000	time 0.2178 (0.2337)	loss 0.9883 (0.8717)	grad_norm 0.2960 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7186MB
[2024-08-01 16:35:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:03 lr 0.000069	 wd 0.0000	time 0.1657 (0.2422)	loss 0.8276 (0.8731)	grad_norm 0.2862 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7186MB
[2024-08-01 16:36:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:32 lr 0.000069	 wd 0.0000	time 0.1925 (0.2374)	loss 0.7993 (0.8734)	grad_norm 0.2832 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7186MB
[2024-08-01 16:36:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:03 lr 0.000068	 wd 0.0000	time 0.1732 (0.2331)	loss 0.9272 (0.8739)	grad_norm 0.2844 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7186MB
[2024-08-01 16:36:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:04:35 lr 0.000068	 wd 0.0000	time 0.1638 (0.2295)	loss 0.7412 (0.8741)	grad_norm 0.2750 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7186MB
[2024-08-01 16:37:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:11 lr 0.000068	 wd 0.0000	time 0.1760 (0.2286)	loss 0.8438 (0.8746)	grad_norm 0.2977 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7186MB
[2024-08-01 16:37:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:03:48 lr 0.000068	 wd 0.0000	time 0.2344 (0.2276)	loss 0.9517 (0.8742)	grad_norm 0.2865 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7186MB
[2024-08-01 16:37:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:23 lr 0.000068	 wd 0.0000	time 0.2057 (0.2254)	loss 0.9170 (0.8743)	grad_norm 0.3054 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7186MB
[2024-08-01 16:38:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:02:59 lr 0.000067	 wd 0.0000	time 0.1833 (0.2233)	loss 0.7798 (0.8745)	grad_norm 0.2859 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7186MB
[2024-08-01 16:38:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:35 lr 0.000067	 wd 0.0000	time 0.1930 (0.2214)	loss 1.1143 (0.8753)	grad_norm 0.2863 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7186MB
[2024-08-01 16:38:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:12 lr 0.000067	 wd 0.0000	time 0.1993 (0.2206)	loss 0.7695 (0.8758)	grad_norm 0.2758 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7186MB
[2024-08-01 16:39:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:01:51 lr 0.000067	 wd 0.0000	time 0.1788 (0.2213)	loss 0.9082 (0.8755)	grad_norm 0.2791 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7186MB
[2024-08-01 16:39:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:28 lr 0.000067	 wd 0.0000	time 0.1766 (0.2199)	loss 0.8496 (0.8751)	grad_norm 0.2998 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7186MB
[2024-08-01 16:39:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:06 lr 0.000066	 wd 0.0000	time 0.1939 (0.2186)	loss 0.9023 (0.8751)	grad_norm 0.2905 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7186MB
[2024-08-01 16:40:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:43 lr 0.000066	 wd 0.0000	time 0.2123 (0.2176)	loss 0.8594 (0.8752)	grad_norm 0.2840 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7186MB
[2024-08-01 16:40:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:22 lr 0.000066	 wd 0.0000	time 0.1860 (0.2177)	loss 0.8765 (0.8755)	grad_norm 0.2842 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7186MB
[2024-08-01 16:40:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000066	 wd 0.0000	time 0.1448 (0.2161)	loss 1.0527 (0.8747)	grad_norm 0.2871 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7186MB
[2024-08-01 16:40:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 11 training takes 0:09:05
[2024-08-01 16:41:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 18.444 (18.444)	Loss 0.3540 (0.3540)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 16:41:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.244 Acc@5 97.618
[2024-08-01 16:41:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 16:41:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.24%
[2024-08-01 16:41:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saving......
[2024-08-01 16:41:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-01 16:41:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][0/2502]	eta 13:31:50 lr 0.000066	 wd 0.0000	time 19.4687 (19.4687)	loss 0.9062 (0.9062)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:42:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:17:51 lr 0.000066	 wd 0.0000	time 0.2025 (0.4461)	loss 0.8228 (0.8628)	grad_norm 0.2945 (0.2867)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:42:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:12:12 lr 0.000065	 wd 0.0000	time 0.1686 (0.3182)	loss 0.8457 (0.8692)	grad_norm 0.2851 (0.2857)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:42:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:04 lr 0.000065	 wd 0.0000	time 0.1736 (0.2746)	loss 0.9014 (0.8787)	grad_norm 0.3105 (0.2857)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:43:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:08:50 lr 0.000065	 wd 0.0000	time 0.1655 (0.2525)	loss 0.8364 (0.8801)	grad_norm 0.2826 (0.2860)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:43:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:08:04 lr 0.000065	 wd 0.0000	time 0.1955 (0.2421)	loss 0.7559 (0.8791)	grad_norm 0.2839 (0.2856)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:43:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:07:59 lr 0.000065	 wd 0.0000	time 0.1943 (0.2521)	loss 0.7764 (0.8790)	grad_norm 0.2873 (0.2860)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:44:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:17 lr 0.000064	 wd 0.0000	time 0.1888 (0.2426)	loss 0.8135 (0.8785)	grad_norm 0.2820 (0.2859)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:44:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:06:41 lr 0.000064	 wd 0.0000	time 0.1774 (0.2358)	loss 0.8984 (0.8773)	grad_norm 0.2744 (0.2858)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:44:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:08 lr 0.000064	 wd 0.0000	time 0.1886 (0.2302)	loss 0.8008 (0.8766)	grad_norm 0.2932 (0.2860)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:45:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:05:54 lr 0.000064	 wd 0.0000	time 0.1629 (0.2363)	loss 0.9165 (0.8766)	grad_norm 0.2832 (0.2861)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:45:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:38 lr 0.000064	 wd 0.0000	time 0.1884 (0.2413)	loss 0.7432 (0.8765)	grad_norm 0.2729 (0.2860)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:46:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:08 lr 0.000063	 wd 0.0000	time 0.1687 (0.2370)	loss 0.8862 (0.8758)	grad_norm 0.2933 (0.2860)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:46:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:40 lr 0.000063	 wd 0.0000	time 0.2046 (0.2330)	loss 0.7861 (0.8759)	grad_norm 0.2961 (0.2858)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:46:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:15 lr 0.000063	 wd 0.0000	time 0.2018 (0.2315)	loss 0.9341 (0.8761)	grad_norm 0.2854 (0.2859)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:47:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:03:50 lr 0.000063	 wd 0.0000	time 0.1738 (0.2304)	loss 0.8354 (0.8769)	grad_norm 0.2842 (0.2860)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:47:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:25 lr 0.000063	 wd 0.0000	time 0.2002 (0.2279)	loss 0.8667 (0.8763)	grad_norm 0.2816 (0.2859)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:47:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:00 lr 0.000062	 wd 0.0000	time 0.1828 (0.2256)	loss 0.8423 (0.8763)	grad_norm 0.2816 (0.2861)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:48:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:36 lr 0.000062	 wd 0.0000	time 0.1843 (0.2236)	loss 0.7974 (0.8764)	grad_norm 0.2834 (0.2863)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:48:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:14 lr 0.000062	 wd 0.0000	time 0.2088 (0.2228)	loss 0.8364 (0.8760)	grad_norm 0.2854 (0.2862)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:48:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:01:52 lr 0.000062	 wd 0.0000	time 0.1830 (0.2233)	loss 0.8228 (0.8763)	grad_norm 0.2855 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7186MB
[2024-08-01 16:49:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:29 lr 0.000062	 wd 0.0000	time 0.1888 (0.2217)	loss 0.8433 (0.8767)	grad_norm 0.2869 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7186MB
[2024-08-01 16:49:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:06 lr 0.000061	 wd 0.0000	time 0.1614 (0.2203)	loss 0.8921 (0.8768)	grad_norm 0.2975 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7186MB
[2024-08-01 16:49:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:44 lr 0.000061	 wd 0.0000	time 0.1900 (0.2194)	loss 0.8730 (0.8765)	grad_norm 0.2682 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7186MB
[2024-08-01 16:50:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:22 lr 0.000061	 wd 0.0000	time 0.1775 (0.2200)	loss 0.8579 (0.8757)	grad_norm 0.2873 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7186MB
[2024-08-01 16:50:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000061	 wd 0.0000	time 0.1525 (0.2182)	loss 0.8965 (0.8755)	grad_norm 0.2909 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7186MB
[2024-08-01 16:50:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 12 training takes 0:09:10
[2024-08-01 16:50:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 18.270 (18.270)	Loss 0.3513 (0.3513)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 16:51:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.230 Acc@5 97.644
[2024-08-01 16:51:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 16:51:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.24%
[2024-08-01 16:51:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][0/2502]	eta 15:31:12 lr 0.000061	 wd 0.0000	time 22.3311 (22.3311)	loss 0.8320 (0.8320)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:51:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:18:50 lr 0.000061	 wd 0.0000	time 0.1741 (0.4708)	loss 0.7866 (0.8651)	grad_norm 0.2787 (0.2854)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:52:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:12:37 lr 0.000060	 wd 0.0000	time 0.1949 (0.3292)	loss 0.7827 (0.8736)	grad_norm 0.2874 (0.2857)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:52:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:10:20 lr 0.000060	 wd 0.0000	time 0.1705 (0.2818)	loss 0.7852 (0.8681)	grad_norm 0.2924 (0.2861)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:52:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:08:59 lr 0.000060	 wd 0.0000	time 0.1642 (0.2568)	loss 0.7578 (0.8692)	grad_norm 0.2898 (0.2863)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:53:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:08:23 lr 0.000060	 wd 0.0000	time 0.1811 (0.2514)	loss 0.8345 (0.8697)	grad_norm 0.2869 (0.2866)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:53:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:28 lr 0.000060	 wd 0.0000	time 0.1730 (0.2674)	loss 0.7993 (0.8708)	grad_norm 0.2883 (0.2872)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:54:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:07:40 lr 0.000059	 wd 0.0000	time 0.1558 (0.2557)	loss 0.9985 (0.8712)	grad_norm 0.3099 (0.2871)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:54:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:00 lr 0.000059	 wd 0.0000	time 0.1675 (0.2469)	loss 0.9077 (0.8712)	grad_norm 0.2842 (0.2871)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:54:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:06:29 lr 0.000059	 wd 0.0000	time 0.2876 (0.2429)	loss 0.9194 (0.8720)	grad_norm 0.2871 (0.2874)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:55:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:13 lr 0.000059	 wd 0.0000	time 0.1996 (0.2486)	loss 0.9678 (0.8730)	grad_norm 0.2943 (0.2876)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:55:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:40 lr 0.000059	 wd 0.0000	time 0.1878 (0.2428)	loss 0.8530 (0.8725)	grad_norm 0.2855 (0.2875)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:55:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:09 lr 0.000058	 wd 0.0000	time 0.1898 (0.2378)	loss 0.9644 (0.8729)	grad_norm 0.2925 (0.2874)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:56:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:04:41 lr 0.000058	 wd 0.0000	time 0.2335 (0.2342)	loss 0.8706 (0.8734)	grad_norm 0.2949 (0.2876)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:56:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:17 lr 0.000058	 wd 0.0000	time 0.2110 (0.2333)	loss 1.0371 (0.8731)	grad_norm 0.2790 (0.2877)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:56:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:03:52 lr 0.000058	 wd 0.0000	time 0.1848 (0.2319)	loss 0.8896 (0.8732)	grad_norm 0.2950 (0.2877)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:57:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:26 lr 0.000058	 wd 0.0000	time 0.2194 (0.2292)	loss 0.8223 (0.8736)	grad_norm 0.2772 (0.2877)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:57:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:02 lr 0.000057	 wd 0.0000	time 0.2183 (0.2270)	loss 0.8154 (0.8737)	grad_norm 0.2846 (0.2877)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:57:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:38 lr 0.000057	 wd 0.0000	time 0.1909 (0.2253)	loss 0.8389 (0.8738)	grad_norm 0.3068 (0.2878)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:58:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:15 lr 0.000057	 wd 0.0000	time 0.2003 (0.2258)	loss 0.7979 (0.8726)	grad_norm 0.2955 (0.2878)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:58:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:52 lr 0.000057	 wd 0.0000	time 0.1924 (0.2249)	loss 0.8574 (0.8734)	grad_norm 0.2789 (0.2880)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:58:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:29 lr 0.000057	 wd 0.0000	time 0.1471 (0.2233)	loss 0.8579 (0.8739)	grad_norm 0.2645 (0.2879)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:59:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:06 lr 0.000056	 wd 0.0000	time 0.1680 (0.2218)	loss 0.9468 (0.8739)	grad_norm 0.2987 (0.2879)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:59:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:44 lr 0.000056	 wd 0.0000	time 0.1934 (0.2209)	loss 0.8032 (0.8735)	grad_norm 0.2868 (0.2879)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 16:59:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:22 lr 0.000056	 wd 0.0000	time 0.2284 (0.2207)	loss 0.8818 (0.8739)	grad_norm 0.2731 (0.2880)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:00:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000056	 wd 0.0000	time 0.1471 (0.2188)	loss 0.8125 (0.8739)	grad_norm 0.2833 (0.2879)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:00:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 13 training takes 0:09:13
[2024-08-01 17:00:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 20.430 (20.430)	Loss 0.3533 (0.3533)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 17:00:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.260 Acc@5 97.664
[2024-08-01 17:00:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 17:00:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.26%
[2024-08-01 17:00:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saving......
[2024-08-01 17:00:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-01 17:01:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][0/2502]	eta 21:14:01 lr 0.000056	 wd 0.0000	time 30.5522 (30.5522)	loss 0.9751 (0.9751)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:01:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:20:41 lr 0.000055	 wd 0.0000	time 0.1708 (0.5169)	loss 0.8467 (0.8714)	grad_norm 0.2890 (0.2881)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:02:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:13:27 lr 0.000055	 wd 0.0000	time 0.1744 (0.3508)	loss 0.8374 (0.8728)	grad_norm 0.2809 (0.2880)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:02:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:10:51 lr 0.000055	 wd 0.0000	time 0.1830 (0.2959)	loss 1.1074 (0.8750)	grad_norm 0.2812 (0.2876)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:02:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:09:36 lr 0.000055	 wd 0.0000	time 0.3031 (0.2744)	loss 1.0820 (0.8740)	grad_norm 0.2854 (0.2881)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:03:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:09:36 lr 0.000055	 wd 0.0000	time 0.1816 (0.2879)	loss 0.9180 (0.8737)	grad_norm 0.2763 (0.2880)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:03:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:08:36 lr 0.000054	 wd 0.0000	time 0.1553 (0.2714)	loss 0.8428 (0.8741)	grad_norm 0.3059 (0.2883)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:03:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:47 lr 0.000054	 wd 0.0000	time 0.1870 (0.2595)	loss 0.7954 (0.8731)	grad_norm 0.2891 (0.2887)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:04:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:07 lr 0.000054	 wd 0.0000	time 0.2029 (0.2514)	loss 0.7871 (0.8733)	grad_norm 0.2848 (0.2887)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:04:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:51 lr 0.000054	 wd 0.0000	time 0.1847 (0.2569)	loss 0.8623 (0.8730)	grad_norm 0.3004 (0.2889)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:05:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:06:15 lr 0.000054	 wd 0.0000	time 0.1814 (0.2498)	loss 0.9087 (0.8722)	grad_norm 0.3102 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7186MB
[2024-08-01 17:05:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:42 lr 0.000053	 wd 0.0000	time 0.1855 (0.2440)	loss 0.8291 (0.8721)	grad_norm 0.2716 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7186MB
[2024-08-01 17:05:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:11 lr 0.000053	 wd 0.0000	time 0.2017 (0.2393)	loss 0.8701 (0.8720)	grad_norm 0.2934 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7186MB
[2024-08-01 17:06:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:04:48 lr 0.000053	 wd 0.0000	time 0.2575 (0.2402)	loss 1.0693 (0.8717)	grad_norm 0.2914 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7186MB
[2024-08-01 17:06:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:28 lr 0.000053	 wd 0.0000	time 0.2109 (0.2436)	loss 0.8999 (0.8720)	grad_norm 0.2749 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7186MB
[2024-08-01 17:06:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:04:00 lr 0.000053	 wd 0.0000	time 0.1833 (0.2398)	loss 0.8540 (0.8724)	grad_norm 0.2937 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7186MB
[2024-08-01 17:07:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:33 lr 0.000052	 wd 0.0000	time 0.1617 (0.2365)	loss 0.8516 (0.8720)	grad_norm 0.2982 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7186MB
[2024-08-01 17:07:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:07 lr 0.000052	 wd 0.0000	time 0.1622 (0.2341)	loss 1.0283 (0.8726)	grad_norm 0.3084 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7186MB
[2024-08-01 17:07:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:44 lr 0.000052	 wd 0.0000	time 0.1777 (0.2339)	loss 0.6924 (0.8728)	grad_norm 0.2873 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7186MB
[2024-08-01 17:08:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:19 lr 0.000052	 wd 0.0000	time 0.1939 (0.2322)	loss 0.8271 (0.8725)	grad_norm 0.2858 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7186MB
[2024-08-01 17:08:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:01:55 lr 0.000052	 wd 0.0000	time 0.1849 (0.2302)	loss 0.7896 (0.8723)	grad_norm 0.2931 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7186MB
[2024-08-01 17:08:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:31 lr 0.000051	 wd 0.0000	time 0.1763 (0.2283)	loss 0.9141 (0.8724)	grad_norm 0.2879 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7186MB
[2024-08-01 17:09:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:08 lr 0.000051	 wd 0.0000	time 0.2112 (0.2271)	loss 0.8633 (0.8730)	grad_norm 0.2763 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7186MB
[2024-08-01 17:09:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:45 lr 0.000051	 wd 0.0000	time 0.1907 (0.2269)	loss 0.8398 (0.8728)	grad_norm 0.2951 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7186MB
[2024-08-01 17:09:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:23 lr 0.000051	 wd 0.0000	time 0.1702 (0.2256)	loss 0.9624 (0.8733)	grad_norm 0.2919 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7186MB
[2024-08-01 17:10:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000051	 wd 0.0000	time 0.1508 (0.2233)	loss 0.8716 (0.8736)	grad_norm 0.2937 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7186MB
[2024-08-01 17:10:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 14 training takes 0:09:24
[2024-08-01 17:10:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 26.314 (26.314)	Loss 0.3499 (0.3499)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 17:11:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.232 Acc@5 97.660
[2024-08-01 17:11:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 17:11:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.26%
[2024-08-01 17:11:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][0/2502]	eta 12:26:18 lr 0.000051	 wd 0.0000	time 17.8971 (17.8971)	loss 0.7925 (0.7925)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:11:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:15:21 lr 0.000050	 wd 0.0000	time 0.1668 (0.3836)	loss 0.9717 (0.8797)	grad_norm 0.2825 (0.2894)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:12:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:10:55 lr 0.000050	 wd 0.0000	time 0.1758 (0.2848)	loss 1.0029 (0.8754)	grad_norm 0.2917 (0.2902)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:12:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:10:49 lr 0.000050	 wd 0.0000	time 0.2380 (0.2949)	loss 0.9272 (0.8738)	grad_norm 0.2802 (0.2903)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:13:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:09:38 lr 0.000050	 wd 0.0000	time 0.1535 (0.2752)	loss 1.0215 (0.8750)	grad_norm 0.2991 (0.2905)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:13:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:08:34 lr 0.000049	 wd 0.0000	time 0.1617 (0.2569)	loss 0.7822 (0.8768)	grad_norm 0.2970 (0.2907)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:13:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:07:44 lr 0.000049	 wd 0.0000	time 0.1689 (0.2443)	loss 0.8350 (0.8764)	grad_norm 0.2994 (0.2906)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:14:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:12 lr 0.000049	 wd 0.0000	time 0.3553 (0.2401)	loss 0.8115 (0.8737)	grad_norm 0.2959 (0.2908)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:14:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:07:09 lr 0.000049	 wd 0.0000	time 0.2177 (0.2522)	loss 1.0205 (0.8742)	grad_norm 0.2981 (0.2909)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:14:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:32 lr 0.000049	 wd 0.0000	time 0.1825 (0.2450)	loss 0.7954 (0.8743)	grad_norm 0.2997 (0.2911)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:15:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:05:59 lr 0.000048	 wd 0.0000	time 0.1841 (0.2393)	loss 0.9253 (0.8739)	grad_norm 0.2886 (0.2912)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:15:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:29 lr 0.000048	 wd 0.0000	time 0.1953 (0.2350)	loss 0.9121 (0.8718)	grad_norm 0.3025 (0.2909)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:16:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:14 lr 0.000048	 wd 0.0000	time 0.1656 (0.2414)	loss 0.8018 (0.8728)	grad_norm 0.2820 (0.2908)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:16:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:04:45 lr 0.000048	 wd 0.0000	time 0.1640 (0.2371)	loss 0.9077 (0.8722)	grad_norm 0.2823 (0.2909)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:16:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:17 lr 0.000048	 wd 0.0000	time 0.1880 (0.2337)	loss 0.7842 (0.8727)	grad_norm 0.2949 (0.2910)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:17:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:03:50 lr 0.000047	 wd 0.0000	time 0.1650 (0.2305)	loss 0.9253 (0.8722)	grad_norm 0.2890 (0.2912)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:17:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:26 lr 0.000047	 wd 0.0000	time 0.2110 (0.2290)	loss 0.9370 (0.8723)	grad_norm 0.2861 (0.2913)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:17:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:03 lr 0.000047	 wd 0.0000	time 0.1507 (0.2288)	loss 0.7861 (0.8726)	grad_norm 0.2869 (0.2913)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:18:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:39 lr 0.000047	 wd 0.0000	time 0.1903 (0.2269)	loss 1.0195 (0.8731)	grad_norm 0.3149 (0.2913)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:18:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:15 lr 0.000047	 wd 0.0000	time 0.1809 (0.2252)	loss 0.9468 (0.8726)	grad_norm 0.3045 (0.2912)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:18:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:01:52 lr 0.000046	 wd 0.0000	time 0.1918 (0.2233)	loss 1.0156 (0.8735)	grad_norm 0.3116 (0.2913)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:19:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:29 lr 0.000046	 wd 0.0000	time 0.1767 (0.2228)	loss 0.8276 (0.8734)	grad_norm 0.2844 (0.2912)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:19:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:07 lr 0.000046	 wd 0.0000	time 0.1611 (0.2230)	loss 0.9053 (0.8737)	grad_norm 0.2846 (0.2911)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:19:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:44 lr 0.000046	 wd 0.0000	time 0.2247 (0.2216)	loss 0.8901 (0.8737)	grad_norm 0.3121 (0.2912)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:20:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:22 lr 0.000046	 wd 0.0000	time 0.1875 (0.2203)	loss 0.9180 (0.8737)	grad_norm 0.2872 (0.2913)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:20:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000045	 wd 0.0000	time 0.1486 (0.2182)	loss 1.0752 (0.8740)	grad_norm 0.2920 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7186MB
[2024-08-01 17:20:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 15 training takes 0:09:15
[2024-08-01 17:20:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_15.pth saving......
[2024-08-01 17:20:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_15.pth saved !!!
[2024-08-01 17:21:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 41.771 (41.771)	Loss 0.3525 (0.3525)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 17:21:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.224 Acc@5 97.664
[2024-08-01 17:21:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 17:21:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.26%
[2024-08-01 17:21:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][0/2502]	eta 10:57:09 lr 0.000045	 wd 0.0000	time 15.7591 (15.7591)	loss 0.7466 (0.7466)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:22:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:15:02 lr 0.000045	 wd 0.0000	time 0.4039 (0.3756)	loss 0.9829 (0.8851)	grad_norm 0.2999 (0.2931)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:22:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:12:55 lr 0.000045	 wd 0.0000	time 0.1619 (0.3368)	loss 0.8794 (0.8744)	grad_norm 0.3027 (0.2920)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:22:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:10:28 lr 0.000045	 wd 0.0000	time 0.1567 (0.2856)	loss 0.9087 (0.8752)	grad_norm 0.2895 (0.2912)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:23:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:09:07 lr 0.000045	 wd 0.0000	time 0.1752 (0.2604)	loss 0.8979 (0.8746)	grad_norm 0.2937 (0.2913)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:23:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:08:11 lr 0.000044	 wd 0.0000	time 0.2150 (0.2457)	loss 0.9722 (0.8743)	grad_norm 0.2861 (0.2913)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:23:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:07:49 lr 0.000044	 wd 0.0000	time 0.1482 (0.2468)	loss 0.9302 (0.8747)	grad_norm 0.2876 (0.2915)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:24:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:30 lr 0.000044	 wd 0.0000	time 0.1728 (0.2499)	loss 0.8940 (0.8751)	grad_norm 0.2915 (0.2915)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:24:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:06:52 lr 0.000044	 wd 0.0000	time 0.1844 (0.2422)	loss 0.8774 (0.8743)	grad_norm 0.2910 (0.2915)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:25:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:17 lr 0.000043	 wd 0.0000	time 0.1834 (0.2357)	loss 0.7993 (0.8758)	grad_norm 0.2949 (0.2917)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:25:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:05:48 lr 0.000043	 wd 0.0000	time 0.2327 (0.2323)	loss 0.8657 (0.8760)	grad_norm 0.2971 (0.2919)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:25:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:26 lr 0.000043	 wd 0.0000	time 0.1681 (0.2327)	loss 0.9658 (0.8764)	grad_norm 0.3060 (0.2921)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:26:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:04:58 lr 0.000043	 wd 0.0000	time 0.1818 (0.2294)	loss 0.9019 (0.8759)	grad_norm 0.2957 (0.2920)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:26:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:04:32 lr 0.000043	 wd 0.0000	time 0.2025 (0.2263)	loss 0.9688 (0.8753)	grad_norm 0.2905 (0.2920)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:26:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:06 lr 0.000042	 wd 0.0000	time 0.1727 (0.2234)	loss 0.7925 (0.8747)	grad_norm 0.2781 (0.2920)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:27:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:03:43 lr 0.000042	 wd 0.0000	time 0.1967 (0.2231)	loss 0.8115 (0.8742)	grad_norm 0.2757 (0.2921)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:27:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:21 lr 0.000042	 wd 0.0000	time 0.2508 (0.2229)	loss 0.7910 (0.8741)	grad_norm 0.2905 (0.2920)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:27:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:02:57 lr 0.000042	 wd 0.0000	time 0.1703 (0.2209)	loss 0.8652 (0.8739)	grad_norm 0.2937 (0.2922)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:28:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:33 lr 0.000042	 wd 0.0000	time 0.1834 (0.2193)	loss 1.0205 (0.8741)	grad_norm 0.2780 (0.2922)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:28:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:11 lr 0.000041	 wd 0.0000	time 0.2017 (0.2177)	loss 0.9873 (0.8732)	grad_norm 0.2894 (0.2922)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:28:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:01:49 lr 0.000041	 wd 0.0000	time 0.2301 (0.2172)	loss 0.8374 (0.8729)	grad_norm 0.2930 (0.2922)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:29:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:27 lr 0.000041	 wd 0.0000	time 0.1937 (0.2175)	loss 0.6802 (0.8726)	grad_norm 0.2886 (0.2923)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:29:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:05 lr 0.000041	 wd 0.0000	time 0.2097 (0.2164)	loss 0.7847 (0.8726)	grad_norm 0.2924 (0.2923)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:29:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:43 lr 0.000041	 wd 0.0000	time 0.1865 (0.2152)	loss 0.6807 (0.8720)	grad_norm 0.3051 (0.2923)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:30:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:21 lr 0.000040	 wd 0.0000	time 0.1850 (0.2143)	loss 0.7773 (0.8719)	grad_norm 0.2954 (0.2922)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:30:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1480 (0.2128)	loss 0.8408 (0.8716)	grad_norm 0.3129 (0.2923)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:30:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 16 training takes 0:09:08
[2024-08-01 17:31:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 27.470 (27.470)	Loss 0.3511 (0.3511)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 17:31:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.230 Acc@5 97.654
[2024-08-01 17:31:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 17:31:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.26%
[2024-08-01 17:31:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][0/2502]	eta 13:02:33 lr 0.000040	 wd 0.0000	time 18.7663 (18.7663)	loss 0.7642 (0.7642)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:32:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:17:53 lr 0.000040	 wd 0.0000	time 0.2210 (0.4470)	loss 0.9761 (0.8729)	grad_norm 0.2798 (0.2914)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:32:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:12:10 lr 0.000040	 wd 0.0000	time 0.1692 (0.3173)	loss 0.8594 (0.8770)	grad_norm 0.2789 (0.2921)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:32:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:01 lr 0.000040	 wd 0.0000	time 0.1591 (0.2732)	loss 0.8853 (0.8732)	grad_norm 0.3102 (0.2926)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:33:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:08:47 lr 0.000039	 wd 0.0000	time 0.1709 (0.2510)	loss 0.9341 (0.8716)	grad_norm 0.2822 (0.2928)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:33:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:08:29 lr 0.000039	 wd 0.0000	time 0.4495 (0.2547)	loss 0.7583 (0.8696)	grad_norm 0.3150 (0.2928)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:34:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:26 lr 0.000039	 wd 0.0000	time 0.1825 (0.2662)	loss 0.8125 (0.8711)	grad_norm 0.3057 (0.2932)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:34:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:39 lr 0.000039	 wd 0.0000	time 0.1864 (0.2549)	loss 0.8975 (0.8702)	grad_norm 0.2985 (0.2932)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:34:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:06:58 lr 0.000039	 wd 0.0000	time 0.1783 (0.2459)	loss 0.7822 (0.8706)	grad_norm 0.2834 (0.2932)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:35:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:29 lr 0.000038	 wd 0.0000	time 0.3197 (0.2433)	loss 0.9824 (0.8710)	grad_norm 0.2873 (0.2930)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:35:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:16 lr 0.000038	 wd 0.0000	time 0.1900 (0.2509)	loss 0.9209 (0.8710)	grad_norm 0.2947 (0.2931)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:35:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:43 lr 0.000038	 wd 0.0000	time 0.2203 (0.2449)	loss 0.7373 (0.8723)	grad_norm 0.2942 (0.2932)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:36:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:12 lr 0.000038	 wd 0.0000	time 0.1904 (0.2400)	loss 0.7710 (0.8738)	grad_norm 0.3048 (0.2934)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:36:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:04:44 lr 0.000038	 wd 0.0000	time 0.2350 (0.2364)	loss 0.9033 (0.8729)	grad_norm 0.2814 (0.2934)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:37:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:28 lr 0.000037	 wd 0.0000	time 0.1785 (0.2437)	loss 0.8975 (0.8738)	grad_norm 0.2776 (0.2935)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:37:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:04:00 lr 0.000037	 wd 0.0000	time 0.1773 (0.2399)	loss 0.8657 (0.8736)	grad_norm 0.2966 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7186MB
[2024-08-01 17:37:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:33 lr 0.000037	 wd 0.0000	time 0.1830 (0.2365)	loss 1.0234 (0.8734)	grad_norm 0.3053 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7186MB
[2024-08-01 17:38:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:07 lr 0.000037	 wd 0.0000	time 0.1888 (0.2336)	loss 1.0195 (0.8736)	grad_norm 0.2930 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7186MB
[2024-08-01 17:38:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:43 lr 0.000037	 wd 0.0000	time 0.2300 (0.2323)	loss 0.7734 (0.8750)	grad_norm 0.2950 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7186MB
[2024-08-01 17:38:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:19 lr 0.000036	 wd 0.0000	time 0.1448 (0.2324)	loss 0.7559 (0.8755)	grad_norm 0.2890 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7186MB
[2024-08-01 17:39:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:01:55 lr 0.000036	 wd 0.0000	time 0.1926 (0.2304)	loss 0.8013 (0.8750)	grad_norm 0.2885 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7186MB
[2024-08-01 17:39:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:31 lr 0.000036	 wd 0.0000	time 0.1915 (0.2285)	loss 0.8052 (0.8745)	grad_norm 0.2848 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7186MB
[2024-08-01 17:39:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:08 lr 0.000036	 wd 0.0000	time 0.2092 (0.2271)	loss 0.9370 (0.8743)	grad_norm 0.2960 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7186MB
[2024-08-01 17:40:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:45 lr 0.000036	 wd 0.0000	time 0.2701 (0.2268)	loss 0.9087 (0.8739)	grad_norm 0.2932 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7186MB
[2024-08-01 17:40:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:23 lr 0.000035	 wd 0.0000	time 0.1950 (0.2258)	loss 0.8291 (0.8742)	grad_norm 0.2947 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7186MB
[2024-08-01 17:40:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1502 (0.2235)	loss 0.9175 (0.8745)	grad_norm 0.2884 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7186MB
[2024-08-01 17:40:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 17 training takes 0:09:27
[2024-08-01 17:41:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 19.611 (19.611)	Loss 0.3491 (0.3491)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 17:41:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.212 Acc@5 97.660
[2024-08-01 17:41:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 17:41:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.26%
[2024-08-01 17:42:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][0/2502]	eta 1 day, 3:37:44 lr 0.000035	 wd 0.0000	time 39.7540 (39.7540)	loss 0.9023 (0.9023)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:42:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:23:24 lr 0.000035	 wd 0.0000	time 0.2032 (0.5846)	loss 0.9819 (0.8767)	grad_norm 0.2996 (0.2948)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:42:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:14:46 lr 0.000035	 wd 0.0000	time 0.1821 (0.3852)	loss 0.8350 (0.8726)	grad_norm 0.2982 (0.2945)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:43:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:12:31 lr 0.000035	 wd 0.0000	time 0.3758 (0.3415)	loss 0.9092 (0.8766)	grad_norm 0.2925 (0.2952)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:43:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:11:37 lr 0.000034	 wd 0.0000	time 0.1761 (0.3318)	loss 0.7930 (0.8780)	grad_norm 0.3042 (0.2949)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:44:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:10:07 lr 0.000034	 wd 0.0000	time 0.1909 (0.3033)	loss 0.6997 (0.8778)	grad_norm 0.2917 (0.2943)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:44:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:08:59 lr 0.000034	 wd 0.0000	time 0.1531 (0.2835)	loss 0.9385 (0.8743)	grad_norm 0.2987 (0.2945)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:44:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:08:10 lr 0.000034	 wd 0.0000	time 0.3059 (0.2720)	loss 0.9360 (0.8713)	grad_norm 0.2790 (0.2942)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:45:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:56 lr 0.000034	 wd 0.0000	time 0.1743 (0.2798)	loss 1.0635 (0.8696)	grad_norm 0.2866 (0.2941)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:45:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:07:11 lr 0.000033	 wd 0.0000	time 0.1715 (0.2695)	loss 0.9468 (0.8702)	grad_norm 0.3055 (0.2942)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:45:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:32 lr 0.000033	 wd 0.0000	time 0.1726 (0.2615)	loss 0.8394 (0.8711)	grad_norm 0.2944 (0.2942)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:46:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:57 lr 0.000033	 wd 0.0000	time 0.2164 (0.2553)	loss 0.7876 (0.8723)	grad_norm 0.2910 (0.2942)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:46:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:45 lr 0.000033	 wd 0.0000	time 0.1665 (0.2651)	loss 0.8901 (0.8718)	grad_norm 0.2902 (0.2942)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:47:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:05:11 lr 0.000033	 wd 0.0000	time 0.1749 (0.2590)	loss 0.8711 (0.8732)	grad_norm 0.2952 (0.2944)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:47:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:39 lr 0.000032	 wd 0.0000	time 0.1791 (0.2538)	loss 0.9922 (0.8726)	grad_norm 0.3037 (0.2945)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:47:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:04:09 lr 0.000032	 wd 0.0000	time 0.2382 (0.2493)	loss 0.8511 (0.8736)	grad_norm 0.2942 (0.2944)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:48:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:42 lr 0.000032	 wd 0.0000	time 0.3021 (0.2468)	loss 0.8633 (0.8729)	grad_norm 0.2975 (0.2945)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:48:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:16 lr 0.000032	 wd 0.0000	time 0.1807 (0.2450)	loss 0.9717 (0.8730)	grad_norm 0.3027 (0.2946)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:48:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:49 lr 0.000032	 wd 0.0000	time 0.2240 (0.2421)	loss 0.8262 (0.8730)	grad_norm 0.3094 (0.2947)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:49:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:24 lr 0.000032	 wd 0.0000	time 0.2416 (0.2395)	loss 0.8286 (0.8727)	grad_norm 0.3006 (0.2948)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:49:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:01:59 lr 0.000031	 wd 0.0000	time 0.2260 (0.2374)	loss 0.8774 (0.8732)	grad_norm 0.2801 (0.2948)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:49:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:35 lr 0.000031	 wd 0.0000	time 0.1884 (0.2369)	loss 0.7388 (0.8734)	grad_norm 0.2987 (0.2949)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:50:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:11 lr 0.000031	 wd 0.0000	time 0.1726 (0.2357)	loss 0.8833 (0.8732)	grad_norm 0.2905 (0.2950)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:50:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:47 lr 0.000031	 wd 0.0000	time 0.1836 (0.2337)	loss 0.7588 (0.8736)	grad_norm 0.2804 (0.2951)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:50:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:23 lr 0.000031	 wd 0.0000	time 0.1842 (0.2319)	loss 0.8618 (0.8737)	grad_norm 0.2976 (0.2952)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:51:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000030	 wd 0.0000	time 0.1513 (0.2294)	loss 0.8599 (0.8737)	grad_norm 0.2976 (0.2952)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:51:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 18 training takes 0:09:42
[2024-08-01 17:51:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 37.787 (37.787)	Loss 0.3494 (0.3494)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 17:52:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.196 Acc@5 97.662
[2024-08-01 17:52:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 17:52:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.26%
[2024-08-01 17:52:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][0/2502]	eta 11:11:11 lr 0.000030	 wd 0.0000	time 16.0956 (16.0956)	loss 0.8633 (0.8633)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:52:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:16:53 lr 0.000030	 wd 0.0000	time 0.4184 (0.4221)	loss 1.0176 (0.8648)	grad_norm 0.2943 (0.2958)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:53:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:13:00 lr 0.000030	 wd 0.0000	time 0.1713 (0.3390)	loss 0.6948 (0.8627)	grad_norm 0.3086 (0.2959)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:53:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:10:34 lr 0.000030	 wd 0.0000	time 0.1679 (0.2882)	loss 0.9678 (0.8679)	grad_norm 0.2953 (0.2957)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:53:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:09:13 lr 0.000030	 wd 0.0000	time 0.2154 (0.2633)	loss 0.8179 (0.8705)	grad_norm 0.2814 (0.2955)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 17:54:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:08:21 lr 0.000029	 wd 0.0000	time 0.2276 (0.2506)	loss 0.9316 (0.8705)	grad_norm 0.2977 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7186MB
[2024-08-01 17:54:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:37 lr 0.000029	 wd 0.0000	time 0.1867 (0.2719)	loss 0.7510 (0.8722)	grad_norm 0.2914 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7186MB
[2024-08-01 17:55:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:07:48 lr 0.000029	 wd 0.0000	time 0.2548 (0.2599)	loss 0.9893 (0.8732)	grad_norm 0.2906 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7186MB
[2024-08-01 17:55:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:07:06 lr 0.000029	 wd 0.0000	time 0.1572 (0.2508)	loss 0.8496 (0.8743)	grad_norm 0.3025 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7186MB
[2024-08-01 17:55:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:06:31 lr 0.000029	 wd 0.0000	time 0.1993 (0.2445)	loss 0.8579 (0.8741)	grad_norm 0.2946 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7186MB
[2024-08-01 17:56:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:24 lr 0.000028	 wd 0.0000	time 0.1744 (0.2560)	loss 0.9531 (0.8748)	grad_norm 0.2892 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7186MB
[2024-08-01 17:56:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:50 lr 0.000028	 wd 0.0000	time 0.1703 (0.2499)	loss 0.8228 (0.8742)	grad_norm 0.2966 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7186MB
[2024-08-01 17:57:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:18 lr 0.000028	 wd 0.0000	time 0.1850 (0.2446)	loss 0.8540 (0.8743)	grad_norm 0.2983 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7186MB
[2024-08-01 17:57:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:04:48 lr 0.000028	 wd 0.0000	time 0.1938 (0.2401)	loss 0.8262 (0.8750)	grad_norm 0.2886 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7186MB
[2024-08-01 17:57:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:24 lr 0.000028	 wd 0.0000	time 1.0825 (0.2404)	loss 0.8257 (0.8745)	grad_norm 0.2953 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7186MB
[2024-08-01 17:58:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:03:57 lr 0.000028	 wd 0.0000	time 0.1898 (0.2375)	loss 0.8853 (0.8749)	grad_norm 0.2800 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7186MB
[2024-08-01 17:58:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:31 lr 0.000027	 wd 0.0000	time 0.2004 (0.2345)	loss 0.8687 (0.8753)	grad_norm 0.3097 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7186MB
[2024-08-01 17:58:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:05 lr 0.000027	 wd 0.0000	time 0.1704 (0.2316)	loss 0.9834 (0.8752)	grad_norm 0.2931 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7186MB
[2024-08-01 17:59:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:41 lr 0.000027	 wd 0.0000	time 0.2127 (0.2296)	loss 0.7993 (0.8755)	grad_norm 0.2909 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7186MB
[2024-08-01 17:59:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:18 lr 0.000027	 wd 0.0000	time 0.1992 (0.2297)	loss 0.8413 (0.8756)	grad_norm 0.2935 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7186MB
[2024-08-01 17:59:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:54 lr 0.000027	 wd 0.0000	time 0.1932 (0.2283)	loss 0.9365 (0.8754)	grad_norm 0.2921 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7186MB
[2024-08-01 18:00:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:31 lr 0.000026	 wd 0.0000	time 0.2151 (0.2265)	loss 0.9697 (0.8751)	grad_norm 0.2953 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7186MB
[2024-08-01 18:00:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:07 lr 0.000026	 wd 0.0000	time 0.1575 (0.2248)	loss 0.8726 (0.8745)	grad_norm 0.3242 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7186MB
[2024-08-01 18:00:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:45 lr 0.000026	 wd 0.0000	time 0.2006 (0.2239)	loss 0.9053 (0.8742)	grad_norm 0.2946 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7186MB
[2024-08-01 18:01:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:22 lr 0.000026	 wd 0.0000	time 0.1731 (0.2242)	loss 0.9507 (0.8741)	grad_norm 0.3065 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7186MB
[2024-08-01 18:01:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1490 (0.2222)	loss 0.7036 (0.8741)	grad_norm 0.2930 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7186MB
[2024-08-01 18:01:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 19 training takes 0:09:24
[2024-08-01 18:01:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 18.203 (18.203)	Loss 0.3518 (0.3518)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 18:02:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.268 Acc@5 97.668
[2024-08-01 18:02:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 18:02:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.27%
[2024-08-01 18:02:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saving......
[2024-08-01 18:02:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-01 18:02:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][0/2502]	eta 22:38:44 lr 0.000026	 wd 0.0000	time 32.5838 (32.5838)	loss 0.8354 (0.8354)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:03:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:20:30 lr 0.000026	 wd 0.0000	time 0.1693 (0.5122)	loss 0.9907 (0.8782)	grad_norm 0.2954 (0.2989)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:03:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:13:23 lr 0.000025	 wd 0.0000	time 0.1701 (0.3490)	loss 0.9341 (0.8695)	grad_norm 0.2994 (0.2977)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:03:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:10:46 lr 0.000025	 wd 0.0000	time 0.2084 (0.2938)	loss 0.7524 (0.8655)	grad_norm 0.3000 (0.2979)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:04:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:09:41 lr 0.000025	 wd 0.0000	time 0.3142 (0.2764)	loss 0.8623 (0.8662)	grad_norm 0.3024 (0.2976)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:04:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:09:20 lr 0.000025	 wd 0.0000	time 0.1888 (0.2798)	loss 0.8589 (0.8655)	grad_norm 0.2855 (0.2981)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:04:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:08:22 lr 0.000025	 wd 0.0000	time 0.1754 (0.2640)	loss 0.7827 (0.8660)	grad_norm 0.3024 (0.2978)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:05:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:35 lr 0.000025	 wd 0.0000	time 0.1900 (0.2528)	loss 0.7793 (0.8664)	grad_norm 0.2876 (0.2979)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:05:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:06:59 lr 0.000024	 wd 0.0000	time 0.2451 (0.2462)	loss 0.9927 (0.8670)	grad_norm 0.2895 (0.2978)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:06:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:59 lr 0.000024	 wd 0.0000	time 0.1710 (0.2620)	loss 0.7432 (0.8670)	grad_norm 0.2853 (0.2979)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:06:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:06:21 lr 0.000024	 wd 0.0000	time 0.1861 (0.2543)	loss 0.8008 (0.8666)	grad_norm 0.2939 (0.2976)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:06:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:47 lr 0.000024	 wd 0.0000	time 0.1688 (0.2479)	loss 0.7925 (0.8669)	grad_norm 0.2925 (0.2976)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:07:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:16 lr 0.000024	 wd 0.0000	time 0.2220 (0.2431)	loss 0.7300 (0.8665)	grad_norm 0.2911 (0.2976)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:07:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:04:55 lr 0.000023	 wd 0.0000	time 0.1933 (0.2457)	loss 0.8838 (0.8666)	grad_norm 0.2980 (0.2974)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:07:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:26 lr 0.000023	 wd 0.0000	time 0.1540 (0.2414)	loss 0.9219 (0.8671)	grad_norm 0.3063 (0.2975)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:08:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:03:58 lr 0.000023	 wd 0.0000	time 0.1720 (0.2380)	loss 0.9517 (0.8667)	grad_norm 0.3008 (0.2975)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:08:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:31 lr 0.000023	 wd 0.0000	time 0.1796 (0.2349)	loss 0.9180 (0.8661)	grad_norm 0.3113 (0.2975)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:08:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:06 lr 0.000023	 wd 0.0000	time 0.2789 (0.2331)	loss 0.9497 (0.8662)	grad_norm 0.2918 (0.2975)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:09:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:43 lr 0.000023	 wd 0.0000	time 0.1788 (0.2333)	loss 0.7944 (0.8669)	grad_norm 0.2953 (0.2975)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:09:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:19 lr 0.000022	 wd 0.0000	time 0.1949 (0.2313)	loss 0.9917 (0.8675)	grad_norm 0.3039 (0.2975)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:09:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:01:55 lr 0.000022	 wd 0.0000	time 0.1575 (0.2294)	loss 0.8984 (0.8674)	grad_norm 0.2917 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7186MB
[2024-08-01 18:10:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:31 lr 0.000022	 wd 0.0000	time 0.1835 (0.2275)	loss 0.9204 (0.8679)	grad_norm 0.2950 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7186MB
[2024-08-01 18:10:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:08 lr 0.000022	 wd 0.0000	time 0.2050 (0.2266)	loss 0.8833 (0.8685)	grad_norm 0.3004 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7186MB
[2024-08-01 18:10:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:45 lr 0.000022	 wd 0.0000	time 0.1789 (0.2265)	loss 0.8149 (0.8694)	grad_norm 0.3113 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7186MB
[2024-08-01 18:11:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:22 lr 0.000022	 wd 0.0000	time 0.1562 (0.2251)	loss 0.8335 (0.8695)	grad_norm 0.2984 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7186MB
[2024-08-01 18:11:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1484 (0.2228)	loss 0.7788 (0.8693)	grad_norm 0.2870 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7186MB
[2024-08-01 18:11:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 20 training takes 0:09:26
[2024-08-01 18:12:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 43.029 (43.029)	Loss 0.3513 (0.3513)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 18:12:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.278 Acc@5 97.676
[2024-08-01 18:12:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 18:12:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.28%
[2024-08-01 18:12:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saving......
[2024-08-01 18:12:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-01 18:12:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][0/2502]	eta 11:16:45 lr 0.000021	 wd 0.0000	time 16.2294 (16.2294)	loss 0.9023 (0.9023)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:13:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:13:56 lr 0.000021	 wd 0.0000	time 0.1889 (0.3483)	loss 0.8906 (0.8823)	grad_norm 0.2965 (0.2982)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:13:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:11:12 lr 0.000021	 wd 0.0000	time 0.3996 (0.2924)	loss 0.9287 (0.8750)	grad_norm 0.2879 (0.2976)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:14:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:10:59 lr 0.000021	 wd 0.0000	time 0.1711 (0.2996)	loss 0.9150 (0.8726)	grad_norm 0.2932 (0.2983)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:14:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:09:30 lr 0.000021	 wd 0.0000	time 0.1834 (0.2713)	loss 0.9839 (0.8726)	grad_norm 0.2984 (0.2979)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:14:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:08:29 lr 0.000021	 wd 0.0000	time 0.1696 (0.2543)	loss 0.8203 (0.8730)	grad_norm 0.2928 (0.2981)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:15:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:07:43 lr 0.000020	 wd 0.0000	time 0.1771 (0.2437)	loss 0.8716 (0.8723)	grad_norm 0.3070 (0.2985)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:15:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:07:31 lr 0.000020	 wd 0.0000	time 0.1856 (0.2507)	loss 1.0000 (0.8726)	grad_norm 0.3064 (0.2983)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:15:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:06:53 lr 0.000020	 wd 0.0000	time 0.1947 (0.2431)	loss 0.9043 (0.8728)	grad_norm 0.3127 (0.2984)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:16:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:19 lr 0.000020	 wd 0.0000	time 0.1710 (0.2367)	loss 0.8203 (0.8738)	grad_norm 0.2933 (0.2982)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:16:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:05:47 lr 0.000020	 wd 0.0000	time 0.1756 (0.2316)	loss 0.8320 (0.8732)	grad_norm 0.2831 (0.2982)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:16:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:05:26 lr 0.000020	 wd 0.0000	time 0.4610 (0.2330)	loss 0.8838 (0.8737)	grad_norm 0.2948 (0.2982)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:17:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:12 lr 0.000019	 wd 0.0000	time 0.1831 (0.2399)	loss 0.8379 (0.8750)	grad_norm 0.2951 (0.2983)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:17:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:43 lr 0.000019	 wd 0.0000	time 0.1597 (0.2357)	loss 0.9434 (0.8745)	grad_norm 0.2886 (0.2982)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:18:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:15 lr 0.000019	 wd 0.0000	time 0.1569 (0.2320)	loss 0.8901 (0.8745)	grad_norm 0.2931 (0.2981)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:18:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:03:50 lr 0.000019	 wd 0.0000	time 0.2186 (0.2299)	loss 0.9170 (0.8742)	grad_norm 0.2957 (0.2981)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:18:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:27 lr 0.000019	 wd 0.0000	time 0.1970 (0.2301)	loss 0.9048 (0.8736)	grad_norm 0.3043 (0.2982)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:19:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:02 lr 0.000019	 wd 0.0000	time 0.1800 (0.2279)	loss 0.8794 (0.8742)	grad_norm 0.2958 (0.2983)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:19:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:38 lr 0.000018	 wd 0.0000	time 0.1754 (0.2260)	loss 0.8833 (0.8742)	grad_norm 0.2952 (0.2984)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:19:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:14 lr 0.000018	 wd 0.0000	time 0.1679 (0.2241)	loss 0.8999 (0.8743)	grad_norm 0.2932 (0.2984)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:20:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:52 lr 0.000018	 wd 0.0000	time 0.2207 (0.2232)	loss 0.7500 (0.8740)	grad_norm 0.3029 (0.2985)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:20:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:29 lr 0.000018	 wd 0.0000	time 0.2373 (0.2238)	loss 0.7656 (0.8735)	grad_norm 0.2890 (0.2986)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:20:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:07 lr 0.000018	 wd 0.0000	time 0.1584 (0.2225)	loss 0.7832 (0.8729)	grad_norm 0.3028 (0.2986)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:21:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:44 lr 0.000018	 wd 0.0000	time 0.1775 (0.2211)	loss 0.9331 (0.8729)	grad_norm 0.2979 (0.2986)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:21:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:22 lr 0.000018	 wd 0.0000	time 0.1812 (0.2197)	loss 0.8584 (0.8729)	grad_norm 0.2890 (0.2987)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:21:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000017	 wd 0.0000	time 0.1488 (0.2180)	loss 0.8994 (0.8730)	grad_norm 0.2755 (0.2987)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:21:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 21 training takes 0:09:14
[2024-08-01 18:22:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 36.913 (36.913)	Loss 0.3501 (0.3501)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 18:22:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.266 Acc@5 97.694
[2024-08-01 18:22:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 18:22:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.28%
[2024-08-01 18:23:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][0/2502]	eta 10:59:04 lr 0.000017	 wd 0.0000	time 15.8050 (15.8050)	loss 0.8374 (0.8374)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:23:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:18:15 lr 0.000017	 wd 0.0000	time 0.2170 (0.4561)	loss 0.9185 (0.8788)	grad_norm 0.3034 (0.2999)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:23:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:12:23 lr 0.000017	 wd 0.0000	time 0.1761 (0.3231)	loss 0.7983 (0.8744)	grad_norm 0.2924 (0.2995)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:24:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:10:11 lr 0.000017	 wd 0.0000	time 0.1824 (0.2778)	loss 0.8721 (0.8740)	grad_norm 0.2986 (0.3000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:24:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:09:02 lr 0.000017	 wd 0.0000	time 0.1843 (0.2579)	loss 0.8096 (0.8790)	grad_norm 0.2894 (0.3002)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:24:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:08:25 lr 0.000017	 wd 0.0000	time 0.3257 (0.2526)	loss 0.7002 (0.8770)	grad_norm 0.2843 (0.2998)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:25:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:48 lr 0.000016	 wd 0.0000	time 0.1827 (0.2776)	loss 0.9229 (0.8782)	grad_norm 0.2814 (0.2998)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:25:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:57 lr 0.000016	 wd 0.0000	time 0.2150 (0.2649)	loss 0.9810 (0.8767)	grad_norm 0.2902 (0.3000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:26:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:07:13 lr 0.000016	 wd 0.0000	time 0.1555 (0.2549)	loss 0.8848 (0.8768)	grad_norm 0.2957 (0.2999)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:26:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:49 lr 0.000016	 wd 0.0000	time 0.3611 (0.2556)	loss 0.8369 (0.8767)	grad_norm 0.2885 (0.3001)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:27:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:28 lr 0.000016	 wd 0.0000	time 0.1935 (0.2590)	loss 0.8916 (0.8763)	grad_norm 0.2918 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7186MB
[2024-08-01 18:27:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:53 lr 0.000016	 wd 0.0000	time 0.1658 (0.2524)	loss 0.7744 (0.8748)	grad_norm 0.2872 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7186MB
[2024-08-01 18:27:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:21 lr 0.000016	 wd 0.0000	time 0.1710 (0.2466)	loss 0.8472 (0.8753)	grad_norm 0.2877 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7186MB
[2024-08-01 18:28:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:04:51 lr 0.000015	 wd 0.0000	time 0.2086 (0.2428)	loss 0.8721 (0.8740)	grad_norm 0.2930 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7186MB
[2024-08-01 18:28:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:27 lr 0.000015	 wd 0.0000	time 0.1940 (0.2425)	loss 0.8613 (0.8738)	grad_norm 0.2943 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7186MB
[2024-08-01 18:28:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:03:59 lr 0.000015	 wd 0.0000	time 0.2081 (0.2392)	loss 0.6904 (0.8737)	grad_norm 0.2919 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7186MB
[2024-08-01 18:29:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:32 lr 0.000015	 wd 0.0000	time 0.1815 (0.2361)	loss 0.8311 (0.8739)	grad_norm 0.3027 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7186MB
[2024-08-01 18:29:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:07 lr 0.000015	 wd 0.0000	time 0.1792 (0.2332)	loss 0.8892 (0.8734)	grad_norm 0.3018 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7186MB
[2024-08-01 18:29:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:42 lr 0.000015	 wd 0.0000	time 0.2311 (0.2314)	loss 0.9282 (0.8734)	grad_norm 0.2959 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7186MB
[2024-08-01 18:30:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:19 lr 0.000015	 wd 0.0000	time 0.1760 (0.2315)	loss 0.8921 (0.8739)	grad_norm 0.2976 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7186MB
[2024-08-01 18:30:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:55 lr 0.000014	 wd 0.0000	time 0.2103 (0.2297)	loss 0.9570 (0.8736)	grad_norm 0.2761 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7186MB
[2024-08-01 18:30:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:31 lr 0.000014	 wd 0.0000	time 0.1707 (0.2279)	loss 0.8164 (0.8740)	grad_norm 0.3023 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7186MB
[2024-08-01 18:31:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:08 lr 0.000014	 wd 0.0000	time 0.1879 (0.2262)	loss 0.6914 (0.8739)	grad_norm 0.2938 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7186MB
[2024-08-01 18:31:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:45 lr 0.000014	 wd 0.0000	time 0.1998 (0.2254)	loss 0.9380 (0.8738)	grad_norm 0.2991 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7186MB
[2024-08-01 18:31:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:22 lr 0.000014	 wd 0.0000	time 0.1693 (0.2249)	loss 0.7598 (0.8739)	grad_norm 0.3022 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7186MB
[2024-08-01 18:32:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1485 (0.2226)	loss 0.8311 (0.8735)	grad_norm 0.3047 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7186MB
[2024-08-01 18:32:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 22 training takes 0:09:24
[2024-08-01 18:32:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 19.747 (19.747)	Loss 0.3496 (0.3496)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 18:32:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.286 Acc@5 97.678
[2024-08-01 18:32:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 18:32:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.29%
[2024-08-01 18:32:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saving......
[2024-08-01 18:32:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth saved !!!
[2024-08-01 18:33:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][0/2502]	eta 1 day, 0:39:43 lr 0.000014	 wd 0.0000	time 35.4851 (35.4851)	loss 0.7695 (0.7695)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:33:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:22:05 lr 0.000014	 wd 0.0000	time 0.1823 (0.5519)	loss 0.8799 (0.8718)	grad_norm 0.3027 (0.3023)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:34:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:14:09 lr 0.000013	 wd 0.0000	time 0.1715 (0.3691)	loss 0.9292 (0.8692)	grad_norm 0.3165 (0.3010)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:34:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:11:22 lr 0.000013	 wd 0.0000	time 0.2347 (0.3100)	loss 0.7725 (0.8679)	grad_norm 0.2961 (0.3011)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:35:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:11:09 lr 0.000013	 wd 0.0000	time 0.2433 (0.3187)	loss 0.9854 (0.8695)	grad_norm 0.2979 (0.3014)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:35:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:09:46 lr 0.000013	 wd 0.0000	time 0.1873 (0.2930)	loss 0.8936 (0.8735)	grad_norm 0.2887 (0.3014)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:35:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:08:42 lr 0.000013	 wd 0.0000	time 0.2159 (0.2749)	loss 0.8906 (0.8745)	grad_norm 0.3036 (0.3014)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:35:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:51 lr 0.000013	 wd 0.0000	time 0.1812 (0.2619)	loss 0.9531 (0.8753)	grad_norm 0.2857 (0.3010)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:36:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:07:43 lr 0.000013	 wd 0.0000	time 0.3284 (0.2722)	loss 0.9746 (0.8750)	grad_norm 0.2991 (0.3009)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:36:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:07:05 lr 0.000012	 wd 0.0000	time 0.1766 (0.2655)	loss 1.1094 (0.8735)	grad_norm 0.3039 (0.3009)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:37:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:27 lr 0.000012	 wd 0.0000	time 0.1899 (0.2577)	loss 0.7451 (0.8739)	grad_norm 0.3024 (0.3009)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:37:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:52 lr 0.000012	 wd 0.0000	time 0.1749 (0.2512)	loss 0.7202 (0.8730)	grad_norm 0.3101 (0.3009)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:37:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:26 lr 0.000012	 wd 0.0000	time 0.4373 (0.2507)	loss 0.9341 (0.8733)	grad_norm 0.2873 (0.3009)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:38:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:05:07 lr 0.000012	 wd 0.0000	time 0.1856 (0.2562)	loss 0.9395 (0.8735)	grad_norm 0.3158 (0.3011)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:38:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:36 lr 0.000012	 wd 0.0000	time 0.1697 (0.2511)	loss 0.9414 (0.8739)	grad_norm 0.3041 (0.3011)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:39:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:04:07 lr 0.000012	 wd 0.0000	time 0.1681 (0.2465)	loss 0.7583 (0.8747)	grad_norm 0.3059 (0.3011)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:39:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:39 lr 0.000012	 wd 0.0000	time 0.1927 (0.2436)	loss 0.8857 (0.8747)	grad_norm 0.2924 (0.3012)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:39:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:15 lr 0.000011	 wd 0.0000	time 0.1684 (0.2436)	loss 0.7920 (0.8745)	grad_norm 0.3012 (0.3013)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:40:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:49 lr 0.000011	 wd 0.0000	time 0.1919 (0.2408)	loss 0.8936 (0.8747)	grad_norm 0.2948 (0.3014)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:40:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:23 lr 0.000011	 wd 0.0000	time 0.2460 (0.2382)	loss 0.7925 (0.8743)	grad_norm 0.2965 (0.3013)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:40:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:01:58 lr 0.000011	 wd 0.0000	time 0.1779 (0.2358)	loss 0.9814 (0.8740)	grad_norm 0.2996 (0.3013)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:41:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:34 lr 0.000011	 wd 0.0000	time 0.2026 (0.2344)	loss 1.0215 (0.8741)	grad_norm 0.2789 (0.3012)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:41:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:10 lr 0.000011	 wd 0.0000	time 0.1983 (0.2344)	loss 0.9536 (0.8736)	grad_norm 0.3114 (0.3012)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:41:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:46 lr 0.000011	 wd 0.0000	time 0.1816 (0.2326)	loss 0.8594 (0.8737)	grad_norm 0.3018 (0.3011)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:42:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:23 lr 0.000011	 wd 0.0000	time 0.1918 (0.2308)	loss 0.8823 (0.8738)	grad_norm 0.2971 (0.3012)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:42:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1558 (0.2284)	loss 0.8057 (0.8736)	grad_norm 0.3072 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7186MB
[2024-08-01 18:42:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 23 training takes 0:09:40
[2024-08-01 18:43:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 38.572 (38.572)	Loss 0.3491 (0.3491)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 18:43:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.270 Acc@5 97.674
[2024-08-01 18:43:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 18:43:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.29%
[2024-08-01 18:43:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][0/2502]	eta 10:42:31 lr 0.000010	 wd 0.0000	time 15.4081 (15.4081)	loss 0.8716 (0.8716)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:44:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:14:01 lr 0.000010	 wd 0.0000	time 0.2393 (0.3503)	loss 0.9795 (0.8689)	grad_norm 0.2889 (0.3021)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:44:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:12:35 lr 0.000010	 wd 0.0000	time 0.2033 (0.3281)	loss 0.8950 (0.8714)	grad_norm 0.3032 (0.3013)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:44:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:10:20 lr 0.000010	 wd 0.0000	time 0.1704 (0.2817)	loss 0.8027 (0.8744)	grad_norm 0.3146 (0.3014)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:45:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:09:01 lr 0.000010	 wd 0.0000	time 0.2093 (0.2576)	loss 0.7310 (0.8755)	grad_norm 0.2970 (0.3014)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:45:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:08:07 lr 0.000010	 wd 0.0000	time 0.1802 (0.2433)	loss 0.8857 (0.8773)	grad_norm 0.3290 (0.3015)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:45:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:07:40 lr 0.000010	 wd 0.0000	time 0.3506 (0.2419)	loss 0.8950 (0.8751)	grad_norm 0.2844 (0.3020)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:46:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:07:27 lr 0.000010	 wd 0.0000	time 0.1789 (0.2483)	loss 0.8311 (0.8745)	grad_norm 0.2944 (0.3016)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:46:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:06:48 lr 0.000010	 wd 0.0000	time 0.1720 (0.2403)	loss 0.8115 (0.8737)	grad_norm 0.3102 (0.3015)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:47:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:06:15 lr 0.000009	 wd 0.0000	time 0.1721 (0.2342)	loss 0.9390 (0.8744)	grad_norm 0.3037 (0.3013)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:47:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:05:46 lr 0.000009	 wd 0.0000	time 0.3059 (0.2304)	loss 0.8120 (0.8752)	grad_norm 0.2981 (0.3013)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:48:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:05:43 lr 0.000009	 wd 0.0000	time 0.1958 (0.2451)	loss 0.8164 (0.8749)	grad_norm 0.3021 (0.3016)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:48:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:12 lr 0.000009	 wd 0.0000	time 0.1613 (0.2403)	loss 0.8262 (0.8746)	grad_norm 0.2835 (0.3017)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:48:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:04:43 lr 0.000009	 wd 0.0000	time 0.1763 (0.2362)	loss 0.7358 (0.8732)	grad_norm 0.3027 (0.3015)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:48:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:16 lr 0.000009	 wd 0.0000	time 0.1843 (0.2329)	loss 0.7827 (0.8736)	grad_norm 0.2895 (0.3016)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:49:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:01 lr 0.000009	 wd 0.0000	time 0.1978 (0.2410)	loss 0.8232 (0.8736)	grad_norm 0.2962 (0.3016)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:49:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:34 lr 0.000009	 wd 0.0000	time 0.1684 (0.2374)	loss 0.8965 (0.8736)	grad_norm 0.2941 (0.3017)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:50:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:08 lr 0.000008	 wd 0.0000	time 0.1650 (0.2345)	loss 0.9570 (0.8740)	grad_norm 0.3081 (0.3016)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:50:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:42 lr 0.000008	 wd 0.0000	time 0.1810 (0.2321)	loss 0.7734 (0.8743)	grad_norm 0.2932 (0.3016)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:50:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:19 lr 0.000008	 wd 0.0000	time 0.1838 (0.2310)	loss 0.7456 (0.8739)	grad_norm 0.2895 (0.3017)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:51:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:01:55 lr 0.000008	 wd 0.0000	time 0.1862 (0.2307)	loss 0.7129 (0.8738)	grad_norm 0.2997 (0.3018)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:51:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:31 lr 0.000008	 wd 0.0000	time 0.2248 (0.2288)	loss 0.9736 (0.8735)	grad_norm 0.3038 (0.3018)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:51:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:08 lr 0.000008	 wd 0.0000	time 0.1738 (0.2271)	loss 0.8667 (0.8734)	grad_norm 0.2957 (0.3018)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:52:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:45 lr 0.000008	 wd 0.0000	time 0.1877 (0.2256)	loss 0.9146 (0.8736)	grad_norm 0.2914 (0.3017)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:52:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:23 lr 0.000008	 wd 0.0000	time 0.2038 (0.2257)	loss 1.0547 (0.8734)	grad_norm 0.2939 (0.3017)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:52:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1489 (0.2237)	loss 0.9819 (0.8733)	grad_norm 0.2911 (0.3017)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:53:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 24 training takes 0:09:30
[2024-08-01 18:53:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 20.871 (20.871)	Loss 0.3503 (0.3503)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 18:53:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.280 Acc@5 97.692
[2024-08-01 18:53:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 18:53:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.29%
[2024-08-01 18:54:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][0/2502]	eta 1 day, 0:44:13 lr 0.000008	 wd 0.0000	time 35.5927 (35.5927)	loss 0.8735 (0.8735)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:54:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:21:59 lr 0.000008	 wd 0.0000	time 0.1755 (0.5493)	loss 0.8364 (0.8888)	grad_norm 0.2901 (0.3033)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:54:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:14:06 lr 0.000007	 wd 0.0000	time 0.1856 (0.3678)	loss 0.8232 (0.8851)	grad_norm 0.3028 (0.3024)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:55:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:11:15 lr 0.000007	 wd 0.0000	time 0.1759 (0.3068)	loss 0.8877 (0.8775)	grad_norm 0.3043 (0.3022)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:55:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:10:26 lr 0.000007	 wd 0.0000	time 0.4192 (0.2980)	loss 0.7397 (0.8783)	grad_norm 0.3043 (0.3022)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:56:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:09:56 lr 0.000007	 wd 0.0000	time 0.2327 (0.2980)	loss 0.8579 (0.8776)	grad_norm 0.2815 (0.3021)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:56:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:52 lr 0.000007	 wd 0.0000	time 0.1779 (0.2797)	loss 0.7329 (0.8771)	grad_norm 0.3136 (0.3020)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:56:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:07:59 lr 0.000007	 wd 0.0000	time 0.1790 (0.2660)	loss 0.8291 (0.8762)	grad_norm 0.3046 (0.3020)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:57:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:07:23 lr 0.000007	 wd 0.0000	time 0.3283 (0.2606)	loss 0.9814 (0.8757)	grad_norm 0.2995 (0.3021)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:57:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:07:09 lr 0.000007	 wd 0.0000	time 0.1612 (0.2680)	loss 0.7305 (0.8754)	grad_norm 0.2995 (0.3021)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:58:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:30 lr 0.000007	 wd 0.0000	time 0.2011 (0.2599)	loss 0.9282 (0.8759)	grad_norm 0.3195 (0.3023)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:58:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:54 lr 0.000007	 wd 0.0000	time 0.1713 (0.2531)	loss 0.9893 (0.8754)	grad_norm 0.3051 (0.3023)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:58:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:23 lr 0.000006	 wd 0.0000	time 0.1952 (0.2482)	loss 1.0029 (0.8762)	grad_norm 0.3052 (0.3022)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:59:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:05:04 lr 0.000006	 wd 0.0000	time 0.1872 (0.2532)	loss 0.8813 (0.8751)	grad_norm 0.2931 (0.3023)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:59:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:33 lr 0.000006	 wd 0.0000	time 0.1732 (0.2485)	loss 0.9365 (0.8747)	grad_norm 0.2913 (0.3022)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 18:59:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:04:04 lr 0.000006	 wd 0.0000	time 0.1819 (0.2444)	loss 0.9678 (0.8756)	grad_norm 0.2984 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7186MB
[2024-08-01 19:00:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:37 lr 0.000006	 wd 0.0000	time 0.1718 (0.2409)	loss 0.7451 (0.8752)	grad_norm 0.2912 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7186MB
[2024-08-01 19:00:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:11 lr 0.000006	 wd 0.0000	time 0.1932 (0.2388)	loss 0.8164 (0.8759)	grad_norm 0.2903 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7186MB
[2024-08-01 19:00:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:46 lr 0.000006	 wd 0.0000	time 0.1720 (0.2379)	loss 0.9019 (0.8754)	grad_norm 0.2901 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7186MB
[2024-08-01 19:01:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:21 lr 0.000006	 wd 0.0000	time 0.1746 (0.2355)	loss 0.9961 (0.8754)	grad_norm 0.2977 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7186MB
[2024-08-01 19:01:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:01:57 lr 0.000006	 wd 0.0000	time 0.1709 (0.2334)	loss 1.0117 (0.8754)	grad_norm 0.3019 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7186MB
[2024-08-01 19:01:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:33 lr 0.000006	 wd 0.0000	time 0.1948 (0.2314)	loss 0.8984 (0.8748)	grad_norm 0.3006 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7186MB
[2024-08-01 19:02:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:09 lr 0.000006	 wd 0.0000	time 0.5116 (0.2305)	loss 0.8364 (0.8745)	grad_norm 0.2834 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7186MB
[2024-08-01 19:02:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:46 lr 0.000005	 wd 0.0000	time 0.2177 (0.2303)	loss 0.7827 (0.8744)	grad_norm 0.2938 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7186MB
[2024-08-01 19:02:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:23 lr 0.000005	 wd 0.0000	time 0.2634 (0.2286)	loss 0.8276 (0.8743)	grad_norm 0.2900 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7186MB
[2024-08-01 19:03:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000005	 wd 0.0000	time 0.1515 (0.2263)	loss 0.8799 (0.8747)	grad_norm 0.3056 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7186MB
[2024-08-01 19:03:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 25 training takes 0:09:34
[2024-08-01 19:04:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 43.817 (43.817)	Loss 0.3499 (0.3499)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 19:04:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.280 Acc@5 97.682
[2024-08-01 19:04:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 19:04:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.29%
[2024-08-01 19:04:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][0/2502]	eta 11:37:10 lr 0.000005	 wd 0.0000	time 16.7186 (16.7186)	loss 1.0215 (1.0215)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:04:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:13:58 lr 0.000005	 wd 0.0000	time 0.1922 (0.3490)	loss 0.7803 (0.8825)	grad_norm 0.2975 (0.3063)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:05:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:12:50 lr 0.000005	 wd 0.0000	time 1.1430 (0.3349)	loss 0.8550 (0.8790)	grad_norm 0.3114 (0.3050)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:05:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:10:38 lr 0.000005	 wd 0.0000	time 0.1828 (0.2899)	loss 0.8691 (0.8802)	grad_norm 0.3138 (0.3046)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:06:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:09:14 lr 0.000005	 wd 0.0000	time 0.1611 (0.2638)	loss 0.8960 (0.8777)	grad_norm 0.3019 (0.3039)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:06:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:08:16 lr 0.000005	 wd 0.0000	time 0.1850 (0.2480)	loss 0.8145 (0.8759)	grad_norm 0.2833 (0.3033)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:06:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:07:36 lr 0.000005	 wd 0.0000	time 0.2070 (0.2400)	loss 0.8633 (0.8767)	grad_norm 0.3003 (0.3035)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:07:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:41 lr 0.000005	 wd 0.0000	time 0.1847 (0.2564)	loss 0.8218 (0.8748)	grad_norm 0.2972 (0.3032)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:07:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:07:01 lr 0.000005	 wd 0.0000	time 0.1642 (0.2476)	loss 0.8467 (0.8759)	grad_norm 0.3113 (0.3031)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:07:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:06:26 lr 0.000005	 wd 0.0000	time 0.1794 (0.2411)	loss 0.7910 (0.8743)	grad_norm 0.3047 (0.3032)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:08:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:05:54 lr 0.000004	 wd 0.0000	time 0.2359 (0.2361)	loss 0.9517 (0.8747)	grad_norm 0.2917 (0.3032)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:08:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:37 lr 0.000004	 wd 0.0000	time 0.1738 (0.2407)	loss 0.9644 (0.8754)	grad_norm 0.2935 (0.3032)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:09:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:07 lr 0.000004	 wd 0.0000	time 0.1669 (0.2363)	loss 0.8984 (0.8751)	grad_norm 0.3051 (0.3032)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:09:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:04:39 lr 0.000004	 wd 0.0000	time 0.1809 (0.2326)	loss 0.7524 (0.8755)	grad_norm 0.2979 (0.3032)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:09:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:12 lr 0.000004	 wd 0.0000	time 0.1453 (0.2294)	loss 0.9712 (0.8752)	grad_norm 0.3008 (0.3032)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:10:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:03:48 lr 0.000004	 wd 0.0000	time 0.3068 (0.2283)	loss 0.8555 (0.8755)	grad_norm 0.2920 (0.3033)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:10:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:28 lr 0.000004	 wd 0.0000	time 0.1834 (0.2309)	loss 0.7393 (0.8745)	grad_norm 0.2848 (0.3033)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:10:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:03 lr 0.000004	 wd 0.0000	time 0.2017 (0.2283)	loss 0.8511 (0.8752)	grad_norm 0.2949 (0.3032)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:11:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:38 lr 0.000004	 wd 0.0000	time 0.1740 (0.2262)	loss 0.9185 (0.8757)	grad_norm 0.3010 (0.3033)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:11:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:15 lr 0.000004	 wd 0.0000	time 0.1713 (0.2243)	loss 0.8750 (0.8751)	grad_norm 0.3016 (0.3032)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:11:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:01:52 lr 0.000004	 wd 0.0000	time 0.2039 (0.2238)	loss 0.9233 (0.8749)	grad_norm 0.3052 (0.3031)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:12:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:30 lr 0.000004	 wd 0.0000	time 0.2837 (0.2239)	loss 0.8926 (0.8752)	grad_norm 0.3118 (0.3032)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:12:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:07 lr 0.000004	 wd 0.0000	time 0.1733 (0.2225)	loss 0.9341 (0.8752)	grad_norm 0.3008 (0.3031)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:12:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:44 lr 0.000004	 wd 0.0000	time 0.1704 (0.2211)	loss 0.8423 (0.8749)	grad_norm 0.3095 (0.3030)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:13:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:22 lr 0.000003	 wd 0.0000	time 0.2517 (0.2201)	loss 0.8706 (0.8752)	grad_norm 0.3129 (0.3031)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:13:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1479 (0.2185)	loss 0.9326 (0.8753)	grad_norm 0.2991 (0.3031)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:13:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 26 training takes 0:09:22
[2024-08-01 19:14:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 27.806 (27.806)	Loss 0.3494 (0.3494)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 19:14:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.284 Acc@5 97.680
[2024-08-01 19:14:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 19:14:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.29%
[2024-08-01 19:14:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][0/2502]	eta 16:13:33 lr 0.000003	 wd 0.0000	time 23.3468 (23.3468)	loss 0.9243 (0.9243)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:15:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:18:53 lr 0.000003	 wd 0.0000	time 0.1996 (0.4721)	loss 0.8779 (0.8798)	grad_norm 0.2998 (0.3024)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:15:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:12:43 lr 0.000003	 wd 0.0000	time 0.1958 (0.3315)	loss 0.7275 (0.8746)	grad_norm 0.3101 (0.3024)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:15:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:10:23 lr 0.000003	 wd 0.0000	time 0.1908 (0.2832)	loss 0.8906 (0.8748)	grad_norm 0.3138 (0.3028)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:16:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:09:04 lr 0.000003	 wd 0.0000	time 0.1736 (0.2591)	loss 0.8105 (0.8738)	grad_norm 0.3036 (0.3029)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:16:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:09:07 lr 0.000003	 wd 0.0000	time 0.1788 (0.2733)	loss 0.7407 (0.8730)	grad_norm 0.3253 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7186MB
[2024-08-01 19:17:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:24 lr 0.000003	 wd 0.0000	time 0.1773 (0.2653)	loss 0.8081 (0.8752)	grad_norm 0.3117 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7186MB
[2024-08-01 19:17:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:38 lr 0.000003	 wd 0.0000	time 0.1937 (0.2542)	loss 0.8354 (0.8748)	grad_norm 0.3159 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7186MB
[2024-08-01 19:17:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:06:57 lr 0.000003	 wd 0.0000	time 0.1755 (0.2454)	loss 0.8911 (0.8742)	grad_norm 0.2916 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7186MB
[2024-08-01 19:18:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:28 lr 0.000003	 wd 0.0000	time 0.2881 (0.2426)	loss 0.7290 (0.8739)	grad_norm 0.2938 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7186MB
[2024-08-01 19:18:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:13 lr 0.000003	 wd 0.0000	time 0.1829 (0.2486)	loss 0.8857 (0.8735)	grad_norm 0.2941 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7186MB
[2024-08-01 19:18:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:40 lr 0.000003	 wd 0.0000	time 0.1645 (0.2429)	loss 0.7676 (0.8735)	grad_norm 0.3088 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7186MB
[2024-08-01 19:19:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:10 lr 0.000003	 wd 0.0000	time 0.1662 (0.2383)	loss 0.8921 (0.8726)	grad_norm 0.2991 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7186MB
[2024-08-01 19:19:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:42 lr 0.000003	 wd 0.0000	time 0.1821 (0.2351)	loss 0.8550 (0.8727)	grad_norm 0.3054 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7186MB
[2024-08-01 19:20:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:25 lr 0.000003	 wd 0.0000	time 0.1774 (0.2411)	loss 0.8037 (0.8726)	grad_norm 0.3016 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7186MB
[2024-08-01 19:20:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:03:57 lr 0.000003	 wd 0.0000	time 0.1984 (0.2374)	loss 0.9727 (0.8727)	grad_norm 0.2937 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7186MB
[2024-08-01 19:20:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:31 lr 0.000003	 wd 0.0000	time 0.2004 (0.2344)	loss 0.8867 (0.8727)	grad_norm 0.2954 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7186MB
[2024-08-01 19:21:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:05 lr 0.000002	 wd 0.0000	time 0.2156 (0.2318)	loss 0.8789 (0.8728)	grad_norm 0.3075 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7186MB
[2024-08-01 19:21:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:41 lr 0.000002	 wd 0.0000	time 0.2238 (0.2305)	loss 0.7676 (0.8732)	grad_norm 0.3018 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7186MB
[2024-08-01 19:21:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:18 lr 0.000002	 wd 0.0000	time 0.1835 (0.2304)	loss 0.8057 (0.8733)	grad_norm 0.3030 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7186MB
[2024-08-01 19:22:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:54 lr 0.000002	 wd 0.0000	time 0.1732 (0.2285)	loss 0.7544 (0.8730)	grad_norm 0.2915 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7186MB
[2024-08-01 19:22:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:31 lr 0.000002	 wd 0.0000	time 0.2018 (0.2267)	loss 1.0088 (0.8739)	grad_norm 0.3210 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7186MB
[2024-08-01 19:22:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:08 lr 0.000002	 wd 0.0000	time 0.1900 (0.2252)	loss 0.7378 (0.8734)	grad_norm 0.2987 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7186MB
[2024-08-01 19:23:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:45 lr 0.000002	 wd 0.0000	time 0.1838 (0.2255)	loss 0.8271 (0.8738)	grad_norm 0.3002 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7186MB
[2024-08-01 19:23:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:22 lr 0.000002	 wd 0.0000	time 0.2394 (0.2245)	loss 0.8857 (0.8734)	grad_norm 0.3102 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7186MB
[2024-08-01 19:23:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1490 (0.2223)	loss 0.8574 (0.8737)	grad_norm 0.2976 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7186MB
[2024-08-01 19:23:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 27 training takes 0:09:25
[2024-08-01 19:24:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 19.390 (19.390)	Loss 0.3499 (0.3499)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 19:24:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.276 Acc@5 97.680
[2024-08-01 19:24:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 19:24:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.29%
[2024-08-01 19:25:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][0/2502]	eta 1 day, 0:55:32 lr 0.000002	 wd 0.0000	time 35.8644 (35.8644)	loss 0.8442 (0.8442)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:25:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:22:14 lr 0.000002	 wd 0.0000	time 0.1714 (0.5554)	loss 0.8916 (0.8692)	grad_norm 0.3155 (0.3039)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:25:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:14:12 lr 0.000002	 wd 0.0000	time 0.1739 (0.3704)	loss 0.8369 (0.8754)	grad_norm 0.3022 (0.3038)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:26:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:11:36 lr 0.000002	 wd 0.0000	time 0.2760 (0.3165)	loss 0.9873 (0.8768)	grad_norm 0.3022 (0.3036)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:26:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:11:13 lr 0.000002	 wd 0.0000	time 0.1803 (0.3205)	loss 0.7852 (0.8719)	grad_norm 0.3056 (0.3037)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:26:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:09:48 lr 0.000002	 wd 0.0000	time 0.1724 (0.2942)	loss 0.8652 (0.8744)	grad_norm 0.3012 (0.3038)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:27:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:45 lr 0.000002	 wd 0.0000	time 0.1702 (0.2761)	loss 0.9136 (0.8756)	grad_norm 0.2985 (0.3035)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:27:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:56 lr 0.000002	 wd 0.0000	time 0.2326 (0.2645)	loss 0.8530 (0.8745)	grad_norm 0.2993 (0.3033)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:28:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:53 lr 0.000002	 wd 0.0000	time 0.1708 (0.2779)	loss 0.8433 (0.8753)	grad_norm 0.2987 (0.3034)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:28:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:07:09 lr 0.000002	 wd 0.0000	time 0.1813 (0.2678)	loss 0.8169 (0.8752)	grad_norm 0.3042 (0.3034)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:28:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:30 lr 0.000002	 wd 0.0000	time 0.1912 (0.2599)	loss 0.8403 (0.8750)	grad_norm 0.2887 (0.3033)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:29:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:55 lr 0.000002	 wd 0.0000	time 0.1842 (0.2536)	loss 0.8125 (0.8734)	grad_norm 0.3058 (0.3033)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:29:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:42 lr 0.000002	 wd 0.0000	time 0.1851 (0.2630)	loss 0.8545 (0.8734)	grad_norm 0.3126 (0.3034)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:30:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:05:09 lr 0.000002	 wd 0.0000	time 0.1770 (0.2571)	loss 0.9648 (0.8738)	grad_norm 0.3103 (0.3034)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:30:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:37 lr 0.000002	 wd 0.0000	time 0.1796 (0.2522)	loss 0.7939 (0.8731)	grad_norm 0.2988 (0.3033)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:30:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:04:08 lr 0.000002	 wd 0.0000	time 0.1763 (0.2479)	loss 0.7886 (0.8733)	grad_norm 0.3136 (0.3035)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:31:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:41 lr 0.000002	 wd 0.0000	time 0.2158 (0.2453)	loss 1.0117 (0.8736)	grad_norm 0.3120 (0.3033)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:31:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:15 lr 0.000001	 wd 0.0000	time 0.1614 (0.2441)	loss 0.9214 (0.8737)	grad_norm 0.3161 (0.3033)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:31:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:49 lr 0.000001	 wd 0.0000	time 0.2084 (0.2410)	loss 0.7651 (0.8733)	grad_norm 0.3152 (0.3034)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:32:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:23 lr 0.000001	 wd 0.0000	time 0.2136 (0.2384)	loss 0.8662 (0.8742)	grad_norm 0.2951 (0.3036)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:32:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:01:58 lr 0.000001	 wd 0.0000	time 0.1816 (0.2362)	loss 0.7954 (0.8734)	grad_norm 0.3005 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7186MB
[2024-08-01 19:32:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:34 lr 0.000001	 wd 0.0000	time 0.1487 (0.2358)	loss 0.8452 (0.8732)	grad_norm 0.3175 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7186MB
[2024-08-01 19:33:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:10 lr 0.000001	 wd 0.0000	time 0.1837 (0.2345)	loss 0.8945 (0.8727)	grad_norm 0.3083 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7186MB
[2024-08-01 19:33:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:46 lr 0.000001	 wd 0.0000	time 0.1752 (0.2327)	loss 0.8096 (0.8725)	grad_norm 0.2970 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7186MB
[2024-08-01 19:33:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:23 lr 0.000001	 wd 0.0000	time 0.1884 (0.2308)	loss 0.9683 (0.8721)	grad_norm 0.3045 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7186MB
[2024-08-01 19:34:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1522 (0.2284)	loss 0.8398 (0.8722)	grad_norm 0.2911 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7186MB
[2024-08-01 19:34:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 28 training takes 0:09:39
[2024-08-01 19:34:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 39.166 (39.166)	Loss 0.3499 (0.3499)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 19:35:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.278 Acc@5 97.678
[2024-08-01 19:35:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 19:35:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.29%
[2024-08-01 19:35:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][0/2502]	eta 11:02:21 lr 0.000001	 wd 0.0000	time 15.8837 (15.8837)	loss 0.9399 (0.9399)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:35:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:15:18 lr 0.000001	 wd 0.0000	time 0.2937 (0.3826)	loss 0.8457 (0.8817)	grad_norm 0.3125 (0.3044)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:36:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:12:38 lr 0.000001	 wd 0.0000	time 0.1704 (0.3295)	loss 0.8833 (0.8814)	grad_norm 0.3140 (0.3040)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:36:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:10:21 lr 0.000001	 wd 0.0000	time 0.1823 (0.2822)	loss 0.8359 (0.8814)	grad_norm 0.3053 (0.3034)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:36:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:09:02 lr 0.000001	 wd 0.0000	time 0.1609 (0.2580)	loss 0.8662 (0.8808)	grad_norm 0.2970 (0.3034)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:37:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:08:08 lr 0.000001	 wd 0.0000	time 0.2085 (0.2440)	loss 0.8267 (0.8802)	grad_norm 0.3097 (0.3039)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:37:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:17 lr 0.000001	 wd 0.0000	time 0.1916 (0.2614)	loss 0.7441 (0.8793)	grad_norm 0.3133 (0.3034)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:38:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:35 lr 0.000001	 wd 0.0000	time 0.1712 (0.2527)	loss 0.8384 (0.8783)	grad_norm 0.2912 (0.3035)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:38:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:06:55 lr 0.000001	 wd 0.0000	time 0.1804 (0.2442)	loss 0.8145 (0.8786)	grad_norm 0.2866 (0.3035)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:38:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:06:20 lr 0.000001	 wd 0.0000	time 0.1603 (0.2375)	loss 0.8740 (0.8788)	grad_norm 0.3123 (0.3036)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:39:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:13 lr 0.000001	 wd 0.0000	time 0.2461 (0.2487)	loss 0.8174 (0.8792)	grad_norm 0.3142 (0.3035)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:39:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:45 lr 0.000001	 wd 0.0000	time 0.1844 (0.2462)	loss 0.9863 (0.8788)	grad_norm 0.2939 (0.3035)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:40:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:14 lr 0.000001	 wd 0.0000	time 0.1951 (0.2413)	loss 0.7539 (0.8775)	grad_norm 0.3079 (0.3036)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:40:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:04:44 lr 0.000001	 wd 0.0000	time 0.1762 (0.2370)	loss 0.8916 (0.8775)	grad_norm 0.3112 (0.3037)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:40:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:19 lr 0.000001	 wd 0.0000	time 0.2316 (0.2354)	loss 0.9644 (0.8773)	grad_norm 0.3151 (0.3037)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:41:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:03:55 lr 0.000001	 wd 0.0000	time 0.1643 (0.2347)	loss 0.8105 (0.8759)	grad_norm 0.3086 (0.3037)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:41:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:29 lr 0.000001	 wd 0.0000	time 0.2311 (0.2321)	loss 0.9048 (0.8753)	grad_norm 0.3019 (0.3037)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:41:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:04 lr 0.000001	 wd 0.0000	time 0.1942 (0.2297)	loss 0.9150 (0.8742)	grad_norm 0.3115 (0.3036)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:41:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:39 lr 0.000001	 wd 0.0000	time 0.1616 (0.2274)	loss 0.7544 (0.8736)	grad_norm 0.2931 (0.3036)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:42:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:16 lr 0.000001	 wd 0.0000	time 0.1848 (0.2263)	loss 0.7163 (0.8737)	grad_norm 0.3084 (0.3037)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:42:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:01:53 lr 0.000001	 wd 0.0000	time 0.1783 (0.2266)	loss 0.8428 (0.8740)	grad_norm 0.3060 (0.3036)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:43:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:30 lr 0.000001	 wd 0.0000	time 0.2339 (0.2250)	loss 0.8037 (0.8741)	grad_norm 0.2909 (0.3036)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:43:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:07 lr 0.000001	 wd 0.0000	time 0.1813 (0.2234)	loss 0.7651 (0.8736)	grad_norm 0.3013 (0.3035)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:43:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:44 lr 0.000001	 wd 0.0000	time 0.2154 (0.2221)	loss 0.7153 (0.8739)	grad_norm 0.3158 (0.3036)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:44:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:22 lr 0.000001	 wd 0.0000	time 0.1529 (0.2220)	loss 0.7759 (0.8738)	grad_norm 0.3131 (0.3036)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:44:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1507 (0.2201)	loss 0.9565 (0.8736)	grad_norm 0.3107 (0.3036)	loss_scale 32768.0000 (32768.0000)	mem 7186MB
[2024-08-01 19:44:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 249): INFO EPOCH 29 training takes 0:09:20
[2024-08-01 19:44:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_29.pth saving......
[2024-08-01 19:44:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_29.pth saved !!!
[2024-08-01 19:44:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 289): INFO Test: [0/98]	Time 17.838 (17.838)	Loss 0.3503 (0.3503)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 7186MB
[2024-08-01 19:45:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 296): INFO  * Acc@1 85.274 Acc@5 97.682
[2024-08-01 19:45:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 19:45:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 182): INFO Max accuracy: 85.29%
[2024-08-01 19:45:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1] (main.py 189): INFO Training time 5:05:02
