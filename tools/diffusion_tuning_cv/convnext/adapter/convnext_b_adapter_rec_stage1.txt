[2024-07-29 21:55:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 366): INFO Full config saved to pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/config.json
[2024-07-29 21:55:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_convnext_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 27
    - 3
    DIMS:
    - 128
    - 256
    - 512
    - 1024
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: stage1
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_conv_b_sequence_stage1
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 0.0001
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 0.8
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.0e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 1.0e-08

[2024-07-29 21:55:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/diffusion_finetune/convnext/adapter_convnext/diffusion_ft_adapter_convnext_base_224_22kto1k_step_stage_process1.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/diffusion-ft", "tag": "diffusion_ft_adapter_conv_b_sequence_stage1", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-29 21:55:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 108): INFO Creating model:adapter_convnext_diffusion_finetune/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1
[2024-07-29 21:55:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 110): INFO Adapter_ConvNeXt_Diffusion_Finetune(
  (uma): UMA(filter_strategy1=18, filter_strategy2=6,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): Identity()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (12): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (13): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (14): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (15): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (16): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (17): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (18): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (19): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (20): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (21): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (22): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (23): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (24): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (25): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (26): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (memory_downsampling): ModuleList()
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-29 21:55:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 113): INFO number of params: 1126312
[2024-07-29 21:55:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 150): INFO no checkpoint found in pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1, ignoring auto resume
[2024-07-29 21:55:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth for fine-tuning......
[2024-07-29 21:55:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 127): WARNING <All keys matched successfully>
[2024-07-29 21:55:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth'
[2024-07-29 21:56:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 65.417 (65.417)	Loss 0.3606 (0.3606)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 3055MB
[2024-07-29 21:57:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.818 Acc@5 97.460
[2024-07-29 21:57:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 162): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 21:57:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 168): INFO Start training
[2024-07-29 21:57:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][0/2502]	eta 17:25:32 lr 0.000100	 wd 0.0000	time 25.0730 (25.0730)	loss 0.8906 (0.8906)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 6174MB
[2024-07-29 21:58:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:16:51 lr 0.000100	 wd 0.0000	time 0.1555 (0.4212)	loss 0.8496 (0.8946)	grad_norm 0.2779 (nan)	loss_scale 32768.0000 (33092.4356)	mem 6174MB
[2024-07-29 21:58:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:11:54 lr 0.000100	 wd 0.0000	time 0.3754 (0.3106)	loss 0.8730 (0.9001)	grad_norm 0.2634 (nan)	loss_scale 32768.0000 (32931.0249)	mem 6174MB
[2024-07-29 21:59:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:45 lr 0.000100	 wd 0.0000	time 0.1911 (0.3477)	loss 0.9233 (0.9031)	grad_norm 0.2691 (nan)	loss_scale 32768.0000 (32876.8638)	mem 6174MB
[2024-07-29 21:59:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:37 lr 0.000100	 wd 0.0000	time 0.1730 (0.3032)	loss 1.2441 (0.9030)	grad_norm 0.2666 (nan)	loss_scale 32768.0000 (32849.7157)	mem 6174MB
[2024-07-29 21:59:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:09:12 lr 0.000100	 wd 0.0000	time 0.1466 (0.2759)	loss 0.8296 (0.9031)	grad_norm 0.2533 (nan)	loss_scale 32768.0000 (32833.4052)	mem 6174MB
[2024-07-29 22:00:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:08:14 lr 0.000100	 wd 0.0000	time 0.2034 (0.2600)	loss 0.9946 (0.9030)	grad_norm 0.2599 (nan)	loss_scale 32768.0000 (32822.5225)	mem 6174MB
[2024-07-29 22:00:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:37 lr 0.000100	 wd 0.0000	time 0.1739 (0.2871)	loss 0.8501 (0.9001)	grad_norm 0.2482 (nan)	loss_scale 32768.0000 (32814.7447)	mem 6174MB
[2024-07-29 22:01:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:43 lr 0.000100	 wd 0.0000	time 0.1727 (0.2724)	loss 0.9199 (0.9013)	grad_norm 0.2447 (nan)	loss_scale 32768.0000 (32808.9089)	mem 6174MB
[2024-07-29 22:01:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:06:57 lr 0.000100	 wd 0.0000	time 0.2078 (0.2609)	loss 1.0771 (0.9000)	grad_norm 0.2561 (nan)	loss_scale 32768.0000 (32804.3685)	mem 6174MB
[2024-07-29 22:01:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:06:19 lr 0.000100	 wd 0.0000	time 0.2021 (0.2524)	loss 0.8838 (0.9000)	grad_norm 0.2604 (nan)	loss_scale 32768.0000 (32800.7353)	mem 6174MB
[2024-07-29 22:02:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:01 lr 0.000100	 wd 0.0000	time 0.2059 (0.2577)	loss 0.8330 (0.8997)	grad_norm 0.2677 (nan)	loss_scale 32768.0000 (32797.7620)	mem 6174MB
[2024-07-29 22:02:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:25 lr 0.000100	 wd 0.0000	time 0.1786 (0.2501)	loss 0.7812 (0.8997)	grad_norm 0.2545 (nan)	loss_scale 32768.0000 (32795.2839)	mem 6174MB
[2024-07-29 22:02:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:04:52 lr 0.000100	 wd 0.0000	time 0.1705 (0.2434)	loss 0.8672 (0.9010)	grad_norm 0.2631 (nan)	loss_scale 32768.0000 (32793.1868)	mem 6174MB
[2024-07-29 22:02:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:22 lr 0.000100	 wd 0.0000	time 0.1790 (0.2382)	loss 0.8940 (0.9013)	grad_norm 0.2693 (nan)	loss_scale 32768.0000 (32791.3890)	mem 6174MB
[2024-07-29 22:03:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:03:55 lr 0.000100	 wd 0.0000	time 0.2076 (0.2352)	loss 0.9692 (0.9019)	grad_norm 0.2648 (nan)	loss_scale 32768.0000 (32789.8308)	mem 6174MB
[2024-07-29 22:03:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:36 lr 0.000100	 wd 0.0000	time 0.1399 (0.2402)	loss 1.0879 (0.9026)	grad_norm 0.2620 (nan)	loss_scale 32768.0000 (32788.4672)	mem 6174MB
[2024-07-29 22:04:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:09 lr 0.000100	 wd 0.0000	time 0.1729 (0.2357)	loss 0.8853 (0.9028)	grad_norm 0.2585 (nan)	loss_scale 32768.0000 (32787.2640)	mem 6174MB
[2024-07-29 22:04:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:02:42 lr 0.000100	 wd 0.0000	time 0.1791 (0.2321)	loss 0.8662 (0.9027)	grad_norm 0.2771 (nan)	loss_scale 32768.0000 (32786.1943)	mem 6174MB
[2024-07-29 22:04:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:17 lr 0.000100	 wd 0.0000	time 0.1601 (0.2287)	loss 1.0078 (0.9029)	grad_norm 0.2554 (nan)	loss_scale 32768.0000 (32785.2372)	mem 6174MB
[2024-07-29 22:05:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:01:54 lr 0.000100	 wd 0.0000	time 0.1969 (0.2275)	loss 0.9365 (0.9031)	grad_norm 0.2715 (nan)	loss_scale 32768.0000 (32784.3758)	mem 6174MB
[2024-07-29 22:05:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:31 lr 0.000100	 wd 0.0000	time 0.2312 (0.2271)	loss 0.9062 (0.9035)	grad_norm 0.2578 (nan)	loss_scale 32768.0000 (32783.5964)	mem 6174MB
[2024-07-29 22:05:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:07 lr 0.000100	 wd 0.0000	time 0.1700 (0.2248)	loss 1.0264 (0.9032)	grad_norm 0.2643 (nan)	loss_scale 32768.0000 (32782.8878)	mem 6174MB
[2024-07-29 22:05:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:44 lr 0.000100	 wd 0.0000	time 0.1807 (0.2226)	loss 1.0186 (0.9031)	grad_norm 0.2692 (nan)	loss_scale 32768.0000 (32782.2408)	mem 6174MB
[2024-07-29 22:06:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:22 lr 0.000100	 wd 0.0000	time 0.1648 (0.2203)	loss 1.0840 (0.9033)	grad_norm 0.2577 (nan)	loss_scale 32768.0000 (32781.6476)	mem 6174MB
[2024-07-29 22:06:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000100	 wd 0.0000	time 0.1287 (0.2180)	loss 0.8848 (0.9032)	grad_norm 0.2479 (nan)	loss_scale 32768.0000 (32781.1020)	mem 6174MB
[2024-07-29 22:06:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 0 training takes 0:09:09
[2024-07-29 22:06:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_0.pth saving......
[2024-07-29 22:06:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_0.pth saved !!!
[2024-07-29 22:07:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 58.570 (58.570)	Loss 0.3687 (0.3687)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 6174MB
[2024-07-29 22:07:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.768 Acc@5 97.460
[2024-07-29 22:07:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 22:07:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.77%
[2024-07-29 22:07:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-29 22:07:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-29 22:08:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][0/2502]	eta 20:44:24 lr 0.000100	 wd 0.0000	time 29.8419 (29.8419)	loss 0.7793 (0.7793)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:08:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:21:05 lr 0.000100	 wd 0.0000	time 0.1545 (0.5268)	loss 0.8364 (0.8888)	grad_norm 0.2597 (0.2583)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:08:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:13:15 lr 0.000100	 wd 0.0000	time 0.1644 (0.3457)	loss 0.7900 (0.8954)	grad_norm 0.2535 (0.2583)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:09:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:10:36 lr 0.000100	 wd 0.0000	time 0.1445 (0.2891)	loss 0.9468 (0.8969)	grad_norm 0.2582 (0.2583)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:09:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:09:01 lr 0.000100	 wd 0.0000	time 0.1473 (0.2576)	loss 0.8989 (0.8981)	grad_norm 0.2606 (0.2588)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:10:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:09:19 lr 0.000100	 wd 0.0000	time 0.3014 (0.2795)	loss 0.8291 (0.8968)	grad_norm 0.2639 (0.2593)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:10:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:08:29 lr 0.000100	 wd 0.0000	time 0.1511 (0.2680)	loss 0.9233 (0.8985)	grad_norm 0.2710 (0.2592)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:10:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:07:37 lr 0.000100	 wd 0.0000	time 0.1728 (0.2540)	loss 0.8452 (0.8977)	grad_norm 0.2595 (0.2593)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:11:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:06:53 lr 0.000100	 wd 0.0000	time 0.1358 (0.2430)	loss 1.0469 (0.8993)	grad_norm 0.2535 (0.2591)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:11:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:06:18 lr 0.000099	 wd 0.0000	time 0.2705 (0.2363)	loss 0.8701 (0.8990)	grad_norm 0.2603 (0.2591)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:11:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:05:54 lr 0.000099	 wd 0.0000	time 0.1573 (0.2360)	loss 0.9043 (0.8991)	grad_norm 0.2584 (0.2592)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:12:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:05:22 lr 0.000099	 wd 0.0000	time 0.1684 (0.2301)	loss 0.9858 (0.9002)	grad_norm 0.2671 (0.2593)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:12:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:04:53 lr 0.000099	 wd 0.0000	time 0.1763 (0.2252)	loss 0.8633 (0.9002)	grad_norm 0.2614 (0.2595)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:12:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:04:25 lr 0.000099	 wd 0.0000	time 0.1784 (0.2209)	loss 0.8745 (0.9009)	grad_norm 0.2633 (0.2595)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:12:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:00 lr 0.000099	 wd 0.0000	time 0.2816 (0.2183)	loss 0.9033 (0.9012)	grad_norm 0.2568 (0.2595)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:13:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:03:47 lr 0.000099	 wd 0.0000	time 0.2035 (0.2267)	loss 0.8950 (0.9021)	grad_norm 0.2607 (0.2595)	loss_scale 65536.0000 (32811.6616)	mem 6174MB
[2024-07-29 22:13:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:21 lr 0.000099	 wd 0.0000	time 0.1608 (0.2230)	loss 0.8345 (0.9020)	grad_norm 0.2430 (nan)	loss_scale 32768.0000 (32808.9344)	mem 6174MB
[2024-07-29 22:14:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:02:56 lr 0.000099	 wd 0.0000	time 0.1677 (0.2199)	loss 0.7861 (0.9021)	grad_norm 0.2630 (nan)	loss_scale 32768.0000 (32806.5279)	mem 6174MB
[2024-07-29 22:14:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:32 lr 0.000099	 wd 0.0000	time 0.1820 (0.2172)	loss 1.0215 (0.9021)	grad_norm 0.2525 (nan)	loss_scale 32768.0000 (32804.3887)	mem 6174MB
[2024-07-29 22:14:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:10 lr 0.000099	 wd 0.0000	time 0.2202 (0.2164)	loss 0.9268 (0.9025)	grad_norm 0.2480 (nan)	loss_scale 32768.0000 (32802.4745)	mem 6174MB
[2024-07-29 22:15:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:01:48 lr 0.000099	 wd 0.0000	time 0.1929 (0.2158)	loss 0.7959 (0.9025)	grad_norm 0.2678 (nan)	loss_scale 32768.0000 (32800.7516)	mem 6174MB
[2024-07-29 22:15:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:26 lr 0.000099	 wd 0.0000	time 0.1814 (0.2140)	loss 0.8545 (0.9024)	grad_norm 0.2705 (nan)	loss_scale 32768.0000 (32799.1928)	mem 6174MB
[2024-07-29 22:15:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:04 lr 0.000099	 wd 0.0000	time 0.1706 (0.2123)	loss 0.7837 (0.9019)	grad_norm 0.2446 (nan)	loss_scale 32768.0000 (32797.7756)	mem 6174MB
[2024-07-29 22:15:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:42 lr 0.000099	 wd 0.0000	time 0.2044 (0.2105)	loss 0.9565 (0.9027)	grad_norm 0.2607 (nan)	loss_scale 32768.0000 (32796.4815)	mem 6174MB
[2024-07-29 22:16:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:21 lr 0.000099	 wd 0.0000	time 0.1563 (0.2095)	loss 0.9282 (0.9027)	grad_norm 0.2680 (nan)	loss_scale 32768.0000 (32795.2953)	mem 6174MB
[2024-07-29 22:16:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000099	 wd 0.0000	time 0.1286 (0.2079)	loss 0.9307 (0.9031)	grad_norm 0.2649 (nan)	loss_scale 32768.0000 (32794.2039)	mem 6174MB
[2024-07-29 22:16:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 1 training takes 0:08:49
[2024-07-29 22:17:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 31.447 (31.447)	Loss 0.3662 (0.3662)	Acc@1 91.211 (91.211)	Acc@5 98.633 (98.633)	Mem 6174MB
[2024-07-29 22:17:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.748 Acc@5 97.456
[2024-07-29 22:17:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-29 22:17:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.77%
[2024-07-29 22:17:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][0/2502]	eta 12:00:10 lr 0.000099	 wd 0.0000	time 17.2702 (17.2702)	loss 0.8066 (0.8066)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:18:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:20:38 lr 0.000099	 wd 0.0000	time 0.2487 (0.5154)	loss 1.0010 (0.9019)	grad_norm 0.2578 (0.2572)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:18:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:14:17 lr 0.000099	 wd 0.0000	time 0.1425 (0.3724)	loss 0.9805 (0.9002)	grad_norm 0.2594 (0.2576)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:18:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:11:08 lr 0.000099	 wd 0.0000	time 0.1813 (0.3035)	loss 0.8398 (0.8958)	grad_norm 0.2661 (0.2575)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:19:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:09:23 lr 0.000099	 wd 0.0000	time 0.1580 (0.2681)	loss 0.9731 (0.8971)	grad_norm 0.2477 (0.2577)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:19:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:08:47 lr 0.000099	 wd 0.0000	time 0.4620 (0.2636)	loss 0.9380 (0.9034)	grad_norm 0.2667 (0.2579)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:20:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:09:01 lr 0.000099	 wd 0.0000	time 0.1635 (0.2845)	loss 0.8188 (0.9032)	grad_norm 0.2584 (0.2578)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:20:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:08:02 lr 0.000099	 wd 0.0000	time 0.1641 (0.2678)	loss 0.8765 (0.9028)	grad_norm 0.2630 (0.2578)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:20:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:13 lr 0.000099	 wd 0.0000	time 0.1573 (0.2548)	loss 0.8145 (0.9013)	grad_norm 0.2543 (0.2577)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:21:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:44 lr 0.000098	 wd 0.0000	time 0.3843 (0.2526)	loss 0.9434 (0.9012)	grad_norm 0.2764 (0.2577)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:21:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:38 lr 0.000098	 wd 0.0000	time 0.1591 (0.2652)	loss 0.8262 (0.9003)	grad_norm 0.2576 (0.2576)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:22:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:59 lr 0.000098	 wd 0.0000	time 0.1583 (0.2564)	loss 0.9321 (0.9004)	grad_norm 0.2592 (0.2577)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:22:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:23 lr 0.000098	 wd 0.0000	time 0.1609 (0.2485)	loss 1.0596 (0.9007)	grad_norm 0.2633 (0.2577)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:22:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:04:52 lr 0.000098	 wd 0.0000	time 0.1659 (0.2432)	loss 0.9180 (0.9016)	grad_norm 0.2649 (0.2577)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:23:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:25 lr 0.000098	 wd 0.0000	time 0.1640 (0.2410)	loss 0.9575 (0.9018)	grad_norm 0.2510 (0.2577)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:23:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:03:57 lr 0.000098	 wd 0.0000	time 0.1539 (0.2371)	loss 1.0859 (0.9023)	grad_norm 0.2509 (0.2578)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:23:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:30 lr 0.000098	 wd 0.0000	time 0.1659 (0.2329)	loss 0.9561 (0.9020)	grad_norm 0.2563 (0.2579)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:23:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:03 lr 0.000098	 wd 0.0000	time 0.1534 (0.2291)	loss 0.9146 (0.9027)	grad_norm 0.2583 (0.2579)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:24:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:38 lr 0.000098	 wd 0.0000	time 0.1871 (0.2262)	loss 0.8809 (0.9026)	grad_norm 0.2477 (0.2580)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:24:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:16 lr 0.000098	 wd 0.0000	time 0.1368 (0.2270)	loss 0.8115 (0.9031)	grad_norm 0.2586 (0.2582)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:24:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:01:52 lr 0.000098	 wd 0.0000	time 0.1477 (0.2251)	loss 0.9106 (0.9031)	grad_norm 0.2514 (0.2581)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:25:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:29 lr 0.000098	 wd 0.0000	time 0.2001 (0.2227)	loss 0.9858 (0.9037)	grad_norm 0.2643 (0.2582)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:25:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:06 lr 0.000098	 wd 0.0000	time 0.1557 (0.2205)	loss 0.8940 (0.9035)	grad_norm 0.2565 (0.2581)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:25:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:44 lr 0.000098	 wd 0.0000	time 0.2011 (0.2188)	loss 0.8403 (0.9034)	grad_norm 0.2644 (0.2582)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:26:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:22 lr 0.000098	 wd 0.0000	time 0.1367 (0.2197)	loss 0.8794 (0.9039)	grad_norm 0.2570 (0.2582)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:26:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000098	 wd 0.0000	time 0.1292 (0.2172)	loss 0.9077 (0.9035)	grad_norm 0.2638 (0.2583)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:26:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 2 training takes 0:09:08
[2024-07-29 22:26:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 27.250 (27.250)	Loss 0.3650 (0.3650)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 6174MB
[2024-07-29 22:27:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.806 Acc@5 97.472
[2024-07-29 22:27:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 22:27:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.81%
[2024-07-29 22:27:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-29 22:27:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-29 22:27:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][0/2502]	eta 1 day, 0:57:04 lr 0.000098	 wd 0.0000	time 35.9012 (35.9012)	loss 0.7500 (0.7500)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:28:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:21:39 lr 0.000098	 wd 0.0000	time 0.1710 (0.5410)	loss 1.0088 (0.9013)	grad_norm 0.2638 (0.2595)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:28:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:13:33 lr 0.000097	 wd 0.0000	time 0.1696 (0.3533)	loss 1.0352 (0.8972)	grad_norm 0.2695 (0.2591)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:28:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:10:41 lr 0.000097	 wd 0.0000	time 0.1510 (0.2913)	loss 1.0518 (0.8985)	grad_norm 0.2570 (0.2590)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:28:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:09:08 lr 0.000097	 wd 0.0000	time 0.2093 (0.2610)	loss 1.0225 (0.8979)	grad_norm 0.2494 (0.2584)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:29:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:10:15 lr 0.000097	 wd 0.0000	time 0.1798 (0.3072)	loss 0.9307 (0.8994)	grad_norm nan (nan)	loss_scale 32768.0000 (32898.8104)	mem 6174MB
[2024-07-29 22:30:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:09:00 lr 0.000097	 wd 0.0000	time 0.1427 (0.2844)	loss 0.8496 (0.8999)	grad_norm 0.2744 (nan)	loss_scale 32768.0000 (32877.0449)	mem 6174MB
[2024-07-29 22:30:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:08:02 lr 0.000097	 wd 0.0000	time 0.1523 (0.2675)	loss 0.9434 (0.9009)	grad_norm 0.2610 (nan)	loss_scale 32768.0000 (32861.4893)	mem 6174MB
[2024-07-29 22:30:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:16 lr 0.000097	 wd 0.0000	time 0.2494 (0.2563)	loss 0.8794 (0.8995)	grad_norm 0.2655 (nan)	loss_scale 32768.0000 (32849.8177)	mem 6174MB
[2024-07-29 22:31:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:07:16 lr 0.000097	 wd 0.0000	time 0.1923 (0.2727)	loss 0.9258 (0.9001)	grad_norm 0.2619 (nan)	loss_scale 32768.0000 (32840.7370)	mem 6174MB
[2024-07-29 22:31:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:34 lr 0.000097	 wd 0.0000	time 0.1890 (0.2623)	loss 1.0752 (0.9018)	grad_norm 0.2628 (nan)	loss_scale 32768.0000 (32833.4705)	mem 6174MB
[2024-07-29 22:31:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:05:55 lr 0.000097	 wd 0.0000	time 0.1799 (0.2535)	loss 0.7993 (0.9013)	grad_norm 0.2718 (nan)	loss_scale 32768.0000 (32827.5241)	mem 6174MB
[2024-07-29 22:32:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:20 lr 0.000097	 wd 0.0000	time 0.1675 (0.2460)	loss 0.9482 (0.9006)	grad_norm 0.2544 (nan)	loss_scale 32768.0000 (32822.5679)	mem 6174MB
[2024-07-29 22:32:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:04:51 lr 0.000097	 wd 0.0000	time 0.1655 (0.2424)	loss 0.9927 (0.9017)	grad_norm 0.2460 (nan)	loss_scale 32768.0000 (32818.3736)	mem 6174MB
[2024-07-29 22:32:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:24 lr 0.000097	 wd 0.0000	time 0.1491 (0.2403)	loss 0.8677 (0.9015)	grad_norm 0.2504 (nan)	loss_scale 32768.0000 (32814.7780)	mem 6174MB
[2024-07-29 22:33:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:03:55 lr 0.000097	 wd 0.0000	time 0.1715 (0.2354)	loss 0.8237 (0.9025)	grad_norm 0.2521 (nan)	loss_scale 32768.0000 (32811.6616)	mem 6174MB
[2024-07-29 22:33:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:28 lr 0.000096	 wd 0.0000	time 0.1818 (0.2314)	loss 0.8804 (0.9017)	grad_norm 0.2676 (nan)	loss_scale 32768.0000 (32808.9344)	mem 6174MB
[2024-07-29 22:33:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:02 lr 0.000096	 wd 0.0000	time 0.1704 (0.2277)	loss 0.9282 (0.9016)	grad_norm 0.2593 (nan)	loss_scale 32768.0000 (32806.5279)	mem 6174MB
[2024-07-29 22:33:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:38 lr 0.000096	 wd 0.0000	time 0.2239 (0.2257)	loss 0.9038 (0.9016)	grad_norm 0.2475 (nan)	loss_scale 32768.0000 (32804.3887)	mem 6174MB
[2024-07-29 22:34:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:15 lr 0.000096	 wd 0.0000	time 0.2119 (0.2251)	loss 0.9131 (0.9012)	grad_norm 0.2542 (nan)	loss_scale 32768.0000 (32802.4745)	mem 6174MB
[2024-07-29 22:34:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:01:51 lr 0.000096	 wd 0.0000	time 0.1793 (0.2230)	loss 0.8789 (0.9016)	grad_norm 0.2489 (nan)	loss_scale 32768.0000 (32800.7516)	mem 6174MB
[2024-07-29 22:34:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:28 lr 0.000096	 wd 0.0000	time 0.1608 (0.2208)	loss 0.7383 (0.9013)	grad_norm 0.2587 (nan)	loss_scale 32768.0000 (32799.1928)	mem 6174MB
[2024-07-29 22:35:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:06 lr 0.000096	 wd 0.0000	time 0.1708 (0.2186)	loss 0.8540 (0.9009)	grad_norm 0.2595 (nan)	loss_scale 32768.0000 (32797.7756)	mem 6174MB
[2024-07-29 22:35:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:43 lr 0.000096	 wd 0.0000	time 0.2128 (0.2174)	loss 0.9834 (0.9011)	grad_norm 0.2594 (nan)	loss_scale 32768.0000 (32796.4815)	mem 6174MB
[2024-07-29 22:35:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:22 lr 0.000096	 wd 0.0000	time 0.1608 (0.2175)	loss 0.8345 (0.9012)	grad_norm 0.2519 (nan)	loss_scale 32768.0000 (32795.2953)	mem 6174MB
[2024-07-29 22:36:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000096	 wd 0.0000	time 0.1304 (0.2149)	loss 0.8315 (0.9017)	grad_norm 0.2696 (nan)	loss_scale 32768.0000 (32794.2039)	mem 6174MB
[2024-07-29 22:36:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 3 training takes 0:09:02
[2024-07-29 22:36:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 22.634 (22.634)	Loss 0.3662 (0.3662)	Acc@1 90.820 (90.820)	Acc@5 98.633 (98.633)	Mem 6174MB
[2024-07-29 22:36:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.790 Acc@5 97.470
[2024-07-29 22:36:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 22:36:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.81%
[2024-07-29 22:37:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][0/2502]	eta 17:26:01 lr 0.000096	 wd 0.0000	time 25.0845 (25.0845)	loss 0.9170 (0.9170)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:37:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:18:45 lr 0.000096	 wd 0.0000	time 0.1684 (0.4687)	loss 0.8086 (0.9057)	grad_norm 0.2570 (0.2592)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:37:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:12:15 lr 0.000096	 wd 0.0000	time 0.1887 (0.3193)	loss 0.9214 (0.9031)	grad_norm 0.2439 (0.2590)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:38:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:09:51 lr 0.000095	 wd 0.0000	time 0.1430 (0.2685)	loss 0.9009 (0.9032)	grad_norm 0.2656 (0.2591)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:38:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:08:30 lr 0.000095	 wd 0.0000	time 0.1549 (0.2431)	loss 0.8750 (0.8982)	grad_norm 0.2505 (0.2590)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:38:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:07:43 lr 0.000095	 wd 0.0000	time 0.1862 (0.2317)	loss 0.9575 (0.8998)	grad_norm 0.2525 (0.2588)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:39:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:07:56 lr 0.000095	 wd 0.0000	time 0.1942 (0.2507)	loss 0.8618 (0.9024)	grad_norm 0.2610 (0.2588)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:39:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:07:10 lr 0.000095	 wd 0.0000	time 0.1657 (0.2387)	loss 1.0098 (0.8994)	grad_norm 0.2549 (0.2585)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:39:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:06:30 lr 0.000095	 wd 0.0000	time 0.1569 (0.2296)	loss 0.8735 (0.8998)	grad_norm 0.2681 (0.2583)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:40:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:05:56 lr 0.000095	 wd 0.0000	time 0.1795 (0.2225)	loss 0.8696 (0.9010)	grad_norm 0.2657 (0.2583)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:40:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:05:55 lr 0.000095	 wd 0.0000	time 0.3425 (0.2368)	loss 0.9150 (0.9011)	grad_norm 0.2605 (0.2583)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:41:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:05:33 lr 0.000095	 wd 0.0000	time 0.1594 (0.2381)	loss 0.9639 (0.9027)	grad_norm 0.2656 (0.2584)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:41:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:02 lr 0.000095	 wd 0.0000	time 0.1616 (0.2321)	loss 0.7583 (0.9025)	grad_norm 0.2517 (0.2582)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:41:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:04:32 lr 0.000095	 wd 0.0000	time 0.1761 (0.2268)	loss 0.8467 (0.9017)	grad_norm 0.2586 (0.2582)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:42:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:07 lr 0.000094	 wd 0.0000	time 0.2392 (0.2250)	loss 0.9233 (0.9012)	grad_norm 0.2633 (0.2583)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:42:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:03:44 lr 0.000094	 wd 0.0000	time 0.1803 (0.2243)	loss 0.7788 (0.9014)	grad_norm 0.2593 (0.2584)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:42:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:19 lr 0.000094	 wd 0.0000	time 0.1448 (0.2213)	loss 0.8511 (0.9014)	grad_norm 0.2584 (0.2583)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:43:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:02:55 lr 0.000094	 wd 0.0000	time 0.1781 (0.2184)	loss 1.0791 (0.9011)	grad_norm 0.2594 (0.2583)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:43:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:31 lr 0.000094	 wd 0.0000	time 0.1857 (0.2158)	loss 0.9556 (0.9016)	grad_norm 0.2499 (0.2583)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:43:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:09 lr 0.000094	 wd 0.0000	time 0.2416 (0.2151)	loss 0.9155 (0.9015)	grad_norm 0.2558 (0.2582)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:44:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:01:48 lr 0.000094	 wd 0.0000	time 0.1646 (0.2157)	loss 0.7803 (0.9011)	grad_norm nan (nan)	loss_scale 32768.0000 (32800.7516)	mem 6174MB
[2024-07-29 22:44:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:26 lr 0.000094	 wd 0.0000	time 0.1738 (0.2141)	loss 0.8340 (0.9019)	grad_norm 0.2717 (nan)	loss_scale 32768.0000 (32799.1928)	mem 6174MB
[2024-07-29 22:44:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:04 lr 0.000094	 wd 0.0000	time 0.1558 (0.2122)	loss 1.0049 (0.9014)	grad_norm 0.2417 (nan)	loss_scale 32768.0000 (32797.7756)	mem 6174MB
[2024-07-29 22:44:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:42 lr 0.000094	 wd 0.0000	time 0.1589 (0.2104)	loss 0.8779 (0.9017)	grad_norm 0.2582 (nan)	loss_scale 32768.0000 (32796.4815)	mem 6174MB
[2024-07-29 22:45:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:21 lr 0.000093	 wd 0.0000	time 0.1859 (0.2098)	loss 0.8408 (0.9020)	grad_norm 0.2408 (nan)	loss_scale 32768.0000 (32795.2953)	mem 6174MB
[2024-07-29 22:45:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000093	 wd 0.0000	time 0.1285 (0.2079)	loss 0.7710 (0.9020)	grad_norm 0.2658 (nan)	loss_scale 32768.0000 (32794.2039)	mem 6174MB
[2024-07-29 22:45:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 4 training takes 0:08:49
[2024-07-29 22:46:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 22.464 (22.464)	Loss 0.3618 (0.3618)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 6174MB
[2024-07-29 22:46:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.788 Acc@5 97.466
[2024-07-29 22:46:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 22:46:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.81%
[2024-07-29 22:46:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][0/2502]	eta 11:18:31 lr 0.000093	 wd 0.0000	time 16.2715 (16.2715)	loss 0.8892 (0.8892)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:46:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:15:01 lr 0.000093	 wd 0.0000	time 0.2730 (0.3753)	loss 0.9224 (0.8929)	grad_norm 0.2667 (0.2577)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:47:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:12:42 lr 0.000093	 wd 0.0000	time 0.1493 (0.3311)	loss 0.8071 (0.8965)	grad_norm 0.2637 (0.2588)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:47:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:07 lr 0.000093	 wd 0.0000	time 0.1715 (0.2760)	loss 1.0146 (0.8953)	grad_norm 0.2559 (0.2582)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:47:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:08:42 lr 0.000093	 wd 0.0000	time 0.1927 (0.2485)	loss 0.9531 (0.8947)	grad_norm 0.2639 (0.2586)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:48:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:07:42 lr 0.000093	 wd 0.0000	time 0.1636 (0.2312)	loss 0.8594 (0.8945)	grad_norm 0.2790 (0.2583)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:48:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:07:14 lr 0.000093	 wd 0.0000	time 0.3382 (0.2285)	loss 0.8564 (0.8974)	grad_norm 0.2595 (0.2584)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:49:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:15 lr 0.000093	 wd 0.0000	time 0.1554 (0.2419)	loss 0.8135 (0.8968)	grad_norm 0.2708 (0.2585)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:49:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:06:36 lr 0.000093	 wd 0.0000	time 0.1621 (0.2327)	loss 0.8594 (0.8967)	grad_norm 0.2583 (0.2585)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:49:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:01 lr 0.000092	 wd 0.0000	time 0.1879 (0.2255)	loss 0.9341 (0.8973)	grad_norm 0.2626 (0.2587)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:49:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:05:29 lr 0.000092	 wd 0.0000	time 0.1489 (0.2194)	loss 0.9282 (0.8992)	grad_norm 0.2541 (0.2588)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:50:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:20 lr 0.000092	 wd 0.0000	time 0.1885 (0.2288)	loss 0.8413 (0.9003)	grad_norm 0.2561 (0.2588)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:50:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:04:53 lr 0.000092	 wd 0.0000	time 0.1548 (0.2256)	loss 0.9194 (0.9009)	grad_norm 0.2558 (0.2588)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:51:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:25 lr 0.000092	 wd 0.0000	time 0.1625 (0.2210)	loss 0.9805 (0.9001)	grad_norm 0.2679 (0.2586)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:51:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:03:59 lr 0.000092	 wd 0.0000	time 0.1408 (0.2169)	loss 0.8599 (0.8994)	grad_norm 0.2646 (0.2586)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:51:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:03:34 lr 0.000092	 wd 0.0000	time 0.1830 (0.2142)	loss 0.8706 (0.9001)	grad_norm 0.2584 (0.2586)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:51:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:14 lr 0.000092	 wd 0.0000	time 0.1493 (0.2156)	loss 0.8193 (0.9008)	grad_norm 0.2628 (0.2587)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:52:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:02:51 lr 0.000092	 wd 0.0000	time 0.1685 (0.2137)	loss 0.8926 (0.9012)	grad_norm 0.2492 (0.2587)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:52:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:28 lr 0.000091	 wd 0.0000	time 0.2130 (0.2114)	loss 0.9146 (0.9006)	grad_norm 0.2599 (0.2588)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:52:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:06 lr 0.000091	 wd 0.0000	time 0.1815 (0.2093)	loss 0.8843 (0.9004)	grad_norm 0.2542 (0.2588)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:53:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:01:44 lr 0.000091	 wd 0.0000	time 0.1594 (0.2078)	loss 0.9805 (0.9010)	grad_norm 0.2605 (0.2588)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:53:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:23 lr 0.000091	 wd 0.0000	time 0.1772 (0.2077)	loss 1.0205 (0.9005)	grad_norm 0.2606 (0.2588)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:53:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:02 lr 0.000091	 wd 0.0000	time 0.1561 (0.2078)	loss 1.0088 (0.9005)	grad_norm 0.2615 (0.2588)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:54:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:41 lr 0.000091	 wd 0.0000	time 0.1554 (0.2063)	loss 0.7686 (0.9003)	grad_norm 0.2701 (0.2588)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:54:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:20 lr 0.000091	 wd 0.0000	time 0.1720 (0.2049)	loss 0.7998 (0.8999)	grad_norm 0.2653 (0.2589)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:54:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000091	 wd 0.0000	time 0.1284 (0.2027)	loss 0.8037 (0.8995)	grad_norm 0.2553 (0.2589)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:54:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 5 training takes 0:08:31
[2024-07-29 22:55:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 43.722 (43.722)	Loss 0.3589 (0.3589)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 6174MB
[2024-07-29 22:55:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.802 Acc@5 97.478
[2024-07-29 22:55:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 22:55:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.81%
[2024-07-29 22:55:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][0/2502]	eta 11:28:41 lr 0.000091	 wd 0.0000	time 16.5154 (16.5154)	loss 0.9424 (0.9424)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:56:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:13:07 lr 0.000090	 wd 0.0000	time 0.1840 (0.3277)	loss 0.8730 (0.9094)	grad_norm 0.2707 (0.2592)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:56:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:12:34 lr 0.000090	 wd 0.0000	time 0.2780 (0.3276)	loss 0.8149 (0.9031)	grad_norm 0.2648 (0.2594)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:57:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:10:57 lr 0.000090	 wd 0.0000	time 0.1729 (0.2987)	loss 0.9199 (0.9037)	grad_norm 0.2632 (0.2596)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:57:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:09:18 lr 0.000090	 wd 0.0000	time 0.1561 (0.2656)	loss 0.8638 (0.9019)	grad_norm 0.2532 (0.2595)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:57:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:08:11 lr 0.000090	 wd 0.0000	time 0.1499 (0.2457)	loss 0.9287 (0.9015)	grad_norm 0.2472 (0.2592)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:58:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:07:27 lr 0.000090	 wd 0.0000	time 0.2200 (0.2352)	loss 0.8916 (0.9015)	grad_norm 0.2680 (0.2594)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:58:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:07:40 lr 0.000090	 wd 0.0000	time 0.2112 (0.2555)	loss 1.0010 (0.9015)	grad_norm 0.2641 (0.2595)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:58:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:06:55 lr 0.000090	 wd 0.0000	time 0.1729 (0.2443)	loss 0.7476 (0.9016)	grad_norm 0.2588 (0.2592)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:59:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:06:17 lr 0.000089	 wd 0.0000	time 0.1657 (0.2357)	loss 0.8936 (0.9009)	grad_norm 0.2532 (0.2592)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 22:59:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:05:43 lr 0.000089	 wd 0.0000	time 0.1771 (0.2285)	loss 0.8521 (0.9021)	grad_norm 0.2582 (nan)	loss_scale 32768.0000 (32833.4705)	mem 6174MB
[2024-07-29 23:00:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:33 lr 0.000089	 wd 0.0000	time 0.1884 (0.2376)	loss 0.8315 (0.9008)	grad_norm 0.2590 (nan)	loss_scale 32768.0000 (32827.5241)	mem 6174MB
[2024-07-29 23:00:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:04 lr 0.000089	 wd 0.0000	time 0.1739 (0.2339)	loss 0.8706 (0.9008)	grad_norm 0.2532 (nan)	loss_scale 32768.0000 (32822.5679)	mem 6174MB
[2024-07-29 23:00:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:04:35 lr 0.000089	 wd 0.0000	time 0.1657 (0.2289)	loss 0.8062 (0.9003)	grad_norm 0.2548 (nan)	loss_scale 32768.0000 (32818.3736)	mem 6174MB
[2024-07-29 23:00:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:07 lr 0.000089	 wd 0.0000	time 0.1627 (0.2242)	loss 0.9395 (0.8998)	grad_norm 0.2540 (nan)	loss_scale 32768.0000 (32814.7780)	mem 6174MB
[2024-07-29 23:01:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:03:41 lr 0.000089	 wd 0.0000	time 0.2096 (0.2206)	loss 0.7949 (0.8997)	grad_norm 0.2553 (nan)	loss_scale 32768.0000 (32811.6616)	mem 6174MB
[2024-07-29 23:01:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:19 lr 0.000089	 wd 0.0000	time 0.1841 (0.2216)	loss 0.8071 (0.8992)	grad_norm 0.2494 (nan)	loss_scale 32768.0000 (32808.9344)	mem 6174MB
[2024-07-29 23:01:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:02:55 lr 0.000088	 wd 0.0000	time 0.1885 (0.2192)	loss 0.8765 (0.8979)	grad_norm 0.2526 (nan)	loss_scale 32768.0000 (32806.5279)	mem 6174MB
[2024-07-29 23:02:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:32 lr 0.000088	 wd 0.0000	time 0.1708 (0.2166)	loss 0.8408 (0.8979)	grad_norm 0.2591 (nan)	loss_scale 32768.0000 (32804.3887)	mem 6174MB
[2024-07-29 23:02:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:09 lr 0.000088	 wd 0.0000	time 0.1830 (0.2144)	loss 0.9326 (0.8984)	grad_norm 0.2597 (nan)	loss_scale 32768.0000 (32802.4745)	mem 6174MB
[2024-07-29 23:02:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:01:46 lr 0.000088	 wd 0.0000	time 0.1946 (0.2125)	loss 0.9502 (0.8988)	grad_norm 0.2628 (nan)	loss_scale 32768.0000 (32800.7516)	mem 6174MB
[2024-07-29 23:03:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:25 lr 0.000088	 wd 0.0000	time 0.1727 (0.2118)	loss 0.8042 (0.8988)	grad_norm 0.2578 (nan)	loss_scale 32768.0000 (32799.1928)	mem 6174MB
[2024-07-29 23:03:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:04 lr 0.000088	 wd 0.0000	time 0.1522 (0.2121)	loss 0.9258 (0.8982)	grad_norm 0.2639 (nan)	loss_scale 32768.0000 (32797.7756)	mem 6174MB
[2024-07-29 23:03:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:42 lr 0.000088	 wd 0.0000	time 0.1553 (0.2103)	loss 0.8467 (0.8982)	grad_norm 0.2605 (nan)	loss_scale 32768.0000 (32796.4815)	mem 6174MB
[2024-07-29 23:04:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:21 lr 0.000087	 wd 0.0000	time 0.1521 (0.2088)	loss 0.8936 (0.8988)	grad_norm 0.2504 (nan)	loss_scale 32768.0000 (32795.2953)	mem 6174MB
[2024-07-29 23:04:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000087	 wd 0.0000	time 0.1288 (0.2063)	loss 0.8022 (0.8994)	grad_norm 0.2603 (nan)	loss_scale 32768.0000 (32794.2039)	mem 6174MB
[2024-07-29 23:04:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 6 training takes 0:08:40
[2024-07-29 23:05:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 41.985 (41.985)	Loss 0.3606 (0.3606)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 6174MB
[2024-07-29 23:05:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.820 Acc@5 97.472
[2024-07-29 23:05:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 23:05:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-29 23:05:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-29 23:05:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-29 23:05:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][0/2502]	eta 11:25:03 lr 0.000087	 wd 0.0000	time 16.4282 (16.4282)	loss 0.8804 (0.8804)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:05:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:13:03 lr 0.000087	 wd 0.0000	time 0.1717 (0.3261)	loss 0.9912 (0.8987)	grad_norm 0.2531 (0.2600)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:06:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:10:13 lr 0.000087	 wd 0.0000	time 0.3525 (0.2667)	loss 0.8843 (0.8967)	grad_norm 0.2506 (0.2606)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:06:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:10:21 lr 0.000087	 wd 0.0000	time 0.1830 (0.2822)	loss 0.8560 (0.8939)	grad_norm 0.2612 (0.2599)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:06:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:08:51 lr 0.000087	 wd 0.0000	time 0.1609 (0.2528)	loss 0.9048 (0.8984)	grad_norm 0.2733 (0.2597)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:07:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:07:50 lr 0.000087	 wd 0.0000	time 0.1627 (0.2351)	loss 0.7754 (0.8960)	grad_norm 0.2417 (0.2594)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:07:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:07:03 lr 0.000086	 wd 0.0000	time 0.1888 (0.2226)	loss 1.0273 (0.8982)	grad_norm 0.2448 (0.2591)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:08:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:07:15 lr 0.000086	 wd 0.0000	time 1.1901 (0.2417)	loss 0.8311 (0.8979)	grad_norm 0.2445 (0.2591)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:08:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:06:47 lr 0.000086	 wd 0.0000	time 0.1653 (0.2396)	loss 0.8311 (0.8970)	grad_norm 0.2541 (0.2591)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:08:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:06:11 lr 0.000086	 wd 0.0000	time 0.1698 (0.2318)	loss 0.8794 (0.8979)	grad_norm 0.2612 (0.2592)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:09:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:05:38 lr 0.000086	 wd 0.0000	time 0.1754 (0.2251)	loss 0.7896 (0.8977)	grad_norm 0.2655 (0.2591)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:09:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:10 lr 0.000086	 wd 0.0000	time 0.3077 (0.2218)	loss 0.7935 (0.8973)	grad_norm 0.2583 (0.2591)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:09:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:03 lr 0.000086	 wd 0.0000	time 0.1500 (0.2328)	loss 0.9316 (0.8967)	grad_norm 0.2644 (0.2590)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:10:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:04:33 lr 0.000085	 wd 0.0000	time 0.1647 (0.2277)	loss 0.9443 (0.8961)	grad_norm 0.2463 (0.2590)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:10:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:06 lr 0.000085	 wd 0.0000	time 0.1532 (0.2233)	loss 0.7954 (0.8965)	grad_norm 0.2637 (0.2591)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:10:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:03:39 lr 0.000085	 wd 0.0000	time 0.1932 (0.2195)	loss 0.8560 (0.8961)	grad_norm 0.2632 (0.2590)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:11:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:17 lr 0.000085	 wd 0.0000	time 0.1972 (0.2186)	loss 0.9033 (0.8958)	grad_norm 0.2577 (0.2590)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:11:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:02:55 lr 0.000085	 wd 0.0000	time 0.3152 (0.2185)	loss 1.0244 (0.8955)	grad_norm 0.2546 (0.2590)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:11:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:31 lr 0.000085	 wd 0.0000	time 0.1499 (0.2160)	loss 0.8394 (0.8956)	grad_norm 0.2531 (0.2590)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:12:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:08 lr 0.000085	 wd 0.0000	time 0.1505 (0.2137)	loss 0.9185 (0.8955)	grad_norm 0.2593 (0.2591)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:12:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:01:46 lr 0.000084	 wd 0.0000	time 0.1622 (0.2116)	loss 0.8574 (0.8950)	grad_norm 0.2655 (0.2591)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:12:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:24 lr 0.000084	 wd 0.0000	time 0.2261 (0.2110)	loss 1.0342 (0.8960)	grad_norm 0.2687 (0.2592)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:13:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:03 lr 0.000084	 wd 0.0000	time 0.2395 (0.2110)	loss 0.7188 (0.8953)	grad_norm 0.2703 (0.2592)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:13:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:42 lr 0.000084	 wd 0.0000	time 0.1985 (0.2095)	loss 0.9844 (0.8954)	grad_norm 0.2610 (0.2592)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:13:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:21 lr 0.000084	 wd 0.0000	time 0.1538 (0.2079)	loss 0.9697 (0.8956)	grad_norm 0.2632 (0.2592)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:13:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000084	 wd 0.0000	time 0.1269 (0.2055)	loss 0.8867 (0.8960)	grad_norm 0.2680 (nan)	loss_scale 32768.0000 (32794.2039)	mem 6174MB
[2024-07-29 23:13:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 7 training takes 0:08:38
[2024-07-29 23:14:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 39.137 (39.137)	Loss 0.3577 (0.3577)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 6174MB
[2024-07-29 23:14:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.776 Acc@5 97.476
[2024-07-29 23:14:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 23:14:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-29 23:15:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][0/2502]	eta 11:53:20 lr 0.000084	 wd 0.0000	time 17.1067 (17.1067)	loss 0.8193 (0.8193)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:15:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:13:30 lr 0.000083	 wd 0.0000	time 0.1547 (0.3374)	loss 0.8774 (0.9016)	grad_norm 0.2608 (0.2603)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:15:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:09:42 lr 0.000083	 wd 0.0000	time 0.2251 (0.2532)	loss 0.8862 (0.9005)	grad_norm 0.2550 (0.2597)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:16:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:10:45 lr 0.000083	 wd 0.0000	time 0.2059 (0.2934)	loss 0.8843 (0.8963)	grad_norm 0.2709 (0.2592)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:16:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:09:15 lr 0.000083	 wd 0.0000	time 0.1734 (0.2645)	loss 0.9990 (0.8970)	grad_norm 0.2586 (0.2590)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:16:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:08:10 lr 0.000083	 wd 0.0000	time 0.1666 (0.2451)	loss 0.8281 (0.8977)	grad_norm 0.2600 (0.2590)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:17:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:07:20 lr 0.000083	 wd 0.0000	time 0.1568 (0.2314)	loss 0.8716 (0.8972)	grad_norm 0.2678 (0.2588)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:17:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:06:46 lr 0.000083	 wd 0.0000	time 0.2729 (0.2256)	loss 0.9116 (0.8965)	grad_norm 0.2675 (0.2589)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:17:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:06:38 lr 0.000082	 wd 0.0000	time 0.1553 (0.2341)	loss 0.7749 (0.8963)	grad_norm 0.2608 (0.2589)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:18:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:02 lr 0.000082	 wd 0.0000	time 0.1508 (0.2264)	loss 1.0322 (0.8975)	grad_norm 0.2519 (0.2589)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:18:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:05:30 lr 0.000082	 wd 0.0000	time 0.1628 (0.2203)	loss 1.0527 (0.8980)	grad_norm 0.2500 (0.2589)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:18:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:01 lr 0.000082	 wd 0.0000	time 0.1837 (0.2154)	loss 1.0029 (0.8979)	grad_norm 0.2654 (0.2590)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:19:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:04:42 lr 0.000082	 wd 0.0000	time 0.3894 (0.2167)	loss 0.8706 (0.8978)	grad_norm 0.2535 (0.2590)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:19:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:31 lr 0.000082	 wd 0.0000	time 0.1820 (0.2260)	loss 0.8354 (0.8980)	grad_norm 0.2602 (0.2591)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:19:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:04 lr 0.000081	 wd 0.0000	time 0.1381 (0.2217)	loss 0.8535 (0.8977)	grad_norm 0.2541 (0.2590)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:20:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:03:38 lr 0.000081	 wd 0.0000	time 0.1487 (0.2177)	loss 0.8706 (0.8976)	grad_norm 0.2669 (0.2592)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:20:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:13 lr 0.000081	 wd 0.0000	time 0.2045 (0.2150)	loss 0.9858 (0.8970)	grad_norm 0.2537 (0.2591)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:20:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:02:53 lr 0.000081	 wd 0.0000	time 0.1539 (0.2158)	loss 0.8755 (0.8977)	grad_norm 0.2470 (0.2593)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:21:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:30 lr 0.000081	 wd 0.0000	time 0.1689 (0.2137)	loss 0.8921 (0.8981)	grad_norm 0.2665 (0.2593)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:21:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:07 lr 0.000081	 wd 0.0000	time 0.1412 (0.2115)	loss 0.7944 (0.8976)	grad_norm 0.2449 (0.2593)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:21:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:45 lr 0.000080	 wd 0.0000	time 0.1884 (0.2097)	loss 0.8438 (0.8978)	grad_norm 0.2762 (0.2593)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:22:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:23 lr 0.000080	 wd 0.0000	time 0.2111 (0.2080)	loss 0.9121 (0.8980)	grad_norm 0.2620 (0.2593)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:22:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:02 lr 0.000080	 wd 0.0000	time 0.1825 (0.2076)	loss 0.8643 (0.8975)	grad_norm 0.2620 (0.2594)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:22:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:41 lr 0.000080	 wd 0.0000	time 0.1692 (0.2073)	loss 0.9976 (0.8973)	grad_norm 0.2580 (0.2594)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:23:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:20 lr 0.000080	 wd 0.0000	time 0.1508 (0.2058)	loss 0.9849 (0.8973)	grad_norm 0.2658 (0.2595)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:23:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000080	 wd 0.0000	time 0.1288 (0.2036)	loss 0.9443 (0.8973)	grad_norm 0.2631 (0.2596)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:23:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 8 training takes 0:08:33
[2024-07-29 23:23:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 22.791 (22.791)	Loss 0.3621 (0.3621)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 6174MB
[2024-07-29 23:24:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.800 Acc@5 97.494
[2024-07-29 23:24:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 23:24:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-29 23:24:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][0/2502]	eta 15:14:13 lr 0.000080	 wd 0.0000	time 21.9240 (21.9240)	loss 0.8945 (0.8945)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:24:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:15:23 lr 0.000079	 wd 0.0000	time 0.1908 (0.3844)	loss 0.9717 (0.8922)	grad_norm 0.2615 (0.2599)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:25:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:10:37 lr 0.000079	 wd 0.0000	time 0.1608 (0.2768)	loss 0.7759 (0.8905)	grad_norm 0.2545 (0.2601)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:25:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:08:56 lr 0.000079	 wd 0.0000	time 0.2466 (0.2438)	loss 0.9546 (0.8921)	grad_norm 0.2486 (0.2604)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:26:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:59 lr 0.000079	 wd 0.0000	time 0.1614 (0.2851)	loss 0.8760 (0.8917)	grad_norm 0.2478 (0.2603)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:26:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:08:44 lr 0.000079	 wd 0.0000	time 0.1900 (0.2618)	loss 0.7007 (0.8965)	grad_norm 0.2656 (0.2603)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:26:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:07:47 lr 0.000079	 wd 0.0000	time 0.1674 (0.2457)	loss 0.7334 (0.8940)	grad_norm 0.2692 (0.2601)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:26:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:01 lr 0.000078	 wd 0.0000	time 0.1530 (0.2337)	loss 0.9712 (0.8949)	grad_norm 0.2661 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:27:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:06:38 lr 0.000078	 wd 0.0000	time 0.3520 (0.2341)	loss 0.9185 (0.8960)	grad_norm 0.2468 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:27:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:17 lr 0.000078	 wd 0.0000	time 0.1657 (0.2359)	loss 1.0693 (0.8966)	grad_norm 0.2581 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:27:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:05:43 lr 0.000078	 wd 0.0000	time 0.1525 (0.2286)	loss 0.9521 (0.8969)	grad_norm 0.2591 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:28:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:12 lr 0.000078	 wd 0.0000	time 0.1656 (0.2226)	loss 0.8066 (0.8970)	grad_norm 0.2645 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:28:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:04:43 lr 0.000078	 wd 0.0000	time 0.1628 (0.2181)	loss 0.9761 (0.8967)	grad_norm 0.2694 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:28:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:22 lr 0.000077	 wd 0.0000	time 0.1840 (0.2183)	loss 0.9375 (0.8970)	grad_norm 0.2536 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:29:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:03:58 lr 0.000077	 wd 0.0000	time 0.1549 (0.2166)	loss 0.9102 (0.8975)	grad_norm 0.2489 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:29:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:03:33 lr 0.000077	 wd 0.0000	time 0.1523 (0.2133)	loss 0.9824 (0.8977)	grad_norm 0.2640 (nan)	loss_scale 32768.0000 (32811.6616)	mem 6174MB
[2024-07-29 23:29:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:09 lr 0.000077	 wd 0.0000	time 0.1520 (0.2105)	loss 0.9194 (0.8973)	grad_norm 0.2505 (nan)	loss_scale 32768.0000 (32808.9344)	mem 6174MB
[2024-07-29 23:30:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:02:46 lr 0.000077	 wd 0.0000	time 0.1542 (0.2080)	loss 0.8286 (0.8980)	grad_norm 0.2480 (nan)	loss_scale 32768.0000 (32806.5279)	mem 6174MB
[2024-07-29 23:30:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:25 lr 0.000077	 wd 0.0000	time 0.1811 (0.2071)	loss 0.7344 (0.8978)	grad_norm 0.2627 (nan)	loss_scale 32768.0000 (32804.3887)	mem 6174MB
[2024-07-29 23:30:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:05 lr 0.000076	 wd 0.0000	time 0.1346 (0.2080)	loss 0.9409 (0.8979)	grad_norm 0.2582 (nan)	loss_scale 32768.0000 (32802.4745)	mem 6174MB
[2024-07-29 23:31:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:01:43 lr 0.000076	 wd 0.0000	time 0.1920 (0.2066)	loss 0.9082 (0.8987)	grad_norm 0.2501 (nan)	loss_scale 32768.0000 (32800.7516)	mem 6174MB
[2024-07-29 23:31:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:22 lr 0.000076	 wd 0.0000	time 0.1799 (0.2050)	loss 1.0391 (0.8992)	grad_norm 0.2559 (nan)	loss_scale 32768.0000 (32799.1928)	mem 6174MB
[2024-07-29 23:31:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:01 lr 0.000076	 wd 0.0000	time 0.1765 (0.2034)	loss 0.9199 (0.8995)	grad_norm 0.2571 (nan)	loss_scale 32768.0000 (32797.7756)	mem 6174MB
[2024-07-29 23:31:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:40 lr 0.000076	 wd 0.0000	time 0.1681 (0.2026)	loss 0.8960 (0.8991)	grad_norm 0.2776 (nan)	loss_scale 32768.0000 (32796.4815)	mem 6174MB
[2024-07-29 23:32:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:20 lr 0.000075	 wd 0.0000	time 0.1512 (0.2031)	loss 0.8223 (0.8991)	grad_norm 0.2656 (nan)	loss_scale 32768.0000 (32795.2953)	mem 6174MB
[2024-07-29 23:32:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000075	 wd 0.0000	time 0.1286 (0.2011)	loss 0.8652 (0.8991)	grad_norm 0.2530 (nan)	loss_scale 32768.0000 (32794.2039)	mem 6174MB
[2024-07-29 23:32:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 9 training takes 0:08:27
[2024-07-29 23:32:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 19.609 (19.609)	Loss 0.3572 (0.3572)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 6174MB
[2024-07-29 23:33:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.830 Acc@5 97.504
[2024-07-29 23:33:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 23:33:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.83%
[2024-07-29 23:33:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-29 23:33:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-29 23:33:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][0/2502]	eta 17:39:52 lr 0.000075	 wd 0.0000	time 25.4168 (25.4168)	loss 1.0547 (1.0547)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:34:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:20:24 lr 0.000075	 wd 0.0000	time 0.1489 (0.5098)	loss 0.7573 (0.9130)	grad_norm 0.2629 (0.2603)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:34:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:12:57 lr 0.000075	 wd 0.0000	time 0.1865 (0.3377)	loss 0.9854 (0.9044)	grad_norm 0.2669 (0.2599)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:34:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:17 lr 0.000075	 wd 0.0000	time 0.1689 (0.2804)	loss 0.8887 (0.8993)	grad_norm 0.2524 (0.2600)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:34:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:08:48 lr 0.000075	 wd 0.0000	time 0.1840 (0.2514)	loss 0.9258 (0.8979)	grad_norm 0.2627 (0.2600)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:35:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:08:04 lr 0.000074	 wd 0.0000	time 0.3286 (0.2421)	loss 0.7842 (0.8990)	grad_norm 0.2690 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:35:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:08 lr 0.000074	 wd 0.0000	time 0.1734 (0.2571)	loss 0.9531 (0.8977)	grad_norm 0.2578 (0.2601)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:35:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:19 lr 0.000074	 wd 0.0000	time 0.1815 (0.2439)	loss 0.8232 (0.8963)	grad_norm 0.2525 (0.2601)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:36:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:06:38 lr 0.000074	 wd 0.0000	time 0.1628 (0.2342)	loss 0.8770 (0.8966)	grad_norm 0.2591 (0.2604)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:36:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:02 lr 0.000074	 wd 0.0000	time 0.1875 (0.2263)	loss 0.8613 (0.8971)	grad_norm 0.2597 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:37:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:05:46 lr 0.000073	 wd 0.0000	time 0.4185 (0.2307)	loss 0.8472 (0.8974)	grad_norm 0.2595 (0.2603)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:37:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:23 lr 0.000073	 wd 0.0000	time 0.1615 (0.2311)	loss 0.7983 (0.8973)	grad_norm 0.2545 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:37:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:04:53 lr 0.000073	 wd 0.0000	time 0.1658 (0.2255)	loss 1.0361 (0.8972)	grad_norm 0.2586 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:37:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:25 lr 0.000073	 wd 0.0000	time 0.1528 (0.2208)	loss 0.9106 (0.8973)	grad_norm 0.2586 (0.2603)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:38:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:03:59 lr 0.000073	 wd 0.0000	time 0.1574 (0.2171)	loss 0.7998 (0.8971)	grad_norm 0.2703 (0.2603)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:38:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:03:36 lr 0.000073	 wd 0.0000	time 0.1552 (0.2162)	loss 0.8696 (0.8969)	grad_norm 0.2651 (0.2601)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:38:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:14 lr 0.000072	 wd 0.0000	time 0.1547 (0.2156)	loss 0.7954 (0.8971)	grad_norm 0.2578 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:39:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:02:50 lr 0.000072	 wd 0.0000	time 0.1427 (0.2131)	loss 0.8926 (0.8974)	grad_norm 0.2545 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:39:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:27 lr 0.000072	 wd 0.0000	time 0.1587 (0.2107)	loss 0.9556 (0.8973)	grad_norm 0.2752 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:39:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:05 lr 0.000072	 wd 0.0000	time 0.1620 (0.2086)	loss 0.9849 (0.8972)	grad_norm 0.2648 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:40:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:44 lr 0.000072	 wd 0.0000	time 0.2547 (0.2081)	loss 0.8765 (0.8977)	grad_norm 0.2602 (0.2603)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:40:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:23 lr 0.000071	 wd 0.0000	time 0.1558 (0.2089)	loss 0.8711 (0.8977)	grad_norm 0.2758 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:40:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:02 lr 0.000071	 wd 0.0000	time 0.1720 (0.2073)	loss 0.8711 (0.8981)	grad_norm 0.2551 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:41:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:41 lr 0.000071	 wd 0.0000	time 0.1601 (0.2058)	loss 0.9409 (0.8977)	grad_norm 0.2554 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:41:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:20 lr 0.000071	 wd 0.0000	time 0.1745 (0.2043)	loss 0.9111 (0.8982)	grad_norm 0.2526 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:41:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000071	 wd 0.0000	time 0.1288 (0.2022)	loss 1.0049 (0.8977)	grad_norm 0.2650 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:41:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 10 training takes 0:08:30
[2024-07-29 23:42:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 43.246 (43.246)	Loss 0.3645 (0.3645)	Acc@1 91.602 (91.602)	Acc@5 98.633 (98.633)	Mem 6174MB
[2024-07-29 23:42:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.790 Acc@5 97.486
[2024-07-29 23:42:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 23:42:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.83%
[2024-07-29 23:42:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][0/2502]	eta 10:59:12 lr 0.000071	 wd 0.0000	time 15.8082 (15.8082)	loss 0.7988 (0.7988)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:43:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:13:48 lr 0.000070	 wd 0.0000	time 0.2188 (0.3448)	loss 0.9121 (0.8917)	grad_norm 0.2558 (0.2610)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:43:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:12:14 lr 0.000070	 wd 0.0000	time 0.1701 (0.3191)	loss 0.9287 (0.8939)	grad_norm 0.2622 (0.2600)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:43:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:09:48 lr 0.000070	 wd 0.0000	time 0.1650 (0.2674)	loss 1.0195 (0.8952)	grad_norm 0.2601 (0.2604)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:44:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:08:28 lr 0.000070	 wd 0.0000	time 0.1920 (0.2419)	loss 0.9609 (0.8934)	grad_norm 0.2661 (0.2605)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:44:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:07:32 lr 0.000070	 wd 0.0000	time 0.1475 (0.2259)	loss 0.8062 (0.8931)	grad_norm 0.2536 (nan)	loss_scale 32768.0000 (32898.8104)	mem 6174MB
[2024-07-29 23:44:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:06:59 lr 0.000069	 wd 0.0000	time 0.2852 (0.2205)	loss 1.0635 (0.8915)	grad_norm 0.2659 (nan)	loss_scale 32768.0000 (32877.0449)	mem 6174MB
[2024-07-29 23:45:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:07:14 lr 0.000069	 wd 0.0000	time 0.1637 (0.2413)	loss 0.8838 (0.8942)	grad_norm 0.2619 (nan)	loss_scale 32768.0000 (32861.4893)	mem 6174MB
[2024-07-29 23:45:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:06:34 lr 0.000069	 wd 0.0000	time 0.1419 (0.2320)	loss 0.9336 (0.8951)	grad_norm 0.2602 (nan)	loss_scale 32768.0000 (32849.8177)	mem 6174MB
[2024-07-29 23:45:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:06:00 lr 0.000069	 wd 0.0000	time 0.1643 (0.2249)	loss 1.0098 (0.8955)	grad_norm 0.2711 (nan)	loss_scale 32768.0000 (32840.7370)	mem 6174MB
[2024-07-29 23:46:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:05:29 lr 0.000069	 wd 0.0000	time 0.2110 (0.2191)	loss 0.8452 (0.8967)	grad_norm 0.2624 (nan)	loss_scale 32768.0000 (32833.4705)	mem 6174MB
[2024-07-29 23:46:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:07 lr 0.000069	 wd 0.0000	time 0.1748 (0.2191)	loss 0.8252 (0.8970)	grad_norm 0.2583 (nan)	loss_scale 32768.0000 (32827.5241)	mem 6174MB
[2024-07-29 23:46:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:04:42 lr 0.000068	 wd 0.0000	time 0.2062 (0.2167)	loss 0.9653 (0.8972)	grad_norm 0.2641 (nan)	loss_scale 32768.0000 (32822.5679)	mem 6174MB
[2024-07-29 23:47:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:04:16 lr 0.000068	 wd 0.0000	time 0.1782 (0.2133)	loss 0.7754 (0.8974)	grad_norm 0.2525 (nan)	loss_scale 32768.0000 (32818.3736)	mem 6174MB
[2024-07-29 23:47:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:03:51 lr 0.000068	 wd 0.0000	time 0.1719 (0.2102)	loss 0.8540 (0.8981)	grad_norm 0.2665 (nan)	loss_scale 32768.0000 (32814.7780)	mem 6174MB
[2024-07-29 23:47:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:03:27 lr 0.000068	 wd 0.0000	time 0.1726 (0.2071)	loss 0.9521 (0.8978)	grad_norm 0.2625 (nan)	loss_scale 32768.0000 (32811.6616)	mem 6174MB
[2024-07-29 23:48:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:05 lr 0.000068	 wd 0.0000	time 0.1907 (0.2061)	loss 0.9370 (0.8980)	grad_norm 0.2782 (nan)	loss_scale 32768.0000 (32808.9344)	mem 6174MB
[2024-07-29 23:48:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:02:45 lr 0.000067	 wd 0.0000	time 0.1850 (0.2069)	loss 0.8057 (0.8981)	grad_norm 0.2607 (nan)	loss_scale 32768.0000 (32806.5279)	mem 6174MB
[2024-07-29 23:48:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:24 lr 0.000067	 wd 0.0000	time 0.1553 (0.2053)	loss 1.1172 (0.8989)	grad_norm 0.2550 (nan)	loss_scale 32768.0000 (32804.3887)	mem 6174MB
[2024-07-29 23:49:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:02 lr 0.000067	 wd 0.0000	time 0.1615 (0.2036)	loss 0.7886 (0.8993)	grad_norm 0.2508 (nan)	loss_scale 32768.0000 (32802.4745)	mem 6174MB
[2024-07-29 23:49:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:01:41 lr 0.000067	 wd 0.0000	time 0.1734 (0.2020)	loss 0.9277 (0.8990)	grad_norm 0.2542 (nan)	loss_scale 32768.0000 (32800.7516)	mem 6174MB
[2024-07-29 23:49:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:20 lr 0.000067	 wd 0.0000	time 0.1972 (0.2010)	loss 0.8823 (0.8989)	grad_norm 0.2744 (nan)	loss_scale 32768.0000 (32799.1928)	mem 6174MB
[2024-07-29 23:49:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:00 lr 0.000066	 wd 0.0000	time 0.1942 (0.2014)	loss 0.9238 (0.8988)	grad_norm 0.2595 (nan)	loss_scale 32768.0000 (32797.7756)	mem 6174MB
[2024-07-29 23:50:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:40 lr 0.000066	 wd 0.0000	time 0.2022 (0.2008)	loss 0.8643 (0.8988)	grad_norm 0.2618 (nan)	loss_scale 32768.0000 (32796.4815)	mem 6174MB
[2024-07-29 23:50:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:20 lr 0.000066	 wd 0.0000	time 0.1708 (0.1995)	loss 0.8940 (0.8991)	grad_norm 0.2638 (nan)	loss_scale 32768.0000 (32795.2953)	mem 6174MB
[2024-07-29 23:50:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000066	 wd 0.0000	time 0.1286 (0.1975)	loss 1.0732 (0.8984)	grad_norm 0.2585 (nan)	loss_scale 32768.0000 (32794.2039)	mem 6174MB
[2024-07-29 23:50:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 11 training takes 0:08:18
[2024-07-29 23:51:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 43.158 (43.158)	Loss 0.3611 (0.3611)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 6174MB
[2024-07-29 23:51:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.876 Acc@5 97.494
[2024-07-29 23:51:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-29 23:51:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.88%
[2024-07-29 23:51:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-29 23:51:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-29 23:52:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][0/2502]	eta 11:10:24 lr 0.000066	 wd 0.0000	time 16.0768 (16.0768)	loss 0.9370 (0.9370)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:52:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:13:02 lr 0.000066	 wd 0.0000	time 0.1539 (0.3260)	loss 0.8413 (0.8874)	grad_norm 0.2641 (0.2616)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:52:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:09:31 lr 0.000065	 wd 0.0000	time 0.1679 (0.2484)	loss 0.8691 (0.8931)	grad_norm 0.2596 (0.2610)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:53:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:29 lr 0.000065	 wd 0.0000	time 0.1801 (0.2861)	loss 0.9287 (0.9029)	grad_norm 0.2804 (0.2609)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:53:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:14 lr 0.000065	 wd 0.0000	time 0.1571 (0.2637)	loss 0.8687 (0.9046)	grad_norm 0.2584 (0.2609)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:53:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:08:09 lr 0.000065	 wd 0.0000	time 0.1681 (0.2445)	loss 0.7881 (0.9029)	grad_norm 0.2645 (0.2605)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:54:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:07:19 lr 0.000065	 wd 0.0000	time 0.1656 (0.2309)	loss 0.7998 (0.9030)	grad_norm 0.2604 (0.2608)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:54:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:06:48 lr 0.000064	 wd 0.0000	time 0.2915 (0.2269)	loss 0.8369 (0.9025)	grad_norm 0.2588 (0.2608)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:55:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:06:47 lr 0.000064	 wd 0.0000	time 0.1406 (0.2396)	loss 0.9399 (0.9011)	grad_norm 0.2538 (0.2608)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:55:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:10 lr 0.000064	 wd 0.0000	time 0.1749 (0.2313)	loss 0.8369 (0.9004)	grad_norm 0.2633 (0.2609)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:55:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:05:37 lr 0.000064	 wd 0.0000	time 0.1902 (0.2247)	loss 0.9409 (0.9007)	grad_norm 0.2531 (0.2610)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:55:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:07 lr 0.000064	 wd 0.0000	time 0.1660 (0.2192)	loss 0.7686 (0.9006)	grad_norm 0.2538 (0.2609)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:56:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:04:44 lr 0.000063	 wd 0.0000	time 0.2253 (0.2185)	loss 0.9023 (0.8997)	grad_norm 0.2687 (0.2609)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:56:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:21 lr 0.000063	 wd 0.0000	time 0.1750 (0.2178)	loss 0.8096 (0.8998)	grad_norm 0.2744 (0.2608)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:56:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:03:56 lr 0.000063	 wd 0.0000	time 0.1566 (0.2147)	loss 0.9668 (0.9000)	grad_norm 0.2624 (0.2607)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:57:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:03:31 lr 0.000063	 wd 0.0000	time 0.1926 (0.2115)	loss 0.8848 (0.9008)	grad_norm 0.2574 (0.2608)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:57:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:08 lr 0.000063	 wd 0.0000	time 0.1598 (0.2088)	loss 0.8701 (0.9002)	grad_norm 0.2525 (0.2607)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:57:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:02:46 lr 0.000062	 wd 0.0000	time 0.1912 (0.2082)	loss 0.8672 (0.9001)	grad_norm 0.2572 (0.2608)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:58:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:26 lr 0.000062	 wd 0.0000	time 0.2559 (0.2087)	loss 0.8135 (0.9003)	grad_norm 0.2661 (0.2609)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:58:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:04 lr 0.000062	 wd 0.0000	time 0.1727 (0.2069)	loss 0.8618 (0.9000)	grad_norm 0.2565 (0.2609)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-29 23:58:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:01:43 lr 0.000062	 wd 0.0000	time 0.1452 (0.2053)	loss 0.8413 (0.9002)	grad_norm 0.2601 (nan)	loss_scale 32768.0000 (32800.7516)	mem 6174MB
[2024-07-29 23:59:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:21 lr 0.000062	 wd 0.0000	time 0.1484 (0.2037)	loss 0.8613 (0.9006)	grad_norm 0.2619 (nan)	loss_scale 32768.0000 (32799.1928)	mem 6174MB
[2024-07-29 23:59:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:01 lr 0.000061	 wd 0.0000	time 0.2045 (0.2028)	loss 0.9277 (0.9008)	grad_norm 0.2647 (nan)	loss_scale 32768.0000 (32797.7756)	mem 6174MB
[2024-07-29 23:59:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:40 lr 0.000061	 wd 0.0000	time 0.1621 (0.2027)	loss 0.8799 (0.9005)	grad_norm 0.2423 (nan)	loss_scale 32768.0000 (32796.4815)	mem 6174MB
[2024-07-29 23:59:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:20 lr 0.000061	 wd 0.0000	time 0.1727 (0.2017)	loss 0.8911 (0.8998)	grad_norm 0.2618 (nan)	loss_scale 32768.0000 (32795.2953)	mem 6174MB
[2024-07-30 00:00:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000061	 wd 0.0000	time 0.1288 (0.1996)	loss 0.9033 (0.8996)	grad_norm 0.2644 (nan)	loss_scale 32768.0000 (32794.2039)	mem 6174MB
[2024-07-30 00:00:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 12 training takes 0:08:24
[2024-07-30 00:00:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 18.110 (18.110)	Loss 0.3584 (0.3584)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 6174MB
[2024-07-30 00:00:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.848 Acc@5 97.470
[2024-07-30 00:00:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-30 00:00:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.88%
[2024-07-30 00:01:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][0/2502]	eta 1 day, 2:23:46 lr 0.000061	 wd 0.0000	time 37.9801 (37.9801)	loss 0.8755 (0.8755)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:01:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:22:07 lr 0.000061	 wd 0.0000	time 0.1727 (0.5528)	loss 0.8062 (0.8903)	grad_norm 0.2571 (0.2603)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:02:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:13:49 lr 0.000060	 wd 0.0000	time 0.1325 (0.3602)	loss 0.8057 (0.8997)	grad_norm 0.2623 (0.2604)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:02:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:10:47 lr 0.000060	 wd 0.0000	time 0.1501 (0.2942)	loss 0.7998 (0.8936)	grad_norm 0.2628 (0.2605)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:02:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:10:43 lr 0.000060	 wd 0.0000	time 0.4089 (0.3063)	loss 0.7881 (0.8945)	grad_norm 0.2638 (0.2606)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:03:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:09:31 lr 0.000060	 wd 0.0000	time 0.1424 (0.2853)	loss 0.8574 (0.8946)	grad_norm 0.2587 (0.2609)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:03:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:25 lr 0.000060	 wd 0.0000	time 0.1783 (0.2655)	loss 0.8149 (0.8959)	grad_norm 0.2631 (0.2612)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:03:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:07:32 lr 0.000059	 wd 0.0000	time 0.1588 (0.2512)	loss 1.0137 (0.8963)	grad_norm 0.2790 (0.2611)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:04:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:06:50 lr 0.000059	 wd 0.0000	time 0.1785 (0.2414)	loss 0.9448 (0.8962)	grad_norm 0.2601 (0.2610)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:04:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:06:47 lr 0.000059	 wd 0.0000	time 0.1592 (0.2545)	loss 0.9209 (0.8970)	grad_norm 0.2658 (0.2611)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:04:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:09 lr 0.000059	 wd 0.0000	time 0.1607 (0.2459)	loss 1.0068 (0.8981)	grad_norm 0.2654 (0.2613)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:05:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:34 lr 0.000059	 wd 0.0000	time 0.1659 (0.2386)	loss 0.8711 (0.8975)	grad_norm 0.2606 (0.2612)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:05:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:02 lr 0.000058	 wd 0.0000	time 0.1625 (0.2324)	loss 0.9932 (0.8978)	grad_norm 0.2662 (0.2611)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:05:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:04:35 lr 0.000058	 wd 0.0000	time 0.2103 (0.2291)	loss 0.9131 (0.8983)	grad_norm 0.2676 (0.2612)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:06:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:11 lr 0.000058	 wd 0.0000	time 0.1702 (0.2285)	loss 1.0869 (0.8980)	grad_norm 0.2548 (0.2613)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:06:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:03:45 lr 0.000058	 wd 0.0000	time 0.2181 (0.2250)	loss 0.9102 (0.8982)	grad_norm 0.2694 (0.2613)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:06:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:19 lr 0.000058	 wd 0.0000	time 0.1422 (0.2216)	loss 0.8594 (0.8987)	grad_norm 0.2676 (0.2613)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:07:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:02:55 lr 0.000057	 wd 0.0000	time 0.1509 (0.2186)	loss 0.8652 (0.8988)	grad_norm 0.2600 (0.2613)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:07:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:32 lr 0.000057	 wd 0.0000	time 0.2926 (0.2167)	loss 0.8516 (0.8988)	grad_norm 0.2700 (0.2614)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:07:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:10 lr 0.000057	 wd 0.0000	time 0.1579 (0.2173)	loss 0.8169 (0.8975)	grad_norm 0.2688 (0.2613)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:08:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:48 lr 0.000057	 wd 0.0000	time 0.1591 (0.2157)	loss 0.8857 (0.8982)	grad_norm 0.2569 (0.2614)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:08:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:25 lr 0.000057	 wd 0.0000	time 0.1712 (0.2135)	loss 0.9009 (0.8987)	grad_norm 0.2438 (0.2614)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:08:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:03 lr 0.000056	 wd 0.0000	time 0.1525 (0.2115)	loss 0.9824 (0.8987)	grad_norm 0.2673 (0.2614)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:08:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:42 lr 0.000056	 wd 0.0000	time 0.1583 (0.2099)	loss 0.8237 (0.8982)	grad_norm 0.2655 (0.2614)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:09:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:21 lr 0.000056	 wd 0.0000	time 0.1291 (0.2107)	loss 0.8955 (0.8987)	grad_norm 0.2559 (0.2615)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:09:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000056	 wd 0.0000	time 0.1284 (0.2085)	loss 0.8501 (0.8987)	grad_norm 0.2571 (0.2615)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:09:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 13 training takes 0:08:50
[2024-07-30 00:10:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 24.038 (24.038)	Loss 0.3599 (0.3599)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 6174MB
[2024-07-30 00:10:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.878 Acc@5 97.502
[2024-07-30 00:10:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 00:10:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.88%
[2024-07-30 00:10:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-30 00:10:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-30 00:10:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][0/2502]	eta 22:51:48 lr 0.000056	 wd 0.0000	time 32.8973 (32.8973)	loss 0.9897 (0.9897)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:11:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:20:33 lr 0.000055	 wd 0.0000	time 0.1651 (0.5137)	loss 0.8672 (0.8927)	grad_norm 0.2622 (0.2607)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:11:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:13:02 lr 0.000055	 wd 0.0000	time 0.1623 (0.3400)	loss 0.8667 (0.8954)	grad_norm 0.2522 (0.2606)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:11:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:10:20 lr 0.000055	 wd 0.0000	time 0.1694 (0.2819)	loss 1.1611 (0.8986)	grad_norm 0.2548 (0.2607)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:12:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:08:54 lr 0.000055	 wd 0.0000	time 0.1903 (0.2545)	loss 1.1094 (0.8976)	grad_norm 0.2586 (0.2613)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:12:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:09:15 lr 0.000055	 wd 0.0000	time 0.1854 (0.2773)	loss 0.9341 (0.8973)	grad_norm 0.2455 (0.2611)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:13:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:08:18 lr 0.000054	 wd 0.0000	time 0.1297 (0.2623)	loss 0.8726 (0.8980)	grad_norm 0.2743 (0.2613)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:13:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:27 lr 0.000054	 wd 0.0000	time 0.1468 (0.2483)	loss 0.8101 (0.8972)	grad_norm 0.2641 (0.2616)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:13:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:06:44 lr 0.000054	 wd 0.0000	time 0.1384 (0.2378)	loss 0.8027 (0.8972)	grad_norm 0.2630 (0.2614)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:14:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:25 lr 0.000054	 wd 0.0000	time 0.6198 (0.2409)	loss 0.8911 (0.8970)	grad_norm 0.2753 (0.2615)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:14:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:06:07 lr 0.000054	 wd 0.0000	time 0.1530 (0.2448)	loss 0.9272 (0.8962)	grad_norm 0.2783 (nan)	loss_scale 32768.0000 (32833.4705)	mem 6174MB
[2024-07-30 00:14:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:33 lr 0.000053	 wd 0.0000	time 0.1712 (0.2375)	loss 0.8413 (0.8960)	grad_norm 0.2508 (nan)	loss_scale 32768.0000 (32827.5241)	mem 6174MB
[2024-07-30 00:15:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:01 lr 0.000053	 wd 0.0000	time 0.1903 (0.2314)	loss 0.8926 (0.8960)	grad_norm 0.2648 (nan)	loss_scale 32768.0000 (32822.5679)	mem 6174MB
[2024-07-30 00:15:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:04:32 lr 0.000053	 wd 0.0000	time 0.2022 (0.2268)	loss 1.0908 (0.8958)	grad_norm 0.2629 (nan)	loss_scale 32768.0000 (32818.3736)	mem 6174MB
[2024-07-30 00:15:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:11 lr 0.000053	 wd 0.0000	time 0.1604 (0.2284)	loss 0.8984 (0.8959)	grad_norm 0.2552 (nan)	loss_scale 32768.0000 (32814.7780)	mem 6174MB
[2024-07-30 00:16:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:03:45 lr 0.000053	 wd 0.0000	time 0.1900 (0.2250)	loss 0.8701 (0.8962)	grad_norm 0.2628 (nan)	loss_scale 32768.0000 (32811.6616)	mem 6174MB
[2024-07-30 00:16:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:19 lr 0.000052	 wd 0.0000	time 0.1937 (0.2215)	loss 0.9028 (0.8957)	grad_norm 0.2645 (nan)	loss_scale 32768.0000 (32808.9344)	mem 6174MB
[2024-07-30 00:16:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:02:55 lr 0.000052	 wd 0.0000	time 0.1453 (0.2183)	loss 1.0771 (0.8962)	grad_norm 0.2707 (nan)	loss_scale 32768.0000 (32806.5279)	mem 6174MB
[2024-07-30 00:16:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:31 lr 0.000052	 wd 0.0000	time 0.1813 (0.2157)	loss 0.7114 (0.8963)	grad_norm 0.2589 (nan)	loss_scale 32768.0000 (32804.3887)	mem 6174MB
[2024-07-30 00:17:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:09 lr 0.000052	 wd 0.0000	time 0.1645 (0.2151)	loss 0.8394 (0.8961)	grad_norm 0.2588 (nan)	loss_scale 32768.0000 (32802.4745)	mem 6174MB
[2024-07-30 00:17:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:01:48 lr 0.000052	 wd 0.0000	time 0.1358 (0.2155)	loss 0.8335 (0.8960)	grad_norm 0.2662 (nan)	loss_scale 32768.0000 (32800.7516)	mem 6174MB
[2024-07-30 00:17:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:25 lr 0.000051	 wd 0.0000	time 0.1592 (0.2135)	loss 0.9497 (0.8960)	grad_norm 0.2584 (nan)	loss_scale 32768.0000 (32799.1928)	mem 6174MB
[2024-07-30 00:18:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:03 lr 0.000051	 wd 0.0000	time 0.1671 (0.2117)	loss 0.8887 (0.8967)	grad_norm 0.2541 (nan)	loss_scale 32768.0000 (32797.7756)	mem 6174MB
[2024-07-30 00:18:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:42 lr 0.000051	 wd 0.0000	time 0.1817 (0.2099)	loss 0.8491 (0.8964)	grad_norm 0.2644 (nan)	loss_scale 32768.0000 (32796.4815)	mem 6174MB
[2024-07-30 00:18:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:21 lr 0.000051	 wd 0.0000	time 0.2012 (0.2093)	loss 0.9863 (0.8969)	grad_norm 0.2630 (nan)	loss_scale 32768.0000 (32795.2953)	mem 6174MB
[2024-07-30 00:19:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000051	 wd 0.0000	time 0.1289 (0.2079)	loss 0.9380 (0.8972)	grad_norm 0.2646 (nan)	loss_scale 32768.0000 (32794.2039)	mem 6174MB
[2024-07-30 00:19:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 14 training takes 0:08:48
[2024-07-30 00:19:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 20.561 (20.561)	Loss 0.3572 (0.3572)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 6174MB
[2024-07-30 00:19:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.880 Acc@5 97.466
[2024-07-30 00:19:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 00:19:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.88%
[2024-07-30 00:19:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-30 00:19:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-30 00:20:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][0/2502]	eta 14:17:47 lr 0.000051	 wd 0.0000	time 20.5704 (20.5704)	loss 0.8271 (0.8271)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:20:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:21:14 lr 0.000050	 wd 0.0000	time 0.2461 (0.5304)	loss 0.9893 (0.9053)	grad_norm 0.2544 (0.2616)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:21:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:13:34 lr 0.000050	 wd 0.0000	time 0.1665 (0.3537)	loss 1.0068 (0.9009)	grad_norm 0.2629 (0.2619)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:21:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:10:41 lr 0.000050	 wd 0.0000	time 0.1604 (0.2912)	loss 0.9380 (0.8984)	grad_norm 0.2572 (0.2620)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:21:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:09:04 lr 0.000050	 wd 0.0000	time 0.1482 (0.2592)	loss 1.0215 (0.8995)	grad_norm 0.2724 (0.2620)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:21:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:08:23 lr 0.000049	 wd 0.0000	time 0.3599 (0.2513)	loss 0.8193 (0.9014)	grad_norm 0.2659 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:22:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:08:23 lr 0.000049	 wd 0.0000	time 0.1556 (0.2649)	loss 0.8438 (0.9008)	grad_norm 0.2690 (0.2622)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:22:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:32 lr 0.000049	 wd 0.0000	time 0.1797 (0.2509)	loss 0.8423 (0.8980)	grad_norm 0.2679 (0.2622)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:23:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:06:49 lr 0.000049	 wd 0.0000	time 0.1613 (0.2403)	loss 1.0332 (0.8984)	grad_norm 0.2708 (0.2622)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:23:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:11 lr 0.000049	 wd 0.0000	time 0.1638 (0.2322)	loss 0.8223 (0.8987)	grad_norm 0.2639 (0.2622)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:23:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:06:00 lr 0.000048	 wd 0.0000	time 0.2228 (0.2399)	loss 0.9419 (0.8983)	grad_norm 0.2584 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:24:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:27 lr 0.000048	 wd 0.0000	time 0.1785 (0.2339)	loss 0.9546 (0.8962)	grad_norm 0.2725 (0.2621)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:24:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:04:56 lr 0.000048	 wd 0.0000	time 0.1643 (0.2279)	loss 0.8169 (0.8972)	grad_norm 0.2561 (0.2620)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:24:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:04:28 lr 0.000048	 wd 0.0000	time 0.1457 (0.2234)	loss 0.9248 (0.8968)	grad_norm 0.2529 (0.2621)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:25:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:02 lr 0.000048	 wd 0.0000	time 0.2352 (0.2199)	loss 0.8223 (0.8971)	grad_norm 0.2686 (0.2621)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:25:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:03:41 lr 0.000047	 wd 0.0000	time 2.0114 (0.2206)	loss 0.9648 (0.8966)	grad_norm 0.2557 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:25:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:16 lr 0.000047	 wd 0.0000	time 0.2047 (0.2182)	loss 0.9741 (0.8968)	grad_norm 0.2641 (0.2624)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:25:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:02:52 lr 0.000047	 wd 0.0000	time 0.1763 (0.2153)	loss 0.8262 (0.8971)	grad_norm 0.2619 (0.2624)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:26:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:29 lr 0.000047	 wd 0.0000	time 0.1620 (0.2130)	loss 1.0547 (0.8977)	grad_norm 0.2727 (0.2624)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:26:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:06 lr 0.000047	 wd 0.0000	time 0.1934 (0.2109)	loss 0.9810 (0.8971)	grad_norm 0.2713 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:26:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:01:45 lr 0.000046	 wd 0.0000	time 0.1511 (0.2105)	loss 1.0303 (0.8980)	grad_norm 0.2743 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:27:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:24 lr 0.000046	 wd 0.0000	time 0.1410 (0.2114)	loss 0.8711 (0.8978)	grad_norm 0.2547 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:27:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:03 lr 0.000046	 wd 0.0000	time 0.1647 (0.2096)	loss 0.9141 (0.8981)	grad_norm 0.2572 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:27:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:42 lr 0.000046	 wd 0.0000	time 0.1337 (0.2079)	loss 0.9287 (0.8981)	grad_norm 0.2778 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:28:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:21 lr 0.000046	 wd 0.0000	time 0.1636 (0.2064)	loss 0.9448 (0.8980)	grad_norm 0.2638 (0.2624)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:28:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000045	 wd 0.0000	time 0.1283 (0.2044)	loss 1.1104 (0.8984)	grad_norm 0.2622 (nan)	loss_scale 32768.0000 (32794.2039)	mem 6174MB
[2024-07-30 00:28:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 15 training takes 0:08:38
[2024-07-30 00:28:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_15.pth saving......
[2024-07-30 00:28:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_15.pth saved !!!
[2024-07-30 00:29:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 43.595 (43.595)	Loss 0.3591 (0.3591)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 6174MB
[2024-07-30 00:29:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.882 Acc@5 97.500
[2024-07-30 00:29:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 00:29:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.88%
[2024-07-30 00:29:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-30 00:29:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-30 00:29:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][0/2502]	eta 13:40:34 lr 0.000045	 wd 0.0000	time 19.6779 (19.6779)	loss 0.7651 (0.7651)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:30:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:18:59 lr 0.000045	 wd 0.0000	time 0.1982 (0.4744)	loss 1.0020 (0.9122)	grad_norm 0.2624 (0.2640)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:30:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:12:17 lr 0.000045	 wd 0.0000	time 0.1632 (0.3202)	loss 0.8960 (0.8992)	grad_norm 0.2702 (0.2631)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:30:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:09:53 lr 0.000045	 wd 0.0000	time 0.1416 (0.2694)	loss 0.9629 (0.9008)	grad_norm 0.2582 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:31:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:08:31 lr 0.000045	 wd 0.0000	time 0.1722 (0.2435)	loss 0.9331 (0.9003)	grad_norm 0.2617 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:31:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:07:53 lr 0.000044	 wd 0.0000	time 0.3776 (0.2365)	loss 1.0000 (0.8998)	grad_norm 0.2628 (0.2622)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:32:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:12 lr 0.000044	 wd 0.0000	time 0.1633 (0.2591)	loss 0.9551 (0.8998)	grad_norm 0.2586 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:32:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:22 lr 0.000044	 wd 0.0000	time 0.1638 (0.2456)	loss 0.9194 (0.8998)	grad_norm 0.2609 (0.2622)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:32:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:06:41 lr 0.000044	 wd 0.0000	time 0.1791 (0.2357)	loss 0.8931 (0.8994)	grad_norm 0.2550 (0.2622)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:33:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:05 lr 0.000043	 wd 0.0000	time 0.2174 (0.2282)	loss 0.8135 (0.9008)	grad_norm 0.2720 (0.2624)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:33:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:05:56 lr 0.000043	 wd 0.0000	time 0.1882 (0.2375)	loss 0.8765 (0.9009)	grad_norm 0.2663 (0.2625)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:33:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:24 lr 0.000043	 wd 0.0000	time 0.1457 (0.2317)	loss 0.9956 (0.9011)	grad_norm 0.2721 (0.2626)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:34:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:04:54 lr 0.000043	 wd 0.0000	time 0.2035 (0.2260)	loss 0.8999 (0.9005)	grad_norm 0.2646 (0.2625)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:34:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:04:25 lr 0.000043	 wd 0.0000	time 0.1701 (0.2211)	loss 0.9854 (0.9000)	grad_norm 0.2600 (0.2625)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:34:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:00 lr 0.000042	 wd 0.0000	time 0.1798 (0.2179)	loss 0.8257 (0.8993)	grad_norm 0.2536 (0.2625)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:35:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:03:40 lr 0.000042	 wd 0.0000	time 0.1581 (0.2199)	loss 0.8481 (0.8989)	grad_norm 0.2452 (0.2625)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:35:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:15 lr 0.000042	 wd 0.0000	time 0.2154 (0.2169)	loss 0.8306 (0.8989)	grad_norm 0.2633 (0.2624)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:35:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:02:51 lr 0.000042	 wd 0.0000	time 0.1523 (0.2142)	loss 0.8799 (0.8986)	grad_norm 0.2616 (0.2625)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:35:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:28 lr 0.000042	 wd 0.0000	time 0.1791 (0.2118)	loss 1.0703 (0.8988)	grad_norm 0.2466 (0.2625)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:36:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:06 lr 0.000041	 wd 0.0000	time 0.2719 (0.2097)	loss 1.0186 (0.8978)	grad_norm 0.2590 (0.2625)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:36:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:01:44 lr 0.000041	 wd 0.0000	time 0.2004 (0.2090)	loss 0.8794 (0.8975)	grad_norm 0.2620 (0.2624)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:36:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:24 lr 0.000041	 wd 0.0000	time 0.1465 (0.2093)	loss 0.6992 (0.8971)	grad_norm 0.2607 (0.2625)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:37:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:02 lr 0.000041	 wd 0.0000	time 0.1462 (0.2077)	loss 0.7876 (0.8970)	grad_norm 0.2665 (0.2625)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:37:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:41 lr 0.000041	 wd 0.0000	time 0.1800 (0.2063)	loss 0.6987 (0.8965)	grad_norm 0.2699 (0.2624)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:37:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:20 lr 0.000040	 wd 0.0000	time 0.1680 (0.2047)	loss 0.8022 (0.8963)	grad_norm 0.2654 (0.2624)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:38:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1290 (0.2028)	loss 0.8745 (0.8961)	grad_norm 0.2704 (0.2624)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:38:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 16 training takes 0:08:35
[2024-07-30 00:38:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 33.074 (33.074)	Loss 0.3591 (0.3591)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 6174MB
[2024-07-30 00:39:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.848 Acc@5 97.482
[2024-07-30 00:39:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-30 00:39:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.88%
[2024-07-30 00:39:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][0/2502]	eta 10:48:10 lr 0.000040	 wd 0.0000	time 15.5438 (15.5438)	loss 0.7788 (0.7788)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:39:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:14:53 lr 0.000040	 wd 0.0000	time 0.3103 (0.3721)	loss 0.9800 (0.8989)	grad_norm 0.2525 (0.2613)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:40:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:12:46 lr 0.000040	 wd 0.0000	time 0.1593 (0.3329)	loss 0.8755 (0.9018)	grad_norm 0.2508 (0.2620)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:40:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:10 lr 0.000040	 wd 0.0000	time 0.2098 (0.2770)	loss 0.8926 (0.8980)	grad_norm 0.2773 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:40:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:08:43 lr 0.000039	 wd 0.0000	time 0.1571 (0.2489)	loss 0.9565 (0.8965)	grad_norm 0.2581 (0.2624)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:41:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:07:42 lr 0.000039	 wd 0.0000	time 0.1643 (0.2313)	loss 0.7783 (0.8943)	grad_norm 0.2761 (0.2626)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:41:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:04 lr 0.000039	 wd 0.0000	time 0.2676 (0.2546)	loss 0.8242 (0.8958)	grad_norm 0.2744 (0.2628)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:42:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:32 lr 0.000039	 wd 0.0000	time 0.1324 (0.2511)	loss 0.9180 (0.8950)	grad_norm 0.2651 (0.2629)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:42:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:06:49 lr 0.000039	 wd 0.0000	time 0.1709 (0.2405)	loss 0.8188 (0.8950)	grad_norm 0.2563 (0.2628)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:42:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:11 lr 0.000038	 wd 0.0000	time 0.1649 (0.2320)	loss 0.9937 (0.8954)	grad_norm 0.2562 (0.2626)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:42:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:05:41 lr 0.000038	 wd 0.0000	time 0.1988 (0.2274)	loss 0.9487 (0.8955)	grad_norm 0.2663 (0.2626)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:43:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:23 lr 0.000038	 wd 0.0000	time 0.1614 (0.2304)	loss 0.7739 (0.8968)	grad_norm 0.2660 (0.2627)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:43:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:04:52 lr 0.000038	 wd 0.0000	time 0.1892 (0.2250)	loss 0.7939 (0.8981)	grad_norm 0.2727 (0.2628)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:43:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:04:25 lr 0.000038	 wd 0.0000	time 0.1636 (0.2207)	loss 0.9336 (0.8973)	grad_norm 0.2584 (0.2628)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:44:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:03:59 lr 0.000037	 wd 0.0000	time 0.1934 (0.2169)	loss 0.9272 (0.8981)	grad_norm 0.2493 (0.2628)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:44:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:03:34 lr 0.000037	 wd 0.0000	time 0.2666 (0.2143)	loss 0.8955 (0.8979)	grad_norm 0.2643 (nan)	loss_scale 32768.0000 (32811.6616)	mem 6174MB
[2024-07-30 00:44:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:13 lr 0.000037	 wd 0.0000	time 0.1699 (0.2148)	loss 1.0781 (0.8978)	grad_norm 0.2682 (nan)	loss_scale 32768.0000 (32808.9344)	mem 6174MB
[2024-07-30 00:45:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:02:50 lr 0.000037	 wd 0.0000	time 0.1979 (0.2127)	loss 1.0518 (0.8979)	grad_norm 0.2648 (nan)	loss_scale 32768.0000 (32806.5279)	mem 6174MB
[2024-07-30 00:45:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:27 lr 0.000037	 wd 0.0000	time 0.1792 (0.2104)	loss 0.8184 (0.8992)	grad_norm 0.2674 (nan)	loss_scale 32768.0000 (32804.3887)	mem 6174MB
[2024-07-30 00:45:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:05 lr 0.000036	 wd 0.0000	time 0.1592 (0.2083)	loss 0.7778 (0.8996)	grad_norm 0.2609 (nan)	loss_scale 32768.0000 (32802.4745)	mem 6174MB
[2024-07-30 00:45:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:01:43 lr 0.000036	 wd 0.0000	time 0.2068 (0.2067)	loss 0.8174 (0.8992)	grad_norm 0.2623 (nan)	loss_scale 32768.0000 (32800.7516)	mem 6174MB
[2024-07-30 00:46:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:23 lr 0.000036	 wd 0.0000	time 0.3682 (0.2076)	loss 0.8311 (0.8986)	grad_norm 0.2572 (nan)	loss_scale 32768.0000 (32799.1928)	mem 6174MB
[2024-07-30 00:46:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:02 lr 0.000036	 wd 0.0000	time 0.1938 (0.2072)	loss 0.9829 (0.8985)	grad_norm 0.2618 (nan)	loss_scale 32768.0000 (32797.7756)	mem 6174MB
[2024-07-30 00:46:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:41 lr 0.000036	 wd 0.0000	time 0.1470 (0.2056)	loss 0.9429 (0.8981)	grad_norm 0.2593 (nan)	loss_scale 32768.0000 (32796.4815)	mem 6174MB
[2024-07-30 00:47:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:20 lr 0.000035	 wd 0.0000	time 0.1499 (0.2042)	loss 0.8320 (0.8984)	grad_norm 0.2637 (nan)	loss_scale 32768.0000 (32795.2953)	mem 6174MB
[2024-07-30 00:47:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1355 (0.2020)	loss 0.9473 (0.8987)	grad_norm 0.2602 (nan)	loss_scale 32768.0000 (32794.2039)	mem 6174MB
[2024-07-30 00:47:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 17 training takes 0:08:34
[2024-07-30 00:48:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 40.800 (40.800)	Loss 0.3577 (0.3577)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 6174MB
[2024-07-30 00:48:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.886 Acc@5 97.486
[2024-07-30 00:48:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 00:48:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.89%
[2024-07-30 00:48:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-30 00:48:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-30 00:48:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][0/2502]	eta 11:17:55 lr 0.000035	 wd 0.0000	time 16.2574 (16.2574)	loss 0.9209 (0.9209)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:49:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:13:49 lr 0.000035	 wd 0.0000	time 0.2270 (0.3453)	loss 1.0195 (0.9040)	grad_norm 0.2714 (0.2638)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:49:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:13:15 lr 0.000035	 wd 0.0000	time 0.2293 (0.3457)	loss 0.8735 (0.8975)	grad_norm 0.2640 (0.2634)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:50:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:10:30 lr 0.000035	 wd 0.0000	time 0.1416 (0.2861)	loss 0.9380 (0.9008)	grad_norm 0.2626 (0.2636)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:50:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:08:57 lr 0.000034	 wd 0.0000	time 0.1897 (0.2558)	loss 0.8081 (0.9027)	grad_norm 0.2673 (0.2632)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:50:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:07:55 lr 0.000034	 wd 0.0000	time 0.1423 (0.2376)	loss 0.7261 (0.9026)	grad_norm 0.2639 (0.2629)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:51:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:07:27 lr 0.000034	 wd 0.0000	time 0.3451 (0.2354)	loss 0.9541 (0.8985)	grad_norm 0.2659 (0.2630)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:51:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:07:20 lr 0.000034	 wd 0.0000	time 0.1705 (0.2447)	loss 0.9443 (0.8957)	grad_norm 0.2518 (0.2627)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:51:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:06:39 lr 0.000034	 wd 0.0000	time 0.1622 (0.2345)	loss 1.0811 (0.8940)	grad_norm 0.2501 (0.2627)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:52:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:06:03 lr 0.000033	 wd 0.0000	time 0.1686 (0.2272)	loss 0.9683 (0.8945)	grad_norm 0.2789 (0.2627)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:52:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:05:31 lr 0.000033	 wd 0.0000	time 0.1990 (0.2210)	loss 0.8662 (0.8954)	grad_norm 0.2627 (0.2627)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:53:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:33 lr 0.000033	 wd 0.0000	time 3.6178 (0.2376)	loss 0.8184 (0.8966)	grad_norm 0.2531 (0.2626)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:53:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:02 lr 0.000033	 wd 0.0000	time 0.1722 (0.2320)	loss 0.9136 (0.8963)	grad_norm 0.2626 (0.2627)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:53:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:04:32 lr 0.000033	 wd 0.0000	time 0.1872 (0.2270)	loss 0.8896 (0.8976)	grad_norm 0.2602 (0.2628)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:53:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:05 lr 0.000032	 wd 0.0000	time 0.1645 (0.2224)	loss 1.0371 (0.8969)	grad_norm 0.2683 (0.2629)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:54:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:03:40 lr 0.000032	 wd 0.0000	time 0.1982 (0.2205)	loss 0.8833 (0.8977)	grad_norm 0.2615 (0.2628)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:54:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:18 lr 0.000032	 wd 0.0000	time 0.1799 (0.2203)	loss 0.9038 (0.8969)	grad_norm 0.2677 (0.2630)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:54:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:02:54 lr 0.000032	 wd 0.0000	time 0.1372 (0.2178)	loss 0.9785 (0.8970)	grad_norm 0.2685 (0.2630)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:55:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:31 lr 0.000032	 wd 0.0000	time 0.1660 (0.2152)	loss 0.8472 (0.8970)	grad_norm 0.2740 (0.2631)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:55:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:08 lr 0.000032	 wd 0.0000	time 0.1501 (0.2127)	loss 0.8472 (0.8967)	grad_norm 0.2764 (0.2632)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:55:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:01:46 lr 0.000031	 wd 0.0000	time 0.1737 (0.2113)	loss 0.9053 (0.8973)	grad_norm 0.2584 (0.2632)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:56:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:25 lr 0.000031	 wd 0.0000	time 0.1634 (0.2120)	loss 0.7544 (0.8975)	grad_norm 0.2689 (0.2632)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:56:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:03 lr 0.000031	 wd 0.0000	time 0.1427 (0.2112)	loss 0.9194 (0.8974)	grad_norm 0.2581 (0.2632)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:56:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:42 lr 0.000031	 wd 0.0000	time 0.1741 (0.2095)	loss 0.7817 (0.8977)	grad_norm 0.2631 (0.2632)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:57:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:21 lr 0.000031	 wd 0.0000	time 0.1498 (0.2079)	loss 0.9155 (0.8979)	grad_norm 0.2662 (0.2633)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:57:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000030	 wd 0.0000	time 0.1287 (0.2055)	loss 0.8667 (0.8980)	grad_norm 0.2651 (0.2633)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:57:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 18 training takes 0:08:41
[2024-07-30 00:58:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 38.322 (38.322)	Loss 0.3572 (0.3572)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 6174MB
[2024-07-30 00:58:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.906 Acc@5 97.472
[2024-07-30 00:58:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 00:58:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.91%
[2024-07-30 00:58:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-30 00:58:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-30 00:58:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][0/2502]	eta 11:11:30 lr 0.000030	 wd 0.0000	time 16.1034 (16.1034)	loss 0.8813 (0.8813)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:58:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:13:27 lr 0.000030	 wd 0.0000	time 0.1959 (0.3361)	loss 1.0215 (0.8894)	grad_norm 0.2598 (0.2637)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:59:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:12:49 lr 0.000030	 wd 0.0000	time 0.1923 (0.3343)	loss 0.7236 (0.8871)	grad_norm 0.2691 (0.2637)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 00:59:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:10:16 lr 0.000030	 wd 0.0000	time 0.1473 (0.2798)	loss 0.9888 (0.8927)	grad_norm 0.2655 (0.2634)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:00:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:08:48 lr 0.000030	 wd 0.0000	time 0.1736 (0.2512)	loss 0.8457 (0.8945)	grad_norm 0.2488 (0.2633)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:00:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:07:47 lr 0.000029	 wd 0.0000	time 0.1678 (0.2334)	loss 0.9487 (0.8944)	grad_norm 0.2598 (nan)	loss_scale 32768.0000 (32898.8104)	mem 6174MB
[2024-07-30 01:00:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:07:10 lr 0.000029	 wd 0.0000	time 0.3331 (0.2263)	loss 0.7759 (0.8959)	grad_norm 0.2594 (nan)	loss_scale 32768.0000 (32877.0449)	mem 6174MB
[2024-07-30 01:01:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:07:11 lr 0.000029	 wd 0.0000	time 0.1389 (0.2397)	loss 0.9990 (0.8971)	grad_norm 0.2558 (nan)	loss_scale 32768.0000 (32861.4893)	mem 6174MB
[2024-07-30 01:01:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:06:32 lr 0.000029	 wd 0.0000	time 0.1483 (0.2305)	loss 0.8823 (0.8986)	grad_norm 0.2638 (nan)	loss_scale 32768.0000 (32849.8177)	mem 6174MB
[2024-07-30 01:01:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:05:57 lr 0.000029	 wd 0.0000	time 0.1474 (0.2233)	loss 0.8823 (0.8986)	grad_norm 0.2598 (nan)	loss_scale 32768.0000 (32840.7370)	mem 6174MB
[2024-07-30 01:01:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:05:26 lr 0.000028	 wd 0.0000	time 0.1727 (0.2172)	loss 0.9390 (0.8994)	grad_norm 0.2611 (nan)	loss_scale 32768.0000 (32833.4705)	mem 6174MB
[2024-07-30 01:02:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:11 lr 0.000028	 wd 0.0000	time 0.4649 (0.2220)	loss 0.8452 (0.8989)	grad_norm 0.2676 (nan)	loss_scale 32768.0000 (32827.5241)	mem 6174MB
[2024-07-30 01:02:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:04:55 lr 0.000028	 wd 0.0000	time 0.1584 (0.2270)	loss 0.8735 (0.8990)	grad_norm 0.2641 (nan)	loss_scale 32768.0000 (32822.5679)	mem 6174MB
[2024-07-30 01:03:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:04:27 lr 0.000028	 wd 0.0000	time 0.1779 (0.2223)	loss 0.8584 (0.8996)	grad_norm 0.2602 (nan)	loss_scale 32768.0000 (32818.3736)	mem 6174MB
[2024-07-30 01:03:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:00 lr 0.000028	 wd 0.0000	time 0.1568 (0.2181)	loss 0.8579 (0.8991)	grad_norm 0.2556 (nan)	loss_scale 32768.0000 (32814.7780)	mem 6174MB
[2024-07-30 01:03:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:03:35 lr 0.000028	 wd 0.0000	time 0.1617 (0.2149)	loss 0.9014 (0.8996)	grad_norm 0.2461 (nan)	loss_scale 32768.0000 (32811.6616)	mem 6174MB
[2024-07-30 01:04:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:13 lr 0.000027	 wd 0.0000	time 0.2232 (0.2140)	loss 0.9106 (0.9000)	grad_norm 0.2712 (nan)	loss_scale 32768.0000 (32808.9344)	mem 6174MB
[2024-07-30 01:04:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:02:51 lr 0.000027	 wd 0.0000	time 0.1595 (0.2137)	loss 1.0127 (0.9000)	grad_norm 0.2614 (nan)	loss_scale 32768.0000 (32806.5279)	mem 6174MB
[2024-07-30 01:04:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:28 lr 0.000027	 wd 0.0000	time 0.2004 (0.2113)	loss 0.8403 (0.9003)	grad_norm 0.2542 (nan)	loss_scale 32768.0000 (32804.3887)	mem 6174MB
[2024-07-30 01:04:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:05 lr 0.000027	 wd 0.0000	time 0.1645 (0.2092)	loss 0.8745 (0.9004)	grad_norm 0.2625 (nan)	loss_scale 32768.0000 (32802.4745)	mem 6174MB
[2024-07-30 01:05:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:44 lr 0.000027	 wd 0.0000	time 0.2009 (0.2073)	loss 0.9785 (0.9002)	grad_norm 0.2639 (nan)	loss_scale 32768.0000 (32800.7516)	mem 6174MB
[2024-07-30 01:05:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:23 lr 0.000026	 wd 0.0000	time 0.1883 (0.2068)	loss 0.9995 (0.9000)	grad_norm 0.2614 (nan)	loss_scale 32768.0000 (32799.1928)	mem 6174MB
[2024-07-30 01:05:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:02 lr 0.000026	 wd 0.0000	time 0.1794 (0.2071)	loss 0.8774 (0.8994)	grad_norm 0.2883 (nan)	loss_scale 32768.0000 (32797.7756)	mem 6174MB
[2024-07-30 01:06:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:41 lr 0.000026	 wd 0.0000	time 0.1632 (0.2057)	loss 0.9326 (0.8991)	grad_norm 0.2647 (nan)	loss_scale 32768.0000 (32796.4815)	mem 6174MB
[2024-07-30 01:06:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:20 lr 0.000026	 wd 0.0000	time 0.1745 (0.2043)	loss 0.9751 (0.8989)	grad_norm 0.2778 (nan)	loss_scale 32768.0000 (32795.2953)	mem 6174MB
[2024-07-30 01:06:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1287 (0.2021)	loss 0.7197 (0.8990)	grad_norm 0.2644 (nan)	loss_scale 32768.0000 (32794.2039)	mem 6174MB
[2024-07-30 01:06:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 19 training takes 0:08:33
[2024-07-30 01:07:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 43.678 (43.678)	Loss 0.3577 (0.3577)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 6174MB
[2024-07-30 01:07:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.906 Acc@5 97.484
[2024-07-30 01:07:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 01:07:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.91%
[2024-07-30 01:07:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-30 01:08:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-30 01:08:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][0/2502]	eta 11:13:02 lr 0.000026	 wd 0.0000	time 16.1399 (16.1399)	loss 0.8501 (0.8501)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:08:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:13:14 lr 0.000026	 wd 0.0000	time 0.2008 (0.3309)	loss 1.0303 (0.9022)	grad_norm 0.2638 (0.2647)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:09:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:12:55 lr 0.000025	 wd 0.0000	time 0.7215 (0.3367)	loss 0.9492 (0.8930)	grad_norm 0.2620 (0.2639)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:09:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:10:22 lr 0.000025	 wd 0.0000	time 0.1552 (0.2827)	loss 0.7656 (0.8892)	grad_norm 0.2710 (0.2639)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:09:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:08:52 lr 0.000025	 wd 0.0000	time 0.1483 (0.2534)	loss 0.8867 (0.8901)	grad_norm 0.2649 (0.2640)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:09:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:07:50 lr 0.000025	 wd 0.0000	time 0.1354 (0.2350)	loss 0.8677 (0.8898)	grad_norm 0.2535 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:10:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:07:14 lr 0.000025	 wd 0.0000	time 0.3397 (0.2282)	loss 0.8232 (0.8905)	grad_norm 0.2640 (0.2642)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:10:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:24 lr 0.000025	 wd 0.0000	time 0.1739 (0.2466)	loss 0.7944 (0.8910)	grad_norm 0.2545 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:11:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:06:42 lr 0.000024	 wd 0.0000	time 0.1754 (0.2364)	loss 1.0146 (0.8915)	grad_norm 0.2567 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:11:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:06 lr 0.000024	 wd 0.0000	time 0.1558 (0.2286)	loss 0.7798 (0.8915)	grad_norm 0.2543 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:11:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:05:33 lr 0.000024	 wd 0.0000	time 0.1731 (0.2222)	loss 0.8276 (0.8911)	grad_norm 0.2589 (0.2640)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:12:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:24 lr 0.000024	 wd 0.0000	time 0.1586 (0.2313)	loss 0.8062 (0.8912)	grad_norm 0.2623 (0.2640)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:12:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:04:56 lr 0.000024	 wd 0.0000	time 0.1515 (0.2275)	loss 0.7554 (0.8912)	grad_norm 0.2604 (0.2640)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:12:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:04:27 lr 0.000023	 wd 0.0000	time 0.1681 (0.2227)	loss 0.8950 (0.8910)	grad_norm 0.2606 (0.2639)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:13:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:00 lr 0.000023	 wd 0.0000	time 0.1575 (0.2184)	loss 0.9263 (0.8915)	grad_norm 0.2730 (0.2640)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:13:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:03:35 lr 0.000023	 wd 0.0000	time 0.1938 (0.2154)	loss 0.9883 (0.8911)	grad_norm 0.2646 (0.2640)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:13:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:13 lr 0.000023	 wd 0.0000	time 0.1345 (0.2149)	loss 0.9316 (0.8905)	grad_norm 0.2776 (0.2640)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:14:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:02:51 lr 0.000023	 wd 0.0000	time 0.1396 (0.2142)	loss 0.9805 (0.8905)	grad_norm 0.2615 (0.2640)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:14:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:28 lr 0.000023	 wd 0.0000	time 0.1676 (0.2117)	loss 0.8232 (0.8911)	grad_norm 0.2722 (0.2639)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:14:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:06 lr 0.000022	 wd 0.0000	time 0.1709 (0.2095)	loss 1.0127 (0.8918)	grad_norm 0.2669 (0.2640)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:14:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:01:44 lr 0.000022	 wd 0.0000	time 0.1685 (0.2077)	loss 0.9189 (0.8918)	grad_norm 0.2607 (nan)	loss_scale 32768.0000 (32800.7516)	mem 6174MB
[2024-07-30 01:15:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:23 lr 0.000022	 wd 0.0000	time 0.1711 (0.2070)	loss 0.9414 (0.8923)	grad_norm 0.2652 (nan)	loss_scale 32768.0000 (32799.1928)	mem 6174MB
[2024-07-30 01:15:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:02 lr 0.000022	 wd 0.0000	time 0.3827 (0.2082)	loss 0.9062 (0.8928)	grad_norm 0.2701 (nan)	loss_scale 32768.0000 (32797.7756)	mem 6174MB
[2024-07-30 01:15:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:41 lr 0.000022	 wd 0.0000	time 0.1764 (0.2068)	loss 0.8164 (0.8937)	grad_norm 0.2660 (nan)	loss_scale 32768.0000 (32796.4815)	mem 6174MB
[2024-07-30 01:16:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:20 lr 0.000022	 wd 0.0000	time 0.1945 (0.2055)	loss 0.8486 (0.8939)	grad_norm 0.2649 (nan)	loss_scale 32768.0000 (32795.2953)	mem 6174MB
[2024-07-30 01:16:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1282 (0.2031)	loss 0.7998 (0.8937)	grad_norm 0.2520 (nan)	loss_scale 32768.0000 (32794.2039)	mem 6174MB
[2024-07-30 01:16:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 20 training takes 0:08:35
[2024-07-30 01:17:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 37.646 (37.646)	Loss 0.3586 (0.3586)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 6174MB
[2024-07-30 01:17:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.914 Acc@5 97.486
[2024-07-30 01:17:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 01:17:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.91%
[2024-07-30 01:17:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-30 01:17:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-30 01:17:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][0/2502]	eta 11:25:09 lr 0.000021	 wd 0.0000	time 16.4305 (16.4305)	loss 0.9365 (0.9365)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:18:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:13:09 lr 0.000021	 wd 0.0000	time 0.1465 (0.3286)	loss 0.9160 (0.9056)	grad_norm 0.2652 (0.2650)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:18:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:10:46 lr 0.000021	 wd 0.0000	time 0.3651 (0.2808)	loss 0.9355 (0.8995)	grad_norm 0.2535 (0.2638)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:18:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:10:26 lr 0.000021	 wd 0.0000	time 0.1492 (0.2843)	loss 0.9360 (0.8972)	grad_norm 0.2634 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:19:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:08:55 lr 0.000021	 wd 0.0000	time 0.1637 (0.2548)	loss 1.0059 (0.8971)	grad_norm 0.2618 (0.2641)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:19:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:07:54 lr 0.000021	 wd 0.0000	time 0.1586 (0.2369)	loss 0.8257 (0.8973)	grad_norm 0.2610 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:19:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:07:08 lr 0.000020	 wd 0.0000	time 0.2437 (0.2251)	loss 0.9194 (0.8970)	grad_norm 0.2706 (0.2646)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:20:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:07:12 lr 0.000020	 wd 0.0000	time 0.3175 (0.2401)	loss 1.0186 (0.8971)	grad_norm 0.2687 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:20:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:06:38 lr 0.000020	 wd 0.0000	time 0.1562 (0.2340)	loss 0.9307 (0.8969)	grad_norm 0.2770 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:20:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:02 lr 0.000020	 wd 0.0000	time 0.1602 (0.2265)	loss 0.8496 (0.8978)	grad_norm 0.2568 (0.2642)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:21:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:05:30 lr 0.000020	 wd 0.0000	time 0.1636 (0.2202)	loss 0.8682 (0.8973)	grad_norm 0.2492 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:21:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:05:02 lr 0.000020	 wd 0.0000	time 0.2347 (0.2157)	loss 0.9258 (0.8978)	grad_norm 0.2569 (0.2642)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:22:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:04 lr 0.000019	 wd 0.0000	time 0.1437 (0.2339)	loss 0.8633 (0.8992)	grad_norm 0.2586 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:22:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:34 lr 0.000019	 wd 0.0000	time 0.1538 (0.2285)	loss 0.9517 (0.8987)	grad_norm 0.2487 (0.2642)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:22:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:06 lr 0.000019	 wd 0.0000	time 0.1532 (0.2239)	loss 0.9150 (0.8987)	grad_norm 0.2548 (0.2641)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:23:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:03:40 lr 0.000019	 wd 0.0000	time 0.1811 (0.2201)	loss 0.9478 (0.8985)	grad_norm 0.2547 (0.2641)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:23:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:17 lr 0.000019	 wd 0.0000	time 0.2468 (0.2193)	loss 0.9316 (0.8980)	grad_norm 0.2722 (0.2642)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:23:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:02:55 lr 0.000019	 wd 0.0000	time 0.1463 (0.2184)	loss 0.8916 (0.8985)	grad_norm 0.2569 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:24:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:31 lr 0.000018	 wd 0.0000	time 0.1629 (0.2157)	loss 0.8965 (0.8983)	grad_norm 0.2597 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:24:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:08 lr 0.000018	 wd 0.0000	time 0.2333 (0.2135)	loss 0.8955 (0.8984)	grad_norm 0.2616 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:24:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:46 lr 0.000018	 wd 0.0000	time 0.1990 (0.2113)	loss 0.7686 (0.8982)	grad_norm 0.2737 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:24:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:24 lr 0.000018	 wd 0.0000	time 0.1812 (0.2106)	loss 0.7847 (0.8977)	grad_norm 0.2559 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:25:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:03 lr 0.000018	 wd 0.0000	time 0.1777 (0.2110)	loss 0.8135 (0.8971)	grad_norm 0.2675 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:25:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:42 lr 0.000018	 wd 0.0000	time 0.1438 (0.2094)	loss 0.9424 (0.8971)	grad_norm 0.2604 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:25:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:21 lr 0.000018	 wd 0.0000	time 0.1793 (0.2078)	loss 0.8833 (0.8970)	grad_norm 0.2589 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:26:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000017	 wd 0.0000	time 0.1287 (0.2054)	loss 0.9170 (0.8973)	grad_norm 0.2465 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:26:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 21 training takes 0:08:41
[2024-07-30 01:26:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 39.988 (39.988)	Loss 0.3572 (0.3572)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 6174MB
[2024-07-30 01:27:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.902 Acc@5 97.486
[2024-07-30 01:27:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 01:27:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.91%
[2024-07-30 01:27:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][0/2502]	eta 11:41:15 lr 0.000017	 wd 0.0000	time 16.8168 (16.8168)	loss 0.8545 (0.8545)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:27:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:13:04 lr 0.000017	 wd 0.0000	time 0.1748 (0.3267)	loss 0.9224 (0.9017)	grad_norm 0.2648 (0.2635)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:28:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:11:13 lr 0.000017	 wd 0.0000	time 0.4891 (0.2926)	loss 0.8008 (0.8971)	grad_norm 0.2579 (0.2632)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:28:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:10:43 lr 0.000017	 wd 0.0000	time 0.1716 (0.2923)	loss 0.8887 (0.8961)	grad_norm 0.2651 (0.2638)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:28:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:09:08 lr 0.000017	 wd 0.0000	time 0.1906 (0.2609)	loss 0.8442 (0.9010)	grad_norm 0.2551 (0.2640)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:29:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:08:03 lr 0.000017	 wd 0.0000	time 0.1274 (0.2416)	loss 0.7158 (0.8990)	grad_norm 0.2552 (0.2637)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:29:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:07:17 lr 0.000016	 wd 0.0000	time 0.1758 (0.2302)	loss 0.9478 (0.9002)	grad_norm 0.2540 (0.2636)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:30:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:20 lr 0.000016	 wd 0.0000	time 0.2268 (0.2442)	loss 0.9951 (0.8988)	grad_norm 0.2541 (0.2639)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:30:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:06:39 lr 0.000016	 wd 0.0000	time 0.1502 (0.2349)	loss 0.9199 (0.8991)	grad_norm 0.2615 (0.2638)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:30:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:04 lr 0.000016	 wd 0.0000	time 0.1821 (0.2273)	loss 0.8643 (0.8989)	grad_norm 0.2591 (0.2640)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:30:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:05:31 lr 0.000016	 wd 0.0000	time 0.1679 (0.2208)	loss 0.9180 (0.8987)	grad_norm 0.2570 (nan)	loss_scale 32768.0000 (32833.4705)	mem 6174MB
[2024-07-30 01:31:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:05 lr 0.000016	 wd 0.0000	time 0.2606 (0.2179)	loss 0.8037 (0.8973)	grad_norm 0.2535 (nan)	loss_scale 32768.0000 (32827.5241)	mem 6174MB
[2024-07-30 01:31:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:04:55 lr 0.000016	 wd 0.0000	time 0.1479 (0.2268)	loss 0.8589 (0.8976)	grad_norm 0.2624 (nan)	loss_scale 32768.0000 (32822.5679)	mem 6174MB
[2024-07-30 01:32:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:04:27 lr 0.000015	 wd 0.0000	time 0.1935 (0.2221)	loss 0.8853 (0.8963)	grad_norm 0.2609 (nan)	loss_scale 32768.0000 (32818.3736)	mem 6174MB
[2024-07-30 01:32:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:00 lr 0.000015	 wd 0.0000	time 0.1705 (0.2181)	loss 0.8750 (0.8961)	grad_norm 0.2664 (nan)	loss_scale 32768.0000 (32814.7780)	mem 6174MB
[2024-07-30 01:32:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:03:34 lr 0.000015	 wd 0.0000	time 0.1502 (0.2145)	loss 0.6938 (0.8961)	grad_norm 0.2589 (nan)	loss_scale 32768.0000 (32811.6616)	mem 6174MB
[2024-07-30 01:32:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:12 lr 0.000015	 wd 0.0000	time 0.2563 (0.2136)	loss 0.8750 (0.8963)	grad_norm 0.2661 (nan)	loss_scale 32768.0000 (32808.9344)	mem 6174MB
[2024-07-30 01:33:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:02:51 lr 0.000015	 wd 0.0000	time 0.1373 (0.2139)	loss 0.9072 (0.8959)	grad_norm 0.2583 (nan)	loss_scale 32768.0000 (32806.5279)	mem 6174MB
[2024-07-30 01:33:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:28 lr 0.000015	 wd 0.0000	time 0.1457 (0.2116)	loss 0.9839 (0.8959)	grad_norm 0.2614 (nan)	loss_scale 32768.0000 (32804.3887)	mem 6174MB
[2024-07-30 01:33:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:06 lr 0.000015	 wd 0.0000	time 0.2108 (0.2095)	loss 0.9292 (0.8964)	grad_norm 0.2622 (nan)	loss_scale 32768.0000 (32802.4745)	mem 6174MB
[2024-07-30 01:34:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:44 lr 0.000014	 wd 0.0000	time 0.1474 (0.2076)	loss 0.9873 (0.8961)	grad_norm 0.2418 (nan)	loss_scale 32768.0000 (32800.7516)	mem 6174MB
[2024-07-30 01:34:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:23 lr 0.000014	 wd 0.0000	time 0.1728 (0.2067)	loss 0.8354 (0.8965)	grad_norm 0.2665 (nan)	loss_scale 32768.0000 (32799.1928)	mem 6174MB
[2024-07-30 01:34:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:02 lr 0.000014	 wd 0.0000	time 0.1477 (0.2074)	loss 0.6987 (0.8964)	grad_norm 0.2643 (nan)	loss_scale 32768.0000 (32797.7756)	mem 6174MB
[2024-07-30 01:35:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:41 lr 0.000014	 wd 0.0000	time 0.1683 (0.2065)	loss 0.9531 (0.8964)	grad_norm 0.2618 (nan)	loss_scale 32768.0000 (32796.4815)	mem 6174MB
[2024-07-30 01:35:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:20 lr 0.000014	 wd 0.0000	time 0.1400 (0.2050)	loss 0.7832 (0.8966)	grad_norm 0.2672 (nan)	loss_scale 32768.0000 (32795.2953)	mem 6174MB
[2024-07-30 01:35:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1305 (0.2028)	loss 0.8560 (0.8961)	grad_norm 0.2695 (nan)	loss_scale 32768.0000 (32794.2039)	mem 6174MB
[2024-07-30 01:35:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 22 training takes 0:08:35
[2024-07-30 01:36:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 40.819 (40.819)	Loss 0.3577 (0.3577)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 6174MB
[2024-07-30 01:36:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.902 Acc@5 97.490
[2024-07-30 01:36:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 01:36:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.91%
[2024-07-30 01:37:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][0/2502]	eta 12:00:24 lr 0.000014	 wd 0.0000	time 17.2762 (17.2762)	loss 0.7769 (0.7769)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:37:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:13:23 lr 0.000014	 wd 0.0000	time 0.1600 (0.3343)	loss 0.8784 (0.8941)	grad_norm 0.2659 (0.2647)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:37:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:10:09 lr 0.000013	 wd 0.0000	time 0.2538 (0.2647)	loss 0.9570 (0.8915)	grad_norm 0.2770 (0.2641)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:38:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:10:12 lr 0.000013	 wd 0.0000	time 0.1592 (0.2780)	loss 0.7949 (0.8902)	grad_norm 0.2576 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:38:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:08:45 lr 0.000013	 wd 0.0000	time 0.1616 (0.2500)	loss 1.0078 (0.8923)	grad_norm 0.2608 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:38:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:07:46 lr 0.000013	 wd 0.0000	time 0.1465 (0.2331)	loss 0.9160 (0.8965)	grad_norm 0.2543 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:39:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:07:00 lr 0.000013	 wd 0.0000	time 0.1749 (0.2212)	loss 0.9048 (0.8975)	grad_norm 0.2619 (0.2646)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:39:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:06:43 lr 0.000013	 wd 0.0000	time 0.3596 (0.2239)	loss 0.9756 (0.8981)	grad_norm 0.2561 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:39:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:06:33 lr 0.000013	 wd 0.0000	time 0.2115 (0.2315)	loss 0.9990 (0.8977)	grad_norm 0.2627 (0.2642)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:40:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:05:59 lr 0.000012	 wd 0.0000	time 0.1768 (0.2242)	loss 1.1250 (0.8961)	grad_norm 0.2679 (0.2642)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:40:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:05:28 lr 0.000012	 wd 0.0000	time 0.1626 (0.2186)	loss 0.7573 (0.8964)	grad_norm 0.2637 (0.2642)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:40:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:04:59 lr 0.000012	 wd 0.0000	time 0.1550 (0.2138)	loss 0.7554 (0.8955)	grad_norm 0.2731 (0.2642)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:41:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:04:49 lr 0.000012	 wd 0.0000	time 0.2070 (0.2225)	loss 0.9429 (0.8959)	grad_norm 0.2525 (0.2642)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:41:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:04:22 lr 0.000012	 wd 0.0000	time 0.1634 (0.2183)	loss 0.9639 (0.8959)	grad_norm 0.2730 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:41:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:03:56 lr 0.000012	 wd 0.0000	time 0.1404 (0.2145)	loss 0.9585 (0.8963)	grad_norm 0.2685 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:42:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:03:31 lr 0.000012	 wd 0.0000	time 0.1559 (0.2113)	loss 0.7793 (0.8970)	grad_norm 0.2686 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:42:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:08 lr 0.000012	 wd 0.0000	time 0.1881 (0.2092)	loss 0.9004 (0.8970)	grad_norm 0.2520 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:42:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:02:49 lr 0.000011	 wd 0.0000	time 0.1470 (0.2112)	loss 0.7969 (0.8968)	grad_norm 0.2673 (0.2646)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:43:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:27 lr 0.000011	 wd 0.0000	time 0.1630 (0.2095)	loss 0.9170 (0.8971)	grad_norm 0.2640 (0.2646)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:43:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:04 lr 0.000011	 wd 0.0000	time 0.1676 (0.2075)	loss 0.8140 (0.8967)	grad_norm 0.2616 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:43:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:01:43 lr 0.000011	 wd 0.0000	time 0.1628 (0.2058)	loss 0.9863 (0.8965)	grad_norm 0.2671 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:43:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:22 lr 0.000011	 wd 0.0000	time 0.1928 (0.2043)	loss 1.0352 (0.8965)	grad_norm 0.2503 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:44:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:01 lr 0.000011	 wd 0.0000	time 0.2038 (0.2042)	loss 0.9805 (0.8960)	grad_norm 0.2721 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:44:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:41 lr 0.000011	 wd 0.0000	time 0.1835 (0.2045)	loss 0.9043 (0.8962)	grad_norm 0.2602 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:44:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:20 lr 0.000011	 wd 0.0000	time 0.1556 (0.2032)	loss 0.8945 (0.8963)	grad_norm 0.2604 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:45:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1281 (0.2011)	loss 0.8159 (0.8961)	grad_norm 0.2652 (nan)	loss_scale 32768.0000 (32794.2039)	mem 6174MB
[2024-07-30 01:45:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 23 training takes 0:08:28
[2024-07-30 01:45:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 23.954 (23.954)	Loss 0.3572 (0.3572)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 6174MB
[2024-07-30 01:46:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.916 Acc@5 97.490
[2024-07-30 01:46:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 01:46:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.92%
[2024-07-30 01:46:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-30 01:46:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-30 01:46:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][0/2502]	eta 12:37:08 lr 0.000010	 wd 0.0000	time 18.1568 (18.1568)	loss 0.9268 (0.9268)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:46:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:13:52 lr 0.000010	 wd 0.0000	time 0.1668 (0.3468)	loss 1.0156 (0.8929)	grad_norm 0.2494 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:47:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:09:51 lr 0.000010	 wd 0.0000	time 0.1557 (0.2569)	loss 0.8926 (0.8947)	grad_norm 0.2636 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:47:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:10:21 lr 0.000010	 wd 0.0000	time 2.0654 (0.2823)	loss 0.8354 (0.8976)	grad_norm 0.2797 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:48:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:09:28 lr 0.000010	 wd 0.0000	time 0.1668 (0.2705)	loss 0.7524 (0.8989)	grad_norm 0.2626 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:48:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:08:20 lr 0.000010	 wd 0.0000	time 0.1831 (0.2498)	loss 0.9209 (0.9009)	grad_norm 0.2826 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:48:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:07:27 lr 0.000010	 wd 0.0000	time 0.1358 (0.2353)	loss 0.9272 (0.8984)	grad_norm 0.2573 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:48:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:06:52 lr 0.000010	 wd 0.0000	time 0.2546 (0.2288)	loss 0.8535 (0.8973)	grad_norm 0.2633 (0.2646)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:49:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:07:04 lr 0.000010	 wd 0.0000	time 0.1867 (0.2492)	loss 0.8203 (0.8964)	grad_norm 0.2745 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:49:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:06:24 lr 0.000009	 wd 0.0000	time 0.1987 (0.2398)	loss 0.9336 (0.8970)	grad_norm 0.2689 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:50:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:05:49 lr 0.000009	 wd 0.0000	time 0.1463 (0.2326)	loss 0.8447 (0.8978)	grad_norm 0.2692 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:50:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:05:17 lr 0.000009	 wd 0.0000	time 0.1794 (0.2266)	loss 0.8545 (0.8976)	grad_norm 0.2659 (0.2646)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:50:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:05 lr 0.000009	 wd 0.0000	time 0.1719 (0.2344)	loss 0.8540 (0.8973)	grad_norm 0.2412 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:51:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:04:35 lr 0.000009	 wd 0.0000	time 0.1630 (0.2293)	loss 0.7510 (0.8958)	grad_norm 0.2676 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:51:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:07 lr 0.000009	 wd 0.0000	time 0.1974 (0.2245)	loss 0.7964 (0.8961)	grad_norm 0.2586 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:51:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:03:41 lr 0.000009	 wd 0.0000	time 0.1691 (0.2208)	loss 0.8354 (0.8960)	grad_norm 0.2636 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:52:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:16 lr 0.000009	 wd 0.0000	time 0.2227 (0.2181)	loss 0.9219 (0.8959)	grad_norm 0.2576 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:52:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:02:54 lr 0.000008	 wd 0.0000	time 0.1360 (0.2181)	loss 0.9971 (0.8964)	grad_norm 0.2667 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:52:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:31 lr 0.000008	 wd 0.0000	time 0.1751 (0.2160)	loss 0.8042 (0.8968)	grad_norm 0.2516 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:53:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:08 lr 0.000008	 wd 0.0000	time 0.1502 (0.2137)	loss 0.7622 (0.8964)	grad_norm 0.2556 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:53:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:01:46 lr 0.000008	 wd 0.0000	time 0.2062 (0.2117)	loss 0.7339 (0.8964)	grad_norm 0.2623 (0.2646)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:53:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:24 lr 0.000008	 wd 0.0000	time 0.1997 (0.2098)	loss 0.9956 (0.8961)	grad_norm 0.2622 (0.2646)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:53:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:03 lr 0.000008	 wd 0.0000	time 0.1777 (0.2092)	loss 0.8745 (0.8960)	grad_norm 0.2627 (0.2646)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:54:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:42 lr 0.000008	 wd 0.0000	time 0.1713 (0.2093)	loss 0.9556 (0.8963)	grad_norm 0.2595 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:54:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:21 lr 0.000008	 wd 0.0000	time 0.1322 (0.2078)	loss 1.0986 (0.8962)	grad_norm 0.2592 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:54:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1284 (0.2055)	loss 0.9985 (0.8961)	grad_norm 0.2576 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:54:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 24 training takes 0:08:42
[2024-07-30 01:55:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 35.555 (35.555)	Loss 0.3582 (0.3582)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 6174MB
[2024-07-30 01:55:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.900 Acc@5 97.496
[2024-07-30 01:55:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 01:55:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.92%
[2024-07-30 01:56:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][0/2502]	eta 12:27:03 lr 0.000008	 wd 0.0000	time 17.9152 (17.9152)	loss 0.8750 (0.8750)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:56:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:13:37 lr 0.000008	 wd 0.0000	time 0.1699 (0.3405)	loss 0.8638 (0.9115)	grad_norm 0.2534 (0.2650)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:56:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:09:46 lr 0.000007	 wd 0.0000	time 0.2019 (0.2548)	loss 0.8594 (0.9079)	grad_norm 0.2642 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:57:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:10:35 lr 0.000007	 wd 0.0000	time 0.2066 (0.2886)	loss 0.9272 (0.9002)	grad_norm 0.2683 (0.2646)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:57:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:09:15 lr 0.000007	 wd 0.0000	time 0.1655 (0.2644)	loss 0.7671 (0.9011)	grad_norm 0.2689 (0.2647)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:58:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:08:10 lr 0.000007	 wd 0.0000	time 0.1701 (0.2448)	loss 0.8755 (0.9005)	grad_norm 0.2487 (0.2646)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:58:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:07:19 lr 0.000007	 wd 0.0000	time 0.1433 (0.2310)	loss 0.7715 (0.8999)	grad_norm 0.2738 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:58:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:06:44 lr 0.000007	 wd 0.0000	time 0.2297 (0.2243)	loss 0.8516 (0.8991)	grad_norm 0.2678 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:59:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:06:39 lr 0.000007	 wd 0.0000	time 0.1841 (0.2344)	loss 0.9868 (0.8986)	grad_norm 0.2655 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:59:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:06:03 lr 0.000007	 wd 0.0000	time 0.1594 (0.2267)	loss 0.7275 (0.8984)	grad_norm 0.2623 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:59:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:05:31 lr 0.000007	 wd 0.0000	time 0.1301 (0.2204)	loss 0.9785 (0.8987)	grad_norm 0.2776 (0.2646)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 01:59:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:01 lr 0.000007	 wd 0.0000	time 0.1381 (0.2153)	loss 1.0430 (0.8981)	grad_norm 0.2644 (0.2646)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:00:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:04:40 lr 0.000006	 wd 0.0000	time 0.4772 (0.2156)	loss 1.0234 (0.8992)	grad_norm 0.2651 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:00:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:04:27 lr 0.000006	 wd 0.0000	time 0.1623 (0.2225)	loss 0.8965 (0.8983)	grad_norm 0.2552 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:01:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:00 lr 0.000006	 wd 0.0000	time 0.1389 (0.2184)	loss 0.9370 (0.8979)	grad_norm 0.2533 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:01:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:03:35 lr 0.000006	 wd 0.0000	time 0.1645 (0.2149)	loss 1.0020 (0.8987)	grad_norm 0.2606 (nan)	loss_scale 32768.0000 (32811.6616)	mem 6174MB
[2024-07-30 02:01:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:11 lr 0.000006	 wd 0.0000	time 0.1789 (0.2119)	loss 0.7705 (0.8983)	grad_norm 0.2555 (nan)	loss_scale 32768.0000 (32808.9344)	mem 6174MB
[2024-07-30 02:02:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:02:55 lr 0.000006	 wd 0.0000	time 0.2068 (0.2183)	loss 0.8491 (0.8991)	grad_norm 0.2583 (nan)	loss_scale 32768.0000 (32806.5279)	mem 6174MB
[2024-07-30 02:02:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:31 lr 0.000006	 wd 0.0000	time 0.1724 (0.2159)	loss 0.9272 (0.8986)	grad_norm 0.2607 (nan)	loss_scale 32768.0000 (32804.3887)	mem 6174MB
[2024-07-30 02:02:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:08 lr 0.000006	 wd 0.0000	time 0.1782 (0.2134)	loss 1.0449 (0.8986)	grad_norm 0.2637 (nan)	loss_scale 32768.0000 (32802.4745)	mem 6174MB
[2024-07-30 02:03:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:01:46 lr 0.000006	 wd 0.0000	time 0.1614 (0.2114)	loss 1.0352 (0.8986)	grad_norm 0.2620 (nan)	loss_scale 32768.0000 (32800.7516)	mem 6174MB
[2024-07-30 02:03:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:24 lr 0.000006	 wd 0.0000	time 0.1822 (0.2098)	loss 0.9160 (0.8980)	grad_norm 0.2584 (nan)	loss_scale 32768.0000 (32799.1928)	mem 6174MB
[2024-07-30 02:03:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:03 lr 0.000006	 wd 0.0000	time 0.1294 (0.2103)	loss 0.8403 (0.8976)	grad_norm 0.2467 (nan)	loss_scale 32768.0000 (32797.7756)	mem 6174MB
[2024-07-30 02:04:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:42 lr 0.000005	 wd 0.0000	time 0.1655 (0.2093)	loss 0.7891 (0.8974)	grad_norm 0.2576 (nan)	loss_scale 32768.0000 (32796.4815)	mem 6174MB
[2024-07-30 02:04:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:21 lr 0.000005	 wd 0.0000	time 0.1517 (0.2077)	loss 0.8579 (0.8974)	grad_norm 0.2512 (nan)	loss_scale 32768.0000 (32795.2953)	mem 6174MB
[2024-07-30 02:04:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000005	 wd 0.0000	time 0.1279 (0.2054)	loss 0.8770 (0.8977)	grad_norm 0.2677 (nan)	loss_scale 32768.0000 (32794.2039)	mem 6174MB
[2024-07-30 02:04:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 25 training takes 0:08:40
[2024-07-30 02:05:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 28.173 (28.173)	Loss 0.3577 (0.3577)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 6174MB
[2024-07-30 02:05:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.904 Acc@5 97.494
[2024-07-30 02:05:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 02:05:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.92%
[2024-07-30 02:05:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][0/2502]	eta 12:24:13 lr 0.000005	 wd 0.0000	time 17.8473 (17.8473)	loss 1.0332 (1.0332)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:06:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:13:46 lr 0.000005	 wd 0.0000	time 0.1696 (0.3440)	loss 0.7983 (0.9063)	grad_norm 0.2632 (0.2669)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:06:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:09:47 lr 0.000005	 wd 0.0000	time 0.1376 (0.2554)	loss 0.8931 (0.9032)	grad_norm 0.2670 (0.2659)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:06:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:09:10 lr 0.000005	 wd 0.0000	time 0.3237 (0.2500)	loss 0.8716 (0.9037)	grad_norm 0.2775 (0.2658)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:07:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:09:05 lr 0.000005	 wd 0.0000	time 0.1796 (0.2596)	loss 0.9141 (0.9017)	grad_norm 0.2765 (0.2653)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:07:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:08:02 lr 0.000005	 wd 0.0000	time 0.1477 (0.2412)	loss 0.8535 (0.8997)	grad_norm 0.2518 (0.2650)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:07:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:07:14 lr 0.000005	 wd 0.0000	time 0.1487 (0.2287)	loss 0.8774 (0.9004)	grad_norm 0.2653 (0.2651)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:08:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:06:35 lr 0.000005	 wd 0.0000	time 0.1939 (0.2196)	loss 0.8516 (0.8981)	grad_norm 0.2612 (0.2650)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:08:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:06:39 lr 0.000005	 wd 0.0000	time 0.2033 (0.2347)	loss 0.8901 (0.8992)	grad_norm 0.2742 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:08:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:06:05 lr 0.000005	 wd 0.0000	time 0.1557 (0.2280)	loss 0.7861 (0.8977)	grad_norm 0.2688 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:09:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:05:33 lr 0.000004	 wd 0.0000	time 0.1495 (0.2218)	loss 0.9487 (0.8980)	grad_norm 0.2602 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:09:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:03 lr 0.000004	 wd 0.0000	time 0.1374 (0.2164)	loss 0.9897 (0.8988)	grad_norm 0.2603 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:09:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:04:37 lr 0.000004	 wd 0.0000	time 0.2626 (0.2135)	loss 0.9326 (0.8985)	grad_norm 0.2555 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:10:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:04:30 lr 0.000004	 wd 0.0000	time 0.1411 (0.2247)	loss 0.7837 (0.8989)	grad_norm 0.2674 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:10:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:02 lr 0.000004	 wd 0.0000	time 0.1620 (0.2204)	loss 0.9819 (0.8985)	grad_norm 0.2569 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:10:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:03:37 lr 0.000004	 wd 0.0000	time 0.1445 (0.2168)	loss 0.8750 (0.8988)	grad_norm 0.2548 (0.2650)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:11:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:12 lr 0.000004	 wd 0.0000	time 0.1674 (0.2136)	loss 0.7563 (0.8978)	grad_norm 0.2561 (0.2650)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:11:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:02:50 lr 0.000004	 wd 0.0000	time 0.2684 (0.2128)	loss 0.8652 (0.8985)	grad_norm 0.2626 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:11:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:29 lr 0.000004	 wd 0.0000	time 0.1583 (0.2130)	loss 0.9331 (0.8989)	grad_norm 0.2609 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:12:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:07 lr 0.000004	 wd 0.0000	time 0.1617 (0.2111)	loss 0.9014 (0.8983)	grad_norm 0.2659 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:12:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:01:45 lr 0.000004	 wd 0.0000	time 0.2030 (0.2092)	loss 0.9424 (0.8982)	grad_norm 0.2654 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:12:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:23 lr 0.000004	 wd 0.0000	time 0.1508 (0.2073)	loss 0.9121 (0.8984)	grad_norm 0.2741 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:13:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:02 lr 0.000004	 wd 0.0000	time 0.2280 (0.2066)	loss 0.9507 (0.8983)	grad_norm 0.2669 (0.2647)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:13:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:41 lr 0.000004	 wd 0.0000	time 0.1863 (0.2071)	loss 0.8667 (0.8980)	grad_norm 0.2698 (0.2647)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:13:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:21 lr 0.000003	 wd 0.0000	time 0.1669 (0.2060)	loss 0.8926 (0.8984)	grad_norm 0.2723 (0.2647)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:14:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1286 (0.2037)	loss 0.9521 (0.8984)	grad_norm 0.2630 (0.2647)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:14:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 26 training takes 0:08:37
[2024-07-30 02:14:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 19.369 (19.369)	Loss 0.3577 (0.3577)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 6174MB
[2024-07-30 02:14:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.906 Acc@5 97.494
[2024-07-30 02:14:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 02:14:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.92%
[2024-07-30 02:15:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][0/2502]	eta 1 day, 5:12:15 lr 0.000003	 wd 0.0000	time 42.0206 (42.0206)	loss 0.9497 (0.9497)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:15:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:23:17 lr 0.000003	 wd 0.0000	time 0.1961 (0.5820)	loss 0.9185 (0.9039)	grad_norm 0.2589 (0.2635)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:16:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:14:20 lr 0.000003	 wd 0.0000	time 0.1539 (0.3738)	loss 0.7290 (0.8977)	grad_norm 0.2716 (0.2636)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:16:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:11:56 lr 0.000003	 wd 0.0000	time 0.3316 (0.3256)	loss 0.9155 (0.8983)	grad_norm 0.2700 (0.2640)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:17:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:11:41 lr 0.000003	 wd 0.0000	time 0.1749 (0.3336)	loss 0.8394 (0.8972)	grad_norm 0.2643 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:17:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:10:01 lr 0.000003	 wd 0.0000	time 0.1724 (0.3004)	loss 0.7856 (0.8966)	grad_norm 0.2765 (nan)	loss_scale 32768.0000 (32898.8104)	mem 6174MB
[2024-07-30 02:17:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:48 lr 0.000003	 wd 0.0000	time 0.1487 (0.2777)	loss 0.8257 (0.8987)	grad_norm 0.2771 (nan)	loss_scale 32768.0000 (32877.0449)	mem 6174MB
[2024-07-30 02:17:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:53 lr 0.000003	 wd 0.0000	time 0.2051 (0.2629)	loss 0.8276 (0.8981)	grad_norm 0.2753 (nan)	loss_scale 32768.0000 (32861.4893)	mem 6174MB
[2024-07-30 02:18:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:44 lr 0.000003	 wd 0.0000	time 0.1830 (0.2728)	loss 0.9136 (0.8972)	grad_norm 0.2526 (nan)	loss_scale 32768.0000 (32849.8177)	mem 6174MB
[2024-07-30 02:18:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:58 lr 0.000003	 wd 0.0000	time 0.1505 (0.2615)	loss 0.7808 (0.8967)	grad_norm 0.2573 (nan)	loss_scale 32768.0000 (32840.7370)	mem 6174MB
[2024-07-30 02:19:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:18 lr 0.000003	 wd 0.0000	time 0.1514 (0.2519)	loss 0.9102 (0.8962)	grad_norm 0.2578 (nan)	loss_scale 32768.0000 (32833.4705)	mem 6174MB
[2024-07-30 02:19:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:41 lr 0.000003	 wd 0.0000	time 0.1382 (0.2438)	loss 0.7866 (0.8961)	grad_norm 0.2673 (nan)	loss_scale 32768.0000 (32827.5241)	mem 6174MB
[2024-07-30 02:19:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:12 lr 0.000003	 wd 0.0000	time 0.2243 (0.2396)	loss 0.9058 (0.8953)	grad_norm 0.2651 (nan)	loss_scale 32768.0000 (32822.5679)	mem 6174MB
[2024-07-30 02:20:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:51 lr 0.000003	 wd 0.0000	time 0.1745 (0.2423)	loss 0.8535 (0.8954)	grad_norm 0.2637 (nan)	loss_scale 32768.0000 (32818.3736)	mem 6174MB
[2024-07-30 02:20:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:20 lr 0.000003	 wd 0.0000	time 0.1629 (0.2368)	loss 0.8208 (0.8954)	grad_norm 0.2609 (nan)	loss_scale 32768.0000 (32814.7780)	mem 6174MB
[2024-07-30 02:20:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:03:52 lr 0.000003	 wd 0.0000	time 0.1667 (0.2322)	loss 0.9971 (0.8954)	grad_norm 0.2616 (nan)	loss_scale 32768.0000 (32811.6616)	mem 6174MB
[2024-07-30 02:20:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:25 lr 0.000003	 wd 0.0000	time 0.1656 (0.2281)	loss 0.9077 (0.8956)	grad_norm 0.2594 (nan)	loss_scale 32768.0000 (32808.9344)	mem 6174MB
[2024-07-30 02:21:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:00 lr 0.000002	 wd 0.0000	time 0.2010 (0.2254)	loss 0.8843 (0.8957)	grad_norm 0.2674 (nan)	loss_scale 32768.0000 (32806.5279)	mem 6174MB
[2024-07-30 02:21:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:38 lr 0.000002	 wd 0.0000	time 0.1706 (0.2253)	loss 0.7939 (0.8962)	grad_norm 0.2648 (nan)	loss_scale 32768.0000 (32804.3887)	mem 6174MB
[2024-07-30 02:21:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:14 lr 0.000002	 wd 0.0000	time 0.1364 (0.2231)	loss 0.8247 (0.8963)	grad_norm 0.2639 (nan)	loss_scale 32768.0000 (32802.4745)	mem 6174MB
[2024-07-30 02:22:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:50 lr 0.000002	 wd 0.0000	time 0.1700 (0.2206)	loss 0.7637 (0.8959)	grad_norm 0.2603 (nan)	loss_scale 32768.0000 (32800.7516)	mem 6174MB
[2024-07-30 02:22:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:27 lr 0.000002	 wd 0.0000	time 0.1470 (0.2183)	loss 1.0391 (0.8969)	grad_norm 0.2810 (nan)	loss_scale 32768.0000 (32799.1928)	mem 6174MB
[2024-07-30 02:22:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:05 lr 0.000002	 wd 0.0000	time 0.2073 (0.2166)	loss 0.7422 (0.8964)	grad_norm 0.2570 (nan)	loss_scale 32768.0000 (32797.7756)	mem 6174MB
[2024-07-30 02:23:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:43 lr 0.000002	 wd 0.0000	time 0.1789 (0.2167)	loss 0.8501 (0.8967)	grad_norm 0.2704 (nan)	loss_scale 32768.0000 (32796.4815)	mem 6174MB
[2024-07-30 02:23:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:21 lr 0.000002	 wd 0.0000	time 0.1694 (0.2152)	loss 0.9067 (0.8963)	grad_norm 0.2740 (nan)	loss_scale 32768.0000 (32795.2953)	mem 6174MB
[2024-07-30 02:23:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1280 (0.2124)	loss 0.8911 (0.8965)	grad_norm 0.2573 (nan)	loss_scale 32768.0000 (32794.2039)	mem 6174MB
[2024-07-30 02:23:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 27 training takes 0:08:59
[2024-07-30 02:24:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 18.737 (18.737)	Loss 0.3577 (0.3577)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 6174MB
[2024-07-30 02:24:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.912 Acc@5 97.492
[2024-07-30 02:24:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 02:24:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.92%
[2024-07-30 02:25:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][0/2502]	eta 1 day, 1:05:06 lr 0.000002	 wd 0.0000	time 36.0935 (36.0935)	loss 0.8569 (0.8569)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:25:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:21:24 lr 0.000002	 wd 0.0000	time 0.1472 (0.5349)	loss 0.9019 (0.8899)	grad_norm 0.2698 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:25:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:13:26 lr 0.000002	 wd 0.0000	time 0.1708 (0.3504)	loss 0.8818 (0.8973)	grad_norm 0.2710 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:25:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:10:36 lr 0.000002	 wd 0.0000	time 0.1625 (0.2890)	loss 0.9863 (0.8998)	grad_norm 0.2605 (0.2647)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:26:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:10:58 lr 0.000002	 wd 0.0000	time 0.1431 (0.3133)	loss 0.7993 (0.8949)	grad_norm 0.2611 (0.2647)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:26:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:09:32 lr 0.000002	 wd 0.0000	time 0.1530 (0.2862)	loss 0.8862 (0.8972)	grad_norm 0.2595 (0.2650)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:27:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:26 lr 0.000002	 wd 0.0000	time 0.1473 (0.2663)	loss 0.9360 (0.8983)	grad_norm 0.2666 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:27:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:33 lr 0.000002	 wd 0.0000	time 0.1594 (0.2517)	loss 0.8760 (0.8975)	grad_norm 0.2667 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:27:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:06:54 lr 0.000002	 wd 0.0000	time 0.2503 (0.2438)	loss 0.8721 (0.8984)	grad_norm 0.2653 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:28:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:34 lr 0.000002	 wd 0.0000	time 0.1606 (0.2463)	loss 0.8481 (0.8982)	grad_norm 0.2676 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:28:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:05:58 lr 0.000002	 wd 0.0000	time 0.1822 (0.2384)	loss 0.8843 (0.8980)	grad_norm 0.2546 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:28:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:24 lr 0.000002	 wd 0.0000	time 0.1883 (0.2318)	loss 0.8281 (0.8964)	grad_norm 0.2674 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:28:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:04:54 lr 0.000002	 wd 0.0000	time 0.1461 (0.2265)	loss 0.9019 (0.8965)	grad_norm 0.2705 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:29:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:04:28 lr 0.000002	 wd 0.0000	time 0.2162 (0.2230)	loss 0.9883 (0.8970)	grad_norm 0.2735 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:29:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:12 lr 0.000002	 wd 0.0000	time 0.1788 (0.2290)	loss 0.8062 (0.8962)	grad_norm 0.2623 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:30:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:03:45 lr 0.000002	 wd 0.0000	time 0.1613 (0.2248)	loss 0.7876 (0.8964)	grad_norm 0.2761 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:30:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:19 lr 0.000002	 wd 0.0000	time 0.1813 (0.2211)	loss 1.0391 (0.8967)	grad_norm 0.2775 (0.2647)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:30:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:02:54 lr 0.000001	 wd 0.0000	time 0.1641 (0.2179)	loss 0.9468 (0.8967)	grad_norm 0.2742 (0.2647)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:30:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:31 lr 0.000001	 wd 0.0000	time 0.2222 (0.2164)	loss 0.7856 (0.8963)	grad_norm 0.2713 (0.2647)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:31:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:10 lr 0.000001	 wd 0.0000	time 0.2927 (0.2163)	loss 0.8994 (0.8971)	grad_norm 0.2676 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:31:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:01:47 lr 0.000001	 wd 0.0000	time 0.1787 (0.2147)	loss 0.8237 (0.8962)	grad_norm 0.2602 (nan)	loss_scale 32768.0000 (32800.7516)	mem 6174MB
[2024-07-30 02:31:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:25 lr 0.000001	 wd 0.0000	time 0.1683 (0.2128)	loss 0.8569 (0.8960)	grad_norm 0.2729 (nan)	loss_scale 32768.0000 (32799.1928)	mem 6174MB
[2024-07-30 02:32:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:03 lr 0.000001	 wd 0.0000	time 0.1893 (0.2108)	loss 0.9082 (0.8955)	grad_norm 0.2675 (nan)	loss_scale 32768.0000 (32797.7756)	mem 6174MB
[2024-07-30 02:32:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:42 lr 0.000001	 wd 0.0000	time 0.2092 (0.2098)	loss 0.8047 (0.8953)	grad_norm 0.2628 (nan)	loss_scale 32768.0000 (32796.4815)	mem 6174MB
[2024-07-30 02:32:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:21 lr 0.000001	 wd 0.0000	time 0.1764 (0.2099)	loss 0.9810 (0.8949)	grad_norm 0.2665 (nan)	loss_scale 32768.0000 (32795.2953)	mem 6174MB
[2024-07-30 02:33:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1283 (0.2078)	loss 0.8755 (0.8950)	grad_norm 0.2512 (nan)	loss_scale 32768.0000 (32794.2039)	mem 6174MB
[2024-07-30 02:33:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 28 training takes 0:08:49
[2024-07-30 02:33:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 19.821 (19.821)	Loss 0.3579 (0.3579)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 6174MB
[2024-07-30 02:33:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.918 Acc@5 97.492
[2024-07-30 02:33:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 02:33:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.92%
[2024-07-30 02:33:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saving......
[2024-07-30 02:33:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_best.pth saved !!!
[2024-07-30 02:34:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][0/2502]	eta 22:48:14 lr 0.000001	 wd 0.0000	time 32.8116 (32.8116)	loss 0.9653 (0.9653)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:34:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:20:01 lr 0.000001	 wd 0.0000	time 0.1769 (0.5004)	loss 0.8701 (0.9046)	grad_norm 0.2779 (0.2654)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:35:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:12:45 lr 0.000001	 wd 0.0000	time 0.1441 (0.3325)	loss 0.9106 (0.9047)	grad_norm 0.2752 (0.2652)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:35:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:10:09 lr 0.000001	 wd 0.0000	time 0.1579 (0.2770)	loss 0.8564 (0.9044)	grad_norm 0.2655 (0.2646)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:35:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:08:45 lr 0.000001	 wd 0.0000	time 0.1792 (0.2499)	loss 0.8687 (0.9036)	grad_norm 0.2612 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:36:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:09:23 lr 0.000001	 wd 0.0000	time 0.2140 (0.2813)	loss 0.8501 (0.9032)	grad_norm 0.2724 (0.2653)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:36:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:20 lr 0.000001	 wd 0.0000	time 0.1937 (0.2631)	loss 0.7627 (0.9021)	grad_norm 0.2690 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:36:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:29 lr 0.000001	 wd 0.0000	time 0.1666 (0.2494)	loss 0.8677 (0.9010)	grad_norm 0.2588 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:37:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:06:46 lr 0.000001	 wd 0.0000	time 0.1464 (0.2386)	loss 0.8350 (0.9013)	grad_norm 0.2566 (0.2650)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:37:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:06:18 lr 0.000001	 wd 0.0000	time 0.4073 (0.2362)	loss 0.8701 (0.9015)	grad_norm 0.2755 (0.2650)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:37:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:00 lr 0.000001	 wd 0.0000	time 0.1854 (0.2399)	loss 0.8452 (0.9016)	grad_norm 0.2662 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:38:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:26 lr 0.000001	 wd 0.0000	time 0.1770 (0.2331)	loss 1.0391 (0.9011)	grad_norm 0.2555 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:38:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:04:55 lr 0.000001	 wd 0.0000	time 0.1624 (0.2273)	loss 0.7690 (0.8999)	grad_norm 0.2654 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:38:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:04:27 lr 0.000001	 wd 0.0000	time 0.1652 (0.2226)	loss 0.9077 (0.8999)	grad_norm 0.2645 (0.2650)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:39:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:06 lr 0.000001	 wd 0.0000	time 0.3581 (0.2237)	loss 0.9902 (0.8997)	grad_norm 0.2741 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:39:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:03:46 lr 0.000001	 wd 0.0000	time 0.1740 (0.2263)	loss 0.8267 (0.8983)	grad_norm 0.2676 (0.2650)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:39:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:20 lr 0.000001	 wd 0.0000	time 0.1353 (0.2224)	loss 0.9331 (0.8977)	grad_norm 0.2602 (0.2650)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:40:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:02:55 lr 0.000001	 wd 0.0000	time 0.1562 (0.2192)	loss 0.9385 (0.8968)	grad_norm 0.2737 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:40:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:32 lr 0.000001	 wd 0.0000	time 0.1743 (0.2166)	loss 0.7998 (0.8962)	grad_norm 0.2520 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:40:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:09 lr 0.000001	 wd 0.0000	time 0.1767 (0.2154)	loss 0.7456 (0.8963)	grad_norm 0.2653 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:41:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:01:48 lr 0.000001	 wd 0.0000	time 0.2750 (0.2158)	loss 0.8594 (0.8966)	grad_norm 0.2662 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:41:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:25 lr 0.000001	 wd 0.0000	time 0.2578 (0.2137)	loss 0.8242 (0.8968)	grad_norm 0.2503 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:41:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:03 lr 0.000001	 wd 0.0000	time 0.1431 (0.2118)	loss 0.7729 (0.8962)	grad_norm 0.2634 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:41:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:42 lr 0.000001	 wd 0.0000	time 0.1867 (0.2101)	loss 0.7363 (0.8965)	grad_norm 0.2712 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:42:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:21 lr 0.000001	 wd 0.0000	time 0.1736 (0.2095)	loss 0.7915 (0.8964)	grad_norm 0.2666 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:42:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1303 (0.2084)	loss 0.9600 (0.8962)	grad_norm 0.2710 (0.2649)	loss_scale 32768.0000 (32768.0000)	mem 6174MB
[2024-07-30 02:42:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 249): INFO EPOCH 29 training takes 0:08:52
[2024-07-30 02:42:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_29.pth saving......
[2024-07-30 02:42:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1/diffusion_ft_adapter_conv_b_sequence_stage1/ckpt_epoch_29.pth saved !!!
[2024-07-30 02:43:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 289): INFO Test: [0/98]	Time 19.881 (19.881)	Loss 0.3577 (0.3577)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 6174MB
[2024-07-30 02:43:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 296): INFO  * Acc@1 84.912 Acc@5 97.490
[2024-07-30 02:43:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.9%
[2024-07-30 02:43:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 182): INFO Max accuracy: 84.92%
[2024-07-30 02:43:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process1] (main.py 189): INFO Training time 4:46:00
